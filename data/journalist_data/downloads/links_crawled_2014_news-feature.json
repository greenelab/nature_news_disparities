[
{"file_id": "517012a", "url": "https://www.nature.com/articles/517012a", "year": 2014, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "From Gradzilla to coffee consumption: the research enterprise quantified for the year to come. The global research enterprise is already vast, whether measured in people, publications, patents or refreshments. And it is getting bigger fast. Assuming current trends continue, here is what the New Year has in store. \n               And here is  \n               boxed-text \n             \n                     Listings: Science in culture 2015 2014-Dec-31 \n                   \n                     Hopes for the year ahead 2014-Dec-31 \n                   \n                     Leadership: New year's resolutions 2014-Dec-30 \n                   \n                     What to expect in 2015 2014-Dec-30 \n                   \n                     Blog post: Hopes for the year ahead \n                   \n                     Nature Special: A preview of 2015 in science \n                   \n                     NSF Science and Engineering Indicators 2014 \n                   \n                     World Intellectual Property Organization \n                   \n                     World Bank databases \n                   Reprints and Permissions"},
{"file_id": "514418a", "url": "https://www.nature.com/articles/514418a", "year": 2014, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "Bioethicists are setting up consultancies for research \u2014 but some scientists question whether they are needed. Stacy Hodgkinson and Amy Lewin had the best of intentions when they enrolled the pregnant 15-year-old in their study. The psychologists were evaluating an educational programme for young parents-to-be, and the teenager met all the inclusion criteria: she was 15\u201332 weeks pregnant with her first child, under 19 years of age, and her partner \u2014 who did not live with her \u2014 was willing to participate in the study. There was just one problem. Dad was 24 years old, and according to local laws he was guilty of child sexual abuse for sleeping with a minor. The couple had apparently lied to each other about their ages, but not to Hodgkinson and Lewin, both then at the Children's National Health System in Washington DC. This presented a dilemma. The scientists had promised the participants that their information would be kept confidential. But did that trump their legal duty to report the crime to the police? And how would that affect the family? \u201cHere was a young father telling us he'd like to be involved in his child's life in a positive way,\u201d says Lewin, who is now at the University of Maryland in College Park. Telling the authorities, she says, \u201ccould potentially do more harm than good\u201d. In search of moral and legal guidance, Hodgkinson and Lewin contacted Tomas Silber, a paediatrician who also runs a research ethics consultation service, a 'one-stop shop' for advice on thorny research issues. To Silber, the course of action was clear. \u201cThere's only one thing you can do,\u201d he says. \u201cYou have to report it.\u201d After explaining their legal obligations to the couple, Lewin and Hodgkinson told the police, who launched an investigation. The teen and her partner broke off contact with the researchers, and Hodgkinson does not know whether the father maintained a positive presence in the child's or the mother's life \u2014 which was ultimately the goal of their programme. \u201cSometimes you do the right thing, but the consequences aren't good,\u201d says Silber. Ethical dilemmas in research are nothing new; what is new is that scientists can go to formal ethics consultancies such as Silber's to get advice. Unlike the standard way that scientists receive ethical guidance, through institutional review boards (IRBs), these services offer non-binding counsel. And because they do not form part of the regulatory process, they can weigh in on a wider range of issues \u2014 from mundane matters of informed consent and study protocol to controversial topics such as the use of experimental Ebola treatments \u2014 and offer more creative solutions. The consulting services are \u201ca really new area\u201d, says Joshua Crites, a research ethicist at the Pennsylvania State College of Medicine in Hershey. \u201cEven some of the most basic questions get complicated really quickly, and it's better to have a group of ethicists working together to sort this out.\u201d But many scientists either do not know that they exist or fear using them because they could add red tape to an already heavy administrative burden. And this year, the US National Institutes of Health (NIH) scrapped funding for a working group to support ethics-consultation services and to develop best practices for the profession. Although financial support could return in some form, ethicists are not waiting around for it. Benjamin Wilfond, director of the Treuman Katz Center for Pediatric Bioethics at Seattle Children's Hospital in Washington, has set up the Clinical Research Ethics Consultation Collaborative, a group of around 35 bioethicists who hope to keep improving the consultation service model, even without NIH support. \u201cThere's energy behind continuing what we started,\u201d says Holly Taylor, a research ethicist at the Johns Hopkins Berman Institute of Bioethics in Baltimore, Maryland, and a member of the group. \n               Here to help \n             IRB approval is required for almost all human-subject research in the United States. The foundations for current IRB practices emerged 40 years ago in the wake of numerous ethical lapses in research, including the infamous Tuskegee experiments performed in Alabama between 1932 and 1972, in which doctors allowed syphilis to progress untreated in hundreds of African American men. Today, IRBs are the main channels for policing ethics in academic medical studies. But their primary function is to ensure adherence to regulatory and legal requirements. They do not always include members with bioethics expertise, and discussion of ethics sometimes takes the form of box-ticking rather than careful deliberation. That is where consultants come in. Unlike IRBs, consultants can provide guidance throughout a study \u2014 not just at the point of regulatory review \u2014 and do so in a non-confrontational advice-giving capacity. They offer \u201can open space for talking about research ethics in a way that is not driven by the regulatory environment\u201d, says Marion Danis, chief of the bioethics consultation service at the NIH Clinical Center, a research hospital in Bethesda, Maryland. The Clinical Center was the first organization to launch a research ethics consultancy, in 1996, and a handful of academic medical centres followed suit over the next decade. Then, in 2006, the NIH launched the Clinical and Translational Science Award programme to enhance drug development and testing in academic settings, and it led to a rapid expansion of the concept in the United States. According to a survey published last year, by 2010 more than 30 academic institutions had set up research-ethics consultation services. That said, fewer than half of them had fielded calls by researchers seeking advice in the previous year, and just six got more than ten calls 1 . \u201cIn most places, these have not ended up being high-volume activities,\u201d says Steven Joffe, a medical ethicist who led a fairly idle service at Harvard Medical School in Boston, Massachusetts, until moving to the University of Pennsylvania Perelman School of Medicine in Philadelphia in 2013. Amy Hagopian, a global-health researcher at the University of Washington in Seattle, found herself turning to an ethics consultant for help with a study in Iraq to find out how many people had died as a result of the US-led conflict that began there in 2003. Her team needed to obtain informed consent from participants, but the researchers on the ground in Iraq were concerned that including the University of Washington's name on the consent forms \u2014 a requirement for IRB approval \u2014 would make it difficult to get the data they needed. \u201cThey feared that being associated with American institutions would get them killed\u201d, says Hagopian. \u201cThey dug in their heels and refused\u201d to carry the form. Hagopian wanted to strip the university's name from the consent document, but the IRB insisted that it was an important part of informed consent, which is meant to protect participants, not the investigators. The impasse brought Hagopian and her team to Wilfond. He concluded that it would be ethical to remove mention of the institution, for three main reasons: first, research subjects would also be placed at risk by signing a document linking them to the University of Washington; second, apart from the link to the United States, the research involved minimal risk to the participants; and third, the study would not happen unless the name of the institution was removed. The IRB eventually agreed with Wilfond. The researchers went ahead with the study and found that nearly half a million people had died from causes attributable to the Iraq war between 2003 and 2011 \u2014 a figure much greater than most previous estimates2. \u201cWe couldn't have done this without him,\u201d Hagopian says of Wilfond. \n               Worldly advice \n             Of course, bioethicists have been providing advice about research for years, long before the NIH created a formal service. Outside the United States, ethics consultations mostly happen through the regional equivalent of an IRB or take place in casual conversations or 'kerbside consults'. \u201cAll in all, it's pretty ad hoc,\u201d says Mark Sheehan, who studies ethics at the Ethox Centre of the University of Oxford, UK. At some institutions in Canada, ethics advice about research studies can also be sought through the services that help patients and doctors to settle end-of-life decisions and other moral issues in health care. Unlike in the United States, where training programmes in research ethics and clinical ethics are usually separate, in Canada \u201cwe all tend to have both kinds of expertise pretty much\u201d, says Ann Heesters, a bioethicist at the Toronto Rehabilitation Institute in Ontario, one of the only Canadian hospitals that publicizes the availability of ethics consultations for researchers. According to Heesters, around one in every seven of her consultations pertains to research. In Australia, \u201cit's very difficult for researchers to be able to seek advice before they submit the full application\u201d for official ethics review, says Nikola Stepanov, who studies research ethics and law at the University of Queensland in Brisbane. And if a human-research-ethics committee \u2014 the Australian equivalent of an IRB \u2014 finds ethical problems in a study's protocol, researchers may have trouble finding a formal channel for further guidance. \u201cWe're obviously in the stage that the United States was at before it brought in these ethics consultations,\u201d says Stepanov. \u201cSomething more formalized would be very appropriate.\u201d But not all ethicists agree that a separate service is needed, even within the United States. \u201cIf the IRB has the responsibility for ethics review, why are we pulling in someone else?\u201d asks Susan Kornetsky, director of clinical research compliance at Boston Children's Hospital in Massachusetts. Norman Fost, who studies ethical and legal issues in research at the University of Wisconsin\u2013Madison, would rather see bioethics panels folded into the standard IRB structure. Because IRBs are \u201ca toll gate that everybody has to go through\u201d, Fost says, these panels, which would ideally include qualified ethicists, should \u201clook at every single protocol and identify problems that nobody else has yet identified\u201d. Relying on a separate, optional service means that some problems could be missed. \u201cIt's the cases they're not getting called about that worry me,\u201d he says. \n               Complementary services \n             Advocates say that the aim of consultancy services is to complement IRBs and other oversight bodies, not to become entwined with them. \u201cFor innovative research designs, you need some independent person to say, 'Well, let's step back and think about this not just from the standpoint of do the regulations permit it, but does it fulfil the spirit of what people want done with the public research enterprise?',\u201d says bioethicist Steven Miles at the University of Minnesota in Minneapolis. Wilfond has been working to increase the visibility and the rigour of ethics consultancies. Last year, for example, he and Taylor launched a biannual series in the  American Journal of Bioethics  entitled 'Challenging Cases in Research Ethics'. The latest case, from Silber and his colleagues describing the obligation to report statutory rape, was published in September 3 . Wilfond is also collecting descriptive data about consultations and has expanded the reach of his service at the University of Washington by welcoming external requests \u2014 including from pharmaceutical companies, which typically employ armies of lawyers but rarely bioethicists. In such cases, the University of Washington consults on a fee-for-service basis: US$200 an hour for drug companies, less for non-profit organizations. The Stanford Center for Biomedical Ethics in California also works with drug firms. There, panellists provide their time and advice at no cost, on the condition that they can publish case studies. In 2011, for example, a start-up company approached the centre for guidance on the sale and promotion of a prenatal genetic test that involves analysing fetal DNA circulating in maternal blood (see   Nature   478 , 440; 2011). The consultation led to an academic paper that called for amendments to informed-consent procedures and restrictions on the sale of direct-to-consumer tests 4 . \u201cMany of our consults end up that way,\u201d says Mildred Cho, associate director of the Stanford centre. \u201cWe do treat these things as scholarly activity as well as a service.\u201d Cho estimates that around one-quarter of her service's cases come from the drug industry. Wilfond is currently working to expand the panels to draw in a wider range of views and to broaden the experience of panellists, a move that he considers one of his most innovative for ethics consultancies. In June, he was called into a meeting at Seattle Children's Hospital with Ron Gibson, director of the hospital's cystic fibrosis centre. Gibson had been gathering data from several studies that were using laboratory tests that can be performed only in a research setting or fall outside of recommended guidelines, but he was unsure whether he should incorporate the results into patients' routine clinical care. Seven bioethicists from Wilfond's collaborative telephoned into the meeting, ready to offer their take. As the consultation began, Wilfond explained that the point of bringing the ethicists into the discussion was twofold. First, it would offer Gibson a wider range of opinions, and second, it would expose the advisers on the phone to a case they might not otherwise have been involved in. \u201cThere's a lot of learning that goes on bidirectionally,\u201d Wilfond says. The hour-long meeting was \u201ceducational\u201d, says Gibson, who has since implemented a new policy for his research programme, although he declined to discuss specifics. \u201cThe spectrum of opinions on various levels of data sharing was reassuring that there is likely not one best way to address the issue.\u201d Wilfond and his colleagues hope that more scientists and clinicians will start to see the benefits of their services. \u201cThere just hasn't been an awareness of how important this is,\u201d says Charles MacKay, a consultant in clinical and research bioethics in Bethesda, Maryland. But getting scientists to actually buy into such services may require a shift in attitudes. \u201cResearchers generally have become members of a culture of research compliance,\u201d says Christian Simon, a bioethicist at the University of Iowa Carver College of Medicine in Iowa City. They are responsive to what IRBs require, he says, but that sometimes means that they are unwilling to step back and consider the finer ethical details. \u201cWe're not the ethics police,\u201d says Reid Cushman, co-director of the ethics consultation service at the University of Miami in Florida. \u201cWe're just another resource to help you stay out of trouble.\u201d \n                     Subject to question 2013-Aug-21 \n                   \n                     Human experiments: First, do harm 2012-Feb-08 \n                   \n                     Fetal gene screening comes to market 2011-Oct-25 \n                   \n                     Bioethics: Dial \u2018E\u2019 for ethics 2006-Apr-26 \n                   \n                     Blog post: \u2018Ethical failure\u2019 leaves one-quarter of all clinical trials unpublished \n                   \n                     Benjamin Wilfond \n                   Reprints and Permissions"},
{"file_id": "515022a", "url": "https://www.nature.com/articles/515022a", "year": 2014, "authors": [{"name": "Alison Abbott"}, {"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "In the 25 years since the collapse of communism, the countries of central and Eastern Europe have each carved their own identity in science. In a lab so new that it still smells of fresh paint, Katarzyna Komorowska expertly handles what looks like a futuristic coffee machine. It is actually an advanced scanning electron microscope with the power to manipulate delicate samples and visualize minute details \u2014 one of several impressive-looking machines in Komorowska's lab in the city of Wroc\u0142aw in southwest Poland. Komorowska turns on the device's ion beam. Minutes later, a screen shows the razor-sharp image of a bearded dwarf clutching a graphene molecule that she has just engraved on a grain of sand. The etched sand is a historical reminder as well as a technological feat. The dwarf became an unlikely symbol of the 1980s protest movement that grew in Wroc\u0142aw against Poland's ruling communist regime. It is now something of a city mascot: Wroc\u0142aw hosts more than 300 dwarf statues, and visitors can track them down using a brochure and app. The fact that the dwarf can be engraved on a grain of sand in seconds also symbolizes the formidable efforts that this city is making to become a science hub in central Europe. Since 2007, more than \u20ac200 million (US$250 million) in European Union (EU) funds have helped to turn Wroc\u0142aw's abandoned military hospital into a campus dedicated to academic and commercial science \u2014 just one part of Poland's high-flying ambitions for science as a whole. Change has swept through central and Eastern Europe since the collapse of communism there 25 years ago. The revolution was quick and unforeseen. For a few months in 1989, protests swelled behind the Iron Curtain, the political barrier that since the end of the Second World War had isolated communist central and Eastern European countries from the West. Then, on 9 November that year, the East German government opened the Berlin Wall and first a trickle \u2014 then a flood \u2014 of East and West Germans began to scale the barrier, delirious with joy. A year later, Germany had been reunified and almost every other former communist country in the region had instituted a democratic government. Researchers shared in the elation: the fall of the Iron Curtain brought them personal and intellectual freedom. But it came with a host of new problems. During the 45-year communist rule, research institutions from the Baltic to the Balkans had been academically isolated and unable to compete with the rest of the world. Now they were suddenly being judged by international standards, and their science looked hopelessly out of date. For many, political change also brought poverty, as economies collapsed. Pitifully low salaries, lack of funding and antiquated labs prompted swathes of scientists to go west or seek careers outside academia. Those who stayed relied almost exclusively on foreign aid. \u201cAfter the Iron Curtain had come down, science and higher-education institutes were thrown into turmoil,\u201d says Liviu Mattei, pro-rector of the Central European University in Budapest. \u201cFew places in the world have gone through such rapid and brutal changes.\u201d Twenty-five years on, researchers find themselves in a more stable scientific landscape. The economic decline of the 1990s has mostly ended, and in the past decade some countries have enjoyed a marked economic upswing that has allowed governments to inject money into science. Membership of the EU has been a major driver of change. In 2004, the union welcomed eight former communist countries, including Poland, Estonia and Hungary. Romania and Bulgaria followed in 2007, and Croatia in 2014. One EU citizen in five now lives in one of these new member states. These relatively poor countries have enjoyed huge financial injections from EU structural funds, which are designed to narrow economic and social disparities between European regions and are distributed by each country's government. In the 2007\u201313 financial period, Brussels invested a staggering \u20ac170 billion in cohesion and regional development in the new member states, and more than \u20ac20 billion of this was earmarked for science and innovation. Most countries have also created funding agencies that allocate grants on a strictly competitive basis. \u201cScientists had to learn that performance is now the sole basis of getting funded and published,\u201d says Franci Dem\u0161ar, director of the Slovenian Research Agency in Ljubljana. \u201cIt has been a difficult process, but it has greatly improved science produced in this part of the world.\u201d But within central and Eastern Europe, different nations have followed starkly different trajectories in science, as a spotlight on three countries in the region reveals (see 'Science in the new Europe'). Poland hosted relatively little research until recent years, but the nation is now becoming a political and economic powerhouse in the region and is rapidly expanding in science. Estonia, a small country on Europe's northern fringes, reformed its research system early on and is now reaping the benefits. Hungary, by contrast, maintained some scientific strengths during the communist era, but a lack of investment is now putting that legacy at risk. This means that when it comes to science, central and Eastern European countries \u2014 so similar to each other in their communist days \u2014 are growing steadily apart. What is more, almost all are still fighting a brain drain to the West. \u201cThe talent for science is all there,\u201d says Lars Wall\u00f8e, a physiologist at the University of Oslo and former president of the Academy of Europe. \u201cNow the conditions and institutions in the region need to develop in such a way that the best minds will find it worthwhile to stay.\u201d \n               Poland: Pockets of excellence \n             Poland has embraced science like few other countries in the region, as is evident on the Wroc\u0142aw campus with its dwarf-engraving machine. The campus has the air of a sprawling, half-built start-up company. Extensive lab spaces are still under construction and will be opened to scientists and entrepreneurs next year. On a rainy September morning, labs and meeting rooms are buzzing with scientists testing equipment and discussing results. The campus is called EIT+, to echo the Budapest-based European Institute of Innovation and Technology, an EU effort to create a network of research powerhouses. Scientists at EIT+ pursue independent research in subjects including nanotechnology, materials science and biotechnology. But the campus operates as a limited company that aims to provide industry with research and services such as microscopy and crystallography, at a profit. \u201cTwenty years ago the kind of things we're doing would have been unthinkable,\u201d says Jerzy Langer, head of EIT+ and a former Polish deputy science minister. \u201cThe time has long gone that scientists here could say 'Sorry, I can't do this or that, I haven't got the money and the tools'.\u201d Komorowska joined EIT+ in 2012. She had trained in Wroc\u0142aw, but left the country for postdoctoral work in France and Belgium, with no plans to return. She changed her mind when she got a job offer from the newly created Wroc\u0142aw Research Centre, part of EIT+. She now leads the centre's laboratory of nanotechnology and semiconductor structures, where she is developing an automated system for analysing the mineral and metal content of rocks \u2014 data of use to the massive Polish mining industry. Some 35 million z\u0142oty (US$10.5 million) are being spent on furnishing the lab with the latest electron microscopes for characterizing and observing materials. \u201cThe conditions to do science in Poland have improved enormously now that we have the same equipment as most people in the West,\u201d says Komorowska. That was not true in the communist era, when the country operated just a few basic-research institutes. The situation began to change in 1990, when Lech Wa\u0142\u0119sa, leader of the trade union Solidarity, took over as Polish president and began to modernize the country. Poland went through a painful transition when democracy and a market-based economy arrived \u2014 and science was shaken to the core. Seeking more lucrative opportunities, thousands of researchers went into business or left to pursue academic careers abroad. What remained of the communist research base was jealously guarded by an increasingly inward-looking group of ageing academics and produced little in terms of internationally competitive science. The situation really turned around when Poland joined the EU in 2004. With 38.5 million inhabitants, the country is by far the most populous member state in the region, and also receives the most EU structural funds. That money has helped to fuel its remarkable economic growth, which has been outpacing that of most other European countries since 2008. Science has ridden on the coat-tails of the country's thriving economy, and the government has recognized that research is an important route to further growth. Domestic funding has doubled over the past five years, although overall science expenditure is still very low compared to other places in Europe, at less than 1% of gross domestic product (GDP). Outside Wroc\u0142aw, the picture is not entirely rosy. Polish science still has a workforce shortage, with fewer than 4 researchers per 1,000 people in the labour force \u2014 well below the EU average of just under 7. Scientists acknowledge that many of the country's research institutes \u2014 particularly the 80 run by the Polish Academy of Sciences \u2014 are reluctant to reform. What is more, says Langer, at some university departments a spirit of obedience lingers from the communist days and tends to stifle creativity. \u201cMany students are too shy,\u201d he says. \u201cThey think that ideas are no good if the authorities haven't rubber-stamped them.\u201d To address the problem, Poland's National Centre for Research and Development now runs a programme designed to bring back early-career Polish scientists who trained abroad, and to attract foreign scientists, by offering them up to 1.2 million z\u0142oty to start an independent group. (Securing this funding was another reason that Komorowska was persuaded to return.) And there is a wave of fresh talent on the way. The number of science graduates from Polish universities has more than doubled over the past decade, and overall student numbers have more than quadrupled since 1990. Every tenth student in the EU is now Polish. \u201cThis is most encouraging,\u201d says Langer. Scientists in Poland still want to see better standards of science education, and more innovative institutes such as EIT+. \u201cThere is sufficient money available now to support promising ideas, but we need to create institutional environs in which science can flower,\u201d says Janusz Bujnicki, a molecular biologist at the International Institute of Molecular and Cell Biology in Warsaw. \u201cThat task has only just begun.\u201d \n               Estonia: Small and focused \n             Andres Metspalu, who runs one of the world's most sought-after banks of human DNA, says that his life began at 40. That was in 1991, the year Estonia declared its independence from the Soviet Union and began its bumpy path towards a Western-style research base. Before this, Metspalu's ambition to do world-class science had been constantly undermined by the absurdities of the isolationist Soviet system. That system had acknowledged his talent: it selected him in 1981 as one of only 25 young scientists across the entire Soviet Union to spend a year training in a US laboratory after his doctorate. (He studied biochemistry at Columbia University in New York, then at Yale University in New Haven, Connecticut.) But his young family had to stay in Tartu, Estonia, so that the authorities could be confident that he would not defect. And after that, he was forbidden further travel until Mikhail Gorbachev swept to power in the Soviet Union in 1985. Over the next few years, Metspalu watched the Soviet Union fall apart. With a population of just 1.3 million people, Estonia found change easier than some larger countries. This, and some good political decision-making, helped to make the country one of the first in the region to reverse its economic decline. The government was prudent enough to stimulate business-orientated research and entrepreneurship early on. Newly created research centres and technology parks in Tartu and the capital, Tallinn, became the nuclei for a remarkable scientific upswing. After the human genome was sequenced at the turn of the millennium, Metspalu, who worked at the University of Tartu, saw a scientific opportunity. Thanks to support from Estonia's EU structural funds, he was able to launch a project to recruit individuals to donate their genetic and health data to a national biobank. In other countries, such as Iceland, similar efforts to collect personal information en masse were met with suspicion. But that was not the case among the newly liberated and optimistic people of Estonia, many of whom were happy to sign up. The biobank now includes genetic and health information on 5% of the country's adult population and is a valuable international resource in studies that require very large numbers of people to identify risk genes associated with common diseases, including obesity 1  and schizophrenia 2 . The database has been \u201cextremely helpful\u201d, says Michael O'Donovan, a psychiatrist at Cardiff University, UK, who was involved in the schizophrenia study. As well as biotechnology, the Estonian government is focusing scientific investment on disciplines such as materials science and informatics. The chemistry department at the University of Tartu, for example, is prominent in the area of superacids and superbases, useful in the development of batteries for electric cars, and has collaborations with car manufacturers in several countries. Estonia has steadily increased its investment in research and development, from 0.72% of the GDP in 2002 to 2.18% in 2012 \u2014 the second highest in central and Eastern Europe, after Slovenia. The country is keen to reap the rewards of its investments by using the biobank for more than just research. This year, the government formally pledged to support a project that would \u2014 in the next few years \u2014 link the repository with Estonia's centralized health database to allow physicians to support their diagnoses and therapies with individual genetic information. If all goes to plan, this will put Estonia among the world's front-runners in personalized medicine. \u201cTwenty-five years ago I'd hardly have imagined being able to contribute to a biomedical revolution,\u201d says Metspalu. \n               Hungary: Science on a shoestring \n             Last year, plant biologist Eva Kondorosi decided to pack up her life in Paris and take her European funding to the Hungarian Academy of Sciences (HAS) Biological Research Centre, where she had begun her research career in the late 1970s. But she found something odd: unlike many research institutes across central and Eastern Europe, this one seemed to be less exciting in the modern era than it had been in the communist one. \u201cIt has lost the vibrancy we enjoyed there in the 1970s and 80s,\u201d she says. If that sounds paradoxical, it is because science in Hungary is a bit of a paradox. During the communist years, research survived against the odds. It was separated from universities and centralized in institutes \u2014 run by the highly politicized HAS \u2014 that tended to appoint cronies and members of the ruling communist party to key research posts. At the end of the 1960s, however, the HAS made a bold decision to start afresh in biology by creating the Biological Research Centre in the southern city of Szeged, close to Hungary's southern border and away from the stifling politics of the capital. Staff members at the multidisciplinary centre were appointed on merit, not political status. The centre became a safe haven for intellectuals, and Kondorosi did a doctorate in plant sciences there. The country's borders were slightly more open than those of most of its communist counterparts, and throughout the 1980s researchers could gain permission to visit the West. This kept the science in Szeged cutting-edge, and the atmosphere buzzing. After the fall of communism, lack of investment dampened enthusiasm, and many scientists left. Funding has never fully picked up. Hungary is one of only three countries to have reduced its public spending on research since 2007 (the others are Croatia and Bulgaria), and it dedicated just 8.5% of its 2007\u201313 EU structural funds to research \u2014 compared to Estonia's 20% and Poland's 14%. What is more, much of the structural funding has gone to companies, not academia. Despite this, the country's rich academic legacy still attracts the best Hungarian scientists. Hungary has hosted more researchers with prestigious European Research Council grants \u2014 including Kondorosi \u2014 than any other former communist EU country. Kondorosi returned because the interdisciplinary organization of the Biological Research Centre offered her the opportunity to take the lessons she had learnt from studying plant\u2013bacteria symbiosis and apply them to medicine. She and others have discovered antimicrobial activity in some of the bacteria that plants use for nitrogen-fixing 3 , for example. Hungary's scientific culture has inspired international confidence. In 2012, CERN, the European laboratory for particle physics, built an advanced data centre close to Budapest. And Szeged is going to be home to one of the three nodes of the Extreme Light Infrastructure, a collaborative EU project to advance laser science (see  Nature 489, 351; 2012 ). Scientists are hopeful that the climate for science is warming up. In June this year, the charismatic J\u00f3zsef P\u00e1link\u00e1s was appointed to the new position of government commissioner for science and innovation. P\u00e1link\u00e1s was formerly president of the HAS, where in 2011 he forced through reforms that streamlined the academy's 40 research units into 15 larger centres, and increased scientific competition for funding. In his new role he will be responsible for advising the government on science policy, as well as coordinating the spending of the current round of research-related structural funds. In this round, he says, around 12% will be directed to research. Scientists in Hungary and elsewhere have their eyes on the EU's Horizon 2020 programme, the \u20ac80 billion of research funding that started this year and will last until 2020. In a bid to widen participation, Brussels has launched a 'teaming' scheme that allows less potent member states to create or upgrade competitive research centres in partnership with leading institutions from other countries. Financial and organizational aid will remain crucial in narrowing the gaps between countries, says Wall\u00f8e. \u201cSome places will always have more capacity of science than others,\u201d he says. \u201cBut every country should have at least one thing or the other that is really good. That is how science is organized in the United States \u2014 and that's what it should be like in Europe.\u201d \n                 See Editorial \n                 page 7 \n               \n                     Romanian science in free fall 2013-Aug-21 \n                   \n                     Rhapsody for Hungarian science 2011-Dec-12 \n                   \n                     Science fortunes of Balkan neighbours diverge 2011-Jan-12 \n                   \n                     Eastern Europe: Scaling the wall 2009-Sep-30 \n                   \n                     Polish science: Poles apart, or together with Europe? 2003-Jan-30 \n                   \n                     Nature special: Eastern Europe \n                   \n                     European Institute of Innovation and Technology \n                   \n                     Wroc\u0142aw Research Centre EIT+ \n                   \n                     Polish National Centre for Research and Development \n                   \n                     Estonian Genome Center \n                   \n                     Biological Research Centre of the Hungarian Academy of Sciences \n                   \n                     Horizon 2020 \n                   Reprints and Permissions"},
{"file_id": "514554a", "url": "https://www.nature.com/articles/514554a", "year": 2014, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Scientists know a lot about the virus that causes Ebola \u2014 but there are many puzzles that they have yet to solve. To much of the world, the virus behind the devastating Ebola outbreak in Africa seems to have stormed out of nowhere. But Leslie Lobel thinks we should have seen it coming. In 2012, Lobel and a team of researchers spent six months in Uganda studying the Ebola virus and related viruses. Over the course of their stay, these pathogens caused at least four separate outbreaks of disease in central Africa, affecting more than 100 people. To Lobel, a virologist at Ben-Gurion University of the Negev in Beer-Sheva, Israel, the outbreaks felt like the small tremors that can precede a major earthquake. \u201cWe all said, something is going on here; something big is going to happen,\u201d he says. Like Lobel, other scientists have predicted that these viruses would one day cause a major epidemic \u2014 and the current outbreak, which has so far killed nearly 5,000 people, has proved them right. There are five species of closely related viruses that scientists refer to as 'ebolaviruses'; the species behind the current outbreak,  Zaire ebolavirus , is more generally known as 'the Ebola virus'. Along with Marburg virus and Lloviu virus, the ebolaviruses make up the filoviruses, a family that was unknown before the 1960s. All of the filoviruses share a common structure, and most of them cause life-threatening haemorrhagic fevers in humans. Research on these once-ignored viruses took off after the 2001 anthrax attacks in the United States, which prompted officials to sink money into investigating lethal pathogens that might be used in bioterror attacks and to build dedicated laboratories where they can be safely studied. Scientists have learned how these viruses work and have created the first experimental vaccines and therapies that might stop them. \u201cThe biodefence funding has been huge,\u201d says microbiologist Thomas Geisbert of the University of Texas Medical Branch at Galveston, who has studied ebolaviruses for 26 years. But the advances in knowledge about filoviruses have also exposed the gaps. Scientists suspect that more members of the filovirus family remain to be discovered and in other parts of the world. They are also working to understand which animals naturally harbour filoviruses and why human filovirus outbreaks seem to be rising in frequency: they have occurred in 19 of the past 21 years, and three times this year alone. Finding answers is difficult because outbreaks are unpredictable and laboratory work with filoviruses requires the highest security measures. In the past few months, research has necessarily taken a back seat to efforts to control the Ebola outbreak \u2014 but as the epidemic escalates, science is coming to the fore. Researchers are recognizing that they might be able to stop this Ebola virus only if they understand its biology and how to control it. \u201cWe need a lot more information about the virology, the clinical presentation and the epidemiology of this virus,\u201d says Michael Osterholm, a public-health scientist at the University of Minnesota's Center for Infectious Disease Research and Policy in Minneapolis. \u201cNobody underestimates the difficulty of doing that research in these settings, but it is really important to get this information.\u201d With this in mind,  Nature  asked leading researchers to discuss the most urgent scientific questions about the Ebola virus and other filoviruses \u2014 the questions that, if answered, might prevent another disastrous outbreak, or help to contain the current one. This is what they said. \n               Where do filoviruses come from? \n             In July 2007, a miner who had been prospecting for lead and gold in a Ugandan cave became infected with Marburg virus. Officials closed the cave, and a team of researchers led by the US Centers for Disease Control and Prevention (CDC) swept in to investigate. They hoped to answer a decades-old question: what animal is the natural host for filoviruses? The mystery had lingered since 1967, when Marburg virus \u2014 the first filovirus to be discovered \u2014 sickened European lab workers who had handled imported monkeys. The high lethality of filovirus infection in monkeys, humans and other apes suggested that primates were not the natural hosts: if a virus kills too many of its hosts, then it cannot propagate and dies out. There were clues that bats might be the 'reservoir' species. But to prove it, scientists needed to find an infected bat. The researchers captured some 1,300 bats roosting in the cave and tested their blood for Marburg virus 1 . They finally found what they were looking for: infectious Marburg viruses isolated from five Egyptian fruit bats, none of which showed symptoms of disease. The team also found more infected bats in a nearby cave that had been linked to a previous Marburg virus outbreak. It is not entirely clear how the virus is transmitted from bats to people, although the most likely route is through contact with bodily fluids. Bats infected with Marburg virus in the lab shed the virus in their mouths, so wild bats might spread it by leaving traces on fruit that is later eaten by other animals 2 . Knowing the host species for the other filoviruses is crucial. \u201cUntil we understand what that reservoir is, it is difficult to limit your encroachment on that species,\u201d says virologist John Dye of the US Army Medical Research Institute of Infectious Diseases in Fort Detrick, Maryland. Researchers now strongly suspect that bats are the natural host for ebolaviruses, too. In 1976, during one of the first known Ebola outbreaks, the six people who were initially infected worked in a factory room in Sudan that was home to roosting bats 3 . Researchers have since isolated antibodies to ebolaviruses from bats, as well as snippets of genetic material from the viruses. But proving that bats are the reservoir has been maddeningly difficult \u2014 no one has isolated an infectious ebolavirus from a wild bat, and it has been difficult to trace rare and sporadic outbreaks back to a source. The ebolavirus outbreaks have originated in many locations, only sometimes among people or animals who have had contact with bats. \u201cYou're pretty much looking at the entire tropical forest,\u201d says Jonathan Towner, a molecular virologist at the CDC in Atlanta, Georgia, who trapped bats in Uganda for the Marburg investigations. The current outbreak is thought to have begun in southeastern Guinea in December 2013, when a two-year-old boy died of a mysterious illness that quickly spread to family members and health-care workers. So far, the response to the outbreak has been much more focused on containing it than tracing its source. \u201cThe public-health crisis is unprecedented,\u201d Towner says. \u201cThere's no room for an ecology investigation at this point.\u201d \n               How widespread are filoviruses? \n             Filoviruses are not just found in bats and primates. That became clear in 2008, when Philippine officials called for help to investigate an outbreak of disease in pigs. When researchers arrived, they found that the pigs were infected with  Reston ebolavirus 4  \u2014 a species that was first discovered in monkeys imported to the United States from the Philippines in 1989. The pig discovery was a shock because until then, no ebolavirus had been known to naturally infect a farm animal. And it was not a freak event:  Reston ebolavirus  was also reported 5  in pigs in China in 2012. However, the Reston virus seems to be relatively harmless to humans. People working on the Philippine pig farms harboured antibodies to it \u2014 a sign that the pigs had transmitted the virus to them \u2014 but no humans fell ill. In 2011, scientists confirmed that pigs can also become infected with  Zaire ebolavirus 6 . The concern now is that pigs could serve as a mixing vessel for filoviruses. Pigs could be simultaneously infected with several filoviruses, which might exchange genetic material to eventually produce new versions that are capable of sickening humans. \u201cThe relevant practical question is, do we need to worry about Reston? If it is truly not pathogenic in humans, is there a potential that it could change?\u201d says Erica Ollmann Saphire, a structural biologist who studies filoviruses at the Scripps Research Institute in La Jolla, California.  We all said, something is going on here; something big is going to happen.  Scientists are probably just beginning to understand the different types of filoviruses and their geographic reach. The list of known filoviruses only recently expanded: the fifth ebolavirus ( Bundibugyo ebolavirus ) was discovered in Uganda in 2007, and the Lloviu virus was identified from dead bats in Spain in 2011. \u201cWe may find more members of the filovirus family elsewhere in the world,\u201d says virologist Ayato Takada of Hokkaido University in Sapporo, Japan. The fact that the viruses are more common than was once thought suggests that they have been around for a very long time \u2014 perhaps for most of human history. And it could be that scientists are detecting only a small fraction of events in which they cross over from animals to humans. Researchers are now trying to work out how frequently they jump into people and, when they do, how often they cause disease. In 2010, one team reported that as many as 20% of people in some areas of Gabon carry antibodies to  Zaire ebolavirus  in their blood, indicating that they were exposed to the virus in the past without becoming ill 7 . Lobel says that these data must be taken with a pinch of salt, and that the assays could actually be detecting immune responses to viruses similar to ebolaviruses. In his studies, people known to have survived definite Ebola virus infections had a different immune response from those who have never been infected. He and other researchers are now surveying immune responses among more filovirus survivors. A pressing question in the present outbreak is how the currently circulating  Zaire ebolavirus  might be changing. Its rapid spread hints that there could be something different about this strain \u2014 possibly that it has become easier to pass from one person to another. \u201cWe have to start investigating whether the 2014 strain behaves like previous outbreak strains, or whether it could potentially be more transmissible,\u201d says Kristian Andersen, a virologist at the Broad Institute in Cambridge, Massachusetts. Andersen is careful to note that there are no data to suggest this yet. Although a handful of researchers have raised fears that the virus might mutate into an airborne form, most think it is unlikely that the virus could change so dramatically in such a short time. Genetic analyses have shown that this strain of  Zaire ebolavirus  has mutated hundreds of times since it diverged from an ancestral virus about ten years ago 8  (see  Nature   http://doi.org/vsd ; 2014 ), but no one yet knows whether any of these mutations have altered important properties of the virus. Instead, its unprecedented spread is thought to be due to the fact that it emerged in an area of Africa where people were unfamiliar with the virus and how to control it, allowing it to escape to urban centres. Researchers are now carrying out more-detailed studies of the virus to better understand its origins and characteristics. \n               Are we making Ebola our own worst enemy? \n             In September, epidemiologists published an analysis in which they mapped the locations of all ebolavirus outbreaks in Africa along with the known ranges of three bat species that are candidate reservoirs for the viruses 9 . They also plotted changes in African populations and mobility \u2014 for instance, the proportion of each country that lives in rural and urban areas. The team wanted to pinpoint the areas that might be at highest risk of future outbreaks. Before this year, all but one of the human ebolavirus outbreaks could be traced back to central Africa, and the  Zaire ebolavirus  species had never been seen in West Africa. But \u201cwe shouldn't have been massively surprised that it was there\u201d, says epidemiologist Simon Hay of the University of Oxford, UK, who led the analysis. Even when he and his team did not include data from the current outbreak, they predicted that the three hardest-hit countries \u2014 Sierra Leone, Guinea and Liberia \u2014 would be at high risk for an ebolavirus outbreak because they have large numbers of people living in areas inhabited by the bats. In all, the analysis highlights 22 African countries where ebolavirus outbreaks are likely to start, putting 22 million people at risk (see 'Know your enemy'). The study also begins to explain why filovirus outbreaks seem to be growing more frequent, widespread and larger in size. Human populations in countries that are likely to harbour filoviruses have nearly tripled since the viruses were first discovered, and flight traffic has increased by one-third since 2005. The viruses are not coming to us; instead, we are encroaching on the viruses, as population growth and increasing travel put humans in contact with viral hosts, and then people unwittingly transport the viruses around the world. \u201cThere's this perception that these outbreaks occur in completely isolated, remote parts of Africa where they burn out before they hit major population centres,\u201d Hay says. \u201cObviously we've seen that this is not the case with the latest outbreak.\u201d His team has released its data 10  and hopes that others will now use the information to look for more specific environmental factors \u2014 combinations of climate and geography that might pinpoint the precise places where future outbreaks are most likely to occur. \n               Why is Ebola so lethal? \n             Ebola virus is one of the most lethal viruses known. In the current outbreak, an estimated 60\u201370% of those infected have died, and in previous outbreaks the figure has reached almost 90%. (Only rabies, smallpox and a handful of other viruses are as fatal if left untreated.) The reason that Ebola virus and other filoviruses are so lethal is because they turn the body's own defences against it. Normally when a virus invades the body, it triggers cells in the 'innate' arm of the immune system, which cause inflammation and other reactions to fight off the infection. The Ebola virus, however, infects and cripples innate immune cells, taking out this first line of defence. These dying cells also trigger a destructive flood of chemicals, called a cytokine storm, and cause the downstream death of cells that normally make protective antibodies. Other highly pathogenic viruses also trigger cytokine storms, but filoviruses are thought to be particularly lethal because they affect a wide array of tissues. As well as the immune system, Ebola virus attacks the spleen and kidneys, where it destroys cells that help the body to regulate its fluid and chemical balance and that make proteins that help the blood to clot. At its worst, Ebola virus causes the liver, lungs and kidneys to shut down, other organs to fail and the blood vessels to leak fluid into surrounding tissues. Too often, this ends in death. If scientists can understand how the immune systems of survivors were able to fight off the virus, they might be able to encourage this form of defence through a vaccine. Researchers have found that survivors of previous outbreaks managed to make antibodies to Ebola virus, avoid the cytokine storm and preserve their immune cells during the course of infection. But why they can do this, and others cannot, is a mystery. \u201cThe question in our mind is, how did they survive?\u201d Lobel says.  The question in our mind is, how did they survive?  The right treatment can raise the chance of survival. In the current outbreak, people infected with Ebola virus who are treated in developed countries have been more likely to survive than patients treated in Africa, because they receive much more intensive care. There is no targeted treatment for filoviruses, but doctors can closely monitor and correct blood chemistry and protein imbalances caused by organ failure and fluid loss \u2014 with intravenous drips or kidney dialysis, for example. \u201cRight now, the Ebola virus has such a high lethality because of the level of care provided in the places where it is occurring,\u201d says Dye. \u201cIf health care gets better, the lethality rates will decrease.\u201d Sadly, Osterholm says, even the most basic interventions that could help people infected with Ebola virus are not being provided right now in the hardest-hit areas. For instance, oral rehydration therapy is being widely used in place of intravenous fluid replacement because of the fear that health-care workers could be infected in the process of inserting an intravenous line. Osterholm says that it is urgent to ask how these choices are affecting patients: \u201cIn this setting, what treatments are working? Is what we're doing having any clinical impact?\u201d \n               Can the virus be stopped? \n             Dozens of previous filovirus outbreaks have been halted using the same basic tools: isolating and treating patients, and tracing and monitoring their contacts. Public-health officials have also used this method to contain the spread of Ebola virus in Nigeria and Senegal. But across West Africa as a whole, the public-health response was completely inadequate at the start of the outbreak, which has allowed the virus to spread rapidly. If, as some epidemiologists predict 11 , the disease infects tens or even hundreds of thousands of people by January 2015, then it could become nearly impossible for tried-and-tested public containment measures to bring the epidemic under control. For one thing, it could be unfeasible to recruit and train the numbers of medical staff required. At this stage, some experts say that a new plan is needed. Aid agencies and non-profit organizations are already trying new types of control. In Sierra Leone, officials are building isolation centres that can house patients away from their family and community, to prevent the virus from spreading, but that have fewer qualified health-care workers than a standard treatment facility. It is a controversial move, because it risks sending the message that patients are being warehoused to die. But it acknowledges the harsh reality that existing clinics are full, patients are being turned away, and that this is fuelling the disease spread. \u201cEveryone realizes these smaller-level community facilities are not ideal, but it is trying to do something rather than nothing to try to bring transmission down in communities,\u201d Hay says. Another new approach in this epidemic has been the use of experimental therapies and vaccines developed specifically to target Ebola virus. Much attention has focused on ZMapp \u2014 a cocktail of antibodies that was first identified using mice vaccinated with Ebola virus proteins, and which has been given to several people in this outbreak. In August, researchers reported that ZMapp protected 18 monkeys from dying of Ebola virus \u2014 the first report of a highly successful therapy in animals already showing symptoms of the disease 12 . Researchers are now organizing further tests of this and other medicines, as well as a handful of experimental vaccines. But even if these therapies are proven to work, the challenge is hardly over. The products that have progressed furthest in development are all focused on  Zaire ebolavirus , the most lethal of the four species that sicken humans, but it is unlikely that they will be as effective against other filoviruses. Saphire leads an international consortium that is systematically testing combinations of antibodies to find the ones that work best against different filovirus types. Researchers hope one day to produce therapies that work against multiple filoviruses and that could be used immediately when symptoms are detected, rather than spending precious time diagnosing exactly which virus is making someone ill. All this work has taken on new urgency as predictions about the African outbreak have grown more dire. This year, the US National Institute of Allergy and Infectious Diseases, the Wellcome Trust, the European Union and various drug companies have channelled emergency funding into research on potential drugs and vaccines. And on 3 November, the US Institute of Medicine is convening a meeting in Washington DC to lay out an agenda for research on Ebola virus. That meeting takes place against growing worries that the virus might become endemic in parts of Africa, continuing to sicken and kill people for several years. Researchers understand that the public-health response to this outbreak is a top priority, but they are also becoming more determined to understand this mysterious family of killer viruses. \u201cWhat's happening in West Africa is a desperate situation,\u201d Saphire says. \u201cIt makes people very willing to figure out what they need to do to solve problems.\u201d See Editorial  page 535  and World View  page 537 \n                     Ebola by the numbers: The size, spread and cost of an outbreak 2014-Oct-15 \n                   \n                     Ebola outbreak shuts down malaria-control efforts 2014-Oct-01 \n                   \n                     Infectious disease: Ebola\u2019s lost ward 2014-Sep-24 \n                   \n                     Ebola drug saves infected monkeys 2014-Aug-29 \n                   \n                     Ebola virus mutating rapidly as it spreads 2014-Aug-28 \n                   \n                     Drug saves monkeys from close relative of Ebola 2014-Aug-20 \n                   \n                     Special: Ebola outbreak in West Africa \n                   \n                     World Health Organization Ebola information \n                   \n                     US Centers for Disease Control and Prevention Ebola information \n                   Reprints and Permissions"},
{"file_id": "515185a", "url": "https://www.nature.com/articles/515185a", "year": 2014, "authors": [{"name": "Emily Anthes"}], "parsed_as_year": "2006_or_before", "body": "Cognitive behavioural therapy is the best-studied form of psychotherapy. But researchers are still struggling to understand why it works. Anna's life began to unravel in 2005 when her husband of 30 years announced that he had fallen in love with another woman. \u201cIt had never even occurred to me that my marriage could ever end,\u201d recalls Anna, a retired lawyer then living in Philadelphia, Pennsylvania. \u201cIt was pretty shocking.\u201d Over the course of several months, Anna stopped wanting to get up in the morning. She felt tired all the time, and consumed by negative thoughts. \u201c'I'm worthless.' 'I messed up everything.' 'It's all my fault.'\u201d She needed help, but her first therapist bored her and antidepressants only made her more tired. Then she found Cory Newman, director of the Center for Cognitive Therapy at the University of Pennsylvania, who started her on a different kind of therapy. Anna learned how to obsess less over her setbacks and give herself more credit for her triumphs. \u201cIt was so helpful to talk to someone who steered me to more positive ways of thinking,\u201d says Anna, whose name has been changed at her request. Cognitive therapy, commonly known as cognitive behavioural therapy (CBT), aims to help people to identify and change negative, self-destructive thought patterns. And although it does not work for everyone with depression, data have been accumulating in its favour. \u201cCBT is one of the clear success stories in psychotherapy,\u201d says Stefan Hofmann, a psychologist at Boston University in Massachusetts. Antidepressant drugs are usually the first-line treatment for depression. They are seen as a quick, inexpensive fix \u2014 but clinical trials reveal that only 22\u201340% of patients emerge from depression with drugs alone. Although there are various approaches to psychotherapy, CBT is the most widely studied; a meta-analysis 1  published this year revealed that, depending on how scientists measure outcomes, between 42% and 66% of patients no longer meet the criteria for depression after therapy. But no one knows exactly how CBT helps. Depression is a complex disorder that manifests in many different ways, and CBT is multifaceted, involving a series of talking sessions whose precise content differs from one therapist and patient to another. Working out exactly how it affects the brain requires studies that are difficult to conduct and to fund. Still, researchers are beginning to piece together answers using a combination of clinical psychology and neuroimaging experiments. Learning more about how CBT works \u2014 and why it does not work for everyone \u2014 could ultimately help doctors to deliver better care. \u201cIf we don't understand the active ingredients, it's going to be hard to improve the treatment,\u201d says Daniel Strunk, a psychologist at Ohio State University in Columbus. \u201cIn understanding the mechanism, we might understand that that's more relevant to some patients than others.\u201d CBT encompasses a range of psychotherapies, all based on the premise that people with depression have excessively negative, and often inaccurate, beliefs about themselves and the world. It is designed to equip patients with the skills they need to \u201cbecome their own therapists\u201d, says Strunk, by critically examining those negative beliefs. Correct a person's way of thinking, and the depression will lift, according to the theory. On the face of it, this seems to be supported by results. \u201cThere are dozens of studies that show that people after being treated with cognitive therapy \u2014 and after being less depressed \u2014 show less negative thinking,\u201d says Robert DeRubeis, a psychologist at the University of Pennsylvania. \u201cThat's as easy to demonstrate as it is that gravity exists.\u201d What scientists debate is the mechanism. People treated with antidepressants and other kinds of psychotherapy also show more positive thinking after recovering from depression. So does changing someone's thought patterns actually cause their depression to lift? Or does the therapy relieve depression in a different way \u2014 by helping people to form a bond with a therapist, for example \u2014 so that the positive thinking is merely a consequence of their improved mental health? \n               Unravelling mechanisms \n             To get at this question, researchers have attempted to show that the change in thinking precedes and predicts the gains in mental health. \u201cBy the end of treatment, lots of things will be better,\u201d Strunk says. \u201cAnd so what you really want to do is get inside the moment or moments when someone has a positive therapeutic change and try to understand what's shifting in just those moments.\u201d Research by DeRubeis and his colleagues has revealed 2 , 3  that many depressed adults undergoing CBT experienced 'sudden gains', in which their symptoms lessened significantly between two therapeutic sessions. These rapid changes accounted for more than half of the patients' total improvement over the course of treatment. Recordings of the therapy session just before a sudden gain reveal that a person's way of thinking changes more in that session than in others. \u201cPatients are beginning to speak about changing their minds about many of the negative, exaggerated ways in which they've seen their lives,\u201d says DeRubeis. The fact that they begin demonstrating these cognitive changes just before their symptoms improve suggests that altering a person's thinking style may indeed lead to recovery. Researchers have also shown that learning mental coping skills may be the most important kind of cognitive change during CBT. \u201cThe cardinal skill is catching your thoughts in a moment where your mood takes a turn for the worse and thinking through the accuracy of your thoughts in that moment,\u201d says Strunk. In CBT, therapists will often ask patients to monitor their own thoughts. Anna, for example, had been doing volunteer teaching when she started therapy, and she often found herself comparing her abilities with those of another teacher, which made her feel inadequate. Anna's therapist asked her to describe what she and the other teacher did during classes. \u201cIt was perfectly obvious once you started thinking about it that the other teacher and I both had good moments and bad moments,\u201d Anna recalls. \u201cI had begun to focus on every possible negative about what I did, and every possible positive about someone else.\u201d Anna is no longer in therapy, but when such thoughts return, she can now identify them and examine them to determine whether she is drawing unrealistic conclusions. \u201cIt's not that I never have sweeping negative thoughts,\u201d she says, \u201cbut I'm not so much a victim of them.\u201d Strunk and his colleagues have found 4  that gaining new cognitive coping skills correlates with an improvement in depressive symptoms, even if negative beliefs remain. And once people have learned these skills, they can use them for the rest of their lives, which may explain why the benefits of CBT last even after the treatment has ended \u2014 something that has not proved true for antidepressants. There are not many data on whether other forms of psychotherapy have a similarly protective effect. Some researchers have looked to neuroimaging to understand more about the mechanisms of CBT. People with depression tend to have detectable differences in two primary brain systems: the prefrontal cortex, which is responsible for complex mental tasks such as self-control and planning, and the limbic system \u2014 including the amygdala \u2014 which is involved in emotional processing. In healthy people, the prefrontal cortex can inhibit amygdala activity, keeping emotions in check. But imaging shows that in many people with depression, the prefrontal cortex seems to be less active. \u201cDepressed people have what you might think of as a trigger-happy amygdala,\u201d says Greg Siegle, a neuroscientist at the University of Pittsburgh in Pennsylvania. There is some evidence that CBT can correct these problems. In a study 5  published in 2007, Siegle used functional magnetic resonance imaging (fMRI) to show that depressed adults had increased levels of activity in the amygdala when performing an emotional task and reduced levels of activity in the dorsolateral prefrontal cortex when performing a cognitive task. When he followed up 9 of the trial participants, Siegle found 6  that a 14-week course of cognitive therapy had almost completely reversed the situation. \u201cThe imaging data have been really encouraging,\u201d says Timothy Strauman, a psychologist at Duke University in Durham, North Carolina, who has generated similar results 7 . \u201cWe do find evidence for the kinds of changes that you would expect.\u201d Researchers speculate that CBT \u2014 with its focus on controlling thoughts \u2014 re-engages the underactive prefrontal cortex, which, in turn, helps to quieten the hyperactive limbic system (see 'Desired behaviour'). \u201cCognitive therapy teaches you to step in and use your prefrontal cortex rather than letting your emotions run away with you,\u201d says Siegle. Still, there are caveats. The prefrontal cortex and the amygdala are not the only brain areas that behave differently in depression; nor are they the only areas that therapy affects. The studies have been small and they occasionally contradict each other. \u201cI'm always cautious, because there haven't been enough studies,\u201d says Cynthia Fu, a neuroscientist at the University of East London, UK. She estimates that there have been three to four times as many neuroimaging studies of antidepressant use as of psychotherapy. \u201cIt's a new field, and people use different tasks, they scan people at different times, and that can lead to quite different results.\u201d \n               Tough questions, tough answers \n             As with the changes in negative thinking, it is not yet clear whether these neurological changes are a cause or a consequence of recovery. To answer that, scientists will need to image patients repeatedly throughout the course of CBT to track the changes and determine whether they predict improvement. Such studies are expensive, time-consuming and burdensome for patients. And in general, scientists say, it can be harder to study CBT than antidepressants: there are more confounding factors, because therapists and sessions can vary widely. And it is difficult to administer a placebo. Researchers can compare participants receiving CBT with others who are randomly assigned to receive drugs or pharmacological placebos, or are put on a waiting list for treatment; they can also use a control group made up of patients who receive general counselling, but it is impossible to blind the study properly, because the therapists will know which participants are receiving which treatments. Another challenge is finding funding. \u201cIt's a David-and-Goliath-type comparison,\u201d says Strunk. \u201cThere are pharmaceutical companies that make antidepressants, so there's a lot of financial backing there. The amount of money is just different scales.\u201d Scientists are eager to know why CBT works for only some people, and to be able to identify those who will respond. \u201cThere's a lot of trial and error,\u201d says Lena Quilty, a psychologist at the Centre for Addiction and Mental Health in Toronto, Canada. But every failed treatment can extend a person's suffering and add to the cost of medical care. Certain clinical and demographic factors seem to predict whether a person will respond to drugs or CBT. Those with personality disorders in addition to depression, for instance, tend to do better with antidepressant medications than with cognitive therapy, and married people seem to benefit more from cognitive therapy than from medication. Researchers have now begun searching for patterns of brain activity that can identify how well someone will respond to CBT. In a study 8  published last year, neurologist Helen Mayberg of Emory University in Atlanta, Georgia, and her colleagues used positron emission tomography (PET) to measure glucose metabolism in the brains of 82 adults with depression. They then randomly assigned each participant to receive 12 weeks of treatment with either CBT or a commonly prescribed antidepressant from the selective serotonin reuptake inhibitor class. People with high activity in the right anterior insula, a brain region that communicates with both the amygdala and the prefrontal cortex, tended to respond well to the drug. Those with an underactive insula were more likely to improve with CBT. It is not yet clear why. \u201cFundamentally, one has to think about the network in the brain that goes wrong in depression as being dynamic,\u201d says Mayberg. \u201cThose systems are broken differently in people who respond to different treatments.\u201d Cognitive therapy may be able to repair some problems, whereas drugs may be better at patching up others. Neuroimaging is not yet a practical tool for identifying the best course of treatment, so researchers are working on other approaches. In 2011, Siegle and his colleagues demonstrated 9  that clinicians might be able to use the pupil of the eye as a window on the brain. Depressed adults were shown negative words; those whose pupils did not dilate much had reduced activity in some areas of the prefrontal cortex and were more likely to benefit from cognitive therapy than those whose pupils dilated more. In practice, clinicians hoping to tailor treatments may need to consider many factors, including a person's marital status, brain activity and genetics; a small body of research indicates that people with certain genetic sequences are more likely than others to respond to CBT. And scientists may need to get a better handle on depression itself \u2014 in all its forms and manifestations \u2014 before they can understand how CBT alleviates it and who is likely to benefit. Strauman is optimistic about the growing number of collaborations that he is seeing between neuroscientists and clinical psychologists who are willing to tackle the problem. \u201cI think we're finally at the point,\u201d he says, \u201cwhere the complexity of our thinking is a match for the complexity of the disorder.\u201d \n                     Medical research: If depression were cancer 2014-Nov-12 \n                   \n                     Mental health: Depression needs large human-genetics studies 2014-Nov-12 \n                   \n                     Mental health: A world of depression 2014-Nov-12 \n                   \n                     Depression: The best way forward 2014-Nov-12 \n                   \n                     Psychological treatments: A call for mental-health science 2014-Jul-16 \n                   \n                     What lies beneath 2014-Mar-19 \n                   \n                     Brain scan predicts best therapy for depression 2013-Jun-12 \n                   \n                     Mental health: On the spectrum 2013-Apr-24 \n                   \n                     Therapy deficit 2012-Sep-26 \n                   \n                     Nature  special: Depression \n                   Reprints and Permissions"},
{"file_id": "515182a", "url": "https://www.nature.com/articles/515182a", "year": 2014, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Research into depression has struggled, while studies of cancer have thrived \u2014 but the balance could be shifting. If the extent of human suffering were used to decide which diseases deserve the most medical attention, then depression would be near the top of the list. More than 350 million people are affected by depression, making it one of the most common disorders in the world. It is the biggest cause of disability, and as many as two-thirds of those who commit suicide have the condition. But although depression is common, it is often ignored. Three-quarters of people with depression in the United Kingdom go undiagnosed or untreated \u2014 and even if the disorder is diagnosed, today's medications will work well for only about half of those who seek help. \u201cIt's unbelievable,\u201d says Tom Foley, a psychiatrist at Newcastle University, UK. \u201cIf that was the case in cancer care, it would be an absolute scandal.\u201d The comparison between depression and cancer is a common one. Cancer, too, is a terrible blight: it affects more than 32 million people and kills some 8 million a year, many more than depression. But at least in developed countries, the vast majority of people with recognized cancers do receive treatment. In research, too, depression has failed to keep up with cancer. Cancer research today is a thriving field, unearthing vast catalogues of disease-associated mutations, cranking out genetically targeted therapies and developing sophisticated animal models. Research into depression, meanwhile, seems to have floundered: once-hopeful therapies have failed in clinical trials, genetic studies have come up empty-handed. The field is still struggling to even define the disease \u2014 and overcome the stigma associated with it. Depression research also gets a great deal less funding than that gobbled up by cancer. The US National Institutes of Health pumped about US$5.3 billion into cancer research in 2013 \u2014 a stark contrast to the $415 million it spent on depression research and the $2.2 billion on mental-health research as a whole. The same pattern holds elsewhere: in its most recently completed funding scheme, the European Union invested about \u20ac54.3 million (US$67.4 million) a year for studies of mental-health disorders, \u20ac8 million of which was flagged specifically for depression. The programme allotted \u20ac205 million a year for studies of cancer. No one denies that cancer deserves rich funding and attention, nor do they begrudge the advances made in understanding the disease. Mental-health researchers just wish that they could claim similar advances for their field, and that medical care could offer more. So why has depression not garnered the same scientific resources and attention as cancer? And had it done so, where would understanding of this disorder stand now?  Nature  put these questions to researchers. Although many said that extra money would have solved some challenges earlier, the technology needed to crack others \u2014 by probing the brain and analysing its circuits, for example \u2014 is only now emerging. But some scientists hope that a recent explosion of interest in brain studies will at last push mental-health research into a different league. \u201cCancer's a great inspiration: they've had a lot of investment and they've made big breakthroughs,\u201d says Foley. \u201cThere's no reason why we can't see the same things in depression.\u201d \n               Power of advocacy \n             Research agendas are rarely set by human need alone. Political, social and economic concerns can all tip the balance in favour of one disease or another \u2014 and patient advocates have a major influence on the way that money is handed out. The divide between cancer and depression can be traced back several decades, when strong advocacy helped to spur the United States to declare a 'war on cancer' in 1971. Since then, funding has poured into the field, seeding a huge research enterprise focused on understanding the causes of cancer and finding treatments for it. That war has not been won \u2014 but no world leader ever stood up and declared a war on depression, and that fact is reflected in the more generous funding that cancer still receives. Garen Staglin, co-founder of One Mind, a non-profit organization in Seattle, Washington, that funds mental-health research, estimates that the US public donates about $1 billion a year to support cancer research and patients. Mental-health research typically nets less than one-fifth of that. Campaigning takes energy and confidence \u2014 and the very nature of depression makes it difficult for those with the condition to come forward and campaign for support. But another major factor is the long-standing stigma associated with depression. Many people still do not acknowledge that it is a legitimate condition, says Nelson Freimer, a psychiatric geneticist at the University of California, Los Angeles. \u201cA large proportion of people believe depression is just something that we all feel,\u201d he says. \u201cThey think you should pull your socks up and get back to work.\u201d Cancer, too, once carried a stigma. \u201cPeople didn't want to talk about their cancer,\u201d says Staglin. \u201cThey called it the C-word.\u201d That has changed, he says, as treatments improved, advocacy groups raised awareness and more people spoke out about their battles with the disease. It helped, too, that the reality of cancer is easy to grasp: tumours can be seen, monitored and removed. No such certainty exists in depression, where the affected tissue is locked inside the brain, cannot be easily seen and certainly cannot be cut out. A rigorous diagnosis requires a two-hour session with a psychiatrist, and yet two patients diagnosed with major depressive disorder \u2014 which is how psychiatrists label depression \u2014 can exhibit completely different symptoms. \u201cEven one person can have two depressive episodes and the second time is unrecognizable from the first,\u201d says Tim Dalgleish, a clinical psychologist at the MRC Cognition and Brain Sciences Unit in Cambridge, UK. All this leaves the concept of depression as a disorder vulnerable to attack. \u201cIt's hard for crackpots to say that pancreatic cancer or breast cancer is not real,\u201d says Eric Nestler, a psychiatrist and neuroscientist at the Icahn School of Medicine at Mount Sinai in New York City. \u201cYet somehow they can say that people with mental illness don't have a real illness. It really is awful.\u201d Efforts are under way to change how depression is defined and diagnosed in research. Last year, Thomas Insel, head of the National Institute of Mental Health in Bethesda, Maryland, pushed researchers funded by the institute to eschew classical psychiatric diagnoses, which tend to be indistinct and overlap. Instead, a study might group together patients with specific symptoms, such as anxiety or difficulty with social communication, that are linked to depression as well as to other psychiatric disorders. The hope is that focusing on well-defined traits will reduce some of the experimental noise from artificial diagnostic boundaries, eventually leading to new diagnoses that are grounded in biology. \u201cUltimately, depression is as biological as cancer and heart disease; it is simply a matter of identifying the relevant molecules,\u201d says Nestler. \u201cIt just turned out to be a lot harder than any of us thought it would be decades ago.\u201d \n               Genetic promise \n             Some researchers hope that genetics will help to define depression and delineate subgroups within the condition. That has been the case in cancer, where in the past few years many countries have poured money into the analysis of genomes from a wide range of cancers. The results are revolutionizing the field: they have generated a huge list of mutations linked to cancers, some of which can now be used to match a patient to a therapy. It is a revolution still in progress, but it has placed cancer at the leading edge of personalized medicine. Depression studies have not fared as well. The largest study so far \u2014 a search through the genomes of just over 16,000 patients with major depressive disorder and another 60,000 controls \u2014 has turned up just one, as yet unconfirmed, genetic association 1 . Jonathan Flint, a psychiatrist at the University of Oxford, UK, who has been looking for genetic links to depression for nearly two decades, says that some colleagues ask him why he is still working on the problem. \u201cWhat has held back the entire field is the belief that it's intractable,\u201d he says. \u201cWhat is the point of doing something if you're not going to get anywhere with it?\u201d The problem stems \u2014 yet again \u2014 from the disorder's fuzzy definition: grouping everyone with a diagnosis of major depressive disorder into one genetic study is like looking for the genetic risk factors for fever, explains Flint. \u201cYou would have lumped together autoimmune disease, infection, cancer and a whole set of different conditions.\u201d And it is not clear that more funding a few decades ago would have helped the field to move much faster, he says, because the genomic technologies needed for such studies have become available only in the past ten years. But even since then, cancer studies have far outstripped those for depression. \u201cSurely we can do better,\u201d he says. \u201cWe have to do better.\u201d Scientists are already doing better in identifying the genes that underlie some other mental-health disorders, such as schizophrenia. Like depression, schizophrenia can be difficult to diagnose accurately, and initial attempts to find genetic risk factors yielded few hits. But an international group of researchers known as the Psychiatric Genomics Consortium worked to ramp up the sample size in the hope of increasing statistical power and helping the signals to rise above the noise. In September, the consortium published an analysis 2  of nearly 40,000 genomes from people with schizophrenia that together highlighted 108 different regions potentially linked to the disorder. The consortium now plans to do the same for depression, aiming to scrutinize up to 60,000 genomes from people with the condition. \n               Animals on trial \n             Results from genetic studies could help depression researchers to clear another major hurdle: the development of better animal models. Scientists studying cancer now have a rich choice of model animals that form a crucial part of their research. These include mice that have been engineered to express cancer-associated genes found in human tumours, and even 'personalized' animal models that have been tailored to study a person's disease by transplanting a piece of their tumour into the mouse. Depression researchers, however, have faced huge challenges in creating mice or other animals that behave in a way that mirrors how people are affected by the disorder (see  page 200 ). Those who do study depression in animals often use physical stresses to prompt behaviours seen in people with depression. The most common assay is the 'forced swim test', in which mice are plunged into water and timed to see how long they struggle to get out. (Those that give up sooner are taken to have depression-like behaviour.) The assay has been used to screen drug candidates \u2014 and many antidepressants on the market do extend the time that a mouse is willing to fight. But it is far from ideal: human depressive episodes are rarely triggered by physical stress, and there are signs that antidepressants act differently in this model compared to humans. In mice, they start to work almost immediately, for example, whereas it can take a month or longer to see an effect in humans. In an attempt to mimic what happens in humans more closely, Nestler and his colleagues subject mice to chronic social \u2014 rather than physical \u2014 stress. In this 'social defeat' model, the researchers place a mouse in a cage with a \u201cbigger, meaner mouse\u201d, he says. The bigger mouse starts to beat up the smaller one, and the fighting continues until the researchers separate the mice using a screen. After ten days of fighting, the smaller mouse typically no longer shows interest in pleasurable activities such as sex or drinking sugar water, and avoids social contact, even with litter-mates 3 . This reflects some of the symptoms shown by people with depression. So far, the social defeat model seems to better mimic the action of antidepressants in humans, says neuroscientist Ming-Hu Han, also at the Icahn School of Medicine. Experimental drugs that act quickly in people, for example, also work rapidly to ease responses to social defeat in mice. Mental-health researchers acknowledge that even the best animal models remain a crude reflection of a complicated human disorder. \u201cTo understand human circuitry, it isn't just about whether you will seek out sugar water,\u201d says Helen Mayberg, a neurologist at Emory University in Atlanta, Georgia. \u201cThere's guilt, there's suicide.\u201d It is also difficult to use animals to study the placebo effect, which is particularly prominent in depression studies and complicates clinical trials of potential antidepressants. Some scientists question whether an animal can ever truly mimic the human condition. \u201cI don't like to say I study depression because I don't think that can be done in animals,\u201d says Olivier Berton at the University of Pennsylvania in Philadelphia. \u201cThose representations of disease are hurting the field and we need to forget them.\u201d Instead, Berton says that he studies stress responses in mice. There is one way in which the science of cancer and depression are closely aligned, and that is in the growing appreciation of their complexity. Genetic studies of tumours are showing that they are not just divided into lung, liver and other tissue types, but that each tumour is an intricate mosaic of cells with different mutations and behaviours, and that this mosaic differs from one person to another (see  Nature   464 , 972\u2013974; 2010 ). In depression, an equally complicated picture is beginning to emerge. Researchers always knew that understanding it would be difficult \u2014 this is the brain, after all. But as they sort through the thousands of different kinds of neuron in the brain, it is becoming clear that it is important not only to identify the cells, but also to find how they are connected to one another in circuits. Efforts now under way to understand neural circuits may not have happened any earlier, even if depression research had been funded to cancer levels, says Nestler. Picking them apart requires methods that did not exist until recently \u2014 for studying single cells, mapping neural connections and activating specific brain circuits. \u201cWe lacked some of the basic knowledge and tools of the brain,\u201d he says. \n               Circuit testing \n             Now, with those tools in hand, researchers are deep into dissecting the neural circuits involved in depression and working out how to manipulate them using methods that rely on magnets or electrical current. Such work could point to treatments that go beyond the traditional antidepressant pill, says Noah Philip, a psychiatrist at Brown University in Providence, Rhode Island. \u201cTreating depression isn't as simple as filling up a tank of neurotransmitters,\u201d he says. \u201cIt's correcting a disorder of different neural networks that are not behaving properly.\u201d Mayberg's team, for example, has been testing deep-brain stimulation as a means to relieve depression. Initial studies found a response rate of around 75%, she says, and she hopes to raise that rate using new imaging techniques to guide the surgery. Nestler and other researchers argue that it would have been premature to declare a war on depression in the 1970s \u2014 but that now, with techniques coming online for brain research, could be the right time. \u201cThis is still going to take a couple of decades,\u201d he says. \u201cBut I have complete confidence that it will work.\u201d One of the biggest challenges for the field is to spread that confidence and attract more bright scientists to tackle depression, however thorny the problem may seem. \u201cYou don't throw your hands up because it's intractable,\u201d says Kelsey Martin, a neuroscientist at the University of California, Los Angeles. \u201cYou figure out the best way to find a route into the problem.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               Reprints and Permissions"},
{"file_id": "515179a", "url": "https://www.nature.com/articles/515179a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Depression causes more disability than any other disorder. A special issue explores how science can help. A few months after the world went grey, Sue Wright checked into a hospital. A social slight had flipped a switch in her mind, draining life of colour and joy. Blue skies became dull; laughter was unthinkable. Often, the depression left her bedridden. \u201cI had prided myself on being able to get through anything,\u201d says Wright, now a social worker in Germantown, Maryland. \u201cSuddenly, I couldn't.\u201d Wright's story is familiar to too many people. Depression is not just the most common mental-health disorder: it is responsible for a greater burden of disability than any other cause. In this special issue,  Nature  asks why that burden is so great, how science is helping and where research is running aground. A graphic tour on  page 180  shows that depression is far from a Western blight, and that many of the countries most afflicted by it are those with the least resources to help. Some mental-health experts say that the high levels of undiagnosed or untreated depression would not be tolerated for a disease such as cancer, and a News Feature ( page 182 ) examines this claim. It finds that the absence of a crisp diagnosis and a lack of tools to understand the brain's complexities have held back therapy and research. The urgent question is how to overcome those barriers, and scientists are exploring several routes. Some argue that there is much to be learned from studying the mechanisms of existing antidepressants; others that there is most promise in teasing apart the affected brain circuits (see  page 200 ) or gleaning information on common medicines that might have unexpected benefits for brain disorders (see  page 165 ). Identifying the genes associated with depression has been a thankless task, but ambitious studies involving many thousands of patients are now called for (see  page 189 ). There is also plenty to be done to refine existing treatments, such as cognitive behavioural therapy, and to tailor them to groups who might benefit most ( page 185 ). Medication, counselling and electroshock therapy did not work for Wright. After trawling through medical journals, she found a psychiatrist prescribing drug combinations that may boost the effect of antidepressants. After weeks of one such combination plus therapy, Wright realized that the sky was blue again. It took months for her to find a way out; the hope is that research will find a faster route to relief. \n                     Psychological treatments: A call for mental-health science 2014-Jul-16 \n                   \n                     No dishonour in depression 2013-Jun-12 \n                   \n                     Mental health: On the spectrum 2013-Apr-24 \n                   \n                     Nature  special: Depression \n                   \n                     Nature  special: The autism enigma \n                   \n                     Nature  special: Schizophrenia \n                   \n                     National Institute of Mental Health on depression \n                   \n                     World Health Organization on depression \n                   Reprints and Permissions"},
{"file_id": "the-top-100-papers-1.16224", "url": "https://www.nature.com/news/the-top-100-papers-1.16224", "year": 2014, "authors": [], "parsed_as_year": "2011_2015", "body": "The discovery of high-temperature superconductors, the determination of DNA\u2019s double-helix structure, the first observations that the expansion of the Universe is accelerating \u2014 all of these breakthroughs won Nobel prizes and international acclaim. Yet none of the papers that announced them comes anywhere close to ranking among the 100 most highly cited papers of all time. Citations, in which one paper refers to earlier works, are the standard means by which authors acknowledge the source of their methods, ideas and findings, and are often used as a rough measure of a paper\u2019s importance. Fifty years ago, Eugene Garfield published the Science Citation Index (SCI), the first systematic effort to track citations in the scientific literature. To mark the anniversary,  Nature  asked Thomson Reuters, which now owns the SCI, to list the 100 most highly cited papers of all time. (See the full list at  Web of Science Top 100.xls  or the  interactive graphic , below.) The search covered all of Thomson Reuter\u2019s Web of Science, an online version of the SCI that also includes databases covering the social sciences, arts and humanities, conference proceedings and some books. It lists papers published from 1900 to the present day. The exercise revealed some surprises, not least that it takes a staggering 12,119 citations to rank in the top 100 \u2014 and that many of the world\u2019s most famous papers do not make the cut. A few that do, such as the first observation 1  of carbon nanotubes (number\u00a036) are indeed classic discoveries. But the vast majority describe experimental methods or software that have become essential in their fields. The most cited work in history, for example, is a 1951 paper 2  describing an assay to determine the amount of protein in a solution. It has now gathered more than 305,000 citations \u2014 a recognition that always puzzled its lead author, the late US biochemist Oliver Lowry. \u201cAlthough I really know it is not a great paper\u2009\u2026\u2009I secretly get a kick out of the response,\u201d he wrote in 1977. The colossal size of the scholarly literature means that the top-100 papers are extreme outliers. Thomson Reuter\u2019s Web of Science holds some 58 million items. If that corpus were scaled to Mount Kilimanjaro, then the 100 most-cited papers would represent just 1 centimetre at the peak. Only 14,499 papers\u00a0\u2014\u00a0roughly a metre and a half\u2019s worth\u00a0\u2014\u00a0have more than 1,000 citations (see  \u2018The paper mountain\u2019 ). Meanwhile, the foothills comprise works that have been cited only once, if at all\u00a0\u2014\u00a0a group that encompasses roughly half of the items. Nobody fully understands what distinguishes the sliver at the top from papers that are merely very well known \u2014 but researchers\u2019 customs explain some of it. Paul Wouters, director of the Centre for Science and Technology Studies in Leiden, the Netherlands, says that many methods papers \u201cbecome a standard reference that one cites in order to make clear to other scientists what kind of work one is doing\u201d. Another common practice in science ensures that truly foundational discoveries \u2014 Einstein\u2019s special theory of relativity, for instance \u2014 get fewer citations than they might deserve: they are so important that they quickly enter the textbooks or are incorporated into the main text of papers as terms deemed so familiar that they do not need a citation. Citation counts are riddled with other confounding factors. The volume of citations has increased, for example \u2014 yet older papers have had more time to accrue citations. Biologists tend to cite one another\u2019s work more frequently than, say, physicists. And not all fields produce the same number of publications. Modern bibliometricians therefore recoil from methods as crude as simply counting citations when they want to measure a paper\u2019s value: instead, they prefer to compare counts for papers of similar age, and in comparable fields. Nor is Thomson Reuters\u2019 list the only ranking system available. Google Scholar compiled its own top-100 list for  Nature  (see  \u2018An alternative ranking\u2019 ). It is based on many more citations because the search engine culls references from a much greater (although poorly characterized) literature base, including from a large range of books. In that list, available at  Google Scholar Top 100.xls , economics papers have more prominence. Google Scholar\u2019s list also features books, which Thomson Reuters did not analyse. But among the science papers, many of the same titles show up. Yet even with all the caveats, the old-fashioned hall of fame still has value. If nothing else, it serves as a reminder of the nature of scientific knowledge. To make exciting advances, researchers rely on relatively unsung papers to describe experimental methods, databases and software. Here  Nature  tours some of the key methods that tens of thousands of citations have hoisted to the top of science\u2019s Kilimanjaro \u2014 essential, but rarely thrust into the limelight. For decades, the top-100 list has been dominated by protein biochemistry. The 1951 paper 2  describing the Lowry method for quantifying protein remains practically unreachable at number\u00a01, even though many biochemists say that it and the competing Bradford assay 3  \u2014 described by paper number\u00a03 on the list \u2014 are a tad outdated. In between, at number\u00a02, is Laemmli buffer 4 , which is used in a different kind of protein analysis. The dominance of these techniques is attributable to the high volume of citations in cell and molecular biology, where they remain indispensable tools. At least two of the biological techniques described by top-100 papers have resulted in Nobel prizes. Number\u00a04 on the list describes the DNA-sequencing method 5  that earned the late Frederick Sanger his share of the 1980 Nobel Prize in Chemistry. Number\u00a063 describes polymerase chain reaction (PCR) 6 , a method for copying segments of DNA that earned US biochemist Kary Mullis the prize in 1993. By helping scientists to explore and manipulate DNA, both methods have helped to drive a revolution in genetic research that continues to this day. Other methods have received less public acclaim, but are not without their rewards. In the 1980s, the Italian cancer geneticist Nicoletta Sacchi linked up with Polish molecular biologist Piotr Chomczynski in the United States to publish 7  a fast, inexpensive way to extract RNA from a biological sample. As it became wildly popular \u2014 currently, it is number\u00a05 on the list \u2014 Chomczynski patented modifications on the technique and built a business out of selling the reagents. Now at the Roswell Park Cancer Institute in Buffalo, New York, Sacchi says that she received little in the way of monetary rewards, but takes satisfaction from seeing great discoveries built on her work. The technique played a part in the explosive growth in the study of short RNA molecules that do not code for protein, for example. \u201cThat is what I would consider, scientifically speaking, a great reward,\u201d she says. The rapid expansion of genetic sequencing since Sanger\u2019s contribution has helped to boost the ranking of papers describing ways to analyse the sequences. A prime example is BLAST (Basic Local Alignment Search Tool), which for two decades has been a household name for biologists wanting to work out what genes and proteins do. Users simply have to open the program in a web browser and plug in a DNA, RNA or protein sequence. Within seconds, they will be shown related sequences from thousands of organisms \u2014 along with information about the function of those sequences and even links to relevant literature. So popular is BLAST that versions 8 ,  9  of the program feature twice on the list, at spots 12 and 14. But owing to the vagaries of citation habits, BLAST has been bumped down the list by Clustal, a complementary programme for aligning multiple sequences at once. Clustal allows researchers to describe the evolutionary relationships between sequences from different organisms, to find matches among seemingly unrelated sequences and to predict how a change at a specific point in a gene or protein might affect its function. A 1994 paper 10  describing ClustalW, a user-friendly version of the software, is currently number\u00a010 on the list. A 1997 paper 11  on a later version called ClustalX is number\u00a028. The team that developed ClustalW, at the European Molecular Biology Laboratory in Heidelberg, Germany, had created the program to work on a personal computer, rather than a mainframe. But the software was transformed when Julie Thompson, a computer scientist from the private sector, joined the lab in 1991. \u201cIt was a program written by biologists; I\u2019m trying to find a nice way to say that,\u201d says Thompson, who is now at the Institute of Genetics and Molecular and Cellular Biology in Strasbourg, France. Thompson rewrote the program to ready it for the volume and complexity of the genome data being generated at the time, while also making it easier to use. The teams behind BLAST and Clustal are competitive about the ranking of their papers. It is a friendly sort of competition, however, says Des Higgins, a biologist at University College Dublin, and a member of the Clustal team. \u201cBLAST was a game-changer, and they\u2019ve earned every citation that they get.\u201d Another field buoyed by the growth in genome sequencing is phylogenetics, the study of evolutionary relationships between species. Number\u00a020 on the list is a paper 12  that introduced the \u201cneighbor-joining\u201d method, a fast, efficient way of placing a large number of organisms into a phylogenetic tree according to some measure of evolutionary distance between them, such as genetic variation. It links related organisms together one pair at a time until a tree is resolved. Physical anthropologist Naruya Saitou helped to devise the technique when he joined Masatoshi Nei\u2019s lab at the University of Texas in Houston in the 1980s to work on human evolution and molecular genetics, two fields that were starting to burst at the seams with information. \u201cWe physical anthropologists were facing kind of the big data of that time,\u201d says Saitou, now at Japan\u2019s National Institute of Genetics in Mishima. The technique made it possible to devise trees from large data sets without eating up computer resources. (And, in a nice cross-fertilization within the top-100, Clustal\u2019s algorithms use the same strategy.) Number 41\u00a0on the list is a description 13  of how to apply statistics to phylogenies. In 1984, evolutionary biologist Joe Felsenstein of the University of Washington in Seattle adapted a statistical tool known as the bootstrap to infer the accuracy of different parts of an evolutionary tree. The bootstrap involves resampling data from a set many times over, then using the variation in the resulting estimates to determine the confidence for individual branches. Although the paper was slow to amass citations, it rapidly grew in popularity in the 1990s and 2000s as molecular biologists recognized the need to attach such intervals to their predictions. Felsenstein says that the concept of the bootstrap 14 , devised in 1979 by Bradley Efron, a statistician at Stanford University in California, was much more fundamental than his work. But applying the method to a biological problem means it is cited by a much larger pool of researchers. His high citation count is also a consequence of how busy he was at the time, he says: he crammed everything into one paper rather than publishing multiple papers on the topic, which might have diluted the number of citations each one received. \u201cI was unable to go off and write four more papers on the same thing,\u201d he says. \u201cI was too swamped to do that, not too principled.\u201d Although the top-100 list has a rich seam of papers on statistics, says Stephen Stigler, a statistician at the University of Chicago in Illinois and an expert on the history of the field, \u201cthese papers are not at all those that have been most important to us statisticians\u201d. Rather, they are the ones that have proved to be most useful to the vastly larger population of practising scientists. Much of this crossover success stems from the ever-expanding stream of data coming out of biomedical labs. For example, the most frequently cited statistics paper (number 11) is a 1958 publication 15  by US statisticians Edward Kaplan and Paul Meier that helps researchers to find survival patterns for a population, such as participants in clinical trials. That introduced what is now known as the Kaplan\u2013Meier estimate. The second (number\u00a024) was British statistician David Cox\u2019s 1972 paper 16  that expanded these survival analyses to include factors such as gender and age. The Kaplan\u2013Meier paper was a sleeper hit, receiving almost no citations until computing power boomed in the 1970s, making the methods accessible to non-specialists. Simplicity and ease of use also boosted the popularity of papers in this field. British statisticians Martin Bland and Douglas Altman made the list (number\u00a029) with a technique 17  \u2014 now known as the Bland\u2013Altman plot \u2014 for visualizing how well two measurement methods agree. The same idea had been introduced by another statistician 14 years earlier, but Bland and Altman presented it in an accessible way that has won citations ever since. The oldest and youngest papers in the statistics group deal with the same problem\u00a0\u2014\u00a0multiple comparisons of data\u00a0\u2014\u00a0but from very different scientific milieux. US statistician David Duncan\u2019s 1955 paper 18  (number 64) is useful when a few groups need to be compared. But at number 59, Israeli statisticians Yoav Benjamini and Yosef Hochberg\u2019s 1995 paper 19  on controlling the false-discovery rate is ideally suited for data coming from fields such as genomics or neuroscience imaging, in which comparisons number in the hundreds of thousands \u2014 a scale that Duncan could hardly have imagined. As Efron observes: \u201cThe story is one of the computer slowly, then not so slowly, making its influence felt on statistical theory as well as on practice.\u201d When theorists want to model a piece of matter \u2014 be it a drug molecule or a slab of metal \u2014 they often use software to calculate the behaviour of the material\u2019s electrons. From this knowledge flows an understanding of numerous other properties: a protein\u2019s reactivity, for instance, or how easily Earth\u2019s liquid iron outer core conducts heat. Most of this software is built on density functional theory (DFT), easily the most heavily cited concept in the physical sciences. Twelve papers on the top-100 list relate to it, including 2 of the top 10. At its heart, DFT is an approximation that makes impossible mathematics easy, says Feliciano Giustino, a materials physicist at the University of Oxford, UK. To study electronic behaviour in a silicon crystal by taking account of how every electron and every nucleus interacts with every other electron and nucleus, a researcher would need to analyse one sextillion (10 21 ) terabytes of data, he says \u2014 far beyond the capacity of any conceivable computer. DFT reduces the data requirement to just a few hundred kilobytes, well within the capacity of a standard laptop. Theoretical physicist Walter Kohn led the development of DFT half a century ago in papers 20 ,  21  that now rank as numbers 34 and 39. Kohn realized that he could calculate a system\u2019s properties, such as its lowest energy state, by assuming that each electron reacts to all the others not as individuals, but as a smeared-out average. In principle, the mathematics are straightforward: the system behaves like a continuous fluid with a density that varies from point to point. Hence the theory\u2019s name. But a few decades passed before researchers found ways to implement the idea for real materials, says Giustino. Two 22 ,  23  top-100 papers are technical recipes on which the most popular DFT methods and software packages are built. One (number\u00a08) is by Axel Becke, a theoretical chemist at Dalhousie University in Halifax, Canada, and the other (number\u00a07) is by US-based theoretical chemists Chengteh Lee, Weitao Yang and Robert Parr. In 1992, computational chemist John Pople (who would share the 1998 Nobel prize with Kohn) included a form of DFT in his popular Gaussian software package. Software users probably cite the original theoretical papers even if they do not fully understand the theory, says Becke. \u201cThe theory, mathematics and computer software are specialized and are the concern of quantum physicists and chemists,\u201d he says. \u201cBut the applications are endless. At a fundamental level, DFT can be used to describe all of chemistry, biochemistry, biology, nanosystems and materials. Everything in our terrestrial world depends on the motions of electrons \u2014 therefore, DFT literally underlies everything.\u201d George Sheldrick, a chemist at the University of G\u00f6ttingen in Germany, began to write software to help solve crystal structures in the 1970s. In those days, he says, \u201cyou couldn\u2019t get grant money for that kind of project. My job was to teach chemistry, and I wrote the programs as a hobby in my spare time.\u201d But over 40\u00a0years, his work gave rise to the regularly updated SHELX suite of computer programs, which has become one of the most popular tools for analysing the scattering patterns of X-rays that are shot through a crystal \u2014 thereby revealing the atomic structure. The extent of that popularity became apparent after 2008, when Sheldrick published a review paper 24  about the history of the system, and noted that it might serve as a general literature citation whenever any of the SHELX programs were used. Readers followed his advice. In the past 6 years, that review paper has amassed almost 38,000 citations, catapulting it to number\u00a013 and making it the highest-ranked paper published in the past two decades. The top-100 list is scattered with other tools essential to crystallography and structural biology. These include papers describing the HKL suite 25  (number 23) for analysing X-ray diffraction data; the PROCHECK programs 26  (number 71) used to analyse whether a proposed protein structure seems geometrically normal or outlandish; and two programs 27 ,  28  used to sketch molecular structures (numbers 82 and 95). These tools are the \u201cbricks and mortar\u201d for determining crystal structures, says Philip Bourne, associate director for data science at the US National Institutes of Health in Bethesda, Maryland. An unusual entry, appearing at number\u00a022, is a 1976 paper 29  from Robert Shannon \u2014 a researcher at the giant chemical firm DuPont in Wilmington, Delaware, who compiled a comprehensive list of the radii of ions in a series of different materials. Robin Grimes, a materials scientist at Imperial College London, says that physicists, chemists and theorists still cite this paper when they look up values of ionic size, which often correlate neatly with other properties of a substance. This has made it the highest formally-cited database of all time. \u201cWe often cite these kinds of papers almost without thinking about it,\u201d says Paul Fossati, one of Grimes\u2019s research colleagues. The same could be said for many of the methods and databases in the top 100. The list reveals just how powerfully research has been affected by computation and the analysis of large data sets. But it also serves as a reminder that the position of any particular methods paper or database at the top of the citation charts is also down to luck and circumstance. Still, there is one powerful lesson for researchers, notes Peter Moore, a chemist at Yale University in New Haven, Connecticut. \u201cIf citations are what you want,\u201d he says, \u201cdevising a method that makes it possible for people to do the experiments they want at all, or more easily, will get you a lot further than, say, discovering the secret of the Universe\u201d."},
{"file_id": "514287a", "url": "https://www.nature.com/articles/514287a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Universities must evolve if they are to survive. A special issue of  Nature  examines the many ways to build a modern campus. When the first universities emerged in eleventh-century Europe, their mission was education, scholarship and nothing else. They housed bright young clerics, studying the newly rediscovered works of ancient thinkers such as Aristotle and Euclid. Only in the nineteenth century, following the lead of Britain and Germany, did universities begin to give equal weight to a second mission: scientific research. But in the past few decades, universities around the world have begun to take on further missions. Today they are supposed to be not only centres of education and discovery, but also engines of economic growth, beacons of social justice and laboratories for new modes of learning. In the face of these sometimes conflicting requirements \u2014 not to mention financial pressure from cash-strapped governments \u2014 today's universities are evolving and changing at an unprecedented pace. In this special issue,  Nature  looks at some of the myriad ways in which universities around the world are trying to free themselves from old habits of thought, and to explore new ways of doing things. One perennial issue is the departmental structure that keeps researchers mentally and physically separated. Two articles look at US attempts to tackle that problem: the first, on  page 292 , describes how Arizona State University in Tempe is aggressively promoting interdisciplinary centres; and the second, on  page 297 , discusses efforts to facilitate the commercialization of research by putting scientists from industry in the same buildings as their academic counterparts. A second challenge is the ivory-tower mindset that leads faculty members to disdain commercial activity. A Comment (see  page 295 ) reveals efforts in China to introduce a Western-style tenure system that will encourage innovation and risk-taking. Other countries are grappling with their own educational legacies, and a News Feature explores some of the diverse efforts to institute change (see  page 288 ). A South African university is attempting to overcome the legacy of apartheid, for example, whereas one in South Korea is throwing out ineffective teaching methods such as mass lectures. There is plenty more content at  nature.com/universities . No one knows which of these experiments will produce the best-educated students or the greatest leaps in academic understanding (see  page 273 ). But all share the sentiment that the twenty-first-century university could be dramatically different from the institutions of the past. \n                     The university experiment: Campus as laboratory 2014-Oct-15 \n                   \n                     Universities challenged 2014-Oct-15 \n                   \n                     Developing excellence: Chinese university reform in three steps 2014-Oct-15 \n                   \n                     Academia and industry: Companies on campus 2014-Oct-15 \n                   \n                     Arizona's big bet: The research rethink 2014-Oct-15 \n                   \n                     Nature  special: The university experiment \n                   Reprints and Permissions"},
{"file_id": "515484a", "url": "https://www.nature.com/articles/515484a", "year": 2014, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA has 35 kilograms of plutonium-238 to power its deep-space missions \u2014 but that will not get it very far. Ken Wilson peers through a yellow-tinted window at the clutter of bottles and chemical equipment on the other side. He is protected from the radiation their contents are giving off by five thick panes of glass interspersed with some 400 litres of oil. Working in such a \u2018hot cell\u2019 is routine for Wilson, who is one of the top nuclear technicians here at the Oak Ridge National Laboratory (ORNL) in Tennessee. Grasping the handholds of some robotic manipulator arms, he begins to move them like extensions of his own lanky frame \u2014 first picking up bottles inside the cell, then uncapping them and pouring liquids from one container to another. Eventually, Wilson will add the residue of all this remote-controlled chemistry to a dark-brown liquid that fills two bottles sitting off in the hot cell\u2019s corner. This liquid is a concentrated solution of plutonium-238: a highly radioactive isotope that was made here at Oak Ridge, and that Wilson is now working to purify. Its ultimate destination is deep space, where heat from its decay will power NASA missions such as future Mars rovers, or spacecraft heading to the outer Solar System, where the Sun\u2019s rays can be too dim for solar panels. NASA will be relieved to get this  238 Pu, because it is increasingly anxious about running out. The isotope is not found in nature, so it has to be made in nuclear reactors. But the main US supply shut down in 1988, when the Savannah River Plant near Aiken, South Carolina, run by the Department of Energy (DOE), stopped making  238 Pu as part of a nuclear-weapons phase-out. Four years later, the DOE began purchasing small amounts of the isotope from the Russian government, but those acquisitions have also ended. As a result, NASA now has just 35 kilograms of plutonium product \u2014 a small supply that may not match the demand to send missions to Mars, the moons of Jupiter and beyond. And the crunch got even worse in late 2013, when budget constraints led NASA to cancel a programme to develop a radioisotope power source that would have used one-quarter of the plutonium of conventional designs (see  Naturehttp://doi.org/w8m;2013 ). This is why Wilson is doing chemistry in the Oak Ridge hot cells. Last year, in a move that was unprecedented for both agencies, NASA started paying the DOE US$50\u00a0million a year to reactivate its long-stalled capability for making  238 Pu. That is a tall order: the DOE is now grappling with having to produce the material in facilities that were never set up for it; interviewing retired plutonium technicians for tips on how to manufacture and store the isotope; and designing machines and workflows that can accommodate more than a kilogram of plutonium per year moving through the system. \u201cThe plutonium-production business is hard to do,\u201d says Ralph McNutt, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, who is participating in an internal NASA study on developing nuclear power for space missions. \u201cEverybody took it for granted that it was out there and would always be there. Life\u2019s a little more complicated than that.\u201d \n               Hot zone \n             The first radioisotope power units were developed in the late 1950s and early 1960s by the US and Soviet space programmes. (The European Space Agency has never developed nuclear power sources for missions, a policy that limited the operating life of a solar-powered lander that visited a comet earlier in November.) The United States has used radioisotope power units on 27 missions, from a Navy navigation satellite launched in 1961 to the Mars Curiosity rover in 2011. All follow the same basic idea: as the isotope decays, the radioactivity heats the junction between two metals or semiconductors (see \u2018Power trip\u2019). Thanks to a phenomenon known as the thermoelectric effect, this sets up an electric current that the spacecraft can use to power its instruments, or store in a battery. Smaller radioisotope units can also help to keep a probe warm in the frigid environment of space. The isotope of choice is  238 Pu, partly because it produces a high amount of power per gram of material, and partly because of worker safety: it emits only \u03b1-particles, which are relatively easy to shield against. NASA\u2019s current favoured design for a nuclear power source, the Multi-Mission Radioisotope Thermoelectric Generator (MMRTG), uses 4.8\u00a0kilograms of plutonium dioxide\u00a0\u2014\u00a0a chemically stable compound\u00a0\u2014\u00a0to provide 2,000\u00a0watts of heat and 110 watts of electrical power at a mission\u2019s start. With a half-life of 87.7 years,  238 Pu can produce power for decades. But the output fades over time. Project scientists working with the Voyager 1 spacecraft, which was launched in 1977 and is now more than 19 billion kilometres from Earth, have had to turn off instruments one by one as the electricity from its power units has dwindled. With 35 kilograms of plutonium dioxide on the shelf, NASA might seem in a good position to fuel many future nuclear-powered spacecraft. But the stockpile has aged, and less than half of it now meets NASA specifications in terms of how much heat it produces. Given the long lead time in planning planetary missions, and the challenges in maintaining the plutonium supply for missions not yet even dreamed of, the agency is less well-off than it might appear. NASA will use about 5\u00a0kilograms as a generator on the next Mars rover, set to launch in 2020. And future missions to the outer Solar System could require multiple generators. The new contract with the DOE will for the first time provide NASA with a steady supply of the isotope. The goal is for the DOE to produce 1.5\u00a0kilograms of plutonium dioxide a year by 2021, which translates to about 1.1 kilograms a year of  238 Pu. With that small influx, NASA should have enough to fuel about two missions a decade, says David Schurr, deputy director of NASA\u2019s planetary-sciences division in Washington\u00a0DC. \u201cWe\u2019re probably good for the next 20\u00a0years for foreseeable missions,\u201d he says. \n               Production line \n             The new  238 Pu production line starts at the Idaho National Laboratory in Idaho Falls, where the isotope neptunium-237 is chemically extracted from spent nuclear reactor fuel (see \u2018Fuel cycle\u2019). The neptunium is then sent to Oak Ridge, the once-secret city where uranium was enriched for the first nuclear bombs during the Second World War. On a glorious Appalachian autumn morning, as reds and oranges begin to tinge the oak trees that give the region its name, it is easy to forget this nuclear history. But not for long: the road to the laboratory winds past the old uranium-enrichment plant and abandoned guard towers from the 1940s, which stand on either side. On the ORNL campus, the  237 Np metal from Idaho is first pressed into pellets about the size and shape of a pencil eraser. The pellets are then slid one at a time into long aluminium tubes and taken to one of the lab\u2019s most historic buildings: the High Flux Isotope Reactor, the 49-year-old home of the highest neutron flux in the Western Hemisphere. Irradiations manager Chris Bryan stands in an overlook area above what looks like an indoor swimming pool, showing off a miniaturized physical model of the reactor core assembly. It nestles in a cylinder of beryllium, 2.4 metres across and studded with dozens of holes. Before a typical reactor run, Bryan will slide each neptunium-filled tube into one of the holes, so that it is fully exposed to the reactor core. \u201cWe\u2019re trying to squeeze as much neptunium into a finite volume as we can,\u201d Bryan explains. Many other nuclear- and materials-science experiments compete for the same space in the reactor. Once the tubes are in place, Bryan will lower the whole assembly into the swimming pool, where the water will serve as a radiation shield, then switch the reactor on for 25 days. During that time, so many neutrons bombard the  237 Np that 10\u201312% of the nuclei in the sample absorb one. The result is neptunium-238, which quickly decays into  238 Pu. Once this process is complete, the tubes are removed and taken next door, using a protected rail carriage, to the low-profile building where Wilson and his co-workers peer through their yellow windows and work their manipulator arms inside the lab\u2019s hot cells. Their job is to dissolve the irradiated pellets in nitric acid, then extract and concentrate the plutonium into an oxide powder that will eventually go into protective drums. Finally, a radiation-shielded truck will drive the drums to the Los Alamos National Laboratory in New Mexico, where the oxide will be pressed into fuel pellets\u00a0\u2014\u00a0although the laboratory will first have to replace its old, faltering pellet-pressing machine. There are many other steps in this elaborate sequence. For one thing, Oak Ridge does not have enough space in its reactor to transform all of the  237 Np. Once the neptunium pellets are made there, some will be sent to the Idaho lab, whose Advanced Test Reactor will help out by doing some of the irradiation. Idaho will also store some of the finished plutonium pellets until they are needed for an MMRTG. But for now the main focus remains in Oak Ridge. Robert Wham, a chemical engineer at the lab, is in charge of working out how to safely go from making a couple of test batches to churning out plutonium dioxide at the rate of 1.5 kilograms a year. Wham is the sort of quietly confident engineer whose eyes light up when he thinks about challenges such as designing an automated neptunium pellet-feeder, or picking the best length for the tubes to go in the Oak Ridge and Idaho reactors. \u201cThe people here hadn\u2019t worked with neptunium before,\u201d he says. \u201cWe\u2019re starting pretty much from scratch.\u201d Now the major challenge is figuring out how to process all that plutonium in the limited number of hot cells at the Oak Ridge lab. Hot-cell technicians are in great demand; Wham will have to double the number of trained staff in the coming years. Already, the cells operate 24\u00a0hours a day, 7 days a week as the team works through test runs. \u201cWe\u2019re going great guns,\u201d Wham says. \u201cEveryone wants to see this happen.\u201d NASA is also looking at ways to extract more power from the plutonium it already has. At its Jet Propulsion Laboratory in Pasadena, California, materials engineer Jean-Pierre Fleurial leads a group that is exploring ways to build thermocouples, the devices that generate electricity from plutonium\u2019s radioactive decay. By replacing the lead-based material currently used in the thermocouples with a cobalt\u2013antimony material known as skutterudite, Fleurial\u2019s team will try to get at least 25% more power out of a generator at the beginning of its life. And this \u2018enhanced MMRTG\u2019 would also conserve power over time, which might substantially lengthen the lifetime of a spacecraft. It should be ready by 2022, Fleurial says. \n               Power hungry \n             Until last year, NASA was also working hard on space-going Stirling engines, which could generate as much power as an MMRTG from just one-quarter the amount of plutonium. Stirling converters work something like high-tech steam engines: the heat generated by plutonium decay drives the expansion of helium gas, which in turn moves a set of pistons to provide power. Missions enabled by Stirling technology might have included a boat to sail on the lakes of Saturn\u2019s moon Titan, or a \u2018comet hopper\u2019 that can manoeuvre to different places on a comet\u2019s surface. But NASA cancelled the programme in November 2013, citing cost constraints. The decision sparked criticism from planetary scientists such as Jessica Sunshine at the University of Maryland in College Park, who is frustrated by what she sees as a lack of long-term planning for how to deal with NASA\u2019s limited plutonium supply. For example, NASA\u2019s latest call for mission proposals\u00a0\u2014\u00a0for relatively low-cost Discovery-class spacecraft \u2014 does not even allow the use of radioisotopes for anything other than minimal heating of instruments. \u201cHow are we getting from DOE\u2019s restarting the programme to NASA\u2019s flying something?\u201d she asks in reference to the plutonium supply. \u201cWhere is that path and how long is that going to take?\u201d Despite the agency\u2019s decision to cancel the Stirling programme, a small research effort has continued. John Hamley, manager of the radioisotope power systems programme at NASA\u2019s Glenn Research Center in Cleveland, Ohio, and his team have continued studies on 12 Stirling convertors in various configurations, which have been running for as long as 10 years. The aim is to prove that the pistons can work reliably for the long periods of time needed during an extended space mission. All these efforts to conserve plutonium and produce more of it may still not be enough if NASA needs the isotope to power human exploration of space. The agency is now talking about sending astronauts to an asteroid or beyond, something that will require much more power than can be supplied by small chunks of  238 Pu. Whereas a planetary mission might require 300\u2013900 watts of power, the much larger spacecraft needed for human deep-space exploration would require several tens of kilowatts, Schurr says. An internal NASA report, due out early next year, has been evaluating the needs for nuclear power in space. It may well conclude that it needs a self-sustaining power source, such as a fission reactor, which the United States has not used in space since 1965. Back at Oak Ridge, Wham is thinking about how to make more plutonium, too. He leads the way through a narrow plywood-lined passageway in another building on the campus, which emerges into a cavernous concrete hall. The room was constructed for additional hot-cell space back in the 1960s, when the DOE was considering building nuclear reactors that run on thorium. Those plans have long since been shelved, but the well-shielded workspace remains. If need be, Wham says that he could fashion more hot cells here and make even more plutonium \u2014 and find a use for the room in this chapter of atomic history, even if it did not find one in the last. \u201cIf they do come to us and want more,\u201d he says, \u201cwe know how to do it.\u201d \n                     NASA pulls plug on plutonium power source 2013-Nov-18 \n                   \n                     Fission power back on NASA\u2019s agenda 2012-Feb-06 \n                   \n                     Nature  News blogpost: A Stirling solution and a pluonium problem \n                   \n                     NASA radioisotope power systems \n                   \n                     Radioisotope Power System documents \n                   \n                     Oak Ridge National Laboratory \n                   \n                     NASA Glenn Stirling research lab \n                   Reprints and Permissions"},
{"file_id": "515480a", "url": "https://www.nature.com/articles/515480a", "year": 2014, "authors": [{"name": "Cat Ferguson"}, {"name": "Adam Marcus"}, {"name": "Ivan Oransky"}], "parsed_as_year": "2006_or_before", "body": "When a handful of authors were caught reviewing their own papers, it exposed weaknesses in modern publishing systems. Editors are trying to plug the holes. Most journal editors know how much effort it takes to persuade busy researchers to review a paper. That is why the editor of  The Journal of Enzyme Inhibition and Medicinal Chemistry  was puzzled by the reviews for manuscripts by one author \u2014 Hyung-In Moon, a medicinal-plant researcher then at Dongguk University in Gyeongju, South Korea. The reviews themselves were not remarkable: mostly favourable, with some suggestions about how to improve the papers. What was unusual was how quickly they were completed \u2014 often within 24 hours. The turnaround was a little too fast, and Claudiu Supuran, the journal's editor-in-chief, started to become suspicious. In 2012, he confronted Moon, who readily admitted that the reviews had come in so quickly because he had written many of them himself. The deception had not been hard to set up. Supuran's journal and several others published by Informa Healthcare in London invite authors to suggest potential reviewers for their papers. So Moon provided names, sometimes of real scientists and sometimes pseudonyms, often with bogus e-mail addresses that would go directly to him or his colleagues. His confession led to the retraction of 28 papers by several Informa journals, and the resignation of an editor. Moon's was not an isolated case. In the past 2 years, journals have been forced to retract more than 110 papers in at least 6 instances of peer-review rigging. What all these cases had in common was that researchers exploited vulnerabilities in the publishers' computerized systems to dupe editors into accepting manuscripts, often by doing their own reviews. The cases involved publishing behemoths Elsevier, Springer, Taylor & Francis, SAGE and Wiley, as well as Informa, and they exploited security flaws that \u2014 in at least one of the systems \u2014 could make researchers vulnerable to even more serious identity theft. \u201cFor a piece of software that's used by hundreds of thousands of academics worldwide, it really is appalling,\u201d says Mark Dingemanse, a linguist at the Max Planck Institute for Psycholinguistics in Nijmegen, the Netherlands, who has used some of these programs to publish and review papers. But even the most secure software could be compromised. That is why some observers argue for changes to the way that editors assign papers to reviewers, particularly to end the use of reviewers suggested by a manuscript's authors. Even Moon, who accepts the sole blame for nominating himself and his friends to review his papers, argues that editors should police the system against people like him. \u201cOf course authors will ask for their friends,\u201d he said in August 2012, \u201cbut editors are supposed to check they are not from the same institution or co-authors on previous papers.\u201d \n               Peer-review ring \n             Moon's case is by no means the most spectacular instance of peer-review rigging in recent years. That honour goes to a case that came to light in May 2013, when Ali Nayfeh, then editor-in-chief of the  Journal of Vibration and Control , received some troubling news. An author who had submitted a paper to the journal told Nayfeh that he had received e-mails about it from two people claiming to be reviewers. Reviewers do not normally have direct contact with authors, and \u2014 strangely \u2014 the e-mails came from generic-looking Gmail accounts rather than from the professional institutional accounts that many academics use (see 'Red flags in review'). \n               boxed-text \n             Nayfeh alerted SAGE, the company in Thousand Oaks, California, that publishes the journal. The editors there e-mailed both the Gmail addresses provided by the tipster, and the institutional addresses of the authors whose names had been used, asking for proof of identity and a list of their publications. One scientist responded \u2014 to say that not only had he not sent the e-mail, but he did not even work in the field. This sparked a 14-month investigation that came to involve about 20 people from SAGE's editorial, legal and production departments. It showed that the Gmail addresses were each linked to accounts with Thomson Reuters' ScholarOne, a publication-management system used by SAGE and several other publishers, including Informa. Editors were able to track every paper that the person or people behind these accounts had allegedly written or reviewed, says SAGE spokesperson Camille Gamboa. They also checked the wording of reviews, the details of author-nominated reviewers, reference lists and the turnaround time for reviews (in some cases, only a few minutes). This helped the investigators to ferret out further suspicious-looking accounts; they eventually found 130. As they worked through the list, SAGE investigators realized that authors were both reviewing and citing each other at an anomalous rate. Eventually, 60 articles were found to have evidence of peer-review tampering, involvement in the citation ring or both. \u201cDue to the serious nature of the findings, we wanted to ensure we had researched all avenues as carefully as possible before contacting any of the authors and reviewers,\u201d says Gamboa. When the dust had settled, it turned out that there was one author in the centre of the ring: Peter Chen, an engineer then at the National Pingtung University of Education (NPUE) in Taiwan, who was a co-author on practically all of the papers in question. After \u201ca series of unsatisfactory responses\u201d from Chen, says Gamboa, SAGE contacted the NPUE, which joined the investigation into Chen's work. Chen resigned from his post in February 2014. In May, Nayfeh resigned over the scandal at his journal, and SAGE contacted the authors of all 60 affected articles to let them know that the papers would be retracted. Chen could not be reached for comment for this story, but Taiwan's state-run news agency said in July that he had issued a statement taking sole responsibility for the peer-review and citation ring, and admitting to the \u201cindiscreet practice\u201d of adding Taiwan's education minister as a co-author on five of the papers without his knowledge. That minister, Chiang Wei-ling, denies any involvement, but nevertheless resigned \u201cto uphold his own reputation and avoid unnecessary disturbance of the work of the education ministry\u201d, according to a public statement. The collateral damage did not stop there. A couple of authors have asked SAGE to reconsider and reinstate their papers, Gamboa says, but the publisher's decision is final \u2014 even if the authors in question knew nothing of Chen or the peer-review ring. \n               Password loophole \n             Moon and Chen both exploited a feature of ScholarOne's automated processes. When a reviewer is invited to read a paper, he or she is sent an e-mail with login information. If that communication goes to a fake e-mail account, the recipient can sign into the system under whatever name was initially submitted, with no additional identity verification. Jasper Simons, vice-president of product and market strategy for Thomson Reuters in Charlottesville, Virginia, says that ScholarOne is a respected peer-review system and that it is the responsibility of journals and their editorial teams to invite properly qualified reviewers for their papers. Nature Publishing Group (NPG) owns a few journals that use ScholarOne, but  Nature  itself and  Nature -branded journals use different software, developed by eJournalPress of Rockville, Maryland. V\u00e9ronique Kiermer,  Nature 's executive editor and director of author and reviewer services for NPG in New York City, says that NPG does not seem to have been the victim of any such peer-review-rigging schemes. \u00a0An interview with Ivan Oransky from Retraction Watch. But ScholarOne is not the only publishing system with vulnerabilities. Editorial Manager, built by Aries Systems in North Andover, Massachusetts, is used by many societies and publishers, including Springer and PLOS. The American Association for the Advancement of Science in Washington DC uses a system developed in-house for its journals  Science ,  Science Translational Medicine  and  Science Signaling , but its open-access offering,  Science Advances , uses Editorial Manager. Elsevier, based in Amsterdam, uses a branded version of the same product, called the Elsevier Editorial System. Editorial Manager's main issue is the way it manages passwords. When users forget their password, the system sends it to them by e-mail, in plain text. For  PLOS ONE , it actually sends out a password, without prompting, whenever it asks a user to sign in, for example to review a new manuscript. Most modern web services, such as Google, hide passwords under layers of encryption to prevent them from being intercepted. That is why they require users to reset a password if they forget it, often coupled with checking identity in other ways. Security loopholes can do more than compromise peer review. Because people often use the same or similar passwords for many of their online activities \u2014 including banking and shopping \u2014 e-mailing out the password presents an opportunity for hackers to do more than damage the research record. Dingemanse, who has published in a number of journals that use Editorial Manager, including  PLOS ONE , says: \u201cIt's quite amazing that they haven't got around to implementing a safe system.\u201d Neither Aries nor  PLOS ONE  responded to several requests for comment. \n               Safety measures \n             Lax password protection has resulted in breaches. In 2012, the Elsevier journal  Optics & Laser Technology  retracted 11 papers after an unknown party gained access to an editor's account and assigned papers to fake reviewer accounts. The authors of the retracted papers were not implicated in the hack, and were offered the chance to resubmit. Elsevier has since taken steps to prevent reviewer fraud, including implementing a pilot programme to consolidate accounts across 100 of its journals. The rationale is that reducing the number of accounts in its system might help to reveal those that are fraudulent, says Tom Reller, a spokesperson for Elsevier. If it is successful, consolidation will roll out to all journals in early 2015. Furthermore, passwords are no longer included in most e-mails from the editorial system. And to verify reviewers' identities, the system now integrates the Open Researcher and Contributor ID (ORCID) at various points. ORCID identifiers, unique numbers assigned to individual researchers, are designed to track researchers through all of their publications, even if they move institutions. ScholarOne also allows ORCID integration, but it is up to each journal to decide how to use it. Gamboa says that not enough scientists have adopted the system to make it possible to require an ORCID for each reviewer. And there is another problem: \u201cUnfortunately, like any online verification system, ORCID is also open to the risk of unethical manipulation,\u201d says Gamboa \u2014 for example, through hacking. That is a common refrain. \u201cAs you make the system more technical and more automated, there are more ways to game it,\u201d says Bruce Schneier, a computer-security expert at Harvard Law School's Berkman Center for Internet and Society in Cambridge, Massachusetts. \u201cThere are almost never technical solutions to social problems.\u201d It ultimately falls to editors and publishers to be on the alert, particularly when contacting potential reviewers. Carefully checking e-mail addresses is one way to ferret out fakes: a non-institutional e-mail address such as a free account from Gmail is a red flag, say sources. But at the same time, it could also be a perfectly legitimate address. Jigisha Patel, associate editorial director of BioMed Central in London, says that it is definitely possible to catch cheaters by being on the alert for dubious e-mail addresses. \u201cWe've had some cases where we've caught them tweaking the e-mail addresses to try to steal someone's identity,\u201d she says. But such screening is imperfect. In September, the publisher retracted a paper in  BMC Systems Biology , stating that it believed that \u201cthe peer-review process was compromised and inappropriately influenced by the authors\u201d. Some scientists and publishers say that journals should not allow authors to recommend reviewers in the first place. John Loadsman, an editor of  Anaesthesia and Intensive Care , which is published by the Australian Society of Anaesthetists in Sydney, calls the practice \u201cbizarre\u201d and \u201ccompletely nuts\u201d, and says that his journal does not permit it. It is unclear exactly what proportion of journals allows the practice, but as fields become more specialized it provides an easy way for busy editors to find relevant expertise. Jennifer Nyborg, a biochemist at Colorado State University in Fort Collins, says that most of the journals to which she submits articles request at least five potential reviewers. For most of the 60 articles retracted by SAGE, the original peer review had used only author-nominated reviewers. Despite this experience, the  Journal of Vibration and Control  still allows authors to suggest peer reviewers (and provide their contact e-mails) when they submit a manuscript \u2014 although more safeguards are now in place, says Gamboa. The Committee on Publication Ethics (COPE), which serves as a kind of moral compass for scientific publishing (but has no authority to enforce its advice) has no guidance on the practice, but urges journals to vet reviewers adequately. Good practice is always to check the names, addresses and e-mail contacts of reviewers, says Natalie Ridgeway, operations manager for COPE in London. \u201cEditors should never use only the preferred reviewer.\u201d NPG journals do allow authors to suggest independent reviewers. \u201cBut these suggestions are not necessarily followed,\u201d says Kiermer. \u201cThe editors select reviewers and the selection includes checking for the absence of conflict of interests.\u201d On the flip side, authors can ask an editor to exclude reviewers who they believe to have unmanageable conflicts, such as competing research. The publisher usually honours such requests, as long as authors do not ask to exclude more than three people or labs, Kiermer says. Sometimes, recommending reviewers can backfire. Robert Lindsay, one of two editors-in-chief of the Springer-published journal  Osteoporosis International , says that his publication allows authors to recommend up to two reviewers \u2014 but that he often uses this information to rule those reviewers out. This is based on past experience, in which he has seen authors recommend their own contacts, or worse: \u201cWe have had family members, folks in the same department, postgraduate students being supervised by an author,\u201d he says. The journal generally uses suggested reviewers \u2014 who have passed screening \u2014 only if it runs into trouble finding other scientists to perform the task. But screening can be difficult. Usually, editors in the United States and Europe know the scientific community in those regions well enough to catch potential conflicts of interest between authors and reviewers. But Lindsay says that Western editors can find this harder with authors from Asia \u2014 \u201cwhere often none of us knows the suggested reviewers\u201d. In these cases, the journal insists on at least one independent reviewer, identified and invited by the editors. In what Lindsay calls the worst case that he has seen, an author suggested a reviewer who shared her first name but not her surname. Some investigation revealed that the surname was the author's maiden name \u2014 she was recommending that she review her own paper. \u201cI don't think she is going to submit anything to us again,\u201d says Lindsay. \n                     Faked peer reviews prompt 64 retractions 2015-Aug-18 \n                   \n                     The scientists who get credit for peer review 2014-Oct-09 \n                   \n                     Journals weigh up double-blind peer review 2014-Jul-15 \n                   \n                     Peer reviewers urged to speak their minds 2013-Dec-04 \n                   \n                     Investigating journals: The dark side of publishing 2013-Mar-27 \n                   \n                     Nature peer-review policies \n                   \n                     Retraction Watch \n                   Reprints and Permissions"},
{"file_id": "515180a", "url": "https://www.nature.com/articles/515180a", "year": 2014, "authors": [{"name": "Kerri Smith"}], "parsed_as_year": "2006_or_before", "body": "Depression is a major human blight. Globally, it is responsible for more \u2018years lost\u2019 to disability than any other condition. This is largely because so many people suffer from it \u2014 some 350 million, according to the World Health Organization \u2014 and the fact that it lasts for many years. (When ranked by disability and death combined, depression comes ninth behind prolific killers such as heart disease, stroke and HIV.) Yet depression is widely undiagnosed and untreated because of stigma, lack of effective therapies and inadequate mental-health resources. Almost half of the world\u2019s population lives in a country with only two psychiatrists per 100,000 people. \n                     Psychological treatments: A call for mental-health science 2014-Jul-16 \n                   \n                     No dishonour in depression 2013-Jun-12 \n                   \n                     Mental health: On the spectrum 2013-Apr-24 \n                   \n                     Nature  special: Depression \n                   \n                     Nature  special: The autism enigma \n                   \n                     Nature  special: Schizophrenia \n                   \n                     National Institute of Mental Health on depression \n                   \n                     World Health Organization on depression \n                   Reprints and Permissions"},
{"file_id": "515330a", "url": "https://www.nature.com/articles/515330a", "year": 2014, "authors": [{"name": "Katia Moskvitch"}], "parsed_as_year": "2006_or_before", "body": "The International Centre for Theoretical Physics was set up to seed science in the developing world; 100,000 researchers later, it is still growing. The dust in Kathmandu cloaks everything. It carpets the streets with a dingy layer. Women cutting waist-high grass are wearing face masks to keep it out. And it settles on the dilapidated buildings of Tribhuvan University (TU) \u2014 the biggest scientific establishment in Nepal. Narayan Adhikari, however, has managed to stay clean. Clad in an impeccable white shirt and black trousers, he adds his motorbike to a collection of some 20 others parked haphazardly in front of a 3-storey building, the university's physics department. Before entering his tiny lab, the 44-year-old researcher removes his shoes to keep the dirt out. In the lab are a dozen desktop computers, which the department received in 2009 \u2014 before that, there were none. Power blackouts happen every day, lasting for up to 16 hours, and the Internet connection works \u201cmaybe one day a month\u201d, Adhikari says. Despite this, for the past eight years Adhikari and his students have been producing a stream of theoretical-physics papers on the properties of materials such as atom-thick graphene. It is a rare \u2014 if not unique \u2014 achievement for a physics lab in Nepal, and Adhikari's contributions are also helping to build up his department as a whole, by boosting the number of PhD students being trained there. \u201cDoing physics in a country like Nepal is a real challenge,\u201d he says. Adhikari's accomplishments are rooted in more than his own determination and wit; they also draw on support from the International Centre for Theoretical Physics (ICTP), an organization based a world away in the picturesque Italian seaside town of Trieste. Set up in 1964 by Pakistani physics Nobel laureate Abdus Salam and Italian physicist Paolo Budinich, it aims to advance theoretical physics in the developing world. Salam, who died in 1996, wanted the centre to be \u201ca home away from home\u201d for researchers from the poorest regions of the world. After they passed through the ICTP's programmes of training and research, he hoped that alumni would establish scientific communities in their home countries, rather than settling abroad as so many scientists did. Adhikari, who completed the ICTP's one-year postgraduate-diploma programme in 1998, is one of the institute's success stories. \n               Global reach \n             Adhikari is hardly the only one. In the 50 years since it was established, the ICTP has trained more than 100,000 scientists from 188 countries through its workshops and courses. Researchers who studied there have contributed to major discoveries in fields ranging from string theory and neutrino physics to climate change, and have racked up a trophy cabinet of academic prizes, including shares in a pair of Nobels. Most physicists credit the institute with stemming the brain drain and bolstering academia in the developing world. The institute is \u201cwidely admired\u201d, says Martin Rees, an astrophysicist at the University of Cambridge, UK, and former head of the Royal Society in London, who hopes that it will \u201cinspire the creation of similar institutions covering other scientific fields\u201d. The ICTP has evolved over time. What started out as a small project focused narrowly on Salam's discipline \u2014 high-energy physics \u2014 has morphed into a broader programme. In 1998, the institute expanded its brief to include mathematics and Earth-systems physics, including climate and geophysics, and in 2014 it added quantitative life sciences. The institute is still changing. In the past two years it has opened satellite campuses in Brazil, Mexico and Turkey, and it is currently establishing branches in Rwanda and China. Plans to expand into more countries and disciplines are being considered. But some worry about the organization's future. The main provider of the ICTP's funding, the Italian government, has started to baulk at shouldering most of its costs, and some scientists are concerned that expanding could dilute the quality of ICTP-fuelled research. \u201cIn the last few years ICTP has started many new things,\u201d says Chris Llewellyn Smith, a theoretical physicist at the University of Oxford, UK, and former head of CERN, Europe's particle physics laboratory near Geneva, Switzerland. \u201cIf they try to take on even more and be too ambitious with new ideas, they might let go of what they've got.\u201d \n               Curious child \n             Adhikari could be a poster child for the ICTP. The youngest of six siblings, he was born to farming parents in a village near Nepal's second-largest city, Pokhara, and grew up with paraffin-oil lamps and no running water at home. His father was literate, his mother was not \u2014 but both parents supported his desire to study. \u201cI am very curious to unearth the secrets of nature \u2014 so I love physics,\u201d he says. He worked as a teacher for three years to earn enough money to study at TU. In 1996, having completed his undergraduate and master's degrees in physics, Adhikari won a place on the ICTP's diploma programme. When he travelled to Trieste, aged 27, he felt as if he had landed on a different planet. \u201cI was astonished by the Western world \u2014 there was no dust in the air!\u201d he says. Adhikari met Nobel laureates and other distinguished physicists, who come to the ICTP to collaborate and teach. After finishing the diploma, he did a PhD at the Martin Luther University of Halle-Wittenberg in Germany, simulating the behaviour of polymers and other materials. This was followed by postdocs in the United States and Germany. \u201cOur life was good, and there was clean drinking water,\u201d says Adhikari's wife, Sabitra. \u201cBut one day Narayan told me: 'We have to go back'.\u201d Adhikari had always felt strongly that he wanted to use his knowledge \u201cto make Nepal a better place\u201d, he says \u2014 and this aim was reinforced during his diploma at the ICTP. When Adhikari rejoined TU in 2006, he set about building his own research group. He had no problem finding willing students; what he did not have was books, the Internet, a good electricity supply or any equipment. That ruled out experimental physics, but it allowed him to continue his theoretical work, which he did by buying a suite of desktop computers with funding from the ICTP. Soon Adhikari was publishing his studies, which modelled the properties of materials ranging from water to polymers and solids such as graphene. In the past two years, for example, he has explored 1 , 2  how graphene might be used to store energy by decorating it with metal \u2014 a study that he estimates took three times as long as it would have in the West, because of the power cuts that routinely stopped work. \u201cThe conditions were so difficult that sometimes I was afraid that I'd never achieve anything in Kathmandu,\u201d he says. \u201cBut I just kept thinking that I had to continue, because it'd be great to develop science in Nepal.\u201d At the time, few scientists at TU were publishing consistently in international journals, but Adhikari's enthusiasm seeped into the rest of his department. In the 40 years before 2006, just 4 students had completed a PhD there; ambitious graduates usually went to Europe or the United States. Since Adhikari joined, 22 students have been admitted to the PhD programme and other researchers have published more, too. \u201cWhat he has helped us to achieve is really remarkable,\u201d says Binil Aryal, head of physics at TU. \n               The greater good \n             But does Nepal need a theoretical-physics department? After all, the country has more urgent issues: its population struggles with malnutrition, its infrastructure is falling apart, and its air quality ranks among the worst in the world. \u201cIn developing countries like Nepal, the government does not allocate sufficient budget for R&D because of much more pressing problems and priorities,\u201d says Ganesh Shah, Nepal's science minister from 2008 to 2009. Shah and Adhikari say that building up the intellectual capacity of the country will drive its economic development. \u201cInvestment in science, technology and innovation is required to create jobs and reduce poverty and improve the living standards of the people,\u201d says Shah. When he was science minister, he tried to allocate more funding for basic research, he says \u2014 but with limited success. The Nepali government invested 0.3% of its gross domestic product in research and development in 2010, similar to that of other developing countries in south Asia but well below the nearly 2% invested by China. Theoretical physics is a lot easier and cheaper to set up than some other fields, Shah points out. Adhikari is paid by the university, but he still receives some support from the ICTP. Until this year, his students had to fly to computing facilities in Kolkata, India, every time they had a complex computation to perform. Not anymore. Gopi Kaphle, one of Adhikari's PhD students, proudly shows off a shoebox-sized computer. \u201cIt performs computations about ten times faster than the machines we used to have,\u201d says Kaphle. Because calculations on the new computer must run without interruption, the ICTP also funded a solar panel on the roof of the department, to deal with Nepal's power cuts. This year, Adhikari decided that he wanted to expand into relatively simple, tabletop experiments in nanoscale materials. \u201cWe have to be able to do experiments; it's the next step forward,\u201d he says. To try to negotiate the funds, he returned to the ICTP. He arrived at the headquarters in Trieste in late September, just as the centre was getting ready to celebrate its 50th birthday. \n               Breaking down barriers \n             The seeds of the ICTP were planted after the Second World War, when physicists including Albert Einstein, Robert Oppenheimer and Niels Bohr championed the concept of a United Nations-backed centre to promote peaceful nuclear-physics research. Initially, this led to the creation of the International Atomic Energy Agency (IAEA). But for Abdus Salam, a science prodigy from Pakistan who had been made a physics professor at Imperial College London by the age of 31, that was not enough. Speaking to the IAEA's General Conference in 1960, he outlined his idea for an IAEA-backed organization that would promote theoretical-physics research in the developing world and bridge East and West in the cold war. In the audience was Paolo Budinich, head of physics at the University of Trieste, who shared the dream. The two men initially encountered resistance to the idea of building a new centre; critics argued that it would be easier and cheaper for developing-world physicists to visit existing labs in the developed world. But Salam and Budinich won the argument, not least after they secured the financial backing of the Italian government and the support of the IAEA and the United Nations Educational, Scientific and Cultural Organization (UNESCO). They chose to locate the centre in Trieste, which was politically symbolic because it sat right next to the Iron Curtain that divided East and West. When the institute opened in 1964, it rapidly established itself as a place for high-level research and training, welcoming scientists from both sides of the Iron Curtain and from farther afield. The centre, which initially offered scientists a two-to-three-month grant to work in Trieste, \u201cwas like a source of oxygen to Third World scientists\u201d, says Abdelkrim Aoudia, a geophysicist from Algeria who works at the ICTP. Even in the institute's early days, many Nobel laureates served as visiting professors. When, in 1979, Salam shared a Nobel prize with Sheldon Glashow and Steven Weinberg for the unification of electromagnetism and the weak nuclear force, the organization's prestige skyrocketed. Speaking at the anniversary celebrations, Salam's son Ahmad, an investment banker at EME Capital in London, wiped away tears as he remembered the sacrifices his father made while he set up the centre \u2014 not least spending little time with his children. \u201cHe had a much bigger mission in life,\u201d said Ahmad. Today, around 2,500 developing-world scientists visit the ICTP each year. About 50 of these enrol in the one-year diploma, an intense predoctoral education programme taught by experts from around the world. (The institute identifies students through both an application process and the recommendations of researchers and teachers.) Many of the rest \u2014 including Adhikari \u2014 are part of the Associates Scheme, which supports scientists from developing countries to make regular visits to the ICTP, where they network and update their skills. What makes the institute successful, say those involved, is its focus on nurturing talented scientists and keeping them connected to the international community, while encouraging them to continue research at home. \n               Brain gain \n             That approach is working, says Fernando Quevedo, the ICTP's director. Three-quarters of the students who have completed the diploma programme have received PhDs, or are working towards them, and more than half of those who complete PhDs go back to their home countries (see 'Sticking with science'). More than 90% of associates remain in their home countries for their careers. Some, inevitably, do end up abroad, but even in those cases, the ICTP often claims success. One of the world's leading string theorists, Argentinian Juan Maldacena, who works at the Institute for Advanced Study in Princeton, New Jersey, attributes his achievements in part to the ICTP, because of the training that he and his master's supervisor received at the centre. The ICTP's journey has not been entirely smooth, however. \u201cWhen Salam passed away, ICTP had a period to recover from the founder's death, but they managed,\u201d says David Gross, a string theorist at the University of California, Santa Barbara, who often visits the institute. Keeping the money flowing has been difficult \u2014 especially in light of the institute's growth into new fields. The satellite campuses that it has been launching, mostly supported by the host countries, are designed to improve postgraduate education in physics and mathematics, as well as to conduct research and training in topics that serve regional interests and strengths. The centre in S\u00e3o Paulo, Brazil, for instance, focuses on pure theory, whereas the one in Chiapas, Mexico, includes climate and renewable energy. When it comes to further expansion, Quevedo says, the institute insists on quality over quantity and is careful to evaluate each proposal. It has also made it a priority to recruit more women into its programmes. Since 2001, the average proportion of female scientists visiting or studying on its campus has been 20%, but the balance is better in the 2013\u201314 diploma programme, in which half of the participants are women. All of these activities take money. The Italian government still covers about 80% of the Trieste centre's annual budget of about \u20ac30 million (US$37 million), with a major chunk of the rest provided by the IAEA and UNESCO. (UNESCO has also had responsibility for the centre's administration since 1996.) \u201cItaly deserves a lot of credit for sticking with the organization over the years through all their financial crises,\u201d says Gross. But the government is keen for the ICTP to find new funding sources, and in 2013 the institute created an office dedicated to seeking additional funding from elsewhere. With many applications for every available training slot, \u201cthe main challenge is to attract funds to be able to fund more students\u201d, says Quevedo. The centre has also had to adapt to geopolitical changes. Back at the start, when it was important to bridge the East\u2013West divide, the institute offered neutral ground for Soviet and US physicists. Today the bridges are built between developed countries in the global north and more impoverished or politically isolated ones in Africa, South America and south Asia. The institute is one of very few places to have helped scientists from North Korea to meet and study with other researchers, for example, says ICTP cosmologist Paolo Creminelli. \u201cThese researchers represent a connection between North Korea and the rest of the world.\u201d Elsewhere, several other institutions have been built on the ICTP model, including the International Centre of Physics (CIF) in Bogota, which since its establishment in 1985 has supported physics research in Colombia and surrounding countries. There is a great need for ICTP-type programmes in natural sciences, engineering and other technical sciences, says Torsten Wiesel, president emeritus of Rockefeller University in New York City, who has worked to advance developing-world science.\u201cThe world needs more programmes reaching out over the borders into countries of need,\u201d he says. Some researchers argue that the ICTP itself should go further. It should \u201cdevelop research schemes and programmes with direct, specific and relevant applications in engineering, industry and medicine in the developing world\u201d, says Estelle Maeva Inack, a condensed-matter physicist from Cameroon who works at the ICTP. Quevedo says that the institute is aware of this need, and that it is one of the reasons for expanding into more applied disciplines. He also points to a popular course on entrepreneurship for physicists, which the ICTP runs in collaboration with partner institutes around the world. \u201cBut our main mission is to promote excellence in science in developing countries and we should continue being faithful to this mandate,\u201d he says. That is what got it this far, after all. \u201cThe first challenge of every institution is survival,\u201d says Quevedo, \u201cand ICTP has survived for 50 years.\u201d \n               Heading home \n             The anniversary celebrations over, Adhikari talks to his students by phone as he gets ready to leave Trieste. It has been raining a lot in Nepal, which has rendered the solar panels rather useless \u2014 and has made work hard for Kaphle, who is getting ready to defend his PhD thesis in a few weeks. But Adhikari is not put out. His proposal for tabletop physics went down well, and now discussions are under way at the ICTP to see whether he can receive the funds he would like. \u201cI owe a lot to the organization,\u201d he says, and he is optimistic that science will appeal to other bright students in Nepal. He wants to see children in villages doing homework on computers, illuminated by electric lights, rather than the oil lamps that he once used. \u201cI hope one day our students in Nepal will be able to find answers to some really big problems in physics.\u201d And there is no reason why they shouldn't, says Gross, with a worldwide pool of talent just waiting to be tapped. \u201cThere are brains everywhere, in roughly the same proportion of the population \u2014 as long as they get a chance.\u201d \n                     Science aid 2012-Nov-07 \n                   \n                     Education: Africa\u2019s counting house 2012-Nov-07 \n                   \n                     Nurturing science in developing countries 2006-Nov-01 \n                   \n                     African institute ready for meeting of mathematical minds 2003-Sep-18 \n                   \n                     International Centre for Theoretical Physics \n                   \n                     World Academy of Sciences \n                   Reprints and Permissions"},
{"file_id": "514422a", "url": "https://www.nature.com/articles/514422a", "year": 2014, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "In 2004, researchers announced the discovery of  Homo\u00a0floresiensis , a small relative of modern humans that lived as recently as 18,000 years ago. The \u2018hobbit\u2019 is now considered the most important hominin fossil in a generation. Here, the scientists behind the find tell its story. \n               The hobbit team did not set out to find a new species. Instead, the researchers were trying to trace how ancient people travelled from mainland Asia to Australia. At least that was the idea when they began digging in Liang Bua, a large, cool cave in the highlands of Flores in Indonesia. The team was led by archaeologists Mike Morwood and Raden Soejono, who are now deceased. \n             Thomas Sutikna    (field archaeologist in charge of the excavation):  In 1999, Mike came to our office and proposed excavating at Liang Bua. \u2018Liang Bua\u2019 means cold cave. It\u2019s 500 metres above sea level, and it\u2019s situated very close to the confluence of two rivers, which provide natural resources like water and raw materials for stone artefacts. The roof is really high, providing good circulation. There\u2019s regular sunlight year round. It\u2019s very suitable for habitation. Richard \u2018Bert\u2019 Roberts    (geochronologist who conceived the dig with Morwood):  The excavations started off on a very small scale in 2001, but we found some interesting things: bones of stegodons, which are these now-extinct primitive elephants. There were lots of Komodo dragons, lots of rat bones, all sorts of other species, including this kind of giant stork. We didn\u2019t find anything spectacular until 2003. Wahyu Saptomo    (field archaeologist):  Before Mike Morwood left for the season in 2003, I said, \u201cWhy are you leaving now? If you leave, maybe we will find something important.\u201d A few days later, on 2 September, I was supervising sector VII. Our local workers were digging at around 5.9\u00a0metres. Their trowel met with a skull. A member of our team who specializes in animal and human bones came down and said, \u201cYes, I\u2019m sure that\u2019s a human bone. But it\u2019s very small.\u201d Thomas, he was sick and was at the hotel that day. So I went back and met with him. I said, \u201cWe have something very important. We found the first hominid in the Pleistocene layer.\u201d Sutikna:  Immediately, my fever vanished. I couldn\u2019t sleep well that night. I couldn\u2019t wait for sunrise. In the early morning we went to the site, and when we arrived in the cave, I didn\u2019t say a thing because both my mind and heart couldn\u2019t handle this incredible moment. I just went down to the pit and looked at the bones carefully. It would be impossible to get them out because of the condition of the bones. So we decided to cut the remains out, together with the sediment, block by block, and bring them back to the hotel. We needed several days to take out all the bones. Ewen Callaway chats to four experts about the discovery of Homo floresiensis and the big impact created by the little fossil. Roberts:  It was a very small body. That was the first thing that was immediately apparent \u2014 but also an incredibly small skull. We first thought, \u201cOh, it\u2019s a child.\u201d There was a guy who was working with us called Rokus. He did all the faunal identifications of the bones. But Rokus said, \u201cNo, no, no, it\u2019s not a child. It\u2019s not modern human at all. It\u2019s a different species.\u201d Saptomo:  Thomas drew the skeleton on paper, and he faxed the drawing to Mike and to Professor Soejono in Jakarta. Sutikna:  Mike called me at night. I couldn\u2019t understand what he was saying over the phone, he was so excited. Roberts:  Mike invited Peter Brown to come and look at the remains. Peter\u2019s a very good palaeoanthropologist, but he\u2019s kind of a difficult person as well. Peter can be kind of prickly. Peter Brown    (palaeoanthropologist):  Mike doesn\u2019t know much about human skeletons, and the Indonesian researchers didn\u2019t either. I was quite sceptical. The drawing may as well have been a Greek urn in terms of looking like anything much at all. I was interested and willing to go to Jakarta. It\u2019s an interesting place to visit. I like the food. I like the atmosphere and the culture and every\u00adthing else, but I didn\u2019t expect to find anything interesting or important. At the most, I thought it was going to be a sub-adult modern human skeleton, probably dating to the Neolithic period or maybe a little bit earlier. The other possibility was a pathological individual, someone with a growth disorder. Those were my expectations when I turned up. Roberts:  Peter\u2019s as sceptical as I was, probably thinking, \u201cA new human species? Sure, probably Mike getting overexcited in Jakarta. He\u2019d been in the bush for too long.\u201d Good on him for flying over there straight away, because most people have got teaching commitments and things you\u2019ve got to be getting on with. Brown:  I walked into the laboratory with Mike and the lower jaw \u2014 the mandible \u2014 had been cleaned. And it was in about six seconds, maybe less, of looking at the lower jaw, I knew it couldn\u2019t have been a modern human lower jaw. I knew it had to be from another species, and things went on from there. I started cleaning the skull and doing other work on the collections. Everything was very, very soft and had to be dried out and coated with preservative. It would have been very easy to scratch or smash. If you\u2019d stepped on it, you would have ended up with a pile of mashed potato, more or less. Roberts:  Some people, like the guys in Africa, seem to work on things for about 10 or 15 years before you finally get a fossil description. Peter was working at lightning speed by comparison. To Mike and myself it still seemed to take forever. Brown:  I smuggled some mustard seeds through customs for the purpose of measuring the volume of the brain. So I cleaned it all as carefully as I could. I turned it upside down, and I poured the seeds in it. I\u2019d taken enough seeds to measure the size of a modern human brain, say 1.5 litres of seeds, but it only took about 400 millilitres. I was flabbergasted. The last time things with a brain that size walked was around about 2.5\u00a0million to 3 million years ago. It was not making any sense at all. I recorded it a second time, a third time. Mike and Thomas are looking at me and wondering why I\u2019m going a bit pale. I was trying to push more seeds into the skull with my finger to try and increase the volume, because it was insane really. Roberts:  The carbon dates came in and they were around 18,000 years. So at that point it was, \u201cOh, this is absolutely bizarre.\u201d This was a very primitive-looking human who was living this side of the last glacial maximum, this side of the last Ice Age. Brown:  If Mike had said he\u2019d found evidence of an alien spaceship on Flores, I would have been less surprised. The team soon determined that the skeleton belonged to a female just over a metre tall. They dubbed her LB1. Brown and Morwood wondered whether the species was an offshoot of  Homo erectus  \u2014 an ancient relative of humans that originated in Africa about 2\u00a0million years ago and lived on Java, near Flores, until about 150,000 years ago. If its descendents had survived on Flores until the tail end of the last Ice Age, they might have shrunk in response to the island\u2019s limited resources. Alternatively, the species might have been related to australopithecines, small-bodied hominins that roamed Africa more than 2 million years ago. Brown and Morwood knew that they needed to let the world in on their find. Henry Gee    (senior editor at    Nature ): I had no warning. Usually with these things you tend to get a little bit of scuttlebutt. But this one just came onto\u00a0my desk one day in March 2004, and there it was. Roberts:  Poor old Henry probably fell off his chair when he got the papers. Gee:  I have to say at first it didn\u2019t strike me as this most fantastic discovery. They had this strange creature and the tone of the paper was very subdued. When you\u2019re an editor you read between the lines, and the line was: \u201cHelp us. We don\u2019t know what this thing is. We\u2019re just going to describe it and we\u2019re going to give it a very non-committal name and see what you think.\u201d Brown:  I thought it was a new species and probably a new genus. I just thought it was so different. Gee:  When it came to us, they had given it this Latin name,  Sundanthropus floresianus  \u2014 man from the Sunda region from Flores. Well, the referees said it\u2019s a member of  Homo  so that\u2019s what it should be, and one of the referees says  floresianus  actually means \u2018flowery anus\u2019 so it should be  floresiensis . So  Homo floresiensis  came along. Roberts:  We knew we had to come up with a name for publicity purposes. We couldn\u2019t call it  Homo floresiensis , so Mike said, \u201cI like hobbit.\u201d I said, \u201cOkay as long as it\u2019s not going to cause any problems with Tolkien\u2019s estate,\u201d or whatever they\u2019re called. They can get pretty stroppy with people using their trademarked words. Mike referred to LB1 as hobbit, not \u2018the\u2019 hobbit, as if its name was Mary. For a while, Mike was trying to persuade Peter Brown to call it  Homo hobbitus . I think he just thought Mike was a complete charlatan for even suggesting it. Brown:  Mike and I didn\u2019t agree about nicknames because I thought it trivialized it, and I thought it would result in every loon on the planet telephoning me as soon as it was published. And that was true \u2014 endless bizarre telephone calls from people who had seen some small hairy person in their backyard. \n               When the papers reporting the discovery were published \n               1 ,\n               2 \n                on 27 October 2004 (28 October in Australia and Indonesia), they grabbed public attention in a way few science stories manage. \n             Leigh Dayton    (science correspondent):  It was huge, absolutely huge. Everybody was talking about it. Even my editors who absolutely do not like science whatsoever, they were fascinated. I\u2019m just looking at the newspaper, the hard copy of the story I wrote for  The Australian , and the other stories are all the usual political stuff, police probes, inflation figures, and then, \u201cSmall, but they\u2019re only human\u201d. Bill Jungers    (palaeoanthropologist):  I had to check the date to make sure it wasn\u2019t April Fool\u2019s Day. It was so preposterous on the surface that there could be this little hominin that evolved in isolation in southeast Asia for God knows how long and persisted until almost the Holocene. Roberts:  This one really did garner just a massive amount of media interest. Way over the top. Every newspaper wanted to talk to you, TV programmes; everyone wanted to talk to everyone. Brown:  The press being the way they are, they always like controversy. It\u2019s no good just to have a good story. Nobody wants to read that, so they\u2019re always trying to find someone who disagrees. Maciej Henneberg    (palaeoanthropologist):  I had a phone call at 7 a.m. on 28 October 2004, from an Australian Broadcasting Corporation (ABC) journalist, who asked me, \u201cWhat do you think about the new find?\u201d I said, \u201cI don\u2019t think anything, you just woke me up.\u201d He said it was published in  Nature  that there is this new species. I said, \u201cOkay. Give me a few hours so I can find the papers.\u201d While I was reading, I was reminded of a paper on a microcephalic [small-brained] skull from Crete, about 4,000 years old. All the measurements of the LB1 skull were not significantly different from this clearly pathological skull from Crete. So at 11 a.m., I went on ABC radio and I said I think that what was found was a pathological specimen. This kind of explanation attracted a lot of attention. \n               Further controversy erupted when Teuku Jacob, head of Indonesia\u2019s national palaeoanthropology institute, decided that the hobbit\u2019s bones belonged in his lab. \n             Roberts:  Soejono invited Teuku Jacob to come over and have a look at the bones, and then Jacob just put them in a suitcase and walked out the door with them. Mike was absolutely ballistic. I didn\u2019t think we\u2019d ever actually get to see the bones back again. Brown:  The real disreputable thing was they tried to take moulds and cast this material. I hadn\u2019t done that because it was clear the material was too soft and too fragile to take moulds. When they had done that, the lower jaw was broken, the skull was damaged. \n               The bones made it back to Jakarta, but the debate over the hobbit\u2019s identity grew hotter. Morwood brought in specialists to examine the fossil, and they agreed with him that it was a new species. Some key studies focused on endocasts \u2014 moulds of the inside of the hobbit\u2019s skull that revealed details of its brain. \n             Jungers:  Mike didn\u2019t have to ask twice. I was introduced to the team in person in Jakarta in 2006, and a good part of my career has been obsessing about this fossil ever since. Roberts:  Quite a few on the American side started to throw their weight behind our team, and that helped steady the ship. They really took the hobbit to pieces and put it back together again, and found it was really a very unusual kind of animal. Jungers:  I was able to assemble a nearly complete foot that was unlike anything I\u2019ve ever seen in the fossil record. I think these little guys were climbers. I don\u2019t know if you\u2019ve ever been to Flores, but there were these huge Komodo dragons on the island when those guys were around. The adults don\u2019t climb, so if I were a hobbit, I would find refuge in the trees. Dean Falk    (evolutionary anthropologist):  Mike Morwood invited me to prepare and describe the endocast. I had a bias going into the study. I thought, because the brain was so small, that it was going to look like other primates with brains of that size, namely apes, and it didn\u2019t. It didn\u2019t look like a chimp brain. What it mostly looked like in overall shape was the endocast from  Homo erectus . \n               Other scientists have continued to support the idea that the LB1 specimen was a diseased human. \n             Robert Martin   (biological anthropologist):  I think there is something seriously weird about the LB1 specimen. The best I could come up with is microcephaly. There are hundreds of genes that can produce a small brain, with knock-on effects throughout the body. Falk:  We felt like, okay, we need to do a microcephalic study. I ended up running with that ball and got together a very small sample, about ten, but it\u2019s really hard to find ten endocasts from microcephalics. We looked at LB1 and we showed there was no way it was a micro\u00adcephalic. As far as I\u2019m concerned, that paper 3  answered it, and I think that persuaded most everybody, except a few people. I think they even were persuaded eventually, because they changed diseases. The \u2018sick-hobbit hypothesis\u2019, Bill Jungers called it. Jungers:  It seems like we\u2019ve got a new one every day. It\u2019s just crazy, crazy stuff. We spent a lot of time unfortunately having to deal with things like Laron syndrome and cretinism and other wild and woolly hypotheses. Henneberg:  About two and a half years ago, it all clicked. I could see that all signs of the bones were compatible with Down\u2019s syndrome. There are about 20 or so characteristics that are matching. There is not a single characteristic of LB1 that doesn\u2019t match. Martin:  I don\u2019t think we\u2019ve made much progress in ten years, quite honestly. What we have is entrenched positions. We should be talking about the interpretations and the facts, not casting aspersions. I\u2019m not an idiot because I\u2019m questioning this. Leslie Aiello    (palaeoanthropologist):  There were some important issues raised during the controversy that the proponents of a new-species hypothesis had to address. But the criticism of the hypothesis didn\u2019t turn out to hold any water. Falk:  In palaeoanthropology there\u2019s always controversy over new specimens. Always has been, always will be. I was a little surprised that in this day and age it would be so over the top. Aiello:  There were personalities involved. The field is full of a lot of egos, and particularly male egos. Roberts:  I think the view now is: yup, it\u2019s not a diseased modern human. But whether it\u2019s a shrunken down version of a  Homo\u00a0erectus , or whether it\u2019s something more ancient like a  Homo\u00a0habilis , or even an australopithecine who\u2019s managed to struggle out of Africa \u2014 that\u2019s still pretty much up for grabs. Brown:  I\u2019m mostly interested in how it got to be where it was, which will require the discovery of additional material. That may not happen in my lifetime. Aiello:  It\u2019ll happen. I tell my students that something is found every year and I never gave the same lectures twice. Roberts:  That\u2019s why we\u2019re still trying to dig up in the centre of the island, looking in the Soa Basin on Flores. Mike took another view: let\u2019s try and find the bones of the ancestors, wherever they came from, which was probably north of Flores. So Mike and I went to the Philippines, and we also went to Sulawesi, Indonesia. Mike was still doing excavations on Sulawesi, as are several of the people here. Jungers:  I never met anybody who was as single-minded and sustained in their work as Mike. He was always looking over the horizon to the next excavation, the next expedition. I excavated at Liang Bua off and on, and the last time I saw Mike was that summer before he passed. Roberts:  Mike actually came and saw me and said, \u201cAh Bert, I need to talk to you about something.\u201d He said \u201cI\u2019ve got cancer.\u201d He seemed to be getting tired more and more easily, and that wasn\u2019t like Mike at all. Jungers:  Mike died of complications of prostate cancer, and he was so consumed by his work that I think he neglected his health. It didn\u2019t occur to him that he should take better care of himself. Even when he was diagnosed, the only thing he wanted to talk about was the next expedition. He was an original and became a good friend, and I miss him. Roberts:  Who would have thought ten years ago that Mike wouldn\u2019t have been with us now? He was one of the forces of nature. Without Mike, it wouldn\u2019t have happened. The hobbit team is still digging up Liang Bua. With new dating work, the researchers hope to determine when  H.\u00a0floresiensis  went extinct and whether it overlapped with modern humans in the region. The hobbit\u2019s discovery thrust southeast Asia to the forefront of research into human evolution, suggesting that key events might have happened there. But the find also complicated the history of  Homo  species in Asia. Roberts:  We had such a nice simple story, where we had modern humans and Neanderthals, and we bumped them off, that was the end of Neanderthals. We ventured across southeast Asia and it was basically empty because  Homo erectus  had died out there already, and we sort of just wandered into Australia and there we go. It was a clean and almost crisp little story. It made nice sense. Everyone was happy with that. And then suddenly the hobbit pops its head up. Brown:  Now I\u2019m more open to the idea that very small-bodied and small-brained bipeds moved out of Africa at a much earlier date, maybe 3\u00a0million years ago, or earlier. I\u2019m more open to the idea that there were lots of failures in the evolution of bipeds. Some were successful, some weren\u2019t. It\u2019s a very branchy tree, and it just so happens we\u2019ve survived. Roberts:  To me, the ultimate value of the hobbit is not what it is, in and of itself, because it\u2019s just a dead end. It probably didn\u2019t lead to anything that\u2019s alive today. But it opened up the door for people to think more broadly about everything. I think the hobbit changed the way people thought. See Comment  page 427 \n                     Human evolution: Small remains still pose big problems 2014-Oct-22 \n                   \n                     'Hobbit' was a dwarf with large feet 2009-May-06 \n                   \n                     Will the hobbit argument ever be resolved? 2006-Aug-25 \n                   \n                     Palaeoanthropology: Looking for the ancestors 2005-Mar-23 \n                   \n                     Critics silenced by scans of hobbit skull 2005-Mar-03 \n                   \n                     Fossil finders in tug of war over analysis of hobbit bones 2005-Mar-02 \n                   \n                     Little lady of Flores forces rethink of human evolution 2004-Oct-27 \n                   \n                     Nature  special: The hobbit at 10 \n                   \n                     Blog post: Who were the hobbit's ancestors? \n                   \n                     Nature Collection:  The history of the hobbit \n                   \n                     Indonesian National Centre for Archaeology \n                   Reprints and Permissions"},
{"file_id": "516028a", "url": "https://www.nature.com/articles/516028a", "year": 2014, "authors": [{"name": "Mason Inman"}], "parsed_as_year": "2006_or_before", "body": "The United States is banking on decades of abundant natural gas to power its economic resurgence. That may be wishful thinking. When US President Barack Obama talks about the future, he foresees a thriving US economy fuelled to a large degree by vast amounts of natural gas pouring from domestic wells. \u201cWe have a supply of natural gas that can last America nearly 100 years,\u201d he declared in his 2012 State of the Union address. Obama's statement reflects an optimism that has permeated the United States. It is all thanks to fracking \u2014 or hydraulic fracturing \u2014 which has made it possible to coax natural gas at a relatively low price out of the fine-grained rock known as shale. Around the country, terms such as 'shale revolution' and 'energy abundance' echo through corporate boardrooms. Companies are betting big on forecasts of cheap, plentiful natural gas. Over the next 20 years, US industry and electricity producers are expected to invest hundreds of billions of dollars in new plants that rely on natural gas. And billions more dollars are pouring into the construction of export facilities that will enable the United States to ship liquefied natural gas to Europe, Asia and South America. All of those investments are based on the expectation that US gas production will climb for decades, in line with the official forecasts by the US Energy Information Administration (EIA). As agency director Adam Sieminski put it last year: \u201cFor natural gas, the EIA has no doubt at all that production can continue to grow all the way out to 2040.\u201d But a careful examination of the assumptions behind such bullish forecasts suggests that they may be overly optimistic, in part because the government's predictions rely on coarse-grained studies of major shale formations, or plays. Now, researchers are analysing those formations in much greater detail and are issuing more-conservative forecasts. They calculate that such formations have relatively small 'sweet spots' where it will be profitable to extract gas. The results are \u201cbad news\u201d, says Tad Patzek, head of the University of Texas at Austin's department of petroleum and geosystems engineering, and a member of the team that is conducting the in-depth analyses. With companies trying to extract shale gas as fast as possible and export significant quantities, he argues, \u201cwe're setting ourselves up for a major fiasco\u201d. That could have repercussions well beyond the United States. If US natural-gas production falls, plans to export large amounts overseas could fizzle. And nations hoping to tap their own shale formations may reconsider. \u201cIf it begins to look as if it's going to end in tears in the United States, that would certainly have an impact on the enthusiasm in different parts of the world,\u201d says economist Paul Stevens of Chatham House, a London-based think tank. The idea that natural gas will be abundant is a sharp turnaround from more pessimistic outlooks that prevailed until about five years ago. Throughout the 1990s, US natural-gas production had been stuck on a plateau. With gas supplying one-quarter of US energy, there were widespread worries that supplies would shrink and the nation would become dependent on imports. The EIA, which collects energy data and provides a long-term outlook for US energy, projected as recently as 2008 that US natural-gas production would remain fairly flat for the following couple of decades. Then the shale boom caught everyone by surprise. It relied on fracking technology that had been around for decades \u2014 but when gas prices were low, the technology was considered too costly to use on shale. In the 2000s, however, prices rose high enough to prompt more companies to frack shale formations. Combined with new techniques for drilling long horizontal wells, this pushed US natural-gas production to an all-time high, allowing the nation to regain a title it had previously held for decades: the world's top natural-gas producer. \n               Rich rocks \n             Much of the credit for that goes to the Marcellus shale formation, which stretches across West Virginia, Pennsylvania and New York. Beneath thickly forested rolling hills, companies have sunk more than 8,000 wells over several years, and are adding about 100 more every month. Each well extends down for about 2 kilometres before veering sideways and snaking for more than a kilometre through the shale. The Marcellus now supplies 385 million cubic metres of gas per day, more than enough to supply half of the gas currently burned in US power plants. A substantial portion of the rest of the US gas supply comes from three other shale plays \u2014 the Barnett in Texas, the Fayetteville in Arkansas and the Haynesville, which straddles the Louisiana\u2013Texas border. Together, these 'big four' plays boast more than 30,000 wells and are responsible for two-thirds of current US shale-gas production. The EIA \u2014 like nearly all other forecasters \u2014 did not see the boom coming, and has consistently underestimated how much gas would come from shale. But as the boom unfolded, the agency substantially raised its long-term expectations for shale gas. In its  Annual Energy Outlook 2014 , the 'reference case' scenario \u2014 based on the expectation that natural-gas prices will gradually rise, but remain relatively low \u2014 shows US production growing until 2040, driven by large increases in shale gas. The EIA has not published its projections for individual shale-gas plays, but has released them to  Nature . In the latest reference-case forecast, production from the big four plays would continue rising quickly until 2020, then plateau for at least 20 years. Other shale-gas plays would keep the boom going until 2040 (see 'Battle of the forecasts'). Petroleum-industry analysts create their own shale-gas forecasts, which generally fall in the neighbourhood of the EIA assessment. \u201cEIA's outlook is pretty close to the consensus,\u201d says economist Guy Caruso of the Center for Strategic and International Studies in Washington DC, who is a former director of the agency. However, these consultancies rarely release the details behind their forecasts. That makes it difficult to assess and discuss their assumptions and methods, argues Ruud Weijermars, a geoscientist at Texas A&M University in College Station. Industry and consultancy studies are \u201centirely different from the peer-reviewed domain\u201d, he says. To provide rigorous and transparent forecasts of shale-gas production, a team of a dozen geoscientists, petroleum engineers and economists at the University of Texas at Austin has spent more than three years on a systematic set of studies of the major shale plays. The research was funded by a US$1.5-million grant from the Alfred P. Sloan Foundation in New York City, and has been appearing gradually in academic journals 1 , 2 , 3 , 4 , 5  and conference presentations. That work is the \u201cmost authoritative\u201d in this area so far, says Weijermars. If natural-gas prices were to follow the scenario that the EIA used in its 2014 annual report, the Texas team forecasts that production from the big four plays would peak in 2020, and decline from then on. By 2030, these plays would be producing only about half as much as in the EIA's reference case. Even the agency's most conservative scenarios seem to be higher than the Texas team's forecasts. \u201cObviously they do not agree very well with the EIA results,\u201d says Patzek. The main difference between the Texas and EIA forecasts may come down to how fine-grained each assessment is. The EIA breaks up each shale play by county, calculating an average well productivity for that area. But counties often cover more than 1,000 square kilometres, large enough to hold thousands of horizontal fracked wells. The Texas team, by contrast, splits each play into blocks of one square mile (2.6 square kilometres) \u2014 a resolution at least 20 times finer than the EIA's. Resolution matters because each play has sweet spots that yield a lot of gas, and large areas where wells are less productive. Companies try to target the sweet spots first, so wells drilled in the future may be less productive than current ones. The EIA's model so far has assumed that future wells will be at least as productive as past wells in the same county. But this approach, Patzek argues, \u201cleads to results that are way too optimistic\u201d. The high resolution of the Texas studies allows their model to distinguish the sweet spots from the marginal areas. As a result, says study co-leader Scott Tinker, a geoscientist at the University of Texas at Austin, \u201cwe've been able to say, better than in the past, what a future well would look like\u201d. The Texas and EIA studies also differ in how they estimate the total number of wells that could be economically drilled in each play. The EIA does not explicitly state that number, but its analysis seems to require more wells than the Texas assessment, which excludes areas where drilling would be difficult, such as under lakes or major cities. These features of the model were chosen to \u201cmimic reality\u201d, Tinker says, and were based on team members' long experience in the petroleum industry. \n               Alternative Futures \n             The lower forecasts from Texas mesh with a few independent studies that use simpler methods. Studies by Weijermars 6 , as well as Mark Kaiser 7  of Louisiana State University in Baton Rouge and retired Geological Survey of Canada geologist David Hughes 8 , suggest that increasing production, as in the EIA's forecasts, would require a significant and sustained increase in drilling over the next 25 years, which may not be profitable. Some industry insiders are impressed by the Texas assessment. Richard Nehring, an oil and gas analyst at Nehring Associates in Colorado Springs, Colorado, which operates a widely used database of oil and gas fields, says the team's approach is \u201chow unconventional resource assessments should be done\u201d. Patzek says that the EIA's method amounts to \u201ceducated guesswork\u201d. But he and others are reluctant to come down too hard. The EIA is doing \u201cthe best with the resources they have and the timelines they have\u201d, says Patzek. Its 2014 budget \u2014 which covers data collection and forecasting for all types of energy \u2014 totalled just $117 million, about the cost of drilling a dozen wells in the Haynesville shale. The EIA is \u201cgood value for the money\u201d, says Caruso. \u201cI always felt we were underfunded. The EIA was being asked to do more and more, with less and less.\u201d Patzek acknowledges that forecasts of shale plays \u201care very, very difficult and uncertain\u201d, in part because the technologies and approaches to drilling are rapidly evolving. In newer plays, companies are still working out the best spots to drill. And it is still unclear how tightly wells can be packed before they significantly interfere with each other. Representatives of the EIA defend the agency's assessments and argue that they should not be compared with the Texas studies because they use different assumptions and include many scenarios. \u201cBoth modelling efforts are valuable, and in many respects feed each other,\u201d says John Staub, leader of the EIA's team on oil and gas exploration and production analysis. \u201cIn fact, EIA has incorporated insights from the University of Texas team,\u201d he says. Yet in a working paper 9  published online on 14 October, two EIA analysts acknowledge problems with the agency's methods so far. They argue that it would be better to draw upon high-resolution geological maps, and they point to those generated by the Texas team as an example of how such models could improve forecasts by delineating sweet spots. The paper carries a disclaimer that the authors' views are not necessarily those of the EIA \u2014 but the agency does plan to use a new approach along these lines when it assesses the Marcellus play for its 2015 annual report. (When  Nature  asked the authors of that paper for an on-the-record interview, they referred questions to Staub.) \n               Boom or bust \n             Members of the Texas team are still debating the implications of their own study. Tinker is relatively sanguine, arguing that the team's estimates are \u201cconservative\u201d, so actual production could turn out to be higher. The big four shale-gas plays, he says, will yield \u201ca pretty robust contribution of natural gas to the country for the next few decades. It's bought quite a bit of time.\u201d Patzek argues that actual production could come out lower than the team's forecasts. He talks about it hitting a peak in the next decade or so \u2014 and after that, \u201cthere's going to be a pretty fast decline on the other side\u201d, he says. \u201cThat's when there's going to be a rude awakening for the United States.\u201d He expects that gas prices will rise steeply, and that the nation may end up building more gas-powered industrial plants and vehicles than it will be able to afford to run. \u201cThe bottom line is, no matter what happens and how it unfolds,\u201d he says, \u201cit cannot be good for the US economy.\u201d If forecasting is difficult for the United States, which can draw on data for tens of thousands of shale-gas wells, the uncertainty is much larger in countries with fewer wells. The EIA has commissioned estimates of world shale potential from Advanced Resources International (ARI), a consultancy in Washington DC, which concluded in 2013 that shale formations worldwide are likely to hold a total of 220 trillion cubic metres of recoverable natural gas 10 . At current consumption rates \u2014 with natural gas supplying one-quarter of global energy \u2014 that would provide a 65-year supply. However, the ARI report does not state a range of uncertainty on its estimates, nor how much gas might be economical to extract. Such figures are \u201cextremely dubious\u201d, argues Stevens. \u201cIt's sort of people wetting fingers and waving them in the air.\u201d He cites ARI's assessments of Poland, which is estimated to have the largest shale-gas resources in Europe. Between 2011 and 2013, the ARI reduced its estimate for Poland's most promising areas by one-third, saying that some test wells had yielded less than anticipated. Meanwhile, the Polish Geological Institute did its own study 11 , calculating that the same regions held less than one-tenth of the gas in ARI's initial estimate. If gas supplies in the United States dry up faster than expected \u2014 or environmental opposition grows stronger \u2014 countries such as Poland will be less likely to have their own shale booms, say experts. For the moment, however, optimism about shale gas reigns \u2014 especially in the United States. And that is what worries some energy experts. \u201cThere is a huge amount of uncertainty,\u201d says Nehring. \u201cThe problem is, people say, 'Just give me a number'. Single numbers, even if they're wrong, are a lot more comforting.\u201d See also Correspondence:  Shale gas: Nuance in output predictions  and  Shale gas: Hardly a fallacy Access the data used in this feature at  https://github.com/the-frack-lab/data/wiki/Nature-feature-%22The-Fracking-Fallacy%22 See Editorial  page 7 \n                     The uncertain dash for gas 2014-Dec-03 \n                   \n                     Fracking fracas 2013-Apr-25 \n                   \n                     Energy: A reality check on the shale revolution 2013-Feb-20 \n                   \n                     China slow to tap shale-gas bonanza 2013-Feb-20 \n                   \n                     The global energy challenge: Awash with carbon 2012-Nov-28 \n                   \n                     The Drillers Are Coming 2010-Jul-01 \n                   \n                     The shale revolution 2009-Jul-29 \n                   \n                     US Energy Information Administration's Annual Energy Outlook \n                   \n                     University of Texas shale-gas studies \n                   \n                     Texas Bureau of Economic Geology \n                   Reprints and Permissions"},
{"file_id": "516024a", "url": "https://www.nature.com/articles/516024a", "year": 2014, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "After a 30-year struggle to harness quantum weirdness for computing, physicists finally have their goal in reach. When asked what he likes best about working for Google, physicist John Martinis does not mention the famous massage chairs in the hallways, or the free snacks available just about anywhere at the company's campus in Mountain View, California. Instead, he marvels at Google's tolerance of failure in pursuit of a visionary goal. \u201cIf every project they try works,\u201d he says, \u201cthey think they aren't trying hard enough.\u201d Martinis reckons that he is going to need that kind of patience. In September, Google recruited him and his 20-member research team from the University of California, Santa Barbara, and set them to work on the notoriously difficult task of building quantum computers: devices that exploit the quirks of the quantum world to carry out calculations that ordinary computers could not finish in the lifetime of the Universe. It is a vision that has frustrated Martinis and many other physicists ever since it was proposed in the early 1980s. In practice, the quantum effects essential in such a computer are incredibly fragile and hard to control: if one stray photon or vibration from the outside hits the device in the wrong way, the calculation will collapse. Even today, after three decades of effort, the best quantum computers in the world are barely able to do school-level problems such as finding the prime factors of the number 21. (Answer: 3 and 7.) The result has been a rate of progress so slow that sceptics often compare quantum computing to fusion energy: it is a revolutionary technology that always seems to be decades away. But maybe not. Many physicists in the field think that their 30-year slog may finally be on the verge of paying dividends. Not only can they now generate quantum bits, or 'qubits', that last for minutes instead of nanoseconds, they are also much better at correcting the system when errors arise from outside perturbations and other causes. At the same time, quantum-software engineers are coming up with applications that could justify the expense of developing these machines, such as finding new catalysts for industrial processes. The prospects for useful and profitable quantum computers are good enough to have drawn Google into the game, along with IBM and Microsoft, among others. Several academic groups are also pushing the technology in practical directions. At the Delft University of Technology in the Netherlands, for example, the government-backed QuTech Centre is bringing researchers together with the Dutch high-tech industry. Delft physicist Ronald Hanson says that he will be able to make the building blocks of a universal quantum computer in just five years, and a fully functional \u2014 if bulky and inefficient \u2014 demonstration machine in a little more than a decade. Martinis says that he has no fixed timetable, but is just as optimistic. \u201cWe got a lot of things working in the last couple of years,\u201d he says. \u201cIt is still possible that nature just won't allow it to work, but I think we have a decent chance.\u201d \n               Seventies child \n             The conceptual foundations of quantum computing were laid during the 1970s and early 1980s \u2014 most notably by the late US physicist Richard Feynman, whose lecture on the subject, published 1  in 1982, is widely credited with launching the field. The basic insight is that conventional computers are 'either\u2013or' machines, meaning that the tiny silicon circuit that encodes a given bit of information acts like a switch that is either open or closed. This means that it can represent choices such as 'true' or 'false', or the 1s and 0s of binary arithmetic. But in the quantum realm, 'either\u2013or' gives way to 'both\u2013and': if binary 1s are represented by, say, electrons that are spinning clockwise, and 0s by electrons spinning counterclockwise, then the subatomic laws that govern those particles make it possible for a given quantum bit to be both 1 and 0 at the same time. By extension, the set of qubits comprising the memory of a quantum computer could exist in every possible combination of 1s and 0s at once. Where a classical computer has to try each combination in turn, a quantum computer could process all those combinations simultaneously \u2014 in effect, carrying out calculations on every possible set of input data in parallel. And because the number of combinations increases exponentially with the size of the memory, the quantum computer has the potential to be exponentially faster than its classical counterpart. That insight became much more than a scientific curiosity in 1994, when the US mathematician Peter Shor developed an algorithm that would allow a quantum computer to factor large numbers very quickly 2 . Such factorization is prohibitively time-consuming for standard computers, which is why it forms the basis for widely used encryption techniques. Shor's algorithm meant that in principle, quantum computers could crack that encryption. Then two years later, Lov Grover, a researcher at Bell Labs in Murray Hill, New Jersey, devised another algorithm that showed how quantum computers could radically speed up searches of massive databases 3 . The demonstration of such obviously important applications quickly attracted researchers and funding \u2014 accompanied by claims that working quantum computers would be ready in a matter of years. \u201cBut in hindsight they were naive,\u201d says Hanson. Researchers have been able to make some progress by devising special-purpose quantum devices that are tailored for solving specific problems (see  Nature   491 , 322\u2013324; 2012 and  Nature   498 , 286\u2013288; 2013 ). But achieving the ultimate goal \u2014 a general-purpose, digital quantum computer that can be programmed to carry out any algorithm \u2014 has proved much tougher. The problem is the extreme fragility of quantum effects: any slight influence from the outside world will cause a qubit to collapse so that it no longer represents many different states at once. If qubits are going to be useful in real-world calculations, they must be kept in the strictest isolation and manipulated with care \u2014 extremely difficult tasks. They also need to remain in their quantum states for much longer than it takes to perform a computing step \u2014 typically a microsecond or so. To achieve those goals, physicists are pursuing a two-fold strategy: extending the life of qubits and reducing how often they go wrong, and devising algorithms that can correct any errors that do occur. The qubit design currently favoured by many researchers is based on microchip-scale circuits made from superconductors, materials that lose all resistance to the flow of electricity at very low temperatures. Thanks to a quantum phenomenon known as the Josephson effect, electric currents flowing around tiny loops in such circuits can circle both clockwise and counterclockwise at once, so are perfect for representing a qubit. Such circuits are tricky to implement, says Martinis. \u201cYou have to work many years to figure out all the physics.\u201d But after a decade spent refining designs and learning how to isolate the circuits from the environment, his group and others have increased qubit lifetimes by a factor of 10,000, meaning that they can now regularly maintain their state for around 50 to 100 microseconds. They have also slashed the rate at which errors occur by finding better ways to manipulate and control their qubits as the computation proceeds. Lifetimes have been tougher to boost for qubits that are based on the spins of electrons or atomic nuclei, because these spins are easily flipped by the magnetic fields of neighbouring particles. In October, however, Andrea Morello and Andrew Dzurak, physicists at the University of New South Wales in Sydney, Australia, announced 4  that they had eliminated such interference by embedding spin-qubits in purified silicon that contains no magnetic isotopes of the element. The resulting qubits lived as long as 30 seconds. In 1997, physicist Alexei Kitaev of the California Institute of Technology in Pasadena proposed 5  a more radical approach: make qubits out of anyons, which are states of matter that arise from the collective properties of many particles, yet behave as just one particle. Some anyons have another special property: their quantum state reveals a history of their recent interactions. If these anyons were used as qubits, Kitaev argued, the order of their interactions could encode information. And because this encoding is effectively spread throughout the system, the qubits would have a natural protection against errors arising in any individual part. Known as 'topological qubits', these entities remain theoretical, but the idea shows enough promise that Microsoft and a number of other companies are investing in efforts to create them in the laboratory. Even with the most robust qubits, however, errors are inevitable. That is also the case in ordinary computers, but errors are particularly troublesome in a quantum computer because they grow exponentially with the number of qubits. \u201cOne of the real tricks of eventually building a quantum computer is finding a way to get around that,\u201d says David Cory, an experimental quantum physicist at the University of Waterloo in Canada. That means implementing some form of quantum error correction. In standard computers, correcting for errors can be as simple as starting off with multiple copies of each bit. A majority vote among the copies can reveal whether any one of them has later flipped from a 1 to 0 or vice versa. That does not work in the quantum world because it is impossible to copy a qubit without destroying its quantum state. But qubits can be compared, so theorists have tried to devise correction schemes that ask various pairs of qubits whether they have the same or different values, and then use the answers to deduce whether individual qubits have gone wrong. Until recently, a big problem was that qubits typically made about one error in every ten computer steps, and the available correction schemes could not begin to keep up. \u201cTheorists were saying we need average error rates to be, say, 1 in 100,000 operations,\u201d says John Morton, an experimental physicist at University College London. In April this year, however, Martinis and his group announced 6  that they had demonstrated a 'surface-code' scheme that spreads the quantum information of a qubit among several physical qubits, similar to what Kitaev proposed for topological qubits. In its publication, the group described how it had used this technique to implement 5 qubits of information in a way that could handle error rates as high as 1 per 100 operations \u2014 a rate that they and others 7  are now able to achieve (see page 10). \n               Onwards and upwards \n             Together, improvements in qubit error rates and the ability of codes to cope with errors have radically changed the outlook of the field, says Morton. \u201cWhat makes it an exciting time is that we can now focus on scaling up,\u201d he says. At the QuTech Centre, Hanson agrees. \u201cThere are no fundamental roadblocks left,\u201d he says. He is now advertising for 5 electrical engineer professorships, and looking for 40 technicians and researchers, so that he can scale up from laboratory experiments to practical technology. Their main tasks will be to figure out how to fabricate large-scale qubit arrays, how to control the quantum computation and read out the results and how to connect up the quantum circuitry to classical electronics that reside on the same chip. Both Hanson and his colleague Lieven Vandersypen, who leads Delft's efforts to develop spin qubits embedded in the tiny semiconductor crystals known as quantum dots, aim to build arrays of 17 qubits in the next 5 years. This, they say, is the minimum to demonstrate that the surface-code scheme works as hoped. To create a single virtual qubit that remains correct over the hours it takes to run real algorithms may mean spreading its information over 100 physical qubits. Each extra qubit increases the complexity of the hardware. But once a team has acquired the know-how to create a few dozen physical qubits, they believe, growing to the hundred they need to make a handful of virtual qubits should be much easier. \u201cThen it's a case of ambitious engineering to go to 100, or 1,000. I hope that in 10 years we'll be talking about 100s of qubits,\u201d says Vandersypen. At the Swiss Federal Institute of Technology in Zurich, however, theoretical physicist Matthias Troyer cautions that the goal of hundreds of qubits will not be easy or cheap to achieve. Assuming that quantum chips will be as least as hard to manufacture as semiconductor chips, Troyer estimates that working out how to wire up, manipulate and fabricate qubits in bulk will be a US$10-billion problem. That poses a crucial question, he says. \u201cWhy should one do it?\u201d Troyer has spent the past three years looking for an answer \u2014 a 'killer app' for quantum computing that would make the development costs worthwhile. The two classic examples, code-cracking and searching databases, are not good enough, says Troyer. Shor's algorithm will require thousands of qubits to do any serious factorization, he says, and there are other forms of encryption that a quantum computer would do nothing to solve. And although quantum computers may search databases faster, they are still limited by the time it takes to feed the data into the circuit, which would not change. Troyer thinks that a much more fruitful application for the near future is the modelling of electrons in materials and molecules \u2014 something that quickly becomes too difficult for today's supercomputers. At first, this, too, seemed a long shot. His early estimates suggested that it would take a quantum computer as long as 300 years to simulate the molecular dynamics of even a small molecule \u2014 such as the iron sulphide inside the ferredoxin proteins that are involved in nitrogen fixation in plants. \u201cClearly, that was on the border of being science fiction,\u201d he says. But by rewriting the software 8 , he brought the figure down to 30 years \u2014 then to just 300 seconds. \u201cJust like in classical computing, where one has to sit down and optimize the algorithm,\u201d he says, \u201cthe same is needed for a quantum algorithm.\u201d With around 400 encoded qubits, Troyer says, it would be possible to analyse ways to improve industrial nitrogen fixation \u2014 the energy-intensive process that turns the unreactive molecule in air into fertilizer. This reaction is now carried out on an industrial scale using the 116-year-old Haber process, but that uses up about 5% of the natural gas produced each year worldwide. Troyer thinks that a quantum computer could help to design a catalyst that would be much more energy-efficient than the current ones. \u201cThat would be worth building a quantum computer for,\u201d he says. Other killer applications might be searching for new high-temperature superconductors, or improving the catalysts used to capture carbon from the air or from industrial exhaust streams. \u201cAll these are important questions. If it makes progress there, easily that's your 10 billion,\u201d says Troyer. For now, however, Martinis and other veterans of the field caution that quantum computing is still in the early stages. Although industry is now deep into the research, no one even has one of these things to play with. Quantum computing today is comparable to conventional computing in the years after the Second World War, he says, when every device was a laboratory experiment that had been crafted by hand. \u201cWe're somewhere between the invention of the transistor and the invention of the integrated circuit,\u201d he concludes. At Google, the project has the buzz of a Silicon Valley start-up, says Martinis, albeit one with hefty backing. After years of the hard work of perfecting qubits, he is happy to finally be able to focus on building a quantum computer that can actually solve real problems. \u201cGoogle created a new name for scientists working on the hardware effort, 'quantum engineers',\u201d says Martinis. \u201cThis is a dream job for me.\u201d \n                     Quantum computation: Silicon comes back 2014-Oct-12 \n                   \n                     Quantum bits get their first compression 2014-Sep-29 \n                   \n                     Quantum computing: Powered by magic 2014-Jun-11 \n                   \n                     Quantum physics: Flawed to perfection 2014-Jan-22 \n                   \n                     Computing: The quantum company 2013-Jun-19 \n                   \n                     Quantum computing: The power of discord 2011-Jun-01 \n                   \n                     QuTech \n                   \n                     Martinis lab \n                   \n                     Troyer lab \n                   Reprints and Permissions"},
{"file_id": "513478a", "url": "https://www.nature.com/articles/513478a", "year": 2014, "authors": [{"name": "Gene Russo"}], "parsed_as_year": "2006_or_before", "body": "The United States has plenty of strong winds offshore, but it has struggled to harness them for energy. The town of Castine, Maine, feels like a place bypassed by time. First settled in the early seventeenth century, its streets are lined with buildings hundreds of years old. Boats bob in its small harbour and a white lighthouse, constructed of rough-hewn stone, stands guard from a high hill. But just half a kilometre offshore, a harbinger of the future pokes out of the grey mist. A canary-yellow wind turbine rocks in the waves, its thin blades slowly rotating. Installed in June last year, the 20-metre-tall structure is an experimental floating design just one-eighth in scale. It provides a maximum of 20\u00a0kilowatts of electricity, barely enough to power half a dozen US homes. But the structure, called VolturnUS, stands out because it is the only offshore wind turbine in US\u00a0waters. Other countries, such as Belgium, the United Kingdom, Denmark and Germany, have built massive turbine farms off their coastlines in the past few decades. In the United States, however, efforts to tap the power of coastal winds have gone nowhere because of environmental concerns, bureaucratic tangles and political opposition. That may soon change. Ecological studies indicate that carefully planned wind farms should not significantly harm birds or marine mammals. And business and politicians are increasingly interested in exploring and investing in offshore wind power. This May, the US Department of Energy awarded money to three demonstration projects, planned for the coasts of New Jersey, Oregon and Virginia. Several state governments are forging ahead with their own ambitions for offshore wind farms, and commercial developers say that they could start planting turbines in the ocean as early as next year. In theory, the potential is tremendous. Including harder-to-reach deep-water sites, the offshore territory of the United States has the capacity to generate an estimated 4,200\u00a0gigawatts of electricity, enough to supply four times the nation\u2019s current needs. But before the field can take off, proponents will have to prove that offshore wind can compete financially against other energy sources, and can clear the thicket of state and federal regulations that govern projects in coastal waters. \u201cI don\u2019t think we\u2019re looking at easy street here,\u201d says Walt Musial, a long-time offshore-wind researcher at the National Renewable Energy Laboratory in Louisville, Colorado. \u201cWe really need to demonstrate that it can be done.\u201d \n               Sea test \n             No project encapsulates the challenges facing offshore wind power better than Cape Wind, being developed by Energy Management of Boston, Massachusetts. The venture aims to take advantage of the strong winds and relatively calm waters of Nantucket Sound near Cape Cod, Massachusetts, some 350\u00a0kilometres southwest of Castine. The plan for Cape Wind consists of 130\u00a0turbines, each standing nearly 80 metres tall, over an area of 65 square kilometres. Energy Management says that the completed wind farm will have a capacity of 468 megawatts, able to produce 75% of the electricity for Cape Cod and the nearby islands of Martha\u2019s Vineyard and Nantucket. But the project has faced strong opposition for more than a decade. Organizations including the non-profit group Save Our Sound have brought dozens of lawsuits against Cape Wind, claiming that the project would harm birds and other wildlife, increase electricity rates for consumers and endanger aeroplanes flying into local airspace.Except for one temporary decision, all of the judicial rulings have been in favour of Cape Wind. Spokes\u00adperson Mark Rodgers says that even with court appeals coming, the project intends to commence construction by spring 2015. \u201cThere are no merits to any of these legal complaints,\u201d he says. Cape Wind has already broken new ground by being the first US offshore wind project to complete a major environmental assessment. That study\u00a0\u2014 thousands of pages long\u00a0\u2014 and independent analyses have helped to appease some groups that were sceptical of the initial proposal. The conservation group Mass Audubon in Lincoln, Massachusetts, for example, spent three years tracking roseate terns ( Sterna dougallii ), migratory songbirds and sea ducks wintering in the area, and found little cause for concern. The songbirds typically fly above 300 metres, making collisions unlikely. And the terns and ducks stay close to shore during migration and breeding. The effects on marine mammals may be harder to predict. Researchers and environmentalists have worried in particular about the construction stage of offshore wind farms, which so far have almost exclusively usedturbines fixed to the ocean floor.Pounding huge steel beams into the seabed generates sounds equivalent to a small explosion\u00a0\u2014 enough to disrupt the behaviour of some marine mammals, at least temporarily. In the early 2000s, Jakob Tougaard, a marine bioacoustician at Aarhus University in Roskilde, Denmark, studied the effects of wind-farm construction on harbour porpoises ( Phocoena phocoena ) off the coast of Denmark. Using recordings of porpoise vocalizations, he found 1  evidence that animals shied away from the construction site even up to distances of 21 kilometres. \u201cIn most cases, there\u2019s a strong effect from construction,\u201d says Tougaard. But his work and follow-up studies by other researchers show 2  that porpoise visits to the wind-farm area increase once construction has finished. To avoid severe problems such as damaging the hearing of marine mammals, Cape Wind is required as part of its lease to have at least one observer monitoring each turbine installation. The company will delay pile driving if a marine mammal comes within 750 metres of the site, says Rachel Pachter, a permitting and environmental project manager for Cape Wind. Other projects might have to take stronger measures to accommodate the endangered North Atlantic right whale ( Eubalaena\u00a0glacialis ). Cape Wind is outside the whales\u2019 typical migration path, but the animals pass closer to many other potential wind-farm sites along the East Coast. In 2012, several environmental groups and developers agreed to guidelines that would minimize risks to the whales. For example, during certain migratory periods, developers are expected to mitigate the noise through measures such as generating curtains of bubbles around the project to dissipate sound waves. Peter Tyack, a marine biologist at the Woods Hole Oceanographic Institution in Massachusetts, says that these and other measures will reduce the effects of construction on whales. \u201cI would be surprised if it has a big impact on them,\u201d he says, although he advocates putting measures in place to reduce the risk. Onceconstruction is over, wind farms could even provide benefits to the marine animals. Researchers have suggested that forests of offshore turbines can become artificial reefs, and a study published 3  this year using tracking data found that seals sought out turbines at active wind farms in Germany and the United Kingdom, perhaps to forage around them. \u201cWhat really shocked me was the pattern they showed,\u201d says Deborah Russell, a marine biologist at the University of St Andrews, UK, who led the study. The seals may like the protection that the wind farm provides from boats, she says. Beyond concerns over wildlife, US proponents of offshore wind farms have had to address the issue of hurricanes, which could buffet turbines with gusts much stronger than those experienced by facilities in Europe. Although no East Coast hurricane has tested an offshore turbine, engineers say that wind farms can be built to withstand them. Experience with offshore structures such as oil platforms provides confidence that widespread failure of turbines should not be a problem, says James Manwell, a mechanical engineer and director of the Wind Energy Center at the University of Massachusetts Amherst. But fortifying turbines requires extra steel, which drives up expenses. Companies will have to determine how to balance the costs and benefits of reinforcing wind farms for infrequent hurricanes. \n               Rocky waters \n             For developers, the big question is whether it makes economic sense to develop wind farms off US shores. Any extra effort associated with meeting environmental regulations or preparing for severe storms will increase the cost of construction, at a time when wind farms have to compete with a bounty of cheap natural gas. So developers are experimenting with different designs in the hope of driving down costs. Monopile foundations\u00a0\u2014 made of a single huge tube driven into the seabed\u00a0\u2014 are generally cheapest and well tested, but some developers are trying foundations that twist three piles around a central column, similar to structures used for offshore oil and gas platforms. As turbines get larger, these multi-pile designs may be more stable and cost effective than monopiles. Another solution could be simply to float the turbines, as researchers have done with the experimental design in Castine. Habib Dagher, an engineer at the University of Maine in Orono, and his colleagues constructed the base of the turbine out of hollow concrete tubes; it is held steady in the waves by three cables attached to anchors on the sea floor. Such a design could operate in much deeper waters\u00a0\u2014 where it is impractical to use a monopile that reaches all the way to the sea floor\u00a0\u2014 and would be relatively cheap to construct, because it could be manufactured onshore and simply towed out to the designated location, says Dagher. He and others will have to prove that the full-size floating structures can stay upright and stable during major storms. Measurements taken since the demonstration turbine\u2019s launch suggest that the design will perform well. Even in winds up to about 80 kilometres per hour, the turbine leans by only 5.9 degrees, which indicates that a full-sized device should remain stable during storms so powerful they are expected to strike only once every 500\u00a0years, says Dagher. Floating turbines were not taken seriously ten years ago, but now they are emerging as serious contenders, says Musial. An experimental 2-megawatt floating turbine off the coast of Portugal has been working since 2012, and Japan has two floating turbines already connected to the power grid. The US energy department has also expressed interest in the design: one of the three demonstration projects funded by the agency this year will station five 6-megawatt floating turbines in 350 metres of water off the coast of Coos Bay, Oregon (see \u2018Air power\u2019). \n               Political problems \n             Experts say that the environmental and technical challenges for offshore wind are surmountable. The biggest barrier at the moment is the tangled fabric of policy rules that slow projects and provide insufficient certainty for developers and investors, says Willett Kempton, who studies offshore-wind policy at the University of Delaware in Newark. In New Jersey, a group of investors from the commercial fishing industry called Fishermen\u2019s Energy succeeded in securing one of the three Department of Energy grants, but has been locked in a court battle with the state Board of Public Utilities. The board has rejected the group\u2019s application for a demonstration project off the coast of Atlantic City, saying that the state\u2019s electricity users would bear too much of the cost. The most recent decision, handed down by a New Jersey appellate court on 18\u00a0August, will force the board to reconsider the application. Other projects have also fallen prey, at least in part, to concerns over politics, policy and costs. In Maine, for example, a deal to build a US$120-million wind farm, involving the Norwegian energy company Statoil, fell apart after the state\u2019s governor elected to re\u00adopen the bidding process to other developers. Kempton lauds the energy policies and financial incentives of the European countries that have pushed ahead with offshore wind. Denmark, for example, has set a target of getting 50% of its power from wind by 2020. To help meet that goal, it requires that the grid connect to offshore wind farms, and it sets a price for electricity from those facilities. Such long-term support is much more attractive to the wind-energy industry than the kind of short-term tax credits offered by the US federal government, which appear and disappear depending on the whims of Congress as it moves through its two-year election cycle. Some US states are starting to provide better support for projects that could encourage investors and developers. For example, early efforts to build a large wind farm off the coast of Maryland have been buoyed by the state\u2019s offer of subsidies for developers. On 19 August, Italian energy company Renexia won an auction to lease 32,000 hectares off Maryland\u2019s coast, with a bid of $8.7 million. For now, however, the greatest chance of getting turbines into the water lies farther to the north. In September, developer Deepwater Wind received what it says is the final federal approval required to install turbines off the coast of Rhode Island in the middle of next year as part of a demonstration project. And Energy Management hopes to start constructing its much larger Cape Wind project even sooner. To make that possible, the port of New Bedford, Massachusetts, is hurrying to finish preparations that will enable it to handle the 1,400-tonne cranes required to lift the turbines onto ships that will carry them to the Cape Wind site. Massive excavators are working 24\u00a0hours a day to deepen the port. \u201cI think in the next several months we\u2019re going to know whether Cape Wind is going to be real or not,\u201d says Bill White, senior director for offshore wind at the Massachusetts Clean Energy Center, which is managing the New Bedford site. Out on a small boat touring the port, White says that Cape Wind is only the beginning for New Bedford\u2019s long-term plans. The hope is that the upgraded harbour will serve as a staging ground for offshore-wind projects all along the eastern seaboard. White and the project engineers have visited ports in Europe, where they learned some valuable lessons\u00a0\u2014 in particular, that loading areas for offshore-wind parts must handle a tremendous amount of weight. A carefully orchestrated sandwich of concrete, steel and sand has added many metres of sturdy land to the port. The Europeans also taught him something else. \u201cThey said be careful with expectations,\u201d White says. \u201cIt\u2019s going to take some time.\u201d\n Reprints and Permissions"},
{"file_id": "512244a", "url": "https://www.nature.com/articles/512244a", "year": 2014, "authors": [{"name": "Douglas Fox"}], "parsed_as_year": "2006_or_before", "body": "Samples from a lake hidden under 800 metres of ice contain thousands of microbes and hint at vast ecosystems yet to be discovered. A cold breeze blew off the Antarctic plain, numbing the noses and ears of scientists standing around a dark hole in the ice. Flecks of ice crackled off a winch as it reeled the last few metres of cable out of the hole. Two workers in sterile suits leaned over to grab the payload \u2014 a cylinder the length of a baseball bat \u2014 dangling at the end of the cable. They used a hammer to chip away the ice and a blow drier to thaw part of the assembly. \u201cDid it close?\u201d asked the winch operator. \u201cYeah,\u201d shouted John Priscu, a microbial ecologist from Montana State University in Bozeman. The cylinder rested heavily in his gloved hands \u2014 evidence that it had filled with water and sealed shut before its long journey to the surface. The fluid inside came from one of the most isolated bodies of water on Earth: Lake Whillans, trapped beneath 800 metres of ice just 640 kilometres from the South Pole. Hardly a word was spoken as Priscu hefted the vessel against his shoulder and shuffled into a metal shipping container, where the team had set up a cramped, makeshift laboratory. That water, obtained on 28 January 2013, was the first sample ever retrieved directly from a subglacial lake. Although Priscu and other scientists had long yearned to explore Antarctica's hidden lakes and look for resident life, efforts to drill into them have been stymied by the threat of contamination, which would cast doubt on any life found and could introduce invasive organisms into the lake. Priscu and his team spent six years devising safe sampling procedures, and then had to surmount numerous logistical hurdles, such as transporting hundreds of tonnes of equipment to the remote site. Researcher Brent Christner talks about the microbial life lurking in Lake Whillans The researchers have been studying the samples since they reached the lake and have found that an abundance of life lurks beneath Antarctica's blanket of ice. In this week's issue of  Nature 1 , Priscu and his team report finding 130,000 cells in each millilitre of lake water \u2014 a density of microbial life similar to that in much of the world's deep oceans 2 . And with nearly 4,000 species of bacteria and archaea, the community in the lake is much more complex than might be expected from a world sealed off from the rest of the planet. \u201cI was surprised by how rich the ecosystem was,\u201d says Priscu. \u201cIt's pretty amazing.\u201d Samples from the lake show that life has survived there without energy from the Sun for the past 120,000 years, and possibly for as long as 1 million years. And they offer the first look at what may be the largest unexplored ecosystem on Earth \u2014 making up 9% of the world's land area. \u201cThere's a thriving ecosystem down there,\u201d says David Pearce, a microbiologist at Northumbria University, UK, who was part of a team that tried, unsuccessfully, to drill into a different subglacial body, Lake Ellsworth, in 2013. \u201cIt's the first time that we've got a real insight into what organisms might live beneath the Antarctic continent,\u201d he says. \n               Life on ice \n             The ice above Lake Whillans is mind-numbingly flat, making it nearly impossible to imagine that anything unusual hides beneath it. I first travelled there in 2007 as a journalist covering a scientific expedition to the lake, which had been discovered earlier that year through remote satellite measurements. I returned in January 2013, embedded as a reporter with the team that Priscu led with two other scientists to sample the lake. That project, called Whillans Ice Stream Subglacial Access Research Drilling, involved collaboration between nearly two dozen researchers from 15 universities across five countries. The US National Science Foundation had invested roughly US$20 million in the effort, which included building a hot-water drill to get into the lake without contaminating it. The idea that lakes might lurk beneath Antarctica's frozen cover was not widely considered until the 1990s, when ice-penetrating radar and seismic mapping yielded the first solid evidence of subglacial lakes. Nearly 400 are now known. They are fed by water that melts from the base of the ice sheet at rates of a few millimetres per year, caused by ambient heat from deep within the planet (see 'Invisible lakes'). Lake Whillans resembles nothing on Earth's surface. The weight of the ice forces the subglacial water upwards, causing the lake to sit at a slant on the side of a hill. It is a thin lens of water \u2014 only 2 metres deep and nearly 60 square kilometres in area \u2014 held in a pocket of low pressure created by the thinning of the ice sheet as it oozes over the hill. The drill camp materialized on this lonely frontier in January 2013, when tractors arrived pulling shipping containers on massive skis. In their two-week journey from the coast, the tractors hauled 500,000 kilograms of gear and fuel, mobile labs, a machine shop and a hot-water drill that filled six cargo containers. Within two weeks, the camp was a noisy, industrial place, populated by three dozen people, a flock of tents flapping in the steady breeze and two roaring 225,000-watt generators. The polar summer resembled a mild winter in Minneapolis, Minnesota, with temperatures 5\u201315 \u00b0C below freezing. It took seven days to drill through the ice sheet. To prevent contamination of the lake, the crew used ultraviolet radiation, water filtration and hydrogen peroxide to sterilize the machinery and the water used to bore through the ice. As the team neared the lake, progress slowed to a crawl when difficulty in steering the drill bedevilled the crew for an agonizing 36 hours. At 7:30 a.m. on 27 January, a voice crackling through a handheld radio summoned me to the drill control room. Inside, six ice drillers in overalls stared at a computer screen showing a line shooting upwards on a graph, indicating that the water in the borehole had risen 28 metres, pushed up by a gush of water from the lake below. The lake was a balmy \u22120.5 \u00b0C, warmer than the drill camp that day. The researchers pulled up the first sample the next day. Within minutes of raising the grey vessel, they decanted its contents: a honey-coloured broth that turned out to be richer in minerals than anyone had expected. The first cells were spotted several hours later under a microscope \u2014 green dots lit up by DNA-sensitive dye. Tests done over the next several days confirmed that those cells were alive. Twenty scientists and graduate students worked around the clock to collect 30 litres of water and several sediment cores from the lake. Before the hole froze shut, the team also measured the water chemistry in the lake and geothermal heat flowing up through the sediments. Sample boxes accumulated in a cave dug out of the snow on the edge of camp. Over the past year, researchers have worked with those samples to assemble a portrait of life beneath the ice sheet. They have isolated and grown cultures of about a dozen species of microbe. And DNA sequencing has revealed signs of 3,931 species in all \u2014 many of them related to known microbes that break down minerals for energy. Although contamination is always a concern, researchers not connected with the Lake Whillans project say that the sterilization precautions seem to have worked well. One sign is that the microbial density of the drilling water in the hole was 200 times lower than that of the lake samples, says Peter Doran, an Earth scientist at the University of Illinois in Chicago, who worked with the US National Research Council for ten years to develop guidelines for sampling Antarctic lakes cleanly. Doran was convinced by the evidence of diverse microbial life in the lake. \u201cThey found it in such a way that it can't be questioned. It's pretty iron-clad,\u201d he says. \n               Vital signs \n             Overall, life in Lake Whillans works much like ecosystems at the surface, but its deep denizens do not have access to sunlight and so cannot rely on photosynthesis for the energy needed to fix carbon dioxide dissolved in the lake water. The genetic analyses by the team show that some of the lake's microbes are related to marine species that derive energy by oxidizing iron and sulphur compounds from minerals in sediment. But according to the DNA data, the lake's most abundant microbes oxidize ammonium, which is likely to have a biological origin. \u201cThe ammonium is probably a relic of old marine sediments,\u201d says Priscu, referring to dead organic matter that accumulated millions of years ago when the region was covered by shallow seas rather than glaciers. Only single-celled bacteria and archaea have turned up in samples from Lake Whillans \u2014 but the particular DNA tests used so far were not designed to detect other types of organism. This preserves the possibility that Lake Whillans might yet be found to harbour more complex life, such as protozoa \u2014 or even submillimetre animals such as rotifers, worms or eight-legged tardigrades, all known to live in other parts of Antarctica. Air bubbles in the overlying ice supply oxygen to the lake, so that is not a limiting factor. But the low rate of carbon fixation by microbes might provide too little food for multicellular life. Lake Whillans receives about one-tenth the amount of new carbon per square metre per year as the world's most nutrient-starved ocean floors, which support sparse animal populations. Although the chances are slim that Priscu and his colleagues will find animals in Lake Whillans, they plan to look for them using better-tailored DNA assays. For now, the researchers are puzzling over the origins of the microbial residents of the lake. The big question is whether Antarctica's subglacial communities are made of 'survivors' or 'arrivers'. Survivors would be the descendants of microbes that lived in the sediments when the area was covered by open ocean, as it has been periodically over the past 20 million years. Alternatively, Lake Whillans might be populated by wind-blown microbes \u2014 the 'arrivers' \u2014 that were deposited on the ice and worked their way down over 50,000 years as ice melted off the bottom of the glacier. It is also possible that some organisms entered the lake more recently, carried in by sea water seeping under the ice sheet. Lake Whillans sits just 100 kilometres from the grounding line, where the ice sheet transitions from resting on ground to floating on the ocean. That line shifts as the ice thins and thickens, so it is possible that the lake exchanged water \u2014 and microbes \u2014 with the ocean during the past few thousand years, says Christina Hulbe, a glaciologist at the University of Otago in Dunedin, New Zealand, who has long studied that area of Antarctica. Other findings from the lake samples have led to some tantalizing ideas. Traces of fluoride in its water offer possible evidence of hydrothermal vents in the area \u2014 rich sources of chemical energy that have the potential to support islands of exotic life, such as worms or heat-loving microbes. \u201cIt's probable that there are hydrothermal systems in there,\u201d says Donald Blankenship, a glaciologist at the University of Texas at Austin. The lake occupies a broad rift valley where Earth's crust has thinned, and radar surveys by Blankenship show putative volcanoes under the ice 3 , 4 . The results emerging from Lake Whillans could also shed light on how Antarctica influences the nearby ocean and even the entire world. If microbes beneath the ice sheet play an important part in altering the minerals in the sediments, as the latest data suggest, those organisms might supply iron to the subglacial waters that eventually reach the ocean. This process could provide an important source of nutrients to the chronically iron-starved ecosystems in the Southern Ocean 5 , says Martyn Tranter, a marine biogeochemist the University of Bristol, UK. In addition, the presence of small amounts of a chemical called formate in the water of Lake Whillans suggests the possibility that methane, a potent greenhouse gas, is produced in the deeper, oxygen-poor sediments beneath the lake. A 2012 study estimated that the sediments under the Antarctic ice sheet contain hundreds of billions of tonnes of methane \u2014 a reservoir equal to that stored in the Arctic's permafrost \u2014 which could potentially escape and exacerbate global warming if the ice retreats 6 . Lake Whillans provides only a local snapshot of life beneath the ice, and several teams are trying to fill in the picture by exploring other subglacial lakes. A Russian team is now analysing water from Lake Vostok, a lake in a deep tectonic rift in eastern Antarctica that is covered by 3.7 kilometres of ice. Researchers say that analysing those samples presents challenges because the water spent a year frozen in the bottom of the borehole before being brought to the surface. And as the ice was raised, it was exposed to the kerosene drilling fluid in the borehole. Closer to Lake Whillans, Pearce and his colleagues attempted in 2013 to drill into Lake Ellsworth, which sits under 3.4 kilometres of ice in a glacial fjord, but they were forced to abandon the effort after difficulties arose with steering the drill. With its thinner ice covering, Lake Whillans was an easier target than Ellsworth or Vostok, but it did not give up its secrets easily. The day after the first sample was retrieved, a camera lowered into the hole presented a mesmerizing scene as it neared the lake. Iridescent flakes of ice drifted upwards \u2014 a snow shower in reverse, and a sign that the hole was quickly refreezing. The scientists' instruments soon began to catch in the narrowing hole, forcing the drillers to pump in hot water to widen it. This tug-of-war lasted for four days before the team abandoned the hole to its inevitable fate, broke camp and flew their hard-won samples home. See News & Views  page 256 \n                     Biogeochemistry: Microbes eat rock under ice 2014-Aug-20 \n                   \n                     Polar drilling problems revealed 2014-Jan-21 \n                   \n                     Lake-drilling team discovers life under the ice 2013-Feb-11 \n                   \n                     Hunt for life under Antarctic ice heats up 2012-Nov-21 \n                   \n                     Teams set for first taste of Antarctic lakes 2010-Mar-23 \n                   \n                     Blog post: Antarctic team reaches Lake Whillans \n                   \n                     Blog post: Antarctic researchers find life in subglacial lake \n                   \n                     The Whillans Ice Stream Subglacial Access Research Drilling (WISSARD) project \n                   Reprints and Permissions"},
{"file_id": "511524a", "url": "https://www.nature.com/articles/511524a", "year": 2014, "authors": [{"name": "Ed Yong"}], "parsed_as_year": "2006_or_before", "body": "DNA circulating in the bloodstream could guide cancer treatment \u2014 if researchers can work out how best to use it. In 2012, Charles Swanton was forced to confront one of cancer's dirtiest tricks. When he and his team at the Cancer Research UK London Research Institute sequenced DNA from a handful of kidney tumours, they expected to find a lot of different mutations, but the breadth of genetic diversity within even a single tumour shocked them. Cells from one end differed from those at the other and only one-third of the mutations were shared throughout the whole mass. Secondary tumours that had spread and taken root elsewhere in the patients' bodies were different again 1 . The results confirmed that the standard prognostic procedure for cancer, the tissue biopsy, is woefully inadequate \u2014 like trying to gauge a nation's behaviour by surveying a single street. A biopsy could miss mutations just centimetres away that might radically change a person's chances for survival. And although biopsies can provide data about specific mutations that might make a tumour vulnerable to targeted therapies, that information is static and bound to become inaccurate as the cancer evolves. Swanton and his team laid bare a diversity that seemed insurmountable. \u201cI am still quite depressed about it, if I'm honest,\u201d he says. \u201cAnd if we had higher-resolution assays, the complexity would be far worse.\u201d But researchers have found ways to get a richer view of a patient's cancer, and even track it over time. When cancer cells rupture and die, they release their contents, including circulating tumour DNA (ctDNA): genome fragments that float freely through the bloodstream. Debris from normal cells is normally mopped up and destroyed by 'cleaning cells' such as macrophages, but tumours are so large and their cells multiply so quickly that the cleaners cannot cope completely. By developing and refining techniques for measuring and sequencing tumour DNA in the bloodstream, scientists are turning vials of blood into 'liquid biopsies' \u2014 portraits of a cancer that are much more comprehensive than the keyhole peeps that conventional biopsies provide. Taken over time, such blood samples would show clinicians whether treatments are working and whether tumours are evolving resistance. As ever, there are caveats. Levels of ctDNA vary a lot from person to person and can be hard to detect, especially for small tumours in their early stages. And most studies so far have dealt with only handfuls or dozens of patients, with just a few types of cancer. Although the results are promising, they must be validated in larger studies before it will be clear whether ctDNA truly offers an accurate view \u2014 and, more importantly, whether it can save or improve lives. \u201cJust monitoring your tumour isn't good enough,\u201d says Luis Diaz, an oncologist at Johns Hopkins University in Baltimore, Maryland. \u201cThe challenge that we face is finding true utility.\u201d If researchers can clear those hurdles, liquid biopsies could help clinicians to make better choices for treatment and to adjust those decisions as conditions change, says Victor Velculescu, a genetic oncologist at Johns Hopkins. Moreover, the work might provide new therapeutic targets. \u201cIt will help bring personalized medicine to reality,\u201d says Velculescu. \u201cIt's a game-changer.\u201d \n               Delayed action \n             Scientists first reported finding DNA circulating in human blood in 1948 (ref.  2 ), and specifically in the blood of people with cancer in 1977 (ref.  3 ). It took another 17 years to show that this DNA bore mutations that are hallmarks of cancer \u2014 proof that it originated from the tumours 4 , 5 . The first practical use of circulating DNA came in another field. Dennis Lo, a chemical pathologist now at the Chinese University of Hong Kong, reasoned that if tumours could flood the blood with DNA, surely fetuses could, too. In 1997, he successfully showed that pregnant women carrying male babies had fetal Y chromosomes in their blood 6 . That discovery allowed doctors to check a baby's sex early in gestation without disturbing the fetus, and ultimately to screen for developmental disorders such as Down's syndrome without resorting to invasive testing. It has revolutionized the field of prenatal diagnostics (see  Nature   507 , 19; 2014 ). \u201cCancer has been slower to catch on,\u201d says Nitzan Rosenfeld, a genomicist at the Cancer Research UK Cambridge Institute. This is partly because tumour DNA is much harder to detect than fetal DNA. There is typically less of it in the blood, and the amounts are extremely variable. In people with very advanced cancers, tumours might be the source of most of the circulating DNA in the blood, but more commonly, ctDNA makes up barely 1% of the total and possibly as little as 0.01%. Early sequencing technologies were not up to the task of detecting it \u2014 at least, not consistently or reliably enough to use ctDNA as a biomarker. But the past decade has brought sensitive techniques that can detect and quantify minute amounts of DNA. For example, an amplification method known as BEAMing \u2014 which fastens circulating DNA to magnetic beads that can then be isolated and counted \u2014 can detect ctDNA even if it is outnumbered by healthy cell DNA by a factor of 10,000 to 1. Genetic oncologists Bert Vogelstein and Kenneth Kinzler at Johns Hopkins developed the technique, and in 2007 they described 7  using it to track ctDNA in 18 people who were being treated for bowel cancer. After surgery, the patients' ctDNA levels fell by 99%, but in many cases the signal did not disappear completely. In all but one of the people with detectable ctDNA at the first follow-up appointment, the tumours eventually returned. None of the people with undetectable levels after surgery experienced a recurrence. These results suggested that ctDNA can reveal how well a patient has responded to surgery and whether they need chemotherapy to finish off any lingering cancer cells. Researchers soon found similar results for other types of cancer. Rosenfeld and his Cancer Research UK colleagues James Brenton and Carlos Caldas showed that ctDNA provides a precise portrait of advanced ovarian and breast cancers 8 . And in the largest study yet, Diaz and other members of the Johns Hopkins group detected ctDNA in at least 75% of patients with advanced tumours, in organs as diverse as the pancreas, bladder, skin, stomach, oesophagus, liver and head and neck 9 . (Brain cancers were a notable exception, because the blood\u2013brain barrier stops tumour DNA from reaching the bloodstream.) \n               Better biomarkers \n             Circulating DNA might perform better than the protein biomarkers that researchers have been seeking and refining for decades. Proteins are used in the clinic to diagnose illnesses and monitor people undergoing treatment. For example, prostate-specific antigen is a biomarker for prostate cancer, but it can give false positives because there are other reasons that the antigen can be elevated in the blood. False positives should be rarer with ctDNA because it is defined by mutations and other genomic changes that are hallmarks of cancer cells. And although most protein biomarkers stay in the blood for weeks, ctDNA has a half-life of less than two hours, so it gives a clearer view of a tumour's present, rather than its past. The Cambridge and Johns Hopkins teams have found that ctDNA is more sensitive than protein biomarkers when it comes to detecting breast 10  and bowel 9  cancers, respectively, and it is more accurate at tracking tumour disappearance, spread and recurrence. Both teams also showed that ctDNA was more sensitive than circulating tumour cells \u2014 intact cancer cells that also travel around the bloodstream and have been an intense area of research. In a sub-study of 16 people, Diaz's team found that where both were present, ctDNA fragments outnumbered circulating tumour cells by 50 to 1 (ref.  9 ). And although ctDNA was always there if the circulating cells were, 13 people with detectable tumour DNA had no trace of such cells. But most exciting to scientists, says Diaz, is the ability to watch tumours evolve and adapt over time: \u201cIt'll help us answer questions in oncology that have never been answered before.\u201d For example, why do so many targeted therapies eventually fail? Gefitinib and panitumumab are among several drugs that block the epidermal growth factor receptor (EGFR), a protein involved in cell growth and division that is overactive in a number of cancers. People taking these drugs do very well \u2014 briefly. But after a few months, their cancers almost always develop resistance, often through changes to other genes, such as  KRAS , which is mutated in many cancers. To monitor patients and decide on the next course of action, clinicians would normally need to take multiple biopsies. But people with advanced cancer often have several tumours to test, and different parts of any single tumour could be resistant in different ways. Biopsies are invasive and risky, and difficult for inaccessible and fragile organs such as the lungs. \u201cYou can't just go to the patient and get five more biopsies after the treatment fails,\u201d says Velculescu. Taking blood is simple in comparison. In 2012, Diaz's team reported 11  using ctDNA to study patients who were being treated with EGFR inhibitors. The researchers found 42 different  KRAS  mutations that confer resistance; on average, these turned up 5 months before imaging techniques showed that the tumours were progressing. The team was specifically looking for  KRAS  mutations, but Rosenfeld's group has used ctDNA to identify resistance mutations from a blind start. Last year, the researchers described how they had sequenced the complete exomes \u2014 the 1% of the genome that encodes protein \u2014 in blood samples from six people being treated for advanced breast, lung or ovarian cancers. In five cases, the unguided search revealed routes to resistance, such as mutations that prevent drugs from binding to their target proteins 12 . Spotting resistance early would let clinicians take patients off toxic and expensive drugs that are unlikely to keep working. And by identifying the mutations that underlie the resistance, they could find effective alternatives or drug combinations. \u201cThe hope is that we can turn cancer from a deadly disease into a chronic one,\u201d says Velculescu. \u201cYou treat someone with one therapy and when it stops working, you switch, or alternate back and forth.\u201d \n               Clinical caveats \n             Despite its promise, ctDNA is not yet ready for a starring role in the clinic. For one thing, the most sensitive techniques for detecting it, such as BEAMing, rely on some knowledge of which mutations to look for. This knowledge can be provided by taking a biopsy, sequencing its mutations, designing patient-specific molecular probes that target them, and using those probes to analyse later blood samples \u2014 a laborious approach that must be repeated for each patient. The alternative is to use exome sequencing, as Rosenfeld's team did. This requires no previous knowledge about the cancer, but it is prohibitively expensive to sequence and analyse every sample at the depth required to detect rare mutant fragments. Maximilian Diehn, a radiation oncologist at Stanford University in California, has tried to combine the best of both worlds. His team identified a small proportion of the genome \u2014 just 0.004% \u2014 that is repeatedly mutated in lung cancers 13 . Whenever the researchers get a new blood sample, they sequence this fraction 10,000 times over. This picks up even rare mutant fragments, and the focused approach keeps costs down. Because almost everyone with lung cancer has at least one mutation in these regions, the method should work in almost every patient, says Diehn. The team is now working to develop similar mutation panels for other types of cancer, and to validate the technique in clinical trials \u2014 work that could take several years. Like practically all ctDNA biopsy techniques, Diehn's approach does not do well at picking up early forms of cancer. In a small study 13 , it detected every lung cancer of stage II or higher, but only half of stage I tumours. This is understandable \u2014 advanced cancers simply discharge more DNA \u2014 but it limits ctDNA's potential as a cancer-screening tool. Diehn says that more-sensitive techniques could overcome this problem, but Diaz disagrees. \u201cThe limiting factor is biology,\u201d he says. \u201cThere just aren't a lot of fragments in circulation.\u201d And if ctDNA hints at the presence of an undetected cancer, what then? \u201cIf you detect a mutation in the circulation, you don't know where it's coming from,\u201d says Diaz. There are other unknowns, too. Does ctDNA paint a truly representative portrait of a cancer? Do tumours that have spread to other organs release as much DNA as the original tumours? Do all the cells in a tumour release as much ctDNA as each other? Diaz says that the only way to answer these questions is to do 'warm autopsies' \u2014 to take samples and characterize all of a person's tumours very soon after death, and compare them with ctDNA extracted in life. \u201cThis is the heavy lifting that'll need to be done in the field,\u201d he says. And the biggest question remains: does an accurate picture of tumour burden, or a real-time look at emerging mutations, actually save patients or improve their quality of life? Even if doctors discover that someone's tumour has developed a resistance mutation, that insight is useless if there are no drugs that target the mutation. \u201cThe limitation is the reality of targeted therapies,\u201d says Velculescu. \u201cYou get all this information \u2014 but so what? Our approaches to understanding cancer are outstripping our clinical options.\u201d Even if ctDNA does not yet affect outcomes, scientists say that it is an invaluable research tool, and clinicians are starting to collect it routinely. Swanton, for example, is leading a \u00a314-million (US$24-million) lung-cancer study called TRACERx (Tracking Cancer Evolution Through Therapy), which will use both conventional biopsies and ctDNA collected once every three months. The circulating DNA may or may not provide clues that help the study participants, but at the very least, it will give Swanton a much better understanding of how lung cancer evolves, and how to control that evolution. As Rosenfeld argues, it is better to have this information than not to. Currently, he says, \u201cwe're groping in the dark. Why would you do that if you have a tool that allows you to see what's happening?\u201d \n                     Cancer crossroads 2014-Apr-16 \n                   \n                     \u2018Pan-cancer\u2019 study unearths tumours\u2019 genetic trademarks 2013-Sep-26 \n                   \n                     Lists of cancer mutations awash with false positives 2013-Jun-17 \n                   \n                     Biopsy gives only a snapshot of tumour diversity 2012-Mar-07 \n                   \n                     Nature  Outlook: Cancer \n                   Reprints and Permissions"},
{"file_id": "511521a", "url": "https://www.nature.com/articles/511521a", "year": 2014, "authors": [{"name": "Richard A. Lovett"}], "parsed_as_year": "2006_or_before", "body": "As the United States destroys its old dams, species are streaming back into the unfettered rivers. Just outside the small town of Stabler in Washington, hydrologist Bengt Coffin surveys a mountain river that he helped to revive from a decades-long coma. Today, the clear waters of Trout Creek run fast and cool between banks covered in young alder trees. But just five years ago, an 8-metre-high concrete wall blocked the river at this site. The dam and the reservoir behind it had tamed the river and made it difficult for endangered steelhead trout ( Oncorhynchus mykiss ) to reach their spawning grounds upstream. In 2009, Coffin led the US Forest Service effort to remove the dam, and Trout Creek has since regained the look of a young river. Vegetation has covered the scars left by the dam and reservoir, and steelhead and other species have started to rebound. The revival of Trout Creek is part of a growing trend in the United States. About half of the nation's roughly 85,000 known dams no longer serve their intended purposes, and an increasing number are being removed. Around 1,150 have gone so far, mostly in the past 20 years, according to a tabulation by the watchdog group American Rivers in Washington DC. In an era when many countries are still building dams, the United States is taking them out. \u201cIt used to be a crazy idea. Now it's accepted,\u201d says Amy Kober, director of communications for American Rivers. Most of the demolished structures were lower than 5 metres, but in the past few years, projects in the Pacific Northwest have removed much taller ones. At the top end of the spectrum, the US National Park Service is dismantling the 64-metre-high Glines Canyon Dam, the largest of a pair of big dams on Washington's Elwha River. Many of the larger dams were removed because their operators decided that it was too costly to bring the old structures in line with modern safety and environmental requirements. Rick Lovett tells Nature\u2019s Noah Baker about the dam problem The power companies' actions are boons for fish advocates who seek to restore populations of endangered species in the rivers. The dam-elimination trend has also provided an unanticipated research opportunity, because the projects have used diverse approaches to minimize the damage caused by unleashing huge floods of water and decades of accumulated sediment. Some efforts take a slow path, restoring river flow over months or years. Others use explosives and other engineering techniques to drain reservoirs within hours. Data are still preliminary, but they suggest that both approaches can bring rapid benefits \u2014 not just to fish, but also to the habitat on which they depend. The rivers are rebounding at the sites studied so far, says Amy East, a geomorphologist with the US Geological Survey (USGS) in Santa Cruz, California. \u201cWe've seen a lot of resilience.\u201d \n               Out of commission \n             At Trout Creek, Coffin and his colleagues decided to take the cautious route when removing the ageing Hemlock Dam. Built in 1935, the structure provided power and irrigation for a nearby tree nursery that shut down in 1997. It had a fish ladder to allow animals to bypass the dam and swim upstream, but it was poorly built by modern standards and the number of fish using it had steadily declined. A bigger concern was the reservoir, which had been steadily filling in with silt. By the time the dam was dismantled, the reservoir had become so shallow that it was possible to wade all the way across, says Coffin, waving a hand at mid-thigh level to show the depth of the water. In the midsummer sun, temperatures in the water could reach 26 \u00b0C \u2014 too warm for steelhead, he says. When the Forest Service decided to remove the dam, it was particularly concerned about the mud, sand and gravel that had built up in the reservoir. Coffin and others worried that flooding the river with all that sediment would harm the steelhead below the dam in Trout Creek. \u201cAll of our baby fish are down there,\u201d Coffin says. \u201cWe didn't want to decimate them.\u201d The solution was to divert the river into a big pipe and then hire a fleet of dumper trucks to carry away the exposed sediment. In the process, the workers rediscovered the creek's original channel through the reservoir bottom and reinforced its banks with logs to stop them from eroding. All those efforts seem to have worked. When water was first allowed to flow back through the old reservoir bottom, it initially ran muddy. But just seven hours later, Coffin's team documented the first steelhead venturing into the new channel above the old dam site. \u201cIt was that clear,\u201d he says. Since then, the number of steelhead in the river and its tributaries has more than doubled, says fisheries biologist Patrick Connelly at the Columbia River Research Laboratory in Cook, Washington, although he notes that fish populations are variable enough that it will take several years to know whether the trend will continue. Returning steelhead are not the only signs of success. Just above the old dam site, Coffin winds his way through patches of alder trees that were planted after the dam was removed, then crosses a rocky beach to the river. The rounded stones range from the size of potatoes to loaves of bread, and make for tricky footing. But Coffin is thrilled to see them because none of these ankle-breakers was here when the dam was first taken out. \u201cAll of this washed in,\u201d he says. The cobbles provide nesting spots for the trout and a habitat for the insects that the fish eat. \u201cPeople pay attention to the big animals,\u201d Coffin says, \u201cbut the bugs are an important part of the system.\u201d Reaching into the water, he plucks out a couple of rocks, turns them over and points out six types of insect clinging to the underside, including caddisfly larvae and a stonefly. \u201cThe year after the dam was removed, these wouldn't have been here,\u201d he says with satisfaction. Elsewhere in the Pacific Northwest, teams opted for much more extreme measures to remove the 14-metre-tall Marmot Dam on Oregon's Sandy River in 2007 and the 38-metre-tall Condit Dam on Washington's White Salmon River in 2011. The dams, both nearly a century old, were too big to take the same approach as at Trout Creek, where it had cost nearly US$1 million to cart away 42,000 cubic metres of sediment. Marmot had nearly 20 times more sediment and Condit had double that of Marmot. Because it would be too expensive to dig out that material and carry it away, project managers opted for a more radical approach, colourfully described as \u201cblow and go\u201d, in which the dams were removed quickly, says Gordon Grant, a research hydrologist at the Forest Service's Pacific Northwest Research Station in Corvallis, Oregon. The results were impressive \u2014 but very different at the two sites. At Marmot, the sediment contained an equal mixture of sand and gravel. Once exposed to river action, it eroded out relatively quickly but sedately, with about half of it gone within 8 months. Researchers were surprised to find that the fish seemed little affected \u2014 the first curious salmon poked its nose back towards the former dam site within a day. At Condit, the sediment contained a higher proportion of fine-grained material: 35% mud, 60% sand and just 5% gravel. The result was predictable in retrospect, but nobody anticipated it. When engineers blew open a hole at the bottom of the dam, a jet of black liquid shot out as if from a giant fire hose. Instead of the expected flood of water, what came out was more like a mudflow, as waterlogged sediment from the reservoir slumped into the rapidly dropping water, then blasted downriver in a slurry that was as much as 28% sediment by volume. The reservoir lost its water and much of its sediment load in three hours. \u201cIt was almost like a volcanic event,\u201d says Jon Major, a geomorphologist at the USGS's Cascades Volcano Observatory in Vancouver, Washington. The 5-kilometre-long stretch of river between the dam and its confluence with the Columbia River temporarily became a muddy wasteland. With this kind of approach, says East, the slug of sediment wipes out everything, but the river can start recovering much sooner. The National Park Service took a much more conservative approach to removing two large dams on the Elwha River, because the stakes were higher. The upstream portions of the Elwha drain more than 100 kilometres of pristine habitat on the north side of Washington's Olympic National Park. A river that large produces a lot of sediment: an estimated 18 million cubic metres was expected to escape from behind the dams, says Jason Dunham, an aquatic ecologist at the USGS office in Corvallis. That is the equivalent of filling eight typical American-football stadiums. And before the dams cut the number of salmon returning each year to around 10,000, the Elwha supported hundreds of thousands of fish. Unwilling to risk the blow-and-go approach on both dams, engineers opted for a compromise. They quickly removed the lower, 32-metre-high Elwha Dam, which contained only about one-sixth of the total sediment. But the upstream Glines Canyon Dam, which is twice as big, is coming out in a series of steps that have so far lowered it to a 9-metre stub of its former self. East compares the method to deciding whether to uncover a wound quickly or gradually. The approach on the Elwha, she says, is like \u201cpulling the Band-Aid off slowly, over the course of three years\u201d. The good news in these giant projects is that scientists have not seen any serious harm from the feared releases of sediment. Instead, the rivers have proved unexpectedly efficient at flushing the worst of the mud downstream towards the sea, rather than letting it accumulate in river-choking mudflats. \u201cIt was not the big catastrophe people thought,\u201d East says. Emily Stanley, a river ecologist at the University of Wisconsin\u2013Madison who has studied dam removals for more than a decade, agrees that it is hard to think of one that had \u201ccatastrophically awful\u201d results. (The one exception, she says, was an event in the 1970s, when the demolition of a dam on the Hudson River allowed sediment containing high levels of toxic chemicals called polychlorinated biphenyls (PCBs) to escape from the reservoir and flow downstream.) Data on the recent dam removals suggest that the fish are now coming back to the unfettered rivers. At Condit, fish were seen returning within weeks of the explosion. Two years later, the total exceeded 5,500, including steelhead and spring Chinook ( Oncorhynchus tshawytscha ), which had been effectively extirpated from the river, says Jody Lando, a quantitative ecologist with Stillwater Sciences in Portland, Oregon, who reported her results in May at an aquatic-sciences meeting in Portland. Even on the Elwha, where the Glines Canyon Dam still impedes the river, East says that hundreds of salmon have been seen spawning in the lower dam's former lake bed. \u201cThat hasn't happened in over a hundred years,\u201d she says. In part, these successes may reflect the fact that the Pacific Northwest is a landscape built by geological disturbances \u2014 volcanic outbursts, landslides and floods. Local wildlife has had to adapt to such upheavals, and salmon do that by not always returning to the precise stream of their birth. \u201cThere's a fair amount that stray,\u201d says East. It is those strays that repopulate any previously inaccessible habitat. But other parts of the United States have also seen dramatic fish returns. On south-central Wisconsin's Baraboo River, the removal of a string of dams has allowed sturgeon to reach their former spawning grounds. And in New England, the destruction of two dams 7\u20139 metres high on Maine's Kennebec River and one of its tributaries has allowed Atlantic alewives ( Alosa pseudoharengus ) to repopulate 100 kilometres of previously blocked-off river. In 1999, before the first dam was taken out, no alewives were recorded in the upper part of the watershed, says Serena McClain, head of river restoration for American Rivers. By 2013, the annual run had rebounded to around 3 million. \n               Quake concerns \n             The next big structure destined for retirement is the 32-metre-tall San Clemente Dam on California's Carmel River. The 93-year-old dam, which was originally built to provide drinking water, is coming out because of concerns over its safety during an earthquake. And there are expensive homes that could be flooded if even modest amounts of sediment were to escape and raise the stream bed, so the dam-removal plan seeks to avoid that, says East. Instead, the $84-million project will cut a notch in a ridge near the upstream end of the reservoir, then divert the water into a nearby drainage that rejoins the original river downstream of the dam. \u201cIt's a major engineering feat,\u201d she says. Researchers say that the surge in large dam removals in the past ten years has offered valuable insight into how rivers and their ecosystems respond to letting the water flow freely. But because every river and dam is different, it is hard to draw simple lessons that will apply in all situations, says Jim Pizzuto, a fluvial geomorphologist at the University of Delaware in Newark. Still, the projects have shown that fish are remarkably adept at finding their way back. \u201cIf you un-build it, it seems like they will come back,\u201d says Grant. At least, that is the sense emerging from the limited data so far. Researchers are struggling to get detailed statistics on fish recovery \u2014 partly because removal projects tend to be planned according to engineering standards, not ones focused on fish and other river residents. And when fish assessments are done, they tend to be carried out by various state and federal agencies that share data only to a limited degree. \u201cA lot of studies wind up on someone's computer, somewhere,\u201d says McClain. But that may be changing because ecological considerations are increasingly part of dam-removal projects. A case in point is Maine's Penobscot River, where a $62-million public\u2013private partnership is buying dams and removing them to provide better access for fish to more than 1,600 kilometres of the river and its tributaries. For a country once so bent on taming rivers, attitudes are quickly evolving. At the site of the former Condit Dam, a couple pulls into the car park and walks to a spot overlooking the water. \u201cI come from a dam-building family,\u201d says the man. \u201cMy father used to build things like this down in California \u2014 the Feather River, the Rubicon, the Yuba. I helped.\u201d He pauses. \u201cA hundred years is a great thing, isn't it? Now we're busily employing people to undo what our ancestors screwed up.\u201d He stares silently for a moment at the ribbon of river, flecked with foam, 40 metres below. \u201cIt's a great thing.\u201d \n                     Water returns to arid Colorado River delta 2014-Mar-18 \n                   \n                     Fish return to undammed Elwha River 2012-Jul-05 \n                   \n                     Snapshot: Flooding the canyon 2008-Mar-12 \n                   \n                     Floods fail to save canyon beaches 2005-Nov-02 \n                   \n                     Grand Canyon: Open the floodgates! 2002-Nov-28 \n                   \n                     Penobscot River Restoration Trust \n                   \n                     Elwha River project \n                   \n                     Hemlock Dam \n                   \n                     Condit Dam removal \n                   \n                       Video of Marmot Dam removal \n                   Reprints and Permissions"},
{"file_id": "512020a", "url": "https://www.nature.com/articles/512020a", "year": 2014, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "The race is on to build a machine that can synthesize any organic compound. It could transform chemistry. In faded photographs from the 1960s, organic-chemistry laboratories look like an alchemist's paradise. Bottles of reagents line the shelves; glassware blooms from racks of wooden pegs; and scientists stoop over the bench as they busily build molecules. Fast-forward 50 years, and the scene has changed substantially. A lab in 2014 boasts a battery of fume cupboards and analytical instruments \u2014 and no one is smoking a pipe. But the essence of what researchers are doing is the same. Organic chemists typically plan their work on paper, sketching hexagons and carbon chains on page after page as they think through the sequence of reactions they will need to make a given molecule. Then they try to follow that sequence by hand \u2014 painstakingly mixing, filtering and distilling, stitching together molecules as if they were embroidering quilts. But a growing band of chemists is now trying to free the field from its artisanal roots by creating a device with the ability to fabricate any organic molecule automatically. \u201cI would consider it entirely feasible to build a synthesis machine which could make any one of a billion defined small molecules on demand,\u201d declares Richard Whitby, a chemist at the University of Southampton, UK. Mark Peplow discusses chemists\u2019 quest to create a machine that can synthesize any organic compound True, even a menu of one billion compounds would encompass just an infinitesimal fraction of the estimated 10 60  moderately sized carbon-based molecules that could possibly exist. But it would still be at least ten times the number of organic molecules that have ever been synthesized by humans. Such a device could thus offer an astonishing diversity of compounds for investigation by researchers developing drugs, agrochemicals or materials. \u201cA synthesis machine would be transformational,\u201d says Tim Jamison, a chemist at the Massachusetts Institute of Technology (MIT) in Cambridge. \u201cI can see challenges in every single area,\u201d he adds, \u201cbut I don't think it's impossible\u201d. A British project called Dial-a-Molecule is laying the groundwork. Led by Whitby, the \u00a3700,000 (US$1.2-million) project began in 2010 and currently runs until May 2015. So far, it has mostly focused on working out what components the machine would need, and building a collaboration of more than 450 researchers and 60 companies to help work on the idea. The hope, says Whitby, is that this launchpad will help team members to attract the long-term support they need to achieve the vision. Even if these efforts fall short, say project members, early work towards a synthesis machine could still transform chemistry. It could deliver a host of reactions that work as continuous processes, rather than one step at a time; algorithms that can predict the best way to knit a molecule together; and important advances in how computers tap vast storehouses of data about the reactivity and other properties of chemicals. Perhaps most importantly, it could trigger a cultural sea change by encouraging chemists to record and share many more data about the reactions they run every day. Some reckon it would take decades to develop an automated chemist as adept as a human \u2014 but a less capable, although still useful, device could be a lot closer. \u201cWith adequate funding, five years and we're done,\u201d says Bartosz Grzybowski, a chemist at Northwestern University in Evanston, Illinois, who has ambitious plans for a synthesis machine of his own. \n               Electric dreams \n             If chemists are to have any hope of building their dream device, they must pull together three key capabilities. First, the machine must be able to access a database of existing knowledge about how molecules can be built \u2014 which reactions create bonds between carbon atoms, for example, or whether using certain reagents to construct one part of a molecule risks damaging other parts. Second, it must be able to feed this knowledge into an algorithm that can map out synthetic steps, in much the same way that a master chess player plans a series of moves to win a game. And finally, it must be able to automatically carry out that sequence using real reagents inside a robotic reactor. The technology for that last step has progressed the farthest. Many labs already own dedicated machines for churning out strands of DNA or polypeptides, and in the past decade, adaptable robot chemists have become increasingly important in commercial pharmaceutical research. But existing machines have limited capabilities: a DNA or protein sequence builder is typically able to combine only a handful of molecular building blocks using fewer than half a dozen reactions. More versatile synthesis workstations are too expensive for most academic groups \u2014 costing from \u00a330,000 to more than \u00a3500,000 \u2014 and still tend to produce molecules with a narrow range of chemical properties. These workstations also do most of their reactions in the same batch-by-batch manner as humans. But some chemists are trying to develop continuous-flow synthesis, in which reactions occur as the chemicals move through the machine. This can improve speed and yields, and is a lot more amenable to automation. Jamison, for example, is working on flow chemistry at the Novartis\u2013MIT Center for Continuous Manufacturing in Cambridge, and he is part of a team that last year reported 1  the first end-to-end, completely continuous synthesis and formulation of a pharmaceutical: aliskiren hemifumarate, a treatment for high blood pressure. Jamison and his colleagues built a machine (now dismantled) that was more than 7 metres long, and about 2.5 metres high and deep. \u201cIt took four years of 'everything that can go wrong, will go wrong',\u201d says Bernhardt Trout, head of the MIT centre and leader of the project. After a lot of trial and error, he says, the researchers got to the point at which they merely had to flip the switch and feed in fresh drums of solvent and raw materials. The machine would hum like a large air-conditioning unit as stirrers whipped up chemicals, pumps whirred, filtration units dripped and squeezed, and a screw conveyer pushed solids through a 2-metre drying tube to be injection-moulded. Finally, after 14 operations and 47 hours, finished tablets dropped down a chute. Batch synthesis would have required 21 operations over 300 hours. Jamison reckons that there is enormous potential for reactions to be adapted to continuous flow: \u201cI think that it will be well over 50% eventually, maybe even 75%\u201d of all reactions, he says. Progress is accelerating, he adds, because fixing a problem in one step \u2014 solids clogging a pipe, say \u2014 can offer immediate improvements to other processes. \n               A chemical brain \n             Although automated machines are growing more versatile, teaching a computer to devise its own synthesis remains a massive problem, says Yuichi Tateno, an automation researcher at pharmaceutical company GlaxoSmithKline in Stevenage, UK, and a member of the Dial-a-Molecule collaboration. \u201cThe hardware has always been there, but the software and data have let it down,\u201d he says. Human chemists planning a synthesis tend to use a technique called retrosynthetic analysis. They draw the finished molecule and then pick it apart, erasing bonds that would be easy to form and leaving fragments of molecule that are stable or readily available. This allows them to identify the chemical jigsaw pieces they need as their raw materials, and to devise a strategy for connecting the pieces in the lab. If need be, they can seek inspiration from a commercial database such as SciFinder \u2014 an interface to the American Chemical Society's Chemical Abstracts Service \u2014 or its main rival Reaxys, offered by publishing giant Elsevier. Entering a molecular structure or a reaction into these databases yields examples in the literature. But even with online help, says Tateno, humans often fail at synthesis. \u201cWith the amount of chemistry that's out there, there's nobody who can know it all.\u201d The hope is that a synthesis machine could one day do much better, says Whitby, not least because computers are so much faster at scanning through terabytes of chemical data to find a specific reaction. The bigger challenge, he adds, is that computers have a much harder time figuring out whether that reaction will actually work in a synthesis, particularly if the target has never been made before. That problem bedevilled Elias Corey, a chemist at Harvard University in Cambridge, Massachusetts, who formalized the rules of retrosynthesis in the 1960s. The following decade, Corey created software called LHASA (Logic and Heuristics Applied to Synthetic Analysis), which could use these rules to suggest sequences of steps towards a synthesis 2 . But LHASA and its successors have never taken off, says Grzybowski: either the databases have included too few reactions and too many errors, or the algorithms have not properly assessed whether proposed reactions are compatible with all functional groups in the molecule. \u201cIf we could just make one chemical bond at a time, in isolation, chemistry would be trivial,\u201d he says. Grzybowski has spent the past decade building a system called Chematica to address those problems. He started by creating a searchable network of about 6 million organic compounds, connected by a similar number of reactions, drawn from one of the main databases behind Reaxys. His team then spent years cleaning up the data \u2014 identifying entries that lack crucial information about reagent compatibility or reaction conditions. Without that kind of clean-up, Chematica would be like a computer chef surveying a gigantic recipe book for dishes that use ice cream, stumbling on baked Alaska, and concluding that ice cream can withstand very high temperatures \u2014 missing the fact that cooking ice cream in an oven only works with an insulating shield of meringue. Chematica includes such crucial information, so its proposed syntheses of novel molecules \u2014 based on about 30,000 retrosynthetic rules \u2014 can be much more trustworthy. The team also designed Chematica to take a holistic view of synthesis: it not only hunts for the best reaction to use at each step, but also considers the efficiency of every possible synthetic route as a whole. This means that a poor yield in one step can be counterbalanced by a succession of high-yielding reactions elsewhere in the sequence. \u201cIn 5 seconds we can screen 2 billion possible synthetic routes,\u201d says Grzybowski. \n               Stronger, faster, cheaper \n             When Grzybowski first unveiled the network behind Chematica in 2005 (ref.  3 ), \u201cpeople said it was bullshit\u201d, he laughs. But that changed in 2012, when he and his team published a trio of landmark papers 4 , 5 , 6  showing Chematica in action. For example, the program discovered 4  a slew of 'one pot' syntheses in which reagents could be thrown into a vessel one after the other, without all the troublesome separation and purification of products after each step. The group tested Chematica's suggestions for making a range of quinolines \u2014 structures commonly found in drugs and dyes \u2014 and showed that many were more efficient than conventional approaches. Chematica can also look up information about the cost of starting materials and estimate the labour involved in each reaction, allowing it to predict the cheapest route to a particular molecule. When Grzybowski's lab tested 51 cut-price syntheses suggested by Chematica 5 , it collectively trimmed costs by more than 45%. These demonstrations have impressed synthetic chemists, although few have had a chance to test Chematica. That is because Grzybowski is hoping to commercialize the system: he is negotiating with Elsevier to incorporate the program into Reaxys, and is working with the pharmaceutical industry to test Chematica's synthesis suggestions for biologically active, naturally occurring molecules. Grzybowski is also bidding for a grant from the Polish government, worth up to 7 million z\u0142oty (US$2.3 million), to use Chematica as the brain of a synthesis machine that can prove itself by automatically planning and executing syntheses of at least three important drug molecules. Others are doubtful that will happen \u2014 at least any time soon. For the foreseeable future, \u201cthere will always be a significant need for human intervention\u201d, says Simon Tyler, commercial director of CatScI, a contract-research company in Cardiff, UK, that is involved in Dial-a-Molecule. \u201cWe won't have RoboCops wandering around in the lab.\u201d And as long as programmes like Chematica rely on databases of published studies, says Whitby, they will struggle to design reliable synthetic routes to unknown compounds. To build a synthesis machine, \u201cwe need to be able to predict when a reaction is going to work \u2014 but more importantly we need to be able to predict when it's going to fail\u201d. Unfortunately, those failures are rarely recorded in the literature. \u201cWe only publish the successes, a cleaned-up version of what happens in the lab,\u201d says Whitby. \u201cWe also lose a lot of information: what really was the temperature, what was the stirring speed, how much solvent did you use?\u201d One solution is to record those successes and failures using electronic laboratory notebooks (ELNs), computer systems for logging raw experimental data that are widely used in industry but still rare in academia (see  Nature   481 , 430\u2013431; 2012 ). \u201cA lot of people ask, 'Who reads all these data?' The point is that machines use them \u2014 they can search the data,\u201d explains Mat Todd, a chemist at the University of Sydney in Australia. In principle, automated workstations and instruments could send information to an ELN, which would upload the details to an open-access database where they could help a synthesis machine to predict how reliable a reaction might be. \u201cIf we really did know the history of every chemical reaction that had ever been done, we'd have amazing predictive capabilities,\u201d says Todd. Dial-a-Molecule researchers have coordinated trials of ELNs in academic labs; started to devise a standardized, machine-readable format for ELN records; and developed software that can push those data into open databases such as ChemSpider. Others in the network have developed prototype software called PatentEye, which could pull in extra data by scraping and cataloguing chemical information from patents. Many of those dreaming of a synthesis machine agree that widespread data harvesting will require a huge cultural shift. \u201cThat's absolutely the biggest barrier,\u201d says Todd. \u201cIn chemistry, we don't have that culture of sharing, and I think it's got to change.\u201d Money is also a significant hurdle. The expense of automated workstations means that few academics are familiar with them or their potential for capturing data. And with a large workforce of graduate students to draw on, academic labs often have little incentive to automate. Whitby is lobbying for a national centre that would host state-of-the-art automated synthesis equipment and software, to encourage their development and use. Until that materializes, he hopes that Dial-a-Molecule will inspire a new generation of chemists to embrace data sharing and automation. Grzybowski, for one, is convinced that the synthesis machine can become a reality: \u201cThe only thing that can kill it is scepticism.\u201d \n                     Chemistry\u2019s web of data expands 2012-Mar-27 \n                   \n                     Going paperless: The digital lab 2012-Jan-25 \n                   \n                     Science in the digital age 2010-Oct-13 \n                   \n                     Chemists spin a web of data 2008-May-07 \n                   \n                     Electronic notebooks: A new leaf 2005-Jul-06 \n                   \n                     Introducing robo-scientist 2004-Jan-15 \n                   \n                     Nature  special: Chemists\u2019 choice 2014 \n                   \n                     Dial-a-Molecule \n                   \n                     Bartosz Grzybowski \n                   \n                     Novartis-MIT Center for Continuous Manufacturing \n                   Reprints and Permissions"},
{"file_id": "indirect-costs-keeping-the-lights-on-1.16376", "url": "https://www.nature.com/news/indirect-costs-keeping-the-lights-on-1.16376", "year": 2014, "authors": [], "parsed_as_year": "2011_2015", "body": "Last year, Stanford University in California received US$358 million in biomedical-research funding from the US National Institutes of Health (NIH). Much of that money paid directly for the cutting-edge projects that make Stanford one of the top winners of NIH grants. But for every dollar that Stanford received for science, 31 cents went to pay for the less sexy side of research: about 15 cents for administrative support; 7 cents to operate and maintain facilities; 1 cent for equipment; and 2 cents for libraries, among other costs. The NIH doled out more than $5.7 billion in 2013 to cover these \u2018indirect\u2019 costs of doing research \u2014 about one-quarter of its $22.5-billion outlay to institutions around the world (see \u2018 Critical calculations \u2019). That money has not been distributed evenly, however: research institutions negotiate individual rates with government authorities, a practice that is meant to compensate for the varying costs of doing business in different cities and different states. Data obtained by  Nature  through a Freedom of Information Act request reveal the disparities in the outcomes of these negotiations: the rates range from 20% to 85% at universities, and have an even wider spread at hospitals and non-profit research institutes (see  interactive graphic ,  data for all institutes  and  methods used ). The highest negotiated rate in 2013, according to the data, was 103% \u2014 for the Boston Biomedical Research Institute (BBRI) in Watertown, Massachusetts. Under financial duress, it closed its doors that same year. Faculty members often chafe at high overheads, because they see them as eating up a portion of the NIH budget that could be spent on research. And lack of transparency about how the money is spent can raise suspicions. \u201cSometimes faculty feel like they\u2019re at the end of the Colorado River,\u201d says Joel Norris, a climatologist at the University of California, San Diego. \u201cAnd all the water\u2019s been diverted before it gets to them.\u201d Nature  compared the negotiated rates, as provided by the US Department of Health and Human Services, to the actual awards given to more than 600 hospitals, non-profit research institutions and universities listed in RePORTER, a public database of NIH funding (see \u2018 Overheads under the microscope \u2019). The analysis shows that institutions often receive much less than what they have negotiated, thanks to numerous restrictions placed on what and how much they can claim. Administrators say that these conditions make it difficult to recoup the cash they spend on infrastructure. In addition, new administrative regulations have meant that universities have had to increase their spending, even as federal and state funding for research has diminished. \u201cWe lose money on every piece of research that we do,\u201d says Maria Zuber, vice-president for research at the Massachusetts Institute of Technology (MIT) in Cambridge, which has negotiated a rate of 56%. But many worry that the negotiation process allows universities to lavish money on new buildings and bloated administrations. \u201cThe current system is perverse,\u201d says Richard Vedder, an economist at Ohio University in Athens who studies university financing. \u201cThere is a tendency to promote wasteful spending.\u201d Reimbursement for overheads is dealt with differently around the world. The United Kingdom calculates indirect costs on a per-project basis. Japan has a flat rate of 30%. And last year, to the dismay of some institutions, the European Union announced that it would no longer negotiate rates and instituted a flat rate of 25% for all grant recipients in its Horizon 2020 funding programme (see  Nature  499,  18\u201319; 2013 ). The comparatively high overhead reimbursement in the United States has generated envy, and at times controversy. About 20 years ago, government auditors found that Stanford was using funds for indirect costs to cover the depreciation in value of its 22-metre yacht moored in San Francisco Bay, and to buy decorations for the president\u2019s house, including a $1,200 chest of drawers. Other universities \u2014 including MIT and Harvard University in Cambridge \u2014 soon came forward to correct overhead claims that they feared would be perceived as inappropriate. In the end, Stanford paid the government $1.2\u00a0million and accepted a large reduction \u2014 from 70% to 55.5% \u2014 in its negotiated rate. But the damage was done. The government layered on new regulations, including an explicit ban on reimbursement for housing and personal living expenses, and a 26% cap on administrative costs, although only for universities. Two decades later, researchers still worry that the system carries the taint of impropriety. Administrators say that changes at some institutions \u2014 such as increased transparency about spending and how indirect costs are calculated \u2014 have allayed faculty concerns. But not everywhere. \u201cPeople often think this is about secretarial staff and bloating the mid-level research administration,\u201d says Tobin Smith, vice-president for policy at the Association of American Universities in Washington DC. \u201cThe faculty doesn\u2019t often think about all the other costs: the lights are on, the heat is on, you\u2019re using online services the university provides.\u201d Despite the high level of scrutiny for universities, they did not top the chart for negotiated rates in the data that  Nature  collected. Few universities have rates above 70%, and they would probably face an outcry from faculty if they raised rates too high, says Samuel Traina, vice-chancellor for research at the University of California, Merced. No such threshold seems to exist at non-profit research institutes: more than one-quarter of the 198 institutes for which  Nature  obtained data negotiated rates above 70%. Fourteen of them have rates of 90% or higher, meaning that their indirect costs come close to equalling their direct research funding. According to Robert Forrester, an independent consultant in Belmont, Massachusetts, who helps institutions to determine their indirect costs, these institutes need to negotiate higher rates because the entire facility is dedicated to research, whereas universities and hospitals also use facilities for other things, such as teaching, that generate funding and must share the burden. Comparisons of negotiated rates against the RePORTER data mined by  Nature  come with caveats. For example, many smaller institutions negotiate a provisional rate with the NIH that is later adjusted to match actual overhead costs, so some grants in RePORTER seem to have a reimbursed rate that exceeds the negotiated value. A change to the negotiated rate in the middle of a year can also cause a disconnect between the data  Nature  obtained and the rates given in RePORTER. But overall, the data support administrators\u2019 assertions that their actual recovery of indirect costs often falls well below their negotiated rates. Overall, the average negotiated rate is 53%, and the average reimbursed rate is 34%.interactive The shortfall is largely due to caps imposed by the NIH on some grants and expenditures, says Tony DeCrappeo, president of the Council on Governmental Relations (COGR), an association in Washington DC that is focused on university finance. Some training grants, such as \u2018K\u2019 awards for early-career investigators, cap indirect costs at 8%. The NIH also does not award money for conference grants, fellowships or construction. And it has placed limits on specific categories, such as costs associated with research using genomic microarrays. Such restrictions can make it hard to make ends meet, says Eaton Lattman, who heads the Hauptman-Woodward Medical Research Institute in Buffalo, New York. The institute negotiated a rate of 94%, but received just 52%. Although it does not incur some of the costly administrative burdens of hospitals or universities, it still fails to recoup its full investment on research, Lattman says. The increasing competition for NIH grants is a major factor in that. Because funds used to support researchers who lose grants or have yet to win one cannot be reimbursed as indirect costs, Hauptman-Woodward must draw from its endowment to keep them working until they can support themselves. \u201cIf you don\u2019t want to kill their research career, you have to provide bridge funding,\u201d Lattman says. The BBRI faced similar strains. The institute was dependent on NIH funding, and could not cope when the NIH budget tightened and faculty members brought in less grant money (see  Nature  491,  510; 2012 ). \u201cThe general cost of operating the organization did not diminish as fast as the direct dollars,\u201d says Charles Emerson, former head of the institute and now a developmental biologist at the University of Massachusetts Medical School in Worcester. \u201cSo we were able to negotiate a higher rate at the end of our time there, just to keep the operation going.\u201d By 2012, the BBRI\u2019s negotiated rate had swelled to 103%, the highest for any organization in the data provided to  Nature . But it ended up recouping just 70%, or $2.4 million on $3.4\u00a0million in direct funding. Although non-profit institutes command high rates, together they got just $611\u00a0million of the NIH\u2019s money for indirect costs. The higher-learning institutes for which  Nature  obtained data received $3.9 billion, with more than $1\u00a0billion of that going to just nine institutions, including Johns Hopkins University in Baltimore, Maryland, and Stanford (see \u2018 Top 10 earners \u2019). At 38%, the average rate for these nine institutions is about 4% higher than that for all institutions with available data. But the range for higher-learning institutions was wide, with one receiving 62% (York College in Jamaica, New York), and one receiving just under 3% (Dillard University in New Orleans, Louisiana). Even if universities did receive the full, negotiated rate, it would still be less than the actual costs of supporting research, says DeCrappeo. The cap on administrative costs that emerged in the wake of the Stanford scandal has remained unchanged even though administrative burdens have swelled. COGR members maintain that their actual costs are about 5% higher than the cap, says DeCrappeo. The rest of the money must come from other revenue, such as tuition fees, donations and endowments. The best solution, according to Barry Bozeman, who studies technology policy at Arizona State University in Phoenix, is not to raise the cap, but to cut costs by getting rid of administrative rules and regulations that are simply wasting time and money. \u201cThe research bureaucracy has inflated wildly in universities and it is expensive.\u201d That inflation, he says, is evident in grant applications. Thirty years ago, administrative requirements associated with grants were relatively low. \u201cNowadays, the actual content of the proposal \u2014 what people are going to do and why it\u2019s important \u2014 is always a small fraction of what they submit,\u201d he says. As an illustration of the growing bureaucracy, DeCrappeo says that when the COGR began to keep a guide to regulatory requirements for its members in 1989, the document was 20 pages long. Now it is 127\u00a0pages. And Bozeman says that he has to fill out forms relating to the care of laboratory animals when he applies for grants, even though he has never used animals. The regulatory burden can be particularly high for medical schools, which must adhere to regulations for human-subject research, privacy protection and financial conflicts of interest, among others. The Association of American Medical Colleges in Washington DC says that 70 of its members have spent $22.6\u00a0million implementing conflicts-of-interest reporting guidelines that came into effect this year. Other funders place strict limits on their reimbursements. The US Department of Agriculture, for example, caps many of its reimbursements at 30%. Many philanthropic organizations do not reimburse for overheads at all, and those that do often pay less than the government rate (see  Nature  504,  343; 2013 ). As a result, some institutions are reluctant to allow researchers to apply for such grants \u2014 providing another source of friction between faculty members and the administration. Tight budgets and fierce competition for federal grants mean that faculty members are keenly sensitive to anything that might affect how much money they receive,says Lattman. Recipients of grants from the National Science Foundation (NSF) are particularly rankled, he says, because the NSF allocates money for indirect costs \u2014 at the federal negotiated rate \u2014 from the total grant awarded. In other words, researchers told that they will receive a $1-million NSF grant might see only 60% of the money. The NIH, by contrast, typically gives faculty members the full $1 million and then reimburses indirect costs in a separate payment to the university. Even so, would-be NIH grant recipients often fear that a high indirect-cost rate at their institution will hurt their chances of getting a grant funded, despite the lack of evidence supporting any such trend. Others are troubled by the lack of transparency at many institutions as to how the indirect costs are calculated and the funds distributed. Because indirect-cost revenue is considered a reimbursement for money the university has already spent, much of the cash received from the government disappears into a university\u2019s general fund. \u201cFaculty have always been somewhat in the dark,\u201d says Edward Yelin, who studies health policy at the University of California, San Francisco. Although the payout for indirect costs is high, officials at the NIH say that the proportion of the NIH budget dedicated to overheads has held steady for more than two decades. When a 2013 report by the US Government Accountability Office warned that indirect costs could begin to eat up an increasing proportion of the NIH\u2019s research budget, the NIH countered that this was unlikely. DeCrappeo is hopeful that regulations due to come into effect in December will rein in the proliferation of caps on indirect cost rates. The regulations will require officers at agencies such as the NIH to have any new caps on overhead reimbursement approved by the head of the agency and provide a public justification for the change. DeCrappeo says that this could lead to a more transparent process. And for those who fret about where this money is going, DeCrappeo urges them to look beyond their own research programmes. \u201cIf all you\u2019re concerned about is the direct costs, it won\u2019t take long for your facilities to deteriorate,\u201d he says. \u201cYou can\u2019t do research on the quad.\u201d"},
{"file_id": "513024a", "url": "https://www.nature.com/articles/513024a", "year": 2014, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "In the haze of incomplete data, scientists are divided over the risks and benefits of electronic cigarettes. In many respects, the modern electronic cigarette is not so different from its leaf-and-paper predecessor. Take a drag from the mouthpiece and you get a genuine nicotine fix \u2014 albeit from a fluid wicked into the chamber of a battery-powered atomizer and vaporized by a heating element. Users exhale a half-convincing cloud of \u2018smoke\u2019, and many e-cigarettes even sport an LED at the tip that glows blue, green or classic red to better simulate the experience romanticized by countless writers and film-makers. The only things missing are the dozens of cancer-causing chemicals found in this digital wonder\u2019s analogue forebears. E-cigarettes \u2014 also known as personal vaporizers or electronic nicotine-delivery systems among other names \u2014 are perhaps the most disruptive devices that public-health researchers working on tobacco control have ever faced. To some, they promise to snuff out a behaviour responsible for around 100\u00a0million deaths in the twentieth century. Others fear that they could perpetuate the habit, and undo decades of work. Now, a group once united against a common enemy is divided. \u201cThese devices have really polarized the tobacco-control community,\u201d says Michael Siegel, a physician and tobacco researcher at Boston University School of Public Health in Massachusetts. \u201cYou now have two completely opposite extremes with almost no common ground between them.\u201d Evidence is in short supply on both sides. Even when studies do appear, they are often furiously debated. And it is not just researchers who are attempting to catch up with the products now pouring out of Chinese factories: conventional tobacco companies are pushing into the nascent industry, and regulators are scrambling to work out what to do. Some countries, such as Singapore and Brazil, have banned the products entirely. The US Food and Drug Administration has proposed to bring them under its control alongside tobacco \u2014 but the path to regulation has been beset by lawsuits and delays. In May, the European Union finalized a major revision to the rules governing tobacco products in its member states. These include standards for e-cigarette products and restrictions on advertising, but the updated rules will take years to come into effect. On 26 August, the World Health Organization (WHO)  released a report  that recommended, among other things, to restrict the indoor use of e-cigarettes, to ban certain flavours and to confine sales to those who are 18 years and older. The report will be debated at a meeting in October to decide how the products are treated under the international Framework Convention on Tobacco Control, which commits governments to regulating tobacco and trying to reduce its impact on health. The open questions include exactly what is in many commercially available products and what health effects they might have. But researchers are also concerned with whether e-cigarette users will give up conventional smoking, or simply become \u2018dual users\u2019. Could e-cigarettes even act as a gateway, increasing tobacco use? Siegel says that it is obvious what data and experiments are needed, but it is not guaranteed that anyone will agree about the results. \u201cIt\u2019s not clear to me that science is going to end this,\u201d he says. \n               Market conflagration \n             Devices for taking the smoke out of smoking have been around for years, but most have failed to gain traction or, like prescription nicotine inhalers, are restricted in their use. A Chinese inventor named Hon Lik is widely credited for developing the modern e-cigarette, about a decade ago. The Shenzhen-based company he worked for, now called Ruyan, commercialized the invention and has been joined by scores of competitors. According to a study 1  from the University of California, San Diego, there were 288\u00a0brands of e-cigarette available online in 2012, many with multiple products. By January 2014, there were 466, meaning that an average of more than 10 brands had been launched every month. Buyers have clearly been snapping them up: from a standing start a few years ago, the United Kingdom alone is now estimated to have more than 2\u00a0million users. This explosive growth has blind-sided scientists and regulators alike. \u201cI\u2019m personally astounded by how quickly the market has grown,\u201d says Wilson Compton, deputy director of the US National Institute on Drug Addiction in Bethesda, Maryland. Further complicating the picture is the remarkably fast evolution of the devices themselves. Early models that resemble cigarettes \u2014 \u2018cigalikes\u2019 \u2014 have been joined by customizable vaporizers costing hundreds of dollars and sporting everything from gold plating to software that lets users tweak how the devices operate. In response, researchers have radically scaled up their efforts to provide regulators with guidance. E-cigarettes promise to drastically reduce the death toll from smoking \u2014 without depriving users of the nicotine they crave. (A phrase often quoted in tobacco-control circles is that people \u2018smoke for the nicotine but die from the smoke\u2019.) But on the central question \u2014 are e-cigarettes safe? \u2014 there are many uncertainties. Long-term consumption of nicotine divorced from tobacco is thought to be relatively safe for most people, barring pregnancy or certain rare conditions. But nicotine is not danger-free. There have already been overdoses from people drinking the liquid from e-cigarettes, or spilling it on their skin, where it is absorbed. Also unknown are the long-term effects of regularly inhaling prop\u00adylene glycol, the chemical that makes up most of the liquid vaporized in e-cigarettes. This organic molecule is used in scores of commercial applications ranging from food to plastics, and it has been shown to be safe to consume except at very high levels. Some evidence from the theatre \u2014 where it is used to create fogs and mists \u2014 suggests that it may irritate the respiratory system, but there are no long-term data about the effects of inhalation. Many e-cigarettes contain other chemicals added for flavouring, and little is known about these. There are also legitimate fears about quality standards for the products: toxic contaminants have been found, and in a very few cases batteries have exploded, leading to injury. Around the world, researchers are now subjecting e-cigarettes to the same kinds of tests used to shed light on how conventional cigarettes damage human health. Some have found 2  genetic changes to human bronchial cells grown  in vitro  in a medium exposed to e-cigarette vapour (see  Nature 508, 159; 2014 ). These looked similar to changes induced by conventional tobacco smoke. Another study found 3  that e-cigarette use, like normal cigarette smoking, led to a reduction in exhaled nitric oxide, which could be a sign that e-cigarettes alter lung function. But this work is early and still inconclusive. Those who are positive about the potential benefits of e-cigarettes say that although their safety clearly needs to be monitored and further investigated, there is simply no way they can be as dangerous as conventional cigarettes. \u201cThe key comparison here is to smoking,\u201d says Lynne Dawkins, head of the drugs and addictive behaviours research group at the University of East London, UK. Dawkins says that the lower risks of e-cigarettes and the fact that many users believe they are an acceptable substitute for tobacco makes them generally a good thing. (Some of Dawkins\u2019s research has been funded by e-cigarette companies.) \n               Snuff it out \n             Dawkins and others are optimistic that beyond being a safer substitute, e-cigarettes could help people to stop smoking. But in many of the jurisdictions where they are taking off, e-cigarettes cannot be sold as smoking-cessation aids. In the United Kingdom, for example, that would require them to be licensed as medicine. The United States also bans direct claims about helping people to quit, but some brands circumvent this with testimonials from users or other implied messages about the devices\u2019 benefits. So far there is a lot of anecdote but only a little hard evidence. One of the few randomized controlled trials on e-cigarettes comes from Christopher Bullen, who studies tobacco control at the University of Auckland in New Zealand. His study, published last year 4 , found that an early e-cigarette model was roughly as effective as nicotine patches at helping smokers to quit. But critics have cited weaknesses such as problems monitoring the actual use of devices and differences in how study participants obtained them. Participants may have had to go to more effort, for example, to obtain patches than to get e-cigarettes. In the absence of further controlled trials, researchers have scoured the Internet for data and conducted surveys of smokers. Dawkins and her team have found 5  that many people report using e-cigarettes for smoking cessation, and that these users had a longer \u2018time to first vape\u2019 in the morning than smokers had to their first cigarette, possibly suggesting reduced dependence on nicotine. But opponents of e-cigarettes have their own ammunition. One study published this year 6  followed 949 smokers reporting their habits online, and found that the e-cigarette users were no more likely to quit tobacco than other smokers. Dawkins and other e-cigarette defenders counter that because the devices may appeal to the smokers who are most heavily dependent on tobacco, results such as this do not actually shed light on the question (see  Naturehttp://doi.org/t3f;2014 ). One problem with using e-cigarettes for smoking cessation may be that at the moment most are probably less effective at delivering nicotine than conventional smoked tobacco, says Peter Hajek, a tobacco researcher at Queen Mary University of London. \u201cI think they need about five years, if the regulators don\u2019t kill them, to become as good as cigarettes in providing smokers with what they want.\u201d This, he says, could ultimately render normal cigarettes obsolete. But in many ways, those in favour of stricter controls on the devices are worried about giving up any ground in the fight against tobacco. As smoking becomes more difficult \u2014 for example, through restrictions on where smokers can light up \u2014 e-cigarettes may be used alongside conventional tobacco to maintain nicotine levels. Such dual use could undermine efforts to stop smoking entirely. And although dual users may consume fewer cigarettes than heavy smokers, which would reduce their risk of cancer to some extent, even very low levels of smoking seem to elevate risks of cardiovascular problems. Those who worry that e-cigarettes will do more harm than good also fret that they could make tobacco socially acceptable again. With many developed nations implementing heavy restrictions on advertising, as well as high taxes and medical warnings, tobacco consumption has been massively stigmatized. Now e-cigarettes \u2014 which are in many cases unregulated \u2014 threaten to disturb this status quo. One of the opponents\u2019 greatest fears is that e-cigarettes will help to attract young people to tobacco. The US Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia, has found 7  that in 2012, around 1.78 million adolescents in the United States had used e-cigarettes, and that a little less than 10% of those had never previously tried conventional cigarettes. When those figures were released last year, CDC director Tom Frieden \u2014 who headed several anti-smoking initiatives in a previous role as New York City\u2019s health commissioner \u2014 said that \u201cthe increased use of e-cigarettes by teens is deeply troubling\u201d. And he warned: \u201cMany teens who start with e-cigarettes may be condemned to struggling with a lifelong addiction to nicotine and conventional cigarettes.\u201d But teenagers often experiment, and it may be that this is all that these data show. Advocates of the devices say that if they were going to cause increases in smoking, then smoking rates would already be going up, given the number of people using e-cigarettes. This does not seem to have happened yet \u2014 in developed nations, smoking rates are generally decreasing. \n               Young and vulnerable \n             A contentious paper 8  on this subject, and one that exemplifies the debate, comes from Stanton Glantz, director of the Center for Tobacco Control Research and Education at the University of California, San Francisco, who has spent years fighting tobacco and the industry that produces it. In March, Glantz and his colleague Lauren Dutra analysed a survey of US adolescents and found that those who used e-cigarettes were more likely than others to smoke conventional cigarettes. They wrote that \u201cin combination with the observations that e-cigarette users are heavier smokers and less likely to have stopped smoking cigarettes, these results suggest that e-cigarette use is aggravating rather than ameliorating the tobacco epidemic among youths\u201d. The paper drew strong criticisms for conflating correlation and causation. \u201cThese researchers are drawing conclusions that aren\u2019t justified by the data,\u201d says Siegel. Although there is clearly a correlation between heavy smoking and e-cigarettes, he says, it is not clear whether e-cigarettes are leading to smoking, or the other way around. Glantz says that much of the ire directed at the paper is the result of the word \u2018gateway\u2019 being used in a press release, which he was unhappy with. He maintains that the data in the paper back the conclusion. Overall, Glantz says, \u201cproperly regulated and available on prescription\u201d, e-cigarettes might be a good thing, but they are currently increasing the number of children using nicotine, and promoting cigarette-smoking among children. Parties on both sides of the debate had been petitioning the WHO even before it took its firm stance against the devices in August. In a 26 May letter to WHO head Margaret Chan, leading researchers including Dawkins, Bullen and Hajek argued that tough regulation would be counterproductive and would serve only to protect the conventional cigarette market. Harm-reduction approaches, they say, seem to have been \u201coverlooked or even purposefully marginalized\u201d. Another group of equally eminent scientists \u2014 including Glantz \u2014 fired back in June, saying that there is insufficient evidence to show that e-cigarettes are useful for smoking cessation, that there is good evidence that they release toxic compounds, and that letting e-cigarettes go largely unregulated could once again allow tobacco companies the opportunity to influence policy. Big tobacco is moving into the market with gusto. Leading US brand Blu \u2014 which Reynolds American, maker of Camel cigarettes, agreed to sell to rival Imperial Tobacco in July \u2014 has cornered about half of the US market by some estimates. Reynolds has kept hold of the popular VUSE brand. Altria, which is famous for the Marlboro cigarette brand, has its own MarkTen e-cigarette. Jason Hughes, a tobacco researcher and head of the department of sociology at the University of Leicester, UK, notes that although e-cigarettes are often seen as something totally new, they may actually be just one more in a long line of attempts to make tobacco consumption more \u2018civilized\u2019, from chewing tobacco to cigarettes to cigarettes with filters. But they also represent a break point: although the nicotine in them is derived from plants, the users are now divorced from tobacco leaves completely. Determining whether this break is truly a good thing becomes crucial when \u2014 despite continuous and graphic warnings of the risks of smoking \u2014 millions still put their lives at risk for a nicotine hit. Population studies to work out the true effects of this new technology are crucial, says Compton. There is one thing that all researchers agree on: while they debate, e-cigarette use grows and grows. Whatever researchers think, says Compton, \u201cThe public is clearly voting with their feet.\u201d See World View:  Allow use of electronic cigarettes to assess risk \n                     Allow use of electronic cigarettes to assess risk 2014-Aug-26 \n                   \n                     E-cigarettes affect cells 2014-Apr-08 \n                   \n                     Electronic cigarettes \u2018don\u2019t aid quitting\u2019, study says 2014-Mar-24 \n                   \n                     Regulation stacks up for e-cigarettes 2013-Sep-25 \n                   \n                     Smoking stays in your genes after you quit 2007-Aug-30 \n                   \n                     WHO tobacco-free initiative \n                   \n                     WHO report on e-cigarettes (PDF) \n                   Reprints and Permissions"},
{"file_id": "513020a", "url": "https://www.nature.com/articles/513020a", "year": 2014, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Sometimes, the brightest stars in science decide to leave.  Nature  finds out where they go. When Soroosh Shambayati left his organic-chemistry lab, he didn't leave chemical synthesis behind. As a chemist PhD turned investment banker, he started working in the derivatives market in the 1990s. The transactions involved arranging a complex series of trades in a precise order, and it reminded him of synthesizing an organic compound, reaction by reaction. As a graduate student, Shambayati had excelled at synthesis, just as he did at everything he turned his hand to. He was \u201cother-worldly brilliant\u201d, says his former adviser Stuart Schreiber. He juggled three distinct projects during his PhD, one in organic synthesis, one in theoretical physical chemistry and a third in biochemistry and immunology. He was also calm, thoughtful and well read: his bookshelf spans science philosophy, evolutionary biology and physics. Schreiber, a biochemist at the Broad Institute in Cambridge, Massachusetts, knew that if Shambayati wanted to become an academic scientist, he was sure to succeed. \u201cIt was very clear to me that he was going to become a star,\u201d he says. But Shambayati chose the financial world \u2014 and excelled there instead: he is now chief executive at Guggenheim Investment Advisors (Suisse) in Geneva, Switzerland, a firm that manages billions of dollars for wealthy families and foundations. Shambayati is among the hundreds of thousands of scientists who train in academia but then leave to follow a different career. According to the latest survey of doctorate recipients conducted by the US National Science Foundation, nearly one-fifth of employed people with science and engineering PhDs were no longer working in science in 2010. This is partly due to a lack of room at the top. In the United States, the number of PhDs entering the workforce has skyrocketed but the number of stable academic jobs has not. In 1973, nearly 90% of US PhDs working in academia held full-time faculty positions, compared with about 75% in 2010. A common perception is that the weaker science students are forced out of a competitive field, leaving the brightest stars to secure the desirable academic positions. But as Shambayati's story shows \u2014 and as most mentors know \u2014 this is not the full picture: sometimes the scientists who move on are the ones with the most promise. Their motivations are diverse: some want more money, or more time with family; others are lured by opportunities elsewhere. To get a better sense of why talented scientists are leaving academia and how their training influences their lives,  Nature  contacted group leaders recognized for mentoring and asked: \u201cWho was the one who got away?\u201d \n               From chemist to capitalist \n             Shambayati was born in Iran, attended school in Sweden, and then won a scholarship to study chemistry and mathematics at a university in Los Angeles. As an undergraduate, he was drawn to science for its pursuit of objective truth and the opportunity for discovery. A PhD was the obvious next step, and he found a perfect fit in Schreiber's lab in the late 1980s. \u201cWhen I met Stuart, it was almost a sense of meeting the da Vinci of what I had in my head as science,\u201d Shambayati says. At the time, the lab was focused on synthetic organic chemistry, but Schreiber also took risks \u2014 such as branching into biology \u2014 which meant that Shambayati could pursue his broad, three-pronged PhD. The realities of doing science, however, soon butted heads with Shambayati's idyllic view of it. He found that chemical synthesis was slow and full of setbacks \u2014 \u201ca bit like banging your head against the wall for long periods of time\u201d, he says \u2014 and he was put off by the political aspects of science, exemplified at the time by bickering over who discovered HIV. Still, he did not hesitate to apply for faculty jobs at several top universities while finishing his PhD, and he received more than one offer. While in New York for a job interview at Columbia University, Shambayati met up with a friend in banking, who was shocked to learn how little an assistant professor earned. He encouraged Shambayati to move into the financial world instead. \u201cI said 'you're nuts',\u201d Shambayati remembers. \u201cI know nothing about banks or banking. Why would anybody want to interview me?\u201d But a good salary was tempting to Shambayati, who felt a deep obligation to support his family; his parents had fled Iran after the 1979 revolution, leaving their house and savings behind. Shambayati set up an interview with his friend's bosses at Banker's Trust, which was later bought by Deutsche Bank. The investment bank was a leader in derivatives trading and was looking for quantitative, analytical thinkers such as Shambayati. He accepted a job earning many multiples of an academic salary, figuring that he could always go back to do a postdoc if things did not work out. They did. Finance was an eye-opener for Shambayati, who worked on chaotic emerging markets, losing and making back tens of millions of dollars in a day. He found the trading floor, surrounded by his colleagues, not unlike his chemistry lab, but with \u201ceven less privacy\u201d, he says. His career progressed quickly and he moved on to jobs at Goldman Sachs, Citigroup and then Lehman Brothers. (He was there in 2008 when the firm abruptly went into bankruptcy, catalysing the global economic crisis \u2014 an experience he compares to \u201cbeing in a plane crash\u201d.) Schreiber never questioned Shambayati's decision to leave science. He works hard not to presume that his best students will follow in his footsteps, he says. And Shambayati credits some of his success to the influence of his former mentor's approach to science, based on calculated risks, hard work and creativity. \u201cI don't think I'm the most natural banker or financial thinker, but I know that I have a certain amount of intellectual ability that I can utilize, if I work very hard,\u201d he says. \u201cThat was very much informed by the way Stuart operates.\u201d \n               From physics to cyberspace \n             Sometimes, the decision to leave science is partly push, partly pull. That was the case for Renata Sarno, who after eight years in theoretical physics ran up against a dearth of academic jobs in her native Italy. Then the World Wide Web happened. Sarno started an online business \u2014 one of Italy's first \u2014 that would eventually sell for hundreds of millions of euros. \u201cShe was a very brilliant student,\u201d remembers her supervisor Giorgio Parisi, a theoretical physicist at the University of Rome. She could comprehend problems posed in theoretical physics and then determine how a computer might tackle the challenge. Sarno came to Parisi's lab to finish her undergraduate thesis in mathematical physics in 1987, and continued to work with him through a PhD and postdoc position. She helped to build a supercomputer, one of the world's fastest at the time, then used it to model subatomic particles called fermions using lattice gauge theory, which divides continuous space-time into series of discrete points. She was inspired by Parisi's diverse interests, such as protein folding and neural networking, as well as his desire to tackle new computational problems in particle physics. An academic life seemed ideal to Sarno, and Parisi thought that she would make an excellent group leader. But when Sarno's postdoc funding ran out in 1994, she was unable to find more money, and there were few job opportunities for those starting out in science. Women were, and are, exceedingly rare at the highest levels of physics in Italy, and she also felt that discrimination held her back. But there were opportunities opening up elsewhere. A year earlier, the European particle-physics lab CERN had made the World Wide Web public, and Sarno saw a chance for people with a background in computer science. \u201cI found myself without a salary and a big road full of possibilities in front of me,\u201d she says. \u201cI decided to take this road.\u201d With three colleagues and roughly \u20ac10,000 (US$13,000), Sarno launched a series of websites, including a travel website called Venere that was one of the first to offer reservations for hotels and others services. The team created tools to allow people to discuss and rate hotels, a novelty at the time. Sarno says that her research on problem solving and computation was good preparation for running a dot-com business, but she was also inspired by Parisi's tutelage: \u201cMy choice to go to the Internet was, in some sense, a choice to do something that is big from scratch, in a direction where nothing exists.\u201d Parisi was sorry to see one of his star trainees leave the lab, but he is proud of her success. Sarno and her colleagues sold Venere to the online travel company Expedia for around \u20ac200 million in 2008. Sarno has not completely let go of research. After selling off Venere, she started a foundation to support research into blue-cone monochromacy, a rare genetic disease that runs in her family and which causes vision problems and colour blindness. She stays in touch with Parisi: when she wanted to know how different photoreceptors were arranged in the human retina, she sought his help in interpreting micrographs, and she is hopeful that delivering genes to the retina could help to cure the disease. Just like particle physics and the Internet, she sees an opportunity in gene therapy to solve problems in a new field. \n               From physiology to stay-at-home dad \n             When Eric Pane started a PhD in physiology, he was already onto his second career \u2014 or was it his third? He had been teaching at a prestigious primary school in California, which was filled with the offspring of ambitious, demanding parents. Meanwhile, he was simultaneously working as a waiter, tutor and babysitter to make ends meet. The heavy workload was wearing him down, and he wanted a way out. \u201cI didn't want to die in a kindergarten classroom of a heart attack at age 70,\u201d he says. So Pane went back to university to study biology. He found that fish physiology, in particular, fascinated him for its efforts to understand how a complex living organism was put together. \u201cI liked the 'take apart the toaster, take apart the fish' aspect,\u201d he says. As Pane read the scientific literature, he repeatedly noticed the name of Chris Wood, a physiologist at McMaster University in Hamilton, Canada. Pane contacted him, and asked to join his lab. \u201cHe was sort of an unusual applicant,\u201d Wood recalls. Most of Wood's graduate students arrived just out of their undergraduate degrees, but Pane was already 31 when he joined the lab in 2000 and embarked on a PhD. Pane quickly made an impression. He investigated the toxic effects of nickel on fish and became the lab's most productive member, publishing seven papers as part of his thesis, collaborating on another three and winning an industry award for his research. \u201cHe was one of those dream graduate students that everybody wishes they had. They come to you and generate their own ideas,\u201d says Wood. \u201cI figured this guy was going to become a faculty member some day. He was the whole package.\u201d With that faculty job in mind, Pane moved on to a postdoc studying ocean acidification at the Monterey Bay Aquarium Research Institute in Moss Landing, California. But when it came to the next career move, the rest of life had intervened. By then, Pane and his wife Michiko had had two boys, Michiko's career as a research-grant administrator was flourishing, and they had settled in the San Francisco Bay area. While Pane's colleagues were being interviewed for faculty positions all over the world, he was limited to local universities so that the family could stay put. The time demands and comparatively low pay of an assistant professor also weighed heavily: Michiko worked 60-hour-plus weeks, and Pane wanted to be able to pick up his boys from school. \u201cI could have gone for it,\u201d he says, of the faculty job, \u201cbut our children would have been raised by wolves and gypsies at that point.\u201d Pane now teaches two days a week at a community college \u2014 much of it done online. He spends the rest of his time as a stay-at-home parent. Pane is still envious of the environment of productivity and achievement his former mentor encouraged, and he tries to build that culture in his own classes. He is proud to be described as \u201ctough, but fair\u201d on the website ratemyprofessor.com. Wood was surprised that his former student took an alternative career route. \u201cInitially I was disappointed. But it's up to everybody to make their own path in life,\u201d he says. Wood's reaction mirrors those of many group leaders who see their star students quit the lab: pleasure that he or she has found a life they are happy with, tinged with regret that science will not benefit from the student's talent. But most of the scientists  Nature  contacted while researching this story saw mentoring as more than simply grooming a new generation of professors, and they recognize that non-academic jobs are a good application of scientific training. In a paper published in 2012, a team of science-policy researchers tried to work out why scientists exit academia (B. van Balen  et al .  High. Educ. Policy   25 , 313\u2013334; 2012 ). The team, led by Peter van den Besselaar at VU University Amsterdam, compared 21 pairs of Dutch researchers who were of comparable ages and working in similar fields. Both were deemed very talented in their early careers, yet one left academia and the other stayed. The team found few concrete differences between stayers and leavers to explain their divergent paths; both published similar numbers of papers that were cited just as highly, for example. But the stayers were more likely than the leavers to have had a stimulating mentor, support from a partner and good job opportunities. When it comes to securing an academic job, says van den Besselaar, \u201cit may be a question of luck \u2014 are you there at the right moment and the right place?\u201d Nearly a decade out of Wood's lab, Pane still misses it \u2014 and he wonders every day if he made the right choice. \u201cIt's just a fork in the road. You've got to go one way or the other, and you're always going to regret what the other one looked like.\u201d But on this particular day, a Friday in early July, there is no time for regret because he has got plans with his kids. \u201cThe blackberries are exploding right now,\u201d he says, \u201cso we'll go pick some.\u201d \n                 See Editorial \n                 page 5 \n               \n                     NIH chief keeps hopes afloat 2014-Aug-15 \n                   \n                     From the frontline: 30 something science 2013-Mar-06 \n                   \n                     The NIH faces up to hard times 2012-Sep-26 \n                   \n                     Education: The PhD factory 2011-Apr-20 \n                   \n                     Education: Rethinking PhDs 2011-Apr-20 \n                   \n                     Give postdocs a career, not empty promises 2011-Mar-02 \n                   \n                     Scientists need a shorter path to research freedom 2010-Oct-06 \n                   \n                     Should I stay or should I go? 2006-Dec-06 \n                   \n                     Nature Careers \n                   \n                     NSF Survey of Doctorate Recipients \n                   Reprints and Permissions"},
{"file_id": "512360a", "url": "https://www.nature.com/articles/512360a", "year": 2014, "authors": [{"name": "Alexandra Witze"}, {"name": "Lauren Morello"}, {"name": "Marian Turner"}], "parsed_as_year": "2006_or_before", "body": "Volcanic eruptions, oil spills and bacterial outbreaks all land in the laps of government science advisers, and put them to the test. As a population biologist, John Beddington spent most of his career studying fisheries rather than worrying about volcanoes. But then came April 2010, when Beddington \u2014 the UK government's chief scientific adviser \u2014 found himself having to figure out not only how to pronounce Eyjafjallaj\u00f6kull, but also what to do about the eruption of the Icelandic volcano. In the small hours of 14 April, the volcano had gone from its previous state \u2014 picturesquely spitting out lava \u2014 to violently spewing plumes of ash high into the atmosphere. Winds were blowing to the south and east, where the fine ash presented a threat to Europe's busy commercial airline routes. Suddenly scientists were scrambling not only to understand how much ash the volcano was generating, but also how it was spreading through the atmosphere and how much of a risk it presented to aircraft. So Beddington got a call at his Cotswolds home summoning him to 10 Downing Street. \u201cI sort of dusted off my brain and went into the meeting,\u201d says Beddington, who is now at the University of Oxford. In the first week of the crisis, authorities progressively closed airspace where the volcanic ash was billowing. Ultimately more than 300 airports were shuttered across Europe, stranding some 8.5 million passengers and causing major economic losses to the airlines and businesses that depend on them. Each country made the decision about its own airspace, which put Beddington front and centre of helping UK officials figure out what to do. When scientists enter government in the role of a scientific adviser or as the head of a science agency, they need to be prepared for the unexpected. Some of their most crucial contributions come during crises, a theme that will be explored on 28\u201329 August at a global summit of science advisers in Auckland, New Zealand. On the eve of that meeting,  Nature  takes a look at how such officials performed during the Eyjafjallaj\u00f6kull eruption, as well as the 2010 oil spill in the Gulf of Mexico and a deadly disease outbreak in Europe the following year. These cases show that science advisers have key roles in a crisis, especially in disseminating clear, reliable information to government leaders and the public. But at times, they struggle with the demands presented by disasters: rare events can take them by surprise, bureaucracy can strangle their attempts to respond and they often cannot keep pace with the evolving situation. \u201cWe have to form a view about advice for the government,\u201d Beddington says. \u201cAnd we have to do that on a fairly quick time scale.\u201d \n               Flight risk \n             After leaving his meeting with the prime minister, Beddington began to round up a panel of volcanology and meteorology experts to form an Eyjafjallaj\u00f6kull-focused Scientific Advisory Group for Emergencies (SAGE), the UK government's main mechanism for gathering technical advice and passing it along to decision-makers in crises. The SAGE concept was born in the wake of the 1990s spread of bovine spongiform encephalopathy, or 'mad cow' disease. Beddington was the first UK chief science adviser to gather a SAGE group together, during a 2009 influenza pandemic. Because of that experience, he says, when the Eyjafjallaj\u00f6kull crisis began, \u201cI knew the sort of people I'd need\u201d. The SAGE volcanic ash group met for the first time on 21 April, after London's Heathrow airport \u2014 the world's busiest \u2014 had faced the cancellation of more than 97% of its flights for five days straight. The group included Sue Loughlin, a volcanologist at the British Geological Survey in Edinburgh, who did her PhD on Eyjafjallaj\u00f6kull and had served in Montserrat, in the West Indies, during a deadly eruption there in 1997. Loughlin and others supplied basic information about the volcano's geological history and the pace of the ongoing eruption. Yet the ash cloud, and the crisis, moved faster than the advisory group. Pressured by airlines that wanted to resume flights, Europe's transport ministers had on 19 April quickly brokered revised operational guidelines. Planes were in the air again even as SAGE began to meet. After the initial eruption had quietened, the volcano continued to spew low levels of ash, and nobody knew whether the activity might pick up again. Three more times over the next two months, Beddington convened SAGE to assess technical details about the eruption and the likelihood of more to come. Among other things, the group explored whether a nearby volcano named Katla might also erupt, as it has in the past along with Eyjafjallaj\u00f6kull. The advisers passed that information to the Cabinet Office, which used it to develop scenarios for future volcanic-ash emergencies. SAGE also pushed government departments to assess the risk of future, larger volcanic eruptions. In 2012, the Cabinet Office added Icelandic eruptions to Britain's National Risk Register, the official list of possible events that could disrupt society. \u201cI had not thought of it at all before then,\u201d says Beddington. \u201cIt was very embarrassing.\u201d The Cabinet Office is also working up a detailed scenario for how to respond in the face of an eruption that could spew sulphur and other toxic gases across Britain, as the Icelandic volcano Laki did for eight months in 1783\u201384. David Alexander, a risk expert at University College London, says that the Eyjafjallaj\u00f6kull experience improved some aspects of disaster response in the country. The International Civil Aviation Organization, for example, has updated and clarified its guidelines on how much ash planes can fly through safely. And the UK Met Office has fine-tuned its atmospheric models for predicting the spread of dry ash through the air. But nearly all parts of the government took much too long to respond to the crisis, Alexander says. And he notes that even now, no coordinated plan exists to manage alternative transportation, such as the ferries, trains and taxis that became overloaded in April 2010. \u201cThere is still no adequate way for dealing with millions of stranded people,\u201d Alexander says. Before Beddington left office in 2013 \u2014 replaced by Mark Walport \u2014 he activated the SAGE mechanism once more, this time to provide advice about whether to evacuate the British nationals in Japan after the 2011 meltdown at the Fukushima nuclear power plant. SAGE modelled how radioactive material might spread and concluded that the risk of being exposed to radiation was relatively modest. In the end, the government provided iodine tablets as a precautionary measure but told its nationals they could stay put. And just in case, Beddington also ran some tabletop exercises for a major space weather event that could blow out power grids as well as other events so alarming that he prefers not to even name them. \u201cIf any of these instances had happened,\u201d he says, \u201cwe'd have been in position to pull a SAGE team together.\u201d \n               Deep trouble \n             Even as the volcanic ash cloud was spreading over Europe, science officials in the United States were struggling with their own crisis, one of the biggest ecological disasters in the nation's history. It all started just after 9 p.m. on 20 April 2010, when an engineer aboard the BP Deepwater Horizon oil rig in the Gulf of Mexico noticed an odd vibration. Minutes later, the rig exploded, killing 11 men and beginning a months-long effort to stanch the flow of oil from a damaged well on the sea floor and avert an environmental catastrophe. By the time the leak was first plugged in early August 2010, an estimated 4.9 million barrels had gushed into the gulf \u2014 surpassing all previous marine spills \u2014 and in so doing had put US President Barack Obama's vaunted first-term science team to its toughest test, one for which it has received mixed marks. Deepwater Horizon was a daunting disaster, with crude oil gushing from a reservoir of unknown size at a depth of 1,500 metres. But for more than a month after the blowout, the administration vastly underestimated the amount of oil flowing into the gulf \u2014 a mistake that hampered efforts to cap the leaking well and undermined public confidence in the president's response to the crisis. Key science officials, including presidential science adviser John Holdren, were slow to correct the erroneous estimates \u2014 even as academic scientists argued that the spill was orders of magnitude larger than BP or the government had publicly stated. On paper, the crisis seemed tailor-made for the all-star group of scientists that Obama had assembled after he took office in 2009. Holdren, a physicist, directed the White House Office of Science and Technology Policy (OSTP), while Jane Lubchenco, a marine ecologist, helmed the National Oceanic and Atmospheric Administration (NOAA). Geophysicist Marcia McNutt had stepped in to lead the US Geological Survey (USGS). And the Energy Department boasted Nobel-prizewinning physicist Steven Chu as its leader. Holdren says that the government sought help from outside scientists within hours of the explosion. But in many respects, Obama and his science team moved too tentatively. It was not until 19 May \u2014 almost a month after the blowout \u2014 that the administration assembled a group of scientists and engineers, headed by McNutt, to revise the controversial flow-rate calculations. The oil flow was extremely hard to estimate because there was no direct way to measure the well's output, and industry and research scientists disagreed about how best to do it. NOAA had long maintained that the flow was about 5,000 barrels a day, but independent scientists examining satellite imagery of the growing oil slick and BP video of the undersea well had argued that the actual output lay between 25,000 and 100,000 barrels per day. \u201cThe estimates that kept coming up formally from the agencies were to me just too low,\u201d says Kate Moran, an oceanographer then working as a senior policy analyst at the OSTP. That error created problems for BP when it tried to cover the gushing wellhead with an iron dome, because the cap was unable to contain the volume of escaping oil and gas. It took until 27 May for the committee assembled by the administration to determine that the flow rates determined by NOAA and BP were indeed too low. The group estimated that 12,000\u201319,000 barrels of oil were spilling into the gulf each day. Ultimately, the government would arrive at a much larger figure \u2014 62,000 barrels a day immediately after the blowout, dwindling to 53,000 barrels a day in August, before a temporary seal stopped the flow. \u201cThe most difficult part about it was trying to understand what we were getting from BP, and whether we really understood the possible sources of error,\u201d says McNutt, who arrived at BP's oil-spill operation centre on 6 May and remained for the duration of the crisis. \u201cIt actually took some time, and maybe too much time, to realize the magnitude of the problem,\u201d says Larry Mayer, an oceanographer at the University of New Hampshire in Durham. He argues, however, that the response quickly improved in mid-May, when Holdren and other officials met with scientists from some of the country's top oceanography programmes, seeking access to equipment such as remotely operated underwater vehicles and ways to track the oil as it spread in a plume below the surface. That plume was a source of great grief for NOAA chief Lubchenco, whose agency was mandated by US law to assist the Coast Guard in tracking the oil's path through the Gulf of Mexico and monitoring its effects. In mid-May, academic researchers reported finding masses of microscopic oil droplets 1,000\u20131,400 metres below the ocean surface, spreading outward for tens, possibly hundreds, of kilometres from the leaking wellhead. Almost immediately, Lubchenco issued a statement calling reports of those findings \u201cmisleading, premature, and in some cases, inaccurate\u201d, drawing a wave of criticism from oceanographers who felt that she was unduly dismissive of important evidence. \u201cThat was truly a head-slapping moment for me as an oceanographer,\u201d says Ian MacDonald from Florida State University in Tallahassee. It took another 22 days before NOAA acknowledged the presence of the plume \u2014 a delay that fed mistrust of the agency by outside scientists. By contrast, McNutt and Chu drew praise for their actions during the crisis. While McNutt helped to determine the amount of oil leaking into the gulf, Chu worked to stop the flow. He arrived in Houston on 12 May, accompanied by distinguished scientists recruited with Holdren's help, including some from JASON, a storied panel that advises the government on issues such as defence and energy. They and others quickly began challenging BP for more and better data about the state of the well. Chu convinced the oil company to monitor the wellhead using \u03b3-ray imaging as well as temperature and pressure gauges, which provided the first direct measurements of the still-flowing oil. Finally, on 19 September \u2014 150 days after the initial explosion and well blowout \u2014 the Coast Guard declared an end to the disaster after engineers inserted a cement plug to permanently seal the well. Four years later, disappointment still lingers among many scientists about the way in which the Obama administration handled Deepwater Horizon. Stopping the oil's flow \u201cwas a huge effort, and people worked heroically and tirelessly\u201d, MacDonald says. But, he argues, the scientists leading government agencies should have acted more quickly and provided better information about the extent and nature of the spill. \u201cAt many critical junctures in the process,\u201d he says, \u201cthe government was on the wrong side of history.\u201d \n               Outbreak \n             A year after the Deepwater Horizon spill, doctors in Hamburg, Germany, put out a call for help. On 19 May 2011, three children at a city hospital were battling haemolytic uraemic syndrome, a life-threatening condition caused by a severe gastrointestinal infection with the bacterium  Escherichia coli . Worried that the outbreak could spread, Hamburg health officials contacted the Robert Koch Institute (RKI) in Berlin \u2014 Germany's federal agency for disease control and prevention. When three RKI epidemiologists arrived in Hamburg the next day, it was clear that something unusual was going on. Several other cases, including some in adults, had popped up at hospitals around the city and reports soon came in from other regions. What followed was Europe's worst recorded outbreak of  E. coli  infection. By the time the outbreak was declared over, some two months later, more than 3,800 people had developed acute gastrointestinal infections. Of those, 845 had progressed to HUS, and 54 had died. The correct source of the infection \u2014 fenugreek seeds from Egypt \u2014 was not identified to the public until 5 July. Reinhard Burger, president of the RKI, says that the outbreak \u201cwas a good example of how rapidly a new threat can appear and develop and affect the population\u201d. The event also illustrated the problems that can emerge when scientists at multiple agencies \u2014 reporting to different levels of government \u2014 respond to a public-health emergency. The RKI's most pressing task was to identify the strain of bacterium that was causing the infection and then where it came from.  E. coli  infections are typically caused by contaminated foods, and the epidemiologists began by interviewing patients about their recent diet. \u201cWe knew within the first two days or so that the usual suspects \u2014 fresh milk and raw-meat products \u2014 were not the problem,\u201d says Burger. The only thing all patients seemed to have in common was that they had eaten salads containing fresh tomatoes, cucumber and lettuces, in northern Germany. On 25 May, the RKI, which reports to the federal health ministry, issued a joint statement with the federal institute for risk assessment (BfR), saying that these vegetables were associated with increased risk of infection. Science advisers at the RKI say that the various federal agencies responsible for disease control and food safety worked together smoothly to assess the risks and communicate them to the public. But the coordination between them and agencies that reported to state governments was not nearly as efficient. As cases emerged throughout Germany, the chain of orderly communication cracked. The worst blunder came on 26 May, when Hamburg health senator Cornelia Pr\u00fcfer-Storcks announced that the Hamburg Institute for Hygiene and Environment had discovered enterohaemorrhagic  E. coli  (a pathogenic class of  E. coli ) on Spanish cucumbers. But she had not consulted the RKI before making that statement. And tests a few days later revealed that the bacteria on the suspect cucumbers did not belong to the same strain found in patients. The ongoing uncertainty about the source of the bacteria led to trade restrictions and large economic losses, particularly in Spain, where farmers found themselves unable to export cucumbers and other suspect produce. The European Commission eventually issued a \u20ac227-million (US$302-million) payout to farmers from several countries. Burger says that the Hamburg statement \u201cdamaged confidence in public announcements\u201d. The problem was compounded by the public's increasing hunger for information while epidemiological investigations were failing to turn up more-specific leads. \u201cI was facing the media every day, but sometimes we had nothing new to say,\u201d he says. Looking back, health officials say that some technological improvements could help. For instance, Burger says that using genetic sequencing rather than the current culture-based diagnostic techniques might have helped physicians to recognize the outbreak more quickly. The response was also hampered by a complicated reporting chain: when physicians confirm a case of a disease, they report it to local health authorities, who forward it to the RKI. Before the outbreak, that process could take up to 16 days. A change to the law last year means that reports must now reach the RKI within 5 days. But the notifications can still trickle in by phone, fax or e-mail. The federal health ministry is therefore developing an electronic system to provide faster and simultaneous notification for local and federal authorities. Such a system would not bypass the problem that the RKI can act only at the request of state agencies \u2014 a rule that some feel should be changed. \u201cWhen there is the impression than an outbreak is affecting more than one state, the RKI should have the right to start investigations on its own,\u201d says Ulrich Frei, medical director of the Charit\u00e9 hospital in Berlin, which handled several cases. \u201cHealth is one of only a couple of topics in which the German states still have much authority, and they're not very willing to transfer this to the federal level,\u201d he says. As with natural disasters and human-caused crises, the outbreak points out the benefits of high-level coordination during emergencies. Peter Gluckman, New Zealand's chief science adviser, grappled with this issue when an earthquake levelled much of Christchurch in 2011. In the aftermath, competing scientific experts debated future risks in the media in a way that spurred confusion among government officials and the public, says Gluckman. His office spent weeks trying to get scientists to provide clear information about existing threats and uncertainties. A crisis demands scientific coordination, he says. \u201cOften it is made worse by inconsistent communication\u201d. \n                 See Editorial \n                 page 347 \n               \n                     Reform falters after Europe\u2019s E.\u2009coli scare 2012-May-30 \n                   \n                     Germany learns from E. coli outbreak 2011-Sep-12 \n                   \n                     Oil spill: Deep wounds 2011-Apr-13 \n                   \n                     Newsmaker of the year: In the eye of the storm 2010-Dec-19 \n                   \n                     Volcanology: Out of the ashes 2010-Jun-02 \n                   \n                     Questions fly over ash-cloud models 2010-Apr-27 \n                   \n                     Government Office for Science \n                   \n                     Scientific Advisory Group for Emergencies \n                   \n                     Report from Flow Rate Technical Group \n                   \n                     Robert Koch Institute \n                   Reprints and Permissions"},
{"file_id": "513157a", "url": "https://www.nature.com/articles/513157a", "year": 2014, "authors": [{"name": "Andrew Curry"}], "parsed_as_year": "2006_or_before", "body": "Using a wildlife version of fitness trackers, biologists can finally measure how much energy animals need to stay alive. After attacking more than a dozen young Hawaiian monk seals, the aggressive male known as KE18 had to be banished from his island home. He now lives in a seawater pool in California, a few hundred yards from the Pacific Ocean. Instead of assaulting more members of his species \u2014 one of the most endangered marine mammals on the planet \u2014 KE18 is now providing information that could help to keep the seals from going extinct. On a breezy June day at the University of California, Santa Cruz, an animal trainer is working to teach him to wear a metal tube containing a trio of accelerometers, tiny devices that track and log changes in velocity. It is the seal version of the fitness trackers that joggers and other endorphin addicts wear on their wrists to capture their every move. Heaving his 200 kilograms up on the side of the pool, KE18 opens his mouth to show off his teeth and gets a fish as a reward. \u201cWe use a lot of fish and hot dogs in our lab,\u201d says biologist Terrie Williams, who heads the mammalian physiology lab. The hope is that data collected on KE18 will help to explain a mystery about the threatened Hawaiian monk seal ( Monachus schauinslandi ). Most of the population lives in the remote northwestern end of Hawaii's island chain, where four in every five pups die before reaching adulthood and the population is falling by more than 3% a year. \u201cThey end up starving to death,\u201d says Charles Littnan, who runs the Hawaiian Monk Seal Research Program at the National Oceanic and Atmospheric Administration in Honolulu. But a much smaller population living close to the crowded beaches of the main Hawaiian islands is actually growing, despite all the human activity nearby. KE18 could be the key to deciphering why the two groups are on opposite trajectories. Researchers at the university's marine lab are teaching the seal to wear a flipper cuff holding the accelerometers while exercising in his pool. Soon, they will also start to measure the oxygen content of his breath \u2014 a proxy for how hard he is working. By combining those data and the accelerometer information, Williams and her colleagues can calibrate the amount of energy that KE18 uses as he swims. They plan to use those data to interpret the readings from accelerometers placed on wild monk seals, which should help to determine why they are not thriving \u2014 whether they are wasting energy, for example, by having to swim too far to catch prey. Seals are not the only animals wearing fitness trackers. In the Arctic earlier this year, researchers fitted polar bears ( Ursus maritimus ) with accelerometers to see how much energy they expend while swimming the ever-increasing distances to reach dwindling ice floes. Marine biologists are deploying the devices to find out whether warming oceans are impairing the swimming prowess of fish. And in the western United States, motion trackers on mountain lions ( Puma concolor ) will help to determine how much extra energy they burn negotiating the sprawl of human development. As accelerometers have become cheaper and smaller \u2014 largely because of their use in mobile phones \u2014 wildlife biologists have embraced them as a way to collect data on movement and energy consumption. The information is starting to answer basic questions about animal behaviour and physiology, and help researchers to predict how climate change, habitat destruction and human activity will affect animals. The flood of data coming in is altering the kinds of questions that wildlife biologists ask, says Craig Franklin, an eco-physiologist at the University of Queensland, Australia. \u201cPeople are really starting to realize the value of physiology in addressing conservation.\u201d \n               The cost of energy \n             Biologists sometimes say that energy is the currency of life. \u201cIf animals are going to collect one thing that's analogous to money, it's energy,\u201d says Rory Wilson, an aquatic biologist at Swansea University, UK. Everything that an organism does requires some expenditure. Movement is particularly costly; but even asleep, the body burns calories to maintain digestion, breathing and circulation. There is a key difference, however, between money and energy: animals cannot go into the red. \u201cIf you don't have energy in your system, you're dead,\u201d says Wilson. Biologists do not have an easy way to track how much energy wild animals use, so they use oxygen consumption as a proxy. The more fuel that animals burn, the more oxygen they need. With an animal on a treadmill, researchers can correlate oxygen use with the speed of the machine to come up with a rough measure of energy use per metre of forward motion, for example. That 'cost of transport' has long served as a crude yardstick of animal energetics. But it relies on many dubious assumptions, such as that animals move through the environment much as they run on a treadmill \u2014 when in fact they could burn much more when covering uneven ground. The technique is even less useful for animals that crawl through sand, swim or fly. And because it relies on knowing the distance travelled, it is hard to apply to animals that spend a lot of time obscured underwater or in the dark, for example. That's where accelerometers come in. First widely applied as the sensors that trip air bags in cars, accelerometers contain tiny weights that shift with a change in speed. When biologists initially packaged them with data loggers and batteries to measure animal motion, the devices were unwieldy. In the late 1990s, Williams put flipper cuffs and the equivalent of small scuba tanks on Weddell seals ( Leptonychotes weddelli ) in Antarctica 1 . \u201cIt was a pretty exotic piece of equipment,\u201d she says. As costs plummeted, however, companies began to offer ready-made accelerometers combined with memory chips that record dozens of data points each second for weeks or even months at a time. And wildlife biologists immediately saw an opportunity to fix them to animals. Since 2009, more than 130 papers have been published using accelerometers to study animal behaviour. \u201cIt's really exploded in terms of interest and technology,\u201d Williams says. \u201cNow we can sample so much, we know every time an animal takes a stroke or a paw hits the ground.\u201d Such detailed results led Wilson to wonder whether accelerometers might be the key to a more flexible and accurate measure of energy use. In 2005, he worked with Lewis Halsey, an environmental physiologist now at the University of Roehampton, UK, to put accelerometers on a quintet of great cormorants ( Phalacrocorax carbo ). They coaxed the diving birds to walk on a treadmill inside a sealed respirometry chamber while wearing a 35-gram data logger the size of a book of matches. The resulting data confirmed that the set-up worked as a way to measure energy expenditure: when the accelerometers recorded more movement, oxygen consumption rose accordingly 2 . The motion information was useful outside the lab, too. Accelerometers taped to wild cormorants revealed that birds carrying a load of fish required 14% more acceleration to stay aloft than did unladen birds, for example. Scientists now refer to dynamic body acceleration, or DBA, a tally of acceleration in three dimensions. Since Wilson and Halsey's experiments with cormorants, there has been a flood of publications using DBA and oxygen consumption to investigate the energy demands of wild animals from lobsters to badgers, toads and penguins. Other labs are working on commercially important species such as scallops, cod and sea bass. \u201cEveryone's saying 'bloody hell, it works on everything',\u201d says Wilson. To test the effects of climate change on fish, behavioural ecologist Julian Metcalfe of the Centre for Environment, Fisheries and Aquaculture Science (CEFAS) in Weymouth, UK, implanted accelerometers into cod ( Gadus morhua ) and studied how the fish responded metabolically to different temperatures. \u201cIf the water gets colder, they get less active \u2014 but are still able to chase and escape when necessary,\u201d he says. When the temperature rises, however, cod have trouble performing high-energy feats. \u201cA fish at high temperatures is less able to escape a predator or catch prey,\u201d Metcalfe says. \u201cIn terms of climate change, that's important to know.\u201d Serena Wright, now a biologist at CEFAS in Lowestoft, UK, studied farmed trout with the help of implanted accelerometers. She found that some of the fish had stunted fins or deformed skeletons, perhaps because of crowding or inbreeding, and the deformed fish used more energy than normal fish while swimming, which slows their growth. The fish had also learned to anticipate regular feedings: they moved relatively little until just before meal times, she says. That is a problem because aquaculture fish grow more quickly when they swim. Wright has therefore suggested that fish farms adopt irregular feeding schedules to keep the fish moving more during the day. \n               Breeding disturbances \n             Anthony Robson, a biologist at the University of Western Brittany in Brest, France, and Halsey have even attached motion sensors to largely sedentary creatures, such as scallops ( Pecten maximus ). The shellfish move only about two minutes per day, on average \u2014 but that accounts for around 17% of their energy expenditure in the wild 3 . Farmed scallops, by contrast, spend more time in escape and evasion mode than their wild brethren because of the lights and vibrations from human activity, and that bumps up their energy expenditure to around 40%. \u201cThey're basically going crazy being disturbed in the hatchery,\u201d says Robson. Rather than feeding and growing, the farmed scallops spend much of their energy budget on moving \u2014 information that could be valuable for fisheries. Energy data can also help to explain some of the behaviour that animals exhibit in the wild. Take the Magellanic penguin ( Spheniscus magellanicus ), found in the cold waters off the coast of southern South America. Researchers know that the birds prefer anchovies over squid, which they eat only when the fish are hard to come by. But the reasons were not clear \u2014 until Wilson put accelerometers on the birds in the lab and then in the wild. He found that the natural buoyancy of penguins made swimming downwards much more costly than going up 4 . The penguins use less energy catching fish because they can take advantage of their buoyancy and lunge at the prey from underneath. \u201cBut penguins have to swim actively after diving squid,\u201d Wilson says. \u201cThe energy costs for catching a squid are hugely higher than for an anchovy. We never would have got that without accelerometry.\u201d And by looking for tell-tale wiggles in the accelerometer data, the researchers could even tell how many times penguins were feeding in the wild, allowing them to estimate the penguins' total consumption \u2014 data that could become important if countries want to limit fish harvests to protect key penguin populations. In Williams's lab, researchers are going after bigger beasts. PhD student Anthony Pagano, a wildlife biologist with the US Geological Survey, is trying to figure out how to get polar bears into a respirometry chamber to measure their energy use. Those data would complement the measurements he has made over the past two years, as part of a project that put tracking collars on female polar bears in Alaska. The location readings show that as sea ice retreats, bears are swimming two to three times farther than they did 10 or 20 years ago, says Pagano. In 2008, for example, researchers recorded a polar bear making a 687-kilometre continuous swim over 9 days to reach pack ice. But what researchers do not yet know is how much more energy the bears are using in the process. So Pagano has fitted the animals with collars that will gather acceleration, global-positioning and even video data over the eight-month-long Arctic winter. Meanwhile, he is working with zoos to put captive females, which weigh up to 370 kilograms, into respirometry chambers built around a polar-bear-sized 'endless pool' or treadmill. \u201cIt's going to come down to the ability to build something that's polar-bear proof,\u201d he says. \u201cOne of the challenges is that they're pretty destructive and big.\u201d  If animals are going to collect one thing that's analogous to money, it's energy.  Pagano's struggles point out a key obstacle to the burgeoning field's growth: to get accurate measurements of energy expenditure, biologists need to find ways to calibrate the devices on individual species. \u201cIt's a hell of a job to calibrate with a new animal,\u201d Halsey says. Wild animals must be trained or coaxed into a respirometry chamber, whether in the field or in a lab, which sometimes proves difficult. Often, the animals simply do not take to treadmills. During her PhD, Astrid Willener found herself wrestling waist-high king penguins ( Aptenodytes patagonicus ) onto a treadmill at a research station on France's Possession Island to study their energetics. Some were too stressed to walk on the treadmill and tried to slide on their bellies or skidded along on the soles of their feet with their backs resting against the wall of the box. \u201cOnce a penguin's found a trick, they'll continue,\u201d Willener says. Even fitting the accelerometer takes creative thinking. Williams's team has come up with 'wetsuits' containing accelerometers and heart-rate sensors that they can slip onto captive dolphins, which they teach to surface under breathing domes like the one used to see how much oxygen KE18 uses. And Halsey has used bits of a pair of tights to strap the devices onto cane toads, which puff up when they are handled. Halsey and Wilson, the pioneers of animal accelerometers, hold out hope that researchers will eventually come up with an algorithm that would allow them to use the data without requiring every species to go into a respirometer. But colleagues are sceptical. \u201cMy feeling is that there's so much variation between individual animals that you have to do at least animals within that species,\u201d says eco-physiologist Michael Scantlebury of Queen's University Belfast, UK. Pagano's polar bears, for example, are such good swimmers that he thinks no other type of bear would work as a proxy. Caleb Bryce, another of Williams's graduate students, wants to study the energy budgets of grey wolves ( Canis lupus ). He initially hoped that large dogs would be acceptable substitutes and has put dozens of them on a treadmill inside a sealed transparent box. But because wolves eat much less frequently than domestic dogs and seem to have a different metabolism, Bryce has concluded that he will need to train captive wolves to run on a treadmill to get exact numbers. It is not so far-fetched: Williams and a collaborator in Colorado managed to convince a captive mountain lion to exercise in a respirometry chamber as part of an effort to assess how the animals are faring in the Santa Cruz mountains as humans encroach on their habitat. Proponents of wildlife accelerometry admit that it will take some time to work out the logistics of how to collect energy data \u2014 and how to make use of them. But with animals such as KE18 providing potentially important information that might help to save a species, researchers hold out a lot of hope. \u201cWe're just at the beginning,\u201d says Williams. \u201cIt's a really exciting time for wildlife biology.\u201d \n                     Precision formation flight astounds scientists 2014-Jan-15 \n                   \n                     Personal technology: Phoning in data 2009-Apr-22 \n                   \n                     Critter cam 2007-Oct-04 \n                   \n                     Terrie Williams \n                   \n                     KE18 \n                   Reprints and Permissions"},
{"file_id": "513160a", "url": "https://www.nature.com/articles/513160a", "year": 2014, "authors": [{"name": "Corie Lok"}], "parsed_as_year": "2006_or_before", "body": "Technologies are allowing doctors to do what was once unheard of: restore blind people's sight. Now the real challenges begin. Tami Morehouse's vision was not great as a child, but as a teenager she noticed it slipping even further. The words she was trying to read began disappearing into the page and eventually everything faded to a dull, grey haze. The culprit was a form of Leber's congenital amaurosis (LCA), a group of genetic disorders in which light-sensing cells in the retina die off, usually resulting in total blindness by the time people reach their thirties or forties. But Morehouse got a reprieve. In 2009, at the age of 44, the social worker from Ashtabula, Ohio, became the oldest participant in a ground-breaking clinical trial to test a gene therapy for LCA. Now, she says, she can see her children's eyes, and the colours of the sunset seem brighter than before. Morehouse calls these improvements life-changing, but they are minor compared with the changes in some of the younger trial participants. Corey Haas was eight years old when he was treated in 2008 \u2014 the youngest person to receive the therapy. He went from using a white cane to riding a bicycle and playing softball. Morehouse often wonders what she would be able to see now if she had been closer to Haas's age when she had the therapy. \u201cI was born a little too soon,\u201d she says. Visual impairment affects some 285 million people worldwide, about 39 million of whom are considered blind, according to a 2010 estimate from the World Health Organization. Roughly 80% of visual impairment is preventable or curable, including operable conditions such as cataracts that account for much of the blindness in the developing world. But retinal-degeneration disorders \u2014 including age-related macular degeneration, the leading cause of blindness in the developed world \u2014 have no cure. \n               Small steps \n             In the past seven years, there has been mounting hope and excitement about the prospect of slowing or even reversing vision loss from retinal disorders. Clinical trials testing gene therapy, cell transplants and retinal prostheses are under way, and many studies \u2014 including the trial 1 , 2  involving Morehouse and Haas \u2014 are producing promising results. Biotechnology firms are taking up the challenge, and several have formed to take treatments through clinical testing. But most of the successes so far have been in treating rare congenital disorders, and it is still unclear how many people will ultimately benefit and to what extent vision can be preserved or restored. \u201cThere's a growing appreciation of the complexity of the clinical problem,\u201d says Thomas Reh, a neurobiologist working on cell transplants for the eye at the University of Washington in Seattle. Corie Lok discusses scientists\u2019 efforts to restore sight in the blind It may seem vulnerable and complex, but the eye has features that make it a good testing ground for experimental treatments. Unlike internal organs, surgeons can easily operate on it and peer inside to track how well a therapy is doing. It is also walled off from many damaging inflammatory responses that might derail a cell-transplant or a gene therapy. So the eye is \u201ca good way to dip the toes in the water\u201d, says Stephen Rose, chief research officer at the Foundation Fighting Blindness in Columbia, Maryland, which funds research and consults with drug firms. Since 2007, clinical researchers have been dipping their toes into gene therapy for congenital forms of retinal degeneration such as LCA. The goal is to use a virus to supply retinal cells with working copies of a gene called RPE65, which is mutated in the form of the disease known as LCA2. The hope is that the working gene will repair malfunctioning cells and keep them alive, preserving and even improving vision. Trials by three different groups 1 , 2 , 3 , 4  have shown not only that the procedure is safe, but also that it boosts vision in most participants \u2014 and that most improvements seem to be maintained for up to seven years. The biotechnology company Spark Therapeutics in Philadelphia, Pennsylvania, is now testing gene therapy for LCA2 in an advanced trial, and it hopes to file for regulatory approval in the United States as early as 2016. But some studies have raised questions about how well the therapy is working. An analysis 5  of data from one 4  of the three initial trials found that although participants' vision had improved, their photoreceptors were still dying at about the same rate as before the treatment. Artur Cideciyan, a vision scientist at the University of Pennsylvania in Philadelphia and a co-author of the study, says that the improvements probably came from the rescue of only some retinal cells. Gene therapy may not have affected the more dysfunctional photoreceptors, and these were the ones that probably died after treatment. Researchers have observed that there seems to be a point of no return in some forms of retinal loss 6 . A possible reason is that cell death disrupts the structure of retinal tissue, leading to a domino-like decline. Cideciyan argues that after retinal degeneration has started, even cells improved by gene therapy may eventually die off, at least in LCA2. Robin Ali, a geneticist at University College London who led one of the early LCA2 trials 3 , is more confident about the promise of these treatments: the careful animal work that preceded human trials showed that gene therapy, if given at the right dose and the right time, can slow degeneration. \u201cWe're still at the very start of the optimization process in humans,\u201d he says. Discovering the best timing for the treatment in humans remains a central challenge. Most researchers agree that the best approach is to replace the faulty gene when patients are young, before the degeneration starts or at least when there are more viable cells to save. That could mean doing retinal surgery in someone with good vision \u2014 a difficult decision, says Robert MacLaren, an ophthalmologist at the University of Oxford, UK, who is running a gene-therapy clinical trial for another form of congenital blindness 7 . \u201cThat is where the risks are greatest, but so are the gains.\u201d Spark's phase III LCA2 trial was open to children as young as three years old. Once the damage has reached a point at which there are few or no useful photoreceptors left to save, gene therapy will probably not help. That is why some research groups are looking to other techniques, such as cell-based therapy. \n               Regeneration game \n             When people talk about the therapeutic potential of embryonic stem cells, they usually mention treatments for diabetes and spinal-cord injuries. But one of the first clinical trials for such cells was actually to treat blindness. Advanced Cell Technology in Marlborough, Massachusetts, has been conducting trials that transplant retinal pigmented epithelial (RPE) cells derived from embryonic stem cells into people with one of two forms of vision loss caused by retinal degeneration (see  Nature   481 , 130\u2013133; 2012 ). The trials started in 2011, and researchers and industry onlookers are eagerly anticipating results later this year. The RPE cells support the function of the photoreceptors, and the hope has been that the cell transplants will stop or slow the loss of the light sensors. Replacing photoreceptors themselves could have a higher pay-off, but deriving them efficiently from stem cells and wiring them into the retina has been difficult.  We're still at the very start of the optimization process in humans.  There are tantalizing signs that it could work. Ali and his colleagues, for example, have shown that when precursors to rod cells \u2014 photoreceptors that are active in dim light \u2014 are transplanted into mouse eyes, they connect with other cells in the retina and can restore vision 8 . They also showed that the rods can be grown from mouse embryonic stem cells and can mature and integrate into the retina 9 . Researchers are now working on deriving and transplanting cone cells \u2014 which enable high-acuity vision \u2014 into animals, and are starting to think about the first human trials. Whatever the strategy, stem-cell-based treatments face some of the same issues as gene therapy: the disease processes that kill off retinal cells could continue to do so after treatment. There may be ways around this for less severe forms of blindness, says Ali, but transplanting cells into the eyes of people with very advanced disease might not work. So for these people, a more radical solution may be required. When doctors first turned on his bionic eye, Roger Pontz thought he was dreaming: for the first time in 15 years, he could see the lights on the ceiling. The 56-year-old dishwasher from Reed City, Michigan, is one of 90 people worldwide to have received the Argus II implant, the only approved retinal prosthesis on the market. Pontz lost his sight to retinitis pigmentosa, a group of inherited disorders that cause retinal-cell death and leave most patients legally blind by the age of 40. Now, he no longer bumps into walls and he can grab the refrigerator door handle without having to feel his way towards it. \u201cIt's made life a lot better,\u201d says Pontz. The Argus II, made by Second Sight in Sylmar, California, was approved by the US Food and Drug Administration in 2013 for severe retinitis pigmentosa. It consists of a small camera mounted on a pair of glasses, which sends video data to a portable computer worn by the user. The processed signals are sent back through a cable to the glasses, where they are then transmitted wirelessly to a receiver wrapped around the eye. This sends the signals to a chip that has been surgically placed on top of the retina. The chip generates electrical impulses that stimulate the remaining cells of the retina. The device \u2014 which is pricey at US$144,000 \u2014 does not restore normal vision. \u201cWe try to transform blind people into low-vision people,\u201d says Jos\u00e9-Alain Sahel, an ophthalmologist and head of the Institute of Vision in Paris, who was involved in testing the device in humans. Pontz says that he sees dots of light in black and white, which correspond to lines of contrast such as a doorway. With rehabilitation exercises, he is learning to make sense of those patterns (see \u2018A critcial question\u2019). He still uses a white cane and has to move his head continually up and down and side to side so that the camera in his glasses can take in the scenery. \n               boxed-text \n             Second Sight is now aiming to open up the technology to more people. The firm hopes to begin testing the Argus II in people with age-related macular degeneration this year. To boost the device's resolution, the company has tried squeezing more electrodes onto the chip but that did not make much of a difference. So, instead, it is focusing on improving the software, with some promising early results. With so many advances, researchers are optimistic about the future. Even if a treatment can save or restore only a small number of light sensors in a diseased retina, that might still be enough, says Ali. \u201cYou don't need very many functioning photoreceptor cells for vision.\u201d It is probably not going to be perfect vision, and it may not even be a permanent fix, but as recipients such as Morehouse say, every little bit of improvement is significant. \u201cEven if you can give me five to ten years of vision, I'm going to take it.\u201d \n                     Prosthetic retina helps to restore sight in mice 2012-Aug-13 \n                   \n                     Neurodevelopment: Unlocking the brain 2012-Jul-04 \n                   \n                     Stem-cell research: Never say die 2012-Jan-11 \n                   \n                     Vision science: Seeing without seeing 2011-Jan-19 \n                   \n                     Colour blindness corrected by gene therapy 2009-Sep-16 \n                   Reprints and Permissions"},
{"file_id": "513294a", "url": "https://www.nature.com/articles/513294a", "year": 2014, "authors": [{"name": "Hannah Hoag"}], "parsed_as_year": "2006_or_before", "body": "Destructive lionfish are invading coral reefs in the Americas, but fishing competitions can help to keep the problem species in check. Stephanie Green plunged her hands, sheathed in thick black gloves, into a cooler full of lionfish. Skilfully avoiding its 18\u00a0venomous spines, she plucked one out and laid it on a table to record its length. Nearby, volunteers were chopping up the brown, red and white striped fish to make ceviche and passing the dish into the crowd. As they nibbled on the food, teams of scuba divers milled around the scoring area. They checked out each other\u2019s catches and argued over who would be taking home the more than US$3,500 worth of prizes from the 2013 lionfish hunting derby in Key Largo, Florida. \u201cAt the check-in time it\u2019s a mad rush, with teams coming in with coolers of fish, trying to beat the clock,\u201d says Green, the chief scientist of the contest and a marine ecologist at Oregon State University in Corvallis. By the end of that day last September, Green and the other scorekeepers had counted 707 lionfish, from one smaller than a golf ball to one that stretched nearly two soccer balls long. The hunting competition is part of an effort to tackle an invasive species that has been identified as one of the world\u2019s greatest conservation issues 1 . Since lionfish ( Pterois volitans ) first appeared on the eastern seaboard of the United States in the 1980s, the voracious predators have gobbled up coral-reef fish from North Carolina to Venezuela. Officials responsible for protecting reefs have struggled to find ways to control populations, and managers are embracing these fishing contests in a handful of coastal communities. The strategy is a bit of a gamble, given that competitions to catch other invasive species \u2014 such as pythons in Florida \u2014 have had limited success. But the data collected by Green show that even one-day contests can effectively knock down local populations. Her findings and those from other hunting efforts offer lessons on how a little bit of reward money \u2014 coupled with science and outreach \u2014 can help to keep invasive species in check. \u201cWe can\u2019t control lionfish in the entire ocean, but derbies can have high impacts locally,\u201d says James Morris, an ecologist with the US National Oceanic and Atmospheric Administration in Beaufort, North Carolina. Like many invasions, the lionfish conquest started small. The fish are normally found in the western Pacific Ocean, Indian Ocean and Red Sea, where predators and competitors keep the populations under control. Genetic analysis 2  suggests that roughly a dozen fish were first introduced off the Florida coast, either accidentally or intentionally released from aquariums. From there, the population exploded. Lionfish spawn almost continuously, releasing 2\u00a0million eggs a year, and they have few predators or competitors in their new home. \u201cAt first people thought they were funny, beautiful,\u201d says Mark Vermeij, a conservation biologist at the Caribbean Marine Biological Institute on the island of Cura\u00e7ao. But opinions changed as the lionfish took over, he says. \u201cQuite quickly they were everywhere. They were like cockroaches.\u201d Since they were first spotted near Fort Lauderdale, Florida, in 1985, lionfish have colonized more than 4\u00a0million square kilometres \u2014 throughout the Caribbean Sea, the Gulf of Mexico and all along the Atlantic coastline of the southern United States \u2014 and show no signs of relenting. Marine ecologists worry that the invasion will eventually extend to Uruguay, stopped only by winter water temperatures. It could become one of the most ecologically harmful fish introductions in the western Atlantic, says Mark Hixon, a marine ecologist now at the University of Hawaii at Manoa, and Green\u2019s supervisor at Oregon State. At some sites off the coast of North Carolina and in the Bahamas, the populations are 5\u201315 times denser than in the fish\u2019s natural range, sometimes even reaching 400 fish per hectare. The conquest could have profound effects on the biodiversity of coral-reef ecosystems. Lionfish consume whatever fits in their maws \u2014 and a lot of it. A DNA analysis 3  of the stomach contents of 157 lionfish caught in the Mexican Caribbean identified 43 crustacean and 34 fish species, including parrotfish, French grunt and graysby \u2014 important sources of food for local people. Without natural predators, a lionfish can gobble up 79% of the juvenile fish on a reef in as little as five weeks. The feeding frenzy could also lead to larger problems. Some of the fish they prey on clean algae off coral reefs and are already overfished in the Caribbean. Without these essential species, algae could outcompete the corals. Simulations by Jes\u00fas Ernesto Arias-Gonz\u00e0lez at the Center for Research and Advanced Studies of the National Polytechnic Institute, in M\u00e9rida, Mexico, have shown that a lionfish invasion would decrease the biomass of corals in a Caribbean reef by about 10% within ten years 4 . \n               Out of control \n             Green did not set out to study lionfish. She had just started a doctorate in conservation biology when she travelled to the Bahamas in 2008 with her adviser Isabelle C\u00f4t\u00e9, a biologist at Simon Fraser University in Burnaby, Canada. A student they visited was seeing lionfish all over her study sites. \u201cNobody knew anything about them, the basics of where they were, or what they ate,\u201d says Green. Green and C\u00f4t\u00e9 wondered whether the native fish would return if they removed the lionfish. In December 2009, they staked out 24 patches of reef and arranged for scuba divers to prune the population of lionfish at the sites every month for 18 months. They predicted that the culling effort would need to remove 25\u201392% of the predators, depending on the site, to keep them from consuming too much of the prey species. By the end of the experiment, the native fish had rebounded by 50\u201370% in the reefs that reached the targeted level of protection 5 . Green and C\u00f4t\u00e9 were not the only ones to hunt down lionfish. Earlier that year, the Reef Environmental Education Foundation (REEF) in Key Largo, Florida, had started running derbies in the Bahamas to increase local awareness of the invasion. Green, who had been collaborating with the foundation during her PhD, got involved in planning the first hunts. She later decided to use the competitions to test whether limited hunts could have an impact. With the help of volunteers outfitted in scuba and snorkels, Green counted lionfish at 60 sites before and after the derbies in Key Largo and the Bahamas in 2012 and 2013. On the basis of a preliminary analysis of the derbies, she says, \u201cthere were dramatic drops in the densities of lionfish in the sites where people fish.\u201d After the competitions, lionfish densities were slashed by more than 60% over a 100\u2013150\u2009km 2  area compared with pre-derby levels. \u201cIt\u2019s like pulling weeds from your garden,\u201d she says. \u201cYou\u2019re not going to completely get rid of them, but below a certain level, they won\u2019t cause problems.\u201d Lionfish recolonized the sites within six months, but the animals were significantly smaller, which helped to reduce pressure on the reef. Smaller lionfish eat less, prey on smaller fish and produce fewer young. Ted Grosholz, a marine ecologist at the University of California, Davis, says that the data collected by Green and REEF support the idea that derbies can effectively control lionfish populations in selected areas. They also dovetail with results from other lionfish control efforts. When the fish invaded the Dutch Caribbean in 2009, volunteers immediately began to use spear guns to remove lionfish from the island of Bonaire, but did nothing in neighbouring Cura\u00e7ao. After two years of spearfishing, Vermeij and his colleagues found that the lionfish biomass in the treated areas of Bonaire was just one-third of that in the unfished areas, and about one-quarter of what was seen in Cura\u00e7ao 6 . \n               On Target \n             The lionfish contests have been much more successful than some other efforts that have used hunters to control invasive species. In 2013, for example, the Florida Fish and Wildlife Conservation Commission organized the first Python Challenge, a month-long event with cash prizes that enlisted professional and amateur hunters to remove Burmese pythons ( Python bivittatus ). But the pythons proved tough to catch because they are hard to spot in the Florida brush; the hunters caught just 68\u00a0snakes from a population that is estimated at 30,000\u2013100,000. Jason Goldberg, a biologist at the US Fish and Wildlife Service in Arlington, Virginia, says that derbies could be improved by incorporating the results of research. Organizers need to calculate how many individuals to remove, whether it is better to cull older or larger individuals and how their density affects the health of the population. That information can then be used to set hunting targets \u2014 and prevent the kinds of problems that arose when Australia culled red foxes ( Vulpes vulpes ). The 2002\u201303 Victorian Fox Bounty Trial removed one-fifth of the state\u2019s red foxes but ended up boosting the population because the survivors thrived when they had less competition for food 7 . Cash incentives can help by drawing amateurs into efforts to control invasives. In the Pacific northwest, for example, anglers are offered $4\u20138 for every northern pike minnow ( Ptychocheilus oregonensis ) they capture to deter the fish from preying on young salmon. The programme has removed more than 3.9 million fish and slashed predation by 40%. Goldberg says that research on lionfish derbies should offer insight into how often \u2014 and when \u2014 they should take place at each location. He adds that new steps might be needed, such as encouraging commercial fishing of lionfish to make the species more common in restaurants. The lionfish invasion and the success of the derbies has led to policy changes in Florida. In August, wildlife regulators relaxed hunting restrictions in the state to allow divers wearing rebreathers \u2014 devices that allow them to remain in the water for longer \u2014 to harvest lionfish. It will also now allow derby participants to spear lionfish in areas where spearfishing is otherwise prohibited. \u201cFor marine protected areas to function as conservation areas, it\u2019s important that the biology and ecology be conserved to the highest level possible, and that now requires lionfish control,\u201d says Morris. With her results pointing in a positive direction, Green intends to continue analysing data from lionfish derbies, including an event in Key Largo on 13 September. When she shares her research findings with the divers, it tends to fire them up, she says. \u201cThere\u2019s this good community feeling at the derbies that this is a tool that can have a positive effect and help to suppress the invasion.\u201d \n                     China battles army of invaders 2013-Nov-27 \n                   \n                     Invasive species: The 18-km2 rat trap 2013-May-15 \n                   \n                     Lionfish not a roaring success for coral reefs 2008-Jul-16 \n                   \n                     REEF Lionfish Derbies \n                   Reprints and Permissions"},
{"file_id": "513297a", "url": "https://www.nature.com/articles/513297a", "year": 2014, "authors": [{"name": "M Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "The sciences can be a sanctuary for gay, lesbian, bisexual and transgender individuals, but biases may still discourage many from coming out. \u201cI was the golden child,\u201d says Justin Trotter, thinking back to his teenage years living near the Kennedy Space Center in Brevard County, Florida. The handsome, articulate son of a devout Mormon family, he earned top grades, assembled winning projects for science fairs and worked in university laboratories from the age of 14. But he was also wrestling with a secret. Trotter, now a neuroscience postdoc at Stanford University in California, says that as early as the ages of 11 or 12 he had begun to sense that he was attracted to boys \u2014 a feeling that he had always been taught was shameful. So all through his teens and early twenties, he says, he struggled to keep his sexuality hidden, to appear masculine, to blend in. \u201cI dreaded dealing with it,\u201d says Trotter. By his undergraduate years at university he was suffering from exhaustion, depression and panic attacks. \u201cMy only escape was to work in the lab,\u201d he says: \u201cIt was my haven.\u201d But the stress took its toll even there. \u201cI felt my memory wasn\u2019t good. I wasn\u2019t as sharp as I could be.\u201d It was not until the last two years of his graduate studies, at the University of South Florida in Tampa, that Trotter finally came out, confiding to a few close friends that he was gay. As the word spread, he found his depression lifting. His energy improved. His work became more focused. \u201cWhen I felt I could just be who I am, a full person,\u201d says Trotter, \u201cthen it was definitely good for the science.\u201d That message is being heard in more and more laboratories and research centres around the world. People who identify as lesbian, gay, bisexual or transgender (LGBT) have long faced discrimination or worse: they are still considered outcasts or even outlaws in most Muslim nations, as well as in Russia and parts of Asia. But attitudes are changing. According to a survey published last year by the Pew Research Global Attitudes Project, openly gay individuals have high levels of public acceptance across broad swathes of Western Europe, Australia, Canada and Latin America (see \u2018Degrees of acceptance\u2019). Nowhere is this change more visible than in the United States, home of the world\u2019s largest research enterprise, where public attitudes are shifting towards acceptance of LGBT people faster than in almost any other nation. Courts and legislatures are lifting restrictions on same-sex marriage in state after state, often in the face of vehement opposition from social conservatives, and LGBT equality has emerged as a dominant civil-rights issue. \u201cThis is an important time in history for the LGBT community,\u201d says Trotter \u2014 not unlike the period several decades ago when women and under-represented ethnic minorities began their push for greater recognition in science. Just as those groups once did, LGBT researchers are trying to seize the moment by creating an infrastructure of organizations and interest groups geared towards helping one another with information, support and networking (see  Nature 505, 249\u2013251; 2014 ). \n               Out in the open \n             In this newly open environment, LGBT scientists are finding it easier to declare themselves \u2014 or at least, to think about doing so. \u201cI\u2019m getting a constant stream of e-mails from young scientists: \u2018Can I meet with you?\u2019,\u201d says Ben Barres, a Stanford neuroscientist who transitioned from female to male in 1997, and who has become a prominent spokesman for LGBT issues in science. But just as for ethnic minorities and women, there is still a long way to go. Many LGBT scientists fear coming out \u2014 if only because publications, career progression and promotion are based heavily on the judgement of fellow scientists, which might be influenced by conscious or unconscious bias. And many students may be avoiding a research career entirely \u2014 although no one knows, because no one has counted. \u201cI worry that there is a vast pool of talent that might be being lost to science,\u201d says Trotter. The only way to change that, he says, is for the scientific community to reach out to its LGBT members, and have an honest conversation. The lab can be an excellent place for that dialogue, says Kale Edmiston, a neuro\u00adscience graduate student at Vanderbilt University in Nashville, Tennessee. \u201cThe cool thing about scientists is that we try to withhold judgement and gather information,\u201d he says. That is exactly what happened when Edmiston began transitioning in 2010. He told everyone in his research group that he would be taking hormones and that his appearance would change. They responded with a combination of sympathy, interest and curiosity. \u201cA lot of my peers and colleagues have really listened and heard what I\u2019m saying,\u201d says Edmiston. Rachael Padman had much the same experience in the early 1980s, when she transitioned from male to female while a graduate student in astrophysics at the University of Cambridge, UK. \u201cOne colleague was never able to say \u2018she\u2019 instead of \u2018he\u2019,\u201d says Padman. \u201cBut that was just one in the last 35\u00a0years. From almost everyone else, I just never get any vibes at all.\u201d The mores of research can work the other way, too, says Vivian Underhill, a field hydrologist with the University of Colorado Boulder\u2019s Institute for Arctic and Alpine Research, and author of \u2018Queered Science\u2019: a blog series about LGBT researchers. \u201cAs scientists we like to think that we\u2019re objective,\u201d she says \u2014 that personal and social issues should be kept separate from the real work. \u201cAnd mostly that\u2019s a good thing,\u201d she says, but too often it leads people to assume that they can eliminate biases by not talking about them. \u201cThat just enables the fear to propagate.\u201d It can also make it hard to comprehend the stark loneliness that comes with being LGBT in a majority-straight world. Unlike women or ethnic minorities, LGBT people are not automatically born into a peer group, says Darrin Wilstead, director of operations for the Point Foundation, an LGBT scholarship and mentoring fund based in Los Angeles, California. Almost always, he says, \u201cthey come home to a family that does not share their identity\u201d \u2014 and may not understand or accept it. Everyone has to come to terms with their sexuality as they grow up. But LGBT individuals often have to begin that journey in isolation. Gay, lesbian and bisexual feelings typically emerge around the time of puberty \u2014 although they may start much earlier. \u201cWhen you\u2019re a kid, you just aren\u2019t as aware of who you\u2019re attracted to,\u201d says Eli Capello, an undergraduate neuroscience major at Centenary College of Louisiana in Shreveport. Transgender issues, by contrast, can become obvious at a very early age. \u201cI knew something was up when I was 3 and 4,\u201d says Capello, who transitioned when he was 18. \u201cI just didn\u2019t know what.\u201d \n               Growing pains \n             Many people lack basic knowledge about gender identity, which is different from sexual orientation. The latter concerns who a person is attracted to; gender identity is about the body someone is born into and whether it matches what the brain is insisting. Either way, LGBT individuals typically find themselves struggling to deal with all this in their teens and early twenties \u2014 precisely when science students are also supposed to be mastering their fields. Some respond by throwing themselves into their coursework. \u201cCollege was a great place to distract myself,\u201d says Underhill, who did not tell close friends that she was lesbian until just before her graduation. \u201cI didn\u2019t even allow myself to look for online sources that might have been helpful, because I didn\u2019t want to go there.\u201d But the kind of emotional turmoil that Trotter describes is also very common. According to the US Centers for Disease Control and Prevention in Atlanta, Georgia, gay, lesbian and bisexual teenagers generally experience high levels of bullying and drug abuse, and are more than twice as likely to attempt suicide as their heterosexual peers. The lack of data means that there is no way of knowing how often this leaves promising students too stressed to attempt challenging science, technology, engineering or mathematics (STEM) degrees. But anecdotal evidence suggests that it does happen. At the Point Foundation, says Wilstead, \u201cwe found out that some areas of studies, like law, medicine and STEM, were much more challenging\u201d for scholarship recipients trying to maintain their grades. And that, in turn, may help to explain why only about 10% of the foundation\u2019s applicants were in STEM fields until five years ago, when the foundation began vigorous outreach efforts that helped to raise the fraction to around 20%. Adding to the loneliness and stress is the highly charged decision of whether to come out at all. To stay in the closet perpetuates the turmoil, but the consequences of not staying there can be awful. After Capello came out as transgender at age 16, for example, his relationship with his family deteriorated to the point at which he had to leave home and attend a boarding school paid for by his grandmother. Jun Ding, a Stanford neuroscientist who grew up in Shanghai, China, before moving to the United States for his PhD relates a different kind of experience. Although Chinese laws that were used to discriminate against gay people were repealed in 1997, there are no protections and very little public discourse on the subject. Ding says that his parents still do not understand when he tries to explain that he is now living with his husband, whom he married under California law. \u201cIt\u2019s not like the US, where almost every movie has a gay role,\u201d he says. \u201cIn China, a lot of people just don\u2019t have the concept of gay life.\u201d \n               Peer pressure \n             Even if family rejection is not a concern \u2014 and it seems to be less common than it once was, says Wilstead \u2014 the decision is not necessarily any easier. More than in almost any other field, a researcher\u2019s career is based on peer review in the widest sense, says Eric Patridge, a chemist at Yale University in New Haven, Connecticut, and president of Out in Science, Technology, Engineering, and Mathematics, a national LGBT student group. Colleagues\u2019 opinions weigh heavily when it comes to funding, collaboration, publication, hiring, promotion and almost every other decision. In a highly competitive environment, every LGBT researcher has to worry that coming out will trigger unconscious biases that could ruin his or her chances. Studies from the US National Institutes of Health over the past few years suggest that such bias may well be a problem for other minorities (see  Nature 512, 243; 2014 ), and there is no reason to think that LGBT researchers are exempt. That may be why Barres hears from many young LGBT scientists who are afraid to come out, even in the San Francisco Bay Area of California, historically one of the most tolerant regions in the United States. And it is worse in the more socially conservative regions of the country: \u201cWhen I talk to people from down south, the fears are so much stronger,\u201d he says. Those fears are justified, says Trotter. After he came out during his graduate studies in Florida, he says, some of the more religious, socially conservative students in his research group became noticeably reticent around him. \u201cThe scientific community is still comprised of people at varying stages of social progress in ideas,\u201d he says \u2014 a reality that he has not escaped. He is very comfortable at Stanford, he says. But once his postdoc appointment there is over, he may well have to apply for tenure-track jobs back in Florida or another less-tolerant part of the country \u2014 \u201cwhere my ability to acquire tenure or run a successful research programme would be in question\u201d. And that is just in the United States. Scientists and science students seem to be equally reticent in LGBT-friendly Western Europe \u2014 and even more so in China. In many parts of the Middle East and Africa, moreover, LGBT activity is punishable by law \u2014 in some cases, with execution (see  Nature 509, 274\u2013275; 2014 ). \u201cSo if you\u2019re a chemist or geologist for an oil company, you\u2019d better be in the closet if they send you to one of those countries,\u201d says Rochelle Diamond, who chairs the board of directors of the National Organization of Gay and Lesbian Scientists and Technical Professionals in Pasadena, California. \n               Difficult conversation \n             Coming out can be even more daunting for transgender people \u2014 especially if the announcement coincides with the start of sex-reassignment treatments. Added to the emotional stress and professional concerns are the physical effects of interventions such as taking hormones. \u201cThere\u2019s a reason you\u2019re supposed to go through puberty before you get to college,\u201d says Capello. Kate Forbes, who now works for a medical information-technology company, transitioned while she was earning her doctorate in ecology at the University of Wisconsin\u2013Madison; she describes nights curled up in pain on her futon after electrolysis treatments to get rid of the hair on her legs. Then there are the awkward conversations. \u201cEvery time I\u2019d start a course I would have to have a very personal discussion with the professor about things like male pronouns,\u201d says Lucas Cheadle, a neuroscience postdoc at Harvard University in Cambridge, Massachusetts. Making the situation doubly difficult was that he transitioned while he was an undergrad\u00aduate at Smith College \u2014 a women\u2019s university in Northampton, Massachusetts. \u201cI missed out on a lot of mentorship relations because of the difficulty of explaining,\u201d he says. Even ordinary paperwork can become a major burden. Newly transitioned individuals can spend endless hours struggling to convince sceptical bureaucrats that they have a legitimate claim to their own university transcripts, publication lists, birth certificates, driving licences, credit cards and more \u2014 all now in a different name. Even in tolerant Western Europe, officials may demand extensive documentation before making the required changes, says Padman. \u201cBritain is quite unusual in that respect,\u201d she adds: the Gender Recognition Act 2004 declares that each individual is the gender he or she decides to be. \u201cThey can get a new birth certificate with the new gender, and have all the legal rights of the acquired gender.\u201d Backing that up is the Equality Act 2010, which forbids discrimination again trans people. \u201cIt discourages the tabloids from making a huge deal about someone\u2019s sex reassignment on the front page, the way they used to,\u201d says Padman. The United States has certainly not gone as far towards recognition as Britain. But even so, the situation seems to be improving rapidly for younger LGBT people \u2014 not least because of the Internet. \u201cWhen Point was founded 13\u00a0years ago,\u201d says Wilstead, \u201cour scholars were saying that they couldn\u2019t find anyone who was older, gay and successful.\u201d But today, thanks to Facebook, Twitter and the plethora of other social-media sites, it is much easier to make such connections. And one consequence, says Wilstead, is that LGBT people are coming out much earlier than they used to. Jack Andraka, for example, was a 15-year-old student in Crownsville, Maryland, when he won the grand prize at the 2012 Intel International Science and Engineering Fair, for discovering a test for pancreatic, ovarian and lung cancer. He had come out as gay when he was 13. Another consequence is an increased sense of solidarity in the LGBT community itself. The group was once defined only by what its members are not: straight. \u201cAside from that,\u201d says Underhill, \u201cmy experience as a white lesbian woman may have little in common with that of a black gay man.\u201d That is a point echoed by many others: their \u2018community\u2019 is often riven by the same fault lines as the society around it, with gay white men dominant, and women, bisexuals and ethnic minorities each feeling marginalized in their own ways. And only in the past five years or so have transgender individuals begun to become more visible. But the rising generation tends to be much more concerned about inclusion, says Wilstead. Witness the embracing of the once-derogatory term \u2018queer\u2019. \u201cIt\u2019s an umbrella term,\u201d he says. \u201cIt\u2019s basically saying, \u2018I am just different\u2019.\u201d That openness and solidarity, in turn, is making it much easier for young scientists to find mentors and role models. It is impossible to overemphasize how important that is, says Trotter \u2014 \u201cseeing that it really does get better, seeing gay and lesbian scientists who have been through it and made it\u201d. But the scientific establishment could give a lot more help in promoting role models than it has so far, say LGBT activists. Barres thinks that the US National Academy of Sciences missed a golden opportunity when he was elected to membership last year. \u201cI asked if they would include in the announcement that I was the first transgender scientist to be elected,\u201d he says. \u201cThey never did.\u201d (Electrical engineer Lynn Conway was elected to the parallel National Academy of Engineering in 1989, although she did not come out as transgender for another decade.) The scientific establishment could also do a lot more about collecting basic data. For example, the US National Science Foundation, which compiles detailed statistics about women, under-represented minorities and the prevalence of various disabilities among US researchers and STEM students, does not currently ask about LGBT identification. Nor do there seem to have been systematic, large-scale studies of the social environment for LGBT researchers. How much stress do they really feel if they stay closeted in the lab? What are the actual effects on their health and productivity? And if they do come out, are they really less likely to be funded, hired or promoted? At least one team \u2014 sociologists Erin Cech of Rice University in Houston, Texas, and Tom Waidzunas of Temple University in Philadelphia, Pennsylvania \u2014 is hoping to carry out a survey of 2,000\u20133,000 LGBT scientists and engineers, but has yet to get funding. Without such data, says Trotter, it is impossible for the funding agencies to know whether LGBT people are over- or under-represented in the research fields, whether there is a need for more support programmes and counselling, or whether they should offer special fellowships for young LGBT researchers in the way they now do for women and minorities. \u201cWe don\u2019t have numbers,\u201d says Trotter, \u201cand that\u2019s frustrating for us as scientists.\u201d Still, without minimizing the challenges that remain, older LGBT scientists stress how far the world has come in a remarkably short time. \u201cWhen I\u2019m contacted by young people,\u201d says Barres, \u201cI always tell them that the fears are so much greater than the reality. And I always encourage them to be open, because they will be so much happier. If you\u2019re doing good science, if you\u2019re a great teacher \u2014 that\u2019s what matters.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Equality: Standing out 2014-Jan-08 \n                   \n                     Ethics: Taboo genetics 2013-Oct-02 \n                   \n                     Benefits blues 2008-Jul-03 \n                   \n                     Does gender matter? 2006-Jul-12 \n                   \n                     Nature  and  Scientific American  special: Diversity \n                   \n                     National Organization of Gay and Lesbian Scientists and Technical Professionals \n                   \n                     Out in Science, Technology, Engineering, and Mathematics \n                   \n                     Point Foundation \n                   \n                     LGBT Science \n                   \n                     Pew Research: The Global Divide on Homosexuality \n                   \n                     International Lesbian, Gay, Bisexual, Trans and Intersex Association \n                   Reprints and Permissions"},
{"file_id": "513474a", "url": "https://www.nature.com/articles/513474a", "year": 2014, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "A hospital in Sierra Leone has struggled to continue its research amid the worst Ebola outbreak in history. Robert Garry had a bad feeling about the tin roof teetering above his head. It was June, and he and a colleague, Sheik Humarr Khan, were surveying a makeshift shelter that was to serve as a temporary Ebola ward for Kenema Government Hospital in Sierra Leone. They could see that the only thing holding the metal sheets to a 5-metre-tall wooden frame was a handful of thin, twisted wires. Half an hour later, at a meeting in the main hospital building, the men were interrupted by a tremendous crash. As the sound reverberated through the hospital grounds, Garry and Khan rushed back outside to see what had seemed inevitable: the precarious structure had collapsed. It was an omen of things to come. In less than a month, the hospital\u2019s operations would topple under the weight of the worst Ebola outbreak in history. The wards were overwhelmed with patients and Khan, an infectious-disease physician at Kenema, and many of his staff were among those fighting for their lives. The epidemic has killed more than 2,600 people since it began in December 2013, and it could infect tens of thousands more by the end of this year, according to the World Health Organization (WHO). Three countries \u2014 Guinea, Liberia and Sierra Leone \u2014 have been the epicentre, struggling with weak health systems and a wholly inadequate global aid response, even after the WHO declared the epidemic an international public-health emergency in early August (see   Naturehttp://doi.org/vsc;2014 ). Khan and his team came to the fight against Ebola armed with experience battling another virus: Lassa, which like Ebola causes a life-threatening illness that sometimes results in haemorrhagic fever. But Lassa has much more predictable annual infection cycles. Along with Garry, a virologist at Tulane University in New Orleans, Louisiana, and an international team of scientists, Khan had spent the better part of a decade building a Lassa treatment and research programme at Kenema, including a dedicated ward and a modern diagnostic laboratory. The ward they were adding was the next step in their arsenal against the disease. But before it could be completed, the Lassa lab diagnosed Sierra Leone\u2019s first case of Ebola. Hundreds more followed. And a medical facility that had been set up to study one disease suddenly found itself overwhelmed by another. Researchers worked hard to study the disease that was filling the wards \u2014 to trace its path into and through the country. But the outbreak consumed the hospital, and research was put on hold. It became clear that even if science could inform the outbreak response, the much more pressing need was for health resources and humanitarian aid. \u201cThere\u2019s a question of research\u2019s role here,\u201d says Pardis Sabeti, a computational geneticist at the Broad Institute in Cambridge, Massachusetts, who has worked with the Kenema team since 2008. Too frustrated to stand on the sidelines, she and other US researchers called for more aid to be sent to Kenema, but found the response painfully slow. \u201cOur friends needed support and every international organization we turned to was stretched too thin.\u201d \n               A shining example \n             Khan knew the risks of working on haemorrhagic fevers: he became the lead Lassa doctor at Kenema after his predecessor died of the disease. Lassa infects 300,000 to 500,000 people a year and kills between 5,000\u00a0and 20,000 of those. The hospital in Kenema had been treating patients in its Lassa ward for decades, even struggling through a bloody civil war that lasted from 1991 to 2002. Its expertise made it an ideal nucleus for a group called the Viral Hemorrhagic Fever Consortium, which started in 2010 and included scientists from Kenema, Tulane and other partners in West Africa and the United States. One of the main obstacles that doctors faced was diagnosing diseases quickly enough to treat them; after the war, no lab in Africa had the technology to detect Lassa in a patient\u2019s blood. So in 2005, Kenema built a lab and developed a diagnostic test. Sabeti, one of the founding members, began to sequence samples to understand how the disease spread through West Africa. In May, Sabeti, Khan and Garry met in Nigeria to celebrate an enormous step forward for their work. In October, the World Bank and the US National Institutes of Health had funded a Centre for Genomics of Infectious Disease led by a collaborator in Ogun State, Nigeria, and the institute was hosting its inaugural meeting. The centre would use genetic technologies to study microbes in West Africa; it would soon acquire the first high-throughput sequencer in the region, meaning that Kenema would no longer have to send samples of Lassa and other viruses overseas for in-depth sequencing. The partnership was becoming a shining example of scientific collaboration on the continent, building infrastructure and experience from within rather than importing it all from abroad. Everyone was buoyed by the news, and by the progress in Sierra Leone, where, with a grant from the US Navy, Kenema was building its new Lassa ward. The ward would have 48 beds \u2014 almost double the capacity of the current ward. It would have air conditioning to help nurses and doctors, who often had to wear stifling protective gear in oppressive equatorial heat. And it would be safer, with features such as a tiled floor and a drainage system, so that a worker could clean it out just by hosing it down. People with haemorrhagic fevers shed the virus in their blood, vomit, diarrhoea, sweat and tears. In the old Lassa ward, with its concrete floors, staff risked infection every time they slogged through the waste with a broom. But the team knew that trouble was coming. When Guinea, to the north, notified the WHO about its Ebola cases in March (see \u2018Ebola\u2019s epicentre\u2019), Garry predicted that Kenema would be next. He and Sabeti shipped trunks of protective gear to Kenema. Researchers from Sabeti\u2019s lab travelled there with the genetic probes needed to diagnose Ebola. In May, the first cases arrived. A woman turned up with a fever, and was bleeding heavily after a miscarriage. She and 13 others had become infected at the funeral of a traditional healer who had been treating Ebola victims in neighbouring Guinea. On 25 May, Augustine Goba, head of the Lassa diagnostic lab, confirmed that these people had brought the virus into Sierra Leone. They were admitted to Kenema\u2019s Lassa ward. Garry flew in right away to help make sure that the Kenema staff were prepared. They needed to swap out their usual gowns and masks for Tyvek \u2018bunny\u2019 suits that cover the whole body in a waterproof barrier. Garry also made sure that the technicians were collecting, decontaminating and packing blood samples from patients after they had been used in diagnosis, so that Sabeti could sequence the DNA at the Broad Institute. At first, the patients arrived slowly \u2014 too slowly. In early June, workers tracing the contacts of infected individuals could see that there were many more people who were potentially infected than there were in the hospital. But Ebola had never before come to West Africa, and people were spreading the disease without knowing it, simply by caring for the sick and burying the dead. Whole villages would be wiped out. Khan suspected that Kenema would soon see a wave of cases, so he ordered the construction of the new, temporary ward. (After the first structure collapsed, workers rebuilt it with a shorter, sturdier roof). His prediction was right: by the end of June, the old Lassa ward was overwhelmed and suspect cases were being admitted to the temporary one. Patients began to flood in from all over eastern Sierra Leone. Everyone was sending patients to Kenema Government Hospital; there was nowhere else to go. Supplies and staff were thin on the ground: M\u00e9decins Sans Fronti\u00e8res (MSF) and other aid groups were already stretched beyond capacity treating patients in Guinea and Liberia. The WHO had sent some staff to Kenema in June, but supplies were dwindling, and Khan was often the only doctor in charge of treating 80 people. He felt alone and afraid for his life. But he continued to care for his patients as best he could. \u201cIf I refuse to treat them, who would treat me?\u201d he told his sister. \n               A deadly chain of events \n             Back in Cambridge, Sabeti was analysing data from the samples that Garry had shipped out of Kenema. Her group now had 99 Ebola virus samples from the first 78 patients in the country\u2019s outbreak. The researchers were performing in-depth genetic sequencing to track the way the virus mutated as it passed from person to person. No one had ever gathered these kinds of data on an outbreak while it was unfolding. Important information was already emerging \u2014 for instance, that the whole outbreak could be traced to a single event in which an animal, probably a bat, transmitted the virus to a human. They also saw that the virus had accumulated hundreds of mutations since separating from an ancestral Ebola virus in Central Africa a decade ago (see   Naturehttp://doi.org/vsd;2014 ). It is the sort of work that could eventually change the way in which outbreaks are fought, says Anthony Fauci, head of the US National Institute of Allergy and Infectious Diseases (NIAID) in Bethesda, Maryland, which funded the work. \u201cWe would normally come out with an analysis like this two years after an outbreak is over,\u201d he says. \u201cTo be able to do this is just extraordinary.\u201d Sabeti\u2019s team released its data as quickly as it could, by 31 July. Among the first users were researchers who had been developing experimental drugs and vaccines for Ebola. These include the antibody cocktail ZMapp, which has since been given to seven individuals, not all of whom have survived, and a NIAID vaccine that entered human trials in early September. None of the mutations seen in the virus so far would render these products less effective, although some affect regions of the virus that are targeted by current diagnostic tests. Sabeti was in close contact with Khan throughout, and knew that the situation in Kenema was deteriorating fast. \u201cHe was concerned, and he was sort of still by himself, and not really getting the support he needed,\u201d Sabeti says. In late June, a feverish local chief was admitted to a private ward in Kenema that lacked the infection-control measures used in the Lassa ward. That started a deadly chain reaction: he infected five staff members, including a pregnant nurse. A midwife, Mbalu Fonnie, who was also the chief Lassa nurse, worked with three others to deliver the nurse\u2019s stillborn baby. She and the other nurses were all infected, almost certainly during the delivery. They all died. Fonnie\u2019s death on 21 July and the deaths of other senior nurses snapped a thread that had kept the hospital together. \u2018Aunty Mbalu\u2019 had been treating Lassa at Kenema for 25 years \u2014 throughout the civil war \u2014 and had survived a Lassa infection herself. Now she was gone. The next day, while in a lab meeting, Sabeti glanced at her e-mail and saw that there was a message about Khan. She opened it immediately: Khan had Ebola. \u201cI just broke down and started bawling,\u201d she says. Sabeti felt helpless. She wanted to do something \u2014 anything. So she wrote a white paper urging US officials to commit more supplies and money to fighting the outbreak, and sent it to Broad Institute director Eric Lander and other members of a board of science advisers to the US president. She and Garry had already travelled to Washington DC to ask health officials and Congress to send more aid; Garry had asked officials to send experimental vaccines and medicines. Now they urged doctors from MSF and the WHO to treat Khan with ZMapp. But the doctors feared that if something went wrong, it would undermine the already-fragile public trust in them, so they decided not to do it. With Khan now very ill, the Kenema hospital was on the verge of collapse. There were too many patients and too few staff to treat them, and supplies were dwindling. Fearing for their lives and feeling ill-equipped to do their jobs, the remaining nurses and lab technicians went on strike. The hospital as a whole had virtually shut down, except for its Ebola work. Tulane physician Daniel Bausch was working in the Ebola ward around that time. One day, he went into the ward with a WHO worker. \u201cThere were 50\u00a0patients and no nurses or other health workers in there. My first reaction was, we just need to close this centre. We can\u2019t say this offers any care.\u201d Still, they soldiered on, knowing full well that Kenema was a place of last resort for patients, who would only spread the disease if released. Meanwhile, hearing rumours that Ebola was a hoax or a conspiracy, people from the surrounding city attacked the hospital, throwing rocks at the building. Police used tear gas to drive the rioters away. On 29 July, Sabeti received a second e-mail from an epidemiologist in Sierra Leone. The message simply read: \u201cDr. Khan is gone.\u201d \n               Lassa looming \n             The period after Khan\u2019s death was the nadir of the outbreak in Kenema. The loss of its leader and of so many others was devastating. \u201cIt completely demoralized the community. It has completely torn them apart,\u201d says Joseph Fair, a virologist who has been working in Sierra Leone since 2004 and advised the country on its response to the current outbreak. Sabeti and her team were also shocked. \u201cWe loved that man,\u201d Sabeti says. By the time the paper on the sequencing of the first 78 cases was published ( S. K. Gire  et al. Science    345,  1369\u20131372; 2014 ), on 28 August, six of its authors, including Khan and Fonnie, had died. But by then, help had started to arrive. Workers from the WHO and MSF began to restock supplies of protective equipment. The International Committee of the Red Cross began building a treatment centre just outside Kenema. Kenema is still treating roughly 50\u00a0Ebola patients, but it is trying to wind down that work and reopen its general wards. But with all the attention now on Ebola, physicians who work in Kenema are concerned about Lassa. The peak Lassa season, November to April ( J. G. Shaffer  et al. PLoS Negl. Trop. Dis.    8,  e2748; 2014 ), is approaching, and of the hospital\u2019s original 36 specialized Lassa staff, 11 have now been infected and 6 have died. Surveillance staff, doctors, nurses, drivers, cleaners and lab technicians have all lost their lives to Ebola. New trainees and the remaining staff \u2014 including Ebola survivors \u2014 are stepping up to treat the cases that do arrive. But the hospital is seeing fewer Lassa patients than it would have expected for this time of year. \u201cWe think the patients are reluctant to come in,\u201d says Garry. \u201cThat\u2019s not good.\u201d Garry still hopes to make Kenema a centre of excellence for Lassa research by training African staff to carry out clinical trials on the best ways to track, diagnose and treat the disease. And the haemorrhagic-fever consortium plans to name the new ward after Khan when it is finally completed. The goal is to outfit it with a high-throughput genetic sequencer so that researchers there can study the circulating viruses all the time, and perhaps detect the next outbreak, of Ebola or otherwise, before it grows out of control. Garry has faith in Kenema\u2019s survivors. \u201cA lot of these people spent a good part of their childhoods hiding out in the bush from the rebels,\u201d Garry says, thinking back to the days of civil war. \u201cYou\u2019re talking about a very resilient group of individuals.\u201d Sabeti, Garry and their colleagues are now preparing for the next step in their research: sequencing samples from every Ebola patient seen at Kenema since 18 June. They hope that the data will reveal whether the virus is continuing to mutate at the same rate and in the same genetic regions as before, and whether the mutations seen in the current outbreak made different circulating viruses more or less able to transmit between people and cause death. The data will also tell a more personal story, revealing the precise path taken by the virus as it infected Khan, Aunty Mbalu and so many of their colleagues. They, too, are represented in the samples.\n Follow Erika on Twitter  https://twitter.com/Erika_Check Reprints and Permissions"},
{"file_id": "online-collaboration-scientists-and-the-social-network-1.15711", "url": "https://www.nature.com/news/online-collaboration-scientists-and-the-social-network-1.15711", "year": 2014, "authors": [], "parsed_as_year": "2011_2015", "body": "In 2011, Emmanuel Nnaemeka Nnadi needed help to sequence some drug-resistant fungal pathogens. A PhD student studying microbiology in Nigeria, he did not have the expertise and equipment he needed. So he turned to ResearchGate, a free social-networking site for academics, and fired off a few e-mails. When he got a reply from Italian geneticist Orazio Romeo, an inter\u00adnational collaboration was born. Over the past three years, the two scientists have worked together on fungal infections in Africa, with Nnadi, now at Plateau State University in Bokkos, shipping his samples to Romeo at the University of Messina for analysis. \u201cIt has been a fruitful relationship,\u201d says Nnadi \u2014 and they have never even met. Ijad Madisch, a Berlin-based former physician and virologist, tells this story as just one example of the successes of ResearchGate, which he founded with two friends six years ago. Essentially a scholarly version of Facebook or LinkedIn, the site gives members a place to create profile pages, share papers, track views and downloads, and discuss research. Nnadi has uploaded all his papers to the site, for instance, and Romeo uses it to keep in touch with hundreds of scientists, some of whom helped him to assemble his first fungal genome. More than 4.5 million researchers have signed up for ResearchGate, and another 10,000 arrive every day, says Madisch. That is a pittance compared with Facebook\u2019s\u00a01.3 billion active users, but astonishing for a network that only researchers can join. And Madisch has grand goals for the site: he hopes that it will become a key venue for scientists wanting to engage in collaborative discussion, peer review papers, share negative results that might never otherwise be published, and even upload raw data sets. \u201cWith ResearchGate we\u2019re changing science in a way that\u2019s not entirely foreseeable,\u201d he says, telling investors and the media that his aim for the site is to win a Nobel prize. The company now employs 120 people, and last June it announced that it had secured US$35\u00a0million from investors including the world\u2019s richest individual, Bill Gates \u2014 cash that came on top of two earlier rounds of undisclosed investment. \u201cIt was really a head-scratcher when we saw that,\u201d says Leslie Yuan, who heads a team working on networking and innovation software for scientists at the University of California, San Francisco. \u201cWe thought \u2014 who are these guys? How are they getting so much money?\u201d Yuan is not the only one who has been taken aback. A few years ago, the idea that millions of scholars would rush to join one giant academic social network seemed dead in the water. The list of failed efforts to launch a \u2018Facebook for science\u2019 included Scientist Solutions, SciLinks, Epernicus, 2collab and Nature Network (run by the company that publishes  Nature ). Some observers speculated that this was because scientists were wary of sharing data, papers and comments online \u2014 or if they did want to share, they would prefer do it on their own terms, rather than through a privately owned site. But it seems that those earlier efforts were ahead of their time \u2014or maybe they were simply doing it wrong. Today, ResearchGate is just one of several academic social networks going viral. San Francisco-based competitor Academia.edu says that it has 11 million users. \u201cThe goal of the company is to rebuild science publishing from the ground up,\u201d declares chief executive Richard Price, who studied philosophy at the University of Oxford, UK, before he founded Academia.edu in 2008, and has already raised $17.7\u00a0million from venture capitalists. A third site, London-based Mendeley, claims 3.1 million members. It was originally launched as software for managing and storing documents, but it encourages private and public social networking. The firm was snapped up in 2013 by Amsterdam-based publishing giant Elsevier for a reported \u00a345\u00a0million (US$76 million). Despite the excitement and investment, it is far from clear how much of the activity on these sites involves productive engagement, and how much is just passing curiosity \u2014 or a desire to access papers shared by other users that they might otherwise have to pay for. \u201cI\u2019ve met basically no academics in my field with a favourable view of ResearchGate,\u201d says Daniel MacArthur, a geneticist at Massachusetts General Hospital in Boston. In an effort to get past the hype and explore what is really happening,  Nature  e-mailed tens of thousands of researchers in May to ask how they use social networks and other popular profile-hosting or search services, and received more than 3,500 responses from 95 different countries. The results confirm that ResearchGate is certainly well-known (see  \u2018Remarkable reach\u2019 , and full results online at  go.nature.com/jvx7pl ). More than 88% of scientists and engineers said that they were aware of it \u2014 slightly more than had heard of Google+ and Twitter \u2014 with little difference between countries. Just under half said that they visit regularly, putting the site second only to Google Scholar, and ahead of Facebook and LinkedIn. Almost 29% of regular visitors had signed up for a profile on ResearchGate in the past year. This does not surprise Billie Swalla, an evolutionary biologist and director of the University of Washington\u2019s Friday Harbor Laboratories. Swalla says that she and most of her colleagues are on ResearchGate, where she finds the latest relevant papers much more easily than by following marine-biology journals. \u201cThey do send you a lot of spam,\u201d she says, \u201cbut in the past few months, I\u2019ve found that every important paper I thought I should read has come through ResearchGate.\u201d Swalla admits to comparing herself to others using the site\u2019s \u2018RG Score\u2019 \u2014 its metric of social engagement. \u201cI think it taps into some basic human instinct,\u201d she adds. Some irritated scientists say that the site taps into human instincts only too well \u2014 by regularly sending out automated e-mails that profess to come from colleagues active on the site, thus luring others to join on false pretences. (Indeed, 35% of regular ResearchGate users in  Nature \u2019s survey said that they joined the site because they received an e-mail.) Lars Arvestad, a computer scientist at Stockholm University, is fed up with the tactic. \u201cI think it is a disgraceful kind of marketing and I am choosing not to use their service because of that,\u201d he says. Some of the apparent profiles on the site are not owned by real people, but are created automatically \u2014 and incompletely \u2014 by scraping details of people\u2019s affiliations, publication records and PDFs, if available, from around the web. That annoys researchers who do not want to be on the site, and who feel that the pages misrepresent them \u2014 especially when they discover that ResearchGate will not take down the pages when asked. Madisch is unruffled by these complaints. The pages are marked for what they are, and are not counted among the site\u2019s real users, he says, adding: \u201cWe changed many things based on the feedback we got. But the criticism is relatively small, relative to the number of people who like the service.\u201d Academia.edu seems less well-known than ResearchGate: only 29% of scientists in the survey were aware of it and just 5% visited regularly. But it has its fans \u2014 among them climate scientist Hans von Storch, director of the Institute for Coastal Research in Geesthacht, Germany, who uses the site to share not only his papers, but also his interviews, book reviews and lectures. Price points out that Academia.edu has much higher web traffic than ResearchGate overall, perhaps because \u2014 unlike its rival \u2014 it is open to anyone to join. And for the 480 social science, arts and humanities researchers included in  Nature \u2019s survey, usage of the two sites was more closely matched. High numbers by themselves do not mean much, says Jan Reichelt, a co-founder of Mendeley (which scored 48% awareness and 8% regular visitors among scientists in  Nature \u2019s survey). \u201cWe\u2019ve moved away from mentioning \u2018start-up vanity metrics\u2019 as the key number,\u201d he says. \u201cIt doesn\u2019t tell you about the quality of interaction.\u201d To get a rough measure of that quality,  Nature  asked a subset of the most active respondents what they actually do on the sites they visit regularly (see  \u2018Idle, browse or chat?\u2019 ). The most-selected activity on both ResearchGate and Academia.edu was simply maintaining a profile in case someone wanted to get in touch \u2014 suggesting that many researchers regard their profiles as a way to boost their professional presence online (see  \u2018A battle for profiles\u2019 ). After that, the most popular options involved posting content related to work, discovering related peers, tracking metrics and finding recommended research papers. \u201cThese are tools that people are using to raise their profiles and become more discoverable, not community tools of social interaction,\u201d argues Deni Auclair, a lead analyst for Outsell, a media, information and technology consulting firm in Burlingame, California. By comparison, Twitter, although used regularly by only 13% of scientists in  Nature \u2019s survey, is much more interactive: half of the Twitterati said that they use it to follow discussions on research-related issues, and 40% said that it is a medium for \u201ccommenting on research that is relevant to my field\u201d (compared with 15% on ResearchGate). Laura Warman, an ecologist at the University of Hawaii at Hilo, echoes the views of many when she says that she has uploaded papers on Academia.edu to keep track of how often, where and when they are downloaded. \u201cI find it especially intriguing that my most downloaded paper is not my most cited work,\u201d she says. \u201cTo put it bluntly, I have no idea if these sites have any impact whatsoever on my career \u2014 I tend to doubt they do \u2014 but I enjoy knowing that my work is being discussed.\u201d Price says that 3 million papers have been uploaded to Academia.edu, and Madisch says that 14\u00a0million are accessible through ResearchGate (although he will not say how many of those have been automatically scraped from freely accessible places elsewhere). An unpublished study conducted by computer scientists Madian Khabsa at Pennsylvania State University in University Park and Mike Thelwall at the University of Wolverhampton, UK, suggests that by August this year, the full texts of around one-quarter of all molecular-biology papers published in 2012 were available from ResearchGate. That said, these days papers are easily found on many sites: a study conducted for the European Commission last year found that 18% of biology papers published in 2008\u201311 were open access from the start, and said that 57% could be read for free in some form, somewhere on the Internet, by April 2013 (see  Nature  500,  386\u2013387; 2013 ). Publishers are worried that the sites could become public troves of illegally uploaded content. In late 2013, Elsevier sent 3,000 notices to Academia.edu and other sites under the US Digital Millennium Copyright Act (DMCA), demanding that they take down papers for which the publisher owned copyright. Academia.edu passed each notice on to its users \u2014 a decision that triggered a public outcry. One researcher who received a take-down request did not want to be named, but told  Nature : \u201cI hardly know any scientists who don\u2019t violate copyright laws. We just fly below the radar and hope that the publishers don\u2019t notice.\u201d These concerns are not unique to large social networks, says Price; the same issue surrounds content posted in universities\u2019 online repositories (to which Elsevier also sent some DMCA notices last year). \u201cThis is really part of the wider battle where academics want to share their papers freely online, whereas publishers want to keep content behind a paywall to monetize it,\u201d he says, noting the nuance that many publishers allow researchers to upload the final accepted version of a manuscript, but not the final PDF. He has seen fewer take-down notices this year. Giant social networks could also disrupt the research landscape by capturing other public content. In March this year, ResearchGate launched a feature called Open Review, encouraging users to post in-depth critiques of existing publications. Madisch says that members have now contributed more than 10,000\u00a0such reviews. \u201cI believe that this is just the tip of the iceberg,\u201d he says. He wants users to upload raw data sets too \u2014 including, perhaps, negative results that might otherwise never be published \u2014 and says that 700 are appearing on the site each day. At Academia.edu, Price is planning to launch a post-publication peer-review feature as well. \u201cWe have to build better filter systems to explain what research you can trust,\u201d he says. Few would argue with these goals, but many wonder why researchers would deposit their data sets and reviews on these new social networks, rather than elsewhere online \u2014 on their own websites, for example, in university repositories, or on dedicated data-storage sites such as Dryad or figshare (see  Nature   500,  243\u2013245; 2013  \u2014 figshare is funded by  Nature\u2019 s parent company, Macmillan Publishers). To Madisch, the answer lies with the social sites\u2019 burgeoning communities of users \u2014 the famed \u2018network\u2019 effect. \u201cIf you post on ResearchGate, you are reaching the people who matter,\u201d he says. But Titus Brown, a computational scientist at Michigan State University in East Lansing, is concerned about the sites\u2019 business plans as they seek to survive. \u201cWhat worries me is that at some point ResearchGate will use their information to make a profit in ways that we are uncomfortable with \u2014 or they will be bought by someone who will do that,\u201d he says. Madisch says that ResearchGate will not sell its user data, and that it already makes some money by running job adverts (as does Academia.edu). In the future, he hopes to add a marketplace for laboratory services and products, connecting companies and corporate researchers to academics (28% of the network\u2019s users are from the corporate world, he says). Price talks about providing institutional analytics to universities as well. But analysts including Auclair argue that the sites have limited earning potential, because they are targeted at a much narrower demographic than Facebook or Twitter. \u201cWhat\u2019s most likely is the networks that have critical mass get acquired and those that don\u2019t will die,\u201d she says (although Madisch says that being bought out \u201cwould be a personal failure\u201d). Mendeley\u2019s acquisition by Elsevier last year left the site better placed to become a global platform for research collaboration, says Reichelt, because it intersects with other Elsevier products such as the Scopus database of research articles. Much of the collaboration done using Mendeley is private, but the firm does allow other computer programs to automatically pull out useful anonymized public information \u2014 such as which papers are viewed most by which researchers. Neither Academia.edu nor ResearchGate yet offer this service, although Madisch says that he is developing it. \u201cI think at some point there will be one winner in this race,\u201d says Madisch. Or \u2014 as  Nature \u2019s survey suggests is already happening \u2014 different disciplines might favour different sites. Some analysts argue that despite their millions of users, massive social academic networking sites have not yet proven their essential worth. \u201cThey are nice-to-have tools, not need-to-have,\u201d says Auclair. But Price says that the networks are on the front line of a trend that cannot be ignored. \u201cWe saw the changes in the market, and we could see that academics wanted to share openly. The tide is starting to turn in our direction.\u201d"},
{"file_id": "514024a", "url": "https://www.nature.com/articles/514024a", "year": 2014, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "After humans arrived in South America, they quickly spread into some of its most remote corners. From the mouth of a cave high in the Andes, Kurt Rademaker surveys the plateau below. At an altitude of 4,500 metres, there are no trees in sight, just beige soil dotted with tufts of dry grass, green cushion plants and a few clusters of vicu\u00f1as and other camel relatives grazing near a stream. The landscape looks bleak, but Rademaker views it through the eyes of the people who built a fire in the rock shelter, named Cuncaicha, about 12,400 years ago. These hunter-gatherers were some of the earliest known residents of South America and they chose to live at this extreme altitude \u2014 higher than any Ice Age encampment found thus far in the New World. Despite the thin air and sub-freezing night-time temperatures, this plain would have seemed a hospitable neighbourhood to those people, says Rademaker, an archaeologist at the University of Maine in Orono. \u201cThe basin has fresh water, camelids, stone for toolmaking, combustible fuel for fires and rock shelters for living in,\u201d he says. \u201cBasically, everything you need to live is here. This is one of the richest basins I've seen, and it probably was then, too.\u201d Rademaker is one of a growing number of young archaeologists investigating how hunter-gatherers first colonized South America at the close of the Pleistocene epoch, when the last Ice Age was waning. Casting aside old dogmas, these researchers are finding that people arrived significantly earlier than previously believed, and adapted rapidly to environments from the arid western coastline to the Amazon jungle and the frosty heights of the Andes. By teaming up with geologists, climate scientists and other researchers, archaeologists are gaining a clearer picture of what the ancient environments were like and how people migrated across the landscape \u2014 clues that are leading them to other ancient occupation sites. \n               Hidden ancestry \n             \u201cThe archaeology that's being done in South America is becoming more scientific with the development of new methodologies, and there's a level of collegiality developing among younger researchers,\u201d says Rademaker. \u201cWe're all really excited about the new developments that are coming faster and faster.\u201d But researchers are racing against time as South American countries rapidly expand mining, road building and other activities that threaten to obliterate evidence from promising sites. For decades, a fractious attitude prevailed over research on the earliest people in the Americas. One of the most acrimonious disputes concerned a site in southern Chile called Monte Verde, which Tom Dillehay, an anthropologist now at Vanderbilt University in Nashville, Tennessee, excavated in the 1970s and 1980s. He found evidence of human occupation 1  that he dated to about 14,500 years ago. Dillehay's conclusions regarding Monte Verde put him in direct conflict with the accepted wisdom among leading archaeologists that people from Siberia did not spread across North America and venture south before around 13,000 years ago. That is the age of the Clovis culture, a group of big-game hunters who used distinctive spear points that are found littered across the United States. The Clovis people were thought to be the pioneers in North America, and many archaeologists there dismissed Dillehay's claim that Monte Verde was older. But antagonism has faded over the past six years, as convincing evidence of pre-Clovis sites has emerged in North America (see  Nature   485 , 30\u201332; 2012 ). Meanwhile, South American archaeologists, who were never as sceptical as their northern colleagues, have found more sites dated between 14,000 and 12,000 years ago, indicating that hunter-gatherers had spread through South America before and during the rise of the Clovis culture in the north. Now that researchers have moved beyond that debate, they are making greater headway in studying when people reached South America and what they did when they got there. Rademaker's finds in the Andes are helping to answer those questions \u2014 and pose new ones. His journey began 150 kilometres away from the Andes cave, on Peru's arid coast at Quebrada Jaguay, where Daniel Sandweiss, an anthropologist at the University of Maine and Rademaker's graduate adviser, was excavating a site that dated to the end of the last Ice Age, between 13,000 and 11,000 years ago. Sandweiss had uncovered the remains of seafood meals, as well as flakes of obsidian produced as people chipped at the glassy mineral to make stone tools 2 . There are no obsidian deposits along that coastline, so the material must have come from formations high in the Andes. Rademaker travelled into the mountains and found a large outcrop of the obsidian known as Alca 3  at Mount Condorsayana in 2004. Over the next three years, he studied the obsidian deposits and evidence of past glaciation in the area with geologist Gordon Bromley of the University of Maine. Those field trips gave Rademaker his first glimpse of the Pucuncho Basin, an alpine wetland with a stream, numerous vicu\u00f1as, llamas and alpacas, and a ready supply of cushion plants, which the researchers discovered are rich in resin and can burn easily. The basin was also littered with points and shards left by early toolmakers. Hiking down the stream, he glanced up the hill to his left and saw a yawning gap \u2014 the Cuncaicha rock shelter, which he began excavating in 2007. \u201cThis is the first time we've found a site this old in the high Andes,\u201d Rademaker says. On a day in August, he wraps a bandana over his mouth and nose and shovels dirt into buckets to fill in an excavation pit that is no longer needed. As he works, his shirt sleeve pulls up, revealing a glimpse of meticulously detailed hominin skulls tattooed up his right arm \u2014 from  Australopithecus afarensis  near his wrist to  Homo sapiens  on his shoulder. This late in the field season, his field trousers are frayed and he has had to bind his left hiking boot with several strata of duct tape. A chilly breeze whips across the Pucuncho plateau as some of Rademaker's companions struggle with the thin air. As well as cautioning his team members to prepare for the cold, Rademaker ensures that they acclimate gradually to the lack of oxygen. Even while battling the extremes, the team has gathered evidence contradicting the conventional wisdom that the mountains were too high, cold and inhospitable for early human habitation. Bromley's data show that at the end of the last Ice Age, glaciers were mainly confined to some alpine valleys, and Pucuncho and other areas were not glaciated. Palaeoclimate data indicate that the environment was probably wetter then, so there might have been more plants and animals available for the early residents, says Rademaker. \u201cThese Palaeo-Indians were able to live in one of the most extreme environments on Earth, at the end of an ice age, and they seem to have done so quite successfully,\u201d he says. \u201cThis tells us that Palaeo-Indians were capable of living just about anywhere.\u201d There are large numbers of animal bones, mainly from deer and vicu\u00f1as, in the earliest layers of sediment in the Cuncaicha rock shelter, showing that the inhabitants found abundant game on the plateau. And some of the tools were made of stone not available in the area, indicating that residents of the cave either travelled outside the region or exchanged materials with other groups that did. Some tools show traces of plant starch, which the researchers hope to analyse to work out what the cave-dwellers ate, and whether they domesticated tubers or other plants. The researchers have also found a fragment from a human skull at the site. It has not yielded DNA and its age is uncertain, but it hints that the cave could contain early human remains, says Rademaker. \n               Tool trade \n             Farther south, C\u00e9sar M\u00e9ndez has followed similar clues in his search for late-Pleistocene sites along the Chilean coast. Beginning in 2004, M\u00e9ndez, an anthropologist at the University of Chile in Santiago, and his colleagues excavated an ancient encampment, which they dated to around 13,000 years ago 4 . Some of the stone tools at the site, called Quebrada Santa Julia, were made of translucent quartz that is not found in coastal deposits. Like Rademaker, M\u00e9ndez mapped potential paths towards known quartz deposits inland. Sampling along those routes, his team found an outcrop of translucent quartz at a site where people had lived and quarried between 12,600 and 11,400 years ago. The similarity with Quebrada Santa Julia in terms of age and tool-making techniques suggests that the coastal tools came from these mountain outcrops. \u201cWhat we're seeing is that 12,000 years ago or more, these groups already had networks, knew the landscape and moved between the coast and the interior,\u201d says M\u00e9ndez. Sites such as Quebrada Jaguay and Quebrada Santa Julia suggest that some early hunter-gatherers in South America might have travelled along the coast, taking advantage of the fish, shellfish, animals and plants found in wetlands and near river deltas, says Dillehay. He is finding more evidence beneath Huaca Prieta, a 32-metre-high mound on the coast of northern Peru (see 'Conquering a continent'). The mound was first excavated in the 1940s, but Dillehay dug deeper and uncovered traces of Ice Age settlements in 2010. Radiocarbon dating indicates 5  that humans had lived there as much as 14,200 years ago, when the area was surrounded by wetlands. \n               Coastal drift \n             If early people did migrate along the coast, some of the best evidence has probably been swallowed up by the ocean. At the end of the Pleistocene, melting ice sheets caused sea levels to rise by 70 metres, which would have flooded much of the former coastline. That effect would have been greatest in some regions of eastern South America, where the land is relatively flat and the ocean migrated well inland. At the border between Uruguay and Argentina, for example, archaeologists suspect that ancient people might have hunted and camped on a broad delta that formerly existed at the mouth of the Uruguay River. But any such sites would have been drowned when the sea advanced by more than 120 kilometres, says Rafael Su\u00e1rez, an archaeologist at the University of the Republic in Montevideo. Su\u00e1rez has looked for clues upriver, and has dated several residential sites to between 12,900 and 10,200 years ago. Some tools found at a site called Pay Paso are made of translucent agate, which apparently came from quarries near the border with Brazil about 150 kilometres away. And other tools from Uruguay have been found 500 kilometres to the south in Argentina's Buenos Aires province 6 , says Nora Flegenheimer, an archaeologist with the National Scientific and Technical Research Council (CONICET) in Necochea, Argentina. Such finds point to widespread trade or travel routes in eastern South America. Some archaeologists wonder whether early residents of the continent might even have crossed the Andes. Bolivian archaeologist Jos\u00e9 Capriles of the University of Tarapac\u00e1 in Arica, Chile, has raised that possibility after studying 12,800-year-old artefacts at Cueva Bautista, a rock shelter 3,930 metres above sea level in southwestern Bolivia. He notes that a similarly aged site exists at the same latitude in Chile on the western slope of the Andes. Future research could explore tools found at both sites to see whether people migrated from one side to the other or established trading routes. But some of the best evidence for Pleistocene humans in South America may disappear soon, owing to rapid expansion in industrial-scale agriculture, road building and other forms of development. Those human threats come on top of the natural ones \u2014 wind erosion and changing watercourses \u2014 that constantly alter landscapes. Su\u00e1rez and his team had to call the navy to evacuate them from a site in Uruguay last December, when floodwaters rose dangerously in the lake behind a nearby hydroelectric dam. A proposed dam could also flood sites in the Oco\u00f1a River valley in Peru, which Rademaker thinks could have been an early route from the coast to the Andes. In the highlands, the rapid expansion of mining can be both a bane and a blessing. Archaeologists discovered Bolivia's Cueva Bautista site during a survey for a road leading to a mine. But open-pit mines threaten many other sites, says Capriles. Archaeological surveys must be carried out before development and infrastructure projects can go ahead, but the people who perform such studies do not always recognize the subtle signs of ancient human occupation, the researchers say. And even if the surveys do turn up important archaeological evidence, developing countries are often reluctant to let the past stand in the way of the future. \u201cI've never seen such destruction as you get in Peru,\u201d says Dillehay. He has witnessed bulldozers ravage sites and landowners destroy evidence to avoid delaying construction work. There are no signs yet of such activity reaching Rademaker's survey site in the high Peruvian Andes. Over the past decade, he and his colleagues have extensively explored the region on foot in an effort to determine whether the inhabitants of the Cuncaicha rock shelter traded for their exotic tools and whether they lived there year-round. The answers may lie in undiscovered occupation sites between the cave and the coast, so Rademaker is exploring likely avenues, mapping the routes that would have required the least energy expenditure while providing access to water and food. The researchers have backpacked along dozens of streams and rivers, sometimes clambering up steep cliffs to avoid flash floods, always with an eye out for gashes in the rock face that signal a potential shelter. Early inhabitants probably would have explored the new landscape in the same way with the same targets in mind. Rademaker surveyed four rock shelters this year but all of them were inhabited too recently \u2014 only 4,000 to 6,000 years ago. Still, he is convinced that there are more late-Pleistocene sites in the Andes. Early inhabitants must have found other places like the Pucuncho Basin and the Cuncaicha rock shelter. They might have followed rivers that flow from the highlands to the coast. Or perhaps they trailed the herds of wild guanacos that still descend along spurs of the Andes nearly to the ocean shore. Each field season dangles more possibilities before Rademaker's team. \u201cI went for a walk one night, found another confluence and found another cave,\u201d he says. \u201cIt's never-ending.\u201d \n                     Palaeogenomics: Genetic roots of the first Americans 2014-Feb-12 \n                   \n                     Ancient migration: Coming to America 2012-May-02 \n                   \n                     Stone tools cut swathe through Clovis history 2011-Mar-24 \n                   \n                     Oldest American artefact unearthed 2009-Nov-05 \n                   \n                     Early Americans had a coastal diet 2008-May-08 \n                   \n                     Palaeoanthropology: Tracking the first Americans 2003-Sep-04 \n                   \n                     Nature special: Peopling the planet \n                   \n                     Center for the Study of the First Americans \n                   \n                     Late Pleistocene in South America \n                   \n                     Radiocarbon database for Central & South America (Quaternary International special issue) \n                   Reprints and Permissions"},
{"file_id": "514020a", "url": "https://www.nature.com/articles/514020a", "year": 2014, "authors": [{"name": "Katia Moskvitch"}], "parsed_as_year": "2006_or_before", "body": "The Pierre Auger Observatory in Argentina has spent almost ten years looking for the source of ultra-high-energy cosmic rays \u2014 but to no avail. Now the observatory faces an uncertain future. The tank looks oddly out of place here on the windy Pampas of western Argentina. Surrounded by yellow grass and spiky thorn bushes, the chest-high plastic cylinder could be some kind of storage container \u2014 were it not for the bird-spattered solar panels and antennas on top. More tanks can be seen in the distance, illuminated by a crimson Sun dropping behind the far-off Andes. \u201cSome locals think that the tanks influence the weather: they make it rain or snow, or make a dry season,\u201d says Anselmo Francisco Jake, the farmer who owns this stretch of land. \u201cBut I know they don't. I know they catch cosmic rays.\u201d Jake is right. There are 1,600 of these tanks, spaced over a 3,000-square-kilometre expanse that could fit all of Luxembourg with room to spare. Together they comprise the Pierre Auger Observatory: a US$53-million experiment to reveal the mysterious origins of ultra-high-energy cosmic rays, the most energetic subatomic particles known to exist. But for all its size, the array has fallen short. After almost ten years of hunting, it has observed dozens of ultra-high-energy cosmic rays, but has not managed to solve the mystery of where they come from. As a detector, \u201cthe device worked twice as well as we expected\u201d, says project co-founder James Cronin, a retired astrophysicist at the University of Chicago in Illinois. But the particles seem to be coming from all over the sky, with too little clustering for researchers to pinpoint the sources. \u201cIt's up to nature with experiments like this one,\u201d he says. Now, the Auger team is putting its hopes on a proposed upgrade that might settle the question by improving Auger's resolution considerably. Five designs are being evaluated internally by a committee of Auger physicists, who are expected to present their final selection to the array's many funding agencies in November. The trouble is, there is a sixth option, too. \u201cIn the worst-case scenario, and I don't want to think about it, we may get shut down,\u201d says Auger's deputy project manager, physicist Ingo Allekotte. An upgrade would require an investment of roughly $15 million, and some argue that the money would be put to better use elsewhere. \u201cAlthough it was worth building Auger, it was a gamble that unfortunately didn't yield much new understanding,\u201d says Eric Adelberger, a physicist at the University of Washington in Seattle. \u201cCosmic-ray physics has delivered very few surprises and progress is terribly slow. Maybe it is time to move on.\u201d That would be a blow to science \u2014 and to Argentina, say Auger's supporters. These flagship projects do more than just conduct research, says Pablo Mininni, head of the physics department at the University of Buenos Aires. They also raise awareness of physics and draw young people into the field. \u201cSuch a big project deserves some continuity,\u201d he says. Physicists have known for more than a century that Earth is continually bombarded by charged particles from space \u2014 many of which have energies that are astonishing even by particle-physics standards. It is not uncommon for cosmic rays to have hundreds or thousands of times the 7 trillion electron volts (10 12  eV) soon to be achieved by the most powerful human-made particle accelerator, the Large Hadron Collider (LHC) near Geneva in Switzerland. Most of these particles are now thought to be protons and other light nuclei originating far outside the Solar System, probably in cataclysmic stellar explosions known as supernovas. But on very rare occasions, cosmic rays have hit Earth's atmosphere at energies of 10 18  eV or more. The most energetic example on record \u2014 the 'Oh-My-God particle' detected 1  on 15 October 1991 in the skies above Utah \u2014 had 3 \u00d7 10 20  eV, about 40 million times that of the LHC. And therein lies a mystery: calculations suggest that the expanding shock wave of a supernova detonation cannot accelerate charged particles beyond about 10 17  eV. No one knows what physical process could accelerate particles to higher energies \u2014 or even what those particles might be (see  Nature 448, 8\u20139; 2007 ). \n               Rule-breakers \n             In 1992, Cronin, who shared the 1980 Nobel Prize in Physics for his work on particle interactions, decided to find out. He, Alan Watson of the University of Leeds, UK, and Murat Boratav of Pierre and Marie Curie University in Paris, set out to build an observatory that \u2014 they hoped \u2014 could detect enough ultra-high-energy cosmic rays to answer those questions. Their sprawling, 1,600-detector design reflected two fundamental facts about their quarry. The first is that the rays are exceedingly rare. Although their low-energy cousins come in at roughly a few particles per square centimetre per second, the rates dive precipitously as the energy increases. Above 10 20  eV, the cosmic-ray flux is less than one particle per square kilometre per century. So the more detectors the researchers could deploy, the better their chances would be of catching one. The second fact is that 'primary' cosmic rays \u2014 those that are coming in from interstellar space \u2014 never reach the ground. Instead, they smash into an air molecule high in the atmosphere, producing a blast of photons, electrons, positrons, muons and other collision products that then slam into other air molecules. The result is an 'air shower': a cascade of lower-energy particles that collectively follow along the track of the original cosmic ray. And that calls for detectors over a very wide area, in the hope that the devices could register enough of the air-shower particles as they hit the ground to reconstruct the energy and direction of the original particle (see 'Celestial messengers'). To help in the reconstruction, the physicists also planned to surrounded the site with four clusters of fluorescence telescopes to scan the skies over the array, mapping the faint streaks of blue and ultraviolet light that the air-shower particles produce as they rip through the atmosphere. Naming their observatory after Pierre Auger, the French physicist who discovered air showers in 1938, the three scientists started going from country to country knocking on doors. They gathered a cadre of high-level physicists from around the world who wanted to join them. And those physicists, in turn, used their connections to get funding from their own governments. In short order, the United States agreed to help, as did Italy, Germany, France, Argentina and several other countries. At the same time, the Auger team was looking at potential sites in South Africa, Australia and South America \u2014 places that met their need for lots and lots of empty, flat land with clear skies above. Nelson Mandela dearly wanted the observatory to be based in South Africa. But the Auger team judged that the nation did not have a strong-enough community of physicists to support the project. The Australian site had a different drawback: it was on land controlled by the military, so collaborators from certain countries might not be able to work there. So in November 1995, Cronin, Watson and Boratav announced that the observatory would be built in Pampa Amarilla, a plain some 1,400 metres above sea level. Except for Malarg\u00fce, a mining town of 23,000 people just to the southwest, the site was as empty as the Auger team could wish. Better still, Argentina's then-president, Carlos Menem, was so excited by the idea of his country hosting an international science project that he promised to support it with the equivalent of US$10 million in Argentinian pesos. The province of Mendoza, where the site is located, agreed to contribute another $5 million. This largesse would prove to be a mixed blessing: in 2001, just as construction was getting under way, Argentina experienced its biggest economic crisis and government default in history. The peso instantly lost two-thirds of its value, leaving the researchers to scramble for funding from other sources to keep construction on schedule. It was one of Auger's biggest setbacks, says Cronin. Another came in 2010, when US funding agencies declined the researchers' request to build a sister observatory in Colorado, which would have allowed them to look for the ultra-high-energy cosmic-ray sources across the entire sky instead of just the Southern Hemisphere. \n               Air showers \n             Still, the first 154 detectors of the Auger observatory were able to start collecting data on 1 January 2004, with the rest of the detectors being deployed in stages until the array was completed in 2008. Each of the plastic tanks is filled with 12,000 litres of purified water, which produces a streak of light when an air-shower particle passes through, and is lined with phototubes that can measure that light. The tank's antennas transmit the data to the observatory's headquarters in Malarg\u00fce, where they are sent out for analysis to some 350 researchers around the world. Their first decade of data-taking has yielded a number of provocative results, including hints that many of the highest-energy rays are actually heavy nuclei such as that of iron, instead of the much more common protons 2 . \u201cIt was a surprising result that nobody had thought about,\u201d says Auger spokesman Karl-Heinz Kampert, a physicist at the University of Wuppertal in Germany. And if true, it might have something important to say about the mysterious acceleration mechanism \u2014 although no one is quite sure what. It also threatened to undermine Auger's central quest: heavy nuclei tend to be more strongly deflected by intergalactic magnetic fields than protons are, and that could randomize their direction and make it impossible to trace the rays back to their sources. That concern seemed to have been put to rest in 2007. Working with three-and-a-half years of data gleaned from 27 rays, Auger researchers reported that the rays seemed to preferentially come from points in the sky occupied by supermassive black holes in nearby galaxies 3 . The implication was that the particles were being accelerated to their ultra-high energies by some mechanism associated with the giant black holes. The announcement generated a media frenzy, with reporters claiming that the mystery of the origin of cosmic rays had been solved at last. But it had not. As the years went on and as the data accumulated, the correlations got weaker and weaker. Eventually, the researchers had to admit that they could not unambiguously identify any sources 4 . Maybe those random intergalactic fields were muddying the results after all. Auger \u201cshould have been more careful\u201d before publishing the 2007 paper, says Avi Loeb, an astrophysicist at Harvard University in Cambridge, Massachusetts. The Auger physicists contend that it would have made no sense to wait. \u201cWe gave the statistical significance of what we observed, so scientists know how to ponder the results,\u201d says team member Esteban Roulet, a physicist at the Balseiro Institute in San Carlos de Bariloche, Argentina. \u201cI think it is important that the community gets the information we can gather in this way.\u201d \n               Massive upgrade \n             Nonetheless, the mystery remains unsolved \u2014 an impasse that the Auger team wants to end with the hoped-for upgrade. The basic strategy is to get a better measure of each primary cosmic ray's mass and thus distinguish the relatively undeflected protons from the heavier particles, says Auger team member Alberto Etchegoyen, a physicist working at Argentina's National Atomic Energy Commission in Buenos Aires. \u201cIf nature is kind enough to us,\u201d he says, and if there are enough protons among the ultra-high-energy cosmic rays to get adequate statistics, \u201cwe'll be able to find the sources\u201d. Currently, the mass is measured by Auger's fluorescence telescopes, which watch how each air shower expands and deposits its energy as it descends through the atmosphere. But the telescopes can operate only on clear, moonless nights, which cuts down on their observing time. So instead, the team wants to look within the showers to count muons: short-lived particles that behave like heavy electrons. Because the muons in air showers tend to be produced most copiously in collisions of heavier cosmic-ray particles, knowing their abundance should tell the Auger physicists whether the incoming primaries are protons or heavy nuclei. The five upgrade proposals represent five different ways of identifying muons, but all are based on the fact that the muons tend to penetrate farther into the water tank than other particles. Each scheme requires a different combination of new electronics, new detectors and internal modifications for all 1,600 tanks \u2014 hence the $15-million cost of the upgrade. Supporters argue that the investment is worthwhile, not least because the array currently has little chance of ever getting statistics good enough to identify the sources, yet still costs $1.7 million a year to run. But the muon-detection schemes have yet to be proved in the field, and the selection committee could still decide that the upgrade is not worth it \u2014 and perhaps even that Auger should be shut down. \u201cThis is a serious question,\u201d says Kampert. Cronin insists that it is much too soon to give up. Auger is exploratory, he says. \u201cI don't know how much we'll learn from it. But you don't learn anything if you don't do something.\u201d Besides, says Allekotte, scrapping Auger would be depriving Argentina of a project that has greatly boosted the country's scientific capacity \u2014 not least by providing an incentive for young people to pursue physics. Tiny Malarg\u00fce now has a university for first- and second-year undergraduate students where many Auger engineers and scientists teach part-time. \u201cOne girl who started in 2012 was at first interested in maths, but as she learned more and more about the observatory and cosmic rays, she decided to switch to physics,\u201d says Marcos Cerda, an Auger engineer and a physics lecturer at the university. \u201cShe's now in her third year, doing a physics major at the University of Mendoza.\u201d In addition, says Etchegoyen, there are many Argentinian students among the roughly 360 who have already earned their PhDs doing research at Auger, or are working towards one there. And now, he says, \u201ctwo out of Auger's five upgrade proposals \u2014 design, prototype construction, everything \u2014 would be made in Argentina. That would've been impossible at the beginning of Auger. We have managed to grow a whole new generation of experimentalists linked to international big physics.\u201d Thanks to the observatory, \u201cArgentina appeared on the map of global science\u201d, says the country's science minister Lino Bara\u00f1ao. He points to the Deep Space Antenna 3 radio dish that the European Space Agency installed about 30 kilometres south of Malarg\u00fce to support space missions such as Mars Express, Herschel and Planck. And he points to the Large Latin American Millimetre Array, a radio telescope being built in the north of Argentina in collaboration with Brazil. The presence of Auger influenced the decisions to base both these projects in Argentina. So if the Auger upgrade does go ahead, Argentina hopes to gain even more expertise, and add more capacity, says Bara\u00f1ao. And even if it doesn't, at least it's left a legacy. \u201cWe're associated with producing soya beans, beef and wine, but many countries can do that,\u201d he says. \u201cNow we're also associated with world-class astrophysics.\u201d \n                     What Argentina\u2019s financial woes mean for science 2014-Aug-21 \n                   \n                     Cosmic rays originate from supernova shockwaves 2013-Feb-15 \n                   \n                     Cosmic-ray theory unravels 2010-Feb-22 \n                   \n                     The dawn of the particle astronomy era in ultra-high-energy cosmic rays 2009-Apr-16 \n                   \n                     Fly's eye detector spies cosmic-ray cut-off 2008-Mar-18 \n                   \n                     Cosmic-ray source still in doubt 2007-Nov-19 \n                   \n                     High-energy cosmic rays traced to source 2007-Nov-09 \n                   \n                     High-energy astrophysics: Let's catch some rays 2002-Sep-05 \n                   \n                       Blogpost on cosmic-ray detectors \n                   \n                       Pierre Auger Observatory \n                   \n                       Alberto Etchegoyen \n                   \n                       James Cronin \n                   \n                     http://fisica.cab.cnea.gov.ar/particulas/User:Allekotte \n                   \n                       Lino Bara\u00f1ao \n                   Reprints and Permissions"},
{"file_id": "514158a", "url": "https://www.nature.com/articles/514158a", "year": 2014, "authors": [{"name": "Matthew Chalmers"}], "parsed_as_year": "2006_or_before", "body": "As the Large Hadron Collider prepares to come back to life after a two-year hiatus, physicists are gearing up to go beyond the standard model of particle physics. Mike Lamont grabs the last croissant from a table and eats it as he walks through the control centre at CERN, the European laboratory for particle physics just outside Geneva, Switzerland. It is mid-morning, and the vast blue room is full of physicists staring into computer screens. Lamont, the operations manager of CERN's beams department, explains that they are running tests to ensure that an unexpected computer outage would not affect the network of electronics, vacuum pipes and superconducting magnets that comprise CERN's Large Hadron Collider (LHC), the most powerful particle accelerator in the world. This is one of numerous checks that are helping Lamont and his colleagues to sleep better at night. They are nearing completion of a major refurbishment that has been under way since March 2013. They have already started cooling down the accelerator's 27-kilometre ring of superconducting magnets in preparation for a restart next year. But when the LHC comes back to life, circulating its twin beams of protons in opposite directions around the ring, Lamont and his colleagues will be pushing to get as close as possible to its design energy of 7 trillion electron volts (TeV) per beam \u2014 nearly twice what the LHC has managed so far. Each beam will pack as much energy as a speeding freight train. Lamont knows all too well what can happen if things go wrong. He was here in September 2008, when the team last attempted to ramp up the US$5-billion collider to such energies \u2014 and ended up triggering an electrical fault that knocked it out of commission for more than a year and cost tens of millions of dollars to repair. \u201cWe've learned a lot about the machine since then,\u201d says Lamont. The researchers managed to patch it up and get it working again by the end of 2009, although they ran it at only half its design energy to avoid another shutdown. Still, that was enough for collisions between the beams to produce conclusive evidence for the long-sought Higgs boson \u2014 the last unconfirmed prediction of the 40-year-old standard model of particle physics, which describes the behaviour of every particle and force known except gravity. But for all the acclaim that greeted the announcement of the Higgs particle in July 2012 \u2014 and the 2013 Nobel Prize awarded to the theorists who first conjectured its existence \u2014 there is much more that the LHC physicists hope to learn from the machine's upcoming run. Is the newly discovered Higgs the only particle of its kind, as the standard model predicts, or is it just the lightest member of a whole family? If there are more Higgs particles, some of them might appear at higher collision energies. Or perhaps the high energies will produce other new, exotic particles that have no place in the standard model. Theorists have been predicting such particles for decades. Supersymmetry, an extension of the standard model first proposed in the early 1970s, holds that each particle has a heavier counterpart or 'sparticle', and that the two differ in predictable ways. One or more such sparticles might turn out to be the constituents of dark matter \u2014 an invisible haze that is massive enough to control the motion of galaxies, but that is unaccounted for in the standard model. Finding these sparticles, assuming that they are not too heavy to be produced at LHC energies, will thus be a prime goal for the refurbished machine. It might even turn up still more exotic results, such as evidence for spatial dimensions beyond the familiar three. But first, Lamont and his team have to get the LHC running at full capacity. \n               Clicks and hisses \n             After a short drive from the control centre, Lamont dons a helmet, steel-capped boots and emergency breathing equipment, then steps into an elevator for a journey 100 metres underground. The elevator doors open onto a service corridor. From there, a short walk leads to the LHC tunnel, where a string of cylindrical, bright-blue magnets curves gently into the distance. Even after 25 years at CERN, Lamont says that he is still in awe of the power and complexity of the machine. It seems light years away from the cerebral calm of the control room. Down here, the LHC hums, clicks and hisses, and its tunnel smells of metal, dust and warm circuitry. The 15-metre-long, 35-tonne magnets are held off the concrete floor by heavy-duty jacks, and are packed with intricate wiring and plumbing that encases the airtight beam pipes running through their centres. To avert another short circuit, the LHC has been fitted with sensors and thousands of kilometres of cable to detect the slightest sign of a surge in voltage. Crucially, 10,000 of the superconducting connectors that link the magnets have been reinforced or replaced \u2014 a task that took more than 250 people more than a year to complete. Since June, the team has been cooling the magnets down towards their operating temperature of 1.9 kelvin \u2014 at which the current-carrying cables that generate the magnetic fields become superconductive. To keep this process manageable, the LHC ring is divided into eight sections that can be refrigerated independently. Once the magnets have been chilled, which takes two months per section, the team will carry out electrical tests to ensure that they can operate at high energy. Lamont already knows that things will not go smoothly. There is a batch of magnets that performed perfectly in tests above ground, but, for some reason, 'quench' or lose their superconductivity when they reach magnetic fields equivalent to beam energies of just 6.5 TeV. This is not a disaster \u2014 fixing the magnets is just a matter of cycling each one through several quenches until it settles down and works properly. But it does take time, he says. \u201cAnd there are hundreds of the buggers!\u201d Eventually, however, proton beams will once again be threaded through the LHC \u2014 a milestone now scheduled for March 2015. And then, after another few weeks of testing, the physicists will start carefully steering the beams into collisions and checking that it is safe for the detectors to start data collection. There is a faint smell of burning in the tunnel. Lamont explains that a vacuum pipe is being heated to drive off stray molecules. He walks past the magnets to a point where the bare beam line plunges through a massive copper and steel wall. On the other side lies ATLAS, one of the LHC's four main particle detectors (see 'The refurbished ring'). Soon, bunches of high-energy protons will be fired past this point into ATLAS, where they will slam into equally energetic protons circulating in the other direction and send collision debris streaming outwards through the detector. \u201cYou think: Jesus, they let us steer a beam through here?\u201d says Lamont. \u201cI still can't believe I get paid to play around with this thing.\u201d \n               System updates \n             Some 8.5 kilometres away from ATLAS, on the opposite side of the LHC ring, Tiziano Camporesi stares up at the 12,500-tonne Compact Muon Solenoid (CMS) \u2014 and marvels at the audacity of the physicists who designed it 30 years ago. \u201cThey must have been crazy,\u201d he says. Many people declared the machine \u2014 a vast cylinder with concentric layers of silicon particle sensors, superconducting magnets and massive iron 'yokes' to contain the magnetic field \u2014 too intricate to ever work. But it did, says Camporesi, and \u201cfar better than we ever expected\u201d. CMS and ATLAS were the detectors that identified the Higgs boson in 2012. Camporesi, who was elected spokesman of the 3,800-strong CMS collaboration earlier this year, is now coordinating activities for next year's high-energy run. His team, like those on all of the LHC's main experiments (which also include the more specialized ALICE and LHCb detectors located elsewhere around the ring) have been making some much needed repairs and upgrades during the downtime. They have had one piece of good news: in the central region of the detector, where the beams intersect and newly created particles explode outwards from the collision point, the sensitive silicon trackers have so far survived without radiation damage. But CMS physicists have replaced several faulty photomultiplier tubes that were giving false results, making it seem as though an exotic new particle had been produced when none had. Camporesi is particularly proud of the four disc-shaped chambers added to each end of the CMS to improve its ability to sense particles called muons. This upgrade, in turn, will beef up the detector's 'trigger' \u2014 a combination of electronics and software that will monitor the particles streaming through the detector from the collisions and look for patterns that could signify an event worthy of further study. Physicists have been using such triggers for decades, says Camporesi. But the LHC's next run will not only boost the energy of each beam, it will also increase the number of protons they carry. The result will be some 1\u20132 billion collisions per second in the CMS. Particles from one collision will still be making their way out of the detector while as many as 50 new collisions occur behind them. From all those events, the trigger will have to decide which to store for further analysis; the goal is to bring the final recorded event rate down to several hundred per second. \u201cIt's occupying a lot of our time right now,\u201d says Camporesi. \n               Big data challenge \n             Once the refurbished LHC is running again, the raw electronic signals from CMS and the other detectors will flow back to the main CERN campus through optical fibres that link directly into the laboratory's computing centre \u2014 a stuffy, windowless room in which row upon row of racks hold some 100,000 processors, and cooling fans work noisily to control the heat. The processors will analyse the incoming data with algorithms that determine the identity, energy and direction of each particle emerging from each collision. The results will then be stored on magnetic tape \u2014 an old-fashioned medium that has the advantage of being cheaper and more durable than digital storage. But just storing the information at CERN would not satisfy researchers' near-insatiable appetite for it. Today's particle physicists spend most of their time writing thousands of lines of computer code designed to search millions of collisions for unusual signals. To get data to these researchers, CERN set up the Worldwide Computing Grid, in which the computer centre streams copies of the data to 13 'tier-1' computer centres worldwide. These centres, in turn, are connected to more than 150 smaller computer clusters called tier-2 nodes, most of which are at universities. Fortunately for the end users, they do not have to know about any of this. A physicist just has to submit a program to the grid and specify which collision events are to be examined. Grid software will then automatically shunt the job to a centre that has enough processing power and disk space free to run it, then return the results (see  Nature 469, 282\u2013283; 2011 ). On this particular day at the CERN computer centre, a live screen shows that 10,500 programs are running at this facility alone \u2014 and it represents only 6% of the grid's resources. Were it not for the grid, says Jeremy Coles, a physicist at the University of Cambridge, UK, who is the grid's UK coordinator, his colleagues would probably still be searching for the Higgs boson. The challenge for the future, says Coles, is dealing with the sky-high event rates to come. During the LHC's first run, despite radical pruning by the detectors' triggers, the data still piled up at the rate of 15 petabytes (15,000 trillion bytes) a year \u2014 more than in all the videos uploaded to YouTube annually. When the LHC starts up again next year, the doubling of the collision rate will bump that up to roughly 30 petabytes per year \u2014 an average of about 1 gigabyte per second. Coles is confident that the grid will be able cope with that increase \u2014 not least because of technological advances that have enabled much closer integration between computer centres. \u201cNetworking has come on very quickly in the past 10 years,\u201d he says \u2014 \u201cmore than we thought.\u201d Just last year, for example, CERN expanded the capability of its data centre, which is at the limits of available space and power, by linking it up with a facility in Budapest through two fibres that transfer data at 100 gigabits per second. From an operations point of view, says Coles, it is just like having the machines in the room next door. But the data onslaught will not stop there. Planned upgrades to the LHC will send its data output soaring to 110 petabytes a year by the early 2020s, and, eventually, to as much as 400 petabytes a year. \u201cWe currently have no way to deal with this,\u201d says Coles. Making matters worse, computer chip speeds are stagnating. The best commercial chips now available often contain two, four or eight processors to boost their power. Future chips are likely to have even more. But the code that runs the LHC was written to be run on one processor at a time, says Coles. Finding ways to run data analysis on many processors in parallel would mean rewriting 15 million lines of code written by thousands of people over many years. Still, when CERN physicists needed a better way to share information in the late 1980s, the result was the World Wide Web. And when they needed a better way to access computer resources back in the 1990s, they invented the world's largest computing grid. The LHC scientists seem confident that they will invent a way around this problem as well. Lamont seems to feel similarly confident when he talks about the 'next big collider' in particle physics. Although CERN just celebrated its sixtieth anniversary, and the LHC still has another 20 years of proton smashing to go, the laboratory is exploring the feasibility of a collider 80\u2013100 kilometres around that would drill even deeper into the structure of matter (see  Nature 503, 177; 2013 ). Lamont says that he would be lucky to see such a machine built during his lifetime, but he points out that the LHC, which came online for the first time in 2008, was first sketched out in 1984. \u201cWe've got to start thinking about the next machine now,\u201d he says. \n                     China plans super collider 2014-Jul-22 \n                   \n                     Particle physics: Together to the next frontier 2013-Dec-18 \n                   \n                     Physicists plan to build a bigger LHC 2013-Nov-12 \n                   \n                     Truant particles turn the screw on supersymmetry 2012-Nov-20 \n                   \n                     After the Higgs: The new particle landscape 2012-Aug-29 \n                   \n                     Nature  special: the Large Hadron Collider \n                   \n                     Nature  Insight: The Large Hadron Collider \n                   \n                     CERN Future Circular Collider study \n                   \n                     Linear Collider Collaboration \n                   \n                     European strategy for particle physics (PDF) \n                   Reprints and Permissions"},
{"file_id": "514154a", "url": "https://www.nature.com/articles/514154a", "year": 2014, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Nobel prizewinners May-Britt Moser and Edvard Moser have spent a career together near the Arctic Circle exploring how our brains know where we are. The fact that Edvard and May-Britt Moser have collaborated for 30 years \u2014 and been married for 28 \u2014 has done nothing to dull their passion for the brain. They talk about it at breakfast. They discuss its finer points at their morning lab meeting. And at a local restaurant on a recent summer evening, they are still deep into a back-and-forth about how their own brains know where they are and will guide them home. \u201cJust to walk there, we have to understand where we are now, where we want to go, when to turn and when to stop,\u201d says May-Britt. \u201cIt's incredible that we are not permanently lost.\u201d If anyone knows how we navigate home, it is the Mosers. They shot to fame in 2005 with their discovery of grid cells deep in the brains of rats. These intriguing cells, which are also present in humans, work much like the Global Positioning System, allowing animals to understand their location. The Mosers have since carved out a niche studying how grid cells interact with other specialized neurons to form what may be a complete navigation system that tells animals where they are going and where they have been. Studies of grid cells could help to explain how memories are formed, and why recalling events so often involves re-envisioning a place, such as a room, street or landscape. While pursuing their studies, the two scientists have become a phenomenon. Tall and good-looking, they operate like a single brain in two athletic bodies in their generously funded lab in Trondheim, Norway \u2014 a remote corner of northern Europe just 350 kilometres south of the Arctic Circle. They publish together and receive prizes as a single unit \u2014 most recently, the Nobel Prize in Physiology or Medicine, which they won this week with their former supervisor, neuroscientist John O\u2019Keefe at University College London. In 2007, while still only in their mid-40s, they won a competition by the Kavli Foundation of Oxnard, California, to build and direct one of only 17 Kavli Institutes around the world. The Mosers are now minor celebrities in their home country, and their institute has become a magnet for other big thinkers in neuroscience. \u201cIt is definitely intellectually stimulating to be around them,\u201d says neurobiologist Nachum Ulanovsky from the Weizmann Institute of Science in Rehovot, Israel, who visited the Trondheim institute for the first time in September. The Mosers' work has also given them traction at one of the most challenging twenty-first-century research frontiers: how the brain computes. Just as computers use programming languages such as Java, the brain seems to have its own operating languages \u2014 a bewildering set of codes hidden in the rates and timing with which neurons fire as well as the rhythmic electrical activities that oscillate through brain circuits. These codes allow the brain to represent features of the external world \u2014 such as sound, light, smell and position in space \u2014 in a language that it can understand and compute. With their grid-cell work, the Mosers have been the first to crack one such code deep in the brain; now the challenge for the field is to find all the rest. \u201cMay-Britt and Edvard's research lies at the very heart of the cognitive-neuroscience enterprise,\u201d says Stanislas Dehaene, who studies consciousness at the Coll\u00e8ge de France in Paris. \u201cThey are trying to understand the neural codes for cognition \u2014 and so unite biology with computer science and even philosophy.\u201d \n               Stars align \n             The Mosers grew up on different Norwegian islands in the North Atlantic, where summer days seem eternal and the long winter nights are brightened only by the dancing Northern Lights. They were both from non-academic families and they went to the same school. But they didn't get to know each other until 1983, when both were at the University of Oslo, both were wondering what to study and both were starting to realize that their true passion was for neuroscience and the brain. Suddenly, everything sparked: romance between the two of them, intellectual curiosity and the beginnings of their mission in life \u2014 to find out how the brain generates behaviour. The Mosers visited one of the university's more famous faculty members, electrophysiologist Per Andersen, and asked to do their undergraduate projects with him. Andersen was studying the activity of neurons in the hippocampus \u2014 a brain area associated with memory \u2014 and the two students wanted to try to link this precise activity of cells with the behaviour of animals. Andersen, like most neuroscientists at the time, was sceptical about making such a big leap across the black box of the brain. But the pair wouldn't leave his office until he gave in and offered them an apparently simple project: how much of the hippocampus could you cut away before a rat could no longer remember new environments? The two young scientists embraced the challenge, and soon discovered something profound. Until then, it had been assumed that the hippocampus was homogeneous. But the Mosers showed that one side of it was much more important for spatial memory than the other side 1 . That brought home to them the importance of detailed brain anatomy for understanding brain function, a lesson that would prove invaluable later in their careers. In 1984, while still undergraduates, the couple got engaged on top of the dormant volcano Mount Kilimanjaro in Tanzania. (The bitter temperature at the peak forced them to rush their exchange of rings, the quicker to get their gloves back on.) The pair had decided how their joint lives should be: children early, postdoc experience abroad and then their own lab together, somewhere in the world. These plans panned out \u2014 just a little faster than they had anticipated. Even before defending their PhDs, they accepted side-by-side postdocs in O\u2019Keefe\u2019s lab in London. In the 1970s, O'Keefe had discovered neurons called place cells in the hippocampi of rats. These cells fire only when an animal is in a particular place \u2014 close to an exercise wheel, for example, or in front of a door. (Since then, other navigation-related neurons have been discovered, including those that fire when the head turns in a particular direction, or when a border, such as the long edge of a cage, is in view.) The research area was red hot, and the Mosers wanted to extend it. But in 1996, just a few months into their postdocs, the Mosers received a surprise offer of two associate professorships at the Norwegian University of Science and Technology in Trondheim. They weren't sure about accepting: it would mean striking out alone, in a small university in a country isolated from the world's major centres of research. \u201cBut the offer of two posts in the same place and in the same research area was too good to turn down,\u201d Edvard says. They flew back home, by this time trailing a toddler and baby. It wasn't easy to get established in Trondheim. They had to build a lab from scratch in a small basement, and establish an animal facility too. But only a few years in, they were winning big grants from the European Commission and the Research Council of Norway. And by then, the results were coming through. \n               On the grid \n             The pair's first aim in Trondheim had been to better describe the origin of the place-cell signal. Although the cells themselves were in the hippocampus, it could be that cells elsewhere were instructing them when to fire. Remembering their lesson from the undergraduate lab, the Mosers knew that they needed to understand the brain's anatomy to see how the signals flowed physically across it. In the lab, they adapted the standard experimental technique for studying place cells: implanting electrodes directly into a rat's hippocampus and recording from them as the animal runs freely in a large box (see 'A sense of place'). The electrodes \u2014 which are sensitive enough to pick up activity from single neurons \u2014 feed into a computer and map the exact spot on the floor of the box where each neuron fires. This appears on screen as a black dot. To make sure that the rat covers the entire floor area, the researchers scatter chocolate treats across it. (May-Britt is a chocolate enthusiast both inside and outside the lab.) The Mosers chemically inactivated different parts of the hippocampus and its surroundings in the rat brains, and then tested whether the place cells continued to fire normally. In this way, they discovered 2  that information flowed to the place cells from the entorhinal cortex, a narrow strip of tissue running vertically up the lower back of the rat's brain. No one had paid much attention to this structure before, in large part because it is extremely difficult to access. One side lies very close to a large blood chamber; puncturing that would be fatal. The Mosers consulted an expert in neuroanatomy and concluded that, fortunately, the ideal place for the electrodes would be away from the chamber and close to the brain's surface. Then they started to repeat their experiments, recording from single neurons in the entorhinal cortex. That is when they found something unexpected. The researchers saw that some of these entorhinal neurons fired when the rats moved onto or through a particular spot in the box, just like hippocampal place cells. But they went on to fire at several other spots too. While a rat scurried around mopping up chocolate treats, the researchers watched, perplexed, as the computer mapped the firings, and overlapping blobs appeared on the screen. The Mosers could see that the blobs were creating some sort of pattern, but they couldn't work out what it was. It took some months before it dawned on them that they needed the rats to run around bigger boxes, so that the pattern would be stretched out and easier to see. At that point, it came into view: a near-perfect hexagon lattice, like a honeycomb. At first they refused to believe it. Such simplicity and regularity was the last thing they had expected \u2014 biology is usually a lot messier than this. But one by one, the pair ruled out all other explanations \u2014 that the pattern was an artefact from their electronic equipment, for example \u2014 and then they began to understand how this part of the brain was working. There were no physical hexagons traced on the floor; the shapes were abstractly created in the rat's brain and imposed on its environment, such that a single neuron fired whenever it crossed one of the points of the hexagon. The discovery was exciting for more than its pleasing pattern. This representation of space in brain-language was one of the long-sought codes by which the brain represents the world around us. \u201cIt was a long-drawn-out eureka moment,\u201d recalls Edvard. The team published the discovery in  Nature 3  in 2005. \n               Hidden pattern \n             Soon the Mosers were putting the grid cells to the test. They showed that the firing pattern of the cells remained constant even in the dark, and that they are independent of the animals' speed or direction 3 . Whereas place cells in a rat brain may change their firing rates if their environment is altered even a little \u2014 for example by changing the colour of the walls \u2014 those of grid cells remain robustly unchanged. The Mosers also found that the different cells in the entorhinal cortex generate grids of many different types, like overlapping honeycombs \u2014 big, small and in every orientation and position relative to the box's border. And they ultimately came to see that the brain's grid cells are arranged according to a precise mathematical rule. The cells that generate smaller grids, with narrower spacing, are at the top of the entorhinal cortex, and those that generate bigger grids are at the bottom. But it is even more exact than that: cells that make grids of the same size and orientation seem to cluster into modules. The modules are arranged in steps down the length of the entorhinal cortex, and the size of the grid represented by each module expands by a constant factor of 1.4 with every step 4 . At the same time, grid cells that represent different positions relative to the box's border are dotted randomly through the structure. Assuming a similar arrangement exists in humans, the idea is that, together, these cells are unconsciously keeping track of where we are as we wander between rooms or stroll down a street. \n               All in the mind \n             These discoveries link the Mosers to a rich cast of scientists and philosophers who have pondered the connections between brain, memory and location since at least the time of Ancient Greece. Back then, a philosopher who needed to remember a long speech might memorize the layout of a building or a street, and mentally attach different parts of the speech to its different landmarks. He (they were almost always men) could then fluently deliver the entire rhetoric as he mentally walked around, allowing each landmark to activate the individual sections from memory. The fascination with memory and location continued into the twentieth century, when behavioural scientists first hypothesized that animals carry an abstract map of space inside their heads. The grid cells finally proved that this was true. The discoveries also astonished and thrilled theoreticians, because the hexagonal pattern is the optimal arrangement for achieving the highest-possible spatial resolution with a minimum number of grid cells. This saves energy, showing how beautifully efficient the brain can sometimes be. \u201cWhoever would have believed that such a beautiful hexagonal representation existed so deep in the brain?\u201d says Andreas Herz, a computational neuroscientist at the University of Munich in Germany. \u201cIt was so unexpected that the brain would use the same simple geometric forms that we have been describing in mathematics for millennia.\u201d The appealing simplicity gives hope, he says, that the entire brain uses computational principles that scientists may eventually understand. That understanding could take a long time to reach. It seems unlikely that the neural codes that the brain uses to represent other aspects of the world will be so simple; individual neurons may code for several different properties of the world, making the languages difficult to disentangle. The grid code is also valuable because it exists high up in the brain's hierarchy, with no direct input of sensory information. Unlike the visual cortex, say, whose coding will be influenced by light falling onto the retina, the entorhinal cortex creates the hexagonal pattern entirely internally, by integrating whatever information about the environment is received by other areas of the brain. With the lab churning out one high-impact paper after another, the Mosers' work has attracted people and funding. Neuroscientist David Rowland was doing his PhD at the University of Oregon in Eugene when he read the 2005 paper on grid cells and was inspired. \u201cI thought it was so cool that I immediately wanted my first postdoc to be in their lab,\u201d he says \u2014 and that's how it worked out. He has joined the Mosers at the Trondheim Kavli Institute, which is now buzzing with six additional research groups, each working on different aspects of neural circuitry and coding. Not every couple would find it easy to work together in such apparent harmony. The Mosers ascribe their ability to do so in large part to their patient temperaments and shared interests \u2014 in science and beyond. Both love outdoor activities: May-Britt runs every other day across the rugged hills around their coastal home, and Edvard hikes at weekends. They share an obsession with volcanoes \u2014 hence their engagement at the top of one \u2014 and have climbed many of the globe's most spectacular peaks. At work, they have evolved some division of labour. Edvard is more involved in computing and theory, and May-Britt manages the lab and staff and is more immersed in the experiments. \u201cWe have different strengths and we know that by combining them, the results become so much better,\u201d says Edvard. They aim for only one of them to attend any particular meeting, so that the other is left in the lab. \u201cSo we are not really stepping on each other throughout the day, as many people might believe,\u201d says Edvard. The Mosers \u2014 and other labs around the world now studying grid cells \u2014 still have a lot to learn. Scientists do not yet know how the grid is generated by the neural networks in the entorhinal cortex, or how the overall map created by grid cells, place cells and other navigation cells is integrated to help animals to get from one place to the next. These challenges require more data, and the Mosers have a roster of experiments under way to collect them. One virtual-reality experiment they are planning will record from electrodes in rats running on a stationary ball surrounded by screens showing changing environments. The rats' heads will be held still so that it becomes possible to place electrodes directly inside individual cells for the first time, and to insert small lenses that allow the researchers to simultaneously examine those cells under a microscope. This will reveal precisely which of the many cell types are firing at any one time as the rats move around the virtual space. The next step will be to map how the grid cells are hard-wired into networks, and to find out when in the rats' lives this wiring happens. Early studies suggest that the grid system is fully established at around three or four weeks after birth 5 , 6 , which implies that babies \u2014 humans as well as rats \u2014 are born with a very primitive sense of where they are in space, and that this sense develops as their brains adapt to the world. The Mosers are also planning to test how the hexagonal pattern would be modified in the brain of a rat that has been reared from birth in a perfect sphere instead of a flat-bottomed cage. Outside the abstract world of neural coding, grid cells have another major relevance \u2014 in understanding memory and its loss. The entorhinal cortex is the first structure in the brain to be affected by Alzheimer's disease, and getting or feeling lost is one of the disease's first symptoms. The Mosers hypothesize that the cells in the entorhinal cortex may have special properties that allow the disease to develop there early \u2014 a puzzle that they hope scientists elsewhere can start solving. Meanwhile, in Trondheim, it is 10 p.m. and Edvard and May-Britt are still discussing the brain as they find their way home. Later, long after they are out of sight, the two scientists continue to make their presence felt. Anyone flying out of Trondheim Airport will find a photograph of the couple in an exhibition of famous Norwegians. The other 13 portraits are all of individual athletes or artists. The Mosers' portrait is the only one featuring two scientific brains. \n                     Flashes of light show how memories are made 2014-Jun-02 \n                   \n                     Neuroscience: Solving the brain 2013-Jul-17 \n                   \n                     Neurons on border patrol 2008-Dec-18 \n                   \n                     Nature special: New angles on the brain \n                   \n                     Nobel prize announcement 2014 \n                   \n                     Moser lab \n                   \n                     Kavli Foundation \n                   Reprints and Permissions"},
{"file_id": "514292a", "url": "https://www.nature.com/articles/514292a", "year": 2014, "authors": [{"name": "Josh Fischman"}], "parsed_as_year": "2006_or_before", "body": "Arizona State University is trying to reinvent academia by tearing down walls between disciplines. Worlds both familiar and strange come together inside a large glass-walled room at Arizona State University in Tempe. Images of the Moon's surface fill giant screens as planetary geologist Jim Bell shows off panoramas from one of the university's cameras, which is currently flying on a lunar orbiter. Bell, tall and enthusiastic, gets even more animated when he talks about plans to visit an odder place: an asteroid named Psyche made almost entirely of iron. Researchers are keen to explore it because it is essentially a naked version of Earth's metallic core, something that scientists have never seen. Designing a mission to study a rapidly spinning hunk of iron more than 255 million kilometres from Earth calls for close collaboration between scientists and engineers. Bell finds that kind of coordination easier at Arizona State University (ASU) than when he worked at Cornell University in Ithaca, New York, on the Mars rovers. At Cornell, \u201cthe engineers were someplace else on campus\u201d, he says. \u201cSo you'd come up with an idea for an instrument, kind of toss it over the wall, and then a year later they'd toss a design back to you that may or may not work, scientifically.\u201d But at ASU, Bell works at the School of Earth and Space Exploration (SESE), which includes engineers and computer scientists. \u201cThey are people who are interested in the same science I'm interested in, and we get things done faster and, I think, better.\u201d The exploration school, formed in 2006 from the former departments of astronomy and geology, is the most striking embodiment of the ambitious vision of Michael Crow, who took over as president of ASU in 2002 with the goal of turning a public university with a middling reputation into something much greater. ASU was not known for exceptional scientific research, and attracted students mainly from within the state. Crow has sought to transform ASU's research and education by tearing down walls between traditional academic departments and bringing together disparate disciplines to tackle large issues such as exploring the Solar System, finding alternative ways to attack cancer and solving problems that matter to Arizona as well as the rest of the world, such as severe water shortages. Crow has travelled extensively, talking up what he calls the \u201cNew American University\u201d that is taking root in the desert. \u201cWe're going to best serve our students, and the world, by preparing them to tackle the big problems of the modern age,\u201d he says. More than a decade into his tenure, the results are mixed. On the positive side, ASU has more than doubled the amount of federal money it attracts for research. And the culture at the university has shifted to make research and education more interdisciplinary. \u201cI think some of the things Arizona is doing could have a real impact,\u201d says Daniel Fisher, a physicist at Bio X, a multidisciplinary institute at Stanford University in California. But seen from another perspective, the changes at Arizona are modest shifts \u2014 layering new institutes on top of traditional departments, for example. And the reinvention effort may not have substantially improved the quality of ASU's research. An analysis of scholarly output conducted by  Nature  shows that ASU's record has improved by some measures, such as the number of papers published, but the university has gained little ground compared with similar institutions. The results underscore how hard it is for large universities, which employ thousands of researchers, to alter their fundamental character by uprooting entrenched academic disciplines. Even Crow says that \u201cthe biggest challenge that we've had has been the strength of 'the invisible' colleges \u2014 the fact that people show more allegiance to their disciplines and the structure of those disciplines than to the institution they are a part of\u201d. \n               Change agent \n             Still, the signs of change are all over the university \u2014 literally. Big placards in hallways announce \u201cA New American University\u201d with eight ambitious calls to action. \u201cFuse Intellectual Disciplines\u201d is one, along with \u201cTransform Society\u201d, \u201cValue Entrepreneurship\u201d, \u201cEnable Student Success\u201d, and \u201cConduct Use-Inspired Research\u201d. The campus itself has a modern, utilitarian look: large buildings with clean lines, many topped with solar panels. Construction cranes poke into the sky as they continue a building boom that has been under way ever since Crow arrived. Throngs of students thread their way around them \u2014 ASU has the largest undergraduate and graduate enrolment of any public university in the country, at about 76,000. There are a lot of new faculty faces as well. Nearly 500 of ASU's 1,700 or so tenure-track faculty have been hired in the past ten years \u2014 the turnover has largely resulted from normal retirements \u2014 and the university has deliberately sought people who work well with others and look beyond disciplinary walls. \u201cI've worked at places where we'd have pitched battles over lab space if room opened up,\u201d says Cheryl Nickerson, a microbiologist at ASU's Biodesign Institute, a cross-disciplinary centre dedicated to understanding how organisms are built down to the molecular level, and how that differs between health and disease. Nickerson, who sends bacteria on NASA missions and works with many physicists and engineers, says, \u201cHere, I'm not saying we're perfect, but several times I've seen people give up space to accommodate a colleague with an expanding project.\u201d All these changes are part of Crow's grand vision for reinventing the university, and his tireless promotion of that vision has brought him to prominence in the world of higher education. He chairs or participates in several national committees, including an advisory council on innovation and entrepreneurship for the US Department of Commerce. And he travels the world to lecture at World Bank meetings and other international gatherings. Much of what Crow talks about is how ASU has focused on replacing narrow academic divisions with big, bold structures. \u201cOther leaders espouse this principle of interdisciplinarity, but Crow has gone the furthest in embracing it, and is the loudest voice,\u201d says Jerry Jacobs, a sociologist at the University of Pennsylvania in Philadelphia and author of the book  In Defense of Disciplines  (University of Chicago Press, 2013). Crow's manner can be blunt and aggressive, says Joshua LaBaer, who left his position as head of Harvard University's Institute of Proteomics in 2009 to work at the Biodesign Institute. But LaBaer says that the decisions by Crow and his team have generally been sound. \u201cI don't see the faculty rankling under a loss of power,\u201d he says. \u201cThe goals here are good ones, and you can take advantage of new opportunities.\u201d And of resources, too: in 2013, the US National Institutes of Health (NIH) gave ASU researchers some US$48 million, about $22 million of which went to the Biodesign Institute. By comparison, the university pulled in just under $20 million from the NIH in 2003. A substantial share of those resources have helped to build LaBaer's unique facility for producing and analysing thousands of proteins, as part of efforts to understand their function and role in disease. In secure rooms full of automated machines, human cell cultures churn out full-length proteins in vials, then robotic arms whisk the molecules to machines that determine their sequence and structure. What sets LaBaer's operation apart is the ability to manufacture and probe thousands of proteins before they lose their natural folding patterns and function. The scientists then compare the proteins to see which shapes and folds are linked to particular diseases. One priority for the university has been to boost biomedical research of this type \u2014 a tall order for an institution without a medical school. It has done so in part by forging close ties with the nearby Mayo Clinic in Scottsdale. That relationship helped ASU to attract LaBaer from Harvard. There were a lot of worries when Crow and his administrators first started to reshape the university. In 2005, for example, the anthropology department was incorporated into a new School of Human Evolution and Social Change, and anthropologists fretted that their discipline was going to be diluted into non-existence. But by 2011, according to anthropologist Alexandra Brewis, the number of faculty members in the school had risen by 40%, and three-quarters of them were anthropologists. The other research slots were occupied by applied mathematicians, epidemiologists, political scientists and human geographers. In 2010, Brewis and some colleagues surveyed all 54 tenured faculty in the school to find out who they collaborated with. The strongest partnerships, they learned, were still between traditional sub-disciplines such as archaeology and physical anthropology. Many non-anthropologists in the school often had stronger ties to anthropology than they did to one another. So diversity within the school had not led to fragmentation, the researchers concluded, and all the disciplines were contributing to anthropological research. For example, a team of researchers is studying the western Mediterranean, an area that has supported dense populations as well as productive agriculture for thousands of years. The team is developing computer models that show how population size, economic behaviour and vegetation change in the region have affected the sustainability of natural resources, and how those resources are likely to fare in the future. ASU's funding numbers show that grant-givers find the cross-disciplinary approach attractive. From 2003 to 2012, the university's federally financed research portfolio grew by 162%, vastly outpacing the average increase seen at 15 similar public institutions, which were picked for comparison purposes by ASU's governing board. And the money that ASU gets is supporting more interdisciplinary work than ever before. The number of funded projects with principal investigators in two or more departments rose by 75% between 2003 and 2014, whereas projects led by one department climbed by just 8%. A similar trend has occurred at Michigan State University in East Lansing, another institution that has pushed for greater collaboration between disciplines. Stephen Hsu, the university's vice-president for research and graduate studies, says that, like ASU, Michigan State has seen the value of shared projects. \u201cDue to increased specialization, you have experts in specific techniques or types of analysis scattered among different departments,\u201d he says. \u201cTo address many really big problems, for example, climate change, you need teams with multiple skills, and therefore must transcend departmental boundaries.\u201d But for all the changes, ASU has had limited success in raising its scientific profile relative to its peers \u2014a least in terms of its publication record. Using Elsevier's SciVal analysis tools,  Nature  compared the publications of ASU researchers to those at some of the same peer institutions identified by the university's governing board. Over the past decade, ASU has more than doubled the number of articles it produces each year, the biggest percentage rise in its peer group. But because everyone increased their production substantially, and because ASU started near the bottom, the university moved up only slightly within the group. In climbed from fourteenth to twelfth place between 2003 and 2013 (see 'Raising Arizona'). \n               Mixed numbers \n             Other metrics suggest that ASU researchers are having mixed success in generating scholarly impact. The university ranks in the middle of its peer group in getting papers into the most cited scientific journals and broke into the top five for a couple of years during the past decade. Yet it generally comes in last place in producing papers that attract the most citations. George Raudenbush, ASU's executive director of research analytics, argues that citation data are not the best measure of research quality. And he counters that the relative increase in publications is truly dramatic. It shows that the university has come a long way in a short time, given that it did not emphasize research as much before Crow's arrival, he says. Beyond metrics, there are also questions about how profound the organizational changes at ASU really are, and whether they represent a major departure in higher education. Few traditional academic departments have been eliminated; the university has simply established most of the new units on top of them. And most of the faculty members in the new schools and groups are actually tenured in traditional departments. (SESE is an exception.) In fact, some of what ASU has accomplished in terms of promoting interdisciplinary research can be seen at other, more staid institutions. \u201cTraditional universities have research centres, and that's where interdisciplinary ideas get addressed,\u201d says Jacobs. When he studied the top 25 research universities in the United States, he found that they have about 100 research centres each, on average. But ASU's administrators maintain that there is something unique happening there. By emphasizing new schools and institutes, rather than centres within disciplinary departments, the university has built conduits among very different specialities that encourage collaboration, says Crow. And hiring broad-thinking researchers and pairing them with practical technologists \u2014 engineers and computer scientists, for example \u2014 leads the way to addressing broad issues. As an example of something the university is doing differently, Crow points to its broad-based approach to cancer research. The university's Center for Convergence of Physical Science and Cancer Biology, financed by the National Cancer Institute, brings astrobiologists and physicists together with oncologists and evolutionary biologists to explore how cancer starts and evolves (see  Nature   474 , 20\u201322; 2011 ) Some of the centre's researchers have developed a theory that as a cancer spreads, it activates a series of ancient genes that were key to the success of the first multicellular organisms (C. Lineweaver, P. C. W. Davies, & M. D. Vincent  et al .  Bioessays   36 , 827\u2013835; 2014 ). The deep roots and robust genes might explain why some tumours are so hard to get rid of, the researchers propose. The idea implies that cancer is an organized response, rather than a series of genetic accidents. That line of enquiry, borne from an unusual marriage of disciplines, is unlikely to come from a typical university, says Crow. \u201cWe don't want to ask the same questions as other institutions do.\u201d \n                     Physicists' model proposes evolutionary role for cancer 2014-Oct-02 \n                   \n                     Physics meets cancer: The disruptor 2011-Jun-01 \n                   \n                     US higher education: The Arizona experiment 2007-Apr-25 \n                   \n                     Nature  special: The university experiment \n                   \n                     ASU School of Earth and Space Exploration \n                   \n                     ASU Biodesign Institute \n                   Reprints and Permissions"},
{"file_id": "509548a", "url": "https://www.nature.com/articles/509548a", "year": 2014, "authors": [{"name": "Meera Subramanian"}], "parsed_as_year": "2006_or_before", "body": "Polluting biomass stoves, used by one-third of the global population, take a terrible toll. But efforts to clean them up are failing. After returning from her nine-and-a-half-hour shift as a security guard, Savita Satish Dadas begins plucking fenugreek leaves from their stems for dinner. She and her two children, along with three of their cousins, gather in a shed-like structure next to their house in the Satara District of Maharashtra, India. As goats and cows settle in for the night a few metres away, Dadas and the children sit down on a packed dirt floor around the family hearth. Whisps of smoke rise up from their  chulha , the Indian name given to a traditional cooking-stove fuelled by wood and other organic matter often gathered from the countryside. Dadas\u2019s stove, like several of her neighbours\u2019, is sculpted out of clay. But many make a rudimentary three-stone fire \u2014 a triangle of elevated points to support a pot \u2014 that humans have used for millennia. Dadas feeds roughly chopped logs into the stove and her hands shape moistened flour into  bhakri  bread, the rhythmic movement illuminated by the flickering flames. With this simple daily act, Dadas shares a connection with more than one-third of the world\u2019s population, the three billion people who depend on solid biomass fuels \u2014 such as wood, animal dung, agricultural waste and charcoal \u2014 or coal for their cooking needs. In India, a nation that is rapidly developing in many ways, 160 million households \u2014 some two-thirds of families \u2014 still rely on such fuel for their primary cooking energy source. Globally, the percentage of households that use biomass has slowly and steadily decreased over the past three decades 1 . But because the world\u2019s population has been rising so quickly, the number of people using solid fuels is not declining, says Kirk Smith, an environmental-health scientist at the University of California, Berkeley, who has studied the health implications of such cooking stoves for 30 years. \u201cThis is not going away.\u201d And the urgency to transition billions of people around the world to cleaner forms of cooking has never been greater, in light of recent research revealing that emissions from traditional cooking-stoves pose a bigger threat than previously thought. Results from a global health study released earlier this year project that household air pollution from such fires causes more than four million premature deaths annually \u2014 more than one-quarter of them in India alone 2 . Earth\u2019s climate is also at risk from the smoke, which contains dark particles that absorb sunlight, alter atmospheric patterns and hasten glacial melting. Environmental organizations, development groups and others have strived to solve the cooking-stove conundrum for decades, but momentum is finally gathering, thanks to the formation of the Global Alliance for Clean Cookstoves. This far-reaching public-private partnership was launched in 2010 by then US secretary of state Hillary Clinton. The Global Alliance has set a lofty goal of convincing 100 million households to adopt clean cooking-stoves by 2020, with an aim of eliminating deaths from cooking-stoves by 2030. This massive effort \u2014 the most ambitious so far \u2014 is uniting specialists in fields as diverse as epidemiology, climate science, global finance and gender equality. It is part of a growing global effort that connects multinational energy companies, non-governmental organizations (NGOs), university design laboratories, governments and young, socially minded inventors. Simultaneously, new funding is flowing in from corporate social-responsibility initiatives, microfinance loans that provide credit to poor people, and the sale of carbon credits. But all the efforts devoted to solving the problem have yet to make much of a dent. During three months touring the Indian states of Maharashtra and Tamil Nadu in late 2013 and early 2014, I interviewed dozens of women in their homes and found that improved cooking-stoves often sit unused in corners, broken or simply abandoned. My observations tally with those of field studies, which show that adoption rates of the new technologies remain as low as they have been for decades. The ongoing struggle is enough to make many researchers question whether it is truly possible to improve biomass cooking-stoves, and whether it might be better to direct efforts towards expanding access to proven technologies \u2014 such as gas stoves and electric cookers \u2014 that are already standard in the developed world. It is time to move beyond age-old methods that cause so much pollution, both inside homes and out, says epidemiologist Kalpana Balakrishnan, director of the World Health Organization (WHO) Collaborating Centre for Occupational and Environmental Health at Sri Ramachandra University in Chennai, India. \"If you want clean air anywhere, you don\u2019t want to be burning biomass in this configuration: open biomass burning.\" \n               Counting the cost \n             The newest health data paint a stark picture of the impact of cooking with biomass. In March, the WHO estimated that 4.3 million people die annually from household air pollution caused by cooking with biomass and coal 3 . It is the greatest health risk in the world after high blood pressure, tobacco and alcohol 4 , with more people dying from the incremental, ongoing inhalation of smoke from fires they ignite in their own homes than from malaria, tuberculosis and HIV/AIDS combined. The new data more than double the WHO\u2019s 2004 estimate of the mortality rate from household air pollution. \u201cThis is not an energy issue,\u201d says Smith. \u201cThis is a health issue.\u201d The data show that household air pollution from such fires causes acute lower respiratory infections, chronic obstructive pulmonary disease, cardiovascular disease and lung cancer 4 . Women and children, in particular, are often exposed to excessive amounts of small particles less than 2.5 micrometres in diameter, known as PM 2.5 , which are considered the most dangerous to human health. A study 1  published by Smith and his colleagues this year that contributed to the WHO report 3  shows that Indian women cooking in households reliant on solid fuel are exposed to a mean 24-hour PM 2.5  concentration of 337 micrograms per cubic metre, more than ten times the WHO indoor air quality guidelines (see \u2018A burning issue\u2019). Even before a match is struck, the stoves put women and girls at risk, because they are usually tasked with collecting the heavy loads of firewood or other materials. They also must often travel to remote locations to find fuel, making them vulnerable to sexual attacks. I have seen the signs of fuel collection across the south Asian landscape. Neat piles of slender branches are stacked high outside homes in Karnataka. Walls in Bihar are plastered with discs of drying cow dung impressed with petite handprints. Limber children scramble up a tree, hacking away branches with a machete in Punjab. A lone woman drags a 6-metre-long trunk down a sandy path in Tamil Nadu. At least there is fuel; India is more abundant in biomass than many places in Africa, where the situation is even more dire. \n               In the neighbourhood \n             Lata Kisan Kare, who lives near Dadas, says that she does not worry much about the smoke that pours out of the  chulha  standing just outside her front door. The pollution does not bother her, she explains matter-of-factly: \u201cIt goes up and away.\u201d In reality, the smoke from Kare\u2019s fire is adding to the pollution in her village and beyond. In India, which now rivals China in terms of air pollution levels, one-quarter of the fine particulate matter in the ambient outdoor air originates from household cooking-stoves. Even people in households that have transitioned to liquefied petroleum gas (LPG) and other cleaner sources of fuel still have elevated pulmonary risk if their neighbours continue to cook with solid fuels, says Balakrishnan. And the impact of such fires reaches around the globe. Evidence suggests that black carbon \u2014 sunlight-absorbing particles from cooking fires and other sources \u2014 are helping to weaken the Asian monsoon, melt mountain glaciers and speed up warming in the Arctic 5 . In 2013, a major assessment found that the black carbon emitted by sources such as cooking-stoves, diesel engines and agricultural fires is the second leading cause of climate warming after carbon dioxide emissions. In Africa and Asia, residential burning of solid fuels, including biomass and coal, accounts for a staggering 60\u201380% of black-carbon emissions. The Global Alliance is trying to tackle these human and atmospheric problems through a range of activities, including improved monitoring and evaluation of cooking-stove programmes, and increased coordination between the hundreds of public, private, independent, non-governmental and funding entities across the 43 nations that are now partners under the alliance\u2019s umbrella. In 2012, the latest year for which data are available, partners distributed 8.2 million clean cooking-stoves. But distribution is just one step in the move away from smoky fires. Households such as Kare\u2019s show how challenging it will be for the alliance to reach its goals, especially if the focus is primarily on improved biomass stoves. As part of a local corporate social-responsibility initiative, Kare received a free improved cooking-stove a few years ago from Cummins, a multinational corporation that operates an industrial megasite in the area. Five hundred stoves, each costing less than US$15, were installed in village homes by an NGO. Many, like Kare\u2019s, sit unused. The stove is a low-tech clay one designed for a cleaner burn, with a combustion chamber made of heat-resistant concrete and an air-intake hole for improved draft. Like dozens of stoves I saw in the Satara District, this one had a brick wedged in the air hole for fear that snakes or scorpions might mistake it for a lair. Those who chose to use their stoves found that the design was flawed. The wire holding the combustion chamber bricks together burned out quickly, causing the stoves to crumple under the weight of a pot, and many found that the fire still smoked too much. Engineers have developed more sophisticated and sturdier designs, many of them portable, to prevent the kinds of problems seen in Kare\u2019s village. There are high-tech gasifier stoves, such as one from Philips, that rely on a rechargeable battery pack to run a fan for cleaner combustion. The Oorja also has a fan and burns pelletized field waste. Another option, BioLite, uses a thermoelectric generator to power a fan (as well as a USB charging port that might encourage mobile-phone-wielding husbands to buy improved stoves for their wives). And sleek units such as Envirofit and Prakti stoves use a natural draft to try to achieve a smoke-free fire. But all of these seem to have limitations in the eyes of the users, who often reject them. Women told me that the stoves are too small to support a pot of bath water, or not hot enough to cook a  roti , or flatbread. And many complained that they have to sit by the improved stoves and feed them continuously. With a conventional stove, they can just throw in a big log. Even those who do take to their new stoves face problems when the devices break; at present there is a very limited supply system in place for spare parts or repairs. The Global Alliance, along with companies such as Oorja, Envirofit and Prakti, are scrambling to put the necessary infrastructure in place, but the road remains uphill, and the best-performing stoves range from $50 to $80, far above the means of many of those who need them most. Similar problems have plagued stove-improvement efforts for decades. A government cooking-stove programme in India reports distributing more than 30 million improved stoves between 1983 and 2002, but the World Bank and numerous researchers have criticized the programme, like many other stove initiatives over the years, for poor stove design, high programme costs, low adoption rates and lack of stove maintenance. Giving devices away has not seemed to work, and several stove designers told me that heavily subsidized programmes undermine the growth of a local market for stoves and spare parts that might help to buttress long-term use. \n               Tradition wins \n             In late 2013, Smith prepared to revisit some of the villages he had first studied in the early 1980s. When we met up in Delhi just before his trip, he said, \u201cI\u2019m afraid that I\u2019m going to see that nothing has changed.\u201d He was wrong. In the villages, people were chatting away on mobile phones, and many houses had electricity, satellite dishes and running water. But one thing had not changed: nearly all households still used  chulhas  for at least some of their cooking. \u201cDevelopment,\u201d Smith says, \u201chas become unconnected with cooking.\u201d Up in Smoke, a 2012 study by researchers at the Massachusetts Institute of Technology in Cambridge, highlighted some of the ongoing challenges 6 . A randomized controlled study in Odisha, India, identified no long-term improvements in health, fuel consumption or \u2014 the authors inferred \u2014 greenhouse-gas emissions in households that had been given a clean cooking-stove, primarily because the stoves were not being used. Although the devices had been distributed by the award-winning NGO Gram Vikas, they quickly fell into disuse, or were not maintained at a level that kept emissions low. Smith criticizes the Up in Smoke study, saying that the introduced stove in question was known to be a poor one. His charge highlights the fact that no one knows how to define a \u2018clean\u2019 cooking-stove because there are no agreed standards for particulate emission from stoves.  Thirty years of research has really not produced a cost-effective way of burning wood.  Gautam Yadama, a professor of social work at Washington University in St. Louis, Missouri, and author of the book  Fires, Fuel & the Fate of 3 Billion  (Oxford Univ. Press, 2013), agrees that clean is a nebulous term. \u201cWhat are the metrics?\u201d he asks. \u201cWho is calling them improved, and are they improved?\u201d Efforts are afoot to address this issue. An International Organization for Standardization technical committee met in February in Nairobi to initiate development of standardized ways to test cooking-stoves, and the Indian government has also been busy developing labs that can approve certain cooking-stoves on the basis of thermal efficiency, as well as production of carbon monoxide and total particulate matter. But none of the designs can get around some fundamental problems of burning biomass. Such fuels vary tremendously in terms of their moisture content and chemical composition, which makes it difficult to design an inexpensive stove that can burn cleanly in many situations. Moreover, users will invariably operate their stoves differently from a lab technician. And, no matter what the stove, biomass cannot pack as much energy as fossil fuels. \u201cThirty years of research has really not produced a cost-effective way of burning wood,\u201d Balakrishnan says. \u201cWood is not a calorific-enough fuel to burn very cleanly.\u201d In some places, development is helping to make the question of adoption moot and hinting at a future without open fires. Many households are now using multiple types of cooking device, a strategy called \u2018stove stacking\u2019 that combines both modern and more traditional methods. This is especially evident in the southern state of Tamil Nadu, one of India\u2019s most developed areas. When I step into Emily Teresa\u2019s house, above the Ladies and Gents Tailor Shop in the Krishnagiri District on a Saturday morning, a pressure cooker is whistling on an LPG stove in the kitchen, and a kerosene stove is stored under the counter. Teresa prefers the LPG, but limits her use of it \u2014 and the kerosene stove \u2014 according to how long her subsidized fuel supply lasts. To heat bathwater, she uses a traditional  chulha  outside. And, in another room, she keeps an Envirofit biomass stove that she purchased through a woman\u2019s cooperative that she belongs to. The NGO Integrated Village Development Project helped to bring 25,000 of those stoves to her district. Her sister-in-law down the road also has multiple stoves, including an induction burner, an increasingly popular streamlined electrical unit that uses electromagnetic induction to transfer heat to pots. Where electricity is dependable, induction offers a stove that is much cleaner and more efficient, at a cost that is comparable to mid-range improved biomass stoves. This stove-stacking by those at the bottom of the energy ladder is reminiscent of the way that those higher up segue seamlessly between gas ranges, microwaves and electric kettles, while a hot-water heater quietly does its work unnoticed. But amid the stack of options, the Envirofit stove is often the last one that Teresa and her sister-in-law reach for. After decades of battling to get people to use improved cooking-stoves, many researchers worry that such devices will never win over consumers and thus never achieve the desired health and climate gains. \u201cMy bottom line is that nothing works,\u201d Smith says. \u201cThe only thing we know that\u2019s ever worked is gas and electric.\u201d Balakrishnan makes a moral argument against improved cooking-stoves, which still produce harmful amounts of pollutants compared with LPG or electric ones, powered by remote energy plants that commonly use fossil fuels. \u201cAre you justified in saying that it\u2019s OK to be just a little bit better?\u201d she asks. \u201cIf it\u2019s OK for 40% of the population to use fossil fuels, then why is not OK for the other 60% of the population? How can we have dual standards?\u201d \n               Energy transition \n             Smith, Balakrishnan and others think that the answer may be for people to jump several rungs on the energy ladder, by-passing improved biomass stoves. It would be better, they suggest, for designers and policy-makers to direct their efforts to helping more people transition directly to gas or electric stoves. One of Kare\u2019s neighbours has done just that. She saved up enough to buy an induction stove and an LPG stove, and spends as much on refilling her subsidized gas cylinders, which she says last three months, as Kare spends buying just three-week\u2019s worth of wood fuel. Kare, too, would like the cleaner stoves, but the up-front costs are too high for her. The rapidly changing energy landscape may be opening up new opportunities. Although Indians are apprehensive about the future of LPG subsidies, which are highly variable, many people are gaining access to new sources of alternative and renewable energy. In India and other developing countries, entrepreneurs are setting up decentralized electrical distribution systems fuelled by solar power, hydropower or biogas derived from agricultural waste (see  Nature   507 , 154\u2013156; 2014), which the world\u2019s rural poor have in abundance. Electric microgrids coupled with induction cookers could provide a means for millions to move away from polluting biomass stoves. Even the Global Alliance of Clean Cookstoves acknowledges the advantages of abandoning biomass stoves of any type. \u201cIf people can afford to and are able to access the cleaner cooking technologies, including electric and LPG stoves, then that\u2019s wonderful from our perspective,\u201d says Sumi Mehta, director of programmes for the alliance. \u201cBut we also know that in the short term not everybody\u2019s going to be able to leapfrog to that.\u201d Of the three billion people burning biomass, at least one-third have little hope of moving up the energy ladder any time soon. For them, she says, the alliance will continue to invest in creating a cleaner biomass stove, no matter how challenging the job. Putting the finishing touches to dinner as the children sit patiently beside her, Dadas has little time to worry about such issues. She dips a spoon into a Vicks container full of salt and adds the seasoning to the fenugreek greens that will accompany lentils and one  bhakri  bread for each of the six family members she is feeding tonight. Tomorrow is Christmas, which means a precious day off from the factory. As a Hindu, Dadas does not celebrate the holiday. When I ask her what she plans to do, she laughs sadly and says that she will use her axe and the extra time to go out collecting firewood. See Editorial  page 533 Reprints and Permissions"},
{"file_id": "511402a", "url": "https://www.nature.com/articles/511402a", "year": 2014, "authors": [{"name": "Virginia Gewin"}], "parsed_as_year": "2006_or_before", "body": "When California's governor enlisted the aid of two palaeoecologists, their careers took an unusual turn. Anthony Barnosky first thought the e-mail was a joke. As an expert in species extinctions who had just sounded the alarm over looming environmental crises, he had grown used to bizarre messages filling his inbox. There was the creepy e-mail enjoining him to \u201cwaste himself\u201d to reduce carbon emissions, a plug for carbon-storing \u201cbiorocks\u201d and a note encouraging him to explore \u201cyogic flying\u201d to help humanity. So Barnosky was understandably suspicious of the one-line request to contact California governor Jerry Brown. He wearily left a voice message at the number listed, apologizing if he had been spoofed. Out on a run later that day, his phone rang. Brown was on the other end. It was June 2012 and Barnosky, a palaeoecologist at the University of California, Berkeley, had days earlier published a headline-grabbing  Nature  paper claiming that Earth faced a 'planetary-scale tipping point' because of human-caused climate disruptions, species extinctions, ecosystem loss, pollution and population growth 1 . Among his co-authors was his wife, Elizabeth Hadly, also a palaeoecologist, at Stanford University in California. The governor had seen the media coverage and had questions about the science but was particularly interested in the level of agreement within the scientific community. Barnosky says that the gist of the conversation came down to one question: \u201cWhy aren't you guys shouting this from the rooftops?\u201d \u201cWe thought we were,\u201d recalls Hadly. Brown called a few more times before he made an unusual request: could Barnosky and Hadly translate the science into a format that he could use in political circles \u2014 a consensus statement? They agreed, and with Brown's help created a rallying cry of a report that has received more than 3,300 signatures of endorsement, the majority from researchers. The document armed Brown with a powerful scientific rationale for the need to combat climate change, and he has handed the report to dozens of politicians, including US President Barack Obama and Chinese President Xi Jinping. Soon after, California entered into an agreement with China to cooperate on developing green technology and reducing greenhouse-gas emissions. And language from the report became part of a climate pact between California, Oregon, Washington and British Columbia, to base energy and environmental decisions on findings presented in the consensus statement as well as in the latest report from the Intergovernmental Panel on Climate Change. Barnosky and Hadly say that working with Brown on the consensus statement altered their careers in ways they could not have imagined. It monopolized their time for much of a year, made them think much more practically about the relevance of their work and forced them to confront head-on the debate over whether scientists should step forward as policy advocates. \u201cThe consensus statement is more valuable than anything else I've done in my career,\u201d says Hadly. \u201cWe never could have guessed the reach this paper has had.\u201d \n               Translating the text \n             Before the document could help to inform international negotiations, Barnosky and Hadly had to transform the seven-page paper they had written for scientists into a document aimed at world leaders, policy-makers and the public. Already on sabbatical to write a book, Barnosky took the lead in writing the 46-page statement. He and Hadly discussed the structure while working on it at night and weekends from their home in Palo Alto, California. Barnosky would write draft sections in intensive bursts and send them around to Hadly and the 14 other co-authors. The hardest part, he says, was summarizing the 126 cited studies \u2014 without using any scientific jargon. It took 21 iterations to nail down the wording. This was new territory for them, but they had a guide. \u201cGovernor Brown taught us how to do this. He told us what kind of format he needed, not just to understand, himself, but to present to policy-makers,\u201d says Hadly. Bulleted points were a must, as was a one-page summary up front. Brown wanted it classic looking, not flashy or cluttered. They went back and forth on formatting, even where to put the signatures. And the font was key. Brown wanted a simple clear font, Franklin Gothic, with the words 'scientific consensus' highlighted in red. But he confined his advice to style; he had no input on the content. Once Hadly had put the finishing touches to it, the next step was to solicit signers. She and Barnosky made a list of global-change researchers they knew and sent a mass e-mail to them asking them to sign \u2014 and to pass it on to other relevant scientists. Within a month, the report had made its way to 41 countries and garnered 522 signatures. They were pleased with the response, but some people declined to sign because they did not agree with every sentence or, in particular, with the term 'tipping point'. Although there is little disagreement that abrupt shifts occur in Earth systems, including climate and the composition of ecosystems, some scientists baulk at the suggestion that there is enough evidence to predict a single tipping point for the whole planet. \u201cI thought it was a great review of the evidence for rapid shifts in ecology, but then it switched to a series of unsupported statements \u2014 at best a hypothesis \u2014 about how a global tipping point in the biosphere could happen,\u201d says Erle Ellis, a landscape ecologist at the University of Maryland, Baltimore County, who was involved in a response to the paper 2 . Yet Ellis understands why the term appeals to politicians. \u201cIt's an extraordinarily simple way to look at human-induced global change. It effectively creates a binary Earth; a line drawn in the sand,\u201d he says. \u201cDoing so gives a false sense of security on the 'safe side' and a false sense it is too late to act on the other.\u201d But the concept has power. In fact, game-theory simulations have shown that the kind of coordination needed to solve global environmental problems is much easier to achieve if a tipping point can be predicted with high certainty 3 . So the feature of the paper that Brown, as a lifelong politician, instinctively responded to \u2014 the tipping point \u2014 was the hardest to sell to scientists. Hadly and Barnosky admit that it is a loaded term. But as researchers who study time periods written in layers of rock, they are used to coming across tipping points. The single scrape of a trowel can reveal, for example, signs of the abrupt extinction of nearly half the world's megafauna some 11,000 years ago. \u201cThe world looks different \u2014 the chemistry, biology, even the stratigraphy \u2014 for a long time after tipping points accumulate and extinctions take place,\u201d says Hadly. To the authors on the consensus statement, the accelerating pace of change on Earth today is sending the planet towards a similar pivot point. They embodied that concept by commissioning Hadly's technician (also an artist), Lily Li, to create a computerized illustration of Earth teetering on the edge of a cliff, held back by a lone, stylized person. \n               At the precipice \n             Despite 8 months of work on the consensus statement, neither Hadly nor Barnosky came face to face with Brown until a warm, sunny May morning in 2013, when 400 business, government and civic leaders packed into a conference room at NASA's Ames Research Center in Mountain View, California, for a conference on sustainability technology. The two scientists were out of their element, with Barnosky in a rarely worn suit and Hadly feeling a bit odd in high heels and a new purple dress. They presented the governor with the report, officially called  Scientific Consensus on Maintaining Humanity's Life Support Systems in the 21st Century . They also gave him a framed version of  Earth on the Cliff . Brown pointed to the figure holding back the planet and asked who it was. Hadly replied: \u201cIt's you.\u201d In his address to the crowd, Brown chastised the media for its anaemic coverage of climate change. He said that a different approach was required to achieve the critical mass needed to create change \u2014 something like the consensus statement. \u201cGovernor Brown is a rare politician, as far as his own interest in science and his belief that science can help to persuade the public on climate change,\u201d says Susanne Moser, a climate-change communication consultant in Santa Cruz, California, who has worked with Brown on several issues. As the report's roll-out continued, it was not uncommon for Barnosky and Hadly to receive urgent requests from Brown's office. One day they got a call asking for hard copies of the consensus statement that the governor could take to southern California for a meeting with President Obama and President Xi Jinping. They went to a printing shop, ran off two dozen copies, then Barnosky and his daughter drove the reports to Sacramento, a six-hour round trip. In the thick of the release, Hadly and Barnosky spent up to half their time working on it. Hadly says that her efforts sparked several conversations with students, who were curious about how to take action without losing respect as a scientist. Conversely, outspoken population biologist Paul Ehrlich from Stanford was sceptical that anything would come of the statement; he had been involved in similar efforts in the past, and gained little political traction. All along, Hadly and Barnosky have tried to walk a fine line between vigorous communication of the facts and outright advocacy for particular policies. They call their chosen middle ground \u201cinformation advocacy\u201d, saying that it offers politicians scientifically sound paths on issues but stops short of calling for a particular route. Last autumn, for example, they were asked to add their names to a list of 20 scientists, including Ehrlich and Ken Caldeira, an atmospheric scientist at the Carnegie Institution for Science in Stanford, who were sending an open letter to Brown requesting a ban on shale fracking for oil and gas in California. But they declined, saying that the message was too policy prescriptive. Hadly also turned down an invitation to advocate for research on bringing back extinct species. \u201cI respect their approach but I don't buy into the notion that prescriptive statements ruin my credibility,\u201d says Caldeira. \u201cEverybody has opinions, and it doesn't do any service to science to keep those opinions secret.\u201d Yet Hadly and Barnosky's approach seems to have worked for Brown, the leader of the world's eighth largest economy. Although calls with Brown's staff have slowed to a weekly check-in, the scientists are still working on getting the message out, most recently briefing California's legislative leaders on climate-change impacts and possible mitigation targets, and on their plans for future projects with the governor's office. They also continue to champion the document outside the United States. Hadly has had the statement translated into other languages and Brown delivered it to political leaders in Norway, Japan, Mexico, Israel and Malaysia. On 4 June, she skyped into an event in Kathmandu during which members of Nepal's parliament signed the consensus statement, and pledged to address climate change as they draft a new constitution. \u201cThe thought that a government \u2014 particularly one squeezed in between China and India \u2014 is crafting a new constitution that hopes to build on these concerns is really powerful,\u201d she says. Barnosky says that it would not have happened without Brown. \u201cYou can have all the consensus statements in the world, but what makes them effective is when somebody in a policy-making position actually uses them,\u201d he says. For him and Hadly, the biggest lesson learned is that \u201ca scientist's job isn't over once a paper is published\u201d, he says. Or, as Hadly puts it, scientists can reach a point in their careers when they decide, in a world of limited resources and time, to focus on making a difference. \n                     We must set planetary boundaries wisely 2012-May-23 \n                   \n                     We must set planetary boundaries wisely 2012-May-23 \n                   \n                     The voice of science: let's agree to disagree 2011-Oct-05 \n                   \n                     Four ways to take the policy plunge 2007-Aug-22 \n                   \n                     Consensus science, or consensus politics? 2001-Jul-12 \n                   \n                     Nature  special: Outlook for Earth \n                   \n                     Nature  special: Planetary boundaries \n                   \n                     Nature  special: Science and politics \n                   \n                     Scientific consensus statement \n                   Reprints and Permissions"},
{"file_id": "509552a", "url": "https://www.nature.com/articles/509552a", "year": 2014, "authors": [{"name": "Amanda Gefter"}], "parsed_as_year": "2006_or_before", "body": "A concept developed for computer science could have a key role in fundamental physics \u2014 and point the way to a new understanding of space and time. When physicist Leonard Susskind gives talks these days, he often wears a black T-shirt proclaiming \u201cI \u2665 Complexity\u201d. In place of the heart is a Mandelbrot set, a fractal pattern widely recognized as a symbol for complexity at its most beautiful. That pretty much sums up his message. The 74-year-old Susskind, a theorist at Stanford University in California, has long been a leader in efforts to unify quantum mechanics with the general theory of relativity \u2014 Albert Einstein's framework for gravity. The quest for the elusive unified theory has led him to advocate counter-intuitive ideas, such as superstring theory or the concept that our three-dimensional Universe is actually a two-dimensional hologram. But now he is part of a small group of researchers arguing for a new and equally odd idea: that the key to this mysterious theory of everything is to be found in the branch of computer science known as computational complexity. This is not a subfield to which physicists have tended to look for fundamental insight. Computational complexity is grounded in practical matters, such as how many logical steps are required to execute an algorithm. But if the approach works, says Susskind, it could resolve one of the most baffling theoretical conundrums to hit his field in recent years: the black-hole firewall paradox, which seems to imply that either quantum mechanics or general relativity must be wrong. And more than that, he says, computational complexity could give theorists a whole new way to unify the two branches of their science \u2014 using ideas based fundamentally on information. \n               Behind a firewall \n             It all began 40 years ago, when physicist Stephen Hawking at the University of Cambridge, UK, realized that quantum effects would cause a black hole to radiate photons and other particles until it completely evaporates away. As other researchers were quick to point out, this revelation brings a troubling contradiction. According to the rules of quantum mechanics, the outgoing stream of radiation has to retain information about everything that ever fell into the black hole, even as the matter falling in carries exactly the same information through the black hole's event horizon, the boundary inside which the black hole's gravity gets so strong that not even light can escape. Yet this two-way flow could violate a key law of quantum mechanics known as the no-cloning theorem, which dictates that making a perfect copy of quantum information is impossible. Happily, as Susskind and his colleagues observed 1  in 1995, nature seemed to sidestep any such violation by making it impossible to see both copies at once: an observer who remains outside the horizon cannot communicate with one who has fallen in. But in 2012, four physicists at the University of California, Santa Barbara \u2014 Ahmed Almheiri, Donald Marolf, Joseph Polchinski and James Sully, known collectively as AMPS \u2014 spotted a dangerous exception to this rule 2 . They found a scenario in which an observer could decode the information in the radiation, jump into the black hole and then compare that information with its forbidden duplicate on the way down. AMPS concluded that nature prevents this abomination by creating a blazing firewall just inside the horizon that will incinerate any observer \u2014 or indeed, any particle \u2014 trying to pass through. In effect, space would abruptly end at the horizon, even though Einstein's gravitational theory says that space must be perfectly continuous there. If AMPS's theory is true, says Raphael Bousso, a theoretical physicist at the University of California, Berkeley, \u201cthis is a terrible blow to general relativity\u201d. \n               Does not compute \n             Fundamental physics has been in an uproar ever since, as practitioners have struggled to find a resolution to this paradox. The first people to bring computational complexity into the debate were Stanford\u2019s Patrick Hayden, a physicist who also happens to be a computer scientist, and Daniel Harlow, a physicist at Princeton University in New Jersey. If the firewall argument hinges on an observer's ability to decode the outgoing radiation, they wondered, just how hard is that to do? Impossibly hard, they discovered. A computational-complexity analysis showed that the number of steps required to decode the outgoing information would rise exponentially with the number of radiation particles that carry it. No conceivable computer could finish the calculations until long after the black hole had radiated all of its energy and vanished, along with the forbidden information clones. So the firewall has no reason to exist: the decoding scenario that demands it cannot happen, and the paradox disappears.  The black hole's interior is protected by an armour of computational complexity.  Hayden was sceptical of the result at first. But then he and Harlow found much the same answer for many types of black hole 3 . \u201cIt did seem to be a robust principle,\u201d says Hayden: \u201ca conspiracy of nature preventing you from performing this decoding before the black hole had disappeared on you.\u201d The Harlow\u2013Hayden argument made a big impression on Scott Aaronson, who works on computational complexity and the limits of quantum computation at the Massachusetts Institute of Technology in Cambridge. \u201cI regard what they did as one of the more remarkable syntheses of physics and computer science that I've seen in my career,\u201d he says. It also resonated strongly among theoretical physicists. But not everyone is convinced. Even if the calculation is correct, says Polchinski, \u201cit is hard to see how one would build a fundamental theory on this framework\u201d. Nevertheless, some physicists are trying to do just that. There is a widespread belief in the field that the laws of nature must somehow be based on information. And the idea that the laws might actually be upheld by computational complexity \u2014 which is defined entirely in terms of information \u2014 offers a fresh perspective. It certainly inspired Susskind to dig deeper into the role of complexity. For mathematical clarity, he chose to make his calculations in a theoretical realm known as anti-de Sitter space (AdS). This describes a cosmos that is like our own Universe in the sense that everything in it, including black holes, is governed by gravity. Unlike our Universe, however, it has a boundary \u2014 a domain where there is no gravity, just elementary particles and fields governed by quantum physics. Despite this difference, studying physics in AdS has led to many insights, because every object and physical process inside the space can be mathematically mapped to an equivalent object or process on its boundary. A black hole in AdS, for example, is equivalent to a hot gas of ordinary quantum particles on the boundary. Better still, calculations that are complicated in one domain often turn out to be simple in the other. And after the calculations are complete, the insights gained in AdS can generally be translated back into our own Universe. \n               Increasing complexity \n             Susskind decided to look at a black hole sitting at the centre of an AdS universe, and to use the boundary description to explore what happens inside a black hole's event horizon. Others had attempted this and failed, and Susskind could see why after he viewed the problem through the lens of computational complexity. Translating from the boundary of the AdS universe to the interior of a black hole requires an enormous number of computational steps, and that number increases exponentially as one moves closer to the event horizon 4 . As Aaronson puts it, \u201cthe black hole's interior is protected by an armour of computational complexity\u201d. Furthermore, Susskind noticed, the computational complexity tends to grow with time. This is not the increase of disorder, or entropy, that is familiar from everyday physics. Rather, it is a pure quantum effect arising from the way that interactions between the boundary particles cause an explosive growth in the complexity of their collective quantum state. If nothing else, Susskind argued, this growth means that complexity behaves much like a gravitational field. Imagine an object floating somewhere outside the black hole. Because this is AdS, he said, the object can be described by some configuration of particles and fields on the boundary. And because the complexity of that boundary description tends to increase over time, the effect is to make the object move towards regions of higher complexity in the interior of the space. But that, said Susskind, is just another way of saying that the object will be pulled down towards the black hole. He captured that idea in a slogan 4 : \u201cThings fall because there is a tendency toward complexity.\u201d Another implication of increasing complexity turns out to be closely related to an argument 5  that Susskind made last year in collaboration with Juan Maldacena, a physicist at the Institute for Advanced Study in Princeton, New Jersey, and the first researcher to recognize the unique features of AdS. According to general relativity, Susskind and Maldacena noted, two black holes can be many light years apart yet still have their interiors connected by a space-time tunnel known as a wormhole. But according to quantum theory, these widely separated black holes can also be connected by having their states 'entangled', meaning that information about their quantum states is shared between them in a way that is independent of distance. After exploring the many similarities between these connections, Susskind and Maldacena concluded that they were two aspects of the same thing \u2014 that the black hole's degree of entanglement, a purely quantum phenomenon, will determine the wormhole's width, a matter of pure geometry. With his latest work, Susskind says, it turns out that the growth of complexity on the boundary of AdS shows up as an increase in the wormhole's length. So putting it all together, it seems that entanglement is somehow related to space, and that computational complexity is somehow related to time. Susskind is the first to admit that such ideas by themselves are only provocative suggestions; they do not make up a fully fledged theory. But he and his allies are confident that the ideas transcend the firewall paradox. \u201cI don't know where all of this will lead,\u201d says Susskind. \u201cBut I believe these complexity\u2013geometry connections are the tip of an iceberg.\u201d \n                     Stephen Hawking: 'There are no black holes' 2014-Jan-24 \n                   \n                     Simulations back up theory that Universe is a hologram 2013-Dec-10 \n                   \n                     Theoretical physics: The origins of space and time 2013-Aug-28 \n                   \n                     Astrophysics: Fire in the hole! 2013-Apr-03 \n                   \n                     Kavli workshop on the firewall paradox \n                   \n                     Juan Maldacena on Anti-de Sitter space \n                   \n                     Leonard Susskind on classical and modern physics \n                   Reprints and Permissions"},
{"file_id": "510026a", "url": "https://www.nature.com/articles/510026a", "year": 2014, "authors": [{"name": "Laura Spinney"}], "parsed_as_year": "2006_or_before", "body": "For decades, most researchers ignored the leading genetic risk factor for Alzheimer's disease. That is set to change. One day in 1991, neurologist Warren Strittmatter asked his boss to look at some bewildering data. Strittmatter was studying amyloid-\u03b2, the main component of the molecular clumps found in the brains of people with Alzheimer's disease. He was hunting for amyloid-binding proteins in the fluid that buffers the brain and spinal cord, and had fished out one called apolipoprotein E (ApoE), which had no obvious connection with the disease. Strittmatter's boss, geneticist Allen Roses of Duke University in Durham, North Carolina, immediately realized that his colleague had stumbled across something exciting. Two years earlier, the group had identified a genetic association between Alzheimer's and a region of chromosome 19. Roses knew that the gene encoding ApoE was also on chromosome 19. \u201cIt was like a lightning bolt,\u201d he says. \u201cIt changed my life.\u201d In humans, there are three common variants, or alleles, of the  APOE  gene, numbered 2, 3 and 4. The obvious step, Roses realized, was to find out whether individual  APOE  alleles influence the risk of developing Alzheimer's disease. The variants can be distinguished from one another using a technique called the polymerase chain reaction (PCR). But Roses had little experience with PCR, so he asked the postdocs in his team to test samples from people with the disease and healthy controls. The postdocs refused: they were busy hunting for genes underlying Alzheimer's, and  APOE  seemed an unlikely candidate. The feeling in the lab, recalls Roses, was that \u201cthe chief was off on one of his crazy ideas\u201d. Roses then talked to his wife, Ann Saunders, a mouse geneticist who was skilled at PCR. She had just given birth to their daughter and was on maternity leave, so they struck a deal. \u201cShe did the experiments while I held the baby,\u201d he says. Within three weeks, they had collected the data that would fuel a series of landmark papers showing that the  APOE4  allele is associated with a greatly increased risk of Alzheimer's disease 1 . Twenty years on,  APOE4  remains the leading genetic risk factor for Alzheimer's, the most common form of dementia (see 'Risky inheritance'). Inheriting one copy of  APOE4  raises a person's risk of developing the disease fourfold. With two copies, the risk increases 12-fold. Yet Roses' data were largely criticized or ignored. Within a couple of years, interest in ApoE had dwindled as researchers flocked to study amyloid-\u03b2. The handful of labs that continued to pursue ApoE did so in the face of indifference from funding agencies and the neuroscience community, and without the resources needed to validate experimental findings with larger studies. Today, the function of the ApoE protein in the brain remains mostly unknown. This neglect of such a strong lead has puzzled some outside the Alzheimer's field. At a forum on brain diseases in Frankfurt, Germany, Thomas Bourgeron, an autism researcher at the Pasteur Institute in Paris, voiced his confusion. \u201cIf I had a risk factor like that, I'd be hot on its trail.\u201d But interest in the lipoprotein is picking up, in part because attempts to target amyloid-\u03b2 have repeatedly disappointed in major clinical trials. Pharmaceutical companies are pulling back from amyloid-based approaches and some academics have begun to question the focus on the molecule. For the first time, researchers are developing drugs aimed at the ApoE4 protein and drawing attention from industry. \u201cThe amyloid hypothesis became such a strong scientific orthodoxy that it began to be accepted on the basis of faith rather than evidence,\u201d says Zaven Khachaturian, president of the non-profit campaign Prevent Alzheimer's Disease 2020, and former coordinator of Alzheimer's-related activities at the US National Institutes of Health. Until recently, he says, \u201cno one has stepped back to ask the fundamental question of whether our basic premise about the disease is the correct one\u201d. \n               Stiff competition \n             Opinions differ as to why Roses' finding was neglected, but many agree that bad timing played a part. In 1991, John Hardy and David Allsop had proposed the 'amyloid cascade hypothesis'. This posits that Alzheimer's disease results from the abnormal build-up of amyloid-\u03b2 clusters, or plaques, in the brain 2 . Others rallied around the idea and it has won most of the funding available to the field ever since. But Roses did not subscribe to that theory. \u201cAmyloid is one of many substances that builds up in plaques as a result of dying cells and atrophy in the brain,\u201d he says. \u201cI never did think it was the cause.\u201d In saying so, he may have deterred others from investigating a possible ApoE\u2013amyloid link, and inadvertently set up a competition between the two hypotheses for funding. He never got another grant to work on ApoE. But there were also technical obstacles to ApoE research. The protein is found throughout the body, making it difficult to target the molecule specifically in the brain. And ApoE is bound to fat, so it tends to stick to other molecules in biochemical assays, says Menelas Pangalos, who leads research on small-molecule discovery at AstraZeneca in Macclesfield, UK, and has long had an interest in ApoE. Working with such proteins requires an intimate understanding of lipid biochemistry. \u201cIf you want to study ApoE biology, you really need to devote a laboratory to understanding the techniques,\u201d says neurologist David Holtzman of Washington University in St. Louis, Missouri. Holtzman did just that, establishing a separate lab dedicated to developing techniques for handling lipoproteins in the central nervous system. Amyloid was the easier target. Two decades of intensive pursuit have yielded a range of drugs that alter the metabolism of amyloid-\u03b2, but these have yet to fulfil expectations. Of the six drugs that were in phase II or III clinical trials in 2012, half have since been dropped because of either safety concerns or lack of effectiveness. This comes against a backdrop of ageing populations, overstretched health-care systems and a dearth of medications for Alzheimer's disease. \u201cThe large number of major failed trials in Alzheimer's is quite frightening,\u201d says Lennart Mucke, director of the Gladstone Institute of Neurological Disease at the University of California, San Francisco. \u201cIt has really scared off big pharma.\u201d The three remaining drug candidates that target amyloid-\u03b2 are currently being tested in people with Alzheimer's, as well as in individuals who have a high risk of developing the disease but who have not yet developed symptoms. Imaging studies have shown that the brains of high-risk individuals look and behave differently from controls decades before the onset of Alzheimer's, and long before they start to accumulate amyloid-\u03b2 or lose grey matter 3 . The trials will examine whether the drugs prevent or delay the onset of the disease; they are due to wrap up over the next six years. There is a growing sense in the field \u2014 among academics and industry representatives alike \u2014 that these efforts are the last chance for the amyloid hypothesis. Amid these concerns, the spotlight has swung back to ApoE. If the prevention trials fail, it will be up to academics to persuade companies back to the table with solid preclinical and early clinical data, says Mucke. He is optimistic that ApoE researchers may soon have that leverage. Despite the obstacles in this area, there is an emerging understanding of how ApoE4 increases risk, which Holtzman's and Mucke's groups have explored through transgenic mice that they have developed to express human forms of ApoE. The molecule seems to contribute to Alzheimer's through two distinct pathways, one of which is amyloid-dependent. In both animals and humans, ApoE4 strongly promotes amyloid-\u03b2 deposition in the brain, compared with ApoE3, long considered the 'neutral' form when it comes to Alzheimer's risk. ApoE2, which is considered the protective form, decreases the build-up 4 . \u201cThese are compelling data,\u201d says Holtzman. The other mechanism does not involve amyloid. When neurons are under stress, they make ApoE as part of a repair mechanism. The 'bad' ApoE4 form tends to be broken down into toxic fragments that damage the cell's energy factories \u2014 the mitochondria \u2014 and alter the cell skeleton. The relative contribution of these two pathways to Alzheimer's risk is not known, says Holtzman, but he and others think that changing a harmful form of ApoE into a less damaging one might prove a promising therapeutic approach. At the Gladstone, cardiovascular scientist Robert Mahley, working with a team including neuroscientist Yadong Huang, has identified small 'corrector' molecules that modify the structure of ApoE4 protein to one more like that of ApoE3, thereby reducing abnormal fragmentation 5 . In cell culture, low concentrations of these corrector molecules can reduce mitochondrial impairment and neuronal dysfunction 6 . They are now being tested more rigorously in a range of animal models. If the molecules ultimately prove safe and effective in humans, Mucke foresees a day when doctors will prescribe them for people deemed at risk of Alzheimer's, just as statins are offered to those with high cholesterol and an elevated risk of cardiovascular disease. \n               Above and beyond \n             Such drugs could also have implications beyond Alzheimer's. \u201cThe mitochondrial-impairment hypothesis provides a pretty logical and parsimonious explanation for why ApoE4 does bad things,\u201d says Mucke, \u201cnot only in the context of Alzheimer's, but maybe also in other diseases.\u201d There is evidence that it may be a risk factor in Parkinson's disease and epilepsy. It is also associated with an increased risk of a poor outcome after brain injury, and more rapid progression of untreated HIV infection. Fifteen biotechnology companies are already collaborating with the Gladstone to develop these and similar drugs. Despite his inability to get grants, Roses never gave up on ApoE. But a few years after his group discovered the link between ApoE and Alzheimer's, he wearied of the constant battles for funding. He left academia and spent ten years in industry \u2014 where he continued to work on ApoE, among other things \u2014 before returning to Duke in 2008. In 2009, his group described a stretch of non-coding DNA in a gene called  TOMM40  that sits next to  APOE  on chromosome 19. This stretch of DNA, known by the shorthand 523, varies in length. The length of 523 can determine the extent to which  TOMM40  and  APOE  are expressed 7 . The discovery was important, Roses says, because the protein encoded by  TOMM40 , called Tom40, is crucial to healthy mitochondria. Tom40 forms a channel in the outer mitochondrial membrane that is used to import proteins. Without these proteins, mitochondria cannot divide as they should throughout a cell's life. \u201cIt's a big effect that's been known about for a decade,\u201d says Roses, \u201cBut it's not well-known in the Alzheimer's field.\u201d Roses went on to suggest that 523 could be exploited to develop therapies and improved tests for Alzheimer's risk. Most people will develop Alzheimer's if they live long enough, but only about 25% of people carry an  APOE4  allele. As a result, a prognostic test for  APOE4  will only ever be partially informative. But genotyping both  APOE  and  TOMM40  could provide information about a wider swathe of the population, Roses says. His group has found, for example, that  APOE3  \u2014 by far the most common  APOE  allele in humans \u2014 is usually inherited either with a short or a very long 523 tract. In those who inherit two  APOE3  alleles, age of onset differs depending on which combination of the two 523 variants they also inherit. Other labs have found evidence supporting Roses' hypotheses, but some attempts to replicate his  TOMM40  findings have failed. In 2012, Hardy, now at University College London, and a colleague, geneticist Rita Guerreiro, wrote an editorial 8  in which they argued that  TOMM40  did not independently affect Alzheimer's risk. Roses' faith in his hypothesis has not wavered: he believes he has a sound mechanistic explanation for his findings. And he says that the genome-wide studies that failed to reproduce his results lacked sufficient power to reveal the association between  TOMM40  and Alzheimer's disease. Khachaturian says a proper test of Roses' findings \u2014 using Roses' methods in a larger cohort of patients \u2014 has not yet been done. Roses hopes to soon be able to back up his findings with more clinical data and has launched a company called Zinfandel Pharmaceuticals in Durham, fuelled in part by his own funds. Along with the Japanese pharmaceutical company Takeda, based in Osaka, Zinfandel is currently funding a phase III trial, called TOMMORROW, that will put his ideas to the test. TOMMORROW is expected to run for about 5 years and will recruit close to 6,000 healthy, elderly individuals. It will evaluate a risk-assessment algorithm based on age,  APOE  and  TOMM40 . The trial will also investigate whether a low dose of a drug called pioglitazone \u2014 already approved at much higher doses for certain patients with type 2 diabetes \u2014 can delay disease onset in those individuals deemed by the algorithm to be at high risk of Alzheimer's. Evidence from animal and small-scale human studies suggests that pioglitazone may prevent or reverse Alzheimer's-related pathology and symptoms 9 . Roses thinks it may do so by stimulating mitochondria to divide. The ongoing trials could have major consequences even without yielding a cure: research has shown that an intervention that could delay the onset of Alzheimer's by just 2 years would result, 50 years later, in nearly 2 million fewer cases of the disease in the United States than projected otherwise 10 . And the results coming in over the next few years could force researchers to re-evaluate their understanding of dementia. It is time it was recognized for what it is, says Khachaturian: a failure of complex, interacting physiological systems. Looking at any one of these systems \u2014 even those involving ApoE4 \u2014 in isolation is unlikely to fully explain changes in behaviour. \u201cThe field is going to recognize the limitations of current approaches and step back,\u201d he says. \u201cAnd if we're honest with ourselves, we'll start forging new directions.\u201d \n                     Novartis reboots brain division 2013-Oct-08 \n                   \n                     Studies cast doubt on cancer drug as Alzheimer's treatment 2013-May-23 \n                   \n                     Alzheimer\u2019s test may undermine drug trials 2012-Dec-18 \n                   \n                     Alzheimer\u2019s drugs take a new tack 2012-Sep-04 \n                   \n                     Alzheimer's disease: A protective mutation 2012-Aug-01 \n                   \n                     Nature  Outlook: Alzheimer's disease \n                   \n                     Nature  Outlook: Ageing \n                   \n                     US National Institute on Aging: Alzheimer's disease genetics \n                   Reprints and Permissions"},
{"file_id": "510022a", "url": "https://www.nature.com/articles/510022a", "year": 2014, "authors": [{"name": "Jessica Marshall"}], "parsed_as_year": "2006_or_before", "body": "Researchers make headway in turning photons into fuel. On a bright spring morning in Pasadena, California, the air is rich with the smells of cut grass and flowers. Photosynthesis seems effortless here: the fronds and blooms that line the walkways of the California Institute of Technology (Caltech) bask in the sunlight, quietly using its energy to store sugars, stretch their leaves, deepen their roots and tend to their cellular processes. Inside Caltech's Jorgensen Laboratory, however, more than 80 researchers are putting a lot of effort into doing the leaf's job using silicon, nickel, iron and any number of other materials that would be more at home inside a cell phone than a plant cell. Their gleaming new labs are the headquarters of the Joint Center for Artificial Photosynthesis (JCAP), a 190-person research programme funded by the US Department of Energy (DOE) with US$116 million over five years. The centre's goal is to use sunlight to make hydrogen and other fuels much more efficiently than real leaves ever made biomass. The researchers are pursuing this goal with a certain urgency. Roughly 13% of greenhouse-gas emissions worldwide come from transportation, so phasing out polluting fuels is a key environmental target. One approach is to replace cars and light trucks with electric vehicles charged by solar cells or wind \u2014 but that cannot tackle the whole problem. Nathan Lewis, an inorganic chemist at Caltech and JCAP's scientific director, says that some 40% of current global transportation cannot be electrified. For example, barring a major breakthrough, there will never be a plug-in hybrid plane: no craft could hold enough batteries. Liquid fuels are unbeatable when it comes to convenience combined with compact energy storage. That is why funding agencies around the world \u2014 and at least a few private companies \u2014 are putting unprecedented resources into making fuels using power from the Sun, which is not only carbon-free but effectively inexhaustible. JCAP stands out not only for its scale, but also for its ambition. It is one of five Energy Innovation Hubs created by the DOE beginning in 2010 to focus on specific problems using basic research, applied research and engineering. JCAP has promised to deliver a working prototype of an artificial leaf by the time its initial grant runs out in 2015. Although the centre has taken some important steps in that direction \u2014 including one reported just last week 1  \u2014 it is still a long way from delivering on that promise, \u201cThis is a really, really difficult, challenging problem,\u201d says electrochemist John Turner of the US National Renewable Energy Laboratory in Golden, Colorado. \u201cThe payback would be huge, but it's not as simple as everyone wanted it to be when we started playing in this area 40 years ago.\u201d Still, the surge of funding and attention has given many researchers reason to hope for long-term success. \u201cIf you could sustain this type of effort for the next ten years,\u201d says Michael Wasielewski, a chemist at Northwestern University in Evanston, Illinois, \u201cit's conceivable you could have a practical solution.\u201d \n               Catching rays \n             The concept of artificial photosynthesis goes back to 1912, but the push to achieve it did not start until 1972, when Japanese researchers outlined what a device would need to take in sunlight and use it to split water into oxygen and hydrogen fuel 2 . Progress was slow. In 1998, Turner reported 3  a complete system that showed a major advance \u2014 it stored 12% of the incoming solar energy as fuel, compared with 1% of energy stored as biomass in real leaves. But it cost more than 25 times too much to be competitive, and its performance dropped off after 20 hours of sunshine. There are three things you want from an artificial leaf, says Lewis: \u201cYou want it to be efficient, cheap and robust. I can give you any two today, but not the third at the same time.\u201d JCAP's mission is to fix that problem \u2014 and in the process, to create a system that is much cheaper than just splitting water with electricity from a solar panel. At the heart of JCAP's artificial-leaf design are two electrodes immersed in an aqueous solution. Typically, each electrode is made of a semiconductor material chosen to capture light energy from a particular part of the solar spectrum, and coated with a catalyst that will help to generate hydrogen or oxygen at useful speeds (see 'Splitting water'). Like many other artificial-photosynthesis devices, JCAP's system is divided by a membrane to keep the resulting gases apart and reduce the risk of an explosive reaction. Once the water has been split, the hydrogen is harvested. It can be used as a fuel by itself \u2014 perhaps in hydrogen-powered cars such as those already making their way into showrooms in California \u2014 or be reacted with carbon monoxide to make liquid-hydrocarbon fuels. Making any one of the artificial leaf's components work well is a challenge; combining all of them into a complete system is even harder. \u201cThis is exactly like building a plane,\u201d says Lewis. \u201cYou've got to not just have an engine, you have to have a design with wings and the fuselage and the engine and the avionics \u2014 and the plane, in the end, has to fly.\u201d Much of the difficulty comes down to finding the right materials. Silicon, for instance, makes a good photocathode \u2014 the electrode that produces hydrogen gas \u2014 but is stable only when the solution around it is acidic. Unfortunately, the situation is reversed with photoanodes, which produce oxygen: the good ones are stable only when the solution is basic, not acidic. And the best catalyst for the oxygen-producing electrode, iridium, is both rare and expensive, which makes it unsuitable for commercial-scale devices. JCAP's High Throughput Experimentation lab is tackling the materials problem with inkjet printers modified to churn out spots of alloys on glass plates for testing as catalysts and photoabsorbers. Together, the printers are able to produce up to one million spots of varying composition per day. In one experiment 4  to find the best proportions of nickel, iron, cobalt and cerium oxides to generate oxygen from water, the team screened nearly 5,500 combinations for stability and function using a miniaturized chemical lab that glided over the glass plates tirelessly. The best-performing combination is not the most effective catalyst ever found for this reaction, but it is transparent, allowing light to pass through to the photoabsorber, and it has good chemical compatibility with that material. One of the toughest challenges for artificial photosynthesis has always been getting a good material for the photoanode, says Carl Koval, an electrochemist and JCAP's director. \u201cThose things were always horribly unstable, often not even stable for minutes.\u201d Many researchers have focused their search on materials known to be cheap and stable \u2014 certain metal oxides, for example \u2014 and tried to make them into good light absorbers. Others feel that it is better to start with materials that are known to be efficient light harvesters, and to work at making them stable and cheap. Just last week, a JCAP team reported 1  success with the latter approach. By putting a protective coating of titanium dioxide on high-performing photoabsorbers such as silicon, the researchers achieved big gains in stability. \u201cThat's basically the last piece of the puzzle to create the first-generation prototype,\u201d says Koval, who predicts that JCAP will have an artificial leaf running in the next few months. Publication of a preliminary system including the titanium dioxide coating is in the works, says Lewis. \u201cThat's going to be a double-digit-efficiency, stable system.\u201d The threshold for commercial viability is thought to be in the 10\u201320% range. The photoabsorbers will not be cheap enough to bring to market, concedes Lewis, because their cores are made from expensive single-crystal silicon. But if subsequent research shows that cheaper fabrication methods work, the system could be cost-effective. \n               Spectrum of ideas \n             JCAP will soon complete its fourth year of operations. It got off to a slow start as new labs were built, but researchers both in and outside the centre praise its systematic focus on producing a practical system, and its progress so far. Even Turner, whose lab bid to become the solar-fuels hub but lost out to Lewis's team, is encouraged by JCAP's latest direction. Still, says Koval, the centre has its critics. Some take issue with its emphasis on engineering and prototype development. But if JCAP were to focus on basic science, he says, it would not be \u201cdoing what the DOE created the hub for in the first place\u201d. Other critics object to how JCAP concentrates on just one of several possible ways to tackle artificial photosynthesis. \u201cA lot of people would have been happier if the DOE had spread the funding around all these different ways of doing this,\u201d says Koval. But that kind of dilution of effort would be risky in its own way, he argues: \u201cThen you'd have progress on none of them.\u201d Besides, many of the alternative approaches are being pursued elsewhere. Up the coast in Santa Barbara, California, for example, a start-up firm called HyperSolar is testing a system in which coated nano- or micro-particles combining a photoabsorber and a catalyst are placed in a transparent, water-filled plastic bag. The bag will inflate as it is exposed to sunlight, and hydrogen and oxygen gas form inside. Such units could be deployed in sunny regions such as deserts. A 2009 DOE report 5  estimated that, if it uses cheap materials, this 'baggie' approach could produce hydrogen economically with 10% efficiency, stable for 10 years. But the system is risky, says Turner, because it produces oxygen along with the hydrogen. \u201cIf you're talking about 100 square miles of baggies in the desert with this explosive mixture,\u201d he says, \u201cone lightning bolt and you have a disaster.\u201d HyperSolar researchers are exploring several ways to eliminate that danger. One is to use a system that separates the gases into two bags, says Syed Mubeen, a postdoc at the University of California, Santa Barbara, and lead scientist at the company. Another is to run the system using waste water rather than pure water, so that the oxygen reacts with organic impurities and degrades them into valuable chemicals. This approach \u201ccompletely removes oxygen out of the equation\u201d, says Mubeen. As with JCAP's stable photoanode, HyperSolar's photoabsorber is protected by a coating. \n               Light industry \n             Another entrant in the artificial-photosynthesis field is the Japan Technological Research Association of Artificial Photosynthetic Chemical Process (ARPChem), a consortium of universities and companies that has government funding comparable to JCAP's grant \u2014 although over ten years rather than five \u2014 to develop a bag-based approach. Kazunari Domen, a chemist at the University of Tokyo and leader of ARPChem's water-splitting group, says that one of the companies in the consortium has been working on a membrane to separate the hydrogen and oxygen products. Other projects are making photoabsorbers from organic molecules, rather than semiconductors. Some are building molecular assemblies inspired directly by the photosynthetic apparatus of plants. And in the past few years, a class of materials called perovskites has drawn the attention of the solar-photovoltaic community for its high energy-conversion efficiency; some researchers think that the materials also have potential in artificial photosynthesis. Daniel Nocera, a chemist at Harvard University in Cambridge, Massachusetts, launched Sun Catalytix to develop his work on a low-cost catalyst. But the company announced last year that it has put that research on hold to pursue a less challenging product with prospects of turning a profit for investors sooner. The decision underscores the challenges of bringing a commercially viable artificial-photosynthesis system to market. \n               Berkeley bubbles \n             On a spring day in the arty\u2013industrial district of Berkeley, California, researchers demonstrate a prototype system inside the temporary lab space that houses JCAP's northern site. As a sunlamp shines on a CD-sized plastic box, fine streams of hydrogen bubbles rise between blue strips of catalyst-coated silicon and exit through tubes in the box's top. This prototype system is not the team's best: it won't last and it is not very efficient. But it is still encouraging to see champagne-like bubbles triggered simply by light. Then Karl Walczak, a postdoc in JCAP's prototyping group, slides a second plastic box in front of the lamp. Inside is a small black square: a new titanium dioxide-coated photocathode. This second system immediately begins to generate bubbles much faster than the first. \u201cThis is where the field is going,\u201d says Walczak. JCAP researchers hope that such prototypes will ultimately lead to industrial hydrogen-production plants. They predict arrays of cells kilometres long, with a tower supplying water and pipes drawing the hydrogen to a storage tank. Some researchers propose that domestic units may also be part of the future, but Lewis warns that the small amount of sunlight that falls on a rooftop cannot make enough hydrogen to supply a family's energy needs. Others say that the technology could be useful in areas of the developing world that lack an energy infrastructure, offering distributed fuel generation where it is needed. In the meantime, researchers at JCAP and elsewhere are moving forward on all fronts. Devens Gust, a chemist at Arizona State University in Tempe, echoes a near-universal sentiment. \u201cThe bottom line,\u201d he says, \u201cis that nobody really knows yet what's going to win out, what's going to be practical.\u201d But whatever technology prevails, says Lewis, the logic behind artificial photosynthesis is inexorable. \u201cThe biggest energy source we have by far is the Sun,\u201d he says. \u201cThe best way to store energy other than in the nucleus of an atom is in chemical fuels. It's inevitable someone is going to take the biggest source and store it in the most dense way.\u201d \n                 See Editorial \n                 p.7 \n               \n                     'Artificial leaf' faces economic hurdle 2012-May-23 \n                   \n                     Secrets of artificial leaf revealed 2011-Sep-29 \n                   \n                     Photochemical CO2 reduction: Towards an artificial leaf? 2011-Mar-24 \n                   \n                     Catalyst heralded as solar-power breakthrough 2008-Jul-31 \n                   \n                     Blog post: The New Yorker \u2014 and MIT \u2014 on Daniel Nocera's artificial leaf \n                   \n                     Joint Center for Artificial Photosynthesis \n                   \n                     HyperSolar \n                   Reprints and Permissions"},
{"file_id": "510204a", "url": "https://www.nature.com/articles/510204a", "year": 2014, "authors": [{"name": " Michele Catanzaro"}, {"name": "Giuliana Miranda"}, {"name": " Lisa Palmer"}, {"name": "Aleszu Bajak"}], "parsed_as_year": "2006_or_before", "body": "Despite myriad problems in many countries, pockets of excellence thrive in South American science. It may seem heretical to say so in the land of the beautiful game, but science in Brazil beats the World Cup \u2014 at least in a financial match-up. Government and businesses there invest some US$27\u00a0billion annually in science, technology and innovation, dwarfing the price tag for the football tournament, which tops out at about $15\u00a0billion. Science in Brazil and many other countries in South America has come a long way since the dark days of the dictatorships just a generation ago. In Argentina, the number of science doctorates jumped nearly tenfold between 2000 and 2010; Peruvian scientists tripled the tally of articles they produced over the same period; and science funding is climbing in most countries. South American science still has far to go if it hopes to catch up with other continents. By many measures \u2014 such as investments, patents and education \u2014 the countries there lag behind other nations with similar levels of gross domestic product (GDP). There is looming instability in countries such as Argentina and Brazil, where recent protests reflect deep social and economic divisions \u2014 problems that plague much of South America. But amid the concerns, there are many bright spots in the world of science. Here, Nature highlights several examples of outstanding researchers and institutions in the region. \n               CHILE: Upward trajectory \n             \n               by Michele Catanzaro \n             When Mario Hamuy finished his university degree in Chile in 1982, he was one of just a handful of students in the country interested in pursuing graduate studies in astronomy. Now, more than 25 Chilean students join such programmes each year and Hamuy directs the Millennium Institute of Astrophysics in Santiago, home to 95 students and faculty members. During the course of Hamuy\u2019s career, Chile has emerged as a major player in the world of international astronomy, in no small part because of the extraordinary collection of telescopes housed in the country\u2019s highlands. \u201cAstrophysics has come to the forefront of Chilean science thanks to the increase in human resources and to the fact that we have the cleanest sky in the world,\u201d says Dante Minniti, an astronomer at the Pontifical Catholic University of Chile in Santiago. Although Chile invested just 0.44% of its GDP in scientific research in 2011, the latest year for which figures are available, funding for astrophysics has steadily grown, from $2\u00a0million in 2006 to $6.8\u00a0million in 2010. Over the same period, the number of faculty positions has almost doubled. And the country\u2019s publications in astronomy have risen more than fourfold during the past decade. The quality of the work has improved as well. Chile ranks highly in terms of citations per paper in space science, and some of its scientists have made important discoveries. In the early 1990s, Hamuy made a key contribution that helped others to measure the accelerating expansion of the Universe and win a Nobel Prize in 2011. And Minniti is one of the leaders at the VISTA infrared survey telescope at the European Southern Observatory\u2019s Paranal Observatory in northern Chile, which has created a catalogue of more than 84 million stars in the central parts of the Milky Way. Chile\u2019s skies have been attracting international telescopes since 1964. By 2020, when the European Extremely Large Telescope is due to be completed, the country is expected to host 70% of the global observation surface for large optical and infrared telescopes. By contract, Chilean astronomers get 10% of the observation time on each telescope installed in the country. But some astronomers say that this is too little, considering how much the country provides for the organizations running the telescopes. \u201cThis country has given enormous advantages to the international consortia, ranging from full tax exemption to diplomatic status: it\u2019s time that Chile participates in a more active way,\u201d says M\u00f3nica Rubio, director of the astronomy programme of the Chilean funding agency CONICYT. A unanimous aspiration of Chilean scientists, says Rubio, is not just to use observatories but also to build them, through local companies and engineers. Another plan Rubio is working on is developing the Atacama Astronomical Park, a 36,347-hectare protected area around the Atacama Large Millimeter/submillimeter Array, which CONICYT plans to use to attract future telescopes from Brazil and the United States, and maybe also from China, South Koreaand Thailand. But many astronomers are worried about the governance of science in Chile. CONICYT has lacked a director since Jos\u00e9 Miguel Aguilera resigned eight months ago, and the country\u2019s new president, Michelle Bachelet, has frozen plans to create a science ministry (see  Nature 507, 412\u2013413; 2014 ). \u201cIt\u2019s a good moment for Chilean astronomy, but keeping the momentum will require more sustained support from the government,\u201d says Minniti. \n               BRAZIL: S\u00e3o Paulos\u2019s heavy hitter \n             \n               by Giuliana Miranda \n             Although Brazil rivals Europe in size, much of the leading research in South America\u2019s largest country emanates from an area the size of the United Kingdom. S\u00e3o Paulo, in southern Brazil, is the richest of the country\u2019s 26 states and publishes more than half of Brazil\u2019s scientific articles. One of the main reasons for its success is the S\u00e3o Paulo Research Foundation (FAPESP), the state agency that promotes research and education. In 2013, the agency invested $512 million in science funding, more than many nations in the region. (At the federal level, Brazil's National Council for Scientific and Technological Development has a budget of about $650 million for science, technology, and innovation in 2014.) Created in 1960, FAPESP has a stream of funding guaranteed by the constitution of S\u00e3o Paulo, which requires that 1% of the tax revenue goes to the foundation. Its success in fostering research and education inspired other Brazilian states: all but one now has a similar agency, and most have guaranteed funding linked to taxes. FAPESP directs 37% of its funding to basic research in fields ranging from climate change to particle physics. About 10% goes to infrastructure and the rest is channelled to applied research. Nearly one-third of its total budget is devoted to medical research. \u201cOne difference in FAPESP\u2019s work is that we invest a lot in basic science,\u201d says Carlos Henrique de Brito Cruz, FAPESP\u2019s scientific director. \u201cWe believe in balance.\u201d The most recent large project approved for funding is the Long Latin American Millimeter Array radio telescope, a joint project between Brazil and Argentina that will receive $12.6\u00a0million from the agency and an equal amount from Brazil\u2019s science ministry. FAPESP\u2019s board is considering a $40-million investment in the Giant Magellan Telescope, which would give S\u00e3o Paulo astronomers access to the facility, planned for construction in Chile. Science officials in other nations can only look with envy at the agency\u2019s guaranteed funding. \u201cFAPESP is a very interesting model for us because S\u00e3o Paulo is one of the few states in the world where support of research is linked directly to GDP,\u201d says Martyn Poliakoff, foreign secretary and vice-president of the Royal Society in London. Regional agencies such as FAPESP play a very important role in Brazil, says Wanderley de Souza, a biomedical scientist at the Federal University of Rio de Janeiro and a member of the Brazilian Academy of Science. \u201cThey can make research happen even if the federal funding gets scarce.\u201d Brazil struggles with vast economic differences among its various regions, and that is reflected in regional science budgets. FAPESP has the biggest budget of all the regional agencies, but that does not reduce federal investments in the state, says Clelio Campolina, the minister of science, technology and innovation. \u201cWe want to improve other states, but also reward excellence,\" he says. FAPESP\u2019s rapid growth has raised some concerns among scientists in S\u00e3o Paulo who complain about an increase in bureaucracy. But agency officials defend its performance and say they are working to improve its procedures. It\u2019s all part of an effort to produce high-quality work, says Brito Cruz. \u201cWe want the best projects.\u201d \n               COLOMBIA: Growth centre \n             \n               by Lisa Palmer \n             In the Cauca Valley of western Colombia, a herd of hefty cows at Petequi farm munches away on lush grass that looks as if it has grown there forever. But the plants are relative newcomers. They are cultivars of African super grasses, bred for enhanced nutrition and hardiness by researchers at the International Center for Tropical Agriculture (CIAT), less than 50\u00a0kilometres to the north. Cows at Petequi once took four years to reach market weight. Now they fatten up in just 18 months. The story is much the same throughout the South American  cerrado , or savanna. The improved grasses have revolutionized tropical forage across the continent thanks to the combined work of researchers at CIAT and the Brazilian Enterprise for Agriculture Research, a state-owned Brazilian company, says Eduardo Trigo, an agricultural economist and science adviser to the Argentine ministry of science, technology and innovation in Buenos Aires. \u201cCIAT has been one of the key actors in the development of the South American  cerrado ,\u201d he says. Established in 1967, the Colombian facility was one of the first members of the CGIAR consortium of international agriculture research centres. CIAT employs 325 scientists and has an annual budget of $114.4\u00a0million, paid for by the multi-donor CGIAR fund and by other international donors. Aside from its work on grasses, CIAT has focused on breeding improved varieties of beans, rice and cassava \u2014 staple crops that are important to the food security of the rural poor. \u201cGenetic improvement of these crops has proved to be a powerful weapon for combating hunger and poverty,\u201d says Ruben Echeverr\u00eda, director-general of CIAT. For example, beans developed by CIAT from Latin American varieties are now feeding up to 30 million people in Africa, according to the centre. Some 70% of rice in South America, and 90% of cassava in Asia, can be traced back to CIAT\u2019s breeding programme. \u201cCassava is now a multibillion-dollar business for starch production in Asia, providing income to smallholders,\u201d says Andy Jarvis, leader in policy research at CIAT. The centre has also helped to grow expertise on the continent and elsewhere; since CIAT opened, some 13,000 researchers have trained there. Its facilities have been instrumental in building capacity for plant physiologists in the poorer countries of the Andean region, says Trigo. \n               ARGENTINA: The RNA sleuths \n             \n               by Aleszu Bajak \n             Molecular biologist Alberto Kornblihtt likes to put things in perspective. \u201cWe may be on the periphery of scientific research,\u201d he admits from his office in Buenos Aires. \u201cBut it\u2019s not an impossible place to do science.\u201d In fact, he and his community of researchers in alternative RNA splicing \u2014 a field he helped to create \u2014 have shown that they can do world-class research despite tight government budgets and three-month delivery times for reagents that can cost three times as much as they would in the United States or Europe. Like Kornblihtt\u2019s lab, alternative RNA splicing makes use of constrained resources in innovative ways. Through varied patterns of cutting and rejoining, a single transcribed gene can give rise to many different messenger RNAs, thus permitting a single gene to express different proteins. Kornblihtt found one of the first cases of this process in humans while he was a postdoctoral fellow in the United Kingdom. He moved back to Argentina in 1984 and has assembled a group of researchers that continues to explore this realm. It has been a good year for his group. Kornblihtt and his doctoral student Ezequiel Petrillo published a paper in  Science  in April on how light affects alternative splicing in plants ( E.\u00a0Petrilloet\u00a0al.Sciencehttp://doi.org/s2d;2014 ). And last month, Gwendal Dujardin, a postdoctoral fellow from France (a rare sight in an Argentine lab), published a splicing study in  Molecular Cell  ( G.\u00a0Dujardin  et\u00a0al. Mol. Cell   54,  683\u2013690; 2014 ). The work is all part of a continuum, says Kornblihtt. He considers scientific research in his native Argentina to be part of a long tradition that started with Bernardo Houssay and Luis Leloir, twentieth-century Nobel laureates whose names now adorn avenues, museums and universities across the country. \u201cThe scientific institutions they founded led to generations of disciples that continue to do the science of today,\u201d he says. Kornblihtt carries on that tradition, in part by teaching an introductory course on molecular biology at the University of Buenos Aires. \u201cThat course has been a nursery for many young Argentine scientists,\u201d he says. It lures in many students, says Diego Golombek, a biologist at the National University of Quilmes in Buenos Aires. \u201cImagine that on the first day of classes, young students find themselves before the country\u2019s most well-known researcher teaching molecular biology classes with an absolutely contagious enthusiasm,\u201d he says. \u201cHe\u2019s had an influence over the new generations of biologists.\u201d Petrillo, who has just left Argentina for a research post at the Medical University of Vienna, says that he will sorely miss the camaraderie of the tight-knit group of RNA researchers from labs and universities all over Buenos Aires. The RNArgentinos, as they call themselves, have for years organized informal seminars and get-togethers to share ideas, concerns, protocols and techniques. Kornblihtt recognizes that Argentine scientists cannot all work in their home country and he encourages his students to \u201cseed the world\u201d as postdocs abroad. But he asks his university students to complete their PhDs in Argentina. \u201cIt\u2019s not necessary to leave the country to get a doctorate,\u201d he says. \u201cWe have a strong science ministry, lots of scholarships and subsidies and new research buildings. The structure to do science in Argentina is not precarious. It has many pillars.\u201d \n                     Research training: Homeward bound 2014-Jun-11 \n                   \n                     Stars of South American science 2014-Jun-11 \n                   \n                     Capacity building: Architects of South American science 2014-Jun-11 \n                   \n                     The impact gap: South America by the numbers 2014-Jun-11 \n                   \n                     Chile puts plan for science ministry on hold 2014-Mar-25 \n                   \n                     S\u00e3o Paulo poised to join megatelescope 2014-Feb-25 \n                   \n                     Emerging powers need a more-inclusive science 2013-Dec-30 \n                   \n                     Brazil f\u00eates open-access site 2013-Oct-22 \n                   \n                     ALMA strike stirs up Chilean labour unions 2013-Sep-17 \n                   \n                     Brazil delays stargazing pact 2013-Sep-03 \n                   \n                     Nature  special: South American science \n                   \n                     Nature  special: The new map of science \n                   \n                     Nature  special: Rio+20 \n                   \n                     Millennium Institute of Astrophysics \n                   \n                     S\u00e3o Paulo Research Foundation \n                   \n                     International Center for Tropical Agriculture \n                   \n                     Alberto Kornblihtt \n                   Reprints and Permissions"},
{"file_id": "510207a", "url": "https://www.nature.com/articles/510207a", "year": 2014, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "South American efforts to repatriate scientists are paying off. When Andrea Bragas left Argentina in 2000 for a postdoctoral fellowship at the University of Michigan in Ann Arbor, she did not know where she would eventually end up. Although the terms of her fellowship obliged her to return home, Argentina\u2019s economy was heading for a crisis and there was no guarantee of continued govern\u00adment funding, much less a job when she came back. But the gamble paid off. By 2004, Argentina\u2019s economy had started to rebound and the president was pledging new investments in science and technology. Bragas returned to teach at the University of Buenos Aires and is now a nanoscientist at CONICET, Argentina\u2019s National Scientific and Technical Research Council. Across South America, thousands of researchers have similar stories. Countries that saw some of their most promising scientists flee during decades of dictatorships or economic crises are now reversing the brain drain, luring researchers home with offers that range from short-term teaching and research fellowships to fully equipped labs and competitive salaries. \u201cUnlike financial capital, which is hard to recover once it has left the country, intellectual capital returns with interest,\u201d says Lino Bara\u00f1ao, Argentina\u2019s science and technology minister. \u201cA scientist who has spent some years outside the country has training, networks of contacts and access to top institutions \u2014 and from a productivity standpoint can be more valuable than one who has stayed in the country.\u201d Brazil was one of the first South American countries to invest in building a base of researchers. When Lindolpho de Carvalho Dias attended the first Brazilian Mathematics Colloquium as a student in 1957, he was one of about 50 participants in a country that had few universities and no graduate programmes in science. But the government was taking major steps to close the education gap. In the early 1950s, it created the National Council for Scientific and Technical Development (CNPq) and launched a higher-education campaign. Since then, Brazil has paid to send students abroad for graduate study, with the commitment that they would come back to teach and do research. Many of those who returned became staff members in new graduate programmes and the country has ramped up its production of scientists and engineers. The number of doctorates awarded in those fields per year nearly doubled between 2001 and 2011. As a measure of the country\u2019s scientific growth, the mathematics colloquium currently draws about 1,000 participants a year. And research institutes in Brazil now attract both home-grown and foreign talent, adds Dias, who has served as director of the CNPq and as executive secretary of the Ministry of Science and Technology. Like Brazil, Argentina has long sent students abroad for graduate education. But the country has only recently devoted sustained and coordinated funding to provide opportunities for returning researchers like Bragas. The science ministry now runs a programme called RAICES (\u2018Roots\u2019) to encourage researchers to return home with offers of fully equipped laboratories and salaries comparable to those in the United States and Europe. So far, 1,062 Argentinean scientists have returned. Most have gone to public universities or research centres, although Bara\u00f1ao expects that to change as Argentina\u2019s private technology sector cranks up. The employer usually provides laboratory facilities, and RAICES pays moving costs and subsidizes salaries for a few years. As an added incentive, it also helps with placements for spouses. In Chile, the Millennium Scientific Initiative \u2014 launched in 1999 \u2014 has set up centres of excellence and offers study-abroad fellowships with a commitment to return home to work. It has also established a programme called Chile\u00adGlobal, which lets Chilean scientists network at home and abroad through seminars and other activities. Countries with smaller science budgets are also experimenting with ways to repatriate researchers through fellowships, networking and incentives. In March, Colombia\u2019s Department of Science, Technology and Innovation announced the US$9-million \u2018It\u2019s Time to Return\u2019 repatriation programme. The initiative offers research posts in various fields, and hopes to lure back 500\u00a0Colombian PhD holders in its first two years. Although brain-drain-reversal programmes take different forms, Bara\u00f1ao says that the key is to harness the expertise, contacts and experience of researchers outside the country \u2014 many of whom were educated at least partly at the taxpayer\u2019s expense \u2014 while expanding research facilities and opportunities at home. Ultimately, the long-term success of these efforts may depend on the willingness of governments and companies to increase research investments, which have been climbing only modestly relative to gross domestic product in most South American countries.\u201cYou have to create a competitive research environment with top-quality, interdisciplinary research centres,\u201d says Bara\u00f1ao. \u201cEven if you offer a good salary or pay relocation expenses, without those conditions, a good researcher won\u2019t return.\u201d \n                     South American science: Big players 2014-Jun-11 \n                   \n                     Stars of South American science 2014-Jun-11 \n                   \n                     The impact gap: South America by the numbers 2014-Jun-11 \n                   \n                     Max Planck Society opens South American outpost 2011-Oct-28 \n                   \n                     Argentina smooths the path for returnees 2010-Jul-21 \n                   \n                     Argentina: The come back 2008-Nov-26 \n                   \n                     Argentina's pivotal moment 2008-Jan-23 \n                   \n                     Argentina's pivotal moment 2008-Jan-23 \n                   \n                     Nature  special: South American science \n                   \n                     Nature  special: The new map of science \n                   \n                     Nature  special: Rio+20 \n                   \n                     ChileGlobal \n                   \n                     \n                         RAICES \n                       \n                   Reprints and Permissions"},
{"file_id": "510202a", "url": "https://www.nature.com/articles/510202a", "year": 2014, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "The expanding economies of South America have led to a significant rise in scientific output over the past two decades, and research spending has increased in most countries. But given the region\u2019s share of the world\u2019s population and gross domestic product (GDP), publication rates still fall short of what would be expected. Research quality has not kept pace with rising output, and the continent\u2019s research papers still struggle to attract citations from the rest of the world. There are huge inequalities across the region, too: Brazil dominates the publication record, for example, whereas Chile takes pole position in the patent landscape and Argentina scores highly in terms of the proportion of its population working in science. \n                     Nature  special: South American science \n                   Reprints and Permissions"},
{"file_id": "510201a", "url": "https://www.nature.com/articles/510201a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Growing resources for research and development are creating opportunities across the continent, but many countries still struggle to build their programmes. Like the night sky, the overall sweep of science in South America can look pretty dark. Brazil is the only country on the continent that spends more than 1% of its gross domestic product on research and development, and even that investment sits far below what other countries of similar means are ploughing into science. But take a closer look at the continent\u2019s scientific enterprise, and bright spots emerge. At the start of the FIFA World Cup in Brazil, with billions of people focusing on South America,  Nature  examines a part of the world that has spent too long on the sidelines of science. A graphic tour on  page\u00a0202  details the inputs and products of research and development on the continent. The region faces many challenges in terms of building a strong scientific workforce and boosting resources, but investment and publications are climbing. A News Feature on  page\u00a0204  profiles several key institutions and research groups \u2014 from agricultural specialists in Colombia to RNA experts in Argentina \u2014 who have gained worldwide recognition. An Editorial on  page 188  calls on inter\u00adnational colleagues to help build South American science in ways that do not cause young researchers to leave permanently. On  page\u00a0213 , a Comment describes one such success: the Pew Latin American Fellows Program, which each year sends about ten top graduates to work in North American labs. More than 70% return to their native countries, bringing with them the expertise they have gained. That initiative is a part of broader efforts, described in a News Feature on  page\u00a0207  that examines how countries are trying to repatriate scientists who left to train abroad. As economies on the continent heat up, they are devoting greater resources to research, increasing the need for better infrastructure and policies to support science. In a Comment on  page\u00a0209 , research leaders describe how they hope to navigate this growth, and how science can help to expand their countries\u2019 economies sustainably. Ideas range from creating a science ministry to using research to find new commercial uses for the fruits of the Amazon. Many researchers in South America maintain a cautious outlook \u2014 they have lived through periods of intense economic and political strife in the not-too-distant past. But they also harbour the hope that the continent\u2019s science is headed for a winning season. \n                     Nature  special: South American science \n                   Reprints and Permissions"},
{"file_id": "510326a", "url": "https://www.nature.com/articles/510326a", "year": 2014, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Researchers are exploring unconventional sources of fresh water to quench the globe's growing thirst. In an effort to combat his country's long-standing water crisis, Iran's president took to Twitter last year. \u201cWe need plan to save water in agriculture, prevent excessive tap water use, protect underground sources of water and prevent illegal drilling,\u201d Hassan Rouhani tweeted in November. Iran is far from alone. From the southwest United States to southern Spain and northern China, water shortages threaten many parts of the world. Nearly 800 million people lack access to safe drinking water and 2.5 billion have no proper sanitation. The situation will probably get worse in coming decades. The world's population is expected to swell from 7 billion today to more than 9 billion by 2050, even as climate change robs precipitation from many parched parts of the planet. If the world warms by just 2 \u00b0C above the present level by the end of the century, which scientists believe is exceedingly likely, up to one-fifth of the global population could suffer severe shortages of fresh water. \u201cEven without global environmental change, feeding 9 billion people by 2050 will require an additional 2,000\u20133,000 cubic kilometres of fresh water in agriculture \u2014 more than the total global use of water in irrigation,\u201d says Johan Rockstr\u00f6m, a specialist on water resources at Stockholm University and director of the Stockholm Resilience Centre. \u201cThis equates to nothing less than a new agricultural revolution. Novel approaches, such as water-harvesting practices, are absolutely critical in the future.\u201d Most countries are seeking to expand access by tapping the underground aquifers that already supply the bulk of the fresh water for the global population. At the same time, some are experimenting with recycling waste water for agriculture and other uses. But many nations hope to tap unconventional sources \u2014 ranging from fog to the ocean \u2014 to quench their thirst. Some approaches involve billion-dollar deals; others are local efforts that require little in the way of costly technology. Here  Nature  looks at five ways to produce fresh water from unusual sources. \n               Desalination at a cost \n             Like all Mediterranean countries, Israel receives most of its precipitation during the winter months. But last winter, almost no rain fell. In the past, such a drought would have caused severe problems for Israel's 8.2 million people. But thanks to the seawater desalination plants that Israel has built over the past decade, the country's taps did not run dry. Israel's four large 'reverse osmosis' plants rank among the biggest and most efficient desalination facilities in the world. By next year, they are expected to provide more than 500 million cubic metres of fresh water per year \u2014 about half of Israel's needs. In 2012, IDE Technologies in Kadima, the company behind three of the existing Israeli plants, signed a deal to design a US$1-billion desalination facility near Carlsbad, California. When completed by 2016, it will supply fresh water to about one-tenth of the 3.2 million people living in San Diego county. A rapidly growing global industry, desalination has become in the past 20 years an essential source of fresh water for the Middle East, Australia, the United States, South Africa, Spain and, increasingly, India and China. In 2012, the total amount of installed desalination capacity exceeded 80 million cubic metres per day, enough to supply some 200 million people. \u201cWith nearly half of the global population living within 100 kilometres of the ocean coast, you just can't avoid desalination,\u201d says Gary Amy, director of the Water Desalination and Reuse Center at the King Abdullah University of Science and Technology (KAUST) in Thuwal, Saudi Arabia. \u201cDesalination is here to stay and it will inevitably become bigger.\u201d But by any method, desalination consumes much more energy than conventional water sources. It takes just over 3 kilowatt hours (kWh) of energy to produce 1 cubic metre of potable water at the most efficient commercial reverse osmosis desalination plants \u2014 where pre-filtered sea water is forced under pressure through a series of semi-permeable membranes. A process that evaporates ocean water in thermal plants requires about 10 kWh to produce the same amount of potable water. Some oil-rich countries do not mind the high price: Saudi Arabia's desalination industry, for example, currently burns some 300,000 barrels of oil per day. Engineers are trying to improve reverse-osmosis technology using components such as low-energy pumps and advanced membranes. Some are experimenting with membranes made of graphene to replace the polymers currently used. And efforts are under way globally to shift from fossil fuels to renewable energies in the desalination process. Even with those advances, desalination will remain costly, says Maria Kennedy, a water-treatment specialist at the United Nations' Institute for Water Education in Delft, the Netherlands. \u201cNobody decides to do desalination unless they're out of other options.\u201d \n               Riverbank filtration \n             Every July and August, millions of Hindu pilgrims flock to the holy city of Haridwar in India, to visit its temples and fetch water from the Ganges river. The aquifers that supply fresh water to the city cannot keep up with the annual influx of people, so another source is needed. The banks of the Ganges offer a solution. Germans along the Rhine have been using riverbanks to filter water since the 1870s. The method is straightforward: when wells are dug next to a river in regions with suitable geology, the river water filters through sand and gravel that strips out most of the chemical and biological pollutants, and so emerges relatively clean. \u201cThe treated water may not always meet the water-quality requirements,\u201d says Saroj Sharma, an environmental engineer at the UN's water institute. But when the river is relatively clean and the geological conditions are favourable, as in Haridwar, it may need only a minor amount of disinfection, says Sharma. India will have to increase its use of natural water-treatment systems. Groundwater currently provides 85% of the country's domestic water, but supplies are rapidly declining: in 20 years, about 60% of all of India's aquifers will be critically degraded, according to the World Bank. Researchers are now looking to improve the efficiency of technologies for natural water filtration and reuse in India as part of the Saph Pani project, a $6.5-million collaboration at nine sites in the country, funded by the European Union. The studies range from riverbank filtration in Haridwar to wastewater treatment in artificial wetlands in Hyderabad. \n               Ancient technology \n             The Tigray region of northern Ethiopia is notoriously dry, and as a result has experienced repeated famines. But the villagers of Koraro no longer face water shortages, thanks to an imported ancient technology. Upmanu Lall, director of Columbia University's water centre in New York City, brought the method to Koraro as part of the university's Millennium Villages Project, which seeks to fight poverty and hunger in Africa through community-led efforts. While searching for a way to supply the community with water, Lall sought inspiration from waterworks known as qanats, invented by Persian engineers more than 2,000 years ago. These elaborate tunnels carry groundwater from high elevations down to dry valleys and plains; some ancient systems are still in use in Iran and parts of the Arabian Peninsula. In 2009, with $250,000 funding from the Ceil and Michael E. Pulitzer Foundation, Lall's engineering students began to design a modern version of a qanat in Koraro. The village and surrounding fields are on a sandy slope, just a few kilometres away from the steep cliffs of a mountain. The region receives scant rainfall, except in July and August, when flash floods badly erode soil. In the past, villagers have stored rainwater in tanks, but much of that water evaporated quickly and the rest often became polluted. To get around these problems, the Columbia students, aided by Ethiopian engineers and local villagers, designed a system of small rock dams at the top of the mountain to control surface run-off and allow the rainwater to seep into the subsurface. The water then flows down through the mountain into a trench measuring 3 metres wide by 3 metres deep, which stretches from the foot of the mountain down the slope to the village 4 kilometres away. The system, which can hold 36,000 cubic metres of water, has been working for three years. The trench recharges the groundwater around Koraro, thus supplying villagers with water for drinking and agriculture. The water has enabled villagers to add an extra planting season, and it supplements irrigation during breaks in the rainy season. \u201cJust like the master-builders of ancient Persian qanats, we have created an aquifer where actually there wasn't one,\u201d says Lall. \u201cAnd, filtered by the sand, the water we produce is of pure drinking quality.\u201d \u201cWater scarcity is often caused by sporadic rainfall rather than actual lack of water,\u201d says Alberto Montanari, a hydrologist at the University of Bologna in Italy. \u201cThe challenge then is to devise sustainable solutions for storing water to make a reserve for the dry season. The Koraro project is an excellent example how this can be done.\u201d As word spreads about the success of the scheme, other communities in Tigray are planning to adopt similar techniques. The method, says Lall, could be applied in many locations with appropriate topography and hydrology, including most of Africa's semi-arid highlands. And Lall is already looking beyond Africa: he is in talks with the state of Jharkhand in northeast India to develop a qanat there. \n               Greening the desert \n             Agriculture uses more than two-thirds of Earth's fresh water, so the idea of a farming practice that produces more water and energy than it consumes seems too good to be true. But in the desert of Qatar, scientists are showing that salt water and sunlight can yield food and clean water in a self-sustaining cycle. The Sahara Forest Project (SFP), a Norwegian company launched in 2009 and supported by the Oslo-based fertilizer company Yara and the Qatar Fertilizer Company of Mesaieed, operates an $8.5-million pilot facility outside Doha. Last year, the 700-square-metre greenhouse produced a crop of vegetables comparable to that of commercial greenhouses in Europe, according to SFP. Greenhouses normally trap heat, but the reverse is required in hot places such as Qatar. At the SFP facility, sea water does the trick. The water, piped from the ocean just 100 metres away, trickles over a lattice at the windward side of the greenhouse. As the water evaporates, it humidifies the air entering the greenhouse and cools it by some 10 \u00b0C, creating an indoor climate suitable for growing vegetables such as cucumbers and tomatoes. Other crops, such as barley, salad rocket and useful desert plants, grow between hedges downwind of the greenhouse. When the desert cools at night, water condenses on surfaces inside the greenhouse and is collected for irrigation and drinking. A desalination facility at the site produces further fresh water. And the electricity needed to run the entire installation comes from solar power. Joakim Hauge, chief executive of the SFP in Oslo, believes that the concept can be scaled up to create green oases in desert climates that are otherwise hostile to farming. \u201cWith 60 hectares of greenhouse production we could match the yearly import of cucumbers, tomatoes, peppers and aubergines to Qatar,\u201d he says. The company is working with the government of Jordan to set up a 20-hectare pilot facility, including a commercial greenhouse unit and a research and innovation centre, in Aqaba. A larger commercial facility, says Hauge, would be able to produce excess electricity that could be exported to the grid. The concept might work in any dry and sunny location that is near sea level, and therefore has low pumping costs. Even so, saltwater greenhouses remain an experiment for now, says Nina Fedoroff, director of the Center for Desert Agriculture at KAUST. \u201cThe concept is intriguing,\u201d she says. \u201cBut it is still a rather pricey way of producing food that might not gain huge commercial traction.\u201d \n               Fog harvesting \n             For as long as people can remember, women in the small mountain village of Tojquia, Guatemala, have had to trek down to the valley bottom during the dry winter months and haul fresh water back uphill to their families. But now they can get their water by wringing moisture from the fog that often envelops their community. One cubic metre of fog can contain up to 0.5 grams of liquid water, and harvesting it is relatively easy. A large vertical mesh panel can collect water droplets as the wind pushes clouds of moisture through its fibres. Tiny at first, the droplets coalesce and grow, then run into a gutter at the bottom and into a storage tank. At 3,300 metres above sea level, where winters are windy and dry but often foggy, Tojquia is an ideal site for this technique. With the help of researchers from the non-profit FogQuest project in Kamloops, Canada, the residents of Tojquia have installed 35 collectors since 2006. These produce an average of 6,300 litres of potable water per day \u2014 enough for about 30 families during the dry season \u2014 and considerably more in the wet season when rainwater, too, is collected in the storage tanks. Fog collection is catching on in seasonally dry regions that lack other sources of fresh water. The first simple mesh panels were built in the 1960s in the port town of Antofagasta in northern Chile. Today, 35 countries are using the technique, particularly along the Pacific coast of South and Central America, in the Atlas Mountains in Morocco and on the high plateaux of Eritrea and Nepal. Improvements could come from advanced mesh materials, such as the permeable fibres developed by scientists at the Massachusetts Institute of Technology in Cambridge; when tested in Chile, these collected fog at a rate five times that of conventional mesh. And in the Namib Desert in Namibia, three-dimensional meshes developed at the Institute of Textile Technology and Process Engineering in Denkendorf, Germany, have achieved up to three times higher water yields than normal meshes. Even with those kinds of gains, fog harvesting will not solve Chile's \u2014 or any other country's \u2014 water shortages. But it can provide a simple and sustainable method of producing fresh water in semi-arid regions that are short of other options, says Otto Klemm, a climatologist at the University of M\u00fcnster in Germany. \u201cIf the climatic conditions are right \u2014 and, importantly, if local people are trained to independently maintain the facilities,\u201d he says, \u201cit does have the potential of supplying rural communities with precious fresh water year-round.\u201d \n                     Floods: Holding back the tide 2014-Apr-09 \n                   \n                     Frequency of extreme El Ni\u00f1os to double as globe warms 2014-Jan-19 \n                   \n                     Water risk as world warms 2013-Dec-31 \n                   \n                     Environmental concerns reach fever pitch over plan to link Red Sea to Dead Sea 2013-Feb-27 \n                   \n                     New desalination technique yields more drinkable water 2012-May-23 \n                   \n                     Water: Purification with a pinch of salt 2008-Mar-19 \n                   \n                     Nature  special: Water \n                   \n                     UN World Water Day 2014 \n                   \n                     KAUST Water Desalination and Reuse Center \n                   \n                     UNESCO Institute for Water Education \n                   \n                     Columbia Water Center \n                   \n                     Millenium Village Koraro, Ethiopia \n                   \n                     Sahara Forest Project \n                   \n                     Saph Pani project \n                   \n                     FogQuest \n                   Reprints and Permissions"},
{"file_id": "510330a", "url": "https://www.nature.com/articles/510330a", "year": 2014, "authors": [{"name": "Peter Aldhous"}], "parsed_as_year": "2006_or_before", "body": "Members of the US National Academy of Sciences have long enjoyed a privileged path to publication in the body's prominent house journal. Meet the scientists who use it most heavily. In April, the US National Academy of Sciences elected 105 new members to its ranks. Academy membership is one the most prestigious honours for a scientist, and it comes with a tangible perk: members can submit up to four papers per year to the body's high-profile journal, the venerable  Proceedings of the National Academy of Sciences  ( PNAS ), through the 'contributed' publication track. This unusual process allows authors to choose who will review their paper and how to respond to those reviewers' comments. For many academy members, this privileged path is central to the appeal of  PNAS . But to some scientists, it gives the journal the appearance of an old boys' club. \u201cSound anachronistic? It is,\u201d wrote biochemist Steve Caplan of the University of Nebraska, Omaha, in a 2011 blogpost that suggested the contributed track could be used as a \u201cdumping ground\u201d for some papers. Editors at the journal have strived to dispel that perception. With  PNAS  currently celebrating its centenary, the news team at  Nature  decided to examine the contributed track, both to assess its scientific impact and to see which members use it most heavily and why. After analysing a decade's worth of  PNAS  papers, we found that only a small number of scientists have used the track at close to the maximum allowable rate. The group includes some of the biggest names in science, and six are past or current members of the journal's editorial board. These scientists say that the main motivator for using the contributed track is an intense frustration with the peer-review process at other high-profile journals, which they argue has become excessive and laborious. Our analysis also suggests that the efforts by  PNAS  to prevent abuse of the contributed track and to boost the quality of papers published by this route are bearing fruit. Although contributed  PNAS  papers attract fewer citations than those handled through the journal's standard review process, the gap has narrowed in recent years. \u201cWe have worked really hard at this,\u201d says Alan Fersht, a biophysicist at the University of Cambridge, UK, one of  PNAS 's associate editors and a heavy user of the contributed track. \n               A privilege to publish \n             An inside track to publication for academy members rests deep in  PNAS 's DNA. The journal was established in 1914 with the explicit goal of publishing members' \u201cmore important contributions to research\u201d in addition to \u201cwork that appears to a member to be of particular importance\u201d. That remit led to the creation of two publishing tracks: contributed and 'communicated' papers (manuscripts sent by non-members to colleagues in the academy, who would shepherd them through review). These two tracks were the only ways to get a paper into  PNAS  until 1995, when biochemist Nicholas Cozzarelli of the University of California, Berkeley, took over as editor-in-chief and introduced 'direct submissions', which are handled more like papers at other journals. Direct submissions must pass an initial screen by a member of the editorial board, after which they are assigned to an independent editor \u2014 either an academy member or a guest editor \u2014 who organizes peer review. Starting in 1972, the journal placed limits on the number of contributed papers that an academy member could submit, and the current annual cap of four was imposed in 1996. Then in 2010,  PNAS  abolished the communicated track, which was already declining in popularity 1 . Today, more than three-quarters of the papers published in the journal are direct submissions. These papers are much less likely to be accepted than those contributed by academy members. Only 18% of direct submissions were published in 2013, whereas more than 98% of contributed papers were published, according to figures on the journal's website. (The one caveat is that  PNAS  has no data on how many papers intended for the contributed track receive negative reviews and never get submitted.) Despite the impressive acceptance rate for contributed papers, the data collected show that many eligible scientists choose not to submit papers through this track. Of the more than 3,100 academy members who could have used the contributed track between 2004 and 2013, fewer than 1,400 scientists did so. (This might in part reflect where researchers from different fields prefer to publish their work; the academy draws its members from all disciplines, including researchers from fields such as astronomy and mathematics, who rarely send their papers to  PNAS .) Most members who used the contributed track did so sparingly: the majority published on average fewer than one contributed paper per year. Only a small group consistently used the track at close to the allowable maximum: from 2004 to 2013, 13 scientists each contributed more than 30 of their own papers. This roster includes some of the best-known people in contemporary science (see 'Who are the power users?'). Some of these researchers, such as Solomon Snyder, a neuroscientist at Johns Hopkins University in Baltimore, Maryland, rarely or never publish in  PNAS  except through the contributed track. But others, including immunologist Tak Mak at the University of Toronto in Canada and cancer researcher Carlo Croce at Ohio State University in Columbus, also regularly send in direct submissions. Having control over the review process brings advantages. Those who work across disciplinary boundaries say that being able to choose your own reviewers is the best way to ensure that referees actually understand the material. \u201cChemists have no idea about glycobiology,\u201d says Chi-Huey Wong of the Scripps Research Institute in La Jolla, California, who studies the chemistry and biology of sugars. But for others, including Croce, who consistently hits his annual allocation of four contributed papers per year, the track's appeal boils down to one word: speed. Several of the contributed track's most regular users say that they have had papers held in limbo for up to two years at  Nature ,  Science  or  Cell  while the manuscripts went through multiple reviews and revisions. \u201cIn two years, you can be scooped over and over and over,\u201d says Croce. Science  and  Nature  each provided figures for median time passed between submission and publication for recent papers, which suggest lag times greater than for contributed articles at  PNAS .  Cell  declined to provide figures. However, comparing across journals is difficult because each has different policies on when a revised manuscript is considered a 'new' submission. Still, many of the contributed track's power users believe that increased competition for space in high-profile journals has allowed editors and reviewers to become more demanding. \u201cBeing able to publish four high-profile papers with much less grief than the usual high-prestige journal \u2014 that's worth something,\u201d says Snyder. Some of the power users, including Snyder and Mak, add that the contributed track benefits postdoctoral researchers or students in their laboratories who are searching for jobs and need high-profile publications more quickly than the review time at  Nature  or  Science  would allow. Complaints about nitpicking reviews at  Nature  and  Science  go hand-in-hand with the charge that the editors at these journals are in thrall to trendy areas of research. \u201cVery often what seems to be fashionable is not very good science,\u201d says Croce. \n               Special access \n             The problem for most scientists looking to advance their career, however, is that they do not have the option of turning to  PNAS 's contributed track. No wonder, then, that successive editors-in-chief have been dogged by the view that  PNAS  is a club for academy members. \u201cWe want to remove this perception,\u201d says current editor-in-chief Inder Verma, a gene-therapy researcher at the Salk Institute for Biological Studies in La Jolla. The steady growth of direct submissions bears witness to efforts by Verma and his predecessors to make the journal attractive to scientists who are not academy members (see 'A changing journal'). \u201cWhen I was editor, I was very concerned about the abuse of members' privilege,\u201d says Randy Schekman of the University of California, Berkeley, a former  PNAS  editor-in-chief, under whose watch communicated papers were abolished (see  Nature   http://doi.org/d22bqx ; 2009 ). Academy members were consulted on that decision, and it was a popular one \u2014 probably because it freed members from having to deal with submission requests from colleagues. But it would be far more difficult to convince members to give up their own publishing privileges. Even the contributed track's critics accept that it is here to stay, at least for the foreseeable future. \u201cI'd just do away with it,\u201d says applied physicist David Weitz of Harvard University in Cambridge, Massachusetts. \u201cBut it's something that many members of the academy have viewed as their prerogative.\u201d Weitz, who sits on the  PNAS  editorial board, publishes some of his best work in the journal, but has a policy of never using the contributed track. \u201cI don't want to have a special 'in',\u201d he says. The contributed track's most enthusiastic users argue that their papers get thoroughly reviewed. \u201cThe referees I choose are people I hardly know but who can give the best review of the papers \u2014 so I don't get egg on my face,\u201d says Fersht. \u201cIt's not a free ride,\u201d agrees Mak, who adds that his haul of contributed  PNAS  papers should be viewed against his high productivity overall. His laboratory published more than 300 original research papers over the same decade. Many of the other power users head similarly productive labs. PNAS  has also tried to limit conflicts of interest by barring members from picking recent collaborators to referee their papers. Current rules prohibit members from choosing any scientist they have worked with in the past four years. The journal's editorial board can also step in to block contributed papers if it feels that members are abusing their privileges, a process that Schekman says took a considerable amount of time and effort during his tenure. Telling big-name scientists \u2014 some with egos to match \u2014 that their work isn't up to snuff can be difficult. \u201cWe would challenge these papers, and people would take umbrage and personally attack me,\u201d says Schekman. \u201cIt was discouraging to have to deal with that, but I was unbowed.\u201d Verma continues the fight, taking a wry view. \u201cEvery member of the academy is a legend in their own mind,\u201d he jokes. As well as providing oversight for the contributed track, the nearly 200-strong  PNAS  editorial board includes some of the track's most enthusiastic users. Our analysis shows that almost half of those who contributed more than 30 papers over the past decade are current or former members of the board \u2014 including Fersht, Mak and Snyder. These scientists work hard for  PNAS : none more so than Snyder, who has organized the review of hundreds of direct-submission papers over the past decade. Verma is adamant that there is no preferential treatment for those who sit on the journal's editorial board. Still, he acknowledges that the perk of the contributed track helps to explain how the journal can operate without professional editors. Fersht agrees: \u201cMembers are willing to act as editors, and part of it is because they know they are able to publish their own papers.\u201d Verma says that more than 1,200 members of the academy responded to the call to edit one or more papers in 2013, and he argues that collective editing by leading scientists is the journal's main strength. But all of that does not quell criticism of the contributed track, and there is evidence that contributed papers have less impact than those reviewed in the usual way. In 2009, psychologist David Rand and evolutionary biologist Thomas Pfeiffer, then both at Harvard University, looked at citations to papers published in  PNAS  between June 2004 and April 2005. Controlling for factors such as scientific discipline and time elapsed since publication, the pair found that contributed papers were cited less often than direct submissions and communicated papers 2 . (By the time Rand and Pfeiffer published their analysis,  PNAS  had already decided to abolish the communicated track.) Although citations are not the only way to judge the impact of papers, they are the most readily available and widely researched measure. We repeated and extended Rand and Pfeiffer's analysis, considering papers published from 2004 to 2011. Overall, the conclusion was the same: the difference between citation rates for directly submitted and contributed papers was not large \u2014 controlling for other factors such as discipline, contributed papers garnered about 4.5% fewer citations \u2014 but it was statistically significant.  Nature 's analysis also suggests that the gap in citation rates between directly submitted and contributed papers has been narrowing, and this does not seem to be because more-recent papers have yet to acquire enough citations for the difference to show. Viewed in this light, the journal seems to be making progress with its efforts to eliminate the abuse of publishing privileges by academy members. And Verma vows to keep up the pressure. He is now encouraging academy members to list the reviewers for contributed papers, taking the lead by doing so for his own most recent contribution 3 . Such transparency, he hopes, will hold everyone to rigorous standards. Verma also wants to eliminate what some scientists see as a vestige of the old communicated track \u2014 an option to request a 'prearranged editor' from the academy. One in five direct submissions published in 2013 used a prearranged editor, and the acceptance rate for these papers is higher than for other direct submissions. \u201cMore and more the playing field will be levelled,\u201d says Verma. As  PNAS  marches into its second century, debate about its idiosyncratic publishing mechanisms is sure to continue. But for those who benefit from the journal's distinctive approach,  PNAS 's quirks are inherent to its appeal. \u201cThe last thing we need, I think, is less diversity,\u201d argues Nobel-prizewinning neuroscientist Thomas S\u00fcdhof of Stanford University in California. \u201cTurning  PNAS  into a standard journal, in my view, would make it unnecessary.\u201d \n                     Investigating journals: The dark side of publishing 2013-Mar-27 \n                   \n                     Row at US journal widens 2009-Oct-09 \n                   \n                     Bioterror paper gets online 2005-Jun-29 \n                   \n                     Blog post:  PNAS  will publish controversial papers, journal says \n                   \n                     Full data fron  Nature 's analysis \n                   \n                     \n                         Proceedings of the National Academy of Sciences  \n                       \n                   \n                     Peer review and the \u201cole boys network\u201d \n                   Reprints and Permissions"},
{"file_id": "510458a", "url": "https://www.nature.com/articles/510458a", "year": 2014, "authors": [{"name": "Kerri Smith"}], "parsed_as_year": "2006_or_before", "body": "Romance often sparks between colleagues, and scientists are no different.  Nature  profiles four super-couples who have combined love and the lab. When physicists Claudia Felser and Stuart Parkin were introduced at a conference on applied magnetics, they felt an immediate attraction. But then, standing outside the Amsterdam conference centre, they started talking shop. It did not go well. Parkin was interested in finding materials he could use to make miniature data-storage devices. Felser espoused the benefits of her pet topic: Heusler compounds, alloys with modifiable magnetic properties. \u201cBut he was not interested!\u201d she laughs. Parkin thought that the compounds sounded as though they would be too difficult to interface with other materials. \u201cSo this was not a successful introduction,\u201d Felser says. But the two kept in touch. And as Felser shared her growing knowledge about the semiconductor and quantum properties of Heusler compounds, Parkin grew more curious about the molecules \u2014 and about Felser. At the end of 2009, she decided to take a sabbatical from Johannes Gutenberg University in Mainz, Germany, to work IBM in San Jose, California, where Parkin worked. \u201cI invited her to stay with me,\u201d Parkin says. They were a couple from then on. \u201cSo this was more or less how it started and we're still working together,\u201d he says. Couple Claudia Felser and Stuart Parkin discuss how they mix research with romance Felser and Parkin are one of thousands of couples who met through science. According to a 2010 survey by the US National Science Foundation, just over one-quarter of married people with doctorates had a spouse working in science or engineering 1 . Such partnerships are on the rise: in 1993, the proportion was one-fifth. More and more institutions are hiring couples. A 2008 survey 2  of around 9,000 US researchers found that the proportion of hires that went to couples rose from 3% in the 1970s to 13% in the 2000s. And data from the online dating service PlentyOfFish reveal that users with a graduate degree are three times more likely than the average user to form a couple with someone with a similar level of education. Collaboration is key to the scientific process, but when collaborators are romantic partners, that relationship offers some unique advantages \u2014 a deep understanding of each other's personality and motivations \u2014 as well as the risk that work will dominate conversation at the dinner table. Here  Nature  talks to four couples about how they have managed to blend their science and lives. \n               Materials and air miles \n             After Felser returned from her sabbatical, she and Parkin began racking up air miles. And Parkin's practical attitude rubbed off on Felser. \u201cAs a chemist you want to understand bonding, you want to find new synthesis methods. But you don't think deeply about applications,\u201d she says. Now, she started to also consider the material's cost and stability. As a result, companies lined up to work with her. \u201cYou really learn to think differently,\u201d she says. In 2011, the couple published a paper 3  on Heusler compounds and their potential in spintronics, a discipline that makes use of electrical fields to manipulate the spin of electrons. Over the past few years Felser and Parkin have managed to spend up to one-quarter of their time together. Conferences and meetings became fruitful ways of meeting up. \u201cAs soon as people recognized that were are a couple, they started to invite us together to conferences. It was very good,\u201d Felser says. Felser's employers \u2014 she is now director of the Max Planck Institute for Chemical Physics in Dresden \u2014 even realized that they might be able to persuade Parkin to accept a position in Germany. After many years on different continents, he is finally making arrangements to move, having been appointed director of the Max Planck Institute for Microstructure Physics in Halle. In April, he was awarded the Finnish Academy of Technology's Millennium Technology Prize, and plans to put part of the \u20ac1 million (US$1.4 million) in prize money towards building a house by the river in Halle. They plan to marry in December \u2014 on Stuart's birthday, \u201cso I won't forget\u201d, he says. It will be their first place together. \u201cLufthansa and United will be very unhappy,\u201d Parkin says. \n               Neuronal connection \n             Lily and Yuh-Nung Jan have made their career studying cell division. But they themselves are inseparable. They start their sentences with 'we' or 'our'. Even their labs are joined. They met in 1967 in their native Taiwan when both were studying physics. Yuh-Nung had just got his bachelor's degree and his class was taking a celebratory hiking trip in the mountains. Joining them was a student from the class below: Lily. She had jumped ahead a year, catching up with Yuh-Nung, and was applying for graduate school, too. \u201cI have a theory that quite a lot of her classmates were intimidated by her,\u201d says Yuh-Nung. \u201cBut I didn't know better.\u201d Both got places studying physics at the California Institute of Technology (Caltech) in Pasadena. They were an item, but spent their first three years in separate dorms. Not long after they started work, a physicist-turned-biologist came to their department to give a seminar, and made them rethink their career choice. \u201cBack in Taiwan we were not exposed to modern biology,\u201d says Yuh-Nung. \u201cAt Caltech, that was our first time. I guess it was good timing because biology was getting really interesting.\u201d Besides, he adds, tongue in cheek, they were over the hill as physicists. \u201cAll the great ones do something really important very early in their career, in their twenties, and we'd already reached that age.\u201d In a month they had made the switch to cell biology, and after pursuing separate thesis projects, began to collaborate. In 1971, they married. It was a very low-key ceremony at the Los Angeles courthouse \u2014 costing just US$6 for the licence and parking \u2014 and they celebrated by going camping and hiking in Yosemite National Park. In 1979, they moved to the University of California, San Francisco. And having spent several years working in the same labs on similar projects, it was natural for them to run a lab together. There were cases of too many cooks spoiling the broth. \u201cIn the very beginning, we both would sit with a postdoc or a student, and that certainly didn't work because no two people have the same idea,\u201d says Lily. \u201cIt very quickly evolved into an argument. The student was just looking back and forth.\u201d Their interests overlapped heavily, but were sufficiently different that it made sense for Lily and Yuh-Nung to take the lead on different strands of the same problem: how brain cells divide. They now run adjoining labs, supervise 29 researchers and consistently produce publications in top journals. Lily focuses on ion channels and Yuh-Nung on cell morphology and, increasingly, function. The Jans feel that being a couple gives them benefits over and above non-romantic collaborators. \u201cIt's not the sum of two parts, it's much better than that,\u201d says Lily. She puts their success down to \u201cvery consistent long-term camaraderie\u201d. And the pairing is certainly convenient. \u201cBecause whenever you think of something,\u201d she says, \u201cit could be at home or at work, you can more easily discuss the questions.\u201d Yuh-Nung adds, \u201cWe've been together more than 40 years and I feel very lucky to have her as a partner.\u201d Their relationship seems to have served as a template for their colleagues. \u201cThere were some romances that started in the lab,\u201d says Lily. \u201cMore than one,\u201d Yuh-Nung says. \u201cThere have been kids born during the time their parents were in our lab, he says. \u201cWe lost track, but at some point we're going to put together an album.\u201d \n               Family trees \n             Few researchers can claim to have established a new field of science \u2014 let alone to have done so with their spouse. But that is exactly what evolutionary biologist Mark Pagel and anthropologist Ruth Mace did. They are the pioneers of using phylogenies \u2014 evolutionary trees \u2014 in anthropology, seeking to explain human cultures and behaviour as if they were evolving species. When they first met, in the zoology department at the University of Oxford, UK, in the late 1980s, their work had little overlap. Mace was working on animal biology and Pagel was developing ways to analyse species relatedness. Both were heavily influenced by the evolutionary biology they were studying. British evolutionists, particularly, were known for their views on the power of adaptation and natural selection to explain behaviour. \u201cWe're both out of that church,\u201d says Mace. They first met at the department morning break, which provided ample time to discuss their ideas. \u201cThose were the days,\u201d Mace recalls. \u201cThe entire department would have massive amounts of coffee for an hour.\u201d Several years later, Pagel and Mace co-authored a paper 4  that used phylogenetic methods to analyse human cultures, and argued that just as zoologists use genetics to look at species evolution, anthropologists could use languages to study human cultural evolution. The same year, their first son was born, adding a twig to their own tree of life. Although they still collaborate on articles and research projects \u2014 Mace estimates that about 10% of their work is joint \u2014 they retain separate research identities. Both have academic interests outside their phylogeny work. But working in overlapping domains can lead to some awkward situations \u2014 especially because they have different surnames. Sometimes, one is asked to review the other's paper or a competing grant application \u2014 offers that they refuse with an explanation of the conflict of interest. \u201cBeing in the midst of two fields that have a history of 'robust' discussion, for want of a better word\u201d, Pagel is grateful to have someone who is on the same side. \n               Dream team \n             Sometimes during his graduate work in marine ecology, Boris Worm would solve problems in his sleep. On waking, he would tell his partner, Heike Lotze, about his dream. A marine ecologist herself, Lotze served as a sleepy sounding board. \u201cYou know how you forget dreams in the morning. But if there's somebody next to you, you can tell them right away,\u201d says Worm. The ecologists believe that their relationship has helped them to shape the early phases of their work in ways that would not be possible in a non-romantic collaboration. \u201cWe can share ideas as they emerge, very raw, very unfinished and some of it not useful but still interesting,\u201d Worm says. \u201cI often have creative, intuitive ideas,\u201d adds Lotze. \u201cThen I feel like I'm handing this raw thing over to Boris and he shapes it a bit.\u201d Worm and Lotze met in the mid-1990s during their graduate study in Germany. Their fields overlapped, but they were pursuing different directions. Lotze was interested in the human influence on the sea and was studying nutrient pollution, thought to be the cause of algal blooms. She puts her practical mindset down to the fact that she was brought up on a farm. By looking after calves and baling hay, she routinely faced the connection between humans and the natural world, and how one changes the other. Worm's background is more analytical; his outlook more theoretical. The son of a psychologist and a professor of education, he grew up thinking a lot about relationships and communities. His PhD was on species interactions, particularly predation in ecosystems. \u201cHeike's perspective grounded my ideas and gave them wheels, and maybe I have provided some wider context for the questions she was asking,\u201d he says. They worked together throughout their PhDs \u2014 even using the same study site, Maasholm field station on the Baltic Sea. \u201cThere was an old rocket-launching station from the cold war, and part had been bought by our institution as a field site. We had the whole place to ourselves,\u201d says Worm. Because their experiments were often closely related, they had to do a little untangling before submitting their work for publication. \u201cWe had to sit down and say, OK, this is what I will publish and this is what you will publish,\u201d Lotze says. They published their first big paper 5  together in 2002 \u2014 a grand synthesis of their PhD projects on the cumulative effects of various influences on marine ecosystems \u2014 and continue to publish together often. Perhaps their most controversial paper, produced as part of a large team in 2006, was a gloomy forecast of global fish stocks 6 . Worm and Lotze were dismayed by how much the media focused on \u201cthe end of seafood\u201d; they had wanted to emphasize the rippling effects on species that are not harvested by humans. \u201cThe focus of the paper was different to what came out in the media,\u201d Lotze remembers. The phone rang constantly, and each found it helpful to have the other for support. \u201cYou understand what the other person is going through,\u201d says Lotze. \u201cI'm a much more shy person, so for me to deal with those media \u2014 it was a storm, really. Boris was more riding the wave.\u201d They are aware that their different personalities sometimes lead to Worm getting more attention than Lotze for their joint work. \u201cBoris was more often the first spokesperson about our ideas,\u201d Lotze says. \u201cFor a while I kept a bit more in the background. People saw Boris more than me.\u201d But Lotze eventually started to step forward. \u201cI didn't like being in the shadow, I had to fight that and get out of my shell,\u201d she says. They are occasionally told that they should differentiate their work, and have made a conscious effort not to co-author all their publications. But last year, the couple won their first joint honour, the Peter Benchley Ocean Award for Excellence in Science. \u201cIt's not very often the connection gets recognized officially,\u201d Worm says. \u201cIt felt really wonderful to have that highlighted.\u201d Official recognition is one thing, but for Lotze and Worm the greatest benefits of collaborating with a partner are less tangible. A romantic partner knows how to motivate, how to comfort when a grant proposal doesn't go your way and how to rein in the loopiest ideas. As Lotze says, \u201cYour partner is your best critic.\u201d \n                     Newlyweds' gut feelings predict marital happiness 2013-Nov-28 \n                   \n                     Online daters do better in the marriage stakes 2013-Jun-03 \n                   \n                     Scientists in love: When two worlds collide 2007-Feb-14 \n                   \n                     Jan lab \n                   \n                     Worm lab \n                   \n                     Lotze lab \n                   \n                     Pagel lab \n                   \n                     Mace lab \n                   \n                     Parkin Lab \n                   \n                     Felser lab \n                   Reprints and Permissions"},
{"file_id": "510462a", "url": "https://www.nature.com/articles/510462a", "year": 2014, "authors": [{"name": "Melinda Wenner Moyer"}], "parsed_as_year": "2006_or_before", "body": "After decades of study, researchers still can't agree on whether nutritional supplements actually improve health. In 1911, Polish biochemist Casimir Funk discovered what was behind a then-mysterious neurological condition known as beriberi, common in regions where people's main source of calories came from de-husked, or 'polished', rice. He fed a group of ill pigeons a substance he had isolated from rice polishings, and within 12 hours, they had recovered. Funk went on to propose 1  that a handful of puzzling ailments including beriberi and scurvy arose because of deficiencies in nutrients like the one he had found in the rice husks. He considered these chemicals vital amines, which he shortened to \u201cvitamines\u201d. Although many embraced the idea that vitamins could prevent or reverse certain illnesses, the medical establishment railed against it: Funk's colleagues at the Lister Institute of Preventive Medicine in London questioned his theory and tried to ban him from using the term vitamine in his papers, and a 1917 editorial in the  Journal of the American Medical Association  noted that although \u201cthe expression 'deficiency disease' has become popular\u201d, the concept is a \u201cvague explanation that is readily accepted by the uncritical\u201d 2 . Today, nobody doubts that vitamin B1 can prevent beriberi or that vitamin C prevents scurvy. But scientific opinion about the use of vitamin supplements by millions of seemingly healthy people has never been more divided. An editorial published in the  Annals of Internal Medicine 3  last year offers a striking case in point. In it, researchers at Johns Hopkins University in Baltimore, Maryland, and other institutions proclaimed with certainty that the US public should \u201cstop wasting money\u201d on vitamin supplements. They argued that research has found no benefits, in part because most people in industrialized nations are well-nourished. Within months a counterattack ensued, headed by huge names in nutrition science and biochemistry, including Bruce Ames at the Children's Hospital Oakland Research Institute in California and Walter Willett at Harvard University in Cambridge, Massachusetts, who argued that vitamin deficiencies are, in fact, widespread in the United States and that supplements can help to close nutritional gaps 4 . Meir Stampfer, an epidemiologist at Harvard, considers the anti-vitamin editorial \u201cgarbage\u201d. \u201cI just felt sadness that such a poorly done paper would be published in a prominent journal and cause so much confusion,\u201d he says. The argument raises important questions about the quality and relevance of more than a century of studies. \u201cThere will always be two polar sides to this argument, and the main reason for that is we don't know the answers \u2014 we don't have evidence one way or the other,\u201d says Paul Coates, who directs the Office of Dietary Supplements at the US National Institutes of Health (NIH) in Bethesda, Maryland. Pooled together, evidence from double-blinded, placebo-controlled clinical trials suggests that hardly any nutrient supplements have a consistent health effect on people in developed countries. But many argue that the null findings reflect research deficiencies, including poor study design, inappropriate mixing of different kinds of data and misunderstandings about how much of a nutrient is enough. \u201cThe tools we've had in the past have been so crude \u2014 it's like we've been looking through a dirty window with the curtains closed,\u201d says Susan Mayne, chair of the department of chronic disease epidemiology at the Yale School of Public Health in New Haven, Connecticut, and a member of the Institute of Medicine's Food and Nutrition Board, which establishes US nutrition guidelines such as the Dietary Reference Intakes for vitamins and minerals. Although some scientists say that researchers can glean important insights from existing nutrition data, others, such as Robert Heaney, an endocrinologist at Creighton University in Omaha, Nebraska, argue that most existing studies are fatally flawed and that the whole enterprise needs a methodological overhaul. \u201cThe trials we have in nutrition aren't answering the right questions, so they're not appropriate,\u201d says Connie Weaver, head of the department of nutrition science at Purdue University in West Lafayette, Indiana, and a member of the Food and Nutrition Board. \u201cWhat we're using now is pretty bad science.\u201d \n               The sweet spot \n             The market for vitamins and supplements has been estimated at US$68 billion worldwide \u2014 and multivitamins are by far the most popular. Most people take them not to treat diagnosed deficiencies, but to improve or maintain \u201coverall health\u201d, as reported 5  last year by the Office of Dietary Supplements. Clinical deficiencies such as scurvy are rare in industrialized nations, but some research suggests that many people are at least mildly deficient in certain nutrients. In 2011, an analysis of data from the US Centers for Disease Control and Prevention's National Health and Nutrition Examination Survey (NHANES) reported 6  that more than one-quarter of the US population are not getting enough of vitamins A, C, D and E, calcium or magnesium. Ninety-seven per cent fail to get enough potassium. The current Dietary Guidelines for Americans, released in 2010, warn that the intake of potassium, dietary fibre, calcium and vitamin D among the general public is \u201clow enough to be of public health concern\u201d. Scientists argue over just how important these seemingly widespread subclinical deficiencies are. Johns Hopkins epidemiologist Pete Miller dismisses them as nonexistent. He argues that even with government-recommended nutrient levels, \u201cthe threshold for what defines deficiency is probably incorrect\u201d. Surveys used to determine what kind of food people eat, and how much, are notoriously unreliable, for example. In 2013, a  PLoS ONE  study 7  found that energy-intake data from the 39 years of NHANES studies were \u201cnot physiologically plausible\u201d for a majority of participants because of systematic under-reporting. Still for some nutrients, Mayne says, it is almost certain that some people are \u201creally not getting enough\u201d. Moreover, research suggests that individuals with lower-than-average intakes but clinically 'normal' nutrient statuses could still benefit from supplements. Researchers at the Harvard School of Public Health recruited 672 health professionals with histories of benign colorectal tumours, a risk factor for colorectal cancer, to see if folic acid helped to reduce tumour recurrence. Half of the participants took 1 milligram of folic acid a day for between 3 and 6.5 years, and the other half took a placebo. The supplements had no effect when everyone was analysed together, but among the people with the lowest folic acid intake at the start of the trial, those who took supplements had a reduced risk of recurrence 8 . On the other side of the coin, several large trials suggest that over-consuming nutrients could be dangerous. The Alpha-Tocopherol Beta-Carotene Cancer Prevention Trial set out to see whether smokers would benefit from certain supplements. It turned out that those who took 20 mg of the vitamin A precursor \u03b2-carotene a day \u2014 3 times the US recommended daily allowance for vitamin A \u2014 for 5\u20138 years were, in fact, 18% more likely to develop lung cancer than those taking a placebo 9 . A potential explanation is that the breakdown products of \u03b2-carotene can, at high doses, cause cell proliferation. These results illustrate one of the many complexities of nutrient metabolism. Nutrition scientists now recognize that risk curves are J- or U-shaped: nutrients have beneficial effects at low doses and toxic effects at high doses. The magnitude of the response differs, too, depending on where individuals start on the curve \u2014 their baseline status. Yet this is often ignored. Many of the studies included in a 2009 systematic review 10  commissioned by the US government to inform the development of guidelines for vitamin D intake, for instance, did not include information on baseline status, so the review probably lumped together individuals who responded differently; perhaps unsurprisingly, it concluded that findings on vitamin D were \u201cinconsistent\u201d (see   Nature   475 , 23\u201325; 2011). \u201cThese are common-sense design issues that need to be put on the table when you're thinking about a study, and they haven't been,\u201d says Heaney. \n               Masked effects \n             Nutrient intake in control groups is also important but often overlooked. As part of the NIH's Women's Health Initiative (WHI), researchers tested the effects of daily doses of 1,000 mg of calcium a day \u2014 along with vitamin D \u2014 on women's fracture risks 11 . Although NHANES data at the time suggested that the average calcium intake for postmenopausal women was about 600 mg a day, the trial investigators learned after randomization that women in the control group were actually consuming more than 1,000 mg a day. The trial found no statistically significant difference in fracture risk between the intervention and control groups, but \u201cthe study design was such that it couldn't show anything\u201d, Heaney says. Even so, \u201csystematic reviews continue to include the Women's Health Initiative as a 'negative' study\u201d. The trial highlights two other potential confounding factors. The first is that study participants are typically more health-conscious than other individuals. Although WHI participants on average consumed relatively high levels of calcium, nearly 75% of US women between the ages of 31 and 50 fail to get the recommended 1,000 mg of calcium per day from food. The second point is that compliance with instructions is often low \u2014 only 59% of participants were still taking at least 80% of their pills by the end. Those who do not stick to the prescribed treatments might differ from those who do in important ways, skewing outcomes. Another important factor is genetic variability. \u201cEvery person has about 50,000 variations in their genes,\u201d says Steven Zeisel, director of the University of North Carolina Nutrition Research Institute in Chapel Hill. Any number of them could be important in metabolism. Yet \u201cvery few geneticists are collecting diet information, and very few diet people collect genetic information\u201d. Zeisel's work has uncovered, for example, that 44% of women have gene variants that significantly increase their dietary requirements for the nutrient choline. It is perhaps no wonder that trial results have been inconsistent \u2014 and that reviews often report null findings (see \u2018Data deficiencies\u2019). Plus, the effects of nutrition interventions are probably subtle: whereas drug trials compare exposure with no exposure, nutrition trials compare higher and lower exposures, because everyone eats and consumes some nutrients. Subtle differences may be hard to detect and have long latency periods. These limitations and considerations add up \u201cin a way that causes trials to be heavily stacked against showing any benefit\u201d, says biochemist Balz Frei, director of the Linus Pauling Institute at Oregon State University in Corvallis. \n               boxed-text \n             \n               A clearer view \n             So how can scientists design studies to arrive at nutritional truths? In a paper 12  published in  Nutrition Reviews  in January, Heaney proposes guidelines. He argues that, first and foremost, scientists need to consider the dose\u2013response curve. It is absolutely crucial, he says, to measure the baseline nutritional status of trial participants and track changes over time. He also suggests that investigators use participants with similar baseline intakes. That could limit who the results apply to, but it would make data clearer. Measuring nutrient status presents additional challenges. Take calcium: the body carefully regulates blood levels, keeping them constant by pulling the mineral from bone when intake is low. Heaney says that it might be possible to measure how much is being consumed by looking at other biomarkers, such as parathyroid hormone, which triggers the removal of calcium from bone, but such tests can be expensive. Researchers must also come up with accurate ways to assess food and nutrient intake during trials. This requires better estimates of the nutrients in foods. Frei says that the US Department of Agriculture's National Nutrient Database for Standard Reference, considered the country's authoritative source of food-composition data, overestimates the amounts of vitamin A in foods because the standard units used do not account for nutrient bioavailability. And it misses some other sources of vitamins in food. It does not, for example, assess levels of 25-hydroxycholecalciferol, a form of vitamin D found in animal products. The good news is that scientists have developed technologies to improve measurements of both nutrient status and intake. Mayne and her colleagues, for instance, have created a skin-spectroscopy method for assessing levels of carotenoids 13 . \u201cYou can do it for zero cost, essentially \u2014 it's a 30-second scan on someone's skin that gives a readout of their nutrient status,\u201d she says. And researchers at Purdue are building a smartphone app that tracks food intake. Users take a picture of a plate of food, and the application estimates and records its nutritional components. These estimates have been shown to be more accurate than self-reports 14 . Researchers also need to do better at considering and accounting for confounding factors. And reviews should be designed to answer specific questions about specific nutrient doses in specific populations, says Heaney \u2014 basically, they should include only those trials that \u201care appropriate for collapsing into a single data set\u201d. The Office of Dietary Supplements has sponsored a series of technical reports to investigate the challenges associated with evidence-based reviews in nutrition; six have been published. So, back to the original question. Are supplements useless? The current state of research offers only an equivocal half-answer: 'maybe yes' for some individuals, nutrients and doses, and 'maybe no' for others. \u201cNutrition is complex, and I don't think we're necessarily going to find one formula that works for everybody,\u201d says Mayne. But new tools in development could \u201creally change the way we look at this\u201d. The big question is whether, once scientists have all the pieces they need, they can put them together to create a clear and cohesive picture. \n                     Nutrition advice: The vitamin D-lemma 2011-Jul-06 \n                   \n                     Fruit proves better than vitamin C alone 2007-Apr-20 \n                   \n                     Vitamin D health benefit boon? 2004-Jan-13 \n                   \n                     Blog post: Vitamin D fails diabetes test \n                   \n                     Blog post: Vitamin D: a dosing down \n                   \n                     US Institute of Medicine\u2019s Food and Nutrition Board \n                   \n                     NIH Office of Dietary Supplements \n                   Reprints and Permissions"},
{"file_id": "511022a", "url": "https://www.nature.com/articles/511022a", "year": 2014, "authors": [{"name": "Ann Finkbeiner"}], "parsed_as_year": "2006_or_before", "body": "The discovery of thousands of star systems wildly different from our own has demolished ideas about how planets form. Astronomers are searching for a whole new theory. Not so long ago \u2014 as recently as the mid-1990s, in fact \u2014 there was a theory so beautiful that astronomers thought it simply had to be true. They gave it a rather pedestrian name: the core-accretion theory. But its beauty lay in how it used just a few basic principles of physics and chemistry to account for every major feature of our Solar System. It explained why all the planets orbit the Sun in the same direction; why their orbits are almost perfectly circular and lie in or near the plane of the star's equator; why the four inner planets (Mercury, Venus, Earth and Mars) are comparatively small, dense bodies made mostly of rock and iron; and why the four outer planets (Jupiter, Saturn, Uranus and Neptune) are enormous, gaseous globes made mostly of hydrogen and helium. And because the same principles of physics and astronomy must apply throughout the Universe, it predicted that any system of 'exoplanets' around another star would look pretty much the same. But in the mid-1990s, astronomers actually started finding those exoplanets \u2014 and they looked nothing like those in our Solar System. Gas giants the size of Jupiter whipped around their stars in tiny orbits, where core accretion said gas giants were impossible. Other exoplanets traced out wildly elliptical orbits. Some looped around their stars' poles. Planetary systems, it seemed, could take any shape that did not violate the laws of physics. Following the launch of NASA's planet-finding Kepler satellite in 2009, the number of possible exoplanets quickly multiplied into the thousands \u2014 enough to give astronomers their first meaningful statistics on other planetary systems, and to undermine the standard theory for good. Not only were there lots of exoplanet systems bearing no resemblance to ours, but the most commonly observed type of planet \u2014 a 'super-Earth' that falls between the sizes of our world and Neptune, which is four times bigger \u2014 does not even exist in our Solar System. Using our planetary family as a model, says astronomer Gregory Laughlin of the University of California, Santa Cruz, \u201chas led to no success in extrapolating what's out there\u201d. The findings have triggered controversy and confusion, as astronomers struggle to work out what the old theory was missing. They are trying ideas, but are still far from sure how the pieces fit together. The field in its current state \u201cdoesn't make much sense\u201d, says Norm Murray of the Canadian Institute for Theoretical Astrophysics in Toronto. \u201cIt's impossible right now to account for everything,\u201d agrees Kevin Schlaufman, an astrophysicist at the Massachusetts Institute of Technology (MIT) in Cambridge. Until researchers reach a new consensus, they will not be able to understand how our own Solar System fits into the grand scheme of things, let alone predict what else might exist. \n               A planet is born \n             In the search for an overarching theory, astronomers do agree that core accretion has some things right: planets are leftovers from the birth of stars, a process in which interstellar clouds of hydrogen and helium gas contract until their cores grow dense and hot enough to ignite (see 'Planetary standard model'). Some hydrogen and helium does not fall straight into the newborn star, but instead swirls around it, forming a thin, flat disk that orbits the star's equator. Carried along with this gas are tiny solid grains of heavier elements such as carbon, oxygen, nitrogen, silicon and iron, all made in earlier generations of stars. As the disk cools, electrostatic charges stick these grains together to form loose conglomerates that eventually grow into kilometre-scale bodies known as planetesimals. At that point gravity takes over, and the planetesimals collide, fragment, mash together and grow into full-sized planets. As that happens, friction with the surrounding gas forces them into almost circular orbits. This core-accretion process happens throughout the disk but has different results in different locations. Towards the centre, the only grains that can survive the heat from the newborn star are materials with high melting points, such as iron and various minerals \u2014 essentially, rock. The result is an inner system of rock\u2013iron planets, limited to an Earth-mass or less by the disk's relative scarcity of solid materials. Farther away from the star, however, the disk is cool enough to preserve ices that are much more abundant than iron and rock, and that accrete readily on the planetesimals. Once the planetesimals grow to maybe ten times the mass of Earth, they can start pulling in the surrounding hydrogen and helium, quickly accreting into Jupiter- and Saturn-like gas giants tens or hundreds of times Earth's mass. They stop growing only when they have cleared all the gas from their orbits. \n               Space oddities \n             This is also where the standard theory of planetary formation stops, mainly because it fits our Solar System so well: rocky planets on the inside, gas giants on the outside. But in 1995, when observers in Switzerland reported 1  the discovery of the first unambiguous exoplanet in orbit around a Sun-like star, it was clear that the standard model had left something out. Precise measurements of the radial velocity of the star 51 Pegasi showed minuscule repeated changes caused by a planet's gravitational pull. The data showed that the planet's mass was 150 times that of Earth, or nearly half that of Jupiter. This clearly put it in the gas-giant category. Yet the planet, 51 Pegasi b, orbited its star every four Earth days at a distance of just 7.5 million kilometres, or 0.05 astronomical units (1  AU  is the distance between Earth and the Sun). This is much smaller than the 0.47- AU  orbit of Mercury, and puts the planet in a region where the temperature of the gas disk during formation would have been about 2,000 kelvin, much too hot for solid ice and gases. \u201cIt was like, 'What! We weren't even looking for that,'\u201d says Derek Richardson, an astronomer at the University of Maryland at College Park. Astronomers called it a hot Jupiter. They soon turned up a family of such giant exoplanets between one-third and ten times the mass of Jupiter, orbiting between 0.03  AU  and 3  AU  from their stars. And there were other oddities: WASP-7b orbits its star's poles instead of its equator; the orbit of HD 80606b is highly elliptical, ranging from 0.03  AU  at one end to 0.8  AU  at the other; HAT-P-7b's orbital direction is opposite to its star's spin.  How did these planets get so close together? And how are they so different?  By 2000, astronomers had found 30 exoplanets; by the end of 2008, 330. Then NASA launched Kepler, which spent the next four years searching for exoplanets in a single patch of sky containing some 150,000 Sun-like stars. Kepler identifies planets by detecting the slight dimming in a star's light that occurs when an object passes in front of it. This 'transit' method can find planets much smaller than the radial-velocity technique can, giving astronomers a chance to detect other Earths. Kepler has now found 974 exoplanets, with 4,254 further candidates waiting for confirmation by ground-based measurements. If all of Kepler's candidates are confirmed \u2014 and they do tend to be \u2014 then the techniques taken together will have found well over 5,000 exoplanets. Kepler's planets run in odd systems. The Kepler-56 system, for example, has two planets, of 22 and 181 Earth masses, both orbiting at 45\u00b0 to the star's plane. In the Kepler-47 system, two planets both orbit a binary star. Kepler-36's planets are closer together than any others yet seen: they orbit the star every 14 days and 16 days, respectively. One is rocky and is eight times as dense as the other, which is ice. \u201cHow did they get so close together?\u201d wonders Richardson. \u201cAnd how are they so different?\u201d Kepler-11 is orbited by six planets, five of which are among the smallest and least massive ever found. Their densities, says David Charbonneau of the Harvard\u2013Smithsonian Center for Astrophysics in Cambridge, Massachusetts, \u201care shockingly low, they must be mostly ice or have significant gas envelopes\u201d \u2014 yet all five are tucked in together within 0.25  AU  of their star. \n               Not like the others \n             Kepler's biggest surprise has come from statistical summaries of its findings. The planets seen so far can be said to fall into three categories: hot Jupiters; giant planets with idiosyncratic orbits; and super-Earths. Worlds in this third category are generally found in compact systems of two to four planets each, orbiting their stars at distances from 0.006 to 1  AU  in periods ranging from more than 100 days down to hours. Although there are no super-Earths in our Solar System, they orbit at least 40% of all nearby Sun-like stars, which makes them the most common type of planet found. \u201cThe hot Jupiters are freaks, less than 1%,\u201d says Joshua Winn, a physicist who studies exoplanets at MIT. \u201cThe long-period eccentric giants are maybe 10%. The 40% \u2014 that makes you wonder.\u201d The question is how to account for all this planetary-system diversity. In general, astronomers begin with the standard core-accretion theory then add in processes that probably did not play out in our own Solar System. To explain hot Jupiters, for example, they suggest 2  that the planets did not stick around at their birth place in the cold outer reaches of stellar disks. Instead, the infant giants spiralled inwards as viscous gas in the disk slowed their orbits. At some point, for reasons unknown, they stopped their death spirals and settled into stable orbits close to their stars. Despite the extreme temperatures, the giant planets had strong-enough gravity to keep hold of their gas. Eccentric giants could be the result of gravitational interaction 3 . If several giant planets started to migrate, they might have passed one another closely enough for their gravity to sling them in crazy new directions. They could have scattered out of alignment with the rest of the system, got knocked into orbits opposite to the star's rotation or even been flung from the system entirely. Super-Earths are harder to account for. For one thing, the term has no agreed definition, says Winn: some of the smallest, closest-in planets might actually be the stripped cores of migrating giants that came too close to their stars and got their gas blown off. \u201cSuper-Earths are probably not nice, stereotypical birds,\u201d says Eric Ford, an astrophysicist at the Pennsylvania State University in University Park. \u201cMaybe some are more like penguins.\u201d The sheer size of the super-Earth flock requires explanation. The standard theory cannot do that because in existing models, the central regions of stellar disks contain much too little material to create several close-in super-Earths. But theorists have found ways around that problem. Laughlin and Eugene Chiang, an astronomer at the University of California, Berkeley, have shown 4  that compact systems of super-Earths can grow from disks with much greater masses, distributed closer to their stars. Murray and Brad Hansen, an astrophysicist at the University of California, Los Angeles, have also proposed 5  a more massive disk, but one in which super-Earths are born from planetesimals that formed farther out in the disk, then migrated in before they collected into planets. Astronomer Douglas Lin of the University of California, Santa Cruz, and his colleagues have tried to merge all the categories of planet into what Winn calls \u201can all-singing, all-dancing model\u201d that can account for all the systems seen 6 . It starts by assuming that the distribution of mass in the disk will vary from system to system. After that, says Lin, it's \u201cmigration, migration, migration\u201d: all types of planet grow to full size in the middle to outer part of the disk, and then move inwards in order. Such models are appealing, but the concept of migration, especially of the smaller planets, gives some researchers pause \u2014 if only because no one has ever seen it happening. The necessary observations may not be possible: stars young enough to have planets migrating through protoplanetary disks are still surrounded by dust, and their light flickers, making it extremely unlikely that current methods will be able to pick out the dimming caused by a transiting planet. The theory is not settled, either. Modellers have found it hard to explain why migrating planets, big or small, would stop in the orbits that astronomers have observed. In simulations, says Winn, they don't: \u201cthe planets plop right down on the star\u201d. Perhaps the biggest question is why our Solar System is so different. Why doesn't it contain the one kind of planet most common around other Sun-like stars? Why are there no planets inside Mercury's orbit when that's where most of the exoplanets are in other systems? Why do we have a balance of large and small planets when most other systems seem to choose one or the other but not both? Astronomers still don't know how different we are. Observations of exoplanets are seriously biased: neither of the two main techniques would find our widely spread-out Solar System, nor are they sensitive to systems with both large and small planets. It might be that we are not unusual at all. Future observations may give some answers. Kepler has been hobbled by a failure of the mechanisms that keep it pointing at its original target patch of sky, but last month it was approved to keep taking data. The longer it does so, the larger the exoplanet orbits it will be able to see. Ground-based programmes are starting to operate with improved instruments, some also capable of seeing planets 5  AU  or more from their stars. And from 2017, NASA's planned Transiting Exoplanet Survey Satellite (TESS) will look for planetary transits across all the bright stars in the sky. The wider range of possible exoplanet candidates makes it more likely that astronomers will spot a Solar System like ours \u2014 if one exists. Meanwhile, researchers continue to nurture their mess of models, which have grown almost as exotic and plentiful as the planets they seek to explain. And if the current theories are disjointed, ad hoc and no longer beautiful, that is often how science proceeds, notes Murray. \u201cLife,\u201d he says, \u201cis like that.\u201d \n                     Three regimes of extrasolar planet radius inferred from host star metallicities 2014-May-28 \n                   \n                     NASA unveils exoplanet haul 2014-Feb-26 \n                   \n                     An Earth-sized planet with an Earth-like density 2013-Oct-30 \n                   \n                     A sub-Mercury-sized exoplanet 2013-Feb-20 \n                   \n                     Planetary science: The search for Earth's twin 2012-Oct-24 \n                   \n                     Super-Earths give theorists a super headache 2011-Dec-13 \n                   \n                     Interactive exoplanet-data explorer \n                   \n                     Extrasolar Planets Encyclopaedia \n                   \n                     NASA Exoplanet Archive \n                   \n                     Super Planet Crash \u2014 game creating exoplanetary systems \n                   Reprints and Permissions"},
{"file_id": "511019a", "url": "https://www.nature.com/articles/511019a", "year": 2014, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "A decade ago, voters in California changed the biomedical research landscape by directly funding embryonic stem-cell research. Now the organization they created needs a hit to survive. On a brilliant day in April, tens of thousands of baseball fans stream past Jonathan Thomas's office towards AT&T Park for the first home game of the San Francisco Giants 2014 season. Thomas's standing desk faces away from the window, but the cheering throngs are never far from his mind. Thomas chairs the board of the California Institute for Regenerative Medicine (CIRM), the US$3-billion agency hailed by scientists around the world for setting a benchmark for stem-cell research funding. But scientists will not be the ones who decide what becomes of CIRM when the cash runs out in 2017. Instead, it will be the orange-and-black-clad masses walking past Thomas's window. And to win their support, Thomas knows that the agency needs to prove that their collective investment has been worthwhile. \u201cWe need to drive as many projects to the patient as soon as possible,\u201d he says. Californians voted CIRM into existence in 2004, making it the largest funder of stem-cell work in the world. The money \u2014 the proceeds of bond sales that must be repaid with $3 billion in interest by taxpayers \u2014 helped to bring 130 scientists to the state, and created several thousand jobs there. It has funded research that led to the publication of more than 1,700 papers, and it has contributed to five early clinical trials. The institute has navigated a difficult path, however. CIRM had to revamp its structure and practices in response to complaints about inefficiency and potential conflicts of interest. It has also had to adapt its mission to seismic shifts in stem-cell science. Now, ten years after taking off, the agency is fighting for its future. It has a new president, businessman Randal Mills, who replaces biologist Alan Trounson. Its backers have begun to chart a course for once again reaching out to voters, this time for $5 billion (with another $5 billion in interest) in 2016. And it is under intense pressure to produce results that truly matter to the public. Whether or not CIRM succeeds, it will serve as a test bed for innovative approaches to funding. It could be a model for moving technologies to patients when conventional funding sources are not interested. Much of what is celebrated and lamented about CIRM can be traced back to the Palo Alto real-estate developer who conceived of it: Robert Klein. Although officially retired from CIRM \u2014 he chaired the board from 2004 to 2011 (see 'State of funding') \u2014 Klein's office is adorned with mementos of the agency: a commemorative shovel from the groundbreaking of a CIRM-funded stem-cell research centre, and a photo of him with former governor Arnold Schwarzenegger at the ribbon-cutting ceremony. It was Klein's idea to ask voters to support stem-cell research in 2004, through a ballot measure called Proposition 71. When he succeeded, CIRM instilled a kind of euphoria in stem-cell scientists, who were at the time still reeling from a 2001 decree by then-President George W. Bush that severely limited federal funding for embryonic-stem-cell research. California's commitment removed this roadblock and revealed that many in the state and the country supported the research. \u201cBefore CIRM, the conversation was about where to draw restrictions on embryonic stem-cell research,\u201d says Sean Morrison, a stem-cell and cancer biologist at the University of Texas Southwestern in Dallas. \u201cOnce the California voters supported CIRM, the conversation shifted to how the rest of the country could keep up.\u201d Indeed, five other states went on to set up stem-cell-research agencies. \n               Planning the sequel \n             One afternoon, Klein doodles on a legal pad as he lays out the case for 'CIRM 2'. He writes the word 'scientists', then draws a box around it. Science, he says, is more under attack than ever before. President Barack Obama might have loosened the restrictions on federal funding for embryonic-stem-cell research in 2009, but some presidential hopefuls \u2014 one of whom could be elected in 2016 \u2014 support reinstating the Bush-era restrictions or even an outright ban on funding the work. Klein points out that 26 states are led by legislatures that oppose the research. Moreover, funding for the National Institutes of Health (NIH) has taken a hit and the agency closed its Center for Regenerative Medicine in April (see   Nature   508 , 157; 2014). This is the case that Klein plans to lay before the voters. \u201cWe have to protect science's access to the full range of cellular types now,\u201d he says. \u201cAnd in doing that, we will protect the freedom of science to ethically pursue knowledge in this country outside of religious ideology.\u201d His focus on a 'full range' of cells reflects the ways in which the stem-cell field has blossomed in the past decade, changing in ways that no one expected when Klein first proposed CIRM. And the biggest breakthroughs have come from outside California. A Japanese group, for example, discovered how to create induced pluripotent stem (iPS) cells (  K. Takahashi & S. Yamanaka  Cell   126 , 663\u2013676; 2006), which can be tailor-made from patients without the use of embryos. And scientists in Oregon managed to clone a human embryonic stem-cell line by nuclear transfer (  M. Tachibana  et al .  Cell   153 , 1228\u20131238; 2013). Some treatments are progressing faster outside California, too. Japan, for instance, has raced ahead of the rest of the world in testing iPS cells as therapies for conditions such age-related macular degeneration, which can cause blindness (see   Nature   494 , 413; 2013). But in California, researchers are making nerve, heart, eye and skin cells from iPS cells and embryonic stem cells \u2014 a range of work rare for a single state \u2014 and they aim to test many of these in humans. They are developing drugs against cancer stem cells, which are thought to perpetuate the disease. And they are leading the world's only two trials of treatments that combine gene editing and cell therapy to treat HIV. They are doing all this with an unmatched infrastructure, including a network of 12 new or newly renovated facilities, and a funding pipeline that acts as a beacon to young scientists. \u201cAlmost every country would be jealous of what they've got in California,\u201d says Christine Mummery of the Leiden University Medical Center in the Netherlands. Top-flight scientists such as Clive Svendsen, formerly at the University of Wisconsin\u2013Madison, have flocked to the state, she says. But, she adds, \u201cthey haven't cured a patient, which is the critique\u201d. That critique frequently bubbles to the surface. On 22 January, Thomas and CIRM's senior vice-president of research and development, Ellen Feigal, faced uncomfortable questions from the state's Citizens Financial Accountability and Oversight Committee at a meeting in Los Angeles. Committee member Jim Lott \u2014 a health-care executive and father of a 13-year-old daughter with a spinal-cord injury \u2014 grew frustrated as he listened to the pair run through PowerPoint slides full of numbers and abstract language touting the agency's scientific accomplishments. None of the slides told him what CIRM had done that would get his daughter out of her wheelchair. He had asked the question before, and there was still no answer. \u201cI'm telling you, pal,\u201d Lott told Thomas, \u201cI would have a hard time voting for it again.\u201d Lott says that he knows that CIRM is doing worthwhile science, but it is not doing a good job explaining how the science fulfils the promises of cures that were made in the Proposition 71 campaign. \u201cThey think that people should understand that this is good work that they're doing, and that should be compelling enough to continue it,\u201d he later explained. \u201cBut that's just not a realistic view.\u201d And it is not just parents who have raised concerns. A 2012 report from an Institute of Medicine panel, for instance, opined that CIRM's ambitious translational goals were \u201cunrealistic\u201d. Only the year before, the California company Geron of Menlo Park had halted a CIRM-funded trial that was the first major test of human embryonic stem cells after deciding to focus on cancer treatments. Klein says that the $34-million campaign he organized to promote Proposition 71 never promised cures in ten years. But the proposition's supporters frequently mentioned cures \u2014 for instance, in the state's official voter information guide, where they said that \u201cPROPOSITION 71 IS ABOUT CURING DISEASES AND SAVING LIVES\u201d. CIRM is now working mightily to provide evidence to sway Lott and people like him. A big part of CIRM's translational aspirations has been wrapped into $450 million in disease-team awards \u2014 funds that aim to mimic the work of early-stage biotechnology companies by spurring groups of scientists to move discoveries into clinical trials. To give the scientists who spearhead the teams expertise and guidance, it created a panel of industry and regulatory experts that meets with each disease team at least once a year to help to nudge them along. And CIRM has made a series of changes to focus more on its translational mission. In May, it awarded Asterias Biotherapeutics in Menlo Park $14 million to continue testing the product Geron had abandoned. Realizing that it would need to boost the odds of success, CIRM adjusted its portfolio to free up more cash and prioritize the projects most likely to succeed. In 2013, for instance, it cut funding for shared lab spaces and basic research, and set aside $200 million to accelerate work by existing disease teams. \n               Matchmaker extraordinaire \n             Scientists who have benefited from these programmes say that CIRM's approach feels fresh. In 2008, for instance, it asked two groups \u2014 one led by immunologist Jeffrey Bluestone at University of California, San Francisco, the other led by the company ViaCyte in San Diego \u2014 to work together on a project to transplant insulin-producing cells derived from embryonic stem cells into people with diabetes. Bluestone worried that patients' immune systems might destroy or overreact to the cells, and had animal data showing that packaging the cells in some kind of container would prevent harmful immune reactions. So ViaCyte developed a porous membrane made from materials similar to those in medical implants, into which it packed the cells. The company is now working with the US Food and Drug Administration to design a clinical trial. \u201cI don't think ViaCyte would be where it is today had there not been a partnership,\u201d Bluestone says. The NIH does not typically suggest that potential grant recipients \u2014 especially from academia and industry \u2014 pool their proposals in this way. Irving Weissman, who heads the Institute of Stem Cell Biology and Regenerative Medicine at Stanford University in California, received a $19-million CIRM disease-team award to work with colleagues in the United Kingdom and develop an antibody-based therapy for leukaemia. The team developed an antibody, tested it in animals, and in December received $13 million more from CIRM for human safety trials.  I'm telling you, pal, I would have a hard time voting for it again.  Weissman says that CIRM funding has allowed science, rather than a focus on the bottom line, to drive the project. They were able to work on two potential approaches, for example, increasing the chance of a successful therapy. He says that this would be \u201cunheard of\u201d elsewhere. \u201cIn every biotech company, the money makes all the decisions \u2014 not the scientists.\u201d Yet some have argued that CIRM puts too much power in the hands of scientists and others who have an inherent stake in its work. In its report, for instance, the Institute of Medicine said that CIRM's \u201cbuilt-in allocation of board seats to university leadership, patient advocates, and members of the biotechnology industry, for example, ensured that a high percentage of those seats would be permanently occupied by persons with almost unavoidable, conflicts of interest\u201d. In response, CIRM changed its rules so that board members whose institutions might receive money through CIRM programmes cannot vote on specific grants or funding issues. The decision, made in March, came after years of complaints about potential conflicts on CIRM's 29-member oversight committee. This committee approves grant initiatives and awards, but one-third of it comprises administrators from academic institutes who receive the money (see   Nature   453 , 18\u201321; 2008). That kind of problem has plagued other efforts as well. The only other US state research funding initiative that rivals CIRM's size, the $3-billion Cancer Prevention and Research Institute of Texas (CPRIT) has also been criticized over conflict issues, such as allegations that it awarded funds to preferred scientists without appropriate peer review (see   Nature   486 , 169\u2013171; 2012). Observers say that these seem to be common pitfalls of creating large state science initiatives. \u201cBoth CIRM and CPRIT have faced the reality that you can get into situations that create concerns about interest groups,\u201d says Aaron Levine, a member of the Institute of Medicine panel and a political scientist at Georgia Tech in Atlanta. On the whole, though, he adds, CIRM \u201chas done a good job of awarding grants fairly\u201d. Scientists who receive those grants argue that CIRM should continue to exist, but some are sanguine about the prospect of losing the funding. \u201cIn ten years more, we'll find out if CIRM's gamble pays off,\u201d Svendsen says. \u201cBut even if CIRM stops funding, we have enough preliminary data of some efficacy of stem cells that we'll continue getting funding from the NIH, wealthy donors and industry.\u201d Thomas is trying to tap some of those sources to raise between $1 billion and $2 billion to help scientists to finish ongoing clinical trials if the agency closes and they run out of money. But if Klein can help it, that will not be a problem. He sees CIRM 2 as a way to tackle what he views as an ever-intensifying war on science. \u201cIf we don't take a position now,\u201d he says, \u201cthe next ten years may see a theocratic government at the state and federal level that restricts scientific research in this country for the next 50\u2013100 years.\u201d It is a shift in the message from 2004, designed to appeal to Californian pride and values. But clearly, it will resonate more if broadcast alongside ads of healthy, smiling patients who have been helped by CIRM. As one board member, former Hollywood executive Sherry Lansing, declared at a meeting in December, \u201cWe need a home run.\u201d The point resonates back in Thomas's office as Giants fans head for the baseball stadium. They will cheer for a routine hit or a nice defensive play. But the only sure way to bring them screaming to their feet will be to slam the ball out of the park. \n                     Funding windfall rescues abandoned stem-cell trial 2014-Jun-03 \n                   \n                     Stem-cell agency faces budget dilemma 2012-Jan-31 \n                   \n                     Stem-cell boss urges communication 2011-Jun-29 \n                   \n                     Stem cells: The impatient advocate 2010-Dec-01 \n                   \n                     California stem-cell grants awarded 2009-Nov-02 \n                   \n                     Stem cells: The 3-billion-dollar question 2008-Apr-30 \n                   \n                     CIRM \n                   \n                     IOM report on CIRM \n                   Reprints and Permissions"},
{"file_id": "511144a", "url": "https://www.nature.com/articles/511144a", "year": 2014, "authors": [{"name": "Emily Sohn"}], "parsed_as_year": "2006_or_before", "body": "From dogs to balloons, researchers are using unorthodox ways to find out where malaria vectors hide during a long dry season. The armed guards at Mali's Bamako Senou International Airport had never seen a German shepherd before. The only dogs they were familiar with were the small, scrappy mixed breeds that are common in West Africa. So when Dana, a wolf-like purebred from California, stepped off a plane and into the airport in February 2012, eight soldiers surrounded her and her trainer Sapir Weiss, guns raised. Weiss, who once trained antiterrorism dogs for the Israeli army, was eager to get Dana outside after 36 hours of bladder-straining international travel that included a seven-hour stopover in Paris. But the soldiers thought the dog's service vest was a suicide bomb. They ordered Weiss to take it off. They demanded to know where Dana's crate was. \u201cWhere's the box?\u201d they yelled. \u201cWhere's the box?\u201d To the guards, and most people in Mali, it was inconceivable that a dog could be trained to travel in economy without a crate. Equally improbable was what Dana had come to Mali to do: sniff out mosquitoes to help eradicate malaria. Dana is part of an ongoing effort to solve a perplexing mystery. Every year, a swathe of the African Sahel region from Senegal to Sudan experiences an extreme dry season that lasts for up to eight months. As surface waters disappear, mosquitoes can no longer reproduce because their eggs and larvae must remain wet to survive. The number of mosquitoes buzzing around crashes to near zero. But when the rains come, adult bloodsuckers appear in explosive numbers in as little as three days \u2014 a timeline that is hard to square with the fact that it takes at least eight days for these mosquitoes to grow from egg to adult. The pattern suggests that adult mosquitoes hide somewhere to wait out the dry season, and that possibility points to a tantalizing plan of attack. Every year, malaria makes hundreds of millions of people ill and kills more than half a million, mostly children in Africa. If scientists could figure out where the mosquitoes go when conditions become inhospitable during dry seasons, they might be able to wipe out the insects \u2014 and with them the disease they carry \u2014 at a point when they are likely to be easy targets. For decades, the hunt for mosquito hideouts has both enticed and plagued scientists, who have run up against a long list of frustrations. Among those refusing to give up is Tovi Lehmann, a research entomologist at the US National Institute of Health's Laboratory of Malaria and Vector Research in Rockville, Maryland, who, along with dozens of team members in both the United States and Africa, has spent six years and about US$700,000 trying to find the elusive insects with every method he can think of, including dogs such as Dana. The potential pay-off is worth the massive effort, he says. \u201cYou could imagine visiting villages for less than half a day, targeting those putative sites and basically cutting malaria transmission to the point where it would be trivial.\u201d \n               Elusive quarry \n             It takes 4 hours to drive from the Malian capital, Bamako, to Thierola, an off-the-grid village of about 300 residents and 120 buildings, made mostly from mud bricks and with thatched or mud roofs. During the wet season, from May or June through to October or November, half a metre of rain falls on the region. Bushes turn green. Millet, maize (corn), peanuts and other crops grow. And mosquitoes arrive. Fast. Lehmann's team has seen mosquito numbers in Thierola surge tenfold within five days of the rain's start 1 . Entomologists have come up with two explanations for how mosquito populations can swell so rapidly before they have had a chance to reproduce. One possibility is long-distance migration on high-elevation winds. Alternatively, the insects might spend the dry season in aestivation, a unique type of dormancy that occurs in some animals that need to survive long dry seasons. Lehmann's group found an early clue that aestivation might be the answer. At the end of the rainy season in late October 2008, the team anaesthetized almost 7,000 mosquitoes, marked them with poster paint and released them. During collections the next May, they were amazed to find a live adult female with the telltale marks, despite the fact that  Anopheles gambiae  (the complex of species that transmit malaria most efficiently in the Sahel) are known to live for 30 days at most. Although aestivation seems a likely scenario, the process has been difficult for biologists to explain. In temperate regions, mosquito species are known to go dormant to survive cold winters, which makes sense because insect metabolisms naturally slow when temperatures drop. Sub-Saharan Africa, on the other hand, is always hot, so it is harder to understand how mosquitoes could slow their metabolism there. The insects must also somehow resist desiccation. Attempts to induce aestivation in mosquitoes have produced little more than circumstantial and anecdotal evidence. Studies in the 1940s, for instance, tried to replicate natural conditions in the lab but failed to get female mosquitoes to go dormant, according to Douglas Norris, a medical entomologist at the Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland. A letter 2  published in  Nature  in 1968 described mosquitoes that managed to survive for almost seven months in an insectary in hot, dry Sudan, but those results were never replicated. Genetic studies could also help to shed light on the aestivation hypothesis. When Norris and his colleagues looked at genetic markers from one wet season to the next in a village in Mali in the late 1990s, they found that at least 5,000 females had to survive the dry season to found a new population 3 . And Martin Donnelly at the Liverpool School of Tropical Medicine, UK, and his colleagues have been comparing the genomes of  Anopheles  mosquitoes from across Africa. If genomes remain consistent from one set of rains to the next, that would show even more strongly that many mosquitoes endure the dry season, as opposed to being replaced each year by a population of migrants. The discovery of the painted female as the rains swept into Thierola showed that a wild mosquito could survive the dry season \u2014 the equivalent of a human living for 700 years, Lehmann says. Norris is building field enclosures in southern Gambia for his own studies of mosquito biology and may eventually make try to demonstrate aestivation in that environment. \u201cThis is something we believe happens, but nobody has been able to prove it other than Tovi's one mosquito.\u201d So for the next couple of years, as the rains again approached, the team set up nets around suspected refuges, determined to catch mosquitoes as they first emerged. \u201cWe thought in a year or two, we were going to be able to find where they hide,\u201d Lehmann says. \u201cEverything looked within reach, and it looked very simple.\u201d Despite around-the-clock monitoring, and even a manufactured rainstorm created by a water-filled truck to lure the mosquitoes out of hiding, the insects remained elusive. Potential hiding spots seemed overwhelming, numbering in the hundreds within just 500 metres of the village, making it impossible to put nets and cages around them all. The hunt, it turned out, would not be so simple after all. \n               On the scent \n             Lehmann's project was not the first to misfire. About 15 years ago, Fr\u00e9d\u00e9ric Simard, a medical entomologist at the Institute of Research for Development, a government institution in Montpellier, France, went on a similar quest in dry-season Senegal. He set up traps around as many potential hiding spots as he could think of, indoors and out, including barns, silos, water-storage containers, wells, tree stumps, tree trunks and cracks in the bottom of dried ponds \u2014 to no avail. \u201cThere was no evidence for resting mosquitoes anywhere despite huge efforts,\u201d he says. \u201cThis is basically just like looking for a needle in a haystack.\u201d A group from the University of Miami in Coral Gables, Florida, has scattered tent-like cages around a village in Kenya. And a team based at Hebrew University in Israel is looking for aestivating mosquitoes in wet hideouts outside villages in Mali by, among other methods, flooding animal burrows with water to try to flush out the insects. Neither team has found anything conclusive. Given so many failed attempts before him, Lehmann decided that he would have to come up with a more targeted strategy. When he heard about dogs that could sniff out bedbugs, he latched on to the idea, despite some potentially major challenges. For instance, unlike bedbugs, mosquitoes fly, making them wily and harder to track. And whereas bedbugs emit distinctive pheromones, mosquitoes have no natural scent. First, he set out to find a way to give mosquitoes an odour. Months of experimenting finally led to vetiver oil, a perfume ingredient derived from an eastern Asian weed grass with an earthy, woodsy smell. Vetiver is not native to Africa, so it would not confuse a dog's nose. It is not toxic or foul smelling, so researchers would not baulk at working with it. And it is stable enough to last for a couple of weeks, long enough to use in experiments. The researchers found that spraying the mosquitoes with vetiver killed the insects, so they soaked tiny bits of string in the scent, then glued the strings onto the bellies of anaesthetized mosquitoes. When they woke, the mosquitoes could still fly, even with the extra weight. In the meantime, Lehmann called Weiss, who jumped at the opportunity to train a dog to track scented mosquitoes, even though several trainers before him had rejected the idea as impossible. On the sunny lawn of his Olivet Kennel and Dog Training Resort in Santa Rosa, California, Weiss got to work with Dana, allowing her to sniff six cardboard boxes. When she came to the one scented with vetiver, she got her favourite reward: a tennis ball. After a year of training, Dana could find 1-centimetre-long scented strings with 97% accuracy, even when they were put in vials and placed in open holes 20 centimetres deep. To see whether she would perform as well in Africa, Weiss and Dana flew to Mali in early 2012. Dana sat with Weiss inside the plane so that she would not overheat in the cargo hold. The airport stand-off nearly derailed the whole project, and once they made it to Thierola, Weiss had to retrain Dana because of the extreme heat. Dogs must pant to stay cool, but they can't do that and sniff at the same time. With temperatures near 50 \u00b0C, Dana needed to learn to stop and cool off every five minutes. Over the course of a month, Dana found scented strings hidden in natural holes again and again. She also found mosquitoes that had been marked with scented strings and released days before, including one under a pile of clothes in a laundry basket. The 30 or so Malians in the search crew were flabbergasted. \u201cThey were just jumping up and down,\u201d Weiss says. \u201cMy status got elevated. They thought I was a shaman because I could talk to a dog and the dog would listen to me.\u201d The hope was to get the scented mosquitoes to lead the researchers to their secret lairs. But Dana ran out of time, returning home with Weiss just before a coup swept Mali. Lehmann departed soon after, leaving the mosquito-hunting project in the hands of Adama Dao, an entomologist at the University of Bamako's Malaria Research and Training Centre, who had been leading the Mali-based portion of the team. In August 2012, two Malian handlers and their dogs travelled to Santa Rosa to learn both the mosquito-sniffing task and how to build a close human\u2013dog relationship. One handler was a physician, the other had a biology degree. Both had been working with Dao and Lehmann for two years on other search strategies, and they were enthusiastic about what they had seen Weiss and Dana do. The Malian-led dry-season dog work, which continued until December 2013, turned up about nine suspected hiding places, Dao says. Both dogs had independently led the team to the same small tree holes, open holes in the ground near trees and old termite mounds, mostly within about 1.5 kilometres of the village. Nets were set up around the potential shelters at the end of the dry season. But like many who came before them, the researchers found no hordes of aestivating mosquitoes. \n               A wider net \n             This month, Lehmann returned to Thierola for the first time in more than two years, armed with some new ideas. He has erected huge nets around the community's wells, for instance. And he has some more-unorthodox plans. Given that other insects might use similar strategies to endure the harsh dry season in the Sahel, he wants to find a larger sentinel species that can be fitted with a radio transmitter and potentially lead researchers to hiding mosquitoes. He also wonders if they could find a marker \u2014 such as fungal DNA, trace chemicals or cells from plants or animals \u2014 that they could put in suspected shelters. Any mosquitoes emerging from those places would then carry lingering tags that would lead researchers straight to the source, if they can catch the escapees quickly enough. Meanwhile, the search is moving out and up \u2014 to, among other places, a set of caverns about 30 kilometres away and into helium balloons equipped to trap any mosquitoes travelling in by wind. Preliminary studies during the wet season have located a few  A. gambiae  flying as high as 160 metres above the ground, even though there is nothing for them to eat up there. It is now starting to look as though one of the three species of mosquito that transmit malaria in the region aestivates, and the other two migrate, says Lehmann. So far, Lehmann and his team have published nine papers on the hunt and have three more in the works. As they continue their efforts in the field, other malaria researchers are cheering them on. \u201cAny time you can find a stage where mosquito numbers are very low and they are maybe congregating in one spot, you could really have a big impact,\u201d says Gregory Lanzaro, an entomologist at the University of California, Davis, who studies the population genetics of  A. gambiae  in Africa. \u201cThere's always hope. When you work on things like malaria, you can't be a pessimistic person. Otherwise, you'd stay home.\u201d Lehmann and Dao remain optimistic that they will eventually find the elusive mosquito dens, where a few low-cost squirts of insecticide could save so many lives. Every setback, they say, provides new information. \u201cWe have never been disappointed and we will remain hopeful,\u201d says Dao. \u201cAs long as we have resources, we will reach our goal.\u201d \n                     Malaria: A race against resistance 2013-Nov-13 \n                   \n                     Zapped malaria parasite raises vaccine hopes 2013-Aug-08 \n                   \n                     Sickly mosquitoes stymie malaria\u2019s spread 2013-May-09 \n                   \n                     Mali International Center for Excellence In Research \n                   \n                     World Health Organization on malaria \n                   \n                     Malaria Consortium \n                   \n                     Tovi Lehmann \n                   \n                     Olivet Kennel & Dog Training Resort \n                   Reprints and Permissions"},
{"file_id": "511140a", "url": "https://www.nature.com/articles/511140a", "year": 2014, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "As a much-hailed breakthrough in stem-cell science unravelled this year, many have been asking: \u2018Where were the safeguards?\u2019 It seemed almost too good to be true \u2014 and it was. Two papers 1 , 2  that offered a major breakthrough in stem-cell biology were retracted on 2 July, mired in a controversy that has damaged the reputation of several Japanese researchers. For scientists worldwide it has triggered painful memories of a decade-old scandal. In February 2004, South Korean researcher Woo\u00a0Suk Hwang announced that he had generated stem-cell lines from cloned human embryos 3 , creating a potential source of versatile, therapeutic cells that would be genetically matched to any patient. A frenzy of excitement followed this and a subsequent publication 4 , but that didn\u2019t compare with the media firestorm when the results were revealed to be fabricated. The two main cloning papers were retracted 5 , and the careers of some dozen scientists were devastated. In the soul-searching that followed, \u2018research integrity\u2019 became a hot topic, scientists re-evaluated the responsibilities of authorship, and institutions vowed to improve the way that they police their staff.  Nature  and other journals also made promises, saying that they would vet manuscripts more thoroughly. In an Editorial at the time,  Nature  wrote 6 : \u201cKeeping in mind the principle that extraordinary claims require extraordinary proof,  Nature  may in rare cases demand it.\u201d A year later, when Shoukhrat Mitalipov of the Oregon Health & Science University in Portland claimed to have cloned embryonic-stem-cell lines from monkeys 7 ,  Nature  required independent tests to verify that the lines came from the monkey donors. This verification was published alongside the cloning paper 8 . \u201cI applaud what they did,\u201d says Alan Trounson, the outgoing president of the California Institute for Regenerative Medicine in San Francisco, who helped with the testing. David Cyranoski tells Kerri Smith why the STAP cell papers were retracted \u00a0 Then came Japan\u2019s stem-cell case. This January, Haruko Obokata, a young biochemist at the RIKEN Center for Developmental Biology (CDB) in Kobe, Japan, reported in  Nature 1 , 2  that she had converted mouse cells to an embryonic-like state merely by subjecting them to stress, such as physical pressure or exposure to acid (see  Nature 505, 596; 2014 ). The process, labelled stimulus-triggered acquisition of pluripotency (STAP), was so contrary to current thinking that some scientists said they accepted it based only on the reputation of Obokata\u2019s co-authors, who were some of the most trusted names in stem-cell research and cloning. But the paper 1  that set out the fundamental technique was soon shot full of holes. There was plagiarized text in the article. Figures showed signs of manipulation, and some images were identical or nearly identical to those used later in the same paper and elsewhere to represent different experiments. More damning were genetic analyses that strongly suggested the cells were not what they were purported to be. And although deriving STAP cells was advertised as simple and straightforward, no one has yet been able to repeat the experiment. Within the space of six months, Obokata was found guilty of misconduct by her institution; well-respected scientists, including RIKEN head Ryoji Noyori, bowed their heads in apology; and both papers were retracted 9 . In the end, the evidence for STAP cells seemed so flimsy that observers began to ask where were the extra precautions and the \u2018extraordinary proof\u2019 that had been promised post-Hwang. The case has reopened difficult questions about the quality of research and peer review, and the responsibilities of co-authors, institutions and journals. It is also making its mark as an example of how not to do things. The episode has already become a \u201cparable in my lab for teaching students about scientific ethics\u201d, says Jeanne Loring, a stem-cell biologist at the Scripps Research Institute in La Jolla, California. In this article, the news team at  Nature  \u2014 which is editorially independent from the journal team that reviewed and published the STAP papers \u2014 attempts to find out what went wrong and what can be learned from the case. \n               Caught in isolation \n             The STAP saga has its roots in a contentious hypothesis more than a decade old. In 2001, Charles Vacanti, an anaesthesiologist at the Brigham and Women\u2019s Hospital in Boston, Massachusetts, said that he had found \u201cspore-like cells\u201d in virtually every type of mammalian tissue 10 . According to Vacanti, these cells were pluripotent \u2014 that is, they could develop into any type of cell in the body \u2014 and seemed to lie dormant until activated, perhaps by injury or disease, to regenerate tissue. Vacanti told  Nature \u2019s news team in January that by 2006 his laboratory could grow the cells in large numbers, but that they still \u201cwere not exceptionally well characterized by us\u201d. That is, the team had not demonstrated pluripotency. This was a job he gave to Obokata, a graduate student who had joined his lab in 2008. Proving pluripotency is often done by injecting cells into a developing mouse embryo \u2014 creating a \u2018chimaera\u2019 \u2014 and tracking their fate. It is a difficult experiment, and Obokata needed help. \u201cI was looking for the god\u2019s hand of chimaeric-mouse generation,\u201d she said back in January. A Google search led her to famed mouse cloner Teruhiko Wakayama at the CDB, whose lab she entered in 2011 as a visiting professor. After hundreds of failures to get cells derived from adult mice to show up in chimaeras, she and Wakayama switched to newborn mice as the source of the cells \u2014 and the process worked. By that point, both Vacanti and Obokata were convinced that the stress of the isolation process was creating the pluripotent cells. Obokata said that the idea had come to her while she was taking a bath and reflecting on the stress in her own life. In the experiments at RIKEN, she used acid to stress spleen cells from newborn mice, and she carried out further experiments to characterize their conversion with Yoshiki Sasai and Hitoshi Niwa, two highly regarded stem-cell biologists at the CDB. With the two key characteristics of STAP cells now demonstrated \u2014 they were pluripotent and were created using stressful conditions \u2014 she had enough data to publish two papers in  Nature  on 30 January 1 , 2 . Obokata became an instant celebrity in Japan, where the media picked up on details such as the \u2018Moomin\u2019 cartoon stickers on her lab equipment and the traditional Japanese cooking apron, given to her by her grandmother, that she wore instead of a lab coat. But within weeks, anonymous observers began noting mistakes in the papers, including evidence of image manipulation, duplications and plagiarism (see  go.nature.com/e4dwry ). Researchers also started to report that they could not reproduce the supposedly simple experiment. On 1\u00a0April, a RIKEN investigative committee concluded that Obokata had committed scientific misconduct. She maintained that the results were real, but one by one her co-authors withdrew support for the findings. In principle,  Nature  retracts articles only when all co-authors agree, although in rare cases papers can be retracted even if one or more of the authors dissent. In June, Obokata relented and agreed to retract both papers (see  go.nature.com/wsfox5 ). She has not responded to multiple requests for interview since April. She has, however, been invited to participate \u2014 under surveillance \u2014 in ongoing efforts at RIKEN to verify the original findings. Should the papers have been published in the first place? Critics have argued that many of the flaws could have been identified beforehand by  Nature  \u2014 the easiest, in theory, being a 17-line passage that was taken almost word for word from a 2005 paper 11  by another group. To detect signs of plagiarism, most journals use a service called CrossCheck. It can compare a submitted manuscript with some 40 million published articles from around 100,000 titles, looking for text matches. Nature  editors did use CrossCheck and did not find the match. But the journal from which the text was lifted,  In Vitro Cellular & Developmental Biology \u2014 Animal , had not been indexed by the service at the time. \u201cAlthough the databases are very large and growing, there are limitations,\u201d explains Rachael Lammey, a product manager at CrossRef in Oxford, UK, which provides the CrossCheck service. Such misses get flagged \u201ca couple times a year\u201d, she says, but there is no way to know how many instances of plagiarism fall through the cracks. Moreover, identifying the match probably would not have halted publication. Many instances of copied text do not constitute plagiarism and just require citation of the original source. Indeed, the RIKEN investigative committee concluded that the passage \u2014 a methodological description \u2014 should have cited the original, but that the failure to do so was not misconduct. The committee was more vexed by instances of manipulated and duplicated images in the STAP papers. Obokata had spliced together gel lanes from different experiments to appear as one. And she had used an image of cells in a teratoma \u2014 a tumorous growth that includes multiple types of tissue \u2014 that had also appeared in her PhD dissertation. The captions indicated that the image was being used to represent different types of cell in each case. The committee judged that in both instances, although she might not have intended to mislead, she should have been \u201caware of the danger\u201d and therefore found her guilty of misconduct. Obokata claimed that they were mistakes and has denied wrongdoing. \n               Picture imperfect \n             Image manipulation and duplication within the same manuscript can be detected, and journals are increasingly checking for such problems. Jana Christopher analyses images in every manuscript before they are accepted by EMBO Press, a journal publisher based in Heidelberg, Germany. She uses a set of automated adjustments created for the image software Photoshop by the US Office of Research Integrity that change attributes such as contrast and colour to make manipulations easier to spot ( ori.hhs.gov/actions ). At the behest of the chief editor of  The EMBO Journal , Bernd Pulverer, Christopher ran tests on the STAP papers without knowing their background. She spotted three problems: the gel manipulation that was ultimately attributed to misconduct, a seemingly innocent duplicated image mistake and a composite image of cell colonies most probably done to save space. \u201cThe aberrations we saw are fairly typical,\u201d says Pulverer, who reports that around 20% of scanned manuscripts have been found to have such issues since the journal started looking for them in 2011.  The Journal of Cell Biology  ( JCB ), published by Rockefeller University Press in New York, has been systematically scanning figures and images in all accepted papers since 2002 and finds about the same rate. But the journals do not immediately consider a problematic image fraudulent. Spliced gel lanes, for example, are often attempts to present data more clearly and concisely. In most cases, these manipulations are done naively, to create a \u2018prettier\u2019, more informative image, says Pulverer. But, he says, \u201cin cases where we don\u2019t obtain plausible explanations and source data for the figure in question, we dig deeper\u201d. At the  JCB , acceptance is revoked for about 1% of papers, according to the journal\u2019s executive editor, Liz Williams.  There has to be control, but also trust in science, otherwise the system breaks down.  Such scanning methods are far from foolproof. Some worry that alerting authors to problems with their images allows would-be fraudsters to improve their forgeries. And although manipulated images might be easy to spot, it is harder to identify duplications, especially when they come from other articles. \u201cCross-literature comparisons would require very high-powered search algorithms and probably a supercomputer,\u201d says Pulverer. \u201cThis has been discussed for a number of years but never moved forward.\u201d In the STAP case, current image-checking procedures would not have caught the problem with the teratoma image \u2014 or several other problems with the main paper 1  that surfaced under closer scrutiny. Philip Campbell, editor-in-chief of  Nature , says: \u201cWe have concluded that we and the referees could not have detected the problems that fatally undermined the papers.\u201d But scientists and publishers say that catching even the less egregious mistakes raises alarm bells that, on further investigation, can lead to more serious problems being discovered. Many say that the tests should be carried out on all papers. Christopher says that it takes about one-third of her working week to check all accepted manuscripts for the four journals published by EMBO Press. At  Nature  and the  Nature  research journals, papers are subjected to random spot-checking of images during the production process. Alice Henchley, a spokeswoman for  Nature , says that the journal does not check the images in all papers because of limitations in resources, and that the STAP papers were not checked. But she adds that as one outcome of this episode, editors \u201chave decided to increase the number of checks that we undertake on  Nature \u2019s papers. The exact number or proportion of papers that will be checked is still being decided.\u201d In the face of extraordinary claims, checking images and text is hardly sufficient to test the veracity of results. Independent genetic analyses 12 , 13  proved that the world\u2019s first sheep cloned from adult cells, Dolly, was genetically identical to the mammary-gland cells from which she was cloned. And Snuppy, created by Hwang\u2019s lab, was similarly confirmed to be the first cloned dog 14 , 15 . Both verifications took place after publication of the initial results in order to quell debate, but such verification also could be done pre-publication, before a controversy arises. Nature  took that step in 2007, when it solicited an independent test of Mitalipov\u2019s monkey stem-cell lines, which showed them to be true clones. Those tests required coordination between researchers who had to navigate restrictions on sending cells across borders. It \u201cdragged on for months\u201d, says Mitalipov. He subsequently chose another journal,  Cell , to publish his next big stem-cell cloning paper 16  \u2014 demonstrating the process using human cells \u2014 partly for that reason. That paper was published 12 days after acceptance. An anonymous critic pointed out mistakes in the final manuscript including image duplication and mislabelled figures, but the authors proved that they were harmless errors (see  Naturehttp://doi.org/mnk;2013 ). Some researchers say that it would be best if collaborators on a project carried out more stringent verification tests of their own before submitting a paper \u2014 something that Wakayama now woefully acknowledges. In the STAP case, however, it is not immediately obvious how this could have been done. Unlike for sheep, dogs or primates, genetically identical mouse strains and matched embryonic-stem (ES)-cell lines are widely available, making it easy to provide samples that look roughly correct. \u201cThere is no way to distinguish, genetically, ES cells from STAP cells originating from the same strain,\u201d says Rudolf Jaenisch, a stem-cell biologist at the Whitehead Institute for Biomedical Research in Cambridge, Massachusetts. That said, post-hoc genetic analyses do seem to be unravelling the STAP riddle. In March, as problems with the papers mounted, Wakayama outsourced genetic sequencing of the purported STAP cells (see  Naturehttp://doi.org/tf8;2014 ). The work focused on a certain characteristic \u2014 the spot where a gene encoding a fluorescent protein inserts itself into the genome \u2014 to pinpoint the cells\u2019 origin. The results, which Wakayama announced in June, showed them to be different from the mice that had supposedly been used to make them (see  Naturehttp://doi.org/tf9;2014 ). A step beyond genetic verification would be independent replication of the experiments. That would probably put undue burden on the scientists asked to do the work. But Richard Behringer, a developmental biologist at the MD Anderson Cancer Center in Houston, Texas, says that asking authors directly whether more than one person in the lab has reproduced the results would be one way for the journal \u201cto ensure that all data and images in the manuscript were solid\u201d. \n               Replication issues \n             Nature  does not disclose communications between editors and authors, but Campbell says that there were four independent groups on the two papers, and \u201cit was our understanding that the work was independently replicated\u201d. When questions first arose about the STAP cells, moreover, co-authors on the papers were adamant that they had overseen replication. Sasai says that his lab observed the generation of STAP cells. But in fact, he had asked Obokata to replicate only the first part of the STAP process \u2014 the expression of a protein, Oct4 \u2014 which he recorded with live imaging. At the time, he says, he did not consider \u201cthe possibility of a gap between these cells and the derivation of STAP stem cells\u201d. Wakayama said that he \u201cindependently\u201d produced STAP stem cells that looked exactly like ES cells \u2014 development beyond what Sasai witnessed \u2014 which convinced him that the process was solid. After problems first emerged, he told the  Nature  news team in an e-mail: \u201cI succeeded at RIKEN independently, therefore, I know this result is absolutely true.\u201d Looking back now, though, he realizes that his replication was not completely independent \u2014 Obokata was at his side during the entire experiment \u201cand oversaw every step in the process\u201d, he says. Because he moved to a new position at the University of Yamanashi soon after that test, he never characterized the cells and could not rule out the possibility that they had been switched or contaminated. The RIKEN investigative committee found that Sasai and Wakayama, although not involved in the misconduct, carried \u201cheavy responsibility\u201d for what happened.  Reputation in science is everything. Once gone, it\u2019s extremely hard to get back.  The co-author who has most confused the issue of replication is Vacanti. Within a week of the STAP papers being published, he sent photos of what he claimed were human STAP cells to the magazine  New Scientist . As others failed to replicate the STAP experiment, he told the  Nature  news teamin mid-February: \u201cThere really shouldn\u2019t be any difficulty. If I can do it, anyone should be able to do so.\u201d In mid-March, he published online a list of tips for making STAP cells \u201cregardless of the cell type being studied\u201d. To date, however, he has produced no additional evidence that he has derived STAP cells in his laboratory. In a statement released on 2 July, Vacanti asserted that although he agreed to the retractions owing to errors in the manuscripts, he is confident that the \u201ccore concept\u201d of STAP will be \u201cverified by the RIKEN as well as independently by others\u201d. For many stem-cell researchers, the most shocking part of the STAP controversy was the involvement of Niwa, Sasai and Wakayama in such troubled work. \u201cCo-authors of a paper like that should have been certain that they can reproduce results independently and in this case they should share responsibility,\u201d says Davor Solter, a developmental and stem-cell biologist at the Institute of Medical Biology in Singapore. Wakayama takes the blame for not making more effort to check Obokata\u2019s work, such as looking at her notebooks, which the investigative committee found to be alarmingly disorganized. Others sympathize with the researchers, who themselves were duped \u2014 whether through negligence or intention \u2014 by a junior colleague. \u201cThere has to be control, but also trust in science, otherwise the system breaks down completely,\u201d says Maria Leptin, a molecular biologist and director of EMBO. \u201cI cannot watch over every step while they are pipetting. That\u2019s not the point.\u201d But in addition to lax oversight, Janet Rossant, a stem-cell researcher at the Hospital for Sick Children in Toronto, Canada, and the outgoing head of the International Society for Stem Cell Research, points to \u201cpoor reviewing and editing by  Nature , who were also too ready to publish without verification\u201d. Campbell disagrees. \u201c Nature  did not let down its guard,\u201d he says. Some say that the journal should publish reviewers\u2019 comments to clarify the process. Campbell says that the publication of referees\u2019 comments has been considered, but that the disadvantages \u2014 which include potential misinterpretations and the desire of many referees to keep their comments confidential \u2014 have prevented the journal from embracing this. \u201cWe have to accept that where there is research, there will be research misconduct,\u201d says Paul Taylor, a research-integrity adviser at the University of Melbourne, Australia. Efforts by institutions to train researchers and improve data-management infrastructure might help, \u201cbut no policy, no education or training, no administrative requirement, is going to stop misconduct\u201d. Taylor adds that the focus should be on how an institution responds. In that sense, he says the STAP problem seems to have been a success. RIKEN has acknowledged flaws in its data management and exaggeration in its press release for the STAP papers. Taylor says that its response has been fast, effective and transparent. In the midst of the investigation into Obokata\u2019s work, Noyori instructed all RIKEN labs to review their published work \u2014 totalling tens of thousands of papers \u2014 for similar types of errors. Among stem-cell researchers, STAP has become another cautionary tale to add to Hwang\u2019s, with its own set of lessons. For Loring, the story stresses the importance of good record-keeping and the need to enter collaborations with caution. \u201cI lecture my lab members that being an author carries responsibility for the validity of all of the work in the paper. I really try to live by that.\u201d She says that she has removed her name from authorship lists in cases when she could not vouch for the quality of a manuscript. But for many it is a lesson hard-learned, once again. \u201cReputation in science is everything,\u201d says Trounson, in a statement that applies no less to journals and institutions than individual scientists. \u201cOnce gone, it\u2019s extremely hard to get back.\u201d \n                     Papers on \u2018stress-induced\u2019 stem cells are retracted 2014-Jul-02 \n                   \n                     STAP retracted 2014-Jul-02 \n                   \n                     Scientists rally around beleaguered Japanese research centre 2014-Jul-01 \n                   \n                     Stem-cell scientist found guilty of misconduct 2014-Apr-01 \n                   \n                     Nature  special: The rise and fall of STAP \n                   \n                     RIKEN CDB update on STAP publications \n                   Reprints and Permissions"},
{"file_id": "511282a", "url": "https://www.nature.com/articles/511282a", "year": 2014, "authors": [{"name": "Virginia Hughes"}], "parsed_as_year": "2006_or_before", "body": "Gastric-bypass surgery can curb obesity as well as diabetes and a slew of other problems. Researchers are now trying to find out how it works. Every week, about 20 people visit the University of Pittsburgh Medical Center in Pennsylvania to be evaluated for weight-loss surgery. They tell a nurse their medical history and have a routine physical examination. Then they sit down with a surgeon to discuss their options. Anita Courcoulas, head of minimally invasive bariatric and general surgery at the centre, has had thousands of these conversations in the past 25 years. During that time, the information she shares with her patients has changed dramatically. Thanks to clinical trials, she can now tell them with some confidence that surgery not only spurs remarkable weight loss in most people, but also significantly lowers the risk of heart attack, stroke, cancer and death. And with the most popular procedure \u2014 Roux-en-Y gastric bypass, which shrinks the stomach to the size of an egg \u2014 up to 60% of patients with diabetes go into remission for at least several years after the operation 1 . There are drawbacks for her to discuss, too: the cost (around US$25,000); the small risk of surgical complications (on a par with that of gall-bladder removal); and the chance of developing nutritional deficiencies or an intolerance to certain foods. But perhaps the toughest issue for patients is the uncertainty. Surgery does not work for everybody, and weight loss can be transient. Doctors are not sure why gastric bypass and similar procedures curb diabetes and other diseases. The conventional view has been that the benefits stem mostly from the weight that patients shed \u2014 typically one-quarter of their body mass 1 . But in the 1980s, some patients were found to show rapid changes in their metabolism after surgery, suggesting that other factors are at play. Now, a slew of high-profile animal studies is identifying potential mechanisms in how the gut adapts to its strange new configuration: with sweeping changes in bacterial populations, bile acids, hormone secretions and tissue growth. The hope is that more research on what happens after bariatric surgery will enable physicians to identify who will respond best \u2014 and even lead to ways of altering metabolism without resorting to the knife. \n               Hunger strike \n             Bariatric surgery debuted in Sweden in 1952, when surgeon Viktor Henrikson removed a 105-centimetre stretch of a woman's small intestine. The procedure did not help the woman to lose weight, but it did treat her constipation and boost her metabolism. According to Henrikson's case report 2 , she was \u201ccontent, subjectively felt healthier and more energetic\u201d. Over the next two decades, surgeons in the United States refined the procedure. They cut the small intestine near each end, then rejoined it to circumvent all but about 40 centimetres. Known as a jejunoileal bypass, it caused remarkable weight loss but also an array of unpleasant side effects, including bloating, diarrhoea, anal burning and dehydration. Bacterial populations in the bypassed intestine continually rose and the liver became inflamed. \u201cEverybody realized that five years after you have this, you lose your liver,\u201d says David Cummings, a endocrinologist at the University of Washington in Seattle. Today's gold standard is the Roux-en-Y gastric bypass. Pioneered in 1977, the procedure creates a small pouch at the top of the stomach and reroutes the small intestine to connect to it. The bypassed section gets reconnected to the intestine, forming a 'Y' shape, so that it can still drain fluids and bacteria, reducing the risk of festering growth. Even in the early days of gastric bypass, surgeons noticed that the operation had swift effects on metabolism: patients' blood-sugar levels normalized within a week or so. \u201cWe were surprised by the rapidity of the improvement,\u201d read a 1987 study reporting on 397 procedures 3 , \u201ceven though the patients were still clearly morbidly obese.\u201d Patients said that they were not as hungry as before the surgery, and that they ate fewer meals and snacked less. Over time, their food preferences seemed to change, too; anecdotal reports suggested that they often chose salads over desserts and fatty foods. These shifts could not be explained by reduced stomach size alone, Cummings notes \u2014 if the reason was mechanical, patients would simply eat lots of small meals. \u201cThat got the field wondering, what's going on with hunger, here?\u201d In 2002, Cummings and his colleagues identified one of the first biochemical markers associated with the bypass. They had tracked blood levels of ghrelin, the 'hunger hormone' produced by cells in the gastrointestinal tract, in more than two dozen people. Normally, ghrelin levels rise sharply when the stomach is empty and then drop after a meal. Surgery suppressed these fluctuations, Cummings found 4 . The normal peaks and valleys of ghrelin production went pancake flat. \u201cIt's pretty dramatic,\u201d he says. But getting a better handle on the mechanisms required an animal model. Lee Kaplan, director of the Massachusetts General Hospital Weight Center in Boston, looked to rats \u2014 a daunting task given their tiny innards. He recruited a young surgeon from Greece, Nicholas Stylopoulos, and the duo, along with a few other research groups, began to publish papers on what happened to the animals after surgery. The research has shown that just like in people, bypass surgery stabilizes glucose levels 5 , boosts metabolism 6  and steers the animals to choose low-fat over high-fat meals 7 . \n               Gut microbes \n             A potential explanation could lie in the trillions of microbes that reside in the gut. In 2009, Rosa Krajmalnik-Brown from Arizona State University in Tempe and her colleagues sequenced the bacterial genes present in faeces from three people who had received a gastric bypass. Compared with obese and normal-weight controls, their guts contained proportionally fewer bacteria from the usually abundant Firmicutes phylum, and excess levels of the Gammaproteobacteria class 8 . \u201cEven with that small sample size we were able to get statistically significant differences because the microbiota changed so drastically,\u201d Krajmalnik-Brown says. The researchers do not know why these particular changes occurred, but they say it could be because Firmicutes die when oxygen is present, and shortening the gastrointestinal tract means that oxygen that is normally consumed in the small intestine reaches the colon. Alternatively, the changes could occur because food is being digested faster. (The group did not test microbial make-up in individuals before surgery, but is now working on a follow-up study that compares before and after.) A similar shift in gut flora has been reported in rats undergoing a gastric bypass 9 . Whether this bacterial shift drives a change in health is hard to say, but there are some indications that the microbes contribute to metabolic changes. Kaplan and his colleagues performed a gastric bypass on obese mice, then transplant the altered gut bacteria into mice bred to be microbe-free. These recipient mice were not obese, but still lost about 5% of their weight after the transplant 10  (see  Nature   http://doi.org/tjq ; 2013 ). This research and other strands of evidence suggest that metabolic regulation could begin in the gut, which has the ability to send messages to the brain, liver, pancreas, kidneys and immune system. \u201cThe idea that a lot of the information starts at the gut is a relatively new concept,\u201d says Kaplan. For example, researchers have now found that bile acids have a role in signalling. These fluids help to emulsify fats so that the lipids are metabolized more efficiently, but they also act as hormones, signalling to receptors in the gut. Randy Seeley, a neuroscientist at the University of Michigan Health System in Ann Arbor, and his colleagues decided to look at what happens when one of these bile-activated-receptors \u2014 the farsenoid-X receptor (FXR), which helps to regulate glucose metabolism \u2014 is deleted in mice. The researchers overfed both mutant and control mice until they were fat, and then did a vertical sleeve gastrectomy. (This procedure shrinks the stomach like a gastric bypass does, but does not circumvent any of the small intestine.) A week after surgery, both types of mice lost a lot of weight. By the fifth week, however, only the control mice had managed to keep it off; the mutants had gained it all back 11 . Without FXR and the messages carried by bile acids, the surgery fails to work. Intriguingly, the control mice, but not the mutants, showed a notable increase in the abundance of  Roseburia , a Firmicutes bacterium that tends to be suppressed in people with diabetes, suggesting that FXR and its related biological pathways could turn out to be therapeutic targets in this disease. Bile-acid and bacterial changes could affect the gut's communication with organs responsible for the glucose dysregulation that causes diabetes. But a study published last year 12  suggests that the gut itself shows changes in glucose metabolism after surgery (see  Nature   http://doi.org/tjr ; 2013 ). Using a rat model of gastric bypass, Stylopoulos, who now runs his own laboratory at Boston Children's Hospital, and his colleagues showed that the 'Roux limb' \u2014 the piece of intestine that runs from the stomach pouch to the reconnected intestine \u2014 expands dramatically in width and length after surgery. \u201cIt really doubles in size,\u201d Stylopoulos says, and it stays that way. That makes sense, because without a full-sized stomach, the tissue must adapt to heaps of undigested food. But the limb's rapid growth requires a lot of energy, which comes from glucose. The changing organ starts to use more glucose, and the change is maintained over time, Stylopoulos says. \u201cEssentially, the intestine becomes a bigger and a more hungry organ that needs more glucose than before.\u201d Stylopoulos believes that this tissue growth in the gut is the main driver of the surgery's remarkable metabolic benefits \u2014 not the reduction in calorie intake. \u201cSurgery works because it changes the physiology,\u201d he says. Weight loss is still important, however, because it triggers a series of changes that help to curb diabetes. \n               Problems in translation \n             How well do these findings translate into people? \u201cThese are elegant studies,\u201d says Samuel Klein, director of the Center for Human Nutrition at Washington University School of Medicine in St Louis, Missouri. But, he asks: \u201cIs the bariatric surgical procedure in a rodent the same as in a human?\u201d Klein allows that just like rodents, people have a marked improvement in blood-glucose regulation within days of bypass surgery. But that could be because their caloric intake goes from around 4,000 calories a day to just 400, he says. \u201cAnyone who has abdominal surgery is not going to be very hungry after the operation.\u201d Rates of diabetes remission are much higher after gastric bypass than after gastric banding \u2014 in which a silicone band squeezes around the stomach to restrict the flow of food (see 'Surgical selection'). Animal studies suggest that that is because the bypass alters metabolism in a way that banding does not, but Klein believes that it is simply because people who have a bypass tend to lose much more weight. To probe this, Klein compared people who had lost one-fifth of their weight after gastric bypass with those who lost the same amount with banding. All patients showed dramatic improvements in glucose tolerance, insulin sensitivity and the function of pancreatic \u03b2-cells, which release insulin 13 . \u201cWe did not see any hint\u201d of differences between the groups, he says. The major caveat of this study is that none of the volunteers had diabetes, so Klein's group is now repeating the study in people with the disease. \u201cIt could be a whole different ball game,\u201d he says. Still, he agrees that rodent studies provide a relatively quick way to investigate specific biological pathways and test hypotheses about why only some procedures curb diabetes and why certain patients are more likely to benefit than others. By testing individual pathways, researchers hope that they can develop personalized treatments \u2014 whether drugs, probiotics or lifestyle changes \u2014 that change the specific pathway that has gone awry in a patient. For Courcoulas, the variability and unpredictability in patient response \u2014 in both weight loss and diabetes remission \u2014 is the most important issue that animal studies could address. When talking to prospective patients about their surgical options, she frequently refers to a study she published last year 14  that tracked nearly 2,500 people who had undergone various types of bariatric surgery. After three years, those who received gastric banding had lost, on average, about 16% of their weight, whereas those who had a gastric bypass lost 32%. Banding also led to partial remission of diabetes in 29% of people, compared with 68% for bypass. In general, Corcoulas notes, most people lose a lot of weight in the first six months, irrespective of the procedure. But after that, they diverge wildly: some people continue to lose at a rapid clip, others plateau and still others gain some back. This uncertainty partly explains why so few people who are eligible for surgery choose to have it, she says. At her centre, nearly 1,500 people a year attend group informational sessions to learn the basics of weight-loss surgery. Only 1,000 of them will elect to talk to a surgeon, and 700 will go on to have an operation. \u201cThe big question is, what are the factors, the predictors for someone's success after surgery?\u201d Courcoulas says. Clinical studies have identified some contributors \u2014 iron deficiency, liver fibrosis and being older than 50 years, for instance, are all associated with less weight loss 15 . But none of these is absolute. The only thing clear, Courcoulas says, is the need to identify better biological markers. \u201cMy colleagues in basic science,\u201d she says, \u201care going to be making a big contribution in doing that.\u201d \n                     Diabetes drugs ride a bumpy road 2013-Dec-10 \n                   \n                     Gastric bypass makes gut burn sugar faster 2013-Jul-25 \n                   \n                     Gut microbe may fight obesity and diabetes 2013-May-13 \n                   \n                     Gut-microbe swap helps mice shed weight 2013-Mar-27 \n                   \n                     Nature  Insight: Obesity and diabetes \n                   Reprints and Permissions"},
{"file_id": "514288a", "url": "https://www.nature.com/articles/514288a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Innovative ways of teaching, learning and doing research are helping universities around the globe to adapt to the modern world. Modern universities are heirs to a thousand-year tradition of scholarship. But they are also being buffeted by twenty-first-century upheavals in technology, economics and society. Through trial, error and experiment, they are now trying to find new ways of thinking and acting that will help them to prosper. \n               GERMANY: The innovative university \n             \n               By Alison Abbott \n             When chemist Wolfgang Herrmann began his first term as president of the Technical University of Munich (TUM) in 1995, he was determined to challenge an academic status quo that had prevailed for more than two decades. Germany had responded to the social upheaval of the 1960s by declaring that all universities were equivalent and taking steps to prevent the development of a privileged elite, a move that tended to undermine any competitive spirit in the faculty. New rules had also guaranteed a place for any student with a school-leaving certificate \u2014 which meant that universities had no say in who took their courses \u2014 and kept faculty members bound to bureaucratic civil-service laws. The result was an inward-looking ivory-tower culture that had stagnated intellectually and financially. Herrmann's vision was to turn the TUM into a nimbler, more internationally competitive 'entrepreneurial university' that would encourage innovation, risk-taking and business initiative among students and faculty members alike. To do that, he restructured the TUM along the lines of successful US institutions such as the Massachusetts Institute of Technology (MIT) in Cambridge. In 1999, he made one of his first \u2014 and, within Germany, pioneering \u2014 reforms by installing a board of trustees that replaced the Bavarian education ministry's direct control of the TUM and allowed for much quicker decision-making. Since then, he has used that freedom to introduce some of the first German graduate schools: institutions that provide PhD candidates with rigorous common standards for coursework, instead of leaving them to the vagaries of individual supervisors. Herrmann has also created a private fund-raising foundation to allow flexible and independent financing of some university projects; formed an institute of advanced studies; and launched a tenure-track system that obliges the university to promote and permanently employ academics who make the grade, and sack those who do not. The latter system is a familiar concept in the United States, but revolutionary in Germany. The changes did not go down well at first with some faculty members, who were uncomfortable with the perceived emphasis on applied research and commercial pay-off at the expense of basic research. But the discontent has faded as the university's scholarly output has soared, from 2,276 publications in 2002 to 5,827 in 2013. The TUM's funding from government agencies and industry \u2014 nearly \u20ac300 million (US$380 million) this year \u2014 is among the highest in Germany. In 2012, Herrmann was re-elected to his post for his fourth consecutive six-year term by a university board that includes representatives from the faculty, students, non-academic staff and the surrounding community. He has announced that this term will be his last. But his unusually long tenure, which will total 24 years when he leaves in 2019, has given him time and clout to push the regional Bavarian government to relax one restriction on the TUM after another. \u201cNow that I know virtually everyone in politics and government, they are sometimes afraid to say 'no' to me \u2014 because they know others will ask them why they are being uncooperative,\u201d he says, only half-joking. When the federal government introduced its Excellence Initiatives \u2014 competitions in 2006 and 2012 designed to encourage universities to actively shed their restrictions and win elite status (see  Nature   487 , 519\u2013521; 2012 ) \u2014 it gave other German universities an incentive to undertake reforms. But nowhere have those changes proceeded as rapidly as at the TUM, which was a winner in both competitions. Bavaria has agreed to pay one-quarter of the running costs of the TUM's Excellence Initiative projects when the federal money runs out in 2017. \u201cThis new culture is now ingrained,\u201d says Herrmann. \u201cThe next generation of leadership will continue in this vein.\u201d \n               SOUTH KOREA: The flipped university \n             \n               By Mark Zastrow \n             Tae-Eog Lee has a simple philosophy about what academics should do in lectures: anything but lecture. \u201cUsually, in a conventional classroom, students don't think,\u201d he says. \u201cThey just follow the professor's teaching.\u201d So at the KAIST science and technology university in Daejeon, South Korea, where Lee heads the Center for Excellence in Teaching and Learning, he is working to implement a 'flipped classroom'. Instead of sitting through endless one-way lectures, students watch online lessons at home, and then come to the classroom to discuss the concepts and work on problems in small groups. Teaching assistants and the lecturer are there to supervise \u2014 but most of the learning happens among the students themselves. Lee calls this Education 3.0, and sees it as a way to spark creativity, teamwork and the willingness to ask questions, all of which are suppressed by the nature of lecturing \u2014 and, say many, by South Korea's hierarchical society. KAIST is not the first university to try out this concept, but strong support from its administration has made it a leader in the flipped-classroom movement in just two years. From 3 pilot classes in the spring of 2012, the effort has grown to nearly 60 classes this autumn. And over the next 3 years, Lee hopes to raise that to 800 classes, 30% of KAIST's total. Observers at institutions elsewhere are impressed by the magnitude of KAIST's efforts. \u201cThey're changing culture at a massive scale,\u201d says Sanjay Sarma, director of digital learning at MIT. That is the sort of cultural shift that KAIST has been seeking since the early 2000s, when the Korean government began overhauling the university to compete in a globalized world. The reform effort took off in 2006, with the selection of Nam Pyo Suh, a Korean American mechanical engineer at MIT, as president of the university. Suh crafted an environmental and sustainability initiative that brought a wave of government funds and elicited private donations. This enabled the university to go on a hiring spree, recruiting lots of young faculty members \u2014 who in turn brought in grants. KAIST's position in  Times Higher Education 's global university rankings skyrocketed, from 198th at the beginning of Suh's tenure to 69th three years later. But faculty members soon began to protest, striking out at Suh's unsparing performance assessments and his insistence on instruction in English instead of Korean. Then, in early 2011, four students committed suicide within three months, rocking the institution to its core. The tragedies put another of Suh's reforms under scrutiny. In an attempt to raise both standards and funds, he had started levying the university's first tuition charges \u2014 but only on students who earned poor grades. Those who succeeded academically would continue to pay nothing. Students say that the social stigma of paying off low grades amplified the already hyper-competitive environment of KAIST \u2014 and of South Korean society at large, which has the highest suicide rates in the developed world. Facing calls to resign, Suh apologized, scrapped the fees and reinstated instruction in Korean. He also expedited the launch of Education 3.0, \u201cin part because I wasn't sure how long I would be there\u201d, he says. (He was finally forced to resign in February 2013.) Education 3.0's flipped-classroom approach has been prospering. An estimated 30% of KAIST's 10,000-strong student body have taken an Education 3.0 course so far, and their test scores are at least as good as those of students in standard classes. Most important to Lee, however, are the intangible benefits. For example: 71% of the Education 3.0 students report an improved understanding of the material, increased motivation and better concentration. But a significant minority remain unconvinced. \u201cPresentation and discussion are not familiar to Korean students,\u201d says Seong Keun Kang, a graduate student in nuclear and quantum engineering. \u201cI'm not sure it is better than the original classes.\u201d Still, other universities are following KAIST's lead. Seoul National University, one of South Korea's most prestigious institutions, introduced its first flipped classes this year. Universities throughout Asia are watching KAIST, says Gerard Postiglione, who studies Asian higher-education development at the University of Hong Kong in China. According to the QS World University Rankings, KAIST is now the second-best university in Asia. Institutions \u201cwant to see: how do you do this, how do you rise so quickly?\u201d says Postiglione. \n               UK: The social university \n             \n               By Elizabeth Gibney \n             In 2011, a handful of prestigious US universities released the first wave of massive open online courses (MOOCs): recorded lectures that could be delivered on the web to tens or hundreds of thousands of students around the world for free. Other institutions scrambled to follow suit, and the media filled with hype about how MOOCs would spark a total transformation of higher education. Mike Sharples took such rhetoric with a grain of salt. But he works at the Open University in Milton Keynes, UK, which has been delivering courses to students around the world by post, television and computer for some 40 years \u2014 and the university was determined not to be outdone. By 2012, Sharples, chair of educational technology at the university, had joined with a team of fellow British academics to create next-generation MOOCs inspired by the work of the late Gordon Pask: a British educational psychologist who believed that students construct their knowledge through mutual interactions. The new MOOCs would put social engagement at the centre of learning, and encourage conversations as intense as those in online games. \u201cIt was something of a gamble,\u201d says Sharples. \u201cIt seems obvious in retrospect that people would want to talk about their learning, but it wasn't obvious a year ago.\u201d The first 36 of the new MOOCs were developed last year by various partner institutions and offered through FutureLearn, a wholly owned subsidiary of the Open University. The catalogue has expanded greatly since then, and now ranges from Introduction to Forensic Science to England in the Time of King Richard III. The MOOCs enable discussions on every single piece of content, allowing users to 'like' comments or follow those posted by particular classmates, as in a standard social network, and even letting students assess each other's work. The FutureLearn software is designed to work on tablets and mobile phones, as well as desktop or laptop computers. And the courses often include strong storytelling elements \u2014 a prime example being the forensic-science course, which was developed by the University of Strathclyde in Glasgow, UK, and which leads students through the material using an unfolding plot about a murder scene. FutureLearn now has 40 partners, 10 of them outside the United Kingdom. Data on its early courses show that some 22% of students who start a FutureLearn MOOC complete the majority of steps and all assessments. This figure drops to 12% when the count includes all the students who enrol in a course but never start, but it still compares favourably to other MOOCs, which average less than a 7% completion rate. (Detailed comparisons are difficult, because each MOOC provider has a different definition of 'completion'.) FutureLearn's MOOCs also get high marks from outsiders such as Sally Mapstone, pro-vice-chancellor for education at the University of Oxford, UK. Although Oxford has elected not to join a MOOC platform \u2014 and Mapstone has doubts about such courses' potential to revolutionize education \u2014 she says she does admire FutureLearn's \u201csimple and attractive\u201d approach. In many ways, FutureLearn is still trailing the first wave of US MOOCs (see  Nature   495 , 160\u2013163; 2013 ). It has more than 500,000 registered users and 130 courses \u2014 whereas leading MOOC company Coursera, founded in April 2012 by computer scientists at Stanford University in California, has almost 10 million registered users and more than 400 courses. Anant Agarwal, chief executive of edX, a MOOC provider in Cambridge, Massachusetts, that has around 3 million users, says that FutureLearn's approach is creative. But his platform too is \u201cevolving at a torrid pace\u201d, he says, using student feedback to improve how discussion forums and cohorts work. \u201cWe need to experiment a whole lot more with hundreds of courses and millions of users before generalizing\u201d about what works best for the students, says Agarwal. And Sharples, for one, is eager to do just that. \n               SOUTH AFRICA: The inclusive university \n             \n               By Linda Nordling \n             During most of South Africa's apartheid era of strict racial segregation, the country's leading universities catered mostly to the white elite. Shortly before the apartheid system was dismantled in the early 1990s, however, the University of Cape Town (UCT) joined with a number of other South African universities in reaching out to impoverished students \u2014 the vast majority of whom were black. The general idea behind the UCT's programme has been to help students from disadvantaged backgrounds to acquire the skills that their wealthier contemporaries take for granted. It provides support including language-development courses for those whose first language is not English, instruction in good study habits and even psychological counselling. It also includes group sessions that let students discuss challenges ranging from how to manage their personal finances to ways to cope with stress. For science students, the UCT offers foundation courses in biology, physics, chemistry and mathematics to patch any knowledge gaps. A winter science programme runs trips to Cape Town's aquarium and nearby fossil parks, and provides other science-related experiences that students may have missed while growing up. To make time for these extra activities, the UCT's Bachelor of Science programme gives students the option of stretching the normal three-year undergraduate curriculum to four years. Since they were introduced in 1986, the UCT's four-year undergraduate courses have trained more than 2,000 students. Mokete Koago was one: he enrolled in what was then known as General Entry to Programmes in Science (GEPS) when he came to the UCT in 2008. A bright student from a poor township in South Africa's rural Free State province, Koago found the extra time, tutoring and mentoring essential. \u201cI don't think I would have made it through my degree without GEPS,\u201d he says. The programme is still evolving. Until last year, for example, undergraduates on science courses were channelled into three- or four-year streams as soon as they enrolled. Now, all students start in the same course. Only after six weeks do they choose whether to stay on the three-year track or opt for the four-year Extended Degree Programme. The idea, says David Gammon, a UCT chemist who serves as a senior advisor for the extended science programmes, is to let students' paths at university be determined by their performance rather than where they went to school or the colour of their skin. This approach also means that students are actively involved in choosing their own paths \u2014 an important consideration given that there could be a stigma attached to joining the longer course. Transformation is proving slow. A report on undergraduate-curriculum reform published by South Africa's Council on Higher Education in 2013 found that, although the fraction of the country's black 20\u201324 year olds attending university has risen slightly, from 10% in 2005 to 14% in 2011, it is still dwarfed by the figure for white people: 57%. And of those black students who do make it to university, only one in five completed their undergraduate degrees within four years, as opposed to 44% of white students. Still, there have been many individual successes. During Koago's four years at UCT, for example, he discovered a passion for meteorology, climate and ocean science \u2014 an unexpected love for a boy who had grown up in the dusty interior of South Africa. \u201cWhen my parents came down for my graduation, it was the first time in their lives that they saw the sea,\u201d he says. He is now a research assistant in the UCT's Climate Systems Analysis Group, and he hopes to embark on a master's degree in oceanography next year. Eventually, Koago hopes to bring his passion for science home \u2014 and perhaps to inspire other young people to follow in his footsteps. \u201cI want to bridge the gap between people living in townships and the science,\u201d he says. \u201cThe biggest problem out there is that people are ill-informed.\u201d \n                     Higher education: The university experiment 2014-Oct-15 \n                   \n                     Developing world: Discuss inequality 2014-Sep-16 \n                   \n                     Online education: MOOCs taken by educated few 2013-Nov-20 \n                   \n                     Education online: The virtual lab 2013-Jul-17 \n                   \n                     Online learning: How to make a MOOC 2013-Jul-17 \n                   \n                     South Korea\u2019s president-elect promises science boost 2012-Dec-22 \n                   \n                     Education: Africa\u2019s counting house 2012-Nov-07 \n                   \n                     Nature  special: The university experiment \n                   \n                     Nature  special: Africa \n                   \n                     Nature  special: Learning in a digital age \n                   \n                     Blog post: Suicides at KAIST \n                   \n                     Blog post: Harvard, MIT launch online education venture \n                   \n                     Technical University Munich \n                   \n                     KAIST \n                   \n                     FutureLearn \n                   \n                     The Open University \n                   \n                     UCT Centre for Higher Education Development \n                   Reprints and Permissions"},
{"file_id": "516162a", "url": "https://www.nature.com/articles/516162a", "year": 2014, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Scientists have been reprogramming adult cells into embryonic ones for decades \u2014 but they are only now getting to grips with the mechanics. Eggs and sperm do it when they combine to make an embryo. John Gurdon did it in the 1960s, when he used intestinal cells from tadpoles to generate genetically identical frogs. Ian Wilmut did it too, when he used an adult mammalian cell to make Dolly the sheep in 1996. Reprogramming \u2014 reverting differentiated cells back to an embryonic state, with the extraordinary ability to create all the cells in the body \u2014 has been going on for a very long time. Scientific interest in reprogramming rocketed after 2006, when scientists showed that adult mouse cells could be reprogrammed by the introduction of just four genes, creating what they called induced pluripotent stem (iPS) cells 1 . The method was simple enough for almost any lab to attempt, and now it accounts for more than a thousand papers per year. The hope is that pluripotent cells could be used to repair damaged or diseased tissue \u2014 something that moved closer to reality this year, when retinal cells derived from iPS cells were transplanted into a woman with eye disease, marking the first time that reprogrammed cells were transplanted into humans (see  Nature   http://doi.org/xhz ; 2004 ). There is just one hitch. No one, not even the dozen or so groups of scientists who intensively study reprogramming, knows how it happens. They understand that differentiated cells go in, and pluripotent cells come out the other end, but what happens in between is one of biology's impenetrable black boxes. \u201cWe're throwing everything we've got at it,\u201d says molecular biologist Knut Woltjen of the Center for iPS Cell Research and Application at Kyoto University in Japan. \u201cIt's still a really confusing process. It's very complicated, what we're doing.\u201d One of the problems, stem-cell biologists say, is that their starting population contains a mix of cells, each in a slightly different molecular state. And the process for making iPS cells is currently inefficient and variable: only a tiny fraction end up fully reprogrammed and even these may differ from one another in subtle but important ways. What is more, the path to reprogramming may vary depending on the conditions under which cells are being grown, and from one lab to the next. This makes it difficult to compare experimental results, and it raises safety concerns should a mix of poorly characterized cells be used in the clinic. But new techniques are starting to clarify the picture. By carrying out meticulous analyses of single cells and amassing reams of detailed molecular data, biologists are identifying a number of essential events that take place en route to a reprogrammed state. This week, the biggest such project \u2014 an international collaboration audaciously called Project Grandiose \u2014 unveiled its results 2 , 3 , 4 , 5 , 6 . The scientists involved used a battery of tests to take fine-scale snapshots of every stage of reprogramming \u2014 and in the process, revealed an alternative state of pluripotency. \u201cIt was the first high-resolution analysis of change in cell state over time,\u201d says Andras Nagy, a stem-cell biologist at Mount Sinai Hospital in Toronto, Canada, who led the project. \u201cI'm not shy about saying grandiose.\u201d But there is more to do if scientists want to control the process well enough to generate therapeutic cells with ease. \u201cYes, we can make iPS cells and yes we can differentiate them, but I think we feel that we do not control them enough\u201d says Jacob Hanna, a stem-cell biologist at the Weizmann Institute of Science in Rehovot, Israel. \u201cControlling cell behaviour at will is very cool. And the way to do it is to understand their molecular biology with great detail.\u201d \n               Nuclear transfer \n             When Gurdon and Wilmut reprogrammed frog and sheep cells, respectively, they did it by transferring a differentiated nucleus into an egg stripped of its own DNA. Scientists knew that something in the egg was able to reprogram the nucleus, such that the genes associated with being a skin cell, for example, were switched off and those associated with pluripotency were switched on and triggered a cascade of downstream events. In the following decade, researchers found various new ways to reprogram \u2014 adding nuclei to fertilized eggs and to embryonic stem cells \u2014 but these methods did little to clarify what it was in the cells that did the reprogramming and how the process worked. That changed when Shinya Yamanaka and Kazutoshi Takahashi at Kyoto University made iPS cells 1 . They showed that just four proteins that are usually expressed in early embryos or in embryonic stem cells could reprogram an adult cell \u2014 and, crucially, they also provided a tool that researchers could use to study reprogramming in a culture dish, something they have been doing ever since. Stem-cell biologists now know that after introducing these proteins \u2014 sometimes known as the Yamanaka factors \u2014 there is a flurry of intense and mostly predictable gene expression. But then, after a few days, the cells enter a mysterious state in which they are dividing but stalled, failing to reprogram further. After a week or so, a slim few \u2014 only one in a thousand \u2014 become true pluripotent cells 7 . This process is unpredictable, in the sense that it is impossible to know at the beginning which cells will reprogram, and it takes them a long time. But it is predictable in some ways. \u201cResearchers doing it in Germany, Japan and the US will all get the iPS cells about the same time and at about the same rate,\u201d says Alexander Meissner at Harvard University in Cambridge, Massachusetts. \u201cThe one thing we know is that it's not magic, there is a mechanism. That's good news \u2014 we should be able to find it.\u201d And yet, Meissner says, it is \u201calmost disappointing\u201d how little progress there is from year to year. From the cell's point of view, it is an immense task to overcome a fully differentiated state, which is like being in biological lock-down. Take fibroblasts, for example, the connective-tissue cells that scientists often extract from skin and try to reprogram. In the long process by which they gained their identity, these cells' DNA has been stamped with 'epigenetic' markers, chemical modifications such as the addition of methyl groups or changes to the histone proteins that package up DNA. These ensure that only genes relevant for a fibroblast are expressed. It wouldn't do for a skin cell to suddenly behave like a dividing stem cell, because that can be the route to diseases such as cancer. Scientists now have a good grip on what happens during the first 48 hours as the four Yamanaka factors, with brute force, kick cells out of this state. In embryonic stem cells, these proteins activate genes in a 'pluripotency network' that keeps cells proliferating indefinitely. But the factors act differently when shoved into a differentiated cell such as a fibroblast. When cell biologist Ken Zaret at the University of Pennsylvania in Philadelphia mapped the location of these factors during the first two days of reprogramming in human fibroblasts, he found that they were \u201cphysically blocked\u201d from reaching their usual target genes by the conformation of the chromosomes 8 . Instead, the proteins head for accessible areas of the chromosomes. Sometimes, they activate genes that force the cell to commit suicide; in others, they bind to distant control regions called enhancers that encourage the activation of genes known to be involved in the reprogramming process. Rudolf Jaenisch, a stem-cell scientist at the Massachusetts Institute of Technology in Cambridge, has labelled this widespread binding of the Yamanaka factors as \u201cpromiscuous\u201d 9 . Other studies have illuminated the sweeping changes that take place on chromosomes during this early phase. In a study published in 2011, Meissner's group showed that a type of histone modification that boosts gene expression, called H3K4me2, changes at more than 1,000 positions in the genome of these cells: it was added at many sites on pluripotency genes, and dropped from sites where genes specific for fibroblasts reside 10 . At the same time, the cells look and behave differently: they compact and move around less. \u201cOur early thought was that the factors create complete chaos,\u201d says Meissner. \u201cBut this first step is predictable and consistent across all cell types.\u201d Now he can almost foretell for a given cell type \u201cwhich sites might become open to active transcription, which might be modified, and which will stay silent\u201d, he says. \u201cThat part you can predict. But that doesn't answer the question of what happens next.\u201d The week-long lag that follows flummoxes scientists. The cells soldier on, and some express new genes, but not in a predictable or comprehensible way. Even the H3K4me2 modifications mapped by Meissner do not seem to boost gene expression until much later in the process. \u201cMost cells reach a partially reprogrammed state. Some get beyond that, and we're not sure why,\u201d says Meissner. \u201cThat is the black box.\u201d If a cell starts to pump out Sox-2 protein, however, that is a really good sign that it is progressing. \u201cOnce Sox-2 comes on, everything falls in line,\u201d says Jaenisch, who studied the activity of nearly 50 genes in individual cells as they went through reprogramming 11 . Within a few days, the production of this and other transcription factors necessary for pluripotency all ramp up. But why does all this take so long, and why is it so rare? \u201cWe don't understand why it can't be faster,\u201d says Woltjen. He suggests that a cell might need to go through several divisions, each taking at least half a day, to reshape its epigenetic state. \u201cPerhaps that's one limiting factor,\u201d he says. Yamanaka offers several possible explanations for the low conversion rate. One is that the starting cell population is a rainbow of cell types. The chunk of tissue used to derive fibroblasts, for example, probably contained a mix of subtly different cell types; even those that are fibroblasts will differ slightly in the blend of proteins and other molecules they contain. Furthermore, cells growing in culture are constantly shuttling back and forth between different states. This means that the introduced reprogramming factors will affect each cell differently. \u201cWhat works for one subset of the population will not work for others,\u201d Yamanaka says. Minor differences in cell culture and the relationship with neighbouring cells also make it difficult to control all the variables and command the cells like an obedient army, he adds. \u201cA perfect implementation is impossible.\u201d Researchers are now trying to classify some of the cell types that come out of the black box, and are tinkering with reprogramming techniques to see if they can pin down how and where they diverge. Woltjen, for example, has shown that the ratio of the different reprogramming factors affects the type of cells produced. One set of conditions has a high success rate, but the resulting cells end up in a partially reprogrammed, unstable state; another has a low efficiency but produces mainly high-quality iPS cells. Project Grandiose has also supported the idea that variability in the reprogramming process is producing fundamentally different cells. The project, launched in 2010 by some 30 senior scientists at 8 research institutes, was motivated by Nagy's desire to open up the black box. \u201cI wanted to find out what was in it,\u201d he says. After triggering reprogramming with the Yamanaka factors, the team collected 100 million cells per day for a month, and then regularly analysed their production of protein and RNA, their changing methylation state and more. The methylation analyses alone produced so much data that collaborators resorted to sharing it on terabyte hard drives that they FedEx-ed around the world. The size of the undertaking also inspired the project's title, Nagy says. \u201cThe name just came out of my head when I was considering how much data was being collected,\u201d he says. \n               A class of its own \n             The headline finding is the new category of pluripotent cell, called F-class cells after the fuzzy appearance of the cell colonies. These cells were produced with a small tweak to the iPS-cell recipe: instead of stopping expression of the reprogramming factors after a few days, the researchers continued to supply them. \u201cThat leads to a bifurcation,\u201d says Nagy. F-class cells are different from iPS cells because they fail one of the most stringent tests of pluripotency: when injected into mouse embryos they cannot contribute to tissues in the resulting chimaeric mice. For this reason, some critics say that F-class cells could be what other scientists have been calling 'partially reprogrammed' cells. But Nagy says that cells do not have to contribute to chimaeras to be considered pluripotent, and points to the cells' other characteristics of pluripotency: for example, they form what is known as a teratoma, which contains a range of differentiated cell types. Nagy says that others have overlooked the F-class state because they were only looking for cells that were similar to embryonic stem cells, whereas his team was \u201cunbiased by expectation of what pluripotency should look like\u201d. He thinks that there are more states of pluripotency to be found, and his group will be looking for them in its hard drives. \u201cIt's a conceptually important thing, it opens up a big door,\u201d he says. All these studies are adding fuel to a central debate in the reprogramming community: does the process have an inherently random and unpredictable element to it? Until recently, there was a general consensus that this was true. According to this 'stochastic' model, as the reprogramming factors trigger cascades of molecules, some cells will drift into a reprogrammed state and some will not, and which way they go cannot be predicted. But some studies, including one by Hanna 12  show that the reprogramming method can be tweaked to make the process more efficient \u2014 suggesting that the randomness can be controlled or even eliminated. These studies imply that reprogramming can be switched from a stochastic process to a deterministic one, in which one step inevitably follows the next to a new cell state. Many scientists now say that reprogramming involves both deterministic phases \u2014 at the start and end \u2014 and a stochastic phase, which is the mysterious week in the middle. Hanna plays down the debate altogether, seeing little contradiction between the two sides. \u201cI do not believe there is a stochastic versus deterministic camp.\u201d He compares reprogramming to flipping a coin: each flip will have a random outcome, but after 100 flips, close to 50% of them will have come up heads. Similarly, whether a given cell flips into a reprogrammed state might be random. But over time, a reprogramming method should produce a certain percentage \u2014 maybe 10% \u2014 of pluripotent cells every time. Further experiments might resolve the debate, says Zaret, by pinpointing the events that snap the cells out of their week-long lethargy. For Zaret, the reprogramming debate offers a window on a bigger concept: how order in biology arises from randomness. \u201cCellular systems are built upon intrinsic noise and stochastic events that somehow elicit cell fates that are locked down and do not switch back and forth,\u201d he says. This question is at the basis of cell type control, he says, and draws him to the research. For others, like Yamanaka, the incentive to open the black box is a practical one. More-efficient reprogramming makes for better experiments and a more reliable source of cells that can eventually be used in human medicine. \u201cThe motivation of my research is to treat patients,\u201d he says. \u201cAnything that helps push iPS cells into the clinic excites me.\u201d \n                     Japanese woman is first recipient of next-generation stem cells 2014-Sep-12 \n                   \n                     Research integrity: Cell-induced stress 2014-Jul-03 \n                   \n                     Cell rewind wins medicine Nobel 2012-Oct-08 \n                   \n                     Nature Special: Reprogramming \n                   \n                     Nature collection: Route to reprogramming \n                   \n                     Andras Nagy lab \n                   Reprints and Permissions"},
{"file_id": "509274a", "url": "https://www.nature.com/articles/509274a", "year": 2014, "authors": [{"name": "Linda Nordling"}], "parsed_as_year": "2006_or_before", "body": "A wave of anti-gay laws and homophobia in Africa is hampering efforts to study and curb the spread of HIV. On the morning of Saturday 12 April, ten police officers raided Maaygo, a men's health and HIV/AIDS advocacy organization in a residential area of Kisumu in western Kenya. Staff watched helplessly as the officers confiscated information leaflets and even the model penis used in condom demonstrations. The police arrested the organization's director and finance officer, as well as one of its members, for \u201cillegally practising sexual orientation information\u201d. The detainees were released later that day after Daniel Onyango, director of a local homosexual-rights group, arrived at the police station and explained that it was not actually a crime to distribute information on sexual orientation. Maaygo will continue its operations \u2014 albeit from a less conspicuous location in Kisumu. An HIV treatment and research project in Uganda was not so lucky. On 3 April, the Makerere University Walter Reed Project in Kampala suspended its operations indefinitely after a staff member was arrested on charges of recruiting homosexuals and carrying out 'unethical research'. Stories such as these are becoming increasingly common across Africa, where vocal protests against homosexuality are on the rise. Many countries, including Ethiopia, Nigeria and Senegal, have stringent anti-homosexuality laws. In February, Uganda toughened its stance, passing harsh new measures that hand down life sentences to people convicted of having gay sex and that stipulate up to seven years in jail for actively supporting the rights of gay people. Antipathy towards homosexuality has hampered efforts to curb HIV in these countries. The Joint United Nations Programme on HIV/AIDS (UNAIDS) has identified men who have sex with men (MSM) as a key risk group for HIV infection, but because of cultural prejudices, gay people in Africa are often unable to access information on how to protect themselves from HIV, and those who become infected are often denied treatment. Homophobia and criminalization are also impeding research on MSM and HIV transmission. \u201cThere are several examples where research has been stopped or slowed based on these laws,\u201d says Stefan Baral, an epidemiologist and physician at Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland. He has seen the problem at first hand, having conducted research with MSM in several African countries over the past decade. \u201cWhat you end up with then is a data paradox, where you know the least in the places with the most stigma,\u201d he says. Researchers and clinicians say that there are a few small signs of hope. In Kenya, for example, one clinic has managed to use education to curb anti-gay sentiments, providing a model that might be successful elsewhere. But that relative stability could easily crumble with changes in the local community or in the country's leadership. \n               Forbidden research \n             The tide of homophobia has hit particularly hard in Uganda, says Paul Semugoma, a gay physician and researcher from that country who left two years ago and now lives in exile in South Africa. \u201cUganda is the worst, it's a witch-hunt,\u201d he says. A research project was supposed to start there this year to identify groups at risk of HIV, but it was suspended because of concerns for the safety of the researchers and participants, he says. When it comes to MSM, he adds, \u201cwhat's going to happen is that there's not going to be any up-to-date information on this risk group\u201d. Similar problems are plaguing research in Ethiopia, where same-sex encounters are punishable by up to 15 years in prison. Researchers are kept from studying MSM and HIV by the Ethiopian Public Health Institute, which must approve medical research in the country. A programme run by the US Centers for Disease Control and Prevention and the Ethiopian Public Health Association managed to pass the screening process in 2011 because it used terms such as 'most at-risk populations' rather than MSM or gay, says an Ethiopian advocate for gay and transgender health and human rights, who lives in exile in the United States and asked not to be named because of concerns about the safety of his family and friends. Once the government found out that the project would target MSM and related groups, the research was stopped, he says. The problem is not limited to countries where homosexuality is a crime. \u201cIn many countries in sub-Saharan Africa, we just cannot do research on MSM-related topics,\u201d says Lung Vu, an HIV and tuberculosis research adviser at Population Services International, a global-health organization in Washington DC. \u201cGovernment officials and religious leaders just don't allow for this to happen.\u201d This is detrimental, he says, because data on MSM are needed to understand and combat HIV in Africa, where there is an epidemic of the disease. In an analysis 1  last year, Vu and his colleagues found that the prevalence of HIV among MSM in three large Nigerian cities was between four and ten times that in the general population. Scraps of data from Senegal and other countries paint the same picture. Because there is so little information on MSM in Africa, researchers are only now starting to appreciate how much that population and other sexual minorities are spurring the spread of HIV on the continent, says Kent Klindera, director of an initiative at amfAR, the Foundation for AIDS Research in New York, that promotes HIV research and prevention for MSM and transgender individuals. Funding problems have also limited research in this area, says a 2013 amfAR report 2 . Of the US$1.5 billion allocated to six African countries (Botswana, Malawi, Namibia, Swaziland, Zambia and Zimbabwe) by the Global Fund to fight AIDS, Tuberculosis and Malaria since 2001, only 0.07% went to research concerning MSM and transgender people. Four of the countries reported no dedicated MSM projects whatsoever. Despite the problems, researchers in Africa point to a few bright spots. For example, Mtwapa, a coastal town north of Mombasa, Kenya, managed to calm a volatile situation through community engagement and education about how the research can help society at large. The trouble at Mtwapa centred on an HIV clinic run by the Kenyan Medical Research Institute (KEMRI), which conducted risk-group studies at the facility. On 12 February 2010, a mob of several hundred people charged the clinic, incited by two religious leaders \u2014 a Christian bishop and a Muslim imam. The riot was based on misinformation. \u201cIt started with a rumour that two gay men were getting married in the town,\u201d says Eduard Sanders, an epidemiologist with the University of Oxford, UK, who has studied MSM in Mtwapa since 2005, and who witnessed the riot. \u201cBut when the mob couldn't find any hint of the wedding, it descended on the clinic because of its well-known research on MSM.\u201d Armed with sticks, stones and other weapons, the crowd surrounded the clinic, demanding that the gay men come out. Police arrested people accused of being gay \u2014 possibly as a way of saving them from mob justice \u2014 and later released them. One KEMRI volunteer was severely beaten, according to the international group Human Rights Watch. \n               Attitude adjustment \n             Today, the clinic is safer, says Sanders, thanks to a campaign to inform local residents about its role in managing HIV in the area. As part of this effort, KEMRI hired community-liaison officer Evanson Gichuru, who met and interviewed local leaders and the people who organized the attack. Most of the antipathy, he observed, came down to misconceptions about gay people, such as the idea that they groom young boys to become prostitutes. Gichuru's meetings, combined with a media campaign and health-worker training on MSM sensitivities, have brought a turnaround in attitudes. There have been no further attacks on the clinic, and research conducted after health-worker training found 3  that it significantly reduced homophobic tendencies, particularly among those who had previously scored a high rating on a homophobia scale. An important factor in changing attitudes was teaching people that the health of the wider community in Kenya depends on understanding and treating HIV among MSM, says Gichuru. Many men who have sex with men in Kenya also have sex with women, so a high HIV incidence in this group puts society in general at risk. But neither Sanders nor Gichuru wants to overstate the success in Mtwapa. \u201cI don't want to be overconfident,\u201d says Sanders. There is still a big stigma to being gay in Kenya, he adds. And the techniques used to raise awareness there are not likely to work in Uganda, says Semugoma. \u201cIn Uganda the homophobia is not only from the people, it's also coming from the state,\u201d he says. Researchers point to Malawi as another example of positive developments. A few years ago, the Centre for the Development of People (CEDEP), a human-rights organization that supports minorities including MSM, had to scale down its activities after health workers were arrested. But in 2012, partly thanks to CEDEP's advocacy, Malawian President Joyce Banda suspended the country's laws criminalizing homosexuality. The arrests have stopped and CEDEP now has five offices across Malawi. The raid on Maaygo's office in Kenya last month worried many physicians and researchers, but it also provided an opportunity. In subsequent meetings with local authorities and the police, people from the organization and other human-rights groups discussed how HIV treatment and support for MSM are needed to fight the high HIV infection rates in Kisumu, says Onyango, who attended the first such meeting. \u201cCurrently all is well. We have not had any further incidents,\u201d he says. \u201cMaaygo are still doing their activities, although at a slow pace so that we can sensitize the community.\u201d \n                     AIDS prevention: Africa's circumcision challenge 2013-Nov-13 \n                   \n                     Cuts hamper bid to tackle AIDS 2012-Mar-06 \n                   \n                     African nations vow to support science 2010-Jun-23 \n                   \n                     Maaygo on Facebook \n                   \n                     Makerere University Walter Reed Project \n                   \n                     amfAR \n                   \n                     UNAIDS \n                   Reprints and Permissions"},
{"file_id": "511278a", "url": "https://www.nature.com/articles/511278a", "year": 2014, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "After two decades and more than half a billion dollars, LIGO, the world's largest gravitational-wave observatory, is on the verge of a detection. Maybe. In the Louisiana swamps just east of Baton Rouge, the daily hunt for gravitational waves cannot really get started until well after noon. Mornings are a lost cause, thanks to the sonic chaos from traffic rumbling along the nearby interstate highway, trains roaring past and loggers occasionally unleashing their chainsaws on plantations of pine trees. Even now, at 6 p.m. on a weekday evening in May, Ryan de Rosa is gazing with resignation at a set of computer monitors in the control room of the Laser Interferometer Gravitational-Wave Observatory (LIGO). The displays are starting to stabilize, but they still show the myriad jolts \u2014 imperceptible to humans \u2014 that are rocking the ground. The traces, generated by distant earthquakes, traffic and even waves breaking on the coast of the Gulf of Mexico more than 100 kilometres away, look like jagged mountain peaks. De Rosa, a physicist at Louisiana State University in Baton Rouge, knows he has a long night ahead of him. He and half a dozen other scientists and engineers are trying to achieve 'full lock' on a major upgrade to the detector \u2014 to gain complete control over the infrared laser beams that race up and down two 4-kilometre tunnels at the heart of the facility. By precisely controlling the path of the lasers and measuring their journey in exquisite detail, the LIGO team hopes to observe the distinctive oscillations produced by a passing gravitational wave: a subtle ripple in space-time predicted nearly a century ago by Albert Einstein, but never observed directly. Within weeks of this May evening, de Rosa and his colleagues will finally achieve full lock. A team working on an identical LIGO detector at the Hanford nuclear complex in Washington state should get there within months. If all goes well, the dual devices \u2014 which have together cost some US$620 million \u2014 could resume taking data next year. They will be the most sensitive of several gravitational-wave detectors around the world that are racing to be the first to claim a discovery. The anticipation and competition are intense. Finding direct evidence of gravitational waves would launch a new era of astronomy. Spotting not just one gravitational-wave source, but eventually dozens and then thousands, astronomers say, will give them new ways to watch black holes collide, stars annihilate themselves and space-time shimmy. Gravitational waves would thus open an entirely new window onto a dynamic, ever-changing universe. There is just one problem. The first incarnation of LIGO hunted the waves for nearly a decade \u2014 and found none. Now, with the major upgrade, the project faces the hard reality of having to finally deliver on its promises. \n               Everywhere and nowhere \n             In theory, Earth should be awash in gravitational waves. They are thought to come from any cosmic event that disturbs the fabric of space and time with sufficient force, in much the same way that seismic waves radiate from an earthquake. A dying star that explodes as a supernova should produce a tsunami of gravitational waves. More-rhythmic waves might come from the rotation of a dense object that is not quite perfectly symmetrical \u2014 say, a furiously spinning neutron star with a small bulge in its side. Another source might be a pair of black holes or neutron stars that whirl around one another, gradually drawing closer until they collide in a final, catastrophic merger. That last example is not hypothetical: in 1974, using the Arecibo radio telescope in Puerto Rico, physicist Joseph Taylor at the University of Massachusetts Amherst and his then-graduate student Russell Hulse discovered just such a neutron-star binary. Over the next few years, Taylor and Hulse watched the timing of radio flashes from one of the spinning stars change ever so slightly as the pair spiralled closer. The shifts matched Einstein's prediction of how gravitational waves would carry energy away from an imminent stellar smash (R. A. Hulse and J. H. Taylor  Astrophys. J.   195 , L51\u2013L53; 1975 ). It was the first indirect detection of gravitational waves, and it netted Hulse and Taylor the 1993 Nobel Prize in Physics. The first attempt to observe gravitational waves directly had come in the early 1960s, when Joseph Weber of the University of Maryland in College Park tried unsuccessfully to observe vibrations caused by gravitational waves passing through an aluminium cylinder. Then, in the late 1960s, physicist Rainer Weiss proposed using lasers rather than a metal bar. The concept involves splitting a laser beam into two using an elaborate maze of mirrors, and sending them down two tunnels that are set at right angles to one another, and back again. The set-up takes advantage of the polarized nature of gravitational waves: when they pass through an object \u2014 in this case, the tunnels \u2014 they cause it to expand ever so slightly in one direction and contract in the perpendicular direction. Weiss, of the Massachusetts Institute of Technology in Cambridge, suggested it would be possible to detect that kind of warping by re-combining the separated laser beams and using interferometry to look for tiny shifts in the way they interact (see 'To catch a wave'). In 1992, after decades of planning, replanning and prototyping, the US National Science Foundation (NSF) committed to spending $272 million ($420 million in 2008 dollars) on building such an interferometer, now called LIGO. The plan called for two identical detectors separated by thousands of kilometres, so that the observatory could cross-check its own results: sites in Washington and Livingston, Louisiana, were chosen. What the plan did not call for was a gravitational-wave discovery \u2014 at least not any time soon. \u201cWe had this careful choice of words and a story about what we were going to do,\u201d says Barry Barish, a physicist at the California Institute of Technology (Caltech) in Pasadena, who helped to make the case to the NSF and became LIGO's principal investigator in 1994. First there would be the initial LIGO, which would develop and demonstrate the technology, with any discovery coming as a bonus. And then would come a second stage \u2014 Advanced LIGO, which would require a separate go-ahead from the NSF, and would increase the sensitivity by an order of magnitude. \u201cWe said that with initial LIGO, detections would be possible,\u201d says Barish, \u201cand with Advanced LIGO, detections would be probable.\u201d The problem was that estimates of what LIGO would see were still very uncertain. \u201cWhen we initially proposed LIGO, the only sources that we were really contemplating were supernovae,\u201d says Weiss. \u201cWe thought we would see something like one a year, maybe even ten a year.\u201d But then improved computer simulations radically downsized the amount of gravitational-wave energy that would be expected from such explosions. A supernova would have to go off very close to Earth for LIGO to see anything from it. Other calculations cut back on how often LIGO would be expected to see gravitational waves from lone wobbly neutron stars. \u201cThere was an optimism about sources that turned out not to have been justified,\u201d says Cole Miller, a theoretical astrophysicist at the University of Maryland who chaired LIGO's external science advisory panel until last year. But by the time the observatory got the go-ahead, the LIGO scientists were growing more optimistic about pairs of neutron stars. They realized that when these stars collided they would send out a clean, easily detectable gravitational-wave signal right in the frequency range where LIGO was most sensitive. Even at its relatively low initial sensitivity, the observatory could have detected two neutron stars merging anywhere within 20 megaparsecs (65 million light years) of Earth. Yet it was still a long shot, says David Reitze, executive director of the LIGO Laboratory, who is based at Caltech: \u201cWe would have had to have gotten lucky.\u201d They were not. During the first phase of LIGO, from 2002 to 2010, Hanford and Livingston saw nothing. Still, the NSF was satisfied enough with LIGO's progress that it allocated another $205 million for Advanced LIGO in 2008. The upgrade will slowly increase the sensitivity of the detectors by a factor of ten, so that Advanced LIGO will be able to see neutron-star mergers not at 20 megaparsecs, but at 150 or even 200. That will multiply the volume of space that LIGO can search by 1,000, and will vastly improve the chance that the detector will spot one of the rare events that produce a gravitational wave. Current best estimates of neutron-star merger rates suggest that with any luck \u2014 assuming that neutron stars don't collide at the absolute lowest end of the probability range, and do go off within the search volume during the observation period \u2014 Advanced LIGO will see several of them per year once it reaches its design sensitivity. \u201cThe real question is not whether we're going to detect gravitational waves, but will they come frequently or will they come rather rarely,\u201d says Stanley Whitcomb, a longtime LIGO physicist at Caltech who serves as the project's chief scientist. \n               Noisy neighbours \n             But first, the LIGO team has to finish building the advanced system. In 2011, engineers began ripping components out of the tunnels at the Livingston and Hanford sites to replace them with much more elaborate versions. LIGO's performance is determined by how accurately it can measure distortions created by a passing gravitational wave in the length of the interferometer's 4-kilometre arms. In its initial configuration, the observatory was able to measure those distortions to about one part in 10 21  \u2014 equivalent to a shift of about one-thousandth the diameter of a proton. To improve the sensitivity by a factor of ten, Advanced LIGO's designers have made a number of major changes, starting with better ways to isolate the machine from random ground-shaking. Seismic noise is a problem particularly at Livingston, where the detector sits just a few kilometres from a major interstate highway and a railway line. Surveys as far back as 1988 had warned about noise there, but the problem did not seem insurmountable. And Louisiana senator Bennett Johnson (Democrat), who was on the panel that appropriated money for the NSF, helped to push the project through. Livingston did have some practical advantages, including few earthquakes, lots of flat land and proximity to an established group of gravitational physicists at Louisiana State University. Planners thought that they could compensate for the noise with a range of devices to dampen ground motion. They couldn't, at least at first. When trains blasted by during the earliest science runs, the interferometer shook so much that it was knocked offline. Even worse was the local logging. Brian O'Reilly, a senior scientist at the Livingston lab, calls it \u201cthe constant bane of our existence\u201d. He waves his hand in frustration out of the window of his office, towards a plot of land just off the LIGO property that was clear-cut during early detector operations. \u201cIt wasn't like we could say, 'Please stop your multimillion-dollar industrial effort so we can detect gravitational waves.'\u201d But the logging is a problem only occasionally, and over time LIGO engineers have fine-tuned the system to withstand passing trains. Looking like a proud parent, O'Reilly uses a scale model of Advanced LIGO to point out a host of obsessive changes made to the noise-isolation system. In each of the arms, the mirrors that reflect the laser beam hang from glass cylinders, which in turn hang from metal plates that hang from yet other plates. Each layer of suspension provides another opportunity to dampen unwanted vibrations. Amid all the glass and metal, triangular steel blades serve as extra protective isolators, delicately balancing the weight of three-quarters of a tonne of engineering equipment. Advanced LIGO also incorporates more-powerful lasers, plus a set of recycling cavities that essentially trick the detector into thinking that there are more photons in it than there are, boosting sensitivity. (There is an upper limit to how much light can actually be pumped into LIGO, because the more photons there are, the more they contribute to a white-noise-like effect at high frequencies that ruins the signal.) Although the system looks perfect in the scale model, the actual project has run into construction difficulties. At Hanford, the material that coats the hanging glass mirrors showed some unexpected deterioration, so two of them are being replaced. At Livingston, mud-dauber wasps made nests in the insulation surrounding the beam tube, where their chlorine-rich excretions \u2014 which in part came from eating poisonous black-widow spiders \u2014 caused a leak in the vacuum system. The leak has been fixed and the wasps cleared out. Even so, as of the night of 29\u201330 June the Livingston detector has managed to achieve full lock for more than two hours at a time, pulling off an official milestone months earlier than expected. If commissioning continues to go relatively smoothly, plans call for the first Advanced LIGO observing run to start in late 2015. A second run, with a decent shot of finding a gravitational wave, would occur in the winter of 2016\u201317. (Weiss likes to point out that a 2016 discovery would be a nice 100th-anniversary commemoration of Einstein's paper describing gravitational waves.) By the third science run, planned for 2017\u201318, the machine should be getting sensitive enough to almost certainly nail a detection, says Reitze. This schedule, however, depends heavily on how quickly engineers can commission both interferometers. The team has decided to focus its energies on commissioning the detector at the relatively low frequencies where signals from binary neutron stars are thought to lurk. They will not worry so much about improving LIGO's performance at high frequencies, to snag other types of signals such as colliding black holes, unless they have their first gravitational waves in the bag. \n               Global competition \n             There are other groups out there seeking gravitational waves, and they just might beat LIGO to the punch. Like light, gravitational waves come in a huge variety of wavelengths \u2014 and just as radio telescopes and X-ray telescopes reveal different phenomena, so too should gravitational-wave detectors working at different wavelength ranges. \u201cEach one of these experiments is doing something exciting,\u201d says David Shoemaker, a physicist at MIT and head of Advanced LIGO. In March this year, there was a burst of gravitational-wave excitement about a report that the BICEP2 telescope at the South Pole had detected primordial gravitational waves left over from cosmic inflation that occurred moments after the Big Bang (see  Nature   507 , 281\u2013283; 2014 ). The wavelengths of these disturbances essentially span the entire Universe, far outside the wavelength range that LIGO can see. The BICEP2 team initially reported a strong signal, but when the scientists published their findings in June (R. A. R. Ade  et al .  Phys. Rev. Lett.   112 , 241101; 2014 ), they admitted that they could not rule out the possibility that the gravitational-wave 'signal' was just an artefact of galactic dust (see  go.nature.com/lruz8e ). A very different kind of hunt is under way by a North American\u2013European\u2013Australian collaboration of astronomers who have been monitoring about 70 pulsars: rapidly spinning neutron stars that emit signals at incredibly precise intervals. The members of the International Pulsar Timing Array (IPTA) hope to detect a passing gravitational wave by the way it affects the timing of the pulses. They would have to be very lucky to see one before Advanced LIGO does, says IPTA co-leader Scott Ransom, an astronomer at the University of Virginia in Charlottesville. But even so, he says, \u201cI always tease the LIGO people that here comes the dark horse\u201d. The gravitational waves found through pulsar timing would also be very different beasts from the ones LIGO is seeking. They would come from sources such as colliding supermassive black holes, whose huge mass would make their coalescence frequency much too low for an interferometer like LIGO to see. Nevertheless, says Joseph Giaime, head of the Livingston observatory, any direct detection will invigorate the field. \u201cYou can only go so many decades without detecting anything before some people start to think there's some quackery involved.\u201d The closest thing Advanced LIGO has to a competitor is also its closest ally. Virgo in Cascina, Italy, is like LIGO's little sister: a laser interferometer with 3-kilometre arms, it can reach only about three-quarters of LIGO's sensitivity. Virgo hunts the same sources as LIGO, focusing mainly on colliding neutron stars. It began running in 2007 and has spotted no gravitational waves so far. But it, too, is in the middle of a major upgrade, currently scheduled to come online about a year after Advanced LIGO. Scientists from the two detectors share their data and collaborate closely; combining signals makes the analysis more robust, says Giovanni Losurdo, project leader for Advanced Virgo at the National Institute for Nuclear Physics in Florence, Italy. Crucially, having another interferometer on a different continent will help astronomers to accurately locate the source of any gravitational-wave signals. While Virgo and LIGO are offline for upgrades, a third machine monitors the skies. GEO600 \u2014 an interferometer in Hanover, Germany, with two 600-metre-long arms \u2014 is much less sensitive than its bigger peers, but will be better than nothing if a big gravitational-wave-producing event does occur. This became clear in late May, when NASA's space telescope Swift reported a high-energy outburst in the nearby Andromeda galaxy. It turned out to be a false alarm, but had it been a real star explosion so close, both LIGO and Virgo would have missed the chance at a once-in-a-lifetime event. \u201cMy nightmare is that it happens before we turn on,\u201d says Gabriela Gonzalez, a physicist at Louisiana State University and spokesperson for the LIGO scientific collaboration. Japanese scientists are building yet another interferometer: the Kamioka Gravitational Wave Detector (KAGRA), which will be buried deep in a mine and could be operational as early as 2018. And in Europe, researchers are dreaming of the Einstein Telescope, with three 10-kilometre arms buried in a triangle. But with a pricetag of at least \u20ac1 billion (US$1.4 billion), the Einstein Telescope remains only a hope for now. Similarly, the European Space Agency has pushed back the proposed launch of a space-based gravitational-wave hunter, the Laser Interferometer Space Antenna (LISA), to 2034. Even as project leaders try to get Advanced LIGO up and running, they are also pushing to place a third detector in India, where it would allow astronomers to pinpoint the source of gravitational waves even more accurately. LIGO engineers have already built a set of components, and are storing them at Hanford. They are waiting for India's new government to select a site and approve funding, but depending on when that happens, LIGO India could be operational by 2022 for a total cost of roughly $350 million. Back in the United States, Advanced LIGO has money to run until October 2018. If it has not reached its full design sensitivity by then, it will be almost certain to get operational funding from the NSF to keep trying for another five years, scientists say. Further upgrades to reduce noise at high frequencies could improve its sensitivity even more. But although most physicists are optimistic that Advanced LIGO will eventually make a discovery, there is no guarantee. \u201cIf we get to the design sensitivity and make no detections, then there are a lot of things that will have to go back to the drawing board theoretically,\u201d says Barish. \u201cIf we fail, we're not expecting that the NSF will help bail it out somehow.\u201d For now, the field's future rests in the hands of de Rosa and his colleagues. He frowns, perplexed, at a glowing screen in the Livingston control room. Something is still not quite right with how the light is bouncing off one particular mirror in the machine. But it is dinner time. He rounds up the others in the room, and they head for a Mexican restaurant for a short break. As they pull out of the car park, a series of spikes appear on the LIGO monitors. The ultrasensitive detectors have picked up the rumbling from the researchers' cars, heading off into the night. \n                     Funding hunt puts Indo-Australian gravity partnership at risk 2011-Mar-15 \n                   \n                     Pulsar watchers race for gravity waves 2010-Jan-13 \n                   \n                     Gravity waves 'around the corner' 2009-Aug-19 \n                   \n                     Gravity-wave hunt stalled 2008-Sep-12 \n                   \n                     Nature special: Waves from the Big Bang \n                   \n                     LIGO \n                   \n                     LIGO Scientific Collaboration \n                   \n                     Advanced LIGO \n                   \n                     Advanced Virgo \n                   Reprints and Permissions"},
{"file_id": "511398a", "url": "https://www.nature.com/articles/511398a", "year": 2014, "authors": [{"name": "M. Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "Fuelled by venture capital and a lot of hope, alternative fusion technologies are heating up. To reach one of the world's most secretive nuclear-fusion companies, visitors must wind their way through a suburban office park at the foot of the Santa Ana Mountains, just east of Irvine, California, until they pull up outside the large but unmarked headquarters of Tri Alpha Energy. This is as close as any outsider can get without signing a non-disclosure agreement; Tri Alpha protects its trade secrets so tightly that it does not even have a website. But the fragments of information that have filtered out make it clear that the building houses one of the largest fusion experiments now operating in the United States. It is also one of the most unconventional. Instead of using the doughnut-shaped 'tokamak' reactor that has dominated fusion-energy research for more than 40 years, Tri Alpha is testing a linear reactor that it claims will be smaller, simpler and cheaper \u2014 and will lead to commercial fusion power in little more than a decade, far ahead of the 30 to 50 years often quoted for tokamaks. That sounds particularly appealing at a time when the world's leading fusion project, a giant tokamak named ITER, is mired in delays and cost overruns. The facility, being built in Cadarache, France, is expected to be the first fusion reactor capable of generating an excess of energy from a sustained burn of its plasma fuel. But it looks set to cost as much as US$50 billion \u2014 about 10 times the original estimate \u2014 and will not begin its first fuelled experiments before 2027, 11 years behind schedule. Mitch Waldrop pits the fusion upstarts against the establishment projects. Can the smaller schemes deliver? With ITER consuming the lion's share of the US fusion-energy budget, fans of alternative approaches have scant government support. But growing impatience with the tokamak technology has spurred the Tri Alpha team and many other physicists in the United States and Canada to pursue different options. Over the past decade and a half, these mavericks have launched at least half a dozen companies to pursue alternative designs for fusion reactors. Some are reporting encouraging results, not to mention attracting sizeable investments. Tri Alpha itself has raised $150 million from the likes of Microsoft co-founder Paul Allen and the Russian government's venture-capital firm, Rusnano. But that success is bringing increased scrutiny of their bold promises. Tri Alpha \u201chas got very tough problems to overcome as it starts scaling up to reactor size\u201d, says Jeffrey Freidberg, a nuclear physicist at the Massachusetts Institute of Technology (MIT) in Cambridge. For example, the company must prove that it can achieve the billion-kelvin temperatures needed to burn the exotic fuel it wants to use, and must demonstrate a practical way to convert the energy output into electricity. Similar questions could be raised about any of the other upstarts, says Stephen Dean, who heads Fusion Power Associates, an advocacy group in Gaithersburg, Maryland. \u201cI don't think you can honestly say that any of these things are at the stage where fusion can be demonstrated quickly,\u201d he says. Will alternative fusion companies be able to sustain their momentum and justify their founders' optimism? Or will they fizzle like so many fusion dreams before them? \n               Follow the Sun \n             In principle, building a fusion reactor is just a matter of imitating the Sun. Take the appropriate isotopes of hydrogen or other light elements, add heat to strip the electrons from the nuclei and form an ionized plasma, then compress that plasma and hold it together for a while, allowing the nuclei to fuse and convert a portion of their mass into energy. But in practice, trying to mimic a star leads to horrendous engineering problems: for example, hot plasma trapped in a magnetic field tends to twist and turn like an enraged snake struggling to escape. Fusion researchers have long favoured tokamaks as the best way to contain this plasma beast. Developed by Soviet physicists in the 1950s and announced to the West a decade later, the reactors achieved plasma densities, temperatures and confinement times much higher than any machine before them. And as physicists refined the design, they improved the way that tokamaks controlled high-energy plasma. But from the beginning, many physicists have wondered whether tokamaks could ever be scaled up to achieve commercial power output. They are dauntingly complex, for starters. The toroidal chamber has to be wound with multiple sets of electromagnetic coils to shape the magnetic field that confines the plasma. And more coils run through the doughnut hole to drive a powerful electric current through the plasma (see 'Trapping fusion fire'). Then there is the fuel, a mixture of the hydrogen isotopes deuterium (D) and tritium (T). D\u2013T is widely regarded as the only sane choice for a power reactor because it ignites at a lower temperature than any other combination \u2014 only about 100 million kelvin \u2014 and releases much more energy. But 80% of that energy emerges from the reaction in the form of speeding neutrons, which would wreak havoc on the walls of a power reactor, leaving them highly radioactive. To generate electricity, the neutrons' energy would have to be used to heat water in a conventional steam turbine \u2014 a process that is only 30\u201340% efficient. Cost, complexity and slow progress have also dogged inertial-confinement fusion, the most prominent alternative to the tokamaks' magnetic confinement. This approach, in which frozen fuel pellets are imploded by high-powered laser beams, has also received a lot of government funding. But despite decades of effort on inertial confinement, initiatives such as the National Ignition Facility at Lawrence Livermore National Laboratory in Livermore, California, are still struggling to deliver on their fusion-power promises (see  Nature 491, 159; 2012 ). \n               Radical departure \n             Such concerns have sparked some enthusiasm for the stellarator: a toroidal device that simplifies certain aspects of the tokamak but requires even more complex magnets. But most mainstream plasma physicists have simply left the practical engineering issues for later, assuming that fixes will emerge after the plasma physics has been worked out. The fusion mavericks are among the minority who argue that a more radical solution is needed: first get the engineering right, by designing a simple, cheap reactor that power companies might actually want to buy, and then try to make the plasmas behave. One of those upstarts is Norman Rostoker, a physicist at the University of California, Irvine, who co-founded Tri Alpha in 1998 at the age of 72. He and his colleagues proposed ditching D\u2013T fuel in favour of fusing protons with boron-11, a stable isotope that comprises about 80% of natural boron. Igniting this p\u2013 11 B fuel would require temperatures of about a billion kelvin, almost 100 times as hot as the core of the Sun. And the energy created in each fusion event would be only about half that released by D\u2013T. But the reaction products would be practically free of troublesome neutrons: the fusion would generate just three energetic helium nuclei, also known as \u03b1-particles. These are charged, so they could be guided by magnetic fields into an 'inverse cyclotron' device that would convert their energy into an ordinary electric current with around 90% efficiency. Burning a billion-kelvin p\u2013 11 B plasma in a tokamak was out of the question, not least because unfeasibly large magnetic fields would be needed to confine it. So Rostoker and his colleagues designed a linear reactor that looks like two cannons pointed barrel to barrel. Each cannon would fire rings of plasma called plasmoids that are known to be remarkably stable: the flow of ions in the plasma would generate a magnetic field, which in turn would keep the plasma confined. \u201cIt's the most ideal configuration you could imagine,\u201d says Alan Hoffman, a plasma physicist at the University of Washington in Seattle. To start the reactor, each cannon would fire a plasmoid into a central chamber, where the two would merge into a larger, free-floating plasmoid that would survive for as long as it could be fed with additional fuel. The \u03b1-particles emerging from the reaction would be guided back through the cannons by another magnetic field, and captured in the energy converter. By the time the team published this concept 1  in 1997, it was becoming clear that the US energy department was not going to fund development of the machine, preferring instead to focus on tokamaks, which seemed to be a safer bet. \u201cThe big experiments have been funded for decades, so there's little chance they won't meet their milestones,\u201d says John Slough, a plasma physicist at the University of Washington. \u201cIf they start funding these alternatives, all the uncertainties come back.\u201d So Rostoker and his colleagues decided to take advantage of the United States' robust culture of high-tech startups and venture-capital funding. They formed a company, naming it Tri Alpha after the output of the p\u2013 11 B reaction, and went on to raise enough investment to employ more than 100 people. Dean suspects that the start-up mindset may explain why Tri Alpha is so secretive. \u201cIt's part of the mystique of being a venture-capital-funded company: develop your ideas before anyone else can see them,\u201d he says. But over the past five years or so, the company has started to let its employees publish results and present at conferences. With its current test machine, a 10-metre device called the C-2, Tri Alpha has shown that the colliding plasmoids merge as expected 2 , and that the fireball can sustain itself for up to 4 milliseconds \u2014 impressively long by plasma-physics standards \u2014 as long as fuel beams are being injected 3 . Last year, Tri Alpha researcher Houyang Guo announced at a plasma conference in Fort Worth, Texas, that the burn duration had increased to 5 milliseconds. The company is now looking for cash to build a larger machine. \u201cAs a science programme, it's been highly successful,\u201d says Hoffman, who reviewed the work for Allen when the billionaire was deciding whether to invest. \u201cBut it's not p\u2013 11 B.\u201d So far, he says, Tri Alpha has run its C-2 only with deuterium, and it is a long way from achieving the extreme plasma conditions needed to burn its ultimate fuel. Nor has Tri Alpha demonstrated direct conversion of \u03b1-particles to electricity. \u201cI haven't seen any schemes that would actually work in practice,\u201d says Martin Greenwald, an MIT physicist and former chair of the energy department's fusion-energy advisory committee. Indeed, Tri Alpha is planning that its first-generation power reactor would use a more conventional steam-turbine system. Other fusion entrepreneurs will have to tackle similar challenges, but that has not deterred them. Slough is chief scientific officer at Helion Energy in Redmond, Washington, which is developing a linear colliding-beam reactor that would be small enough to be carried on the back of a large truck. The Helion reactor will fire a steady stream of plasmoids from each side into a chamber, where the fuel is crushed by magnetic fields until fusion begins. Within one second, the fusion products are channelled away just as the next pair of plasmoids hurtles in. \u201cThe analogy we like to make is to a diesel engine,\u201d says the company's chief executive, David Kirtley. \u201cOn each stroke you inject the fuel, compress it with the piston it until it ignites without needing a spark, and the explosion pushes back on the piston.\u201d Helion has demonstrated the concept 4  in a D\u2013D reactor with plasmoids that fire once every three minutes, and it is now seeking $15 million in private financing over the next five years to develop a full-scale machine that could use D\u2013T fuel to reach the break-even point, when it generates as much energy as it takes to run. The company hopes that its reactor could eventually reach the hotter conditions needed to fuse deuterium with helium-3, another combination that produces only \u03b1-particles and protons, with no neutron by-products. Kirtley is optimistic about the money. \u201cThere is a giant market need for low-cost, safe, clean power,\u201d he says. \u201cSo we're seeing a big push in the private investment community to fund alternative ways to generate it.\u201d And if the fund-raising is successful, says Kirtley, \u201cour plan is to have our pilot power plant come online in six years.\u201d \n               In a spin \n             Other alternative concepts stick with D\u2013T fuel, but confine it in different ways. In Burnaby, Canada, researchers at General Fusion have designed a reactor in which a plasmoid of D\u2013T will be injected into a spinning vortex of liquid lead, which will then be crushed inwards by a forest of pistons. If this compression happens within a few microseconds, the plasma will implode to create fusion conditions 5 . One advantage of this design is that the liquid lead does not degrade when it gets blasted by neutrons, says Michel Laberge, who founded General Fusion in 2002. General Fusion has demonstrated the idea with a small-scale device, using pistons driven by explosives, and has raised about $50 million from venture capitalists and the Canadian government. If the company can win another $25 million or so, Laberge says, it will build a beefier implosion system that can compress the plasma to the levels needed for fusion \u2014 perhaps within the next two years. Despite such optimism, Dean estimates that it will be at least a decade, maybe a lot longer, before any alternative fusion company produces a working power plant. There is simply too much new technology to be demonstrated, he says. \u201cI think these things are well motivated, and should be supported \u2014 but I don't think we're on the verge of a breakthrough.\u201d It is not clear how much of that support will come from the US energy department in the foreseeable future. The department's fusion-energy programme has provided a modicum of cash for Helion, as well as for some small-scale academic work on alternative reactors. And its long-shot funding agency, the Advanced Research Projects Agency\u2014Energy, has expressed interest in some of the alterative concepts, to the extent of holding a workshop on them last year. The fusion-energy advisory committee is preparing a ten-year research plan, due by the start of next year, that could conceivably lead to more backing for the upstarts. But funds are tight, and ITER continues to be a huge financial drain. For now, the big money will probably have to come from the private sector. And despite the many technical hurdles, investors seem willing to take a chance. \u201cPeople are starting to think, 'Hey, maybe there are other ways of doing this!'\u201d says Slough. \u201cMaybe it's worth a few million to find out.\u201d \n                 See Editorial \n                 page 383 \n               \n                     Fusion furore 2014-Jul-23 \n                   \n                     Laser fusion experiment extracts net energy from fuel 2014-Feb-12 \n                   \n                     Triple-threat method sparks hope for fusion 2013-Dec-30 \n                   \n                     ITER keeps eye on prize 2013-Oct-15 \n                   \n                     Fusion project struggles to put the pieces together 2012-Oct-26 \n                   \n                     US fusion in budget vice 2012-Jul-24 \n                   \n                     The FIRE Place: general information on fusion \n                   \n                     Helion Energy \n                   \n                     General Fusion \n                   \n                     ITER \n                   Reprints and Permissions"},
{"file_id": "508302a", "url": "https://www.nature.com/articles/508302a", "year": 2014, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "After years in the doldrums, the quest to harvest energy from the oceans is gathering speed. Several kilometres off the coast near Perth in Western Australia, hidden beneath the waves and out of sight of watchful boaters, three giant buoys will soon begin producing electricity as they bob to the rhythm of the Indian Ocean. At 11 metres wide and 5 metres tall, the squat orange floats look a bit like giant pumpkins. As waves pass by, the tethered buoys will drive hydraulic pumps on the sea bottom, converting the motion of the ocean into 720 kilowatts of electricity to power a nearby naval base. Carnegie Wave Energy of North Fremantle, Australia, plans to have the system \u2014 the latest attempt at harvesting power from the sea \u2014 up and running by June. The pilot project will generate a lot of press, but veterans of the marine-energy field will watch warily to see how it fares. This industry has taken a slow road: none of the myriad devices designed thus far has proved its worth in the highly competitive energy market, and few have survived prolonged exposure to the harsh conditions in the sea. Despite an overall investment of around US$735 million over the past decade by a dozen leading companies, marine power from tide and waves has yet to take off. In fact, it remains the most expensive form of power on Earth. But the outlook has brightened for those hoping to tap this source of energy. In the past few years, several major industrial leaders have acquired start-up companies that harvest energy from tides, the easiest type of marine power to capture. In March, three projects were approved for Canada's Bay of Fundy, home to some of the largest tides on the globe. The wave-energy industry, which is targeting a much larger but more elusive resource, has had a few setbacks, including a decision to scale back plans for an array off the coast of Oregon last month. But there is little doubt that both types of marine energy will eventually grow. Last year, the London-based consultancy Bloomberg New Energy Finance projected that up to 22 tidal projects and 17 wave projects generating more than one megawatt of electricity \u2014 enough to power around 250 homes \u2014 could be installed by 2020. In theory, oceans could power the entire globe without adding any pollution to the atmosphere. And they could provide a more dependable source of electricity than the wind or sun. They are also geographically convenient: roughly 44% of the global population lives within 150 kilometres of the coastline. Some nations have been using large, dam-like structures to block off inlets and draw power from tidal flow for decades, but the latest approaches are designed to be less intrusive. Although the potential environmental impacts are still under investigation, many researchers say that the sea could turn out to be an even more benign source of power than wind. Indeed, energy experts envisage a day when the sea will deliver a significant amount of reliable carbon-free power to islands and burgeoning coastal cities around the world. \u201cIt has proved harder than people had expected at the start, but it has also proved possible,\u201d says Neil Kermode, managing director of the European Marine Energy Centre, the leading test facility for wave- and tidal-energy devices in the Orkney Islands, UK. \u201cWe have shown that you can make electricity from moving sea water, and that's a huge step forwards.\u201d \n               Shifting tides \n             Twice a day, some 350 million cubic metres of tidal water flows through a narrow strait into Strangford Lough \u2014 a small inlet southeast of Belfast, UK \u2014 and then back out to sea. With each trip, it passes a pair of 16-metre-long propellers attached to a central tower that is anchored to the floor of the channel. The force of the water, equivalent to a wind blowing at 555 kilometres per hour, spins the propellers at up to 15 revolutions per minute, generating 1.2 megawatts of electricity. In addition to the traditional propeller, tidal-power companies have experimented with contraptions such as corkscrews, hydrofoils and underwater kites. The device used in Strangford Lough, however, is leading the way. Built by Marine Current Turbines in Bristol, UK, the design has generated more than 90% of the industry's power to date, according to the company. The achievements attracted the interest of engineering giant Siemens in Munich, Germany, which took control of the company in 2012. Marine Current Turbines is now preparing to deploy its first array of five 2-megawatt machines \u2014 each costing roughly \u00a39 million (US$15 million) \u2014 off the coast of Wales by 2016. As well as boosting the size of the machines, the company added a third blade to reduce vibrations and make the machines more durable, says chairman Kai K\u00f6lmel. But he cautions that progress is likely to be incremental. \u201cI think some of the venture capitalists are disillusioned, but this is not a quick-buck industry,\u201d he says. \u201cThe wind industry didn't start up rapidly either.\u201d Even with major companies such as Siemens entering the game, the biggest challenge remains attracting the money needed to do the engineering and build prototypes, says Christopher Sauer, chief executive of Ocean Renewable Power Company, based in Portland, Maine. Sauer's company has developed and deployed, albeit briefly, a unique device off the coast of Maine that looks a bit like the spinning blades of a combine harvester. The company is now working on a second-generation device that should be ready for deployment as early as 2015. \u201cWe're doing the best that we can with the money we have,\u201d he says. \n               Waves of energy \n             The power of waves is vast, but developing machines that can reliably extract that energy and withstand the often-punishing environment represents a wholly different kind of challenge. Companies have explored designs ranging from swinging flaps to gyroscopic devices that convert the rocking of a ship into a circular motion to drive an onboard generator. Each has its advantages, but the idea behind Carnegie Wave Energy's bobbing buoys in Australia was to escape the rough battering of waves at the surface. The submersion has the added advantage of keeping the devices out of sight and avoiding the debates over aesthetics that have arisen with wind farms. As the waves carry the buoys up and down, the sea-floor pumps circulate fluid through a closed loop that extends roughly 3 kilometres to an onshore generation facility (see 'Water works'). Operating like a bagpipe, the system accumulates pressure and then releases it gradually to generate a constant flow of electricity. Each of the three devices can generate up to 240 kilowatts of energy. \u201cThis is obviously not a commercial project, but there's not a commercial wave-energy facility in the world at the moment,\u201d says Carnegie's chief operating officer Greg Allen. Nonetheless, it represents progress, he says: each device generates three times more power than the version that was tested in the same waters in 2011. Allen says that the first commercial projects could come as early as 2018. To gain a toehold in the market, the company aims to compete with diesel-fired power generators on islands. Pelamis Wave Power, based in Edinburgh, UK, has taken a different approach. It uses a set of five connected buoys that float on top of the ocean and wriggle in the waves like a snake. The segments move independently, and hydraulic pumps at each of the joints use the motion to drive fluids to an on-board generator. The company is currently testing a pair of 750-kilowatt machines at the Orkney Islands testing site. One of these is operated through a partnership with Scottish Power Renewables, a utility based in Glasgow. New components have helped to reduce internal wear and tear in the hydraulic system, and the company is now working on algorithms that will allow the device to adjust each of its 16 hydraulic pumps individually and maximize energy production as it rides the waves. The company hit some rough waters last year when the German energy firm E.ON pulled out of a partnership after a three-year project to test one of the devices in the Orkney Islands. Founder and chief executive Richard Yemm remains optimistic, and says that the device is still in the water and producing power. But he acknowledges that the company needs to strengthen its bonds with the industrial energy sector. \u201cWe need the big industrial skills that the big companies have,\u201d he says. One reason that wave energy has attracted less commercial interest is that no one has yet managed to produce machines that can withstand the rough and tumble of the seas and produce electricity around the clock for sustained periods, says Angus McCrone, chief editor at Bloomberg New Energy Finance. \u201cThese companies have gone through a lot of money,\u201d he says, \u201cand now the industry finds that it is going to have to spend significantly more to get the devices to commercialization.\u201d \n               Green machines \n             The marine-energy industry has also encountered wary regulators who are well aware of controversies surrounding bird deaths caused by wind turbines. Before Marine Current Turbines was allowed to start testing, it had to place seal spotters atop its turbines, who would hit an emergency cut-off button if any seals approached (which did not happen). And fears that seabed-mounted turbines designed by OpenHydro in Dublin, Ireland, could turn orcas into whale sushi nearly killed a proposal to test the devices in the Puget Sound near Seattle, Washington. Gayle Zydlewski, a fish biologist at the University of Maine in Orono, says that she was able to capture only limited data on fish moving around and through Ocean Renewable Power's tidal unit in Maine. Fish mostly seemed to avoid the turbine, she says, but she wonders: \u201cWhat happens when you have another one next to it?\u201d Her team is still collecting baseline data, and her goal is to improve her models and understand how much fieldwork will be needed to determine potential impacts. Others are busy in the lab. Biologists with the US Department of Energy have shot fish through turbines and exposed them to electromagnetic fields similar to those that surround the cables that transport the power back to shore. Neither seemed to cause any permanent damage, according to the department. In the case of the orcas in Puget Sound, energy-department researchers at the Pacific Northwest National Laboratory in Richland and Sandia National Laboratories in Albuquerque, New Mexico, studied a worst-case scenario: what if a curious orca stuck its head inside one of the turbines? The teams scoured the literature, tested various rubber materials as surrogates for whale skin and built a model to understand the potential impact of a blade strike (see go.nature.com/aaptn2). When a dead whale washed up onto the shore near Seattle last year, the scientists performed a computed tomography scan on the skull to look at skin and blubber thickness and used the information to improve their models. They also took some whale skin and tested its strength in the lab. The upshot of the study, released in January, was that an orca that got struck on the head by a turbine blade would probably swim away with little more than a bruise, says biological oceanographer Andrea Copping from Pacific Northwest National Laboratory, who led the effort. \u201cWhen whales hit a ship, it's the jawbone break that causes the death, but there wasn't enough force for that to happen,\u201d she says. The proposal to test the turbines in Puget Sound was approved by the Federal Energy Regulatory Commission on 20 March. Copping is also heading an international collaboration that is pulling together all the environmental research on tidal- and wave-energy development. The goal is to determine the most likely impacts and concentrate the research on those. Its first report, issued in January 2013, focused on three areas: animal interactions, turbine noise and the effect of taking energy out of the marine system and slowing down the flow of water. Thus far, the team reports, there is no evidence that there would be significant effects on marine animals or water flow, although the influence of large arrays is difficult to project. The issue of sound could be more difficult to resolve. Researchers have taken detailed measurements of individual devices, and blasted fish at volume levels that the animals would experience if they were effectively strapped to the turbines for 24 hours. Apart from some tissue damage, equivalent perhaps to what a teenager would experience at a rock concert, Copping says that the fish seem to be okay. But the broader effects of an array of devices in an environment that is already saturated with sound from the motion of water as well as the loud drone of ships are hard to forecast. A little noise might help the animals to avoid the machines, but too much could trouble whales and other animals that use sound to communicate.\u201cMany or all of these projects are going to need a good deal of monitoring,\u201d Copping says. \u201cThe oceans are everybody's backyard.\u201d Developers, researchers and environmentalists all agree on one thing: to understand both the economics and the environmental impacts, the industry needs to put more machines in the water. Bloomberg's McCrone says the projections for wave power are likely to drop in their next assessment, owing to declining industrial interest and the cancellation of some projects. But he also believes that both sectors will eventually mature. One of the current hot spots is Canada's Bay of Fundy, which will soon host three projects, including a 4-megawatt installation featuring two devices from OpenHydro that will produce enough power for 1,000 homes by 2015. If all goes well, the company hopes to expand the array to eventually generate 300 megawatts. Although that would equal just one small coal-fired electricity plant, it would be a significant step forward for marine power. \u201cIt will take off eventually,\u201d McCrone says. \u201cThere's a lot of energy in the sea.\u201d \n                     Climate science: A line in the sands 2013-Aug-07 \n                   \n                     The global energy challenge: Awash with carbon 2012-Nov-28 \n                   \n                     How green is my future? 2011-May-11 \n                   \n                     Energy alternatives: Electricity without carbon 2008-Aug-13 \n                   \n                     Energy: To catch a wave 2007-Nov-07 \n                   \n                     Wave energy gets to the point 2005-Oct-11 \n                   \n                     Nature  special: After Kyoto \n                   \n                     European Marine Energy Centre \n                   \n                     Intergovernmental Panel on Climate Change marine energy assessment (PDF) \n                   \n                     International Energy Agency Ocean Energy Systems initiative \n                   Reprints and Permissions"},
{"file_id": "508306a", "url": "https://www.nature.com/articles/508306a", "year": 2014, "authors": [{"name": "Josie Glausiusz"}], "parsed_as_year": "2006_or_before", "body": "When toxicologists warned that the plastics ingredient BPA might be harmful, consumers clamoured for something new. But problems persist. A stroll down the aisles of a US supermarket reveals a modest victory for consumer activism. In the baby-products section, plastic baby bottles, spill-proof cups and miniature cutlery are proudly marked 'BPA-free' \u2014 a sign that they no longer contain the compound bisphenol A, found in many plastics. A range of blenders and water bottles in the kitchenware aisle are also untainted by the chemical, as are a few cans of beans tucked away in the organic foods section. And customers filling their baskets with these BPA-free treasures may even receive a BPA-free receipt at the cash register. The partial withdrawal of BPA is the culmination of two decades of research and hundreds of studies linking the compound \u2014 which mimics sex hormones called oestrogens \u2014 to adverse health effects in rodents and humans. The decision by regulators in the United States and European Union to ban BPA from baby bottles, combined with industry marketing campaigns, has convinced many consumers that the plastics and other containers currently used to store food are safe. It is a false sense of security. BPA is still a constituent of many food containers, especially cans. And when companies did abandon BPA, they often adopted compounds \u2014 such as the increasingly common bisphenol S (BPS) \u2014 that share much of the same chemistry and raise many of the same concerns as BPA. \u201cPeople use this chemical to replace BPA without sufficient toxicological information,\u201d says Kyungho Choi, an environmental toxicologist at Seoul National University. \u201cThat is a problem.\u201d \n               Fall from grace \n             BPA has formed the chemical backbone of most hard, clear polycarbonate plastic since the 1950s. Over time, studies have linked the chemical \u2014 which can leach out of plastics and into food \u2014 to a host of adverse health effects, including reductions in fertility and birth weight, male genital abnormalities, altered behavioural development, diabetes, heart disease and obesity 1  (see   Nature   464 , 1122\u20131124; 2010). Establishing a clear connection between a compound such as BPA and human health is complex, notes Geoffrey Greene, who studies oestrogens and their receptors at the University of Chicago in Illinois. \u201cMost studies address only the question of whether such adverse effects can occur in various cell- or animal-based models,\u201d he says, \u201cwithout addressing whether the amounts that we are exposed to are sufficient to have an effect on human health.\u201d Because many of the potential health effects of BPA are difficult to assess, the US National Institute of Environmental Health Sciences in Research Triangle Park, North Carolina, has launched a US$30-million research programme designed to answer outstanding questions. A few years ago, mounting evidence and concerned consumers convinced governments to take action. In 2011, the European Union banned BPA from baby bottles; the United States followed suit a year later. But BPA-based linings are still slathered on the insides of most food and beverage cans, and used to coat water-supply pipes in many countries. The compound is also found in dental sealants and in incubators for premature infants. In the quest to replace BPA, finding an alternative for food and drink cans has proved particularly vexing. Creating a cheap lining for tins suitable for a range of foods \u2014 from beans to tomatoes to haggis curry \u2014 is no simple matter. Not only must the packaging prevent bacteria and fungi from attacking the food, the can's lining must also stop the food from attacking and corroding the can. Moreover, when metal comes into contact with food, it can ruin the flavour. \u201cIf your food tastes funny, but you tell people it's safer, are they going to believe that?\u201d says Daniel Schmidt, a plastics engineer at the University of Massachusetts in Lowell. Manufacturers also prefer linings that block sulphur compounds \u2014 found in proteins, preservatives and pesticides \u2014 from reacting with the metal and forming unattractive iron or tin sulphide stains. No BPA-free lining has yet emerged that can accomplish all of this. \u201cYou have to have a special can and a special coating for every class of food,\u201d Schmidt says. \u201cIt gets extremely cumbersome and quite expensive.\u201d BPA-based epoxy linings are widely used because they are strong, flexible and cheap. They tolerate the high temperatures needed to sterilize foods during canning, and do not interact with a huge array of foods and beverages, according to the North American Metal Packaging Alliance in Washington DC. The alliance estimates that 95% of all aluminium and steel can coatings are epoxy-type resins: more than 99.9% of these contain BPA. And although there are alternatives, these are not without drawbacks. In 1999, Eden Organic of Clinton, Michigan, began coating bean tins with plant-based oleoresins. The switch has increased the cost of the tins by more than 20%. Oleoresin linings can also alter the taste of food, and are vulnerable to attack from high-acid foods \u2014 such as tomatoes \u2014 which have a particular propensity to leach BPA, according to biologist Frederick vom Saal of the University of Missouri-Columbia. Some Japanese manufacturers now use reduced-BPA lacquers to coat cans. Other coatings include acrylics, which are too brittle for use in many tins, and vinyls and phenolics, both of which may have oestrogenic effects. New options are beginning to surface. Schmidt is developing an epoxy based on a molecule in Tritan \u2014 a BPA-free polymer manufactured by the Eastman Chemical Company in Kingsport, Tennessee, that is used in baby bottles. He hopes that his epoxy will be as versatile and cheap as BPA. \u201cThe profit margins are so thin in the can-coating industry,\u201d he says. \u201cUnless somebody hands them that solution, it's going to be tough for them to accept anything.\u201d In contrast to the can-liner conundrum, replacing BPA in baby bottles and cash-register receipts proved relatively straightforward. When BPA fell from grace, many manufacturers turned to the compound's structural kin: BPS. A BPA molecule consists of two phenol groups connected by a branched three-carbon group. In a BPS molecule, the two phenol groups are instead connected by a sulphone group (SO 2 ). BPS was first made in 1869 as a dye. But because it was introduced into consumer goods only recently \u2014 into cash-register receipts in 2006, for example \u2014 few researchers have studied its toxicity. \u201cThe main question, to which we have no answer, is: 'is BPS as toxic as BPA?'\u201d says Ren\u00e9 Habert, an endocrinologist at Paris Diderot University. \n               A key to action \n             The similarity of BPS's structure to that of BPA is enough to raise suspicions that it may mimic oestrogens, says Cheryl Watson, a biochemist at the University of Texas Medical Branch in Galveston. Natural oestrogens are small molecules containing several phenolic rings; these bear chemical adornments that bind to a pocket found in oestrogen receptors in the body. BPA and BPS are about the same size and have similar phenolic rings with similar attachments, so they may slot like keys into oestrogen receptors, Watson says. Watson and a colleague, Rene Vi\u00f1as, now at the US Food and Drug Administration, measured the responses of cultured rat pituitary cells to BPS. These cells are particularly sensitive to oestrogens and oestrogen mimics, allowing the team to study concentrations of BPS down to 10 \u221215  moles per litre. The team found that even at these very low levels, BPS triggered the enzyme cascade normally activated by an oestrogen called oestradiol 2 , an effect also seen with BPA. When combined with levels of oestradiol found in adult women, BPS seemed to over-stimulate the pathway, shutting it down and causing cell suicide. The results, says Watson, were typical of those expected of an oestrogen mimic: inappropriate activation of oestrogen responses, disruption of normal oestrogen-response pathways, and eventual cell death. Others have seen similar effects. Susanne Bremer and her colleagues at the Institute for Health and Consumer Protection, a European Commission-funded research centre in Ispra, Italy, tested BPS and BPA on an oestrogen-sensitive human cell line. They found that both chemicals behaved like oestrogens, but were 100,000-fold less active than oestradiol 3 . Choi and his colleagues discovered that zebrafish exposed to 0.5 micrograms of BPS per litre of water \u2014 about one-sixth of the maximum concentration detected in the environment \u2014 had fewer eggs, more malformed offspring and higher oestrogen to testosterone ratios than untreated zebrafish 4 . \u201cHigh concentrations of BPS have the same effect as high concentrations of BPA,\u201d says Habert, who has conducted preliminary experiments on the effect of BPS on mouse and human fetal testis cells. \u201cAt low concentrations, the effect is unknown.\u201d What concentration best approximates human exposure to BPS is not clear. A team led by Catherine Simoneau of the Institute for Health and Consumer Protection analysed a total of 30 BPS-containing baby bottles from 12 countries. After five minutes in boiling water and two hours at 70 \u00b0C, none of the bottles released detectable quantities of BPS 5 . \u201cThese materials are far more resistant to hydrolytic breakdown than polycarbonate \u2014 that was one of the big selling points,\u201d says Schmidt. \u201cAs such, I would consider them to be safer than polycarbonate in a food-contact setting.\u201d But people are exposed to BPS in many different ways. Kurunthachalam Kannan, an analytical chemist at the New York State Department of Health in Albany, and his team have found BPS on cash-register receipts, and aeroplane luggage tags and boarding passes, all of which are made from thermal paper containing BPS as a colour developer. The scientists also found BPS in products made from recycled paper, including pizza boxes and food buckets. Kannan's team estimates that the average daily exposure to BPS through the skin is well below the threshold values for toxic effects. Nevertheless, given the potential for higher levels of exposure from other sources such as food, Kannan urges further studies of the compound. And Watson argues that even small amounts of oestrogen mimics can cause trouble. \u201cThe problem is that they are active in such small quantities,\u201d she says. \u201cIf you leach even a little, you still leach enough for responses to happen.\u201d \n               Branching out \n             Some manufacturers have left the bisphenol family in search of a replacement. In 2007, the Eastman Chemical Company launched Tritan \u2014 a new heat-resistant clear plastic \u2014 for infant-care products such as baby bottles. This BPA-free plastic has since replaced the old BPA-containing polycarbonate in many water bottles, food containers and children's cups. Eastman says that the results of testing, analysed by Thomas Osimitz of Science Strategies, a consulting firm in Charlottesville, Virginia, and his colleagues, verified that Tritan's monomers do not bind to oestrogen or androgen receptors 6 . In 2011, George Bittner, a neurobiologist at the University of Texas at Austin and the chief executive of Austin-based chemical-testing company CertiChem, reported that 92% of 102 commercially available plastic products leached chemicals with oestrogenic activity 7 . This included plastics advertised as BPA-free. The reason, Bittner says, is that additives in plastics \u2014 such as stabilizers and lubricants \u2014 can also bind to oestrogen receptors, as can some of the plastic monomers themselves. Tritan resins produced by Eastman were among the polymers that showed oestrogenic activity in Bittner's assays. When PlastiPure, a sister company of CertiChem, produced a brochure publicizing these results, Eastman sued. The company's lawyers maintained that the  in vitro  test used by CertiChem \u2014 which involved oestrogen-sensitive breast cancer cells grown in culture \u2014 is not a definitive assay for oestrogenic activity. In a letter to the editor of the journal  Food and Chemical Toxicology , Bittner countered that his assays are up to 200 times more sensitive than the tests Osimitz analysed to demonstrate Tritan's safety 8 . Bittner had support: Wade Welshons, who studies endocrine disruptors at the University of Missouri-Columbia, independently tested five Tritan bottles using the same assay as Bittner. In a deposition entered during the trial, Welshons reported that he found detectable oestrogenic activity in each test. But the jury ruled in Eastman's favour, and the judge barred Bittner, PlastiPure and CertiChem from making claims about Tritan's oestrogenic activity. Eastman stands by the results reported by Osimitz. And, unlike Bittner, Welshons suspects that the oestrogenic activity he found is attributable not to the Tritan polymer itself, but to other compounds added during plastics manufacturing. He is not the only one concerned about the complex mixtures of chemicals used to make plastics. In 2012, the world produced some 280 million tonnes of plastic. According to a model based on the United Nations' Globally Harmonized System of Classification and Labelling of Chemicals, more than 50% of these plastics contain ingredients that can be hazardous (see   Nature   494 , 169\u2013171; 2013). Some are carcinogenic; others are oestrogenic. It is not yet clear how many of these chemicals are dangerous at the concentrations found in the plastics. But mixed together, the chemicals could have synergistic effects. Watson and Vi\u00f1as recently studied the effect of the oestrogen mimics BPA, BPS and nonylphenol (a detergent precursor) on cultured rat pituitary cells. They found that a combination of two or three of the compounds caused greater disruption to the oestrogen-signalling system \u2014 and did so at lower concentrations \u2014 than did a single compound 9 . \u201cWe don't experience any of these chemicals alone,\u201d Watson says. \u201cA lot of other chemicals mimic oestrogens.\u201d Ideally, says Watson, the next generation of chemicals would be tested for effects on oestrogen signalling before widespread deployment in food containers. To that end, she and a group of biologists and chemists have put together a plan called TiPED, or Tiered Protocol for Endocrine Disruption. Under this testing system, newly synthesized chemicals would be evaluated for endocrine-disrupting potential at five different stages, from initial computational analysis of structure to whole-animal experiments. The goal is to form a consortium of independent laboratories that would test chemicals on request by plastics companies. Convincing these companies to participate will be a challenge, Watson acknowledges. But there is an incentive, she argues, because companies can suffer from bad press, lost business and lawsuits when a chemical they produce or use is linked to human health concerns. \u201cWhen it gets proved that an individual chemical is a problem,\u201d says Watson, \u201cthey're going to have to, as an industry, completely retool.\u201d The TiPED proposal is designed to ensure that endocrine-disrupting chemicals no longer reach the market. For Watson and many other researchers, the current situation raises concern because there are so many untested compounds found in countless plastic products. Those chemicals, she says, \u201care really all around us\u201d. \n                     Toxicology: The learning curve 2012-Oct-24 \n                   \n                     US opts not to ban BPA in canned foods 2012-Apr-01 \n                   \n                     Toxicology: The big test for bisphenol A 2010-Apr-21 \n                   \n                     Bisphenol A link to heart disease confirmed 2010-Jan-12 \n                   \n                     Bisphenol A linked to disease in humans 2008-Sep-16 \n                   \n                     Blog post: Europe's food agency maintains BPA stance \n                   \n                     Blog post: Europe bans bisphenol A from baby bottles \n                   \n                     US National Institute of Environmental Health Sciences: BPA \n                   Reprints and Permissions"},
{"file_id": "507294a", "url": "https://www.nature.com/articles/507294a", "year": 2014, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "With a unique programme, the US government has managed to drive the cost of genome sequencing down towards a much-anticipated target. In Silicon Valley, Moore's law seems to stand on equal footing with the natural laws codified by Isaac Newton. Intel co-founder Gordon Moore's iconic observation that computing power tends to double \u2014 and that its price therefore halves \u2014 every 2 years has held true for nearly 50 years with only minor revision. But as an exemplar of rapid change, it is the target of playful abuse from genome researchers. In dozens of presentations over the past few years, scientists have compared the slope of Moore's law with the swiftly dropping costs of DNA sequencing. For a while they kept pace, but since about 2007, it has not even been close. The price of sequencing an average human genome has plummeted from about US$10 million to a few thousand dollars in just six years (see \u2018Falling fast\u2019). That does not just outpace Moore's law \u2014 it makes the once-powerful predictor of unbridled progress look downright sedate. And just as the easy availability of personal computers changed the world, the breakneck pace of genome-technology development has revolutionized bioscience research. It is also set to cause seismic shifts in medicine. In the eyes of many, a fair share of the credit for this success goes to a grant scheme run by the US National Human Genome Research Institute (NHGRI). Officially called the Advanced Sequencing Technology awards, it is known more widely as the $1,000 and $100,000 genome programmes. Started in 2004, the scheme has awarded grants to 97 groups of academic and industrial scientists, including some at every major sequencing company. It has encouraged mobility and cooperation among technologists, and helped to launch dozens of competing companies, staving off the stagnation that many feared would take hold after the Human Genome Project wrapped up in 2003. \u201cThe major companies in the space have really changed the way people do sequencing, and it all started with the NHGRI funding,\u201d says Gina Costa, who has worked for five influential companies and is now a vice-president at Cypher Genomics, a genome-interpretation firm in San Diego, California. \n               A giant's legacy \n             The $1,000 genome programme, now close to achieving its goal, will award its final grants this year. As technology enthusiasts look to future challenges, the coming milestone raises questions about how the roughly $230-million government programme managed to achieve such success, and whether its winning formula can be applied elsewhere. It benefited from fortuitous timing and the lack of an entrenched industry. But Jeffery Schloss, director of the division of genome sciences at the NHGRI in Bethesda, Maryland, who has run the programme from its inception, says that its achievements also suggest that there are ways to navigate public\u2013private partnerships successfully. \u201cOne of our challenges is to figure out what is the right role for the government; to not get in the way, but feed the pipeline of private-sector technology development,\u201d he says. The quest to sequence the first human genome was a massive undertaking. Between 1990 and the publication of a working draft in 2001, more than 200 scientists joined forces in a $3-billion effort to read the roughly 3 billion bases of DNA that comprise our genetic material (International Human Genome Sequencing Consortium  Nature   409 , 860\u2013921; 2001 ). It was a grand but sobering success. The project's advocates had said that it would reveal 'life's instruction book', but in fact it did not make it possible to interpret how the instructions encoded in DNA were transformed into biology. Understanding how DNA actually influences health and disease would require studying examples of the links between genes and biology in thousands, perhaps millions, more people. The dominant technology at the time was Sanger sequencing, an inherently slow, labour-intensive process that works by making copies of the DNA to be sequenced that include chemically modified and fluorescently tagged versions of the molecule's building blocks. One company, Applied Biosystems in Foster City, California, provided the vast majority of the sequencers to a limited number of customers \u2014 generally, large government-funded laboratories \u2014 and there was little incentive for it to reinvent its core technology. Still, researchers had seen some advances, including robots that replaced some human work and improvements in devices capable of handling small amounts of liquid. At a 2002 meeting convened by the NHGRI, scientists predicted that such developments would drive costs down at least 100-fold over the next five years. But that was not enough. They debated what price target would make human genome sequencing routine, the kind of thing a physician might order to help diagnose a patient \u2014 on a par with a magnetic resonance imaging scan. \u201cSomebody threw out, to great rolling of eyes, 'a thousand dollars',\u201d recalls Schloss. That seemed too ambitious, given the state of the technology. \u201cThe risk associated with that is not one that your normal investor is willing to spend any money on,\u201d says Eric Eisenstadt, a retired official from the US government's Defense Advanced Research Project Agency who is now a consultant in Reston, Virginia. So Schloss and the NHGRI stepped in and began to fund basic research on entirely new methods of sequencing, as well as industrial research to develop these technologies for commercial use. The mixture of applied and academic research within a single programme was uncommon at the National Institutes of Health (NIH), the NHGRI's parent agency. The project was also more nimble than the typical NIH grant programme because it allowed the agency to make small awards for work considered promising but risky. \u201cThat flexibility is unusual for the NIH,\u201d says Schloss.  There's a tremendous amount of altruistic sharing of knowledge.  Furthermore, the programme provided support to sequencing companies that could compete with Applied Biosystems. One of the companies funded in the first round of grants, 454 Life Sciences of Branford, Connecticut, was the brainchild of entrepreneur Jonathan Rothberg. It aimed to develop a method that was faster and cheaper than Sanger sequencing by using a much simpler sample-preparation procedure and running many sequencing reactions simultaneously on a solid surface. But as he tried to round up funding, Rothberg heard the same refrain over and over from investors. \u201cPeople said, 'Why would you want to sequence DNA fast? We've already done the Human Genome Project.'\u201d A $7-million award from the NHGRI allowed the company to commercialize a technology called pyrosequencing, which was the first to begin chipping away at Applied Biosystems' monopoly. The funding commitments also ultimately helped to convince private investors to enter the market. Stephen Turner, founder and chief technology officer of Pacific Biosciences in Menlo Park, California, says that his company's 2005 NHGRI grant of $6.6 million helped to attract subsequent venture-capital funding. The NHGRI's imprimatur had convinced investors to provide the much more substantial money that the company needed to commercialize its technology, which observes DNA synthesis as it occurs in real time. \u201cHaving experts in sequencing technology give us a favourable score was hugely influential,\u201d says Turner. The NHGRI's investments \u2014 typically a few million dollars or less \u2014 could not by themselves nurse a technology from lab to market. But they could fund parts of it, such as work on improving a dye, a piece of circuitry or a laser, or tests of combinations of components. The programme has invested $88 million in technologies based on nanopores and nanogaps. The form of this technology closest to the market involves reading bases as they are threaded through a pore (see  Nature 456, 23\u201325; 2008 ), a method that has long promised to save costs and time by reading DNA while it is processed. It would negate the need for expensive and slow reactions to make lots of copies of the molecule. But solving basic issues, including how to move the DNA through the pore slowly enough, has been a major challenge. The NHGRI has funded work to overcome these hurdles \u2014 including $9.3 million given to collaborators of the company now ushering the concept to market, UK-based Oxford Nanopore Technologies (see  Nature   http://doi.org/rvm ; 2014 ). Turner says that such investments have helped to cut sequencing costs before the technology hits the shelves. The $1,000 genome project seeded so many companies and labs that it populated the entire industry with expertise, say sequencing researchers. One of the beneficiaries of that is Illumina in San Diego, currently the market leader in sequencing machines. Illumina, whose technology reads out many short stretches of DNA, has acquired multiple companies and many scientists who were once supported by the NHGRI. \u201cIt's through acquisitions that Illumina has become stronger and stronger,\u201d says Mostafa Ronaghi, the company's chief technology officer. But Schloss's programme also forced competitors to exchange expertise at an annual progress meeting that has become a must-attend event. \u201cThat meeting is one of the most important venues for keeping an eye on what's happening in sequencing technology development,\u201d says Turner. \u201cThere's a tremendous amount of altruistic sharing of knowledge that occurs.\u201d \n               Cut-price caveats \n             Some scientists question certain choices made by the programme. \u201cThere's been a lot of money given to the nanopore space, but the objective of nanopore really hasn't hit the mark,\u201d says Costa, for example. Kevin McKernan, who worked with Costa to develop SOLiD \u2014 a sequencing technology based on an enzyme that joins pieces of DNA together \u2014 points out that many of the companies funded by the $1,000 genome programme ultimately failed. \u201cTheir hit rate probably isn't much better than a venture capitalist,\u201d he says. But others give Schloss and the programme credit for spreading their investments over an array of academic and industrial work that is diverse enough to allow progress in the face of failures. Many NHGRI-funded firms are now defunct \u2014 including 454, and Helicos BioSciences of Cambridge, Massachusetts \u2014 but other grant recipients have moved the field forward, often using ideas generated by the shuttered firms. \u201cThe NHGRI funded smaller companies and academic groups to create a pipeline of technologies,\u201d says Ronaghi. \u201cThey didn't decide which technologies to bet on.\u201d Working out what the $1,000 genome programme got right has emerged as a key question as Schloss and the NHGRI shape its successor. Sequencing still needs much improvement, especially in terms of quality. For all of Sanger sequencing's high cost, it remains the benchmark for accuracy. And sequencing costs are no longer dropping as quickly as they were a few years ago. But researchers are optimistic that another technology will emerge to challenge Illumina. Most think, in fact, that the crucial questions for the field will shift away from technology. Now that sequencing is cheap enough to talk about scanning every patient's genome, or at least the protein-coding portion of it, it is still not clear how that information will translate into improved care (see  Nature   http://doi.org/rvq ; 2014 ). These more complex issues will require another great leap in genomic science \u2014 one that could make the trouncing of Moore's law seem easy. \n                 Tweet \n                 Follow @NatureNews \n               \n                 See Editorial \n                 page 273 \n               \n                     How to get ahead 2014-Mar-19 \n                   \n                     Global genomic data-sharing effort kicks off 2014-Mar-06 \n                   \n                     Data from pocket-sized genome sequencer unveiled 2014-Feb-14 \n                   \n                     Is the $1,000 genome for real? 2014-Jan-15 \n                   \n                     Human genomics: The genome finishers 2009-Dec-16 \n                   \n                     My genome. So what? 2008-Nov-05 \n                   \n                     Nature  special: The human genome at ten \n                   \n                     Sequencing costs from the NHGRI \n                   Reprints and Permissions"},
{"file_id": "507414a", "url": "https://www.nature.com/articles/507414a", "year": 2014, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Thirty years after the study of ancient DNA began, it promises to upend our view of the past. Before ancient DNA exposed the sexual proclivities of Neanderthals or the ancestry of the first Americans, there was the quagga. An equine oddity with the head of a zebra and the rump of a donkey, the last quagga ( Equus quagga quagga ) died in 1883. A century later, researchers published 1  around 200 nucleotides sequenced from a 140-year-old piece of quagga muscle. Those scraps of DNA \u2014 the first genetic secrets pulled from a long-dead organism \u2014 revealed that the quagga was distinct from the mountain zebra ( Equus zebra ). More significantly, the research showed that from then on, examining fossils would no longer be the only way to probe extinct life. \u201cIf the long-term survival of DNA proves to be a general phenomenon,\u201d geneticists Russell Higuchi and Allan Wilson of the University of California, Berkeley, and their colleagues noted in their quagga paper 1 , \u201cseveral fields including palaeontology, evolutionary biology, archaeology and forensic science may benefit.\u201d At first, progress was fitful. Concerns over the authenticity of ancient-DNA research fuelled schisms in the field and deep scepticism outside it. But this has faded, thanks to laboratory rigour that borders on paranoia and sequencing techniques that help researchers to identify and exclude contaminating modern DNA. These advances have fostered an ancient-genomics boom. In the past year, researchers have unveiled the two oldest genomes on record: those of a horse that had been buried in Canadian permafrost for around 700,000 years 2 , and of a roughly 400,000-year-old human relative from a Spanish cavern 3 . A Neanderthal sequence every bit as complete and accurate as a contemporary human genome has been released 4 , as has the genome of a Siberian child connecting Native Americans to Europeans 5 . Enabling this rush are technological improvements in isolating, sequencing and interpreting the time-ravaged DNA strands in ancient remains such as bones, teeth and hair. Pioneers are obtaining DNA from ever older and more degraded remains, and gleaning insight about long-dead humans and other creatures. And now ancient DNA is set to move from the clean-rooms of specialists to the labs of archaeologists, population geneticists and others. Thirty years after the quagga led the way,  Nature  looks to the field's future. \n               A million-year-old genome \n             Ludovic Orlando, an evolutionary biologist at the University of Copenhagen, had low expectations when he started sequencing DNA from a 560,000-to-780,000-year-old horse leg bone. His colleague, Eske Willerslev, had discovered the bone buried in the permafrost of the Canadian Yukon in 2003. Then he had chucked it into a freezer, waiting for technological improvements that would allow the bone's degraded DNA to be read. (Freezers in ancient-DNA labs brim with such 'wait and see' samples.) On a Sunday evening in 2010, Willerslev called Orlando to say that the time had come. Orlando was unconvinced: \u201cI started the project with the firm intention of proving that it was not possible,\u201d he says. Sequencing ancient DNA is a battle against time. After an organism dies, the long strands of its DNA fissure into ever shorter pieces, helped along by DNA-munching enzymes. Low temperatures slow this process, but eventually the strands become so short that they contain little information. To read the horse's genome, Orlando needed to shepherd useful DNA fragments through the harsh enzymatic treatments used to extract them and ready them for sequencing. Orlando and his team found that the preparation lost vast quantities of fragments. But with a few tweaks to the experimental protocol, such as reducing the extraction temperature, the researchers captured ten times more scraps of DNA than before \u2014 and produced a draft of the oldest genome on record 2 . Using a similar approach, Svante P\u00e4\u00e4bo, a geneticist at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, and his team turned their attention to 400,000-year-old remains from the Sima de los Huesos cavern in northern Spain, which may have been a burial pit for recent relatives of modern humans called hominins (see 'Hidden heritage'). In the pit, the bones remained at stable, low temperatures, slowing the breakdown of DNA. \u201cIf you could have told the hominins where to leave their bones, you may have chosen that site,\u201d says Matthias Meyer, a molecular biologist at P\u00e4\u00e4bo's institute who is leading the efforts. Last December, the team reported 3  roughly 16,300 letters of a Sima de los Huesos individual's mitochondrial genome \u2014 the DNA from power-generating structures in its cells. The sequence revealed an unexpected relationship between the Sima de los Huesos remains and the Denisovans, an archaic group of humans that P\u00e4\u00e4bo's team had discovered in Russia's Altai Mountains thousands of kilometres away. Meyer and his colleagues hope to improve their methods enough to obtain some or all of the Sima de los Huesos individual's nuclear genome, the DNA from the nuclei of its cells. \u201cIt must be possible,\u201d says Meyer. \u201cI won't rest until this has been done.\u201d It is now a matter of when, not if, someone will produce a genome from an Arctic animal buried in permafrost for longer than 1 million years, says Meyer. But he and P\u00e4\u00e4bo want to push the limits of ancient DNA in hominin specimens from warmer locales, such as fossils of  Homo erectus , the common ancestor of humans and Neanderthals, found in Asia. And Orlando says that researchers may have luck using new extraction techniques on previously vexing remains such as Egyptian mummies or  Homo floresiensis , a small hominin at least 18,000 years old that was found in a cave on the Indonesian island of Flores. \u201cIt opens a great number of places where there are lots of important stories going on, such as the Middle East or the tropics,\u201d he says. \n               Ghosts in the code \n             A few years ago, David Reich discovered a ghost. Reich, a population geneticist at Harvard Medical School in Boston, Massachusetts, and his team were reconstructing the history of Europe using genomes from modern people, when they found a connection between northern Europeans and Native Americans. They proposed that a now-extinct population in northern Eurasia had interbred with both the ancestors of Europeans and a Siberian group that later migrated to the Americas 6 . Reich calls such groups ghost populations, because they are identified by the echoes that they leave in genomes \u2014 not by bones or ancient DNA. Ghost populations are the product of statistical models, and as such should be handled with care when genetic data from fossils are lacking, says Carlos Bustamante, a population geneticist at Stanford University in California. \u201cWhen are we reifying something that's a statistical artefact, versus when are we understanding something that's a true biological event?\u201d Sometimes these statistical spectres get a body. Last year, Willerslev's team reported 5  the genome from 24,000-year-old remains dubbed the Mal'ta boy. The results showed that the boy, who had been found in central Siberia, came from a population related to both modern Native Americans and modern Europeans, matching Reich's prediction (see  Nature   http://doi.org/r2b ; 2013 ). \u201cIt's a spectacular find,\u201d he says. Ghost populations also lurk in ancient DNA. While analysing high-quality genomes of a Neanderthal and a Denisovan, a team led by Reich and Montgomery Slatkin at the University of California, Berkeley, noticed a peculiar pattern: present-day sub-Saharan Africans are more closely related to Neanderthals than they are to Denisovans 4 . But evidence from other ancient genomes suggested that the two archaic groups were equally related to present-day Africans. After weighing the possibilities, the scientists realized that they might have uncovered another ghost population. The puzzle could be solved, they theorized, if Denisovans had interbred with a species that had left Africa perhaps more than 1 million years ago and branched off from the common ancestor of humans, Neanderthals and Denisovans. Subsequent Denisovans would have inherited DNA sequences that present-day Africans lack, explaining why Neanderthals seem to be closer kin to Africans. Reich's team is analysing genetic signatures in humans with Denisovan DNA to establish when the Denisovans mated with this mystery population \u2014 information that could narrow the range of fossils to which it might belong. Genomes studied by P\u00e4\u00e4bo's lab, principally the Sima de los Huesos remains, may also reveal clues. Reich is not the only one conjuring ghosts. Chris Stringer, a palaeoanthropologist at the Natural History Museum in London, has proposed that the 900,000-year-old hominin  Homo antecessor , known from fossils found near Sima de los Huesos, could be part of the ghost population. If it had interbred with an ancestor of the Denisovans and the Sima de los Huesos hominins, it could explain the relationship between the two groups of remains. Testing that hypothesis would require the elusive Sima de los Huesos nuclear DNA. But Reich is optimistic that P\u00e4\u00e4bo and his team will pull it off. \u201cThey've done miracles before in that lab and they may succeed again.\u201d \n               The Neanderthal within \n             \u201cWe don't need bones necessarily to find ancient DNA,\u201d says Josh Akey, a population geneticist at the University of Washington in Seattle. \u201cWe can find the remnants of ancient DNA floating around in contemporary populations.\u201d If early human populations bred with Neanderthals and Denisovans, their descendants should carry short segments of archaic-human DNA. Researchers such as Akey are beginning to catalogue these segments to learn about the biology of archaic humans. Unlike the hunt for ghost populations, which relies on statistical population models, this approach allows researchers to identify specific regions of the genome acquired by interbreeding. In January, independent teams led by Akey 7  and Reich 8  pieced together a substantial portion \u2014 about 20% and 40% respectively \u2014 of the Neanderthal genome from bits lurking in the genomes of hundreds of living humans. Their research indicated that some Europeans and Asians had gained genes involved in skin and hair from Neanderthals, possibly helping their ancestors to adapt to cold climates by providing thicker skin, more hair and fewer pores (see  Nature   http://doi.org/rz9 ; 2014 ). But giant swathes of the modern genomes were devoid of Neanderthal ancestry, hinting that many Neanderthal genes might have been harmful in modern humans. Akey's team identified 7  one such region around the gene  FOXP2 , which is involved in speech and language. \u201cIt's extremely compelling evidence that there were fitness costs to interbreeding,\u201d he says. These discoveries are only the beginning. The Akey and Reich teams found that the genomes of east Asians possess, on average, slightly more Neanderthal DNA than do people of European ancestry. Akey sees this as possible evidence that Neanderthals interbred with ancient humans on at least two separate occasions: once with the ancestors of all Eurasians, and later with a population ancestral only to east Asians. And Akey believes that humans are likely to bear genetic scraps from other extinct species, including some that interbred with the ancestors of humans in sub-Saharan Africa. \n               Ancient DNA for the masses \n             For much of the past 30 years, the sensitivity of the polymerase chain reaction (PCR), the method used to amplify ancient DNA, made it prone to contamination. The field's leaders often greeted the work of outsiders with suspicion, earning some of them the title 'the PCR police'. And in recent years, palaeogenomics has been the domain of specialist labs such as P\u00e4\u00e4bo's, with the expertise and money to obtain and screen hundreds of fossils to find the few that yield enough DNA to sequence an entire genome. That is set to change. New procedures mean that researchers can now reliably obtain DNA from all but the most degraded samples, and then sequence only the portions of a genome that they are interested in. \u201cI'm still surprised that there are so few labs in the world that do this,\u201d says Johannes Krause, a palaeogeneticist at the University of T\u00fcbingen, Germany, who led much of the Denisovan work while in P\u00e4\u00e4bo's lab. \u201cIt's not rocket science.\u201d Gradually, new researchers are entering the field. \u201cIf I can break in, then anyone can,\u201d jokes Bustamante. His research originally focused on ancestry in current human populations. Then, a few years ago, he got a phone call about a mummy. An international team had sequenced the genome of \u00d6tzi, a 5,300-year-old frozen corpse found in the Tyrolean Alps of Italy in 1991. The researchers wondered if Bustamante could help them to make sense of the ice-man's ancestry. Together, they showed that \u00d6tzi was more closely related to humans who now live in Sardinia and Corsica than those in central Europe, evidence that the population of Europe when he was alive looked very different to how it does today 9 . Bustamante has since plunged into the world of ancient DNA. His team is sequencing samples that chart the arrival of farming in Bulgaria, the transatlantic slave trade in the Americas and dog domestication. The group is developing tools to make sequencing ancient DNA cheaper and easier. \u201cWe want to democratize the field,\u201d says Bustamante. Reich, too, sees ancient DNA becoming more egalitarian. His lab's growing interest in areas of human history such as the advent of agriculture or the history of the Indian subcontinent has led it to analyse \u2014 often in bulk \u2014 remains less rarefied than the scarce Neanderthal samples that first lured him to the field. Last year, Reich was part of a team that reported 10  an analysis of mitochondrial DNA from 364 European samples between 5,500 and 1,550 years old, to identify major population shifts in Neolithic Europe. Ancient genomics is also set to solve long-standing questions about when and where humans domesticated animals such as dogs, cattle and chickens. A 2013 study 11  of 18 mitochondrial genomes from ancient dogs and wolves, for instance, suggested that European hunter-gatherers domesticated wolves from a population that is now extinct. Researchers are also returning to the questions that launched the field 30 years ago. Around the time that Orlando's team began sequencing the 700,000-year-old horse, it also turned its attention to a much younger sample \u2014 from the quagga. The effort to sequence the full quagga genome is part of large project to understand the evolutionary relationship between living and extinct horses, zebras and donkeys, and to identify the genetic basis for certain traits. \u201cI was thinking it would be cool to do the oldest, but also the first \u2014 where ancient DNA started,\u201d says Orlando. \u201cIt shows the progress the field has made.\u201d \n                     Ancient European genomes reveal jumbled ancestry 2014-Jan-02 \n                   \n                     Hominin DNA baffles experts 2013-Dec-04 \n                   \n                     Mystery humans spiced up ancients\u2019 sex lives 2013-Nov-19 \n                   \n                     Prehistoric genomes reveal European origins of dogs 2013-Nov-14 \n                   \n                     First horses arose 4 million years ago 2013-Jun-26 \n                   \n                     Ancient DNA: Curse of the Pharaoh's DNA 2011-Apr-27 \n                   \n                     Nature PastCast: The Man-Ape of South Africa \n                   \n                     Ludovic Orlando \n                   \n                     Matthias Meyer \n                   \n                     David Reich \n                   \n                     Joshua Akey \n                   \n                     Carlos Bustamante \n                   Reprints and Permissions"},
{"file_id": "507418a", "url": "https://www.nature.com/articles/507418a", "year": 2014, "authors": [{"name": "Ken Garber"}], "parsed_as_year": "2006_or_before", "body": "Despite a long record of failure, a few immunologists continue to pursue precisely targeted therapies for autoimmune diseases. Ever since Ed Wiley learned that he had type 1 diabetes in 1997, he has fretted over his meals, blood glucose levels and the daily programming of his insulin pump. Wiley, a statistician who lives outside Boulder, Colorado, and works on big data analytics, has learned to live in a state of hypervigilance. Finding the right dose of insulin turned out to be more art than science and, like many with the disease, his control began slipping away with time. By 2008, he says, \u201cmy insulin doses just basically didn't work any more\u201d. Unable to reliably anticipate what he needed, Wiley was having severe hypoglycaemic episodes and was at risk of diabetic seizures and long-term disability. On his endocrinologist's advice, he enrolled in a clinical trial of a novel drug called BHT-3021. Although technically a vaccine, BHT-3021 is not designed to stimulate an immune response, but rather to shut it down, stopping the body's errant attack against cells in the pancreas that produce insulin. The goal is to achieve immune tolerance. Drugs that broadly suppress immunity are the standard treatment for autoimmune disorders such as multiple sclerosis (MS), rheumatoid arthritis and lupus. But these drugs can lead to life-threatening infections, and do not address the cause of the disease. Tolerance therapies are different. They aim to target only the immune cells that react to a specific antigen, a substance \u2014 in Wiley's case, the insulin precursor proinsulin \u2014 that might trigger a response. \u201cWhy shut down a major arm of the immune system, if we're just trying to restore tolerance to one antigen?\u201d asks immunologist Larry Steinman of Stanford University in California, who developed BHT-3021. This strategy, known as antigen-specific tolerance, is simple in concept. But, so far, dozens of clinical trials have failed to achieve a categorical success. And there is a fine line between calming the immune system and stimulating it, so these efforts risk making a disease worse \u2014 as happened in an MS trial some 15 years ago. BHT-3021 is one of a new wave of treatments conceived by five veterans of the field that promises to do better. Early-stage trials show encouraging results in people with MS and type 1 diabetes. \u201cA number of these approaches really are going to work,\u201d predicts David Wraith, an immunologist at the University of Bristol, UK, and one of the few persisting in pursuing the work. \u201cThe science has caught up.\u201d \n               Autoimmune override \n             The approaches are varied, but they all rely on the body's natural ability to distinguish its own substances from those of foreign intruders. When bacteria or viruses invade, some are swallowed by specialized antigen-presenting cells, or APCs. These chop up the bacterial or viral antigens and present them to T cells, white blood cells that orchestrate the immune response. The T cells then proliferate and launch a coordinated attack. APCs also ensure that normal daily maintenance does not turn deadly. As the body's own cells continuously die and are replenished, APCs mop up the debris and present those self-antigens to T cells along with an array of proteins that signal that these cellular remnants pose no danger. In autoimmunity, for unknown reasons, this protective mechanism goes awry. The new therapies are designed to override this dysfunction by deliberately sending the relevant antigen to tissues where the body is likely to see it as a non-threatening part of itself (see 'Teaching tolerance'). Most of the therapies developed so far target MS, which occurs when the immune system attacks the myelin sheath that protects neurons in the brain and spinal cord. Immunologist Stephen Miller of Northwestern University in Chicago, Illinois, designed a therapy 1  that he and neurologist Roland Martin, now at University Hospital Zurich in Switzerland, began testing in patients in 2009. During the treatment, the patients' white blood cells are extracted, chemically linked to seven myelin antigens, then reinfused. The cells make their way to the spleen, where they die and release the antigen, which is picked up by APCs. Wraith's drug 2 , ATX-MS-1467, uses four peptides, or pieces, of a myelin protein commonly attacked in MS. These injected antigens are taken up by immature APCs, which are incapable of stimulating T cells and instead inactivate them or convert them to a T-cell type that maintains tolerance. Krzysztof Selmaj's group at the Medical University of Lodz in Poland designed a similar therapy for the disease using three myelin peptides delivered through a patch that users wear on their skin 3 . Instead of protein fragments, Steinman's diabetes treatment consists of circular pieces of DNA carrying the proinsulin gene, injected into muscle 4 . The proinsulin protein is manufactured in the muscle cells, and is then secreted, taken up by APCs and presented to T cells. This produces \u201ca signal that doesn't invoke danger but invokes tolerance\u201d, says Steinman. So far, this treatment and the other new therapies have been tested in fewer than 150 patients, but industry onlookers say they show promise. \n               Dangerous ground \n             The treatments not only have to overcome strong autoimmunity, they must also avoid making it worse. \u201cWe need to be extremely cautious,\u201d says Gerald Nepom, an immunologist at the Benaroya Research Institute in Seattle, Washington. Any novel manipulation of the immune system involves some risk. In 2006, an antibody-based treatment developed by the German drug company TeGenero was given to six healthy volunteers in a UK trial. Designed to quell the autoimmune response by a mechanism different from antigen-specific tolerance, it instead caused a massive immune response and multiple-organ failure 5 . The participants survived, and investigators have since implemented safer dosing protocols, but researchers know that an immune response can quickly go wrong. \u201cPeople ask me what keeps me up at night,\u201d says Steinman. \u201cUntil we have quite a few patients under our belts for some time, it's the worry that we're going to make things worse.\u201d Antigens can easily trigger immunity instead of tolerance, because there is a delicate balance between the two fates. Drug dose, delivery route, tissue destination and unpredictable changes in T-cell identity all matter. In a trial for an MS treatment that began in 1998 (ref.  6 ), doctors gave patients a single modified myelin peptide, but the trial was halted after three of the first eight recipients suffered worsening symptoms; one was left unable to walk. All three recovered with immunosuppressive treatment, but tests clearly implicated the experimental therapy, and the researchers ultimately worked out that they had extrapolated too high a dose from earlier  in vitro  studies. \u201cWe were both frustrated and also shocked,\u201d says Martin, a lead investigator on the trial. Most trials so far have simply failed to work. In 2009, a trial of a myelin peptide antigen involving 612 people with MS showed no benefit over a placebo 7 . One likely reason is that the immune response in most autoimmune diseases can shift from one antigen to another as tissue damage progresses. Miller documented this phenomenon, known as epitope spreading, in animal models 20 years ago 8 . Martin points out that the failed 2009 trial used a single antigen, and adds that the patients involved were at a very advanced stage of the disease, when the immune system is no longer the main cause of neuronal damage. Wraith says that the field has learned from its mistakes. The new therapies all incorporate multiple antigens to anticipate epitope spreading, for example. And researchers are paying close attention to other relevant factors, such as how the drugs are administered. In the past, says Christophe Benoist, an immunologist at Harvard Medical School in Boston, Massachusetts, it was often more of a gamble. The approach, he says, was, \u201cLet's just put the antigen in and hope something good happens\u201d. Richard Ransohoff, an MS researcher at the Cleveland Clinic in Ohio, has faith in the new therapies, which build on recent advances in understanding antigens and T cells. \u201cThese are all very experienced people who understand the complexity of what they're trying to do,\u201d he says. That is not to say that the mechanisms of tolerance have been completely worked out. \u201cWe're working furiously,\u201d says Steinman, but he admits that they are operating in \u201ca vast ocean of ignorance in between icebergs of knowledge\u201d. Waiting for that perfect understanding, however, seems foolish. \u201cWe have to take small steps and see what happens,\u201d he says. Results from the latest wave of trials are reassuring. Martin's clinical team gave nine patients a single injection of the manipulated immune cells, in escalating doses. The treatment seems to be safe, and the four patients receiving the highest doses showed a reduction in the number of T cells targeting self-antigens 9 . \u201cThat was a very positive proof-of-concept study,\u201d says Nepom, who was not involved in any of the trials. The most promising trial, he adds, was a 30-patient test of Selmaj's therapy. Compared with a placebo, the treatment achieved a statistically significant drop in MS disease activity, as measured by magnetic resonance imaging of the brain. Patients assigned to the therapy also had far fewer relapses 10 . In Wraith's ATX-MS-1467 trial, sponsored by Apitope in Diepenbeek, Belgium, 43 patients received the treatment in a series of five escalating doses either under or into the skin. Those in the latter group showed a large reduction in MS activity, says Wraith, although this returned three months after the treatment ended. The data have not yet been published. Steinman's 80-patient, placebo-controlled, BHT-3021 diabetes trial established that the drug was safe, and one dosage group showed a statistically significant increase in a marker of insulin secretion and a simultaneous decrease in the number of T cells targeting proinsulin 11 . Wiley believes the treatment has helped. During the 12-week study, he says, he regained control of his insulin dosing. And, subjectively at least, the positive effects have persisted. \n               Moving forward \n             But the legacy of failure has left many researchers \u2014 and drug companies \u2014 deeply sceptical. Even after positive trial results, Martin says, there are \u201cvery few investigators that are masochistic enough over a long time to continue in this field, because it's difficult to get funding\u201d. He and Selmaj are trying to get support for their new MS trials. And Steinman and the company he co-founded, Tolerion of Portola Valley, California, are seeking between US$20 million and $30 million to take their diabetes vaccine to the next stage. \u201cIt's impossible to say when this is going to happen,\u201d Steinman says. His first diabetes trial was sponsored by the biotech giant Genentech, based in South San Francisco, California. But after acquiring the company in 2009, Swiss drug firm Roche sought to get out of type 1 diabetes therapies, Steinman says. The company returned the therapy's licence even before the trial ended, and terminated all future commitments. Others have had more success. Another Swiss drug company, Merck Serono, has already moved Wraith's therapy into phase II to confirm its efficacy. Miller, meanwhile, is planning a phase I trial of a variation on his original approach that uses biodegradable nanoparticles instead of blood cells as antigen carriers 12 . And Chicago-based COUR pharmaceuticals \u2014 co-founded by Miller \u2014 has signed partnerships with two drug companies for trials in people with diabetes and coeliac disease. The next round of trials, Nepom says, should incorporate detailed mechanistic studies \u201cin order to learn whether we've chosen the right antigen, and whether we've chosen the right dose and route\u201d in treated patients. This is because, in diseases such as MS and diabetes, researchers can only guess which antigen triggers the immune response at any point in time. \u201cThat's an incredibly challenging problem,\u201d says Nepom. He heads the Immune Tolerance Network (ITN), a US-led international consortium that allocates roughly $27 million a year from the National Institutes of Health for clinical trials and related studies. In his view, antigen therapies should be used in combination with drugs from a second major category of tolerance treatment. Unlike antigen-specific therapies, these treatments do not inactivate, convert or destroy the relatively small number of T cells that attack a given antigen. Instead, they are designed to tilt the balance of the body's T-cell repertoire away from the subtypes that promote inflammation and towards those that maintain a state of tolerance, without impairing normal immunity against pathogens. These tolerance treatments have worked only temporarily, if at all, in autoimmunity trials. Nepom thinks that combining the two approaches will produce longer-lasting results. The ITN will soon require that all of the antigen trials it supports be combination trials. \u201cThat's definitely the path to go,\u201d agrees Benoist. \u201cWhether that will work or not, who knows. But at least that's a more rational way of doing things.\u201d But pushing combinations does not sit well with some in the field. Miller, for example, doesn't think that the second approach achieves true tolerance, and he fears that combining it with antigen therapies will convolute the results. \u201cIf you want to test tolerance, it really has to be done as an individual entity,\u201d he says. Wraith thinks that adding the other class of treatment may even interfere with antigen-specific tolerance. But the combination approach should reduce risk, say Nepom and ITN founder Jeff Bluestone, an immunologist at the University of California, San Francisco. This is because shifting the overall system towards tolerance should help to blunt any unexpected reaction to antigens. Miller and Wraith say that their treatments have already proved safe in patients, and Wraith debated with Bluestone during a meeting in the Netherlands last October. Wraith calls Bluestone's concerns unfounded. Bluestone's reply: \u201cI hope he's right.\u201d Wiley, for his part, had no problems while taking BHT-3021. The only side effect he noticed was the welcome disappearance of some painful plantar warts. He thinks that BHT-3021 stabilized his body's ability to produce insulin, and would gladly take part in a longer study. \u201cNo question,\u201d he says. \u201cI would jump at the opportunity.\u201d \n                     Drug-free organ transplants without tissue matching 2012-Mar-07 \n                   \n                     Reprogrammed cells trigger immune reactions in mice 2011-May-13 \n                   \n                     Teaching T cells transplant tolerance 1999-Nov-02 \n                   \n                     The peanut papers 1999-Apr-01 \n                   \n                     \n                         Nature Immunology  \n                       \n                   \n                     Focus on immunological tolerance \n                   \n                     Lawrence Steinman \n                   \n                     Stephen Miller \n                   Reprints and Permissions"},
{"file_id": "508028a", "url": "https://www.nature.com/articles/508028a", "year": 2014, "authors": [{"name": "Ron Cowen"}], "parsed_as_year": "2006_or_before", "body": "After years of work in the Antarctic, John Kovac and his team have captured strong evidence for a long-held theory about the Universe\u2019s birth. The taxi ride across Cambridge normally takes just 15\u00a0minutes. But on 10\u00a0March, astronomer John Kovac had a momentous secret to share and wanted to avoid being spotted by reporters or scientific rivals. So he left his office at the Harvard-Smithsonian Center for Astrophysics a few minutes early, and directed his driver to drop him outside the Center for Theoretical Physics at the Massachusetts Institute of Technology (MIT). That left him time to walk around the back of the building and climb a little-used staircase that led straight to the third-floor office of cosmologist Alan Guth. Back in 1980, Guth had proposed an idea that was both startling and appealing. During the first tiny fraction of a second after the Big Bang, he had theorized, the Universe underwent \u2018inflation\u2019: a process of ultra-rapid expansion that took it from subatomic size to a scale so vast that no one will ever see it all. Because the inflation hypothesis posited that far-flung regions of the Universe had started off close together, it solved several enduring cosmological puzzles, including why distant reaches of the Universe look almost identical. Indeed, most cosmologists believed that inflation, or something very much like it, must have happened. Yet for more than three decades, the theory had lacked definitive proof. Now, Kovac told Guth, proof seemed to be in hand. Kovac was principal investigator of a team that had spent 2010 to 2012 monitoring the skies over the South Pole with an ultra-sensitive microwave receiver known as BICEP2. By outfitting BICEP2 with the microwave equivalent of polarizing sunglasses, they had been able to detect subtle patterns in the microwave afterglow of the Big Bang. These patterns were the faint imprint of gravitational waves \u2014 tremors in the fabric of space-time generated during inflation. And now, after painstakingly checking and rechecking those measurements, the team was set to make the results public in exactly one week\u2019s time. The distribution and magnitude of the gravitational waves, Kovac told Guth, were just as predicted by the theory of inflation. Guth grilled Kovac for an hour and a half, going over the team\u2019s draft paper line by line to verify the results. At the end of the meeting, Guth was convinced. \u201cThis is a wonderful result,\u201d he said later \u2014 an \u201cincredibly strong piece of evidence for inflation.\u201d The news was announced to the world in a headline-making press briefing at the Center for Astrophysics on 17\u00a0March. Everyone involved was well aware that the finding came from just one group, and still needed independent confirmation. Nonetheless, the thoughts of many in the field were voiced by Marc Kamionkowski, a cosmologist at Johns Hopkins University in Baltimore, Maryland, who was one of the first to predict the gravitational-wave imprint detected by BICEP2. After the briefing, he told reporters: \u201cTo me, this is as Nobel-prize-worthy as it gets.\u201d But for the 43-year-old Kovac, one of the most gratifying aspects of the day was that two of the founders of inflationary cosmology \u2014 the 67-year-old Guth and 66-year-old Andrei Linde of Stanford University in California \u2014 were watching from the audience. \u201cIt\u2019s a rare thing in science that the originators of the theory are around when testable consequences are actually searched for and ultimately found,\u201d Kovac says. That is why he had taken time away from the team\u2019s feverish pre-announcement preparations to make the clandestine trip to see Guth at MIT. \u201cWe both realized it would be an important moment,\u201d he says. \n               Back to the beginning \n             Mention the prospect of a Nobel prize to Kovac, however, and he politely but firmly changes the subject. \u201cI just think about the work,\u201d he says. It is a subject he talks about earnestly and methodically, while fixing his listener with a piercing blue-eyed stare. It took that kind of intensity to detect the imprint of gravitational waves in the Big Bang\u2019s afterglow \u2014 known more formally as the cosmic microwave background (CMB). The BICEP2 researchers had to measure temperature variations in the CMB as small as one ten-millionth of a kelvin. They had to detect the ever-so-slight polarization in the radiation, and how that varied with position. They had to isolate \u2018B\u00a0modes\u2019: swirling patterns in the polarization that can be caused by gravitational waves. And they had to be extremely careful to make sure that the B\u00a0modes they saw were actually in the CMB, and not caused by other things such as interstellar dust. \u201cIt\u2019s been an emotional roller coaster,\u201d says Kovac, thinking back over his team\u2019s efforts to determine that their signal was real. They had to be especially rigorous when they realized that the strength of their B-mode signal was about twice that extrapolated from non-polarization results reported last year from the European Space Agency\u2019s Planck spacecraft. The BICEP2 team eventually decided to go with its own data \u2014 but the discrepancy is still not fully understood. Adding to the pressure was the threat of being scooped by several other teams that were racing to find the polarization signal. Kovac and his collaborators had to keep their results secret even from their close companions working on the South Pole Telescope, which stands just metres from BICEP2. \u201cWe eat meals with them all the time,\u201d says Kovac. \u201cWe\u2019re friends. We party together.\u201d In fact, the team working on that telescope is led by Kovac\u2019s former thesis adviser, John Carlstrom of the University of Chicago in Illinois. \u201cI\u2019ve been dying to talk with John about this,\u201d says Kovac. \u201cBut professionally, we all know how these things work.\u201d Despite the urgency, Kovac was a perfectionist about the analysis. But finally, he called a team meeting at the South Pole in early December 2013, laying out all the tests the data had passed and the milestones still to be achieved. If the data held up, he told his group, the team was ready to publish. It was an intense meeting because so much was at stake, recalls Kovac. But, he says, \u201cmy role in this process has been to remain calm at all times\u201d. Kovac learned this cool, systematic approach to problems from his father Michael, a former dean of engineering at the University of South Florida in Tampa, who died two years ago. \u201cMy dad was an amazing guy and full of wisdom on how to lead teams, how to organize efforts in science,\u201d says Kovac; he still has trouble talking about his father without choking up. It was Michael Kovac who guided John into science. From the time he could talk, Kovac says, he was always asking questions. \u201cMy dad was able to feed that by answering every question that I asked him about how the world works in a way that explained to me what I wanted to know and led me to another question.\u201d When Kovac was nine, he became fascinated by the integrated circuits his father had been studying. \u201cJohn never met a machine he didn\u2019t want to take apart and find out how it worked,\u201d recalls his mother, Midge. He built a simple calculator from parts his father had brought home from work. Then at the age of ten, he graduated to building a half-a-million-volt van\u00a0de Graaff generator. \u201cIt was fun to zap all my friends at birthday parties,\u201d he says. Another strong influence was Lottie Peterson, a science teacher at his elementary school. Peterson had studied at the University of Chicago during the tenure of Enrico Fermi, the Nobel-prizewinning particle physicist. \u201cShe was able to tell me stories that captivated me about what it really meant to do physics at those high levels,\u201d says Kovac. Peterson also gave Kovac\u2019s family a telescope that he set up behind his house. By the time Kovac entered secondary school, he was determined to be a scientist. After reading every cosmology book in the school library within the first year, he asked for more. Among them was Steven Weinberg\u2019s 1977 account of the moments that followed the Big Bang,  The First Three Minutes: A Modern View of the Origin of the Universe  (Basic Books). Here, Kovac encountered Weinberg\u2019s description of the CMB: \u201ca diffuse background of radio static left over from near the beginning of the universe.\u201d Kovac was hooked on exploring the CMB and the clues it held. \u201cAs a kid, it seemed clear to me that this was the coolest thing in all of science \u2014 there are no bigger questions.\u201d Kovac chose to go to Princeton University in New Jersey in part because some of the major players in the field of CMB astronomy were there. By a stroke of luck, he says, he was assigned a work-study job with one of those researchers, astronomer David Wilkinson, in a group that was planning to build a telescope at the South Pole to search the apparently uniform CMB for regions that were ever so slightly hotter or colder. These temperature variations would signal the existence of fluctuations in the density of the rapidly cooling masses of hydrogen and helium that came out of the Big Bang. Measuring them was tantamount to seeing the \u2018seeds\u2019 that would eventually contract \u2014 as a result of gravity \u2014 to form the galaxies and clusters of galaxies seen today. This prospect so captivated Kovac that he took a year out from university to join the team in Antarctica for the austral summer of 1990\u201391. Wilkinson\u2019s group was soon beaten to the discovery of the first temperature fluctuations in the CMB by the team analysing data from NASA\u2019s Cosmic Background Explorer satellite. But within a year, the Princeton group\u2019s South Pole instrument detected the fluctuations, too, and Kovac was hooked once again. In the years since, he has made a further 22\u00a0visits to the South Pole, often stopping over in New Zealand en route to indulge his hobby of mountain-climbing in the nation\u2019s Southern Alps. On one occasion, he stayed at the South Pole for the entire southern winter, a nine-month interval when planes are typically not permitted to fly to the Antarctic because of the dangers posed by the extreme cold. Kovac is the only principal investigator in the field of CMB astronomy who has \u2018wintered over\u2019, says BICEP2 telescope engineer Steffen Richter. And because of that experience, Richter adds, \u201che knows the telescope down to the last screw; whatever the problem is, if you get his attention and he starts focusing on it, you can solve it with him in very little time\u201d. During his years as a graduate student under Carlstrom, Kovac\u2019s Antarctic trips included work on the Degree Angular Scale Interfero\u00admeter: an array of radio telescopes that the group used to make the first detection of CMB polarization in 2002. \u201cI think the world of John,\u201d says Carlstrom. \u201cHe never really needed advising.\u201d Later, as a postdoc and then a senior fellow at the California Institute of Technology in Pasadena, Kovac worked in Andrew Lange\u2019s laboratory on highly sensitive polarization detectors for the QUAD and BICEP1 radio telescopes, which were also based at the South Pole. \u201cAndrew was an inspiration and a close friend,\u201d says Kovac. \u201cHe entrusted me with a huge amount of responsibility, encouraging me to take charge of the deployment and operation of the BICEP1 telescope and then to step into the role of leader of BICEP2.\u201d On his bookshelf, Kovac keeps a picture of the late Caltech astrophysicist, who in 2010 lost his battle with depression and committed suicide. After Lange\u2019s memorial service, Kovac had a meeting with the three other key researchers on the BICEP2 project \u2014 Clement Pryke of the University of Minnesota in Minneapolis, Jamie Bock of NASA\u2019s Jet Propulsion Laboratory in Pasadena and Chao-Lin Kuo of Stanford. The four agreed to take an equal share in running the team\u2019s South Pole programme, which has now upgraded BICEP2 into a five times more sensitive detector known as the Keck Array, and which will next year add an equally sensitive telescope called BICEP3 that will measure the CMB polarization at a different wavelength. Bock believes that such shared leadership is unique among CMB projects. \u201cI feel our decisions are always better than what one single person would initially propose,\u201d he says, adding that the unusual arrangement \u201cworks for us because we respect and trust each other\u201d. Indeed, at the 17\u00a0March press briefing, all four scientists took turns presenting the BICEP2 findings. The next day, at MIT, Linde addressed a packed lecture hall, giving the first talk on the theoretical implications of the BICEP2 results. Afterwards, Guth reminded the audience that just as the theory of inflation rests on the shoulders of others such as Newton and Einstein, the experimental techniques used by the BICEP2 team members depended on great developments in technology made by those who came before them. Then, as cups of bubbly cider were poured, Guth proposed a toast: \u201cTo the power of scientific reasoning!\u201d Kovac and the rest of the audience cheered. \n                     Gravitational-wave finding causes 'spring cleaning' in physics 2014-Mar-21 \n                   \n                     Telescope captures view of gravitational waves 2014-Mar-17 \n                   \n                     How astronomers saw gravitational waves from the Big Bang 2014-Mar-17 \n                   \n                     How to see quantum gravity in Big Bang traces 2013-Sep-27 \n                   \n                     Polarization detected in Big Bang's echo 2013-Jul-24 \n                   \n                     Cosmology: The test of inflation 2009-Apr-15 \n                   \n                     Nature  special: Waves from the Big Bang \n                   \n                     BICEP2 2014 results \n                   \n                     BCIEP2 (Harvard-Smithsonian CFA site) \n                   \n                     BICEP2 (Caltech site)\u00a0 \n                   \n                     South Pole Telescope \n                   \n                     Planck \n                   Reprints and Permissions"},
{"file_id": "507290a", "url": "https://www.nature.com/articles/507290a", "year": 2014, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Deep brain stimulation has shown promise in treating conditions such as Parkinson's disease. Now scientists are using the technology to eavesdrop on problem neural circuits. For Frank Donobedian, sitting still is a challenge. But on this day in early January, he has been asked to do just that for three minutes. Perched on a chair in a laboratory at Stanford University in California, he presses his hands to his sides, plants his feet on the floor and tries with limited success to lock down the trembling in his limbs \u2014 a symptom of his Parkinson's disease. Only after the full 180 seconds does he relax. Other requests follow: stand still, lie still on the floor, walk across the room. Each poses a similar struggle, and all are watched closely by Helen Bronte-Stewart, the neuroscientist who runs the lab. \u201cYou're making history,\u201d she reassures her patient. \u201cEverybody keeps saying that,\u201d replies the 73-year-old Donobedian, a retired schoolteacher, with a laugh. \u201cBut I'm not doing anything.\u201d \u201cWell, your brain is,\u201d says Bronte-Stewart. Like thousands of people with Parkinson's before him, Donobedian is being treated with deep brain stimulation (DBS), in which an implant quiets his tremors by sending pulses of electricity into motor areas of his brain. Last October, a team of surgeons at Stanford threaded the device's two thin wires, each with four electrode contacts, through his cortex into a deep-seated brain region known as the subthalamic nucleus (STN). But Donobedian's particular device is something new. Released to researchers in August 2013 by Medtronic, a health-technology firm in Minneapolis, Minnesota, it is among the first of an advanced generation of neurostimulators that not only send electricity into the brain, but can also read out neural signals generated by it. On this day, Bronte-Stewart and her team have temporarily turned off the stimulating current and are using some of the device's eight electrical contacts to record abnormal neural patterns that might correlate with the tremors, slowness of movement and freezing that are hallmarks of Parkinson's disease. Until now, such data have been accessible only when a patient's brain is exposed briefly during surgery. But being able to make long-term neural recordings from human patients may become increasingly important \u2014 especially because researchers are experimenting with using DBS as a treatment for many other neurological conditions, including depression, obsessive\u2013compulsive disorder and Tourette's syndrome. The networks involved in such disorders are even less well understood than those involved in Parkinson's disease, says Helen Mayberg, a neurologist at Emory University in Atlanta, Georgia. Devices such as Donobedian's could change that, allowing scientists to start to understand just how unhealthy neural networks misfire in different diseases, and what DBS actually does to the brain. \u201cEvery disease will be different and one size won't fit all,\u201d Mayberg says. \u201cThe new technology is going to enable progress exponentially.\u201d Eventually, adds Bronte-Stewart, engineers could use the new-found knowledge about brain networks to build even more-advanced brain implants \u2014 devices that could interpret the neural signals they record, monitor their own effectiveness and generate personalized treatments. \u201cThis is such an exciting time,\u201d she says. \u201cThis is the first time we're really getting a window into the brain.\u201d \n               'Black box' beginnings \n             The roots of DBS reach back to the 1960s, when Parkinson's disease was commonly treated with surgery to remove or destroy certain brain regions. To pinpoint which areas to target in each patient, some neurosurgeons began to experiment with electrical stimulation. They discovered that the delivery of rapid pulses to the basal ganglia \u2014 a cluster of structures including the STN \u2014 could markedly reduce the patient's tremors. By the late 1980s, long-term brain stimulation started to emerge as an alternative treatment to surgery 1 . DBS has since been approved for the treatment of Parkinson's and other movement disorders by both the US Food and Drug Administration (FDA) and European regulators, and has been used in more than 100,000 people. The biological mechanism underlying DBS remains mysterious, and is a subject of controversy. \u201cWe've been guessing a lot over the last decade or two,\u201d says Michael Okun, a neuroscientist at the University of Florida in Gainesville. \u201cIt would be premature for anyone to claim they know exactly how the therapy works.\u201d There are some clues, however. For example, DBS is not thought to mimic any natural signals in the brain. The high-frequency pulses \u2014 delivered at 130\u2013180 times per second for Parkinson's disease \u2014 exceed the 1\u2013100-hertz frequency range of most natural neural communications. Furthermore, with each 60\u201390-microsecond burst, DBS typically delivers several orders of magnitude more current than any neuron or groups of neurons can produce. And it does not seem to produce permanent changes in the brain, at least not when applied to Parkinson's disease, currently one of the most common targets of the technology. Turning on the current can produce immediate relief from symptoms such as tremor and rigidity. But in many people, symptoms return seconds or minutes after the device is turned off, or the battery runs out \u2014 which happens every 3\u20135 years. Nor does the therapy halt the progressive neurodegeneration associated with the disease; in the long run, patients will typically succumb to symptoms that are not well treated by DBS, such as cognitive deterioration. From the evidence gleaned so far, researchers suspect that DBS does more than affect neural tissue at the site of the electrodes: it somehow disrupts pathological signals that reverberate through multiple brain regions, corrupting their communications (see 'Circuit training'). That theory meshes with the emerging view that Parkinson's disease, as well as depression and many other neuropsychiatric conditions are best understood as network dysfunctions. \u201cThat's a really important realization that has caught on in the last five years,\u201d says Cameron McIntyre, a biomedical engineer at Case Western Reserve University in Cleveland, Ohio. Indeed, it has helped to launch two major neuroscience efforts in the past year: the US Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative, and the European Union's Human Brain Project. The primary target of DBS for Parkinson's disease, for example \u2014 the STN \u2014 sits in the middle of a highly interconnected brain network that helps an individual to control his or her motions. There is some evidence 2  that as Parkinson's destroys neurons in the basal ganglia, the activity of groups of cells in the STN and across this sensorimotor network becomes abnormally synchronized, locking at certain frequencies. DBS seems to release them from these activity patterns, as do some of the drugs that relieve Parkinson's symptoms 3 , 4 . Recordings from the new generation of neurostimulators are poised to elucidate these mechanisms, not just for Parkinson's but also \u2014 as DBS applications broaden \u2014 for psychiatric conditions. The data could help to resolve concerns about the wisdom of expanding the treatment's usage. Although the sensorimotor network involved in Parkinson's disease has been mapped in great detail, says Joseph Fins, a medical ethicist at Weill Cornell Medical College in New York City, much less guidance is available on how best to apply the technology to other disorders. \u201cThere has got to be a biological rationale for what you're intending to do,\u201d he says. But others argue that controlled testing of DBS in humans need not wait for complete or near-complete understanding of the relevant networks. \u201cAs a clinician, that's not really the important question,\u201d says Benjamin Greenberg, a psychiatrist at Brown University in Providence, Rhode Island. \u201cThe real questions are: do these treatments help people? Are they safe?\u201d Okun adds that, unlike the field of movement disorders, the mechanistic study of neuropsychiatric disorders has been slowed by a lack of realistic animal models. \u201cIf we're going to move forward with some of these human diseases, we are going to have to use humans \u2014 in a very careful way, of course,\u201d he says. \n               Zooming in \n             Mayberg has been doing just that for more than a decade. In 2005 she published one of the first studies on the use of DBS to alleviate severe, treatment-resistant depression 5 . Since then, she has mainly focused her experiments on a structure known as the subgenual cingulate, in which elevated metabolism has been shown to correlate with the severity of a patient's depression 6 . She estimates that the use of DBS in this region and elsewhere has successfully eased symptoms in 40\u201360% of the roughly 150 cases of depression reported on so far. But in recent years, her group has begun to do better by using brain imaging to map the dense web of nerve fibres zigzagging through and around the subgenual cingulate, which connects to regions involved in learning, motivation, appetite and sleep. Combining this information with the effects seen in patients, Mayberg is zeroing in on millimetre-scale differences in electrode placement that can make the difference between success or failure. Potentially, she says, new implants such as the device being tested by Bronte-Stewart could help her team to do even better, allowing researchers to monitor patients' condition in real time and fine-tune the stimulation pulses to maximize benefit. \u201cThere may be an optimal tuning frequency for a given person, and it may not be the same for everyone,\u201d she says. Creating personalized DBS treatments is a top priority in this field. Just before Donobedian's meeting with Bronte-Stewart, his neurologist, Camilla Kilbane of Stanford University, spends half an hour tuning the device's stimulation settings to address his symptoms. Using a short-range radio device, she programs a pulse generator implanted in Donobedian's upper chest. The generator \u2014 about half the size of a deck of cards \u2014 sends electrical pulses through insulated wires that run under the skin of his neck and scalp, and into his brain. Kilbane has already determined during a previous visit the subset of electrode contacts she wants to tweak, and Donobedian has stopped taking his supplementary Parkinson's drugs overnight so that Kilbane can cleanly isolate the effects of neurostimulation.  This is the first time we're really getting a window into the brain.  As she drops the voltage and the implant can no longer overcome Donobedian's tremors, his hands and feet begin to quiver again. Within seconds, the tremors grow and spread, until his arms clap against his sides and his shoes tap the linoleum floor. Kilbane clicks the voltage up again, and Donobedian's limbs calm down \u2014 but then his arms begin to tingle, a common side effect of DBS. At intermediate voltages, his right leg stops shaking, but the other continues to tremble. \u201cIt's stubborn, that left foot!\u201d remarks Kilbane. She spends another 10 minutes inching the voltage up and down, gradually homing in on an optimal setting. Even after this, Donobedian may need to return in the coming months for further fine-tuning. \u201cWhat we have right now for DBS works, but it's very much the first generation,\u201d says Bronte-Stewart. She and others are using the new recording-capable DBS implants as a stepping stone towards 'closed-loop' neurostimulators \u2014 devices that can continuously track an individual's brain activity and automatically optimize settings as needed in real-time. As a first step, the Stanford group is beginning to mine the electrical recordings downloaded wirelessly from the implants in Donobedian and other patients to find patterns that correlate with different Parkinsonian symptoms. They are also looking to see how these patterns might change in the context of different actions, such as sitting, standing and walking \u2014 data that could not be obtained with bulky hospital machines. Indeed, Bronte-Stewart says, there may not be just one set of 'optimal' stimulation parameters. \u201cWe may find out there are different frequency ranges that are better for different functions,\u201d she says. \n               Smarter stimulation \n             As scientists collect more data, some manufacturers are already starting to make strides in closed-loop technology. Last November, the FDA approved the first closed-loop, implantable neurostimulator for intractable epilepsy, another disorder attributable to network dysfunction. The device, made by NeuroPace in Mountain View, California, monitors neural networks for the first sign of abnormal activity \u2014 which in some patients originates again and again at one or a few 'epileptic foci' \u2014 then responds with a pulse of electrical current to prevent a seizure. \u201cWe use stimulation to disrupt that abnormal activity so that it doesn't get picked up by the adjacent neurons,\u201d explains Frank Fischer, the company's chief executive. But Fischer concedes that, whatever the device might do for epilepsy treatment, the technology is not immediately applicable to other conditions. Epilepsy is a comparatively simple disorder, generally consisting of discrete episodes of abnormal brain activity. By contrast, Parkinson's disease involves a mishmash of symptoms that rise, fall and morph over time. Researchers are still searching for the relevant neural signatures in Parkinson's and other diseases, and developing the computational tools required to keep up with changing symptoms. The first laboratory demonstration of a closed-loop DBS system for Parkinson's disease was reported last year by experimental neurologist Peter Brown at the University of Oxford, UK, for a group of eight patients 7 . Brown plugged the patients' DBS implants into an external machine, which triggered stimulation of the STN only when certain abnormal brain rhythms were detected. This selective stimulation improved the symptoms by almost 30% compared with standard DBS treatments, which stimulate the brain at regular intervals. \u201cIt's far short of being introduced into patients,\u201d says Brown of the bulky experimental system, but the demonstration does provide an important proof that the closed-loop concept could work for Parkinson's disease. In an effort to accelerate the move towards closed-loop technology, the US Defense Advanced Research Projects Agency (DARPA) last October announced a 5-year, US$70-million programme to support the development of novel brain stimulators. As part of the BRAIN Initiative, the project aims to foster brain implants to treat conditions such as post-traumatic stress disorder, anxiety and traumatic brain injury. The agency is looking for implantable devices that can monitor and manipulate neural activity not just at one or a few sites at a time, but across entire functional networks of neurons. Accomplishing this goal will require the development of new types of miniaturized sensor, as well as detailed network models of brain function to interpret data streaming in from multiple brain areas, says DARPA programme manager Justin Sanchez. Some of those models may eventually grow out of data from researchers such as Kendall Lee, a neurosurgeon at the Mayo Clinic in Rochester, Minnesota. At last year's Society for Neuroscience meeting, he presented a prototype DBS system called Harmoni that can deliver current to one area of the brain while recording electrical and neurochemical responses elsewhere (see  Nature   http://doi.org/rvj ; 2013 ). Because the brain uses both electrical and chemical signals to communicate, explains Kevin Bennet, the lead engineer on the project, monitoring each type of data could provide more complete information about what is going on. The group intends to test Harmoni first in patients with movement disorders. But, ultimately, the scientists hope to extend combined chemical and electrical monitoring to psychiatric disorders. \u201cThose will be the most difficult to treat,\u201d says Bennet. \u201cThe symptoms are harder to detect and quantify.\u201d Bronte-Stewart projects that testing might begin in about five years for the first implantable, closed-loop DBS devices for Parkinson's disease, with psychiatric applications following close behind. It is not clear whether Donobedian and other current research volunteers could be easily upgraded to those systems; much depends on the precise design of the devices. But even if he does not benefit directly from the data he is generating, Donobedian is glad to participate. \u201cSomebody had to give to me, to get this far,\u201d he says. \u201cIf there's a chance for me to give something back without too much effort, I'd like to help.\u201d \n                 See Editorial \n                 page 273 \n               \n                     What lies beneath 2014-Mar-19 \n                   \n                     Implant aims to track brain signals in real time 2013-Nov-12 \n                   \n                     Brain electrodes fix depression long term 2012-Jan-03 \n                   \n                     Neuroscience: Brain buzz 2011-Apr-13 \n                   \n                     Electrodes spark neuron growth 2009-May-29 \n                   \n                     Shocks switch brain on 2002-Nov-07 \n                   \n                     Nature  special: New angles on the brain \n                   \n                     Helen Bronte-Stewart \n                   \n                     Helen Mayberg \n                   \n                     Kendall Lee \n                   Reprints and Permissions"},
{"file_id": "508024a", "url": "https://www.nature.com/articles/508024a", "year": 2014, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The immune system can be a powerful weapon against cancer \u2014 but researchers are still grappling with how to control it. The first tumour was a small melanoma on the left side of attorney Mark Gorman's neck. Doctors removed it, and assured him that the cancer was gone. But eight years later, in 1998, a physician felt Gorman's abdomen during a routine physical examination, arched an eyebrow, and asked if he had become a heavy drinker. The melanoma had spread to Gorman's liver, seeding an inoperable beast of a tumour that wrapped around the inferior vena cava carrying blood to his heart. People with advanced melanoma typically live for just six to ten months after diagnosis. But Gorman, then 49, had little patience for the doctors advising him to get his affairs in order. When his sister told him about a drug called interleukin-2 (IL-2) that was being used together with chemotherapy against melanoma at a hospital in Colorado, he travelled from his home in Silver Spring, Maryland, to give it a try. IL-2 is a protein produced by white blood cells called T cells during an immune response. Taking high doses of it sends T cells into overdrive, making them more likely to recognize and attack cancer cells. Gorman was treated, and remains cancer-free 15 years later. \u201cSome doctors say my immune system is really smart,\u201d he says. \u201cI just know I'm lucky.\u201d The drug that saved Gorman's life was the first treatment approved by the US Food and Drug Administration (FDA) to fire up the immune system's response to cancer \u2014 a technique known as immunotherapy. After that 1992 approval, researchers and pharmaceutical companies spent years trying to develop new immunotherapies that could produce success stories like Gorman's. But those attempts failed to live up to their promise in the clinic, leading to decades of frustration. Now the tide seems to be turning. Clinical-trial successes in the past five years suggest that a new generation of approaches has potential against several forms of cancer that resist conventional treatments. Some analysts predict that in the next ten years, immunotherapies will be used for 60% of people with advanced cancer, and will comprise a US$35-billion market. \u201cIt is kind of crazy,\u201d says Cary Pfeffer, chief executive of Jounce Therapeutics, a company specializing in cancer immunotherapy in Cambridge, Massachusetts. \u201cThis field has become so crowded. It's frenzied.\u201d But the sobering experience with earlier drugs has made many researchers and clinicians cautious. Despite its potential for miracles, IL-2 produces complete remission in only around 6% of people with melanoma. The treatment kills as many as 2% of recipients. Researchers are now racing to find ways to boost the number of patients who respond to immunotherapy and to reduce the dangerous side effects. \u201cThe good news \u2014 and the bad news \u2014 is that the immune system is incredibly powerful,\u201d says Robert Tepper, chief medical officer at Jounce. \n               Checkmate \n             Cancer immunotherapy was born in 1891, when a New York surgeon named William Coley began injecting bacteria into patients' tumours in the hope of triggering an immune response to the infection that would also attack the tumour. Physicians before him had noted mysterious and rare cancer remissions following infections, and Coley was eager to harness that therapeutic power. It would not be so simple. Tumours wield many defences against the immune system's most powerful cancer-fighting weapon: T cells that hunt out and eliminate problem cells. Cancer cells disguise themselves and make it difficult for T cells to find them. Tumours also fend off immune attack by expressing proteins that suppress T cells in the surrounding environment. For decades, researchers chased the possibility of a vaccine that would alert the immune system to cancer cells. But those efforts have largely failed: the only FDA-approved therapeutic cancer vaccine is a complicated and costly therapy for prostate cancer. Whether it provides a significant benefit to patients is a matter of debate. The field turned a corner in 2011, when the FDA approved a new kind of immunotherapeutic drug. Yervoy (ipilimumab) binds to and blocks a 'checkpoint' protein called CTLA-4, which normally acts as a brake on the immune system by preventing T-cell activation. Checkpoint proteins keep the cells in check so that they do not attack normal tissue. When Yervoy releases the brake, T cells are free to destroy tumours. Like IL-2, Yervoy can bring long-lasting responses. Some participants in the original trials have been in remission for 13 years, says James Allison, a cancer immunologist at the University of Texas MD Anderson Cancer Center in Houston. But those clinical cures occur in just a small fraction \u2014 about 8% \u2014 of patients. And although Yervoy can rouse T cells to battle against cancer, sometimes the cells attack healthy tissue, too. Of the 540 people who took Yervoy in the largest trial, up to 15% experienced serious side effects and seven died of immune-related events. Some oncologists prefer to steer clear of the drug, says Suzanne Topalian, a melanoma researcher at Johns Hopkins University School of Medicine in Baltimore, Maryland. Still, the promising aspects of Yervoy established the potential of checkpoint inhibitors \u2014 drugs that block checkpoint proteins \u2014 and that has prompted researchers to look at other potential target proteins. By the time Yervoy was approved, some investigators had begun to focus on PD-1, a checkpoint protein that some cancers use to deactivate the phalanx of T cells that surrounds the tumour. Because PD-1 interacts directly with cancer cells, unlike CTLA-4, its inhibitors have the potential to be more potent and less toxic. Early clinical trials suggest that this is the case. A leading PD-1 inhibitor \u2014 nivolumab, made by New York's Bristol-Myers Squibb \u2014 shrinks tumours in 28% of people with advanced melanoma. The FDA is expected to issue a decision on whether to approve it by early 2015, if not sooner. Hopes are high that, although there are some side effects, the new drugs will be less toxic than Yervoy. Some people notice no problems at all. \u201cMany patients say, 'Doc, are you even giving me anything?'\u201d says Antoni Ribas, a melanoma specialist at the University of California, Los Angeles, who has participated in trials of PD-1 inhibitors. \u201cThen the tumours start disappearing, and they know.\u201d Researchers want to push immunotherapies even further. \u201cWe wish response rates were higher than what we currently have,\u201d says Michael Postow, an oncologist and cancer researcher at Memorial Sloan Kettering Cancer Center in New York. Inhibitors of other checkpoint proteins are trickling into clinical testing and clinicians may one day match patients with the inhibitors most likely to act on the proteins expressed by their own cancer cells. For other patients, the challenge may be in attracting T cells to the tumour in the first place. PD-1 inhibitors do not accomplish this \u2014 they simply remove the shackles from T cells already amassed at the tumour's edge, says Daniel Chen, head of immunotherapy development at Genentech in South San Francisco, California, a subsidiary of the Swiss pharmaceutical giant Roche. \u201cSome patients just seem to have no existing immune response to start with,\u201d he adds. \u201cSo then we need to add something that will generate that response.\u201d \n               Better together \n             The key to attracting T cells is to create an 'inflamed' tumour using combinations of therapies, says Postow. Yervoy and PD-1 inhibitors are already in clinical trials with each other and a range of other treatments intended to alert T cells to the cancer. Radiation, for example, breaks open cancer cells and releases antigens, molecules that can trigger immune responses. In another approach, researchers alert a patient's immune system with experimental cancer vaccines containing proteins that are overexpressed by tumour cells. \u201cThe future is clearly combination therapy,\u201d says Anthony Marucci, chief executive of Celldex Therapeutics in Hampton, New Jersey. Eventually, checkpoint inhibitors could also be combined with a form of immunotherapy called adoptive T-cell transfer. This is a personalized treatment in which physicians isolate T cells from patients and select those that react to cancer. They then multiply the T cells and stimulate them with molecules such as IL-2 before injecting them back into the bloodstream. Trials of this method led by tumour immunologist Steven Rosenberg at the National Cancer Institute in Bethesda, Maryland, have shrunk tumours in more than half of people with advanced melanoma receiving the treatment, with 20% experiencing complete remission. A newer form of T-cell transfer promises to broaden its reach to other cancers, by engineering extracted T cells to express an artificial tumour-targeting receptor called a chimaeric antigen receptor (see 'Immune boost'). A trial using T cells engineered to target B cells wiped out cancer in 14 of 16 people with acute leukaemia ( M. L. Davila  et al. Sci. Transl. Med.   6,  224ra25; 2014 ). But technical challenges have limited the spread of T-cell transfer therapies. Only a handful of academic medical centres have performed the procedure so far. \u201cAfter our initial results, we were besieged with melanoma patients,\u201d says Rosenberg. \u201cWe couldn't possibly treat all the patients sent to us.\u201d Since those early days, researchers have simplified and standardized protocols. That, plus the remarkable results in leukaemia, has lured industry investors. Novartis, based in Basel, Switzerland, has bought a facility in New Jersey to process T cells extracted from patients around the United States. The facility will be key to the company's plans to expand its clinical trials to more sites this year. Smaller firms are following suit. In early 2015, Kite Pharmaceuticals in Santa Monica, California, hopes to launch a multicentre trial of adoptive T-cell transfer in a form of lymphoma that kills around 37% of patients within five years of diagnosis. \n               The true target \n             Another big challenge for adoptive T-cell transfer is to broaden its reach by finding new molecular targets that will guide T cells to specific tumour types while sparing healthy cells. The approach works well in leukaemia and other cancers that affect B cells, another class of white blood cell, because researchers can engineer T cells to target a protein called CD19, which is found only on B cells. Although the treatment wipes out healthy B cells in addition to the cancerous ones, patients can tolerate that side effect relatively easily. But finding a similar target for solid tumours, which are less uniform than liquid tumours, has been difficult. \u201cIt's a major limiting step,\u201d says Ribas. \u201cWe're all excited about CD19, but it's not clear what the next target will be.\u201d Researchers are mining growing databases of gene expression to find the best candidates. But firing up immune responses to specific proteins can be dangerous: a few years ago, four patients died in trials of T cells engineered to attack cells expressing a protein called MAGE-A3. This protein is expressed only in embryos and in some cancer cells in adults, so it seemed an ideal target. But researchers later learned that the T cells attacked similar proteins present in the heart and brain. \u201cThese T cells are professional killers,\u201d says Arie Belldegrun, chief executive at Kite. \u201cIf their target is expressed even in minute quantities on normal cells, these super killers are going to find those cells and destroy them.\u201d In response to the deaths, ImmunoCore, an immunotherapy company based in Abingdon, UK, developed new bioinformatic methods to search for signs that any possible T-cell target could be expressed in normal tissue. The company also began to do its initial safety testing in three-dimensional cell cultures that better reflected the cells' natural environment. This approach has led to a collection of more than 20 potential targets for various cancers. Michel Sadelain, a cancer geneticist at Memorial Sloan Kettering, hopes to engineer T cells that target two proteins, both of which would have to be expressed on a cell for the T cells to destroy it. The idea, he says, is that the chance that a healthy cell will have both targets on its surface will be slim. Finding more targets could help immunotherapy to reach more types of cancer. So far, researchers have focused on melanoma and kidney cancer because they responded best to immunotherapies in early trials, and are thought to be particularly visible to the immune system. Rosenberg says he is working on 11 clinical trials testing adoptive T-cell therapies against a variety of cancers, including a particularly lethal and rare form called mesothelioma. The door to much wider applications for cancer immunotherapies opened in 2012, when results showed that the checkpoint inhibitor nivolumab shrank tumours in 18% of people with certain types of advanced lung cancer ( S. L. Topalian  et al. N. Engl. J. Med.   366,  2443\u20132454; 2012 ). Because lung cancer is one of the world's most prevalent forms of cancer, the results raised hopes that immunotherapy could make a sizeable dent in cancer deaths. \u201cThis was a cancer that we thought was not immunogenic,\u201d says Ribas, who notes that both Yervoy and IL-2 failed to shrink lung-cancer tumours. \u201cWe thought immunotherapy wouldn't have a chance.\u201d Some cancers, including liver cancer, may still pose a challenge to immunotherapy approaches, says Lisa Butterfield, a cancer researcher at the University of Pittsburgh in Pennsylvania. The liver processes pathogens and antigens in the blood, and the immune system is carefully controlled there to avoid prompting reactions that would target an individual's normal cells. Breast, colorectal, pancreatic and ovarian cancers are also particularly adept at suppressing immune cells. Combination therapies may provide a way around these limitations, she says. Combination therapies may also be the salvation of the cancer-vaccine concept. Although the vaccines tested thus far have fared poorly, they may work synergistically with other immunotherapies, says Willem Overwijk, a cancer researcher at MD Anderson. After so many years of disappointing results, the growing excitement over immunotherapy has surprised many cancer researchers and families touched by the disease. Since his own remarkable recovery, Gorman has mourned again and again as friends he made at melanoma support groups succumbed. Then, a few years ago, he had a new experience: a close friend was given Yervoy, and went into full remission. As for his own melanoma, Gorman goes for scans to look for new tumours every two years. In February, he noted that it might be time to schedule his next set of scans. But he wasn't sure \u2014 he had stopped fearing his cancer's return years ago. \u201cI'm a cool cucumber now,\u201d he says. \u201cMy immune system has it under control.\u201d Reprints and Permissions"},
{"file_id": "508168a", "url": "https://www.nature.com/articles/508168a", "year": 2014, "authors": [{"name": "W. Wayt Gibbs"}], "parsed_as_year": "2006_or_before", "body": "Biomathematician Steve Horvath has discovered a strikingly accurate way to measure human ageing through epigenetic signatures. As a teenager in Germany, Steve Horvath, his identical twin Markus and their friend J\u00f6rg Zimmermann formed 'the Gilgamesh project', which involved regular meetings where the three discussed mathematics, physics and philosophy. The inspiration for the name, Horvath says, was the ancient Sumerian epic in which a king of Uruk searches for a plant that can restore youth. Fittingly, talk at the meetings often turned to ideas for how science might extend lifespan. At their final meeting in 1989, the trio made a solemn pact: to dedicate their careers to pursuing science that could prolong healthy human life. J\u00f6rg set his eye on computer science and artificial intelligence, Markus on biochemistry and genetics, and Steve says that he \u201cplanned to use mathematical modelling and gene networks to understand how to extend life\u201d. J\u00f6rg did end up working in artificial intelligence, as a computer scientist at the University of Bonn in Germany, but \u201cMarkus fell off the wagon\u201d, his brother says, \u201cand became a psychiatrist\u201d. Steve, now a human geneticist and biostatistician at the University of California, Los Angeles (UCLA), says that he finally feels poised to make good on the promise. Through a hard-fought project that involved years of solo work, multiple rejections by editors and reviewers and battling through the loss of a child, he has gathered and analysed data on more than 13,000 human tissue samples 1 . The result is a cellular biological clock that has impressed researchers with its accuracy, how easy it is to read and the fact that it ticks at the same rate in many parts of the body \u2014 with some intriguing exceptions that might provide clues to the nature of ageing and its maladies. Horvath's clock emerges from epigenetics, the study of chemical and structural modifications made to the genome that do not alter the DNA sequence but that are passed along as cells divide and can influence how genes are expressed. As cells age, the pattern of epigenetic alterations shifts, and some of the changes seem to mark time. To determine a person's age, Horvath explores data for hundreds of far-flung positions on DNA from a sample of cells and notes how often those positions are methylated \u2014 that is, have a methyl group attached. He has discovered an algorithm, based on the methylation status of a set of these genomic positions, that provides a remarkably accurate age estimate \u2014 not of the cells, but of the person the cells inhabit. White blood cells, for example, which may be just a few days or weeks old, will carry the signature of the 50-year-old donor they came from, plus or minus a few years. The same is true for DNA extracted from a cheek swab, the brain, the colon and numerous other organs. This sets the method apart from tests that rely on biomarkers of age that work in only one or two tissues, including the gold-standard dating procedure, aspartic acid racemization, which analyses proteins that are locked away for a lifetime in tooth or bone. \u201cI wanted to develop a method that would work in many or most tissues. It was a very risky project,\u201d Horvath says. But now the gamble seems to be paying off. By the time his findings were finally published last year 1 , the clock's median error was 3.6 years, meaning that it could guess the age of half the donors to within 43 months for a broad selection of tissues. That accuracy improves to 2.7 years for saliva alone, 1.9 years for certain types of white blood cell and 1.5 years for the brain cortex. The clock shows stem cells removed from embryos to be extremely young and the brains of centenarians to be about 100. \u201cSuch tight correlations suggest there is something seemingly immutable going on in cells,\u201d says Elizabeth Blackburn of the University of California, San Francisco, who won a Nobel prize for her research on telomeres \u2014 caps on the ends of chromosomes that shorten with age. It could be a clue to undiscovered biology, she suggests. And there may be medical implications in cases in which epigenetic estimates do not match a person's birth certificate. In the months since Horvath's paper appeared, other researchers have replicated and extended the results. The study has stirred up excitement about potential applications, but also debate about the underlying biology at work. \u201cIt's something new,\u201d says Peter Visscher, chair of quantitative genetics at the University of Queensland in Australia. \u201cIf he's right that there is something like an inherently epigenetic clock at work in ageing, that is very interesting. It must be important.\u201d \n               Clocking on \n             Horvath kept his vow to the Gilgamesh project by supplementing his PhD in mathematics with a doctorate in biostatistics, which led to a position in the genetics department at UCLA in 2000. After receiving tenure in 2006, he began to focus on ageing by searching for shifts that occur in gene activity over the course of life. A doctoral student took the lead, feeding gene-transcription data through statistical filters in the hope of turning up a robust biomarker for age. But after more than a year, Horvath and the student had found no strong clues. If any such signal exists in gene-transcript data, they concluded, it is hopelessly swamped by the noisy variations from organ to organ and person to person. With little to show for their work, \u201cI decided to keep quixotic projects like this away from students and postdocs,\u201d Horvath says. \u201cIt didn't seem fair to risk their careers.\u201d Things began to look up in 2011, however. As part of a team led by his UCLA colleague Eric Vilain, Horvath had analysed methylation patterns in DNA extracted from the saliva of 68 adults. The researchers were looking for an epigenetic pattern that correlated with sexual orientation. None turned up, but with the data in hand Horvath and his colleagues decided to see whether they could use it to predict age. In human DNA, methyl groups most often attach at 'CpG sites' \u2014 places where a cytosine precedes a guanine in the DNA. A typical human genome contains more than 28 million such sites. But the microarray technology used to detect methylation samples finds only a fraction of them: older machines pin down just 27,000 sites and newer ones around 485,000. Horvath got lucky. He found success with a simple statistical model, which looked at how many cells in a drop of saliva have DNA methylated at just two particular CpG sites. The index roughly paralleled participants' ages with a correlation of 0.85, or 85%, and an average accuracy of about five years 2 . While working on a subsequent study, Horvath identified methylation patterns that hewed even more closely to age in very different cell types, such as brain and blood. Suddenly, a goal that he had thought impossible \u2014 finding a biomarker for the age of almost every part of the body \u2014 seemed attainable. But it would not be easy. He would have to pull together myriad data sets that included both peoples' ages and their DNA methylation information. Methylation profiles are used for many kinds of medical research \u2014 usually in areas other than ageing (see  Nature 508, 22; 2014 ). And because of variations in the way they are collected and processed, they can be tricky to compare. Horvath worried: \u201cHow do you make data sets comparable if they were generated by different labs using different protocols?\u201d Building on work by Andrew Teschendorff at University College London, Horvath devised a way to normalize methylation profiles and put them all on the same footing. Beyond that, his audacious strategy for dealing with some of the uncertainty was to ignore it \u2014 and hope that it didn't clobber the accuracy of his model. It didn't. By early 2012, his algorithm was using 16 CpG sites in the genome, and was returning correlations with chronological age of 96% in nine kinds of tissue. The accuracy was astonishing: median errors were within three years for blood samples and just 18 months for cheek swabs. But the editors of two journals rejected Horvath's paper. The \u201ctenor of the reviewers was that it was just too good to be true,\u201d he says. They suspected that the clock model fit the training data used to build it but that Horvath had insufficient test data to validate it thoroughly. Humbled but undaunted, Horvath continued collecting data sets and expanding the algorithm. By December 2012, his methylation database spanned 51 types of non-cancerous tissue and cells, plus 20 kinds of cancer. The age estimator had grown to include 353 CpG sites. He had completed his analyses and was preparing to rewrite his paper from scratch when his pregnant wife's waters broke \u2014 more than three months ahead of her due date. For the next 20 days, he barely left the chair beside her hospital bed while she and the medical staff tried to stave off infection and premature delivery. The stress focused him. \u201cI wrote every hour as if it was the last hour I had for finishing the article,\u201d he says. He made good progress, as did his wife and their baby. Towards the end of the third week, with Christmas approaching, \u201cI started to feel really hopeful,\u201d he says. But suddenly the baby's heart rate shot up. After an emergency Caesarean section, the baby struggled to breathe. \u201cThe doctors made a heroic effort,\u201d Horvath says, \u201cbut she died in my hands on the day of her delivery. It wasn't until 10 days later that I found enough strength to upload the paper to  Genome Biology .\u201d The reviews came back in the spring: more disbelief, and another rejection. Horvath didn't blame the reviewers for being sceptical. \u201cEveryone who develops biomarkers knows what to expect: a very strong biomarker gives you a correlation of, say, 0.6 or 0.7.\u201d For example, the correlation between age and the length of telomeres is less than 0.5. For Horvath's clock algorithm, that figure is 0.96. He confesses that he had trouble believing it himself until other researchers independently confirmed the tight association. This time, Horvath refused to take no for an answer. \u201cAfter reading the reviewers' comments, I spent the next 10 minutes doing three things that one should never do,\u201d he says. \u201cFirst, I went to the fridge and drank three bottles of beer as fast as I could. Second, I went back to the computer and drafted a letter to the editor. Third, I sent it off.\u201d \n               About time \n             The appeal worked, and after his article 1  was featured in the October 2013 issue of  Genome Biology , others began downloading the epigenetic-clock program from Horvath's website to test it on their own data. Marco Boks at the University Medical Centre Utrecht in the Netherlands applied it to blood samples collected from 96 Dutch veterans of the war in Afghanistan aged between 18 and 53. The correlation between predicted and actual ages was 99.7%, with a median error measured in months. At Zymo Research, a biotechnology company in Irvine, California, Wei Guo and Kevin Bryant wondered whether the program would work on a set of urine samples Zymo had collected from 11 men and women aged between 28 and 72. The correlation was 98%, with a standard error of just 2.7 years. \u201cThat's amazingly good,\u201d Bryant says. \u201cUrine samples weren't even part of the data that Steve used to develop this algorithm.\u201d Horvath's method has many potential applications. Criminal investigators, for example, might find an epigenetic clock handy for establishing the age of a victim or an assailant by analysing any biological residues left behind. Trey Ideker, chief of the medical-genetics division at the University of California, San Diego, says that his group is working with a forensics lab to test an epigenetic clock that he and his collaborators designed to work specifically on blood, using mathematical methods very similar to Horvath's 3 . Although Ideker's clock is tissue-specific and not quite as accurate, it could be cheaper to use because it is based on fewer CpG sites \u2014 71 rather than 353. Both Ideker and Horvath expect that the most interesting use of the clock will be to detect 'age acceleration': discrepancies between a person's epigenetic and chronological ages, either overall or in one particular part of their body. Such discrepancies could be signs that something is awry. In work due to be presented at the November meeting of the Gerontological Society of America, Brian Chen of the US National Heart, Lung, and Blood Institute (NHLBI) in Framingham, Massachusetts, teamed up with Horvath and others to analyse methylation data collected on more than 2,100 men and women aged 40 to 92 as part of the Framingham Heart Study. The researchers concluded that for every five-year increase in age acceleration, the risk of dying from any cause during the study jumped by 15%. Horvath says that unpublished work from two other large studies also finds epigenetic age acceleration to be a substantial risk factor for mortality, even after controlling for chronological age and other well-known risk factors. Researchers are also comparing the ages of different tissues from the same individual, in the hope of identifying more accurate, less invasive ways to diagnose disease or gauge the risk of future illness. Last year, Ideker and his collaborators reported that the epigenetic ages of breast, kidney, lung and skin cancers were 40% older, on average, than the patients from which they were removed 3 . The picture from Horvath's method is less clear. Some cancers, such as brain tumours, seemed to be decades older, in terms of their methylation, than they should be. But the effect was reversed for some other cancers, such as certain types of endometrial and breast tumours. Distortions in epigenetic age seem to parallel other diseases more closely. Horvath says that recent work has found that people with HIV who have detectable viral loads appear older, epigenetically, than healthy people or those with HIV who have suppressed the virus. Another study, not yet published, observes that some tissues show significant age acceleration in morbidly obese people, he reports. In the coming months, he will be mining the vast Women's Health Initiative database \u2014 which includes thousands of methylation profiles gathered as part of this 20-year, 160,000-person study spearheaded by the NHLBI \u2014 for more links. \n               An age-old question \n             Medical researchers might be able to use the epigenetic clock to better diagnose and classify illnesses even without really understanding how the biology works. But Horvath hopes that the science won't stop there. \u201cThe big question is whether the clock measures a biochemical process that serves a purpose,\u201d he says. His best guess is that the clock corresponds to the function of an epigenomic housekeeping system, which helps to stabilize the genome by maintaining methylation patterns. The more active this mechanism, he proposes, the faster the epigenetic clock ticks. Because methylation is usually reversible, Wei says, it might be possible to grab the minute hand of the epigenetic clock and retard its incessant progress \u2014 an idea that makes Horvath's solemn adolescent vow sound almost attainable. \u201cThe greatest hope is that this clock measures the output of a process that really does relate to ageing \u2014 even causes ageing,\u201d Horvath says. But some are sceptical. Teschendorff's research has shown that genome-wide patterns of methylation drift gradually as the years slip past 4 . He suspects that some passive process is behind the shift and that it leads to ageing and disease mainly by interfering with the ability of stem cells to differentiate. Ideker agrees that the epigenetic transition from young to old could be mostly random, in which case there may be nothing especially informative about the 353 cogs of Horvath's clock. Horvath acknowledges that it will take more work to find out whether epigenetic age predicts the onset of disease and decrepitude better than a calendar does. \u201cBut the epigenetic clock gives us a new start and a new hope of something that will affect ageing,\u201d he says. In that way, Gilgamesh's ancient quest for a way to delay the inevitable lives on. \n                     Epigenomics starts to make its mark 2014-Apr-02 \n                   \n                     Chemical 'clock' tracks ageing more precisely than ever before 2013-Oct-21 \n                   \n                     Long life passed down through generations 2011-Oct-19 \n                   \n                     Longevity genes challenged 2011-Sep-21 \n                   \n                     Ageing: Much ado about ageing 2010-Mar-24 \n                   \n                     Twins grow apart as they age 2005-Jul-04 \n                   \n                     Outlook on Ageing \n                   \n                     Steve Horvath \n                   Reprints and Permissions"},
{"file_id": "509022a", "url": "https://www.nature.com/articles/509022a", "year": 2014, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Frozen mummies and envelopes of scabs could contain remnants of one of history's most prolific killers. In 2011, while construction workers were digging a foundation at a site in Queens, New York, their equipment struck against something metal. Then a body rolled out of the rubble. Thinking that they might have unearthed the shallow grave of a murder victim, the workers immediately called the New York chief medical examiner's office, and forensic anthropologist Scott Warnasch drove over with a team to check it out. The body, which had probably been buried in the cemetery of a nearby church, turned out to be a mid-19th-century mummy \u2014 of an African-American woman dressed in a nightshirt and socks who had been exceptionally well preserved by her ornate iron coffin. The find struck the forensics team as odd: a black woman in the mid-1800s was unlikely to have been able to afford such a luxurious resting place. Then the examiners noticed the lesions and raised bumps that covered the corpse. The marks reminded Bradley Adams, New York City's chief of forensic anthropology, of photos he had seen of smallpox victims. The pricey coffin with its airtight seal, the scientists realized, might have been meant not to preserve the body of a wealthy individual but to quarantine an infection. \u201cWe took a step back,\u201d says Warnasch. The site instantly changed from potential crime scene to potential biohazard, and the city's public-health department called the Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia, for advice. CDC officials reassured the New York investigators that the risk of infection was low. But the agency quickly dispatched epidemiologist Andrea McCollum and a team of scientists in protective clothing to autopsy the body and retrieve tissue samples. No one knows how long the smallpox virus can survive in a human corpse, and McCollum's team hoped to recover DNA or even viable virus particles from the woman's body. This month, the World Health Assembly \u2014 the decision-making body of the World Health Organization (WHO) \u2014 will meet in Geneva, Switzerland, and decide when to destroy the only known stocks of smallpox virus, held in deep freezes at highly protected laboratories in the United States and Russia. It is a move that has been delayed since the 1980s, and in all likelihood will be put off yet again. But even if the official stocks of virus are destroyed, the chance remains that other batches of the virus could be hidden in a freezer somewhere \u2014 or that the pathogen could re-emerge, zombie-like, from a mummified corpse such as the dead woman found in Queens. Although the risk of such a virus causing a pandemic is low, says McCollum, \u201cit's a very real concern\u201d. And an opportunity. In fact, she and a handful of smallpox specialists rather hope that ancient poxviruses, dead or alive, are still out there somewhere. Researchers jump on tips that could turn up specimens reaching back decades or more, and then scour the remains for clues. Practically, such a find could reveal just how long the smallpox virus, known as variola, can survive under different conditions. And even if samples do not yield viable virus, researchers could potentially recover DNA from past infections that will add to our picture of how the scourge has evolved, perhaps offering insight into how we might mount defences should smallpox ever re-emerge. \n               Traces from history \n             Smallpox has a reputation as one of the worst diseases in history: it spreads quickly through the human population and kills about one-third of those infected. Although it has afflicted people throughout the world, Native Americans and Africans suffered in extreme ways: some populations all but vanished after contracting the disease from European settlers between the sixteenth and eighteenth centuries. In 1966, when an estimated 10 million to 15 million cases were still occurring worldwide per year, the WHO decided to step up its strategic vaccination and containment campaigns and, by the end of 1977, had eradicated the disease. Yet remnants of variola remain scattered around the world. Signs of the disease, including skin lesions, virus particles and smallpox DNA, have turned up in stored human scabs and corpses as old as the 3,200-year-old mummy of Rameses V (ref.  1 ). But no one has ever reported the recovery of live virus from a dead body. To the CDC's disappointment, the woman from Queens was no exception: the smallpox DNA in her corpse had degraded, leaving no trace of the virus. In theory, other mummies could harbour the virus, although the risk of infection is slight, says Peter Jahrling, a virologist at the US National Institute of Allergy and Infectious Disease in Frederick, Maryland. \u201cIf you dig up one of these things, you might want to take some precautions,\u201d he says. Cold climates, in particular, may preserve the virus better. \u201cI think it's plausible to imagine that virus might exist in mummies in cold crypts,\u201d says Jahrling. The virus is extraordinarily stable in human tissue, notes D. A. Henderson at the University of Pittsburgh Center for Health Security in Baltimore, Maryland, who led the WHO's smallpox eradication efforts in the 1960s and 1970s. When the characteristic bumps on a person's skin burst, blood coagulates at the site and fibrous proteins weave a mesh around the virus, trapping it inside a scab. Even after the scabs flake off, the caged virus is unlikely to become airborne or to stick to a person's skin if touched. This stability allowed physicians to develop an early form of immunization known as variolation, in which a small bit of a smallpox scab was inserted into a cut in the skin \u2014 causing, for reasons that remain unclear, a milder case of smallpox than a normal infection would have done. Variolation was used into the twentieth century, especially in poorer communities, although in the nineteenth century many physicians switched to vaccinating with the related, but much less harmful, vaccinia virus. With both viruses, scabs were a useful tool: doctors carried them around in their cases and the scabs could even be mailed, as the Virginia Historical Society (VHS) Museum in Richmond discovered in 2010 when it came across an unusual envelope in its collection. In a letter dated 1876, William Massie, who had recently moved to Richmond, Virginia, wrote to his father Henry in Charlottesville. \u201c[I] hope that this will reach you in faculty of time,\u201d he had scrawled in spidery handwriting. Pinned to the letter \u201cso that you cannot lose it as you did before\u201d was a twist of metal foil containing a thumbnail-sized scab that was \u201cperfectly fresh and was taken from an infant's arm yesterday\u201d. It should be enough to vaccinate 12 people, the younger Massie wrote. VHS president Paul Levengood thinks that the artefact is an enchanting glimpse into history. \u201cIt's one little story of one family trying to protect itself from something that was this horrifying bane of human existence,\u201d he says. \u201cCharlottesville would have been the hinterlands in 1870s; maybe you had access to the vaccine in the big city, but your family wouldn't, so here you were trying to keep them safe.\u201d The museum displayed it along with its letter in an exhibit of \u201coddities\u201d. A few months later, Levengood received a call from the CDC. Someone had alerted the agency after seeing a review of the exhibit in the newspaper. McCollum and a colleague drove up to collect the scab, hopeful that this one would contain viral DNA. Molecular virologist Inger Damon, who heads poxvirus research at the CDC, says that the oldest known viable sample of variola is from 1939. \u201cTo get a sample that came from the 1800s would be enormously important,\u201d she says. Studying the virus's evolution could reveal when its ancestor emerged from an animal, or whether poxviruses have evolutionary tricks for stepping up potency, which may be relevant when studying viruses such as monkeypox, which is of increasing concern in Africa. The museum's scab did contain degraded viral DNA, yet it probably belongs not to variola but to a closely related poxvirus. The CDC group is still waiting for the results of the complete 186,000-base-pair genome sequence \u201cI think they were genuinely disappointed,\u201d Levengood says. Just to be safe, the researchers irradiated the scab before returning it to the museum, where it is now kept in a plastic lab tube \u2014 albeit a crumble of its former self because of the radiation. The researchers at the CDC still hope that they will come across a good DNA sample from such a source. \u201cWe have little snippets of information from vaccine scabs that fell out of books or were squirrelled away in attics,\u201d says Damon. One such cache was stashed inside an envelope in an old book in a New Mexico library, and fell out when a librarian opened the volume in 2003. Stored scabs have provided the best evidence for how long the virus can live. In an study begun in the 1950s, researchers in the Netherlands collected scabs freshly shed from people with smallpox and kept them in envelopes. They were able to isolate variola virus for 13 years, when they ran out of scabs, and the experiment has not been repeated. Nevertheless, the findings do show that the virus can survive for more than a decade in a temperate climate 2 . A more likely source of infectious virus would be frozen bodies. Influenza viruses seem to be able to survive freezing in lakes and may thereby infect migrating birds 3 . And in February 2014, researchers studying Siberian permafrost reported that they were able to resurrect a giant 30,000-year-old virus that infects amoebae 4 . As global warming continues to melt the permafrost, it is possible that viral diseases could be released from the ice, the authors say. \n               Siberian mummies \n             Human activities such as drilling, construction and archaeological digs too, could unearth a viral cache. In 2004, a team of anthropologists hunting for mummies in Yakutia in Eastern Siberia turned up a gravesite containing five well-preserved frozen mummies thrown together in an ornate wooden coffin. The group \u2014 probably a family \u2014 seemed to have died suddenly in the early 1700s. The best-preserved body, that of a young woman, had traces of variola DNA in her tissue. The DNA was too degraded for the scientists to reconstruct its entire sequence, but there was enough to show that it was a separate strain from those that circulated widely in Europe and Asia during the twentieth century. The scraps of DNA allowed the researchers to expand our knowledge of the evolutionary history of the smallpox virus, and such studies could eventually help to show how it spread around the world 5 . Scientists at Russia's VECTOR lab in Koltsovo had been thinking about this possibility years earlier. In 1991, a team set out for another village in Yakutia to try to isolate virus DNA from a handful of corpses that had been unearthed by a flood. The researchers were unable to recover any viable virus, or even any dead virus that had retained its shape. \u201cIt was a great disappointment,\u201d Henderson says. The tissue was well preserved and the virus should have been present. But the Russian scientists were among the best in the business, he says. \u201cIf they couldn't get it, it was ungettable.\u201d The Russian researchers say that they have not repeated the expedition. And such hunts for live virus remain a low priority for funding organizations such as the WHO. Of more immediate concern is the ease with which someone could synthesize the virus in a clandestine lab: variola's genome sequence has been available since the 1990s 6 . WHO assistant director-general for health security Keiji Fukuda says that member states will discuss that possibility at the World Health Assembly meeting this month and put together a working group to assess the extent of the threat. Another concern is that smallpox could escape from a secret cache. Few biosecurity specialists believe that the two stocks kept at the CDC and VECTOR are the only ones in existence. For instance, variola could very well be in the freezer of someone who defected from the Soviet Union, says Jahrling. Perhaps even more worrying is that someone could fairly easily tinker with an existing poxvirus to change its host species, make it more resistant to drugs or coax it to spread more easily. All those possibilities \u2014 along with the chance that ancient smallpox could resurface \u2014 has led some researchers to argue that stocks of the virus should stay available. Most people born since the virus was eradicated are not vaccinated against the disease, partly because there are risks associated with the vaccine. And keeping smallpox around to allow the testing of new treatments for the disease makes sense, Jahrling argues. His group has been developing antiviral drugs to treat a smallpox infection after it occurs. \u201cI'm impassioned to keep research going for a while,\u201d he says. Damon adds that newer, safer vaccines are being developed and that having the original virus around could help with testing these as well. She hopes that the decision to destroy US and Russian stocks will once more be delayed. \u201cI don't think we will ever know everything we could possibly know.\u201d In the meantime, researchers continue to piece together the snippets of history they can glean from the occasional corpse or scab. \u201cIt's one of these great examples,\u201d Levengood says, \u201cof a tiny object that can open up this enormous story.\u201d \n                     Giant virus resurrected from 30,000-year-old ice 2014-Mar-03 \n                   \n                     US smallpox vaccine stocks questioned 2003-Aug-20 \n                   \n                     Pox parts list published 2003-Jun-18 \n                   \n                     Smallpox pill promising 2002-Mar-20 \n                   \n                     Blog post: WHO defers decision on smallpox stocks \n                   \n                     Blog post: Monkeypox emerges in Africa in the wake of smallpox \n                   \n                     WHO report on smallpox activities (PDF) \n                   \n                     Virginia Historical Society \n                   \n                     Peter Jahrling lab \n                   \n                     D. A. Henderson \n                   Reprints and Permissions"},
{"file_id": "508444a", "url": "https://www.nature.com/articles/508444a", "year": 2014, "authors": [{"name": "Amanda Mascarelli"}], "parsed_as_year": "2006_or_before", "body": "Biologists are directing the evolution of corals to prepare them to fight climate change. Off the coast of American Samoa, the tropical sun beats down on a shallow tidal lagoon, heating the water to a sizzling 35 \u00b0C for a few hours each day. Such temperatures would kill off most coral reefs, and yet the Samoan lagoon hosts courtyards of antler-like branching corals and mound corals the size of refrigerators. \u201cThe fact that they're there means they've adapted to survive,\u201d says Steve Palumbi, a marine biologist at Stanford University in California. \u201cThe real question is: how did they do that and can all corals do that?\u201d Palumbi is just starting to understand how these Samoan corals thrive in such extreme conditions. And he thinks he might be able to harness that ability to create a reef of hardy coral with a chance of surviving the hot seas that are expected to result from climate change. Starting in August, he and his team are going to try to plant \u201cthe smartest future reef we can imagine\u201d. Palumbi is part of a small group of coral researchers around the world tackling such issues to throw threatened reefs a lifeline. Their ultimate intent is to launch a programme of 'human-assisted evolution', creating resistant corals in controlled nurseries and planting them in areas that have been \u2014 or will be \u2014 hard-hit by changing conditions. \u201cIt's a brave new world of working with corals in this way,\u201d says Ruth Gates, a marine biologist at the University of Hawaii at Manoa who, along with coral geneticist Madeleine van Oppen at the Australian Institute of Marine Science in Townsville, is helping to pioneer the field. The work is not without controversy. Although no one is yet attempting to create genetically modified corals, some researchers are concerned that human-assisted evolution goes too far down the slippery slope of altering natural systems. \u201cIf you're basically farming a reef, you've taken a natural habitat and you've converted it,\u201d says Steve Vollmer, a coral geneticist at Northeastern University's Marine Science Center in Nahant, Massachusetts, who feels that more needs to be known before embarking on such programmes. \u201cIt's like going to the Midwest and taking grasslands and making it into soy. There are huge implications to doing this.\u201d Jamie Craggs of the Horniman Museum\u2019s aquarium reveals how they are getting coral to spawn \n               In hot water \n             Coral reefs have been besieged in recent decades by everything from warming waters to ocean acidification, disease, overfishing and pollution. According to  Status of Coral Reefs of the World: 2008 , a synthesis report 1  by hundreds of scientists and environmental managers, 19% of the world's coral reefs have been lost since 1950 and another 35% are threatened or in critical condition. Some areas have suffered disproportionately: the Caribbean, for example, has lost 80% of its reefs since the 1970s (ref.  2 ). By the end of this century, researchers expect ocean waters to drop from a pH of 8.1 to 7.9 or lower, and to warm by at least 2 \u00b0C, averaged across the globe. \u201cIt's kind of like if you pull the plug on the bathtub and the water is rushing out \u2014 that's the state of corals,\u201d says Palumbi. Reef-restoration projects have been focusing on the Caribbean and other hard-hit spots for more than 20 years. In these programmes, small samples are taken from local reefs and grown in controlled coral nurseries. After a few months, fragments the size of a hand or larger can be 'outplanted' to a reef using underwater cement, where the coral will continue to grow. Such projects have shown that transplantation and reef restoration can be done on a small scale. But transplanted corals grow more slowly and have higher mortality rates than normal 3 . \u201cCoral restoration has always been highly expensive and slow and inefficient,\u201d says Palumbi. \u201cFiguring out how to do this in a smarter way is our goal.\u201d That smarter way takes advantage of the surprising resilience and resourcefulness of some corals and the symbiotic algae that live inside them. \u201cSometimes we find reefs that are doing very, very well in places that you would least expect to find them,\u201d says Gates \u2014 such as a reef off Taiwan that lies below the waste-water outfall pipe of a nuclear power plant and experiences temperature fluctuations of between 6 \u00b0C and 8 \u00b0C per day. \u201cBy all of our understanding, we would expect those corals to all be dead. But they're not, they're flourishing.\u201d Waters with a reduced pH are expected to dissolve coral skeletons \u2014 but in Palau in the western Pacific Ocean, researchers have found 4  reefs that are bigger and more diverse in relatively acidic waters than the Pacific average. Another study 5  found that dire predictions about the frequency of future coral-bleaching events \u2014 mass die-offs when stressed corals lose their symbiotic algae \u2014 are reduced by 20\u201380% if the models take into account corals' ability to adapt after previous bleaching events. That delays predicted mass reef deaths by about a decade. So far, researchers have only a handful of hints as to what makes some corals resilient. In a study 6  published in 2013, Palumbi and his colleagues, including Daniel Barshis, a marine biologist at Stanford, compared two populations of the reef-building coral  Acropora hyacinthus  at their field site off Ofu Island in American Samoa. One population lives in the toasty pool where temperatures reach 35 \u00b0C during summer low tides and fluctuate by up to 6 \u00b0C daily; the other, less isolated by tides, has to deal with temperatures of only about 29 \u00b0C. The team placed samples in controlled tanks and shocked them with temperatures of nearly 3 \u00b0C above normal for four days. All of the corals bleached by the end of the fourth day. But those from the hotter pool survived for longer and had higher expression of 60 genes, including well-known thermal-tolerance genes such as those that make heat-shock proteins and antioxidant enzymes. Palumbi and Barshis think that genetic fitness and acclimatization both play important roles in boosting tolerance. Their analyses suggest that corals can 'toughen up' over the course of their lifetimes in response to environmental conditions. Those in the hot pool are physiologically primed to tolerate additional heat stress, \u201clike an athlete who's been training every day since a very early age\u201d, says Barshis. A promising twist is that the more heat-tolerant species seem also to be more transplant-friendly. After experimentally planting some 400 samples from the two reef areas back into the two pools, Palumbi and his team found that the corals from the hotter pools transplanted more efficiently and grew faster than those from the cooler pools. This August, Palumbi and his colleagues plan to begin an experimental restoration project on Sili Reef off Ofu Island. To select the best corals, the researchers will rely on their extensive data for the area, including growth measurements and transcriptomes \u2014 blueprints of the part of the genome that is actively transcribed into proteins. They also plan to use data from a portable stress test for corals that Palumbi is developing \u2014 \u201clike a human treadmill test for cardiac function\u201d, he says. He and his team have built tanks out of 7.5-litre cooler boxes rigged with lights, heaters and chillers that can dose corals with a controlled bout of high physiological stress. By monitoring bleaching and chlorophyll content, they should be able to predict how corals might respond to potential bleaching conditions. Using all this information as a guide, they will handpick the hardiest, fastest-growing and most heat-resistant corals for their smart reef. At the same time, they will build a second reef from corals selected at random. They will then monitor reef survival over several years. \u201cThe question is: can we do better if we have a lot of information about the individual corals?\u201d says Palumbi. \u201cHonestly, I don't know the answer.\u201d \n               Legacy of survival \n             Others have found encouraging evidence that stress resistance gained through acclimatization can be passed on to offspring. Unpublished work by Gates, led by the University of Hawaii's Hollie Putnam, shows that adult cauliflower corals ( Pocillopora damicornis ) exposed to stress during brooding produce larvae with increased resilience to heat and ocean acidification. The team hypothesizes that this transgenerational protection is caused by epigenetic changes: the modification of molecular tags on the genome that affect gene expression. Gates and van Oppen are aiming to look specifically at areas that have already survived massive bleaching events, such as Moorea in French Polynesia, the central Great Barrier Reef in Australia, and the Seychelles, where 97% of corals in the inner islands died following the 1997\u201398 El Ni\u00f1o oceanic warming event. (A nursery has already been created from the Seychelles corals that survived, and fragments grown from them have been planted onto reefs to aid their recovery.) Gates and van Oppen aim to cross-breed corals that have survived such stressful bleaching, and to track the resilience of the offspring. Their ideas won Gates and van Oppen the 2013 Paul G. Allen Ocean Challenge prize of US$10,000, along with an invitation to apply for multimillion-dollar funding. Depending on how much of that funding comes through, they also aim to use heat and acidity to stress corals before they breed, to see if and how tolerance gets passed down the generations. Beginning in May, van Oppen and her team will start collecting adults of the branching coral  Pocillopora acuta  from the Great Barrier Reef, and will grow them in the Australian Institute of Marine Science's massive National Sea Simulator, an aquarium facility that provides controlled tanks to replicate open-ocean conditions. Ultimately, Gates and van Oppen hope to create a 'seed bank' of gametes and fertilized embryos from extreme settings in which corals persist despite the odds \u2014 including the shallow reefs skirting Coconut Island, Hawaii, where both temperature and pH fluctuate drastically, reaching upper limits similar to those expected in the open ocean by 2050. The seed bank would add to efforts spearheaded by the US Smithsonian Institution, in collaboration with Hawaiian and Australian bodies, which are already banking coral sperm and embryonic cells. A final, important piece of the puzzle is the corals' symbiotic algae: these are shorter-lived and faster-evolving than their hosts, and research has shown that they can pass along thermal tolerance. One study 7 , for example, found that juvenile corals inoculated with strains of algae collected from a warm reef known for heat resistance grew well when exposed to temperatures up to 32 \u00b0C, whereas samples of the same coral inoculated with algae from a cooler reef suffered bleaching and tissue death. Andrew Baker, a marine biologist at the University of Miami in Florida, and his colleagues discovered 8  that symbionts from a lineage called clade D tend to become more prevalent in some corals when they are heat stressed, suggesting that the algae are better able than other strains to survive such conditions, and that they help their hosts to survive too. Since then, studies have shown 9  that clade D symbionts, in particular types D1 and D1a, are prevalent in a wide variety of corals that have survived extreme bleaching events. Putnam, Gates and their colleagues have found 10  that a different strain, C15, seems to be dominant in heat-resistant corals near Moorea. Researchers such as Baker are starting to think about the possibility of intentionally seeding coral reefs with hardier strains of algae to help them to resist the perils of climate change. But it is still unclear whether it will be possible to manipulate symbiont populations effectively in the wild, where environmental conditions might cause the corals to favour one type of alga over another. Workers at existing coral nurseries and farms have been sending samples of coral and symbionts to researchers for genetic sequencing, while keeping tabs on which organisms fare well in heat shocks or disease outbreaks. Researchers have banked hundreds of genotyped strains from a handful of coral species, including the critically endangered staghorn coral ( Acropora cervicornis ) from locations in the Caribbean, says Les Kaufman, a marine biologist at Boston University in Massachusetts. \n               Help or harm \n             The days of trying to build reefs with designer-made corals are still in the future. But as the research heads in that direction, some are wary that such tinkering might do more harm than good. Selecting for traits such as resistance to heat or acidification might lead to a genetic bottleneck, for example. \u201cSelective-breeding programmes may effectively reduce the capacity of corals to adapt to future changes in environmental conditions by narrowing genetic variation,\u201d says David Miller, a coral biologist at James Cook University in Townsville. And that is if selective breeding in corals even works. It is too soon even to tell whether acid and heat resistance are strongly heritable, he says. Miller and others point out that cross-breeding to enhance specific traits in crops and dogs, for example, often comes at the expense of other traits. \u201cThere's often a 'trade-off' effect, so that, for example, more-stress-tolerant individuals are likely to grow more slowly,\u201d says Miller. Selecting for resilience against heat and acidity could hypothetically lead to higher susceptibility to disease, for instance. Manuel Aranda, an evolutionary molecular biologist at the Red Sea Research Center at King Abdullah University of Science and Technology in Thuwal, Saudi Arabia, agrees that breeding might come at a cost. But he says that the serious decline in reef health warrants exploring all available options. \u201cIf you think about losing an entire ecosystem, you want to start somewhere.\u201d Until recently, says Baker, the goal for coral-reef management was simply to create marine reserves and reduce the pressures of pollution and fishing, hoping that that would leave reefs strong enough to deal with climate change. \u201cThe pendulum has sort of shifted as people have realized just how dire the situation is,\u201d says Baker. \u201cWe need to do more than that. We need to take action.\u201d Some 500 million people depend in some way on coral reefs for food and income, and the livelihoods of another 30 million are entirely dependent on reefs 1 . For Gates, statistics like those, combined with the facts of climate change, make the pursuit of assisted evolution necessary and urgent. \u201cWe don't have a lot of time,\u201d she says. \n                     Coral genomes could aid reef conservation 2011-Jul-24 \n                   \n                     Coral marches to the poles 2011-Jan-21 \n                   \n                     Coral bleaching goes from bad to worse 2010-Nov-19 \n                   \n                     Ocean greenery under warming stress 2010-Jul-28 \n                   \n                     Sea survey measures acid increase 2004-Jul-15 \n                   \n                     Global warming threatens coral reefs 2004-Feb-16 \n                   \n                     \n                         Status of Coral Reefs of the World: 2008  \n                       \n                   \n                     Consensus Statement on Climate Change and Coral Reefs \n                   \n                     Paul G. Allen Family Foundation Ocean Challenge \n                   \n                     The Australian Institute of Marine Sciences National Sea Simulator \n                   \n                     Smithsonian Conservation Biology Institute \n                   Reprints and Permissions"},
{"file_id": "508164a", "url": "https://www.nature.com/articles/508164a", "year": 2014, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "With the Ganges\u2013Brahmaputra delta sinking, the race is on to protect millions of people from future flooding. In the wake of Cyclone Aila in 2009, swollen seas washed over the delta of the Ganges and Brahmaputra rivers. The storm surge breached the embankments surrounding a small island that was home to 10,000 families, turning the land into a muddy hell. The deluge of salty water washed out fields, homes, roads and markets just as people had begun to recover from the damage caused 18 months before by Cyclone Sidr. Many migrated to nearby cities. And thousands more took shelter on what remained of the embankments, where lack of sanitation and privacy would soon spur disease and crime. When Steven Goodbred, an Earth and environmental researcher at Vanderbilt University in Nashville, Tennessee, came across this site during a field trip in 2011, he and his students were shocked to find the land still badly flooded and thousands of families living in tents and ramshackle huts. The broken embankments had been poorly repaired and the homesteads that they were supposed to protect remained uninhabitable. \u201cIt looked as desolate as the Moon \u2014 mud everywhere,\u201d says Goodbred. \u201cI'd never seen anything like it.\u201d He made it his mission to determine how the embankments around the island, called Polder 32 after the Dutch word for land protected by dikes, had been eroded and undermined enough for a relatively small storm to wreak such havoc. Scenes of disaster are not unusual in Bangladesh. About 6,000 square kilometres of the massive Ganges\u2013Brahmaputra delta, the largest delta in the world, lies less than two metres above sea level. On average, 6,000 people in Bangladesh die each year in storms and floods. In April 1991, a single cyclone, the worst in recent decades, wiped out well over 100,000 lives in the delta and left millions of people homeless. Risks are expected to climb. Global warming is raising sea levels around the planet by 2\u20133 millimetres each year. That only adds to bigger problems in the Ganges\u2013Brahmaputra delta, which is sinking so rapidly that the local, relative sea level may be rising by up to 2 centimetres each year. And Bangladesh's population of more than 150 million people is projected to grow by a further 50 million by 2050, putting more people in harm's way. Gloomy forecasts warn that millions of Bangladeshis might be displaced by the end of the century. Yet scientists such as Goodbred see a ray of hope. Last month, the country joined with the Netherlands to launch the Bangladesh Delta Plan, to protect the area's people from flooding. To shore up the specifics, researchers are now scrambling to provide basic data on just how fast the delta is sinking and why, and how best to guard against or even stop it. \n               Going under \n             The Ganges\u2013Brahmaputra delta is the dumping ground of the Himalayas. As wind and rain erode the mountain range, massive rivers carry more than a billion tonnes of sediment into the Bay of Bengal each year; in some places, the layer deposited since the most recent ice age is more than one kilometre thick. As in all deltas, this loose material compacts easily, causing the land to sink slowly and the relative sea level to rise. In the past, sediment carried downstream each year would have refreshed the delta. But agriculture, industry and hydroelectric dams have diverted water and choked the flow of sediments, so the land is no longer being rebuilt. A 2009 study found 1  that 85% of the world's largest deltas suffered severe flooding in the first decade of the twenty-first century. Under current projected rates of sediment sinking and sea-level rise, the area of land at risk on deltas globally is expected to increase by at least half by 2100. Previous efforts at flood defence in Bangladesh have not solved the problems. In 1990, the first flood action plan called for barriers to be built along main rivers: in less than 10 years, some 3,500 kilometres of embankments sprang up. In 2000, the country's focus shifted towards constructing more storm shelters and improving warning systems \u2014 but even so, about three-quarters of Bangladesh's population remains exposed to severe flooding. A big part of the problem is a lack of understanding of how the delta's behaviour differs from one place to another. Embankments might work to some extent to protect the capital, Dhaka; but as Polder 32 demonstrates, they do not always do their job elsewhere. \u201cEveryone who says something simple about a big delta has never been to one,\u201d says James Syvitski, a geologist at the University of Colorado Boulder. For subsidence rates in Bangladesh, he says, \u201cdepending on how and where you measure, you might get 15 different values\u201d. Things are dramatically different between the west and east sides of the delta, for example. Over the past several centuries, geological forces and erosion have shifted the lower stretch of the Ganges steadily to the east, leaving the western parts of the delta especially starved of sediment. That makes the southwest particularly vulnerable to both seawater flooding and intrusion of salt into groundwater, which can make the water unfit to drink (see 'A sinking delta'). Researchers need to quantify and map that complexity if policy-makers are to stand a chance of addressing the problems, says Catharien Terwisscha van Scheltinga, a water-management researcher at Wageningen University in the Netherlands who is helping to prepare the Bangladesh Delta Plan. Syvitski's work with satellite data 1  suggests that the delta is sinking below sea level by between 8 and 18 millimetres per year. But those numbers need to be checked against ground-based measurements \u2014 which are now on the way. Michael Steckler, a geologist at Columbia University's Lamont\u2013Doherty Earth Observatory in Palisades, New York, has been installing a network of Global Positioning System (GPS) receivers to monitor subsidence since 2003. He currently maintains around 20 sites, including one established on Polder 32 last year. So far, the results suggest subsidence rates of some 9 millimetres per year in the southwest, and just 2\u20134 in the southeast. But the sites are still few and far between, and there are not many in the most vulnerable locations. Some flood-control efforts might exacerbate the problems. UK geographers John Pethick at Newcastle University and Julian Orford at Queen's University Belfast reported 2  last year that water levels at some spots in the most vulnerable southwest are much higher than expected. They concluded that embankments along hundreds of tidal channels, some of which reach hundreds of kilometres inland, have vastly reduced the area of land covered by water at high tide. Because the water is less able to spread out, it shoots farther inland where it can. The result is a huge increase in tidal range in less-protected areas. Tide-gauge records from three locations in the southwest suggest a mean rate of relative sea-level rise of about 5 millimetres per year over the past 30 years, but some local spots have experienced an average annual high-water-level increase of 15\u201320 millimetres. That tidal amplification has big implications for coastal protection, says Goodbred: for areas with long tidal channels, building more embankments could actually cause higher tides and exacerbate saltwater intrusion. But others warn that it is hard to say whether Pethick and Orford's findings will hold true across the southwestern coast \u2014 it might depend strongly on the steepness of the channel walls, for example. Extrapolating is \u201cmisleading\u201d, says Maminul Haque Sarker, a geologist and deputy executive director of the Center for Environmental and Geographic Information Services in Dhaka. Sarker points to parts of the delta that seem to be sinking much slower. In 2012, he and his colleagues took measurements to see how far the bases of ancient mosques and temples have been buried beneath incoming sediments. The present plinth levels suggest a subsidence rate of just 1\u20132.5 millimetres per year. Sea-level rise would have to be added to that to get a relative sea-level change. But Sarker thinks that the entire delta is sinking less significantly than researchers such as Syvitski have proposed. \n               Earth-shaking change \n             Whatever the current rate of subsidence, it may not reflect the full scale of the problem. In 2010, Till Hanebuth, a geologist at the University of Bremen in Germany, excavated 3  more than a dozen ancient kilns in the Sundarbans, a coastal region of mangrove forests renowned for its population of royal Bengal tigers. The kilns were built for salt production some 300 years ago, just above the winter high-tide level of the time. Today they are buried 1.5 metres beneath the mud and the modern sea level, indicating an average sinking rate of about 5 millimetres per year. Hanebuth thinks that the drop happened not at a slow, constant pace, but in a succession of abrupt events related to big earthquakes or cyclones. Mud-filled stumps in the area show that mangrove trees died from flooding around 1676 and 1762, when strong earthquakes hit the region. The quake in 1762, estimated at magnitude 8.8, caused land around the southeastern city of Chittagong to sink by several metres; in the Sundarbans it seems to have caused at least a 20-centimetre drop, says Hanebuth. Seismologists think that another major quake is overdue in the tectonically unstable region, and that when it comes it will devastate poorly built high-density cities such as Dhaka and Chittagong. It could also cause patches of the delta to drop more in one fell swoop than they have over decades of slow sea-level rise and sediment compaction. Other complicating factors are easier to assess and guard against. A year after their initial observations, Goodbred and his team returned to Polder 32 armed with GPS receivers and survey tools. They found that the embankments that protect the land from the river and sea had also robbed it of fresh supplies of sediment: during the five decades of its existence, the polder had sunk by a full metre relative to the land outside the embankments because it was not being replenished. On top of that, Goodbred found, local shrimp farmers had drilled holes into the dikes to pipe salt water from coastal rivers into their hatcheries, weakening the barriers. Although Cyclone Aila brought much suffering to the people, it helped to rescue the land a little. During the two years in which the dikes were broken, the polder rebounded with tens of centimetres of sediment deposited by daily tides. The mud caused havoc in the short term by flooding peoples' floors and gardens, but offers the possibility of long-term sustainability for delta ground. All this information will feed into the Delta Plan, which will be written over the next 2.5 years by a Dutch\u2013Bangladeshi consortium of government departments, research organizations and engineering consultants. The Netherlands has pledged an initial \u20ac7 million (US$9.7 million) to develop the strategy. \u201cHaving the Netherlands and their invaluable treasure of experience on board is a big push for our flood-defence efforts,\u201d says Shamsul Alam, head of the general economics division of Bangladesh's planning ministry, which coordinates the Delta Plan. The uncertainty in the science makes it difficult for policy-makers to see how much investment is justified, and what kind, says van Scheltinga. But at least some of the problem is coming into better focus. \u201cWe're only beginning to understand how the delta works \u2014 but we know enough to do a bit better,\u201d says Goodbred. In rural coastal areas, Goodbred adds, one solution might be to return to the kind of low, flexible embankments that people in this region built before the 1960s. Locals could raise them in the dry season to keep salty water away, and cut them down in the wet season to allow sediment in. Hugh Brammer, a UK geographer who consulted on Bangladesh's 1990 flood action plan for the World Bank, agrees that flexible barriers are needed. Tidal water must, from time to time, be allowed to flush embanked land, he says, to deposit sediment and thus prevent the polders from sinking over the long term. Homes in these polders, he notes, tend to be on land that sits half a metre or more above the polder basins, so would be protected from the influx. The most urgent step, says Brammer, is to divert water from the Ganges to the western parts of the delta, so that the people there have access to fresh water in the dry season. In 2008, the Bangladesh government promised to consider one diversion scheme. But the costs and feasibility of such a major engineering project have yet to be properly examined; Alam says that such a diversion is unlikely to happen any time soon. There are cheaper options, he says. Scientists with the Bangladesh Rice Research Institute in Gazipur have developed salt-tolerant rice to grow in flood-prone plains. In large coastal cities, new homes and public infrastructure could be built on artificially raised land. Near the coast, conserving and planting trees could create a buffer against storm surges. In its 2011\u201315 economic plan, Bangladesh earmarked more than 120 billion taka (US$1.5 billion) \u2014 4% of all public expenditure \u2014 for climate adaptation and disaster management. Furthermore, it is currently channelling a $170-million multi-donor climate-change-resilience fund, set up in 2010, into projects including flood protection. More money could come from the multi-billion-dollar international Green Climate Fund. To enact a fully fledged Delta Plan, says Saleemul Huq, a senior fellow in the climate-change group at the International Institute for Environment and Development in London, will require several billion dollars over the next few years. Bangladesh currently gets about $2 billion per year from donors for everything from economic development to food relief, so Alam says that it is not unreasonable to hope that it will be able to redirect funds to achieve the flood goals. Meanwhile, life on Polder 32 is slowly returning to normal. Not all of the destroyed embankments have been repaired or replaced, but hundreds of homesteads and businesses are being moved to higher land both inside and outside the polder. Goodbred trusts that the delta and its people have a future. \u201cBangladesh is blessed by options,\u201d he says. \u201cBut time is short and the issues are substantial.\u201d \n                     IPCC: The climate chairman 2013-Sep-18 \n                   \n                     Climate science: Rising tide 2013-Sep-18 \n                   \n                     Increased flood risk linked to global warming 2011-Feb-16 \n                   \n                     Nature  special: Outlook for Earth \n                   \n                     Bangladesh Delta Plan \n                   \n                     Delta Alliance \n                   \n                     Green Climate Fund \n                   \n                     International Institute for Environment and Development \n                   \n                     Bangladeshi Center for Environmental and Geographic Information Services \n                   Reprints and Permissions"},
{"file_id": "508448a", "url": "https://www.nature.com/articles/508448a", "year": 2014, "authors": [{"name": "Kim Krieger"}], "parsed_as_year": "2006_or_before", "body": "A new generation of industrial plants can make liquid fuels from almost any organic scraps \u2014 from corn stalks and wood chips to urban rubbish. By the end of 2015, all British Airways flights out of London City Airport will be fuelled by rubbish \u2014 the paper, food scraps, garden clippings and other organic detritus discarded by the city's residents. But before it goes into planes, the rubbish will be processed at GreenSky London: a biofuels plant under construction on the eastern side of the city. Each year, the facility will take in some 500,000 tonnes of the city's waste and will transform the organic component into 60,000 tonnes of jet fuel, a similar quantity of diesel fuel combined with petrol-like naphtha, and 40 megawatts of power. This level of output would hardly be noticed at conventional petroleum refineries, which typically generate a similar volume of product within a week. But \u201cgathering enough biomass to run a petroleum-scale refinery is almost unthinkable\u201d, says Nathanael Greene, director of renewable-energy policy at the Natural Resources Defense Council in New York City. GreenSky London is typical of a trend for second-generation biofuel reactors that are not only omnivorous \u2014 they can be fed with corn stalks, wood chips and other forms of agricultural waste, as well as urban rubbish \u2014 but also small. The hope is that they will slash transportation costs by bringing the reactors to the biomass instead of vice versa. Proponents argue that novel catalytic techniques and compact designs will make second-generation biofuel plants not just environmentally friendly, but also profitable enough to compete with petroleum-based fuels without subsidies. Questions remain about how realistic this hope is. But at least some customers are giving the plants a try; commercial units have begun to spring up from Finland to Mississippi to Alaska. If these second-generation plants do succeed, says Greene, they will offer at least one crucial advantage over their predecessors: a low-carbon way to create fuel that suits existing vehicles. Limited compatibility in this regard is a key problem dogging the first generation of biofuels plants, which rely on technology developed over millennia to make beer, wine and spirits. These facilities grind up edible products such as corn or sugarcane, add water and yeast, and allow fermentation to take its natural course. The result is a copious supply of ethyl alcohol, which makes an excellent fuel and can be mixed with petrol. But there are serious drawbacks to making fuel from food in a world with a growing population and limited arable land. So, for more than a decade, the biofuels industry has been working on economical ways to use cornstalks, wood chips and other by-products that currently go to waste. This has posed a challenge for the fermentation approach, because these materials contain tough, long-chain molecules such as cellulose and lignin that yeast cannot easily digest. Over the past five or ten years, advances involving pretreatment with acids and enzymes have partially overcome that barrier, and commercial plants designed to produce cellulosic ethanol are now under construction in Iowa and Kansas (see  Nature   507 , 152\u2013153; 2014 ). \n               Hitting the wall \n             But even these facilities will not be able to overcome the biggest restriction on the fermentation approach: the 'blend wall'. This is the maximum amount of ethanol that can be mixed into petrol without causing corrosion in fuel lines and car engines. For current models, the blend wall is about 10\u201315% \u2014 and first-generation fermentation plants already produce more than enough ethanol to meet this demand. Indeed, several US ethanol refineries built in the past decade already stand idle, victims of drought-induced price hikes and market saturation. That reality, paired with nine years of historically high oil prices \u2014 the price per barrel currently stands at around US$100 \u2014 has spurred vigorous research into thermochemical reactors, which convert biomass directly into fuels other than ethanol using heat and catalysts. The most common thermochemical approach is gasification, in which carbon-rich material such as coal, wood chips or municipal waste is heated to produce synthesis gas or 'syngas' \u2014 a mixture of mainly hydrogen and carbon monoxide, with traces of carbon dioxide and other gases (see 'Fuel flow'). At the GreenSky London facility, one or more proprietary gasifier units built by Solena Fuels, a renewable energy firm in Washington DC, will accomplish this step by vaporizing the waste with jets of ionized plasma that heat the material to some 3,500 \u00b0C. Such torches are more energy intensive than other methods of gasification, in which the biomass is heated from below on beds of sand or other material. GreenSky London elected to use them because the contents of municipal waste can vary markedly, and by adjusting the temperature of the torches, the composition of the syngas can be kept consistent. Consistency is important for optimizing the second step of the process, in which the syngas is sent into a chemical reactor \u2014 made, in the case of GreenSky, by Velocys of Plain City, Ohio. There, it undergoes the Fischer\u2013Tropsch reaction, which fuses hydrogen and carbon monoxide into long-chain hydrocarbons. Velocys has made its system unusually compact by reducing the size of the cobalt-containing catalyst particles to the nanometre scale and arranging them along a series of microchannels, which direct the flow of the syngas and produce reaction surfaces with an effective area of a much larger device. The Fischer\u2013Tropsch units have also been made as modular as possible, so that chunks can be assembled at a factory and then be plugged together on site. \u201cYou need to achieve economy not through size, but in the way you build them,\u201d says Neville Hargreaves, business-development manager at Velocys. Another compact system is the BioMax gasifier developed by the Community Power Corporation in Englewood, Colorado. The company says that this device is modular and small enough that four can fit into a standard shipping container, and can run on almost any kind of shredded biomass, from food scraps to cardboard to wood chips. The resulting syngas can then be used in place of natural gas for heating, cooling or electricity generation. A typical unit generates about 150 kilowatts, enough to power between 25 and 50 homes, run three supermarkets or keep vital hospital equipment working. And in the near future, BioMax units should be able to plug in a Fischer\u2013Tropsch reactor and produce biodiesel as well. In 2011, Community Power was bought by the Afognak Native Corporation, which is owned by the indigenous people of Alaska's Afognak Island. They hope to sell the units throughout Alaska and northern Canada, where electricity and transportation fuel are expensive. \n               Clean combustion \n             Among the strongest selling points of the two-step gasification approach to biofuels is the fact that almost all the syngas gets turned into hydrocarbons with no double bonds or ring structures, producing fuels that burn cleanly and completely. But that advantage has not kept researchers from exploring a single-step alternative. In the pyrolysis approach, the biomass is heated in the absence of oxygen to some 500 \u00b0C and converted into organic liquids directly. These liquids can then be refined into fuels using standard technology. Pyrolysis is relatively immature compared with gasification, says Mark Nimlos, a principal scientist at the National Renewable Energy Laboratory in Boulder, Colorado. But that can be seen as a virtue, he adds. \u201cThere is lots of potential to improve.\u201d Several companies are already testing the commercial viability of the technology. For example, UOP of Des Plaines, Illinois \u2014 a subsidiary of the New Jersey-based conglomerate Honeywell International \u2014 is partnering with Ensyn Technologies of Ottawa to market Ensyn's Rapid Thermal Processing (RTP) units. The companies foresee these units being installed next to lumber mills, where each one would be capable of turning waste wood into some 76 million litres of pyrolysis oil a year. That would be enough to warm 31,000 homes if it were burned directly as heating oil; alternatively, if refined into petrol, it could fuel about 35,000 typical US automobiles. Green Fuel Nordic, a biorefining company based in Kuopio, Finland, is planning to install at least one RTP unit in the Finnish town of Iisalmi, where it will process waste from the country's extensive forestry industry. The company is also working with the European Commission to develop a set of quality standards for pyrolysis fuels. One component of concern is tar: a gummy residue of long-chain molecules that are hard to refine. Another is oxygen, which is abundant in biomass and reacts with pyrolysis oil to form organic acids that can seriously corrode refinery equipment. Finding better ways to deal with both of these contaminants is a major goal of pyrolysis-oil research. At present, the easiest way to remove the oxygen is to add molecular hydrogen derived from natural gas, but that would both undermine the climate-friendly appeal of pyrolysis oil and drive up the cost. Indeed, the financial viability of any of the second-generation biofuel technologies is still an open question. Witness the saga of one of the world's most advanced pyrolysis biorefineries: a $225-million facility in Columbus, Mississippi. Owned by KiOR, a renewables company based in Pasadena, Texas, the facility demonstrated its technical viability by producing some 3.5 million litres of petrol and diesel fuel from wood waste in 2013 \u2014 about as much as a conventional petroleum refinery produces in a day. But KiOR, which shut down the Columbus refinery for upgrades in January, will run out of operating funds by the end of August \u2014 and it has enough money to last that long only because it secured a $25-million loan earlier this month from billionaire venture-capitalist Vinod Khosla, whose company, Khosla Ventures, originally funded the project. For GreenSky London, economic viability also remains an open question. But its partners \u2014 Velocys, Solena and British Airways \u2014 are hopeful. They have not disclosed the cost of the facility, but none of them see cost as the central issue. British Airways expects the operation to help it meet the carbon-emissions targets mandated by the European Union while ensuring a steady supply of jet fuel that is not subject to the price fluctuations that plague the oil market. And both Solena and Velocys hope that GreenSky London will be the first of many such facilities serving airports around the world. Every field, forest and landfill site is a potential fuel source for these facilities, says Hargreaves. And the need for liquid fuels will never completely go away. \u201cFifty years in the future, we might get land transportation entirely electrified,\u201d he says. But aircraft require a level of energy density that batteries simply cannot provide. Liquid fuel, he says, \u201cis very difficult to substitute.\u201d \n                     Cellulosic ethanol fights for life 2014-Mar-11 \n                   \n                     Chemical treatment could cut cost of biofuel 2014-Jan-16 \n                   \n                     EU debates U-turn on biofuels policy 2013-Jul-01 \n                   \n                     Canadian biofuel plans derailed 2012-May-03 \n                   \n                     Biofuels need enforceable ethical standards 2011-Apr-12 \n                   \n                     Tide turns against corn ethanol 2010-Dec-20 \n                   \n                     Solena Fuels \n                   \n                     Velocys \n                   \n                     KiOR \n                   \n                     UOP \n                   \n                     National Renewable Energy Laboratory \n                   \n                     European Biofuels Technology Platform \n                   Reprints and Permissions"},
{"file_id": "509148a", "url": "https://www.nature.com/articles/509148a", "year": 2014, "authors": [{"name": "Corie Lok"}], "parsed_as_year": "2006_or_before", "body": "Methods for monitoring tumour cells in living animals are transforming our view of cancer. Mikala Egeblad was blown away when she made her first action film of tumour cells inside live mice. Until then, she had studied samples on microscope slides, where the cells sat still, frozen in time. But seeing them in a living animal brought the cells to life. \u201cYou turn on the microscope and look in the live mouse and suddenly these same cells are running around like crazy,\u201d says Egeblad, a cancer researcher at Cold Spring Harbor Laboratory in New York. \u201cIt really changed my thinking.\u201d Increasingly, cancer researchers are embracing the chance to spy on individual tumour cells in their native environment. In studies of static tissue cultures, investigators have to infer what cancer and other cells surrounding the tumour might be doing, and how they might be interacting. Tracking cancer in live animals over time \u2014 an approach called intravital imaging \u2014 puts those interactions on display, and allows biologists to zoom in on the small number of dangerous cells within a tumour that drive the disease or resist treatment. The technique is young, and labs are still working out how best to analyse the gigabytes of video data it generates. But the increasing use of intravital imaging over the past decade has already helped researchers to piece together timelines for key cellular and molecular events, such as the process by which tumour cells sneak into blood vessels. Such clues have yielded new hypotheses about how cancers grow, spread and resist treatment \u2014 information that could, for example, eventually enable drug developers to understand why some cancer cells do not succumb to therapy. And in a video-obsessed culture, the imaging technique holds instant appeal. \u201cWhen we show our movies, people fall out of their seats when they see how dynamic a tumour lesion can be,\u201d says Peter Friedl at Radboud University Nijmegen in the Netherlands. \u201cIt's a change in perception.\u201d \n               Deep dive \n             First used by cancer biologists in the late 1990s, intravital imaging involves focusing powerful microscopes directly onto exposed tissue in a live, anaesthetized mouse. More labs have adopted intravital imaging as technological improvements have made it possible to peer further into tissue \u2014 now as many as 20 cells deep \u2014 and to tease out fainter signals. A growing library of molecular markers has given researchers the ability to visualize up to eight different kinds of cells and structures, including various immune-system cells and the endothelial cells that line blood vessels. \u201cThe markers and the microscopy technology make this a powerful combination,\u201d says Frederic de Sauvage, vice-president of molecular oncology at the biotechnology company Genentech in South San Francisco, California, who has seen the technology in action.  When we show our movies, people fall out of their seats when they see how dynamic a tumour lesion can be.  Putting these components together creates a comprehensive picture of cancer as a complex ecosystem of cells that migrate, proliferate and interact. Although cancer researchers have long understood that cells in a tumour are genetically heterogeneous, intravital imaging is revealing how the behaviour of individual cells can also differ. For example, cancer cells may march in single file or collectively as a tight-knit group, depending on the type of tumour and its environment. One mysterious cellular behaviour that has landed in the sights of these microscopes is that of the macrophage, a type of immune cell that normally engulfs pathogens, removes dead cells and stimulates immune responses. Macrophages can incite immune cells to fight cancer, but more often they boost a tumour's growth and spread. Intravital imaging studies showed that macrophages, along with tumour cells and endothelial cells, form a structure that pumps tumour cells into the bloodstream \u2014 a key step in metastasis. Working with rodents, researchers led by John Condeelis at Albert Einstein College of Medicine in New York found that when macrophages come into contact with mammary tumour cells, the tumour cells become more invasive, degrading the protein-rich matrix around blood vessels and squeezing between the endothelial cells. Macrophages cause the endothelial cells to lose contact with each other, opening a hole in the vessel wall and allowing tumour cells to stream out of the tissue and into the bloodstream 1 , 2 . Condeelis's team has shown that this 'pump' is present in human breast cancer. The group has also identified three molecular markers, one for each cell type in the structure, that indicate its presence in tumours. In a study 3  of 60 people with breast cancer, individuals with a higher density of these pumps in their tumours were more likely to develop metastases in other organs. A start-up company, MetaStat in Montclair, New Jersey, has licensed this prognostic technology and is developing a test that predicts metastatic risk in people with breast cancer. The company hopes to have the test in clinical trials by the end of this year. Condeelis's group is also working on a probe to identify the pumps using magnetic resonance imaging, avoiding the need to take tissue biopsies from patients. Others are using intravital imaging to track cancer drugs in the body, and to explore why some drug treatments fail. Cancer biologists typically test the effect of chemotherapies  in vivo  by measuring changes in tumour growth and size in mice. Intravital imaging gives a more direct view, revealing which cells in a tumour take up the drugs, and whether those cells live or die. Egeblad and her team have made films of doxorubicin, a naturally fluorescent cancer drug, as it infiltrated mammary tumours in mice. They were surprised by the degree of variability \u2014 even within small regions of the tumour \u2014 in the amount of the drug that got into the cells, and in the number of cells that died. One important factor, they found, was the 'leakiness' of the blood vessels in the tumour 4 . Mid-stage tumours, which have more porous blood vessels than early- or late-stage tumours, were more sensitive to the drug. Compounds that boost the permeability of vessels could therefore improve the delivery of cancer drugs, suggests Egeblad. \n               Viewing window \n             To capture films in live mice, researchers were initially restricted to a single imaging session. Ideally, they would like to watch tumours in the same animal over days or weeks to track longer-term changes. Many are adopting a technique that implants a glass coverslip in a frame in the mouse's skin. These windows, which can provide views into areas including the brain, abdomen and mammary glands, allow investigators to image the same location in the same mouse many times over. The mice wake up after an imaging session and carry on as normal in their cages. Using the windows, a team led by Jacco van Rheenen at the Hubrecht Institute in Utrecht, the Netherlands, watched colorectal-cancer cells colonize the livers of living mice over the course of two weeks. Newly arrived cancer cells moved within small areas of the organ during the first few days, but by day five they had stopped migrating and were becoming densely packed. The team found that in mice in the early stages of tumour spread, treatment with a molecule that inhibits cell migration decreased the number of metastatic liver tumours that developed later 5 . As intravital imaging of cancer has matured, the field has moved beyond eye-catching films and has begun to generate quantitative data detailing, for example, the speed and direction of moving cells. Such data allow researchers to construct and refine mathematical models of cell behaviour. These could predict, for example, how tumour cells invade tissues, says Friedl. But generating such quantitative data is difficult and time-consuming: analysing the movies can take up to 15 times longer than making them, says Egeblad. Others note that software for quantitative-image analysis is limited, so many labs are writing their own programs. And intravital imaging continues to pose technical challenges. The technique can access only tissues near the surface, which makes it applicable to just a few tumour types, says de Sauvage. It has also been difficult to integrate intravital imaging with classical tools of molecular biology, such as fluorescent biosensors used by researchers to see when and where cell-signalling pathways are turned on. Many of those sensors work well  in vitro  \u2014 where cells can be manipulated to amplify changes in signalling \u2014 but are not sensitive enough to pick up the more subtle changes seen  in vivo , says van Rheenen. This sort of information might provide clues to the molecular escape routes that allow some tumour cells to dodge the effects of cancer drugs, says Scott Powers, a cancer geneticist at Cold Spring Harbor. \u201cIt would be nice to know what's happening biochemically inside the cells that's making them do what they're doing.\u201d Egeblad is now integrating biochemical and genetic tools in her imaging work. She will soon be launching a new project to trace the history of different subsets of cells in mouse mammary tumours as they grow over several weeks. At the end of the experiment, her team will remove the tumours and sequence the genomes of individual cells. The aim is to link genetic signatures to cellular behaviours, such as rapid growth or drug resistance, in different regions of the tumour. The team also plans to image the activity of key cancer genes in mice as tumours grow. For Egeblad, the new project is a chance to return to the questions that first drew her to intravital imaging: how do different components of the tumour and its environment co-evolve? Powers says that working with Egeblad and watching her movies helped him to see how the tumour's environment, not just its genetics, can influence cancer. \u201cHow could it not have an impact?\u201d he says. \u201cYou're recording things that haven't been recorded before.\u201d Reprints and Permissions"},
{"file_id": "509151a", "url": "https://www.nature.com/articles/509151a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Since the birth of synthetic biology nearly 15 years ago, the field has splintered into diverse tribes of scientists, all attempting to bestow cells with new abilities. Until just a short time ago, the boundaries of biology were set by nature. But those limits are receding. In the past decade, the field of synthetic biology has shattered the idea that living cells must stick to the biomolecular widgets that have evolved naturally. Synthetic biology \u2014 a more complex form of genetic engineering \u2014 allows researchers to assemble molecular gears on an entirely new scale. From such tools, biological freedom has emerged; even the rule that DNA's alphabet consists of just four letters has been thrown out of the window. In this special issue,  Nature  surveys the messy landscape of synthetic biology and the various scientific tribes that are pushing it forward. Although the field is young, it is already divided into factions that foresee different futures. A News Feature on  page 152  investigates the schism between those who advocate free-for-all tools, such as open-source repositories, and the groups that seek to protect the fruits of research using legal instruments such as patents (see also Editorial,  page 133 ). Volker ter Meulen follows that theme on  page 135 , highlighting the threat of excessive regulation in the field. On  page 155 , experts diagnose the discipline's biggest challenges and suggest solutions through building bridges across scientific and cultural divides. A News & Views Forum on  page 166  debates the merits and drawbacks of engineering useful features into cells by fashioning genetic circuits directly or through successive rounds of screening and selection. And on  page 168 , Daniel G. Gibson and J. Craig Venter describe the research power of a synthetic yeast chromosome built to scramble genes and then probe which combinations can keep cells growing. Even the most basic building blocks of biology are being remodelled. On  Nature 's website, Denis A. Malyshev and co-authors describe a cell that propagates with unnatural nucleic acids in its DNA (D. A. Malyshev  et al .  Nature   http://dx.doi.org/10.1038/nature13314 ; 2014 ). As explored in an accompanying News & Views article, this kind of expanded genetic alphabet might eventually allow the regulatory functions of DNA to be more precisely engineered, or permit new types of amino acid to slip easily into designer proteins (R. Thyer and J. Ellefson  Nature   http://dx.doi.org/10.1038/nature13335 ; 2014 ). Two of  Nature 's sister journals,  \n Nature Methods \n  and  \n Nature Reviews Microbiology \n , are also exploring applications and advances in synthetic biology. Together, the package of reports and commentaries provides a broad overview of how synthetic biology will be building bridges and pushing limits for decades to come. Reprints and Permissions"},
{"file_id": "509152a", "url": "https://www.nature.com/articles/509152a", "year": 2014, "authors": [{"name": "Bryn Nelson"}], "parsed_as_year": "2006_or_before", "body": "Synthetic biology is facing a tug of war over whether to patent its discoveries or embrace open-source innovation. A Canadian futurist named Andrew Hessel has an unorthodox idea about how to cure breast cancer. He asks: what if volunteer researchers, working cooperatively from their garages and bedrooms, could rival the efforts of multibillion-dollar pharmaceutical companies? His crowd-funded venture, the Pink Army Cooperative, is trying to do just that by tapping into open-source tools springing from synthetic biology \u2014 an emerging field that designs biological products using engineering principles and a modular approach. Since the cooperative launched in 2009, nearly 600 people have invested in it. The cost to join? A mere US$20. This radical idea faces considerable hurdles \u2014 but even so, it has attracted plenty of attention from industry groups and the media. The cooperative, launched by Hessel and two co-founders, hopes to start cell-culture studies this year and is considering a therapeutic trial in dogs. Currently based at the software-design firm Autodesk in San Francisco, California, Hessel represents an increasingly impatient and outspoken faction of synthetic biology that believes that the patent-heavy intellectual-property model of biotechnology is hopelessly broken. His plan relies instead on freely available software and biological parts that could be combined in innovative ways to create individualized cancer treatments \u2014 without the need for massive upfront investments or a thicket of protective patents. He calls himself a \u201ccatalyst for open-source synthetic biology\u201d. This openness is one vision of synthetic biology's future. Another is more akin to what happens at big pharmaceutical companies such as Pfizer, Merck and Roche, where revenues from blockbuster drugs fund massive research initiatives behind locked doors. For such businesses, the pursuit of new drugs and other medical advances depends heavily on protecting discoveries through patents and restrictive licensing agreements. Tight controls on intellectual property are necessary to encourage promising medical developments, says the Biotechnology Industry Organization (BIO) in Washington DC, the sector's dominant trade association. On its website, BIO calls intellectual property \u201cimperative for innovation\u201d around the world. \u201cSocieties that protect inventors with patents are the world's most advanced \u2014 scientifically and technologically,\u201d it says.  It's not just return on investment. It is also about doing good in the world.  How synthetic biologists resolve the conflict between open source and patent protection could determine whether the field delivers on its ambitious goal of transforming medicine, agriculture, energy, environmental remediation and other industries through precision engineering. \u201cIt's not just return on investment,\u201d says Linda Kahl, director of the legal programme at the BioBricks Foundation, a non-profit organization in Cambridge, Massachusetts, that advocates for biological engineering in the public interest. \u201cIt's not just commercial applications. It is also about doing good in the world.\u201d \n               Two cultures \n             Although its roots extend back to the early twentieth century, synthetic biology started sprouting as an organized field just over a decade ago. In 2003, only 3 peer-reviewed articles listed in Elsevier's Scopus database used the term synthetic biology; in 2013, more than 800 did. Last year, the field also marked one of its biggest developments. Capitalizing on a discovery by biochemical engineer Jay Keasling of the University of California, Berkeley, the Paris-based pharmaceutical firm Sanofi began large-scale production of a partially synthetic form of the malaria drug artemisinin, which is normally derived from plants (see  Nature   494 , 160\u2013161; 2013 ). And more big advances are in the pipeline: at the Pacific Northwest National Laboratory in Richland, Washington, for example, researchers are creating synthetic fungal enzymes that can convert sugars from broken-down plant biomass into fuels and other industrially useful chemicals. From the start, the field has been an amalgam of disparate influences, each with different cultures of intellectual property. On one side sit software design and engineering, which introduced the idea of encoding desired functions in pieces of DNA and joining together a standardized set of biological widgets, much like bricks or Lego pieces. Software engineers also brought with them the philosophy of sharing their work using open, public registries or only lightly restrictive licensing agreements, such as copyrights. On the other side sit molecular biology and biotechnology, which supplied know-how about messy and unpredictable biological systems. They also brought the practice of patenting genes, molecules and technical processes. Half of the papers published in  Nature Biotechnology  between 1997 and 1999, for example, were linked to a patent. \u201cThey came with different perspectives, different goals, and in some cases, different expectations,\u201d says Andrew Torrance, a law professor at the University of Kansas in Lawrence who focuses on synthetic biology. Which intellectual-property culture will come to dominate synthetic biology is still unclear. In June last year, in a case brought by the Association for Molecular Pathology against the company Myriad Genetics, the US Supreme Court ruled unanimously that \u201cproducts of nature\u201d such as genes and genetic markers are not eligible for patents. But by its very nature, Torrance says, synthetic biology creates DNA that does not occur naturally \u2014 and so the court's ruling explicitly allows such human-designed DNA to be patented. Legally, therefore, synthetic-biology sequences and techniques can be patented, at least in the United States. But the morals and ethics of doing so are vigorously debated by researchers, companies, lawyers and bioethicists. Patent advocates say that protecting intellectual property is necessary to spur innovation. In a statement after the ruling against Myriad, Craig Venter, founder and chief executive of Synthetic Genomics in La Jolla, California, applauded the court for making a distinction between naturally occurring and human-derived DNA segments. \u201cThese man-made genetic constructs are already being used to create new vaccines, biofuels and nutritional products,\u201d he said. \u201cAnd the ability to protect this intellectual property is a necessary component of a vital and robust science and biotechnology industry.\u201d Many synthetic biologists are indeed patenting their work. Writing in  Systems and Synthetic Biology  last year, a group of researchers in Germany documented a trend towards increasing patent applications in the field \u2014 particularly in the energy, medical and industrial sectors (D. van Doren  et al .  Syst. Synth. Biol.   7 , 209\u2013220; 2013 ). Lead author Davy van Doren, an emerging-technologies researcher at the Fraunhofer Institute for Systems and Innovation Research in Karlsruhe, Germany, concedes that the trend is inferred from a limited number of patents and a short time frame \u2014 but says that it is consistent with other areas of biology. \u201cWe couldn't find any evidence that patent trends in synthetic biology might be different compared with other domains,\u201d he says. But open-source advocates argue that patents squelch innovation. This opinion is widespread in start-up companies, non-profit organizations, graduate programmes and the wildly popular annual International Genetically Engineered Machine (iGEM) competition, in which university and school students compete to make synthetic systems that work in living cells. These researchers say that if companies and universities can patent key synthetic-biology tools and building blocks, they can charge hefty fees for others to use them, making it prohibitively expensive to create new products building on those discoveries \u2014 especially for start-ups and organizations with few resources. \n               Out in the open \n             The free-for-all synthetic-biology movement is advancing its aims by assembling public registries analogous to open-source software registries. The iGEM Registry of Standard Biological Parts, the oldest and biggest, contains samples submitted mainly by teams that have entered the competition. By building up a critical mass of components in repositories dedicated to public use, Torrance says, sharing advocates are creating a commons that future innovators can rely on for synthetic-biology building blocks, dubbed biobricks. Individual parts from these collections can be incorporated into larger and potentially patentable inventions, but theoretically it is harder to patent the basic parts if they are already in the public commons. The iGEM Registry alone is growing by a few thousand parts per year. But there is a big caveat: no one can say with any certainty how many of these parts are themselves entirely free of patent claims. Not all researchers are willing or able to verify that parts that they label 'open-source' actually are. To provide some clarity, the BioBricks Foundation has developed a legal tool known as the BioBrick Public Agreement: a contract for acquiring standardized biological parts on an open-source basis. Contributors agree not to assert any existing or future intellectual-property rights on a biological part that they have developed, in exchange for a promise by users that they will give proper credit to the developer and abide by security regulations. Although public registries are rapidly expanding, few have the curatorial capacity to verify that every part works as claimed. \u201cYou're not getting finished, high-quality pieces of DNA in every case,\u201d Torrance says. Some researchers are more blunt. \u201cThere's a lot of crap in there,\u201d says Keasling. To encourage sharing while weeding out the junk, he favours requirements for authors of journal articles to deposit standardized part-source data and descriptions into a repository \u2014 provided that the field can agree on a fair set of rules. Advocates say that the iGEM Registry has improved vastly in recent years, and point to new collections that are emphasizing quality control. The Synthetic Biology Engineering Research Center in Emeryville, California, is developing an Internet interface called the Web of Registries to stitch multiple databases into a linked system that offers uniform information about parts and their legal status. If the field takes off like open-source software, Torrance says, it may attract a do-it-yourself crowd that will help to verify that parts do what is advertised, just as some software enthusiasts currently spend their free time fixing bugs. Synthetic biologists on both sides of the debate say that few in the field take an absolutist view on patents. Many are instead homing in on the idea of a 'diverse ecology' \u2014 one that includes both intellectual-property protections and public-sharing agreements (J. Calvert  BioSocieties   7 , 169\u2013187; 2012 ). Complexity matters here: if the synthetic-biology building blocks are compared to Lego, then in this situation the bricks would be free but a design for a complex rocket ship made of hundreds of Lego pieces would be patentable. \n               Share and protect \n             To give an idea of what a robust and commercially friendly open-source regime might mean for synthetic biology, Hessel points to the Linux computer operating system, the open-source platform that became so popular that it is now among the most widely used in the computer industry. Although the base operating system is free, developers have built proprietary businesses onto it, just like biotech companies might be able to incorporate free synthetic-biology building blocks into more sophisticated and patent-worthy systems. Ginkgo Bioworks in Boston, Massachusetts \u2014 which bills itself as the world's first organism-engineering foundry \u2014 is part of an emerging class of synthetic-biology companies that have embraced both public and proprietary models. Among its many projects, Ginkgo is engineering yeast cells to produce chemicals including flavours and fragrances, such as a designer rose extract. The company is not averse to taking out patents on such advanced creations, but it also has a stake in open-source science: Ginkgo sells a $253 kit for assembling biobricks from iGEM's Registry of Standard Biology Parts into a multicomponent genetic system. And in 2011, the company agreed to make publicly available one of its engineered constitutive promoters, a DNA regulatory segment that allows a gene to be continually copied into RNA. \u201cIt's not particularly useful to be patenting individual parts, per se, except in very specific cases,\u201d says Ginkgo co-founder Reshma Shetty. \u201cSo I think having the commons available to everyone is a good thing for everyone.\u201d Although biobricks and other open-access parts have already shown their potential in research projects, advocates say that it is still too early to predict how much they will be accepted into commercial research and development. Ginkgo co-founder Tom Knight, a computer engineer at the Massachusetts Institute of Technology in Cambridge who is often called the father of synthetic biology, says that the field is shifting away from a focus on handcrafted biology, towards a system in which large-scale foundries create standardized parts en masse. If this shift continues, then companies will want to use small parts interchangeably and without complex patent agreements from every manufacturer. Patents will not disappear entirely, says Knight, but they might have a limited role in an industrial context. Even if the field evolves towards a middle way, the debate will continue. The biotech industry, for one, worries about liability issues associated with free-for-all biological parts. If a publicly available building block is incorporated into a transgenic seed or medical treatment, for example, it is not obvious who is responsible for tracking down its provenance and demonstrating to regulatory authorities that the part is safe. \n               Innovate or die \n             In the tug of war between patents and open-source registries, a nagging question remains: which mechanism is better at driving innovation? In 2003, the US National Research Council issued a report called  Patents in the Knowledge-Based Economy , which said that the evidence on how patents affected innovation was still \u201cemergent\u201d. A decade later, the uncertainty persists. \u201cThere are a lot of people looking into this question,\u201d says Torrance. \u201cIt is amazing to me that in 2014, it's impossible to point to a definitive study that indicates that the patent system or the copyright system is a net benefit or a net cost to the economy or to innovation. But that's where we are.\u201d It may not matter what the data say, according to Hans Sauer, deputy general counsel for intellectual property at BIO. \u201cFor better or worse, we're just committed to a system that depends on the availability of patents, at least to some extent, for greasing the wheels that put the biotech business model in motion.\u201d In other words, whether patents actually spur innovation may be trumped by the widespread view of entrepreneurs and investors that they are key to minimizing risk in the start-up phase. \u201cThese people, rightly or wrongly, all act on their beliefs and their convictions,\u201d says Sauer. Many in the biotech industry have difficulty imagining a world without patents, he adds. The industry is \u201ca bit spooked\u201d about emerging public hostility to patent rights, and about a legal pendulum that seems to be swinging towards a more restrictive application of patent law, at least in the United States. The hesitancy is understandable, says Hessel, given the biotech industry's big investments and long lead times. But a new generation of nimbler, leaner open-access types is not bound by such restraints. \u201cWhat we're seeing is a kind of transition era, where there's this new community emerging and it's in some ways competing intellectually with the current, established industry,\u201d he says. The old guard can go on worrying about downstream investment costs and liability, says Hessel, while he and his Pink Army invent a way to cure cancer. In March, Hessel spoke to pharmaceutical executives and consultants at the Pharma Summit 2014 in London about the Pink Army Cooperative's cancer-therapy work. And BIO has invited him to join a panel discussion about emerging trends in biotechnology at the BIO International Convention in San Diego, California, in June. Although the cultural gap between the two camps remains wide, there are signs that the bridge-building has begun. \n                     Bioengineers look beyond patents 2013-Jul-03 \n                   \n                     DNA tool kit goes live online 2013-Mar-12 \n                   \n                     Malaria drug made in yeast causes market ferment 2013-Feb-13 \n                   \n                     US legislation aims to simplify rules for inventors 2011-Apr-12 \n                   \n                     DNA factory builds up steam 2010-Jul-22 \n                   \n                     Five hard truths for synthetic biology 2010-Jan-20 \n                   \n                     Nature Outlook: Synthetic Biology \n                   \n                     Blog post: Open science summit unlocks research access \n                   \n                     Biotechnology Industry Organization: Intellectual property \n                   \n                     Pink Army Cooperative \n                   \n                     Mapping Controversies on Science for Politics: Intellectual Property in Synthetic Biology \n                   \n                     iGEM Registry of Standard Biological Parts \n                   \n                     BioBricks Public Agreement \n                   \n                     International Open Facility Advancing Biotechnology \n                   Reprints and Permissions"},
{"file_id": "509276a", "url": "https://www.nature.com/articles/509276a", "year": 2014, "authors": [{"name": "Joanne Baker"}], "parsed_as_year": "2006_or_before", "body": "The left-over radiation from the Big Bang has given up what may be its last great secret about the early Universe, but astronomers are determined to mine more from this primordial prize. Cosmologists couldn't have wished for a better anniversary present. Almost 50 years to the day after the first detection of the Big Bang's afterglow \u2014 a faint glimmer of long-wavelength photons known as the cosmic microwave background (CMB) \u2014 the field has been galvanized by what may be the last major discovery from the radiation. On 17 March, astronomers announced that a microwave detector at the South Pole had recorded the first signs of primordial 'B modes': subtle, swirling patterns in the CMB data that were imprinted during the early history of the Universe. The result was hailed as direct evidence of gravitational waves, ripples in the fabric of space-time that were produced by a sudden 'inflation' of the Universe a split second after the Big Bang.  The most obvious question \u2014 is the B-mode signal real? \u2014 has sparked a race among teams running telescopes on the ground, in space and carried by balloons. \u201cThe name of the game is confirmation,\u201d says experimental cosmologist Amber Miller of Columbia University in New York City. Should the results check out, and most in the field think they will, the focus will shift to the next frontier. Scientists would like to see a new era of B-mode astronomy that would collect more extensive and more precise measurements of the patterns. Through such data, researchers hope to reach back in time to better understand the Universe's first moments, as well as how galaxies formed and clustered together in the aftermath of the Big Bang. The B-mode data may even help to reveal the origins of mysterious factors such as dark matter and dark energy that control the form and fate of the cosmos. \u201cThe CMB has been our best window on the early Universe by a long shot,\u201d says George Efstathiou, a cosmologist at the University of Cambridge, UK. But a rich new B-mode era is not guaranteed. Funding is scant, the existing surveys have little coordination with each other, and the available instruments are limited. What's more, theorists still need to pin down exactly what the new views of the CMB can reveal. Even as they celebrate this year's discovery, CMB researchers are fretting over the future of their field. Decisions made over the next few months will determine whether astronomers can hope to realize the scientific promise of this new vista in the next decade or more. \n               Early days \n             The discovery of the Big Bang's afterglow came as a happy accident, when Arno Penzias and Robert Wilson, two astronomers at Bell Labs in Holmdel, New Jersey, set out to map radio emissions from the Milky Way. On 20 May 1964, they noticed a faint signal that seemed to come from every direction. Penzias and Wilson assumed it was an artefact from some local source until a conversation with a colleague led them to conclude that the radiation was not earthly but cosmic. Theorists, they learned, had long predicted such a signal: it was strong evidence in favour of the Big Bang theory, which holds that the Universe exploded into existence at a moment in the past, rather than having existed forever in an unchanging 'steady state'. By observing it, Penzias and Wilson had proved that the Universe was once much hotter than it is today. The photons they had recorded were released about 380,000 years after the Big Bang, when the expanding cosmic fireball had cooled enough for electrons and protons to combine to form hydrogen atoms. The photons have been travelling ever since, cooling as the Universe expands and preserving a snapshot of the Universe at the moment they were liberated (see '50 years of discovery'). In 1990, NASA's Cosmic Background Explorer (COBE) satellite made the first precise measurement of the CMB's temperature \u2014 2.725 kelvin \u2014 and showed that the value was the same in every direction, implying that the primordial plasma was similarly uniform 1 . But it soon became apparent that the CMB is not perfectly smooth. In 1992, COBE scientists found that the temperature of the CMB varies across the sky by roughly 1 part in 100,000 (ref.  2 ). These tiny 'anisotropies' turned out to provide crucial information about the evolution of the Universe. The hot and cold spots reflect small variations in the density of the gas when the CMB photons were released. Most cosmologists think that gravity later magnified these fluctuations, pulling together denser regions to form galaxies and clusters of galaxies. Seeing the anisotropies also inspired theorists, says Marc Kamionkowski, a cosmologist at Johns Hopkins University in Baltimore, Maryland. A prime example was the recognition that the warm and cold blotches in the CMB have characteristic sizes determined by vast waves of pressure and density that reverberated through the infant cosmos in much the same way that sound harmonics echo inside a violin. These dominant frequencies, or acoustic peaks, in the CMB allow astronomers to infer many physical properties of the Universe. For example, the biggest peak, akin to the loudest harmonic, lies at a scale of about 1\u00b0, or about twice the diameter of the full Moon. This is exactly as would be expected if the expanding Universe is geometrically flat, so that parallel light rays never cross as they traverse space. The location and relative strength of the second peak, at roughly 0.4\u00b0, allows astronomers to infer that ordinary matter \u2014 the kind found in atoms, planets and stars \u2014 comprises less than 5% of the cosmic total. Everything else is in the form of invisible dark matter and dark energy. \n               Polarization patterns \n             CMB research entered a new phase a decade ago, with the advent of detectors sensitive enough to measure its polarization \u2014 the direction of vibration in the photons coming from each point in the sky. Polarization in the CMB results from photons scattering off free-roaming electrons in the cosmic plasma, and the potential scientific pay-off from measuring it was huge: one component, the swirling B modes, promised to give astronomers the first direct evidence that the Universe had undergone an extreme form of inflation when it was just 10 \u221236  to 10 \u221232  seconds old. Theorists proposed the idea in the early 1980s to explain why the Universe is both smooth at the largest scales and geometrically flat 3 . The rapid expansion, in which the cosmos grew by a factor of at least 10 26 , would have smoothed out most irregularities and flattened out any curvature. The few remaining irregularities \u2014 visible as the CMB temperature anisotropies \u2014 were vastly magnified vestiges of tiny quantum fluctuations in energy. But that was all theory until researchers developed the capacity to measure B modes. That required them to find a way to identify a minuscule signal that is easily masked by polarized emissions from dust and magnetic fields in our Galaxy. The first detection wasn't announced until 2013 (refs  4 ,  5 ) \u2014 and even then, the measurements were made on a small angular scale, at which polarization patterns are distorted by the gravitational fields of galaxies in front of the CMB. The real prize arrived in March, when astronomers working with the BICEP2 detector at the South Pole announced that they had measured B modes on scales of about 1\u00b0, large enough to avoid the signal from intervening galaxies and to probe fundamental polarization patterns such as those from inflationary gravitational waves 6 . After so many years of searching for inflationary B modes, BICEP2's results triggered widespread elation in the cosmology community. \u201cIt has injected a whole lot of adrenaline into the endeavour,\u201d says experimental cosmologist Shaul Hanany of the University of Minnesota in Minneapolis. But with that excitement came a puzzle. The patterns detected by BICEP2 are considerably stronger than most cosmological models predicted. And it exceeds limits set by the European Space Agency's now-deactivated Planck satellite on the degree to which gravitational waves might have contributed to the CMB temperature fluctuations. \u201cThe BICEP2 result was a bit of a shock for me,\u201d says Efstathiou, who is a member of the Planck science team. \u201cI think the jury is still out\u201d on what it means, or if it's even real. In the next year, half a dozen experiments in Antarctica and Chile will try to confirm the findings. Members of the BICEP2 team are working on two new South Pole telescopes. The Keck Array, which is already operational, has five times as many detectors as BICEP2 and covers two frequency bands. A second, called BICEP3, is an upgraded version of the previous detector that is scheduled to start collecting data in December 2014. One or two US-funded balloon-borne experiments may also fly later this year from McMurdo Station in Antarctica; last year's flights were cancelled because of the US government shutdown. But cosmologists are most eager to see this autumn's planned release of the full data set from Planck \u2014 findings that will include polarization maps. Planck has the advantage of monitoring a wider range of frequencies than ground- and balloon-based experiments, which can measure only within the narrow bands of radiation frequencies that are not absorbed by water vapour in the atmosphere. Planck's improved sight will give astronomers much more confidence in subtracting foreground polarization from our Galaxy. And instead of being restricted to the portion of sky visible from a given latitude, Planck has an unobstructed view. If Planck confirms BICEP2's results, the champagne will come out. But if it does not, cosmologists will have to resolve the discrepancy, which will pose a challenge. To take just one example, gravitational waves as strong as those recorded by BICEP2 should have had a noticeable effect on the acoustic peaks \u2014 yet the limited Planck data currently available have shown no evidence for that. \u201cHow can you reconcile it?\u201d wonders Efstathiou. The ideas put forward so far seem contrived, he says. Kamionkowski is more optimistic, and counsels patience. \u201cIt may take years to really understand what the most promising models are and how to distinguish them.\u201d \n               Next-generation experiments \n             In the meantime, most CMB scientists are focusing on developing their capability for measuring B modes. For example, there are many theories for precisely how inflation unfolded, each making its specific prediction about how the gravitational wave B modes are distributed across the sky. Being able to measure B modes at the largest scales would allow astronomers to weed out the theories that are obviously wrong. At smaller scales, the B modes are sensitive to how mass is distributed around the Universe, and how vast galaxy clusters have grown over time. Such a signal would help astronomers to constrain stubborn cosmological unknowns, including the nature of dark energy \u2014 a mysterious force that is causing the Universe's expansion to speed up \u2014 and the identity of the invisible dark-matter particles that make up most of the Universe's mass. Combining B-mode maps with surveys of hydrogen across the Universe could also allow observers to probe the epoch in which the first stars and galaxies switched on their ionizing radiation. Electron scattering from this period should have left a large-scale mark in the B-mode polarization of the CMB. Unfortunately, limited money is constraining choices about what comes next. A UK competitor to BICEP2 was cancelled in 2009 (see  Nature   http://doi.org/fnsdc3 ; 2009 ) as its funding council struggled to meet commitments to international bodies such as CERN, Europe's particle-physics laboratory near Geneva in Switzerland. Europe as a whole, meanwhile, has focused its CMB research programme almost exclusively on Planck \u2014 a policy that Efstathiou describes as a \u201cbig mistake\u201d. With no follow-on mission in the pipeline and little ground-based activity, the concern is that hundreds of postdocs and students will have to move to new fields when the research programme ends. In the United States, CMB work falls into the cracks between grant-agency panels. Space and balloon work competes against planetary and X-ray astronomy missions at NASA, and ground-based arrays go up against particle-physics experiments at the Department of Energy (DOE) and the National Science Foundation (NSF). Philanthropic donations from the Keck and Simons foundations, among others, are helping fill the gap. A solution suggested by some astronomers would be to cut back on the number of ground-based CMB experiments with similar aims. Critics contend that ground-based CMB experiments rarely share their data, which undermines calls for more projects. Most space-science missions are required to make their data public, says Jean-Loup Puget, an astronomer at the University of Paris-South and a principal investigator on Planck. \u201cGround-based experiments should do so too,\u201d he says. But others argue that the ground experiments are cheap and that diversity makes for a healthy field. The one thing that everyone agrees on is that the science case for another CMB space mission is compelling. Efforts are afoot to make that happen after 2020. It may be an uphill battle. No CMB probe was ranked highly in NASA's 2010 Decadal Survey, a community-led review that sets scientific priorities to guide future mission selection. But there was a clause recommending a mid-decade review in the event that B modes were discovered. After BICEP2, the US CMB community, led by Hanany and Jamie Bock of the Jet Propulsion Laboratory in Pasadena, California, is urging that the case for such a mission be reappraised and funding be redirected from existing missions that have suffered delays. A consortium of US experimenters is proposing a follow-up to the present South Pole and Atacama telescopes. Known as CMB-S4, it would have hundreds of thousands of detectors and could come online after 2020 if it is given a high priority in a particle-physics review currently being carried out by the DOE and the NSF. Balloons could also play a part. \u201cA coherent programme is warranted,\u201d Hanany says. In Europe, a higher-resolution successor to Planck has not so far been selected by the European Space Agency. A revised mission is being drawn up for the next round of proposals, and if successful might be launched in the mid-2020s. But such complicated proposals are expensive and difficult to realize, Efstathiou says. 'Keep it simple' is now his mantra. He would like to see a small mission dedicated to observing B modes on large angular scales, thus targeting the gravitational-wave signature alone. In effect, it would be a BICEP2 experiment in space, says Peter Ade at Cardiff University, UK, who has built detectors for ground-based experiments and Planck. The technology is mature and he thinks such a mission could be ready in five years. A Japanese-led satellite proposal called LiteBIRD could be just such a mission. Proposed by physicists in Japan, in collaboration with experimenters in the United States, Germany and Canada, the project could be launched in the early 2020s if it received some US$100 million in funding. In the meantime, the researchers are developing a ground-based experimental version, called GroundBIRD. For all the uncertainties about the future, CMB scientists are in bullish mood. \u201cNature has been kind to us in giving us this clear view of the early Universe,\u201d Efstathiou says. \u201cWith a gift like that we should exploit it as much as we can.\u201d \n                     Cosmology: Polar star 2014-Mar-31 \n                   \n                     Telescope captures view of gravitational waves 2014-Mar-17 \n                   \n                     Cosmologists at odds over mysterious anomalies in data from early Universe 2013-Dec-13 \n                   \n                     How to see quantum gravity in Big Bang traces 2013-Sep-27 \n                   \n                     Waves from the Big Bang Special \n                   \n                     BBC CMB collection \n                   \n                     Scientific American 's CMB page \n                   \n                     Planck satellite \n                   \n                     BICEP2 \n                   \n                     Sean Carroll's Preposterous Universe blog \n                   Reprints and Permissions"},
{"file_id": "509414a", "url": "https://www.nature.com/articles/509414a", "year": 2014, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Techniques that transfer DNA from diseased human eggs to healthy ones \u2014 creating offspring with three biological parents \u2014 are on the verge of clinical use. Douglass Turnbull spends much of his time seeing patients who have untreatable, often fatal, diseases. But the neurologist has rarely felt more helpless than when he met Sharon Bernardi and her young son Edward. Bernardi had lost three children within hours of birth, owing to a mysterious build-up of acid in their blood. So it was a huge relief when Edward seemed to develop normally. \u201cHe did all his milestones: he sat up, he crawled and started to walk at 14 months,\u201d Bernardi recalls. But when he was about two years old, he began to fall over after taking a few steps; he eventually started having seizures. In 1994, when Edward was four, he was diagnosed with Leigh's disease, a condition that affects the central nervous system. Doctors told Sharon that her son would be lucky to reach his fifth birthday. Turnbull, who works at Newcastle University, UK, remembers despairing that \u201cwhatever we do, we're never going to be able to help families like that\u201d. His frustration sparked a quest to develop assisted-reproduction techniques to prevent disorders such as Leigh's disease, which are caused when children inherit devastating mutations in their mitochondria, the cell's energy-making structures. The procedures \u2014 sometimes called three-person  in vitro  fertilization (IVF) \u2014 involve transferring nuclear genetic material from the egg of a woman with mutant mitochondria into another woman's healthy egg. Turnbull and others have tested the techniques in mice, monkeys and human egg cells in culture; now, they say, it is time to try them in people. The UK Parliament is set to vote on the issue later this year; if legislation passes, the country would be the first to allow this kind of genetic modification of unborn children. But some scientists have raised concerns over the safety of the procedures, and an increasingly vocal coalition of activists, ethicists and politicians argues that a 'yes' vote will lead down a slippery slope to designer babies. US regulators and scientists are closely watching the debate as they consider allowing similar procedures. \u201cI admire what they've done in Britain,\u201d says Dieter Egli, a stem-cell scientist at the New York Stem Cell Foundation, a non-profit research institute. \u201cI think they are far ahead in discussion of this, compared to the US.\u201d \n               A fatal inheritance \n             The mitochondrion, according to one popular theory, was once a free-living bacterium that became trapped in a host cell, where it boosted the cell's capacity to generate the energy-carrying molecule ATP. As a result, each mitochondrion has its own genome \u2014 but it no longer has all the genes it needs to function independently (the human mitochondrial genome, for example, has a paltry 37 genes). Unlike the genome in the cell nucleus, which includes chromosomes from both parents, all of a person's mitochondria derive from the thousands contained in the mother's egg. For reasons still being studied, the mitochondrial genome is much less stable than the nuclear genome, accruing random DNA mutations about 1,000 times faster. As many as 1 in 5,000 children are born with diseases caused by these mutations, which affect power-hungry cells such as those in the brain and muscles. The severity of the conditions depends on the proportion of diseased mitochondria a mother passes on to her children. Turnbull first got interested in mitochondrial disease and energy metabolism in the late 1970s, when he was working as a junior doctor on a neurology ward. A member of the Royal Air Force arrived at his clinic with a mysterious ailment: whenever he went on training runs, his muscles would suddenly give out and force him to stop. Turnbull at first suspected that the airman had a mitochondrial disease \u2014 and although he turned out to be wrong, his curiosity was piqued.  This isn't 'designer babies'. This is about preventing serious, lifethreatening, disabling diseases.  Turnbull found that the treatment options for mitochondrial diseases were limited to managing symptoms, for example by prescribing anticonvulsant drugs to ward off seizures, rather than addressing the underlying biological problem. \u201cYou see them develop a mitochondrial disease and there's bugger all you can do about it,\u201d he says. The young neurologist went on to do a PhD on the inner workings of mitochondria, and has devoted his career to understanding how they malfunction. After Turnbull met the Bernardis in the mid-1990s, a muscle biopsy confirmed that Sharon carried mutant mitochondria. \u201cHe couldn't believe I looked so well,\u201d she says. The diagnosis helped Sharon to understand some of her health problems \u2014 and her family's. Her mother, it turned out, had lost several children, and was experiencing heart difficulties in her fifties; a cousin and other family members had also lost children. \u201cIt's been a family wiped out,\u201d says Bernardi, who lost three more babies after Edward was born. Her tragedy spurred Turnbull to seek ways to keep children from inheriting their mothers' mutant mitochondria. Others had been thinking along similar lines. In the 1980s, embryologists working with mice had begun using 'pronuclear transfer' techniques to investigate the developmental role of egg cells' cytoplasm. The procedures involve moving nuclear DNA from one fertilized egg to another, leaving in place most of the other contents, including the mitochondria. In 1995, researchers raised the idea that similar procedures could interrupt the transmission of mitochondrial diseases in human eggs 1 . Turnbull's laboratory began replicating the mouse research in the early 2000s, aiming to move quickly to human eggs. Working with Mary Herbert and Alison Murdoch, reproductive biologists at Newcastle University and an affiliated fertility clinic that provides IVF, they planned to start with eggs that had not been fertilized correctly and had no hope of generating a fetus. It took 18 months to convince regulators to allow the first experiments. The UK Human Fertilisation and Embryology Authority (HFEA) twice denied the team's application, on the grounds that the procedures would alter the \u201cgenetic structure\u201d of the egg \u2014 illegal under the 1990 Human Fertilisation and Embryology Act, which had established the agency. In response, the researchers argued that the term was vague and did not apply to pronuclear transfers. They filed a third appeal, this time with lawyers to argue their case, and won approval in 2005. Around the same time, the UK Parliament began updating the 1990 law. Revised legislation came into force in 2009 and prohibited clinical application of pronuclear transfers \u2014 but it allowed for the topic to be revisited by Parliament without passing entirely new laws, pending a full airing of the scientific, regulatory and ethical issues. The law change gave the Newcastle team hope that its experiments, if successful, could one day be translated to the clinic. \n               A steady hand \n             Human egg cells are one-tenth of a millimetre wide, and pronuclear transfers must be done under a microscope, in a specially designed chamber that controls temperature and air flow. It takes an expert embryologist with a steady hand: \u201cPeople don't breathe when they're doing this,\u201d says Herbert. First, a fertilized egg cell is zapped with a laser, making a hole in its membrane. Then the embryologist eases a pipette into the hole and plucks out the pronuclei, twin genetic structures that result from fertilization. Next, the researcher empties a fertilized donor egg of its genetic material and squirts the pronuclei into the hollow egg. The feat takes several minutes (see video). If the United Kingdom approves clinical use of the procedure, the egg would then be incubated for a few days until it develops into a blastocyst of between 50 and 200 cells, which would then be transplanted into a woman's uterus. In a paper published in May 2010, the Newcastle researchers showed 2  that the abnormally fertilized eggs they had been using could undergo pronuclear transfer and then develop in culture almost as well as untouched egg cells. Crucially, the transferred pronuclei brought few mitochondria with them, suggesting that a resulting embryo would largely be free of any disease-causing mutant mitochondria. But many questions remained. Could the transfers be done efficiently enough that a woman could hope to become pregnant? Did they cause subtle molecular or genetic changes that might hinder further development or cause health problems after birth? And would the UK government ever allow them to reach the clinic? The Newcastle team has spent the past few years looking for answers, optimizing its technique in healthy human eggs. \u201cWe're reasonably comfortable there's a chance of pregnancy with this,\u201d says Herbert. The still-unpublished experiments have proceeded slowly, partly because healthy human eggs for experimentation are hard to come by. But Herbert says that the group has already performed more than 100 pronuclear transfers on such eggs. It also hopes to conduct safety studies to assess whether the procedures alter the transferred genome or epigenome. But such checks cannot provide complete reassurance before the leap into humans, the researchers acknowledge. \u201cWe can never say for sure that it's 100% safe,\u201d says Herbert. \u201cIt has to, at some point, go to treatment.\u201d \n               Battle lines \n             In 2010, the Newcastle researchers asked the UK government to consider changing the law that prohibits them from conducting their mitochondrial-replacement procedure in humans. The request prompted a flurry of hearings, consultations and reports, involving independent scientists, bioethicists, regulators, the general public and others; another scientific review is expected in the next few weeks. But the protracted process has thrown up no major roadblocks. Nancy Lee, a senior policy adviser at the Wellcome Trust, the United Kingdom's largest biomedical-research charity, praises the review as \u201ca good example of evidence-based policy-making and informing the public as much as is possible\u201d. The London-based charity has funded Turnbull's team to the tune of \u00a34.4 million (US$7.4 million), and has thrown its considerable political clout behind changing the law.  I think what everybody was a little bit uncomfortable with was just HOW much is not known.  Yet some scientists argue that the procedures have not been vetted rigorously enough. Klaus Reinhardt, an evolutionary biologist at the University of T\u00fcbingen in Germany, worries about incompatibilities between the nuclear and mitochondrial genomes in individuals conceived using the procedures. Both nuclear and mitochondrial genes are needed for mitochondria to function, and it is likely that gene variants in both structures have evolved together, he says. Mitochondrial replacement in mice, fruit flies and other organisms has occasionally resulted in problems with respiration, cognition and fertility, several studies have found 3 . Reinhardt, who has expressed his concerns to the panel in charge of reviewing the science, questions whether there are enough safety data to go forward with clinical trials. \u201cI don't really know how robust everything is,\u201d he says. In response, Turnbull's team casts doubt on the relevance of mitochondrial-replacement experiments that use inbred lab animals, and points out that other studies of mitochondrial replacement in mice failed to find health problems 4 . Some critics use more emotive language. In a March Parliamentary debate and a column in  The Daily Telegraph , Conservative Member of Parliament Jacob Rees-Mogg equated mitochondrial replacement with cloning, and said that the techniques would promote eugenics. \u201cIn a country nervous about genetically modified crops, we are making the foolhardy move to genetically modified babies,\u201d he said in the debate. An international coalition of several dozen scholars and bioethicists, many at religious institutions, expressed similar sentiments in March 2013 in a letter to  The Times  newspaper, arguing that mitochondrial replacement \u201cwould open the door to further genetic alterations of human beings with unforeseeable consequences\u201d. To counter this opposition, Turnbull and other supporters point out that the techniques will be used only to prevent serious mitochondrial diseases. The researchers have made patients' stories, such as the plight of the Bernardi family, central to their appeals. They have compared mitochondrial replacement to changing the batteries in a camera (a poor analogy, some other scientists say), and they argue that mitochondrial DNA makes up a tiny fraction of the overall genome, with little influence over a person's defining traits. \u201cThis is not a slippery slope, in my view,\u201d Turnbull says. \u201cThis isn't 'designer babies'. This is about preventing serious, life-threatening, disabling diseases.\u201d \n               Monkey trial \n             A similar debate is shaping up across the Atlantic. While Turnbull and his team were developing their pronuclear-transfer technique in human egg cells, a US team was testing a related method in monkeys. In 2009, reproductive biologist Shoukhrat Mitalipov at the Oregon Health and Science University in Beaverton and his colleagues reported the birth of two healthy rhesus macaques whose mitochondria and nuclei had come from different egg cells 5 . The monkey twins \u2014 named Mito and Tracker, after a reagent used to make mitochondria glow \u2014 were conceived through a method called maternal spindle transfer (see 'Genome transplant'). This involves shuttling an egg's nuclear genetic material to an empty donor egg before fertilization, rather than after as in pronuclear transfer. There have not yet been any side-by-side experiments to compare the merits of the two techniques, although both teams are keen to try. Mitalipov's team has used maternal spindle transfer to conceive five monkeys, including one from a previously frozen egg (to mimic a likely clinical situation). Mito, Tracker and two others born in 2009 have celebrated their fifth birthdays, and are still healthy. Mitalipov plans to breed them soon to determine their fertility. His team has also proved its technique in human eggs: the embryos formed blastocysts, albeit at a low rate, and produced embryonic stem cells with the potential to give rise to all the body's different tissues 6 . In unpublished work, the researchers have since drastically improved the efficiency of the procedure, he says. \u201cNow we want to transplant these embryos.\u201d First, he will need approval from the US Food and Drug Administration (FDA). The agency has required researchers to seek permission for mitochondrial transfers since 2001, after a New Jersey fertility clinic carried out dozens of procedures that involved moving small amounts of cytoplasm \u2014 including some mitochondria \u2014 between human eggs to improve conception rates (see 'An unplanned experiment'). \n               boxed-text \n             Mitalipov last year put in a proposal to carry out clinical trials in humans, and an FDA advisory panel met in February to discuss the issue. The committee spent two days chewing over the same questions that the United Kingdom has been grappling with, such as how to establish the safety and effectiveness of the procedures in cells and animal models, and what the first patient trials might look like. Committee chair Evan Snyder, a stem-cell biologist at Sanford-Burnham Medical Research Institute in La Jolla, California, says that most of his colleagues are disposed to take cellular therapies to patients, and that they recognize the potential to unshackle families from the consequences of mitochondrial mutations. But, he says, \u201cI think what everybody was a little bit uncomfortable with was just how much is not known\u201d. Some panel members wanted to see multiple generations of monkeys born healthy using the procedures, as well as more safety work on human eggs. Mitalipov found the meeting frustrating: \u201cI don't want to go back and do another decade or two decades of research, which we can do. But meanwhile, there will be thousands and thousands of children born every year that will suffer.\u201d He says he would consider moving his lab to Britain to help bring his research to patients more quickly. Snyder, however, senses that his committee is not far from green-lighting clinical trials, and that safety hurdles could be surmounted in two or three years. Back in the United Kingdom, the legislation to allow mitochondrial replacement is still being hammered out \u2014 a consultation of the draft law finishes on 21 May \u2014 but proponents are quietly confident that Parliament will say yes. The move has support across the political spectrum, and most of the scientific and ethical advice given to the government has been encouraging. However, a law change would merely give the HFEA the power to allow the procedures, and the agency would probably want more safety and effectiveness data before it approved any trials. Bernardi hopes that clinical trials will eventually go ahead. But \u201cI think it would be bittersweet if somebody had a baby\u201d conceived with the procedures, she adds. Her son Edward lived well beyond the expectations, although he was eventually confined to a wheelchair and his health worsened in waves as doctors struggled to find medications to quell symptoms including spasms that rendered his arms stiff and immobile. Bernardi strove to give him a normal life: he attended school, went on class trips and developed crushes. \u201cHe liked his girls, he did,\u201d she says. Bernardi resisted feeding him through a tube until he was unable to eat normally, at the age of 20. \u201cUp until the last ten weeks, I would say he had a very good quality of life,\u201d she says. Edward Bernardi died in March 2011 after a 21-year struggle with Leigh's disease. \u201cI don't think this would benefit me,\u201d says Bernardi of the procedures that may be on the cusp of helping other women with mitochondrial disease. \u201cBut this keeps Edward's legacy.\u201d\n Reprints and Permissions"},
{"file_id": "509418a", "url": "https://www.nature.com/articles/509418a", "year": 2014, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "A rash of road construction is causing widespread change in the world's largest tropical forest \u2014 with potentially global consequences. Next to a newly paved highway in the Peruvian Amazon, a discreet white-on-green sign urges travellers to protect the surrounding ecosystem. \u201cLet's care for the environment, let's conserve the forest,\u201d it reads. But the appeal comes too late for this spot in the region known as Madre de Dios. Before the route was paved a few years ago, tall trees lined the roadside, but the forest edge here now lies about half a kilometre away, beyond a jumble of underbrush and freshly cut trees where a cattle pasture was recently carved out of the woods. As drivers head east and enter Brazil, the view is much the same for hundreds of kilometres. Such is the impact of the Interoceanic Highway, a route some 5,500 kilometres long that cuts clear across South America. The highway is just one strand in a web of roads that now criss-cross the Amazon. So far, most have encroached on forest around the edges of the basin, but they are increasingly slicing through the middle. In Brazil alone, the Amazon road system grew by an average of almost 17,000 kilometres a year between 2004 and 2007 (ref.  1 ). Across the basin, estimates for the total length of roads vary widely from about 100,000 to 190,000 kilometres of paved and dirt roads cutting through the Amazon. Once construction begins, road crews are quickly followed by land speculators, loggers, farmers, ranchers, gold miners and others who carve away the forest along the route. That activity leaves obvious scars on the landscape in the form of treeless expanses, but research is now showing that the building of roads also triggers a cascade of environmental changes in the remaining forest that can dry out trees, set the stage for wildfires and weaken the ecosystem. \u201cPut a road into a frontier area and it opens a Pandora's box,\u201d says biologist William Laurance of the Centre for Tropical Environmental & Sustainability Science at James Cook University in Cairns, Australia. The drying brought about by roads influences local atmospheric circulation patterns and can have farther-reaching effects that not only compromise the health of the Amazon but can also contribute to global warming by releasing carbon stored in the forest. Understanding those details is crucial, researchers say, for determining whether these effects \u2014 combined with severe droughts such as those that struck parts of the Amazon basin in 2005, 2007 and 2010 \u2014 could tip the world's largest expanse of tropical forest from being a net absorber of carbon dioxide to a net emitter 2 . \n               The first cut \n             It was a road that kicked off the pattern of destruction in the Amazon forest. In the 1970s, Brazil began building the Trans-Amazonian Highway from near the country's easternmost point on the Atlantic coast to its western border, where the state of Amazonas meets Peru. The route opened up the heart of the Amazon to logging, ranching and settlement, causing deforestation rates to soar. Extreme spells in the 1990s and early 2000s claimed more than 25,000 square kilometres a year \u2014 an area bigger than New Jersey. Since 2005, government measures, including crackdowns on illegal logging, have slowed forest loss. Throughout, roads have provided the means to penetrate the forest and erase large chunks of it. In an unpublished study of the Brazilian Amazon, Christopher Barber, a researcher at South Dakota State University in Brookings, found that 95% of deforestation in the region occurs within 7 kilometres of a road. And that is not the only problem: just as serious as outright deforestation is fragmentation, which happens when loggers, ranchers and farmers move in. In Brazil, up to 38,000 kilometres of new forest edge are created each year 3 . Standing in a field in the western Brazilian state of Mato Grosso, Michael Coe can feel the difference that deforestation makes in the Amazon. An atmospheric scientist who heads the Amazon programme of the Woods Hole Research Center in Falmouth, Massachusetts, Coe is visiting an 80,000-hectare patch of former forest that was originally cleared some years ago to build a cattle ranch, which later morphed into a soya-bean farm. The air is noticeably hotter and drier in the field than in one of the few patches of forest left on the farm. Coe and his colleagues are here to study how forest degradation and fires alter the flow of water and energy in the Amazon ecosystem. Evapotranspiration from trees provides moisture to the air and feeds much of the precipitation in the Amazon: when the trees disappear, so does a major source of moisture. A study using satellite data and models of atmospheric circulation suggests that air passing over tropical regions rich in vegetation produces at least twice as much rain as air moving over areas with little vegetation 4 . Stripping away trees not only eliminates a source of moisture; it also changes the regional air flow. Heat rising from a bare field creates a low-pressure system that pulls in air from the surrounding area, sucking moisture out of the nearby forest, says Coe.  We're looking at a tidal wave of road expansion happening in the next few decades.  As the forest dries, it transfers less moisture to the atmosphere, changing rainfall patterns hundreds or thousands of kilometres downwind. That could affect not only forests and agriculture across the basin, but also the amount of water available to power hydroelectric dams. In a simulation using climate, hydrological and land-use models, Coe and his colleagues projected that reductions in rainfall caused by deforestation could drastically cut the power-generating capacity of Amazonian dams 5 . That would upset the plans of Brazil, Peru and Ecuador, which intend to increase hydropower to meet rapidly growing electricity demands. The drying effect reaches well past the forest's edge. And the more fragmented the forest, the wider the impact, according to one study that found canopy drying 2.7 kilometres from the edge of a highly fragmented forest 6 . The influence of roads in the Amazon could even reach around the world. Recent lines of research suggest that changes in several factors prevent trees in disrupted forests from storing as much carbon as they did in the past, a shift that could accelerate global warming. Greg Asner, a tropical ecologist at the Carnegie Institution for Science at Stanford University in California, studies the chemistry of the tree canopy in the Amazon using ground plots and airborne spectrometers. He is finding that the forest canopy along the edges of open patches does not seem to hold as much water or pigment, such as chlorophyll, as trees in unbroken parts of the forest. \u201cNot enough chlorophyll and not enough water keep the canopy from soaking up carbon dioxide at the rate that we know it can, compared to the more interior forest,\u201d he says. \n               Line of fire \n             Changes in the Amazon's fire potential are also impeding the forest's ability to store carbon. Conventional wisdom has long held that the rainforest was too humid to burn. But in 2005, when drought struck the western Amazon, wildfires in the Brazilian state of Acre merged into a line 11 kilometres long, with flames leaping to canopy height, recalls Foster Brown, an environmental geochemist at the Woods Hole Research Center who witnessed the fires. The flames damaged more than a quarter of a million hectares of forest in that state alone and caused US$100 million in damages. Smoke blanketed Rio Branco, the state capital, and public-health concerns finally led to ordinances to control burning during times of drought. Scientists considered the 2005 drought to be a once-in-a-century event; some 70 million hectares of forest suffered water stress 7 , and there was significant drying within the tree canopy. But five years later, a similar dry spell struck, triggering another extreme bout of fires. Because they have not evolved in an environment frequently beset by fires, trees in the Amazon forest are susceptible to heat and damage from flames. Farther east, in Brazil's Xingu region, researchers saw similar results from experimental fires during a drought in 2007. Tree mortality from heat and fire damage that year was more than four times that of a normal year 8 , especially along the forest edge, which the researchers burn every three years in a cycle emulating traditional Amazonian agricultural practices, says ecologist Paulo Monteiro Brando of Brazil's Amazon Environmental Research Institute in Bras\u00edlia. In the Amazon, burning is the cheapest and most effective way for farmers to clear fields and give them a nutrient boost before planting crops, or rid them of ticks that plague livestock. Understanding the future of the Amazon means learning how to model not just physical and atmospheric processes, but also how humans are changing the land, researchers say. And as the wider impact of Amazonian roads becomes clearer, planners and conservationists face a dilemma. Although roads threaten the forest's health, they also significantly lower costs for farmers and businesses, and can make a difference between life and death for people in remote areas far from hospitals. But unrestricted road building could lead to irreparable environmental harm, say researchers. \u201cWe're looking at a tidal wave of road expansion happening in the next few decades,\u201d Laurance says. \u201cIt's ecological Armageddon, and it's happening again and again.\u201d \n                     Atmospheric science: Drought and fire change sink to source 2014-Feb-05 \n                   \n                     Drought sensitivity of Amazonian carbon balance revealed by atmospheric measurements 2014-Feb-05 \n                   \n                     The Amazon basin in transition 2012-Jan-18 \n                   \n                     Amazon drought raises research doubts 2010-Jul-20 \n                   \n                     Climate change crisis for rainforests 2009-Mar-05 \n                   \n                     Modelling conservation in the Amazon basin 2006-Mar-23 \n                   \n                     Blog post: Carnegie scientists unveil initial data on Amazon drought \n                   \n                     Blog post: Amazon deforestation drops to record low \n                   \n                     NSF drought and fire in the Amazon \n                   \n                     World Bank on Brazil's fight against global warming \n                   Reprints and Permissions"},
{"file_id": "516311a", "url": "https://www.nature.com/articles/516311a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "Ten people who mattered this year. Andrea Accomazzo: Comet chaser | Suzanne Topalian: Cancer combatant | Radhika Nagpal: Robot-maker | Sheik Humarr Khan: Ebola doctor | David Spergel: Cosmic sceptic | Maryam Mirzakhani: Surface explorer | Pete Frates: Ice-bucket challenger | Koppillil Radhakrishnan: Rocket launcher | Masayo Takahashi: Stem-cell tester | Sjors Scheres: Structure solver | Ones to watch \n               ANDREA ACCOMAZZO: Comet chaser \n             A former test pilot steered the Rosetta mission to an icy world in deep space .  By Elizabeth Gibney Nearly two decades ago, Andrea Accomazzo got into trouble with his girlfriend when she found a scrap of paper on his desk. In his handwriting was scrawled a phone number next to a female name: Rosetta. \u201cShe thought it was a girl,\u201d says Accomazzo. \u201cI had to explain to my jealous Italian girlfriend that Rosetta is an interplanetary mission that is flying to a comet in almost 20 years.\u201d Ever since, Accomazzo has divided his attention. He eventually married his girlfriend and has also spent the past 18 years pursuing the comet 67P/Churyumov\u2013Gerasimenko. As flight director for the mission, Accomazzo led the team that steered Rosetta to its August rendezvous with the comet, following a 6.4-billion-kilometre journey from Earth. The pinnacle of the project came in November, when Rosetta successfully set down a lander named Philae, providing scientists with the first data from the surface of a comet and making it one of the most successful missions in the history of the European Space Agency (ESA). Accomazzo did not act alone: it took a large operations team at ESA to manoeuvre Rosetta with enough precision to drop Philae down just 120 metres from the centre of the landing zone. \u201cGiven that we'd had a 500-metre error circle, that was not a bad shot,\u201d says Fred Jansen, who led the mission. When Philae's anchoring systems failed, the craft bounced into a shady site where it could not charge its solar panels, so the lander lost power after 64 hours. But in that time, it gathered a trove of data that will add to the information collected by Rosetta about the comet's structure and composition. Armed with those insights, scientists hope to better understand the origin and evolution of the Solar System, including whether comets could have brought water and organic molecules to Earth during its infancy. Accomazzo started off his career focused on a different type of flight. He first trained as a test pilot in the Italian Air Force. But although he loved flying, he found the culture too constraining and after two years he quit to study aerospace engineering. With his quiet, hard-working, sometimes no-nonsense nature, colleagues say that Accomazzo brings a bit of the military with him into mission control. For Accomazzo, the biggest parallel between flying a fighter jet and Rosetta is the need for split-second judgements. \u201cYou have to prepare and train a lot to be able to make the right decision, very quickly,\u201d he says. Between launch and landing, his team ran 87 full-day simulations. Although the Rosetta mission has been a broad success, Accomazzo still cried when he heard that Philae had died, and hopes the lander will revive when the comet approaches the Sun. After swinging around the Sun in August 2015, the comet will head back out towards deep space. By early 2017, there will be too little sunlight to power Rosetta, and Accomazzo is planning a daring finale. He would love to see the craft skim above the surface of the rubber-duck-shaped comet through the valley that separates its body and head. The team might even try to land the spacecraft on the comet's surface. The decision might not be up to him. Accomazzo is stepping away from the day-to-day flight operations at Rosetta and is busy preparing for ESA's interplanetary missions to Mercury, Mars and Jupiter. Even with such exciting projects, he finds it hard to leave Rosetta behind. \u201cIt's a bit sad,\u201d he says. \u201cI don't know how I will be able to cope.\u201d He still dreams of Rosetta. \u201cThis morning I woke up at 4 a.m. and thought 'something is wrong',\u201d he says. \u201cAt 7.30 a.m. I got a call \u2014 Rosetta had briefly lost signal to Earth at 4 a.m. \u2014 I often have this kind of episode. I'm totally linked.\u201d \n               SUZANNE TOPALIAN: Cancer combatant \n             One clinician always believed that cancer immunotherapy would work \u2014 and she was right .  By Heidi Ledford When Suzanne Topalian heard in July that a therapy she had helped to pioneer could now be prescribed to treat people with advanced melanoma, she greeted the news with excitement, but also characteristic resolve. The meticulous cancer researcher and physician was already focused on the field's next challenges: approval for the drug in other countries and against a wider range of cancers. \u201cAlthough this was reason to celebrate, we're still looking towards the horizon,\u201d she says. The drug in question is part of a hot new class called PD-1 inhibitors, which allow T cells in the immune system to jump into high gear so that they are free to attack tumours. This July, Japanese regulators approved the first such drug \u2014 nivolumab, made by Bristol-Myers Squibb of New York \u2014 largely on the back of clinical trials that Topalian led. Two months later, the US Food and Drug Administration approved another, called pembrolizumab. Some analysts predict that the drugs will become a cornerstone of cancer treatment, with a market exceeding US$10 billion by 2020. Even as a medical student, Topalian says, she was hooked by the idea of turning the body's own defences against cancer rather than \u2014 as most other therapies do \u2014 attacking a tumour directly with radiation or drugs. In 1985, she joined the lab of tumour immunologist Steven Rosenberg at the US National Cancer Institute in Bethesda, Maryland. She intended to leave after 2 years; instead, she stayed for 21 and set up her own lab. Rosenberg says that Topalian quickly made her mark as a talented, careful scientist who always kept the big picture in mind. \u201cShe was totally passionate about finding effective cancer treatments,\u201d he says. Even when sceptics doubted that cancer immunotherapy would work, and early clinical trials looked disappointing, Topalian was undeterred. \u201cThere would always be some patients who responded to those treatments,\u201d she says. \u201cIt was those exceptional responders who kept hope alive.\u201d In 2006, Topalian left Bethesda to help to launch trials of nivolumab at Johns Hopkins University in Baltimore, Maryland. That work led to a landmark publication in 2012 showing that nivolumab produced dramatic responses not only in some people with advanced melanoma but also in those with lung cancer \u2014 the world's most common cause of cancer death (S. L. Topalian  et al .  N. Engl. J. Med.   366 , 2443\u20132454; 2012 ). Regulators are now considering approval of the drugs for treatment of lung cancer. Other researchers are pouring into the field, spurred by successes with PD-1 inhibitors and other cancer immunotherapies, says Jedd Wolchok, an oncologist at the Memorial Sloan Kettering Cancer Center in New York. \u201cIt's legitimized a field that was once scorned,\u201d he says. \n               RADHIKA NAGPAL: Robot-maker \n             A researcher inspired by social insects gets robots to coordinate on a massive scale .  By Corie Lok When Radhika Nagpal was a high-school student in India, she hated biology: it was the subject that girls were supposed to study so that they could become doctors. Never being one to follow tradition, Nagpal was determined to become an engineer. Now she is \u2014 leading an engineering research team at Harvard University in Cambridge, Massachusetts. But she also has a new appreciation for the subject she once disliked. This year, her group garnered great acclaim for passing a milestone in biology-inspired robotics. Taking their cue from the way in which ants, bees and termites build complex nests and other structures with no central direction, Nagpal's group devised a swarm of 1,024 very simple 'Kilobots'. Each Kilobot was just a few centimetres wide and tall, moved by shuffling about on three spindly legs and communicated with its immediate neighbours using infrared light. But the team showed that when the Kilobots worked together, they could organize themselves into stars and other two-dimensional shapes (M. Rubenstein  et al .  Science   345 , 795\u2013799; 2014 ). Achieving that level of cooperation in a swarm this large was a major feat, says Alcherio Martinoli, a roboticist at the Swiss Federal Institute of Technology in Lausanne. Nagpal's approach \u2014 combining theoretical proofs with a physical demonstration of swarm behaviour \u2014 \u201cis, to me, extremely powerful and something other people should follow\u201d, he says. The hope is that this kind of swarm-robotics research will eventually lead to self-organizing robot teams that can rapidly respond to disasters, say, or aid in environmental clean-up. But getting even this far took much longer than Nagpal and her team originally estimated. The original idea for the Kilobots is four years old, says Nagpal. Like other swarm-robotics researchers, her team had been doing computer simulations and small laboratory experiments. But then one of her postdocs, Michael Rubenstein, convinced her that it was possible to do much larger experiments, because advances in electronics, materials and three-dimensional printing were making it easier and cheaper than ever to create robots en masse. The team struggled to go from building 20 autonomous robots \u2014 their largest group at the time \u2014 to the full-sized swarm of 1,024 Kilobots. The key turned out to be simplicity, says Nagpal. \u201cThe individuals would be less calibrated, have lower-quality components and would have less control over what they do,\u201d she says, but they would still need to carry out complex tasks by working together. \u201cSomehow, at the top, we would have to think of algorithms that didn't depend on precision at the individual level.\u201d Nagpal is now trying to develop large robot swarms that can self-assemble into structures in three dimensions. And she will continue to draw her inspiration from nature, she says \u2014 a practice she learned from her graduate-school adviser, computer scientist Gerald Sussman at the Massachusetts Institute of Technology in Cambridge. Sussman convinced her to set aside her distaste for biology when he pointed out that cells are the ultimate computers, able to take in data from signalling molecules, and to carry out complex chemical calculations to decide how to act. And then there are the extraordinary things that happen when these cell-computers come together, says Nagpal. \u201cAt the end, you get this functioning organism and it's so amazing that you forget that it's even composed of cells,\u201d she says. This is a key goal in swarm-intelligence research: using the collective to accomplish much more than the individual. \u201cLooking at biology makes me think differently about computer science,\u201d she says. \n               SHEIK HUMARR KHAN: Ebola doctor \n             An infectious-disease expert battled a killer virus in Africa .  By Erika Check Hayden In this year's devastating outbreak of Ebola, Sheik Humarr Khan played a unique part. He was a scientist \u2014 part of the team that performed the first genetic sequencing studies of the virus in his native Sierra Leone. He was an infectious-disease doctor who turned down an invitation to leave his country so that he could stay and treat patients. He also became one of its many victims, dying on 29 July. Ebola brought devastation to Guinea, Sierra Leone and Liberia as it ballooned into an epidemic during 2014. Khan was the lead physician at Sierra Leone's Kenema Government Hospital, where he was treating and studying Lassa, another potentially fatal viral disease, until the hospital was overwhelmed by people with Ebola. According to those who knew him, Khan believed that research and medicine should serve everyone \u2014 not just those able to access and afford it \u2014 and he had eschewed offers to make more money working in the capital, Freetown, to stay in the underserved rural region of Kenema. \u201cThat was one of the more important examples he set,\u201d says John Schieffelin, a physician at Tulane University in New Orleans, Louisiana, who worked with Khan. Khan became a central figure in the Kenema community and when Ebola struck, he cancelled his plans to teach abroad. When he became sick himself, his doctors decided not to give him the experimental treatment known as ZMapp in case it backfired and caused dangerous side effects. Some staff at the hospital worried that his death would spark civil unrest. \u201cThey said that if Dr Khan dies, people in Kenema are going to tear the hospital down,\u201d remembers Lina Moses, an epidemiologist also at Tulane who spent much of the year working in Kenema. The outbreak now looks as though it is levelling off, and drug and vaccine trials are getting under way. The research that Khan was involved in showed how quickly the virus was mutating, and the team he worked with is now installing genetic sequencers throughout West Africa so that they can continue to track its evolution. But the toll has been great: Ebola has killed around 6,300 people, including many doctors and other health-care workers. Recovering from this loss of scarce experts will be a tremendous challenge, says Estrella Lasry, a tropical-medicine specialist for M\u00e9decins Sans Fronti\u00e8res (Doctors without Borders) in New York City. \u201cIt's going to take years before the same number of people who died are trained\u201d. \n               DAVID SPERGEL: Cosmic sceptic \n             An astrophysicist found errors in a major discovery about cosmic inflation .  By Ron Cowen David Spergel first spotted the blunder while on a train in late March. Ten days earlier, researchers had made front-page headlines by holding a press conference announcing the probable detection of gravitational waves from the far reaches of space. That long-sought signal provided evidence that the infant Universe had undergone a brief but enormous expansion called cosmic inflation, and the result had prompted talk of a Nobel prize for the team, which was led by John Kovac of the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts. Spergel was troubled from the start by the evidence that Kovac's team had gathered from the BICEP2 telescope at the South Pole. As an astrophysicist who studies the early Universe at Princeton University in New Jersey, he worried that the signal might be an artefact. On the train, en route to giving a lecture in New York City, he realized that the BICEP2 team had made a mistake when accounting for how nearby dust might alter the long-distance signal. He raised his concerns in his talk, and in May he co-authored a paper that pointed out the flaws (R. Flauger  et al . Preprint at  http://arxiv.org/abs/1405.7351 ; 2014 ). Spergel, who sports a shaved head and a voice that can fill a room, decided that he needed to speak out. \u201cI wanted to let the broader physics community know there were reasons to have doubts,\u201d he says. Social media amplified his criticisms. A video of his New York talk drew nearly 2,000 views, alerting others to the controversy. Soon, talk of a Nobel prize for the BICEP2 team was eclipsed by discussions about how it had made a cosmic mistake. When the BICEP2 researchers published their findings in June (P. A. R. Ade  et al .  Phys. Rev. Lett.   112 , 241101; 2014 ), they were more tentative than at the press conference \u2014 although not enough to satisfy Spergel. A forthcoming analysis of satellite data may soon settle the controversy. For cosmologist Marc Kamionkowski of Johns Hopkins University in Baltimore, Maryland, the episode shows the danger of announcing major results too early. Although the BICEP2 researchers may have had good reasons to hold a press conference, he says, \u201cthey or others in a similar situation in the future may lean towards awaiting some vetting\u201d. \n               MARYAM MIRZAKHANI: Surface explorer \n             A mathematician's award shines a light on a lack of women in the field .  By Erica Klarreich When Maryam Mirzakhani was a mathematics graduate student at Harvard University in 2003, she went to her adviser, Curtis McMullen, with a question. McMullen had just solved a long-standing problem related to the behaviour of billiard balls on a type of abstract table that can be folded up into a doughnut surface with two holes. It was a major discovery, but Mirzakhani asked why he had proved it just for surfaces with two holes, rather than for complex surfaces with even more. She was drawn to the largest possible problem \u2014 even if she had no idea, back then, just how hard it would be to solve. \u201cMaybe sometimes not knowing enough is a blessing,\u201d she says, \u201cbecause then you just do your thing.\u201d Mirzakhani, now at Stanford University in California, turned this problem over in her mind for almost a decade, until she found an answer. In a 172-page paper written in 2012 with Alex Eskin of the University of Chicago, Illinois, she extended McMullen's result to all surfaces with two or more doughnut holes, tying together disparate mathematical fields such as geometry, topology and dynamical systems (A. Eskin and M. Mirzakhani Preprint at  http://arxiv.org/abs/1302.3320 ; 2013 ). \u201cIt's a spectacular result,\u201d says Howard Masur, a mathematician at the University of Chicago. In August, Mirzakhani was awarded the Fields Medal, often called mathematics' Nobel prize, for this and other advances in pure mathematics. Among her other findings is a surprising link between hyperbolic geometry \u2014 the geometry of saddle shapes \u2014 and string theory. Mirzakhani is humble \u2014 when she got word of her award, she assumed it came from a hacked e-mail account \u2014 and extremely private. She kept a low profile after her prize was announced, but the news was greeted with an explosion of interest elsewhere. It raced through social media and the press, reaching outlets such as the fashion magazine  Elle  and the feminist blog Jezebel. Most of the discussion was not about abstract surfaces, however: it was about how the Iranian-born mathematician was the only woman to receive the Fields Medal since the prize was first awarded in 1936. The commotion threw a spotlight on the vast under-representation of women in mathematics: according to a 2012 survey of US universities by the American Mathematical Society, women make up only 30% of PhD students \u2014 a number that has not budged for years \u2014 and only 12% of tenured faculty members at PhD-granting universities. Those who do become tenured mathematics professors receive a disproportionately small number of scholarly awards. Mirzakhani says that she has not encountered any outright discrimination against women, but that there are subtle cultural forces that can undermine their confidence, such as a shortage of peers and a perception among girls that mathematics isn't \u201ccool\u201d. She hopes her award will inspire confidence in female mathematicians \u2014 and others believe that it will change how they are perceived. From now on, \u201cno one will be able to think about the Fields Medal without picturing Maryam Mirzakhani\u201d, says Ruth Charney, a mathematician at Brandeis University in Waltham, Massachusetts, and president of the Association for Women in Mathematics. \u201cIt's a clear signal that there are women doing absolutely top-notch mathematics \u2014 in case anyone wasn't sure.\u201d Mirzakhani is sure, and she predicts more female Fields Medal winners soon. Meanwhile, she is focusing on pushing her analysis of billiard surfaces even further. She regards herself as a discoverer, not an inventor, of mathematics. \u201cI see it as exploring some unknown territory,\u201d she says. \u201cIt's an adventurous thing, trying to find the connections.\u201d \n               PETE FRATES: Ice-bucket challenger \n             A patient advocate helped to kick-start the social-media stunt of the year \u2014 with huge returns for research .  By Sara Reardon In the two-and-a-half years since he was diagnosed with amyotrophic lateral sclerosis (ALS), 29-year-old Pete Frates has lost the ability to speak or move. But in November, the former university baseball coach was the guest of honour at a sporting-goods shop near his home in Beverly, Massachusetts, where he sat with his newborn daughter in his lap and watched a Christmas celebration that featured an actor dressed as Santa Claus dousing himself with snow. Santa was paying homage to the 'Ice Bucket Challenge', in which people post and share videos of themselves dumping ice water over their heads to raise awareness and donations for ALS research. Frates first promoted the idea in August, through posts to Facebook and YouTube that he dictated using eye-tracking software. Since then, it has become one of the most lucrative social-media fund-raisers ever for biomedical research \u2014 and has led advocates for other little-known diseases to wonder whether similar efforts could also help them to raise money. The ice-bucket idea did not originate with Frates's posts \u2014 similar challenges had been used in other social-media campaigns. But his efforts, along with posts by Pat Quinn of Yonkers, New York, who also has ALS, did a lot to help the challenge go viral. Both men urged Internet users to show solidarity by posting videos. The meme morphed into a fund-raising campaign: either dump water on your head or donate money to ALS research, then challenge friends to do the same. Many people chose both. So far, participants from around the world have posted at least 17 million ice-bucket videos on Facebook, and raised more than US$115 million \u2014 almost three times the $40 million the US National Institutes of Health spent on ALS research last year. Critics say that the Ice Bucket Challenge is a fad and that its focus on a disease affecting around 500,000 people worldwide could draw attention away from deadlier threats, such as heart disease, which kills 7.4 million people every year. Nevertheless, the strategy has caught the attention of other advocacy groups. The National Organization for Rare Disorders in Danbury, Connecticut, held a seminar in October on viral fund-raising campaigns, and is planning a follow-up session owing to its popularity. Back in Massachusetts, the Frates family still hopes that the Ice Bucket Challenge will one day pay off for ALS. \u201cWhen there is a treatment,\u201d says Pete's father, John Frates, \u201cit will go back to August 2014.\u201d \n               KOPPILLIL RADHAKRISHNAN: Rocket launcher \n             India's space chief led the country's charge to Mars .  By T. V. Padma Koppillil Radhakrishnan knew the odds were against him when India's Mangalyaan space probe closed in on Mars this year. As head of the Indian Space Research Organisation (ISRO), he was well aware that half of all attempts to reach Mars have ended in failure. But the ISRO had taken lessons from other countries' mistakes, and it set modest aims for its first interplanetary mission, which it billed as a technology demonstration. When Mangalyaan settled successfully into Mars orbit on 24 September, India joined the elite group of nations with the ambition and technical capability to explore the Solar System. In his 43 years as an engineer and manager at the ISRO, Radhakrishnan has led a diverse set of projects, from developing remote-sensing satellites to setting up India's tsunami-warning system. The Mars mission was a gamble, but it caused less heartache than the ISRO's work on a cryogenic rocket engine that had failed during a launch in 2010 and finally succeeded this year. \u201cThe Mars mission was a slightly more joyous occasion,\u201d he says, while playing down his own role. \u201cI was like a conductor of an orchestra.\u201d The Mars mission has put the spotlight on Asia's space ambitions. India plans in the next three years to launch its second Moon mission, and China aims to bring lunar samples back to Earth by 2017. India's success this year drew widespread applause. \u201cThis is good for India and its economy, demonstrating the ability to develop and implement high-technology enterprises,\u201d says Raymond Arvidson, a planetary scientist at Washington University in St. Louis, Missouri. Radhakrishnan says that India's space plans should not be judged against those of other countries: \u201cWe are not racing with anyone. We are only racing with ourselves.\u201d But he will soon leave the race. Radhakrishnan will retire at the end of the year, leaving him free to pursue his love for classical South Indian singing and dancing. He has not had much time for that during the ISRO's hectic pursuit of Mars. \n               MASAYO TAKAHASHI: Stem-cell tester \n             An ophthalmologist injected hope into the stem-cell field during a troubled year .  By David Cyranoski For an hour on Friday 12 September, Masayo Takahashi sat alone, calmly reflecting on the decade of research that had led up to this moment. An ophthalmologist at the RIKEN Center for Developmental Biology (CDB) in Kobe, Japan, Takahashi was about to watch a sheet of epithelial cells that she had grown be transplanted into the back of a woman's damaged retina. She had made the cells from induced pluripotent stem (iPS) cells, which have been widely touted for their potential to generate genetically-matched tissue for treating a range of diseases. The transplant would be the first test of that promise in people, and therefore a major milestone for the stem-cell field. As she sat, Takahashi quietly considered all those who had helped her get to that point (\u201cso many people \u2014 it would be like the credits rolling at the end of a movie\u201d), and the scandal in the stem-cell field that had threatened to derail the project earlier in the year. \u201cIt was like a sacred hour,\u201d she says. Takahashi had been trying to use stem cells to repair retinal damage for ten years \u2014 and trying to downplay hype about the cells for almost as long. Her work received a boost when, in 2006, stem-cell scientist Shinya Yamanaka at Kyoto University in Japan discovered how to make iPS cells, which are much easier to make than other human pluripotent cells. Collaborating with Yamanaka, Takahashi worked out how to turn the iPS cells into sheets of retinal epithelial cells. She then tested the resulting cells in mice and monkeys, passed regulatory hurdles, recruited patients, and practised growing cells from those patients. Finally, she was ready to try the transplants in people with a common condition called age-related macular degeneration, in which wayward blood vessels destroy photoreceptors and vision. The transplants are meant to cover the retina, patch up the epithelial layer and support the remaining photoreceptors. Watching the procedure, \u201cI could feel the tension of the surgeon\u201d, Takahashi says. In the end, everything went smoothly \u2014 but Takahashi will not reveal whether it has been a success until a year after the transplant. She does say that the tissue seems to have maintained its brownish colour, a sign that it has not been attacked by the immune system. The patient, a woman in her 70s, had already lost most of her vision and is unlikely to get it back; but Takahashi's team is keen to see whether the transplant is safe and prevents further retinal deterioration. Takahashi had planned to operate on six patients in an informal clinical study. But a law that went into effect in Japan last month opens the door to a fast-track formal trial that would move the technology, if successful, to open clinical use. She is now considering which path to take. The transplant was a high point for the field after a major low. Earlier in the year, controversy over two stem-cell papers published in  Nature  and unrelated to Takahashi's research had enveloped the CDB. The papers, which reported a quick recipe for making pluripotent stem cells, were first lauded and then shunned after it emerged that some figures had been manipulated. The spotlight fell on Haruko Obokata, the papers' first author, who continued to argue that the method worked. The episode took a tragic turn when Yoshiki Sasai, who supervised Obokata at the CDB, killed himself in August. In the wake of the scandal, the centre was drastically restructured and its research budget was slashed. As all this unfolded, Takahashi found her own work under intense scrutiny: she was accused of rushing the procedure in an effort to make money, and concerns were raised over whether the cells were safe. A month before the scheduled surgery, the health ministry suddenly announced that several new safety tests would be required. At times, Takahashi says, she felt \u201cbeaten\u201d. Now upbeat, however, Takahashi is aiming to clear a much higher bar \u2014 transplanting layers of photoreceptors together with the epithelial sheets \u2014 to restore a small degree of vision to people with macular degeneration. The photoreceptors would have to make connections with neurons, something that Takahashi realizes will be a challenge. For that, she will use the ability to grow three-dimensional retinal tissue  in vitro  \u2014 a technique, she notes with sadness, that was pioneered by Sasai. Other scientists at the centre share the grief, and say that Takahashi's success was a welcome distraction. \u201cIt was definitely encouraging for all CDB people,\u201d says developmental biologist Masatoshi Takeichi, former director of the centre. \n               SJORS SCHERES: Structure solver \n             A biologist brought the cell's molecular machines into sharper focus .  By Ewen Callaway Sjors Scheres is surrounded by ribosomes. A picture of one fills his computer screen, and thousands more are stuffed on his hard drive. His CV is studded with high-profile papers from this year showing some of the clearest images ever produced of these complex protein-making machines. So it is all the more surprising when Scheres, a structural biologist, says that he isn't all that interested in ribosomes. \u201cIt's all about the math,\u201d he says, with relish. \u201cThat's what my main contribution is.\u201d That mathematics is helping to drive a revolution in structural biology. Once dominated by a method called X-ray crystallography, the field is now in the thrall of a technique called cryo-electron microscopy, or cryo-EM. Scheres's calculations have led to software that transforms grainy cryo-EM images into exquisitely detailed pictures, allowing biologists to visualize molecular machines more easily and accurately than ever before. Scheres started his PhD trying to get a portion of a gene-regulation protein to form tidy crystals \u2014 a prerequisite for X-ray crystallography, which involves pummelling the crystals with X-rays, then using the resulting diffraction patterns to deduce the protein's shape. But he abandoned the project when his protein, like so many others, defied crystallization. He was drawn instead to cryo-EM, in which a beam of electrons is used to visualize flash-frozen protein solutions. Three-dimensional structures are then created by merging electron micrographs taken from different angles. But at the time, the technique was known as 'blob-ology' because the images it produced were so patchy, Scheres says. In 2010, when Scheres joined the Laboratory for Molecular Biology (LMB) in Cambridge, UK, microscopes were being developed that could detect electrons more efficiently and take snapshots of proteins at hundreds of frames per second. But Scheres knew that better computer programs would be needed to make sense of the flood of data, so he shut himself in his office to try to write one. \u201cI didn't have a group. I was just programming,\u201d he says. The resulting software, named RELION, brought the blobs into focus: it did a much better job of marrying images into a three-dimensional molecular structure than did existing tools. \u201cWe left him alone for a couple years, and he came up with all this beautiful software,\u201d says Venki Ramakrishnan, a molecular biologist at the LMB. Ramakrishnan had won the 2009 Nobel Prize in Chemistry for his work in determining the structure of the bacterial ribosome using X-ray crystallography. But it takes years to obtain such structures because ribosomes are made up of dozens of different proteins and RNA molecules. Cryo-EM offers a quicker route, and this year, Ramakrishnan collaborated with Scheres to produce detailed structures of yeast and human ribosomes. Now, his lab has converted almost exclusively to the new technology. \u201cFor us it's a perfect saviour,\u201d he says. \u201cWe can be defined by the biological questions, rather than what we can crystallize.\u201d Scheres is now looking for more difficult structures to crack. He found one in a project with a team at Tsinghua University in Beijing, to determine the structure of \u03b3-secretase, a protein implicated in Alzheimer's disease. The protein is relatively small and prone to movement, which blurs cryo-EM images \u2014 but Scheres has already produced one structure and is working on improvements. \u201cIt is kind of a boom time in cryo-EM,\u201d says Richard Henderson, a structural biologist at the LMB who helped to develop the new electron microscopes, \u201cand Sjors deserves a lot of the credit for getting it going.\u201d \n               Ones to watch in 2015 \n             Xie Zhenhua, China's top climate official  After this year's climate accord between the United States and China, Xie and the world's biggest greenhouse-gas polluter will be a focus of attention at climate talks. Alan Stern, Principal investigator of NASA's New Horizons mission  Stern will be firmly in the spotlight in July when his mission becomes the first to reach Pluto. Just don't tell him it's not a planet. Joanne Liu, International president of M\u00e9decins Sans Fronti\u00e8res (MSF)  MSF has shone in the global response to the Ebola epidemic, and Liu will be a big player in next year's efforts to end it. Bernard Bigot, Nominated as next director-general of ITER  Bigot wants to radically reform the troubled multi-billion-euro international project to build a huge reactor that would demonstrate the feasibility of fusion energy. Rick Horwitz, Executive director, Allen Institute for Cell Science  As head of a new US$100-million venture funded by philanthropist Paul Allen, Horwitz must push cell biology to a new frontier. \n                     The ice bucket 2014-Oct-22 \n                   \n                     India joins elite Mars club 2014-Sep-24 \n                   \n                     Infectious disease: Ebola\u2019s lost ward 2014-Sep-24 \n                   \n                     Japan stem-cell trial stirs envy 2014-Sep-16 \n                   \n                     Iranian is first woman to nab highest prize in maths 2014-Aug-12 \n                   \n                     Rosetta craft makes historic comet rendezvous 2014-Aug-06 \n                   \n                     Gravitational-wave team admits findings could amount to dust 2014-Jun-20 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Nature  special: 2014 the year in science \n                   Reprints and Permissions"},
{"file_id": "507154a", "url": "https://www.nature.com/articles/507154a", "year": 2014, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "More than a billion people lack electricity, but now microgrids are powering up rural areas. In Haiti, the least-electrified country in the Western Hemisphere, some residents spend US$10 a month on candles and kerosene just to light their homes \u2014 roughly 125 times what those in the United States typically pay for the equivalent light. In India, many pay a premium to charge their mobile phones from car batteries at the local market. The Sun still dictates life for millions of Africans, and diesel generators burn through budgets on small Pacific islands. Around the world, nearly 1.3 billion people live without access to electricity, many of them far from the ever-expanding electric grid. The quest is on to find the best way to bring clean power to rural areas. Mixing local development work with Silicon-Valley-style entrepreneurship, engineers, scientists and economists are setting up independent 'microgrids' that can be deployed quickly and cheaply one community at a time. Those leading such electrification schemes aim to create small-scale renewable-energy systems, building an archipelago of light across the developing world and helping remote communities to kick their dependence on fossil fuels. Such efforts have often failed in the past, as subsidies lapsed or infrastructure collapsed. But today's entrepreneurs are better placed to succeed. A new generation of cheaper photovoltaic panels and wind turbines can be managed with simple smart-grid devices. The price of fossil fuels has soared over the past decade, making renewable energy more competitive. And the United Nations has set a goal of achieving universal access to electricity by 2030, providing political impetus. \u201cThe ambition is there, and the economics are making a lot more sense now than they were a few years ago,\u201d says Richenda Van Leeuwen, executive director for energy access at the United Nations Foundation. But the challenge remains extreme. A 2012 analysis by the International Energy Agency projects that, on the basis of current plans, the percentage of people without access to electricity will fall from 19% in 2010 to 12% in 2030 \u2014 leaving nearly 1 billion people still in the dark. Achieving universal energy access would mean increasing investments from a projected $14 billion to $49 billion a year, the agency says. Centralized grids are expected to provide only about 30% of the solution in rural areas. Among the projects already on the go are a few bright spots with lessons to teach about technologies and business models that could help to light the world. \n               Tamkuha, India \n             When a pair of young Indian entrepreneurs flipped the switch to electrify the remote agricultural village of Tamkuha in 2007, the power flowed from rice husks. Gyanesh Pandey and Ratnesh Yadav knew that photovoltaic panels were too expensive for their plans, and there wasn't a lot of wind blowing through this town of roughly 2,000 people. But their home state of Bihar has rice in abundance. Trained in electrical engineering at Rensselaer Polytechnic Institute in Troy, New York, Pandey sketched out a plan with his long-time friend Yadav. Working with a grant of roughly $12,000 from the Indian Ministry of New and Renewable Energy, the duo invested more than $40,000 of their own money to purchase and modify a gasifier to turn rice husks into biofuel, buy a 32-kilowatt generator, and run power lines through the village. Within five months, the residents of Tamkuha had enough electricity to charge their mobile phones and fend off darkness with two compact fluorescent light bulbs per household for 6\u20138 hours a night. Pandey and Yadav formed Husk Power Systems with Manoj Sinha, who studied business at the University of Virginia in Charlottesville, and the company now has more than 80 mini-power plants serving some 200,000 people in India, Uganda and Tanzania. Success in Tamkuha proved that even poor customers will pay 100 rupees ($1.60) per month or more for minimal power, in a country where rural households often survive on $15\u201380 a month. The rates are higher than in urban centres, but customers typically save overall because they purchase less kerosene. In 2007, says company president Sinha, nobody believed that Husk Power could create a viable business.\u201cBut when we scaled up to more than 300 villages, people started believing in the model.\u201d The opportunities in India are huge. Although the percentage of people without access to electricity in 2011 was only 25% \u2014 much lower than the 80\u201390% rates seen in some African countries \u2014 that still left a record 300 million people without power in a single country. The government has invested money and attention in the problem, and those efforts have slashed the number of people without a connection to the main grid by more than half in the past decade. But the country is struggling to supply enough power to feed all those lines, and to hook up the most remote communities. Husk Power has become one of the world's largest microgrid developers. And it is dreaming big, targeting 5 million customers within five years in India and east Africa. With the cost of photovoltaic panels falling, the company is building solar microgrids and pairing them with storage batteries to meet evening demand. And it is experimenting with a solar\u2013biomass hybrid power plant intended to provide power around the clock. \u201cWhere Husk is going is very positive,\u201d says Daniel Kammen, an energy researcher at the University of California, Berkeley. \u201cIt is not fixating on one technology, it is fixating on solutions.\u201d But problems may lie ahead. In some areas, small providers such as Husk Power compete with the expanding central grid, leaving some villages with two suppliers. The microgrids tend to be more reliable, but are also more expensive, because subsidies usually go into capital construction costs rather than towards keeping electricity rates low. Kammen says governments and companies should agree on some basic industry standards for regulation and finance, so that investment in microgrids \u2014 the only solution for some areas \u2014 expands rather than being undermined. \n               Tokelau, South Pacific \n             The Sun shone brightly on Tokelau as a cargo ship pulled into harbour in June 2012, bringing the tiny trio of South Pacific islands their largest delivery ever. On board were more than 4,000 solar panels and 1,000 storage batteries, as well as innumerable nails and screws. \u201cWe thought the island was going to sink,\u201d jokes energy minister Foua Toloa. The cargo gave Tokelau the moral high ground in the battle to halt global warming: it has been widely billed as the first nation to accomplish a sweeping shift from fossil fuels to renewable energy. Tokelau, like almost all small island nations, used to rely on diesel-powered generators to meet the needs of its 1,400 residents. In its first full year of operation, the new 1-megawatt solar system met roughly 93% of the nation's electricity demand. Today, Tokelau has reduced its annual fuel bill by about $800,000, which more than covers payments on the loan it received from the government of New Zealand for the microgrid. \u201cWe're very proud,\u201d Toloa says. \u201cWe are challenging the world and the big emitters of greenhouse gases to equal or better what Tokelau has done.\u201d A handful of Caribbean islands has signed up to that challenge with the help of the Carbon War Room, a Washington DC-based advocacy group founded by British entrepreneur Richard Branson. The Caribbean island of Aruba, where wind power currently provides 12% of demand, led the way in March 2012 with a commitment to eliminate fossil-fuel use by 2020. But with 109,000 residents and regular demand for roughly 100 megawatts of power, Aruba's challenge is much bigger than Tokelau's. \u201cThis is actually a very interesting proving ground to test out ambitious levels of renewables and energy efficiency,\u201d says Amory Lovins, co-founder of the Rocky Mountain Institute in Snowmass, Colorado, which co-hosted a clean-energy summit for Caribbean nations with the Carbon War Room in February. Lovins notes that the lessons learned about balancing energy supply and demand could help with the management of mainland power, too. Some US states, including New York, are exploring ways to divide the main grid into electricity 'islands' that could be isolated in the face of large-scale outages. And, Lovins adds, island projects such as that on Aruba may help to convince the world that reliable power systems can be built almost entirely from renewables. Tokelau has not yet achieved its goal of going 100% renewable. The old diesel generators still occasionally kick in to charge batteries during the rainy season, and many residents rely on imported gas for cooking. The nation's government is planning to help residents to purchase more efficient appliances or make the switch to electric cookers. Air conditioners, considered an unnecessary luxury on the island, have already been banned for government use. And if the economics work out, as early as next year the country hopes to begin producing coconut oil to power the generators when the Sun doesn't shine. \u201cWe've got plenty of extra coconuts,\u201d Toloa says. \n               Sine Moussa Abdou, Senegal \n             Residents in the village of Sine Moussa Abdou once had to trek ten kilometres to a neighbouring village to charge their mobile phones, paying fees as high as $110 per kilowatt hour \u2014 the average US rate is 12 cents. Those with televisions hauled a car battery to be recharged. The village's 900 residents now pay about $1.40 per kilowatt hour for power delivered to their homes through a microgrid built in 2009. The company in charge of supplying the power \u2014 a combination of wind, solar and diesel \u2014 says all of the students in the village school passed their annual exam for the first time one year after electrification, thanks to having enough light at night to study by. The project is just one of many seeking to solve the massive energy problem in sub-Saharan Africa, where nearly 600 million people \u2014 more than two-thirds of the population \u2014 lack access to electricity (see 'In the dark'). But it is an innovative example of public\u2013private partnership that many observers are watching closely. The project, a partnership of Inensus in Goslar, Germany, and Matforce, based in Dakar, Senegal, was divided into two parts: international grants were used to wire up the village, but the power generation and supply is entirely unsubsidized. Inensus uses smart meters to track customers' usage, and asks users to pay for weeks' worth of power in advance, offering a discounted rate to those who predict and commit six months ahead. That information helps to keep costs and emissions down by ensuring that the wind and solar systems can cope, and that the diesel generators are not leaned on too heavily; they typically mop up the last 10\u201320% of demand. Although the cost of the power is more than three times what urban customers might face, the business model is designed to promote sustainability and flexibility. Nico Peterschmidt, managing director of Inensus, foresees a scenario in which local companies own a grid and contract out the supply of power, fostering competition and freeing up companies and communities to shop around. The company is now expanding the project into five nearby villages and has launched a larger project targeting 16 villages and 82,000 people in Tanzania. Peterschmidt says the Tanzanian government has perhaps the most advanced microgrid policy in the world, including a simple subsidy of $500 per connection for grid infrastructure, which covers the bulk of up-front costs. The biggest challenge, he says, is convincing governments to abandon fixed electricity rates that do not allow for company profit. \u201cIf we can overcome that, we can accelerate the private sector to provide energy access,\u201d he says. Kammen notes that there is generally enough commercial competition and watchdog activity to prevent price abuses, with most projects providing electricity at or below the price of diesel power. The trick, notes Pepukaye Bardouille, an energy analyst who tracks microgrids at the International Finance Corporation in Washington DC, is to balance a nation's desire to attract profitable industry with the wish for their poorest people to get electricity. \u201cAre we trying to promote commercially viable businesses? Or are we trying to promote access at any cost?\u201d she asks. \u201cSometimes those two do not overlap.\u201d Dean Cooper, an energy-finance specialist at the United Nations Environment Programme (UNEP) in Paris, says that UNEP is working on microgrid demonstrations in different countries to determine which policies and models work best. At present, it is too early to say which will win out. \u201cAll of the business models can be scaled up on paper,\u201d says Bardouille. \u201cIn practice, it is harder to deliver.\u201d \n               Atlin, Canada \n             For years, the only source of power in Atlin, an old mining town of some 400 people in the northwest corner of British Columbia, was diesel generators. The steady drone and smelly fumes were a constant reminder that money was going up in smoke, and members of the Taku River Tlingit First Nation, who make up 25% of the town's population, were determined to find an alternative. After experimenting with a wind turbine, which buckled under ice and wind in the winter of 2002\u201303, the tribal band settled on a small hydroelectric project. With $15 million from grants, community funds and loans, the Atlin hydroelectric project began generating 2.1 megawatts of power on 1 April 2009. Atlin is enjoying the benefits. Eliminating diesel prevented more than 5,000 tonnes of greenhouse-gas emissions last year. And, because the First Nation owns the hydroelectric station, the money that residents pay for power stays at home. \u201cWe are paying our loans, but there's a little bit extra that is benefiting the community,\u201d says Stuart Simpson, general manager of the Atlin Tlingit Development Corporation. There are 175 aboriginal or northern off-grid communities in Canada, most of which rely on diesel. The Taku River Tlingit First Nation was one of the first to switch to home-owned hydropower, and others are looking to follow. A new wave of small-scale hydroelectric development aiming to supply both off-grid and on-grid energy in British Columbia has spurred controversy about the potential ecological impacts of such projects. The Vancouver-based Wilderness Committee, for one, has voiced concerns about possible disturbances to grizzly bear habitat and salmon-bearing rivers. But the actual effects are hard to tease out. A review released in January by the Pacific Salmon Foundation, a conservation organization in Vancouver, found no conclusive evidence about effects on fish. Nigel Protter, executive director of the BC Sustainable Energy Association, says modern hydroelectric projects can, if well-conceived and implemented, improve the local ecosystem; the Atlin project, for example, built a fish ladder to help graylings get around the small dam, and Simpson says that fish counts have increased. The problem, Protter says, is that many rural communities in the developed world want more power than their small rivers can provide without the construction of dams to store up water. \u201cStorage often creates additional environmental and social impacts.\u201d Atlin has all the power it needs for now; it is even considering expanding its project to tie into the main electric grid and to export power to the northern Yukon territory. \u201cIn 20 years, when we have this bank loan paid off, we'll have a couple million coming into the community each year,\u201d Simpson says. \u201cThis is really about our grandkids.\u201d \n                     Warsaw talks to thrash out UN climate roadmap 2013-Nov-13 \n                   \n                     Making growth sustainable 2012-Oct-01 \n                   \n                     Negotiators achieve early agreement at Rio summit 2012-Jun-19 \n                   \n                     http://www.nature.com/news/specials/kyoto/index.html \n                   \n                     http://www.nature.com/news/specials/rio20/index.html \n                   \n                     Sustainable Energy For All \n                   \n                     United Nations \n                   Reprints and Permissions"},
{"file_id": "506424a", "url": "https://www.nature.com/articles/506424a", "year": 2014, "authors": [{"name": "Shaoni Bhattacharya"}], "parsed_as_year": "2006_or_before", "body": "A powerful method for deducing microbial relationships has been edging its way into civil and criminal investigations. But courts should proceed with caution. Anaesthetist Juan Maeso led a seemingly respectable life in the coastal Spanish town of Valencia. But he had a secret. Over the course of at least a decade, at two different hospitals, he regularly skimmed morphine from his patients, injecting himself just before using the same needle to administer their doses. In 2007, Maeso was found guilty of infecting at least 275 people with hepatitis C, four of whom had died from complications related to the disease. He was sentenced to 1,933 years in prison, although he is expected to serve only 20 under Spanish law. To this day, Maeso protests his innocence, saying that a patient must have infected him with the hepatitis C virus (HCV). But the scientific evidence, which was published in full only last year 1 , overwhelmingly suggests otherwise. In that work, Fernando Gonz\u00e1lez-Candelas and his colleagues at the University of Valencia analysed and categorized almost 4,200 viral sequences in an effort to disentangle the path the infection followed, using a process known as phylogenetic forensics. The method, which marries classic evolutionary-biology practices with modern sequencing technology, is increasingly being used in criminal and civil investigations, and for biodefence. A paper published this month 2 , for example, describes how the technique allowed scientists to trace the likely origin of an anthrax-laced batch of heroin that has been killing users across Europe since 2009. But the intersection of this science with the legal system makes many uneasy, says Anne-Mieke Vandamme, an evolutionary geneticist at the University of Leuven in Belgium, who has worked on 19 criminal cases since 2002, mostly for the defence. Unlike DNA evidence, which is routinely used in legal settings around the world, the results of phylogenetic forensics are rarely definitive. \u201cYou can never prove guilt,\u201d she says. And there are social concerns. Many patient advocates feel that tracing the path of infection in civil and criminal cases may further stigmatize diseases such as AIDS. Now, as the field matures thanks to advanced sequencing and analytical tools, a team of experts led by Vandamme is trying to develop guidelines for best practice both on technical aspects of the work and on presenting the evidence in courts. She hopes, she says, \u201cto make clear to lawyers, judges and prosecution officers the powers and limitations of these methods\u201d. \n               A common factor \n             Maeso's misdeeds started to come to light when doctors at Spanish utility companies noticed clusters of HCV among workers. While reviewing the workers' medical records, one doctor, Manuel Beltran, noticed that they had all had minor surgery at the Hospital Casa de Salud in Valencia some months before. Beltran contacted the local public-health authority, sparking what turned out to be a massive investigation that scoured the records of more than 66,000 patients across two hospitals. Early on, it was clear that Maeso was a common factor in many of the cases. But prosecutors would need more evidence. This is where phylogenetics came in. Some viruses, such as HCV, HIV and influenza, mutate incredibly quickly. By sequencing virus samples from different individuals \u2014 and then comparing tiny differences in their genomes \u2014 scientists can trace their evolution and place them on a family tree (see 'Infectious forensics'). \u201cWhat we are doing is a virus genealogy,\u201d says Oliver Pybus, who studies evolution and infectious diseases at the University of Oxford, UK. The process allows scientists to predict how likely it is that two or more infections are closely related and what their relationship is. And as the technology has steadily improved, such information has proved increasingly useful. Prosecutors have used it in cases of intentional infections, such as that of Richard Schmidt, who was in 1998 convicted by a Louisiana court of attempted second-degree murder. He injected his former girlfriend with HIV- and HCV-tainted blood, telling her that he was giving her a vitamin B12 jab. The method was used to help track the source of anthrax spores posted to several US politicians and media outlets in 2001. And it has been used to provide evidence in rape accusations and in investigations of child sexual abuse in which a disease was transmitted years earlier. But phylogenetic evidence is very different in nature from the DNA matches that juries may be more familiar with, says Vandamme: the latter can often confirm or exclude a suspect's involvement in a crime with extremely high certainty. Phylogenetic analyses can offer supporting evidence \u2014 that a virus found in person A is very likely to have come from person B, say \u2014 but can never prove direct transmission on their own, she says. In the Maeso case, for example, prosecutors used viral phylogenies to corroborate evidence gained from epidemiological investigations. Gonz\u00e1lez-Candelas and his colleagues used patterns of changes in a highly variable region of the HCV genome to sort the viruses into clades, or branches of a tree that illustrate their evolutionary relationships. The scientists analysed, on average, 11 such viral sequences per person from 321 people believed to have been infected by Maeso and 42 controls \u2014 local HCV-infected patients with no known connection to the case. When printed out, the tree that the researchers developed was 11 metres long. Using all the data, the team determined for each infected individual a 'likelihood ratio' \u2014 that is, the probability that the infection was related to Maeso's and others whom Maeso had presumably infected, versus the probability that it had come from a source unrelated to the outbreak. Because there were so many samples and a strong phylogenetic signal, the likelihood ratios the scientists got were high. Most were higher than 10 5 , and the highest was 6.6 \u00d7 10 95 , exceptionally strong support for this type of analysis. The Valencia work was also notable in that it attempted to pinpoint when individuals had contracted the virus, using a 'molecular clock' technique. To do this, the researchers sampled the genetic diversity of viruses in each person, and then used the mutation rate of HCV in the outbreak to estimate when they had been infected. Almost two-thirds of the estimated dates of infection lined up with when the patients had visited the Valencia hospitals, adding to the evidence that Maeso was the source. Presenting such data in court is challenging. Gonz\u00e1lez-Candelas and his colleague Andr\u00e9s Moya had to lecture judges and attorneys for two days to familiarize them with evolutionary terms and concepts before launching into three weeks of scientific testimony. One of the challenges was differentiating the process from conventional DNA testing in minds of the judges and lawyers. Court officials needed to understand that the analysis is inherently more messy: because HCV mutates so rapidly, the longer a person has an infection, the more viral diversity they are likely to have. When that person infects another, any of the new variants could be passed on, and not all are necessarily sampled in the forensic process, meaning that a connection could be missed or the strength of the relationship distorted. \u201cThere is never a full match between strains of linked individuals or even within a single individual,\u201d says Vandamme. Even in cases in which the viruses from two or more individuals are clearly related, she says, \u201cthere are several possible trees, depending on when the samples are taken and how many variants were passed during transmission\u201d. In the Maeso case, the probabilities linking him to the some of the patients were quite strong. But the method also helped to clear him of blame in 47 suspected cases. Those individuals were therefore not entitled to compensation. \u201cOur analysis worked both ways,\u201d says Gonz\u00e1lez-Candelas. \n               Clear cut \n             Many scientists see the technique's ability to clear individuals of crimes as its greatest strength. In May 2004, five Bulgarian nurses and a Palestinian doctor were sentenced to death for allegedly infecting 426 children with HIV at the al-Fateh Hospital in Benghazi, Libya (see  Nature 430, 277; 2004 ). The 'Benghazi Six' had been detained and reportedly tortured since 1999. A phylogenetic analysis had suggested that the particular strain of HIV involved had been circulating years before the arrival of the foreign health workers.  Nature  published the results online just before a retrial in 2006 (ref.  3 ), and although they did not sway the court from the death penalty at the time, the findings did seem to change diplomatic relations \u201cquite considerably\u201d, says Pybus, who was part of the research team. In 2007, the sentences were commuted to life imprisonment, and the health workers were extradited to Bulgaria, where they were pardoned by the Bulgarian president. The field has developed since these watershed cases. In 2010, evolutionary biologist David Hillis of the University of Texas at Austin and his colleagues described methods that, for the first time, gave supportive evidence on the direction of viral transmission 4 . To do this, investigators look closely at the populations of viruses in infected individuals. Because one person harbours many variants, only a subset is transmitted when they infect someone new. Once transmitted, this subset will multiply in number and continue to evolve rapidly. As a result, some viruses in the source may seem to be more closely related to the viruses in a recipient than to other viruses in the source, Hillis explains. Identifying these relationships can help to support a hypothesis of who infected whom. New sequencing technologies are also increasing the power of what phylogenetics can do. \u201cThe more you sample, the better \u2014 the more you can fill in the gaps,\u201d says Andrew Rambaut of the University of Edinburgh, UK, who worked with Pybus on the Benghazi case. Rapid, automated sequencing can give a huge amount of information, says Bruce Budowle, who worked as a scientist for the US Federal Bureau of Investigation (FBI) for 26 years, and is now director of the Institute of Applied Genetics at the University of North Texas Health Science Center in Fort Worth. But there is a catch. The masses of data generated have to be processed in a way that is useful for forensic purposes, he says: if software or methods for developing the phylogenies are not properly validated, findings could be challenged in court. Many useful applications developed in academia may not be subjected to such validation because it is not a priority until the methods are needed for forensics work. \u201cWe often get so enamoured with our science, and then something comes up and you have to use it,\u201d Budowle says. Budowle and his colleagues were in exactly this situation during the 2001 anthrax attacks. To piece together the bacterial phylogenies, they had to use an unvalidated method developed by an academic microbiologist \u2014 Paul Keim at Northern Arizona University in Flagstaff. \u201cIt gave us guidance on what may have occurred, and pointed to a laboratory strain rather than one found in nature,\u201d says Budowle. This helped investigators to track the microbe back to a laboratory strain called Ames. A variant of this strain was later linked to Bruce Ivins, a microbiologist at the US Army Medical Research Institute of Infectious Diseases at Fort Detrick in Maryland. It is impossible to say how important the phylogenetic data would have been because the case never went to court. After the FBI began to investigate Ivins in 2008, he committed suicide (see  Nature 454, 672; 2008 ). The high stakes involved in many cases using phylogenetics has led to other concerns \u2014 notably, that the technique might contribute to the stigmatization of people infected with HIV, or to the criminalization of HIV transmission. In several countries, people have been charged and prosecuted for murder, attempted murder or bodily harm for unwittingly transmitting the virus to a sexual partner or not disclosing that they have it \u2014 even if it was not transmitted. Some researchers think this dissuades people from coming forward for testing. For this reason, some in the phylogenetics field have stopped working on criminal cases altogether or are extremely selective about the cases they take on. Andrew Leigh Brown, who studies HIV evolution at the University of Edinburgh, assisted in the first-ever investigations using phylogenetics for forensics in the early 1990s. But he no longer works on such cases. Leigh Brown contributed to a policy document, published by the Joint United Nations Programme on HIV/AIDS last May, calling for an end to prosecution for HIV transmission other than in clearly intentional cases. Where intent is apparent, phylogenetic forensics should be used carefully and with other supporting evidence, the document advises: the burden of proof must be high. \n               Promise and pitfalls \n             Vandamme laments the lack of guidance for researchers in phylogenetic forensics. She hopes the guidelines that she and other concerned specialists are currently drafting will help scientists to avoid misinterpretations. In addition to providing tools for presenting findings in court, Vandamme hopes to reach a consensus on technical issues such as how to find a control population and which genetic regions of a virus should be assessed. \u201cThis will help the increasing number of phylogenetic experts that are called by court to provide their expertise in a forensic context,\u201d she says. Moving forward, scientists say that they will continue to carefully pick which cases they agree to get involved in. \u201cJust because we can test these relationships doesn't mean that it is always in society's best interest to do so,\u201d says Hillis. \u201cMy own choice is to work on such analyses only when they are used to test a clear crime that goes beyond accidental viral transmission, such as rape or attempted murder.\u201d Although the Valencia case is several years old, publication of the data has renewed discussion about phylogenetic forensics, its potential uses and its pitfalls, not just in legal proceedings, but also in biodefence. To that end, Gonz\u00e1lez-Candelas was invited to speak at a meeting in Zagreb, Croatia, last October to hammer out the main challenges that the field faces. The workshop, hosted by the US National Academy of Sciences and the UK Royal Society, among others, has not yet published its findings. But Budowle says that there is a major conflict in the field over access to data, with members of the biosecurity and intelligence communities wishing to keep data confidential because of concerns about risk. Where lives may hang in the balance, getting it right is crucial, says Budowle. The answers from phylogenetic forensics could mean sending an individual to prison or ostracizing a patient population. In cases involving bioweapons, the conclusions could mean levying sanctions against a country or even going to war. Validating the tools and tests is all the more challenging in an area evolving nearly as fast as the microorganisms it traces. \u201cIt's still an emerging field,\u201d Budowle says. \u201cWe expect that what we are using today, we probably won't be using two years from now.\u201d \n                     Faulty forensic science under fire 2014-Feb-04 \n                   \n                     Forensic investigation needs more science 2012-Aug-23 \n                   \n                     Science in court: DNA's identity crisis 2010-Mar-17 \n                   \n                     Nature  special: Science in court \n                   Reprints and Permissions"},
{"file_id": "506422a", "url": "https://www.nature.com/articles/506422a", "year": 2014, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Researchers are finding that online, crowd-sourced collaboration can speed up their work \u2014 if they choose the right problem. At the end of January 2009, Timothy Gowers embarked on what he later called \u201cone of the most exciting six weeks of my mathematical life\u201d. Inspired by the online citizen-science movement, Gowers, a mathematician at the University of Cambridge, UK, posted an esoteric theorem on his blog and challenged his readers to prove it \u2014 together. Crowd-source your expertise, he urged them: \u201cIf a large group of mathematicians could connect their brains efficiently, they could perhaps solve problems very efficiently as well.\u201d They could. Within hours of the problem being posted, Gowers' blog was abuzz with back-and-forth brainstorming, as mathematicians chimed in with ideas and possible avenues of attack. Gowers had hoped for new insights, but even he was surprised that by March, after nearly 1,000 comments, he was able to declare the theorem proved. \u201cThe quite unexpected result \u2014 an actual solution to the problem \u2014 added an extra layer of excitement to the whole thing,\u201d he says. The proof was published 1  under the collective pseudonym D. H. J. Polymath. Gowers' online challenge was a radical suggestion for mathematics \u2014 a field that is often viewed as the domain of lonely, secretive figures who work for years in isolation. And it went against the grain of the wider academic culture, which tends to encourage researchers to share their ideas only by publishing them. Yet this open approach has taken root as an ongoing crowd-sourcing project called Polymath. Today, just past its fifth anniversary, Polymath has a dedicated website where people can post and debate suggestions for new challenges \u2014 and, if they agree that the challenge is worthwhile, circulate ideas for its solution. Not every challenge has worked as well as the first, but other mathematicians offer cautious praise for the project, both for providing solutions to problems and for helping to spark a much-needed shift towards greater openness in mathematical research. \u201cThe impact on the community is larger than the net scientific impact,\u201d says Gil Kalai, a mathematician at the Hebrew University of Jerusalem, who coordinated one of the challenges. Many of the Internet's most popular crowd-sourced science projects require no expertise from their participants. One called Galaxy Zoo, for example, engaged more than 150,000 lay users during its first year, 2007, to sort images of galaxies by shape (see  Nature 466, 685\u2013687; 2010 ). Problems on Polymath, by contrast, attract just a few dozen participants, but those users have real expertise. In that way, the project parallels commercial ventures that pose technological and data-analysis problems online, looking for responses from highly skilled people. Companies such as InnoCentive in Waltham, Massachusetts, offer cash rewards to encourage participation, but most of the entries come from individuals motivated by a deep love for solving problems \u2014 and the chance to win recognition. As with Polymath, these companies are finding that some challenges work well, but others go nowhere. \u201cWe're still learning what works and what doesn't,\u201d says Terence Tao, a mathematician at the University of California, Los Angeles, and the coordinator of several Polymath challenges. \n               A winning formula \n             One key strength, says Tao, is Polymath's responsiveness. \u201cWe can react rather quickly to hot events in mathematics,\u201d he says. Last April, for example, Yitang Zhang, a previously obscure mathematician at the University of New Hampshire in Durham, announced that he had taken a giant step towards answering one of the great open questions in the theory of prime numbers: is there an infinite number of 'twin primes' that differ by 2, as in (11, 13) and (41, 43)? Zhang had not given the complete answer: he was able to show only that there is an infinite number of 'near-twin' primes that differ by no more than 70 million (ref.  2 ). But it was the first time that anyone had put any limit on such pairings. Polymath seemed like an ideal tool for whittling down that limit. The project, dubbed Polymath 8, got under way last June with Tao as coordinator. Within months, mathematicians all around the world had pitched in with refinements to Zhang's proof, using the Polymath website to discuss and answer one another's questions. They swiftly reduced the separation between the primes from the millions to the thousands 3 . And by November, James Maynard, a mathematician at the University of Montreal in Canada, had drawn on that impetus to reduce the limit to 600 (ref.  4 ). Polymath 8 was a triumph for the collaborative approach, says Tao. If mathematicians had been attacking the problem in the standard way, with what he describes as \u201ca flood of mini-papers\u201d, it might have taken years to get the bound down that far. Polymath has not always worked so well, however: some of the challenges simply never got off the ground. But after five years of experience with it, users have begun to home in on the features that determine success. For example, says Tao, \u201cIt helps if the problem is broadly accessible and of interest to a large number of mathematicians\u201d. This tends to draw a wide range of participants with a rich mix of skills, but it works only if the problem can easily accommodate what they have to offer. That was one of the virtues of the twin-primes challenge, says Maynard. \u201cThe proof can be split into separate sections, with each section more-or-less independent of the others,\u201d he says. Perhaps the most important lesson is that setting up and sustaining a Polymath project is a big commitment. So far, Tao and Gowers have initiated all but two of the Polymath projects. \u201cIt's quite difficult to get people interested,\u201d Gowers admits. \u201cIt needs an active leader who is willing to spend a fair amount of effort to organize the discussion and keep it moving in productive directions,\u201d says Tao. \u201cOtherwise, the initial burst of activity can dissipate fairly quickly.\u201d \n               Keep them coming \n             Incentives can help with that. \u201cIn academia, people are willing to spend a lot of time for 'kudos' or for the sake of science \u2014 but only up to a point,\u201d says Thomas Kitching, a cosmologist at University College London who has been involved in crowd-sourcing ventures. Beyond that point, he says, \u201cmonetary incentives or prizes seem to be required\u201d. That is the idea behind prize-based crowd-sourcing initiatives, which offer financial rewards to experts who provide solutions. Some of these initiatives are government-led, such as the NASA Tournament Lab and the US cross-agency  Challenge.gov , which offers cash prizes for solutions to a whole range of engineering and technological problems. Other efforts are completely commercial, and charge clients to post a problem online. Among the most prominent is InnoCentive, which will host any scientific or technological challenge. These range from the mundane but important \u2014 developing economical forms of \u201clatrine lighting in emergencies\u201d, for example, or \u201ckeeping hair clean for longer without washing\u201d \u2014 to the esoteric: \u201cseeking 4-hydroxy-1H-pyridin-2-one analogues\u201d, or \u201cstabilizing foamed emulsions\u201d. It has more than 300,000 registered 'solvers', who stand to gain rewards of between US$5,000 and $1 million if their solution works. Another commercial venture, Kaggle in San Francisco, California, specializes in data analysis, with applications ranging from oil and gas recovery to predicting drug targets. In 2012, a team of astronomers led by Kitching launched a Kaggle competition called Observing Dark Worlds. It offered $20,000 \u2014 donated by London-based financial firm Winton Capital Management \u2014 for the three best algorithms to map the distribution of dark matter in galaxies using the matter's gravitational-lensing effects on background objects. The competition was a success for all parties: the winning entries offered the astronomers about a 30% improvement over existing algorithms, and Winton recruited new analysts from the contestant list for a fraction of the usual advertising and interviewing costs. The need for such projects might well increase, says David Harvey, an astronomer at the University of Edinburgh, UK, and a co-author of a study 5  that resulted from the competition. \u201cWith new telescopes such as the Square Kilometre Array, the Large Synoptic Survey Telescope and Euclid on the horizon, astronomers will be facing real problems of data processing, handling and analysing.\u201d But Harvey stresses that Observing Dark Worlds was not an unalloyed success. As interesting as the resulting algorithms were, none of them had been tested and developed to a point at which they could routinely be used on real data. \u201cIt's vital that the winners of the competition work in collaboration \u2014 post-competition \u2014 on the problem and develop the initial idea all the way through to a final package,\u201d he says. That process will probably require a lot more time and compensation than the initial prize money. \n               The love of the chase \n             On the surface, at least, Polymath differs from commercial ventures in several ways. Most importantly, its challenges seem to be genuinely collaborative, rather than competitive. People make possibly small contributions that others build on, or they each solve part of the puzzle, rather than vying to be the victor. But Polymath and the commercial ventures also have some essential elements in common \u2014 starting with people's fundamental reasons for participating. \u201cWinning solvers rarely list the cash among their top motivations,\u201d says InnoCentive founder Alph Bingham. \u201cTheir motivations are frequently more intrinsic, such as intellectual stimulation or curiosity to explore where an idea might lead.\u201d InnoCentive aims to encourage this through non-cash incentives, such as prospects for further collaboration or joint press releases publicizing the winner. Kaggle invites participants to \u201ccompete as a data scientist for fortune, fame and fun\u201d. \u201cCompetition, if well posed, can help in science,\u201d says Kitching. \u201cBut a poorly posed problem may just increase noise.\u201d See Editorial  page 407 \n                     Crowdsourcing goes mainstream in typhoon response 2013-Nov-20 \n                   \n                     Crowdsourcing in manhunts can work 2013-Apr-26 \n                   \n                     Website pitches solutions in search of problems 2012-Oct-22 \n                   \n                     Tapping the crowd for technologies 2010-Jul-01 \n                   \n                     Massively collaborative mathematics 2009-Oct-14 \n                   \n                     Polymath \n                   \n                     Timothy Gowers's blog \n                   \n                     Timothy Gowers's homepage \n                   \n                     Terence Tao's Polymath blog \n                   \n                     Gil Kalai's blog \n                   \n                     InnoCentive \n                   \n                     Kaggle \n                   \n                     Observing Dark Worlds \n                   \n                     Galaxy Zoo \n                   Reprints and Permissions"},
{"file_id": "505146a", "url": "https://www.nature.com/articles/505146a", "year": 2014, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Using massive amounts of data to recognize photos and speech, deep-learning computers are taking a big step towards true artificial intelligence. Three years ago, researchers at the secretive Google X lab in Mountain View, California, extracted some 10 million still images from YouTube videos and fed them into Google Brain \u2014 a network of 1,000 computers programmed to soak up the world much as a human toddler does. After three days looking for recurring patterns, Google Brain decided, all on its own, that there were certain repeating categories it could identify: human faces, human bodies and \u2026 cats 1 . Google Brain's discovery that the Internet is full of cat videos provoked a flurry of jokes from journalists. But it was also a landmark in the resurgence of deep learning: a three-decade-old technique in which massive amounts of data and processing power help computers to crack messy problems that humans solve almost intuitively, from recognizing faces to understanding language. Deep learning itself is a revival of an even older idea for computing: neural networks. These systems, loosely inspired by the densely interconnected neurons of the brain, mimic human learning by changing the strength of simulated neural connections on the basis of experience. Google Brain, with about 1 million simulated neurons and 1 billion simulated connections, was ten times larger than any deep neural network before it. Project founder Andrew Ng, now director of the Artificial Intelligence Laboratory at Stanford University in California, has gone on to make deep-learning systems ten times larger again. Such advances make for exciting times in artificial intelligence (AI) \u2014 the often-frustrating attempt to get computers to think like humans. In the past few years, companies such as Google, Apple and IBM have been aggressively snapping up start-up companies and researchers with deep-learning expertise. For everyday consumers, the results include software better able to sort through photos, understand spoken commands and translate text from foreign languages. For scientists and industry, deep-learning computers can search for potential drug candidates, map real neural networks in the brain or predict the functions of proteins. \u201cAI has gone from failure to failure, with bits of progress. This could be another leapfrog,\u201d says Yann LeCun, director of the Center for Data Science at New York University and a deep-learning pioneer. \u201cOver the next few years we'll see a feeding frenzy. Lots of people will jump on the deep-learning bandwagon,\u201d agrees Jitendra Malik, who studies computer image recognition at the University of California, Berkeley. But in the long term, deep learning may not win the day; some researchers are pursuing other techniques that show promise. \u201cI'm agnostic,\u201d says Malik. \u201cOver time people will decide what works best in different domains.\u201d \n               Inspired by the brain \n             Back in the 1950s, when computers were new, the first generation of AI researchers eagerly predicted that fully fledged AI was right around the corner. But that optimism faded as researchers began to grasp the vast complexity of real-world knowledge \u2014 particularly when it came to perceptual problems such as what makes a face a human face, rather than a mask or a monkey face. Hundreds of researchers and graduate students spent decades hand-coding rules about all the different features that computers needed to identify objects. \u201cComing up with features is difficult, time consuming and requires expert knowledge,\u201d says Ng. \u201cYou have to ask if there's a better way.\u201d In the 1980s, one better way seemed to be deep learning in neural networks. These systems promised to learn their own rules from scratch, and offered the pleasing symmetry of using brain-inspired mechanics to achieve brain-like function. The strategy called for simulated neurons to be organized into several layers. Give such a system a picture and the first layer of learning will simply notice all the dark and light pixels. The next layer might realize that some of these pixels form edges; the next might distinguish between horizontal and vertical lines. Eventually, a layer might recognize eyes, and might realize that two eyes are usually present in a human face (see 'Facial recognition'). The first deep-learning programs did not perform any better than simpler systems, says Malik. Plus, they were tricky to work with. \u201cNeural nets were always a delicate art to manage. There is some black magic involved,\u201d he says. The networks needed a rich stream of examples to learn from \u2014 like a baby gathering information about the world. In the 1980s and 1990s, there was not much digital information available, and it took too long for computers to crunch through what did exist. Applications were rare. One of the few was a technique \u2014 developed by LeCun \u2014 that is now used by banks to read handwritten cheques. By the 2000s, however, advocates such as LeCun and his former supervisor, computer scientist Geoffrey Hinton of the University of Toronto in Canada, were convinced that increases in computing power and an explosion of digital data meant that it was time for a renewed push. \u201cWe wanted to show the world that these deep neural networks were really useful and could really help,\u201d says George Dahl, a current student of Hinton's. As a start, Hinton, Dahl and several others tackled the difficult but commercially important task of speech recognition. In 2009, the researchers reported 2  that after training on a classic data set \u2014 three hours of taped and transcribed speech \u2014 their deep-learning neural network had broken the record for accuracy in turning the spoken word into typed text, a record that had not shifted much in a decade with the standard, rules-based approach. The achievement caught the attention of major players in the smartphone market, says Dahl, who took the technique to Microsoft during an internship. \u201cIn a couple of years they all switched to deep learning.\u201d For example, the iPhone's voice-activated digital assistant, Siri, relies on deep learning. \n               Giant leap \n             When Google adopted deep-learning-based speech recognition in its Android smartphone operating system, it achieved a 25% reduction in word errors. \u201cThat's the kind of drop you expect to take ten years to achieve,\u201d says Hinton \u2014 a reflection of just how difficult it has been to make progress in this area. \u201cThat's like ten breakthroughs all together.\u201d Meanwhile, Ng had convinced Google to let him use its data and computers on what became Google Brain. The project's ability to spot cats was a compelling (but not, on its own, commercially viable) demonstration of unsupervised learning \u2014 the most difficult learning task, because the input comes without any explanatory information such as names, titles or categories. But Ng soon became troubled that few researchers outside Google had the tools to work on deep learning. \u201cAfter many of my talks,\u201d he says, \u201cdepressed graduate students would come up to me and say: 'I don't have 1,000 computers lying around, can I even research this?'\u201d So back at Stanford, Ng started developing bigger, cheaper deep-learning networks using graphics processing units (GPUs) \u2014 the super-fast chips developed for home-computer gaming 3 . Others were doing the same. \u201cFor about US$100,000 in hardware, we can build an 11-billion-connection network, with 64 GPUs,\u201d says Ng. \n               Victorious machine \n             But winning over computer-vision scientists would take more: they wanted to see gains on standardized tests. Malik remembers that Hinton asked him: \u201cYou're a sceptic. What would convince you?\u201d Malik replied that a victory in the internationally renowned ImageNet competition might do the trick. In that competition, teams train computer programs on a data set of about 1 million images that have each been manually labelled with a category. After training, the programs are tested by getting them to suggest labels for similar images that they have never seen before. They are given five guesses for each test image; if the right answer is not one of those five, the test counts as an error. Past winners had typically erred about 25% of the time. In 2012, Hinton's lab entered the first ever competitor to use deep learning. It had an error rate of just 15% (ref.  4 ). \u201cDeep learning stomped on everything else,\u201d says LeCun, who was not part of that team. The win landed Hinton a part-time job at Google, and the company used the program to update its Google+ photo-search software in May 2013. Malik was won over. \u201cIn science you have to be swayed by empirical evidence, and this was clear evidence,\u201d he says. Since then, he has adapted the technique to beat the record in another visual-recognition competition 5 . Many others have followed: in 2013, all entrants to the ImageNet competition used deep learning. With triumphs in hand for image and speech recognition, there is now increasing interest in applying deep learning to natural-language understanding \u2014 comprehending human discourse well enough to rephrase or answer questions, for example \u2014 and to translation from one language to another. Again, these are currently done using hand-coded rules and statistical analysis of known text. The state-of-the-art of such techniques can be seen in software such as Google Translate, which can produce results that are comprehensible (if sometimes comical) but nowhere near as good as a smooth human translation. \u201cDeep learning will have a chance to do something much better than the current practice here,\u201d says crowd-sourcing expert Luis von Ahn, whose company Duolingo, based in Pittsburgh, Pennsylvania, relies on humans, not computers, to translate text. \u201cThe one thing everyone agrees on is that it's time to try something different.\u201d \n               Deep science \n             In the meantime, deep learning has been proving useful for a variety of scientific tasks. \u201cDeep nets are really good at finding patterns in data sets,\u201d says Hinton. In 2012, the pharmaceutical company Merck offered a prize to whoever could beat its best programs for helping to predict useful drug candidates. The task was to trawl through database entries on more than 30,000 small molecules, each of which had thousands of numerical chemical-property descriptors, and to try to predict how each one acted on 15 different target molecules. Dahl and his colleagues won $22,000 with a deep-learning system. \u201cWe improved on Merck's baseline by about 15%,\u201d he says. Biologists and computational researchers including Sebastian Seung of the Massachusetts Institute of Technology in Cambridge are using deep learning to help them to analyse three-dimensional images of brain slices. Such images contain a tangle of lines that represent the connections between neurons; these need to be identified so they can be mapped and counted. In the past, undergraduates have been enlisted to trace out the lines, but automating the process is the only way to deal with the billions of connections that are expected to turn up as such projects continue. Deep learning seems to be the best way to automate. Seung is currently using a deep-learning program to map neurons in a large chunk of the retina, then forwarding the results to be proofread by volunteers in a crowd-sourced online game called EyeWire. William Stafford Noble, a computer scientist at the University of Washington in Seattle, has used deep learning to teach a program to look at a string of amino acids and predict the structure of the resulting protein \u2014 whether various portions will form a helix or a loop, for example, or how easy it will be for a solvent to sneak into gaps in the structure. Noble has so far trained his program on one small data set, and over the coming months he will move on to the Protein Data Bank: a global repository that currently contains nearly 100,000 structures. For computer scientists, deep learning could earn big profits: Dahl is thinking about start-up opportunities, and LeCun was hired last month to head a new AI department at Facebook. The technique holds the promise of practical success for AI. \u201cDeep learning happens to have the property that if you feed it more data it gets better and better,\u201d notes Ng. \u201cDeep-learning algorithms aren't the only ones like that, but they're arguably the best \u2014 certainly the easiest. That's why it has huge promise for the future.\u201d Not all researchers are so committed to the idea. Oren Etzioni, director of the Allen Institute for Artificial Intelligence in Seattle, which launched last September with the aim of developing AI, says he will not be using the brain for inspiration. \u201cIt's like when we invented flight,\u201d he says; the most successful designs for aeroplanes were not modelled on bird biology. Etzioni's specific goal is to invent a computer that, when given a stack of scanned textbooks, can pass standardized elementary-school science tests (ramping up eventually to pre-university exams). To pass the tests, a computer must be able to read and understand diagrams and text. How the Allen Institute will make that happen is undecided as yet \u2014 but for Etzioni, neural networks and deep learning are not at the top of the list. One competing idea is to rely on a computer that can reason on the basis of inputted facts, rather than trying to learn its own facts from scratch. So it might be programmed with assertions such as 'all girls are people'. Then, when it is presented with a text that mentions a girl, the computer could deduce that the girl in question is a person. Thousands, if not millions, of such facts are required to cover even ordinary, common-sense knowledge about the world. But it is roughly what went into IBM's Watson computer, which famously won a match of the television game show  Jeopardy  against top human competitors in 2011. Even so, IBM's Watson Solutions has an experimental interest in deep learning for improving pattern recognition, says Rob High, chief technology officer for the company, which is based in Austin, Texas. Google, too, is hedging its bets. Although its latest advances in picture tagging are based on Hinton's deep-learning networks, it has other departments with a wider remit. In December 2012, it hired futurist Ray Kurzweil to pursue various ways for computers to learn from experience \u2014 using techniques including but not limited to deep learning. Last May, Google acquired a quantum computer made by D-Wave in Burnaby, Canada (see  Nature   498 , 286\u2013288; 2013 ). This computer holds promise for non-AI tasks such as difficult mathematical computations \u2014 although it could, theoretically, be applied to deep learning. Despite its successes, deep learning is still in its infancy. \u201cIt's part of the future,\u201d says Dahl. \u201cIn a way it's amazing we've done so much with so little.\u201d And, he adds, \u201cwe've barely begun\u201d. \n                     Neuroelectronics: Smart connections 2013-Nov-06 \n                   \n                     Computing: The quantum company 2013-Jun-19 \n                   \n                     Artificial intelligence finds fossil sites 2011-Nov-08 \n                   \n                     Quiz-playing computer system could revolutionize research 2011-Feb-15 \n                   \n                     Man and machine hit stalemate 2003-Feb-11 \n                   \n                     Deep learning \n                   \n                     Geoffrey Hinton \n                   \n                     Andrew Ng \n                   \n                     Yann LeCun \n                   Reprints and Permissions"},
{"file_id": "505468a", "url": "https://www.nature.com/articles/505468a", "year": 2014, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Ten years ago, Woo Suk Hwang rose to the top of his field before fraud and dodgy bioethical practices derailed his career. Can a scientific pariah redeem himself? The Sooam Biotech Research Foundation nestles on a wooded hillside in Guro, a district on the southwestern outskirts of Seoul. Spartan, quiet and cold on this winter day, the grey-white exterior belies the buzz of activity within. A door just off the foyer leads to a corridor of canine chaos. In stalls to the left, Tibetan mastiff and Australian shepherd puppies are cavorting. A Yorkshire terrier dances back and forth on its hind legs. And an adult mongrel howls with separation anxiety, only calming down when the two beagle pups that she gave birth to are returned to her pen. She doesn\u2019t know that she is just a surrogate mother, nor that the pups are highly unusual dog clones, engineered to show the symptoms of Alzheimer\u2019s disease. The right side of the corridor houses a wall-sized window that looks onto an operating theatre. Inside, Woo Suk Hwang, in a blue surgeon\u2019s gown, cap and mask, is working on a bitch in labour. He greets his visitors through a microphone headset and then explains that this is an emergency: one of the puppies is stuck in the cervix. He makes an incision and carefully probes the dog\u2019s womb until the whitish sausage of a puppy emerges. After it is wiped down, Hwang holds it to his ear, listening for sounds of breathing. He then gently massages the groggy pup into consciousness and goes back for the last one. Minutes later he announces: \u201cWe have saved all three cloned dogs.\u201d Hwang brims with pride. Eight years ago, few could have imagined watching such a jubilant scene. Hwang, a world-famous cloning researcher, had just plummeted from the pinnacle of scientific success, when it became clear that he had committed fraud in two articles 1 , 2  describing stem-cell lines derived from cloned human embryos. There had been gross ethical lapses in the way Hwang had collected the human eggs for his experiments, and the papers were found to contain fabricated data. They were eventually retracted. It was one of the most widely reported and universally disappointing cases of scientific fraud in history. In January 2006, Un-chan Chung, then president of Seoul National University (SNU), where Hwang had done the work, called the episode \u201can unwashable blemish on the whole scientific community as well as our country\u201d. If the stain cannot be washed away, perhaps it can be stamped out of memory by hundreds of paws and hooves. With private funding from steadfast fans, Hwang opened Sooam in July 2006. He has since cloned hundreds of animals \u2014 dogs, cows, pigs and coyotes. His goals include producing drugs, curing diabetes and Alzheimer\u2019s disease, providing transplantable organs, saving endangered species and relieving grief-stricken pet owners. He has a raft of publications in respectable journals, collaborations within and outside South Korea, and increasing institutional support from government agencies. It is hard to square this image with the pictures of Hwang released by the South Korean media in 2005. Shattered by the controversy, he was photographed in a hospital bed, unshaven and reportedly suffering from exhaustion. Today Hwang plays down his involvement in the fraud. He retains a base of ardent supporters, mostly in South Korea. And he maintains, contrary to scientific consensus, that he really did create the first line of cloned human embryonic stem cells. He has even had success in getting some legal recognition of that claim. In December, he welcomed reporters into Sooam to tour the facilities and see him deliver some cloned puppies, but he declined to comment for this story. Maybe \u201cin a couple of decades\u201d, he wrote by e-mail. \n               Cloning for country \n             A veterinarian by training, Hwang rose to fame in South Korea in the late 1990s by cloning animals \u2014 and by developing important allies (see \u2018The rise and fall and rise of Woo Suk Hwang\u2019). He asked then-President Kim Dae-jung to name the first cloned beef bull, and he promised a national agricultural boom centred on cloned cattle. His popularity in South Korea grew, and in 2004 he shot to international fame when  Science  published a paper 1  in which he claimed to have created an embryonic-stem-cell line from a cloned human embryo \u2014 something that several groups had been trying to do. Hwang\u2019s success seemed to offer an endless supply of versatile cells genetically matched to the cell donor. Through this process, often called therapeutic cloning, it was hoped that doctors could rejuvenate failing tissues or organs, or that cells derived from people with virtually any disease could be used for research and drug screening. The following year, his group published a second paper 2 , describing the development of 11\u00a0more such lines, making the process so routine that clinical application seemed imminent. But even as his star was rising, cracks were beginning to show. In May 2004, one of Hwang\u2019s graduate students told  Nature  that she had donated eggs for experiments in the first paper (see  Nature 429, 3; 2004 ). It was a controversial assertion: many bioethicists worry that, in such a situation, students might feel pressure to endure a risky and uncomfortable procedure. Hwang denied the charge and the student recanted her statement. But in November 2005, amid increasing evidence, Hwang admitted that he had lied (see  Nature 438, 536\u2013537; 2005 ). Two students had donated eggs; Hwang even drove one to the clinic, where she donated her eggs before returning to the lab to try to make cell-line clones of herself. Hwang had also paid donors for eggs used in the 2004 paper, contradicting what the paper said. And he continued to compensate donors even after a South Korean bioethics law came into effect in January 2005 banning the practice. Hwang\u2019s triumphs soon unravelled further. In January 2006, an SNU investigation committee announced that both of his human-cloning papers were fraudulent. The committee found that the cell line reported in 2004, called NT-1, was not produced by cloning and was probably a product of parthenogenesis \u2014 the \u2018virgin birth\u2019 process by which an egg starts embryonic development without the contribution of sperm. The 11 stem-cell lines claimed to be patient-specific clones in the 2005 paper turned out to be normal embryonic-stem-cell lines from a fertility hospital that had been relabelled. Images and graphs in both papers were fabricated to give the appearance of clones. \u201cThe research team of Professor Hwang does not possess patient-specific stem cell lines or any scientific bases for claiming having created one,\u201d the report concluded. Hwang\u2019s empire crumbled. He was expelled from SNU in March 2006. The Seoul Prosecutor\u2019s Office raided his laboratory and launched a massive investigation. Hwang took responsibility for poor oversight of his lab, but maintained that he had been duped by a co-author. During the investigation, one co-author admitted to switching stem cells without Hwang\u2019s knowledge, but Hwang also admitted to ordering subordinates to fabricate data. A complicated web of blame emerged in which Hwang admitted being involved in fraud but still maintained that the achievement was real. Data fabrication is not illegal in South Korea, but knowingly using bogus articles to get funding is. The Prosecutor\u2019s Office charged Hwang with fraud, embezzlement and bioethics violations, and a three-year court case ensued. In 2009, the court threw out the fraud charge, saying that the companies involved gave the money knowing that they would not benefit from the donation. Hwang was, however, convicted of violating the country\u2019s bioethics law and of embezzling government funding. He was sentenced to two years in prison. The term, later reduced to 18 months, is still under appeal in court. But even if Hwang loses his appeal, as long as he doesn\u2019t break the law during his probation, he will not spend any time in jail, says Sean Hayes, a partner at IPG Legal in Seoul. \n               Dogged pursuit \n             Despite his legal troubles \u2014 and the widespread belief that his career was over \u2014 Hwang continued to work, thanks to the supporters who amassed US$3.5\u00a0million to launch Sooam. About 15 scientists followed Hwang from SNU, and around half of those remain today among Sooam\u2019s 45 staff. His team now creates some 300 cow and pig embryos per day, and delivers about 15 cloned puppies per month. Hwang has long been interested in cloning dogs. He reported 3  the world\u2019s first cloned puppy in 2005 \u2014 a claim upheld by the SNU investigation. Since 2006, Sooam has cloned more than 400 dogs, mostly pets. Customers, the majority of whom are from the United States, pay about US$100,000 for the service. Sooam has begun supplying dogs to the Korean National Police Agency in Seoul in the hope that clones of proven service animals will quickly learn their trade as sniffer dogs. And last year, it launched a contest for a UK dog owner to have a dog cloned for free \u2014 which would make it the first cloned canine in the country. Although Sooam could make more money from cloning pets if it cut prices and increased production, the non-profit organization wants to be more than a dog-cloning factory. \u201cIt\u2019s just a side project to get research funding for our other projects,\u201d says Insung Hwang, a scientist at the institute who agreed to speak about research at Sooam. He is no relation to Woo Suk. Using cloning technology, Sooam is creating cows that produce the human interferon protein, which can be used for treating a number of human diseases, in their milk 4 , and pigs that are genetically tweaked so that their organs might be suitable for transplantation into humans 5 . Sooam researchers have also created new models for diabetes by putting genes that cause symptoms of the disease in mice into cloned pigs 6  and dogs 7 . Likewise, says Insung Hwang, a transgenic beagle at Sooam that carries a gene related to Alzheimer\u2019s disease shows hallmarks of the disease. Researchers at the institute have cloned this beagle 18 more times and are waiting to see whether these dogs also develop the symptoms. Sooam\u2019s ambitions don\u2019t stop there. In March 2012, the centre began a collaboration with the Institute of Applied Ecology of the North, part of the North-Eastern Federal University in Yakutsk, Russia. They have joined forces to try to clone a mammoth from ancient tissue dug from permafrost. The project has received great fanfare, but Insung Hwang admits that it is a long shot. \u201cThe chances are very small,\u201d he says. Sooam is also expanding its repertoire of species. It has already cloned coyotes ( Canis latrans ) 8  using dog eggs and dog surrogates, and it now hopes to build on that work to clone the African wild dog ( Lycaon pictus ), one of the most endangered carnivores in Africa. Under Woo Suk Hwang\u2019s guidance, the institute has published more than 40 papers documenting cloning successes and technical improvements to the cloning process. \u201cHis group is making important yet incremental progress towards long-term goals,\u201d says Cindy Tian, a cloning and reproductive biology researcher at the University of Connecticut in Storrs. The fact that Hwang is being published in peer-reviewed journals is a sign that he is becoming accepted once more. Insung Hwang says that researchers he meets often bring up the fraud and \u201csome reviewers are a little hesitant\u201d to take Sooam manuscripts seriously, but overall, they are treated fairly. Tian, who edited two of Woo Suk Hwang\u2019s papers for  PLoS ONE , says that his \u201cdesigns are sound and the conclusions are supported with good data\u201d. She adds that \u201cit is very unlikely a \u2018come-back fraudster\u2019 would do the same trick again\u201d, and that because Sooam work is likely to be closely scrutinized, the researchers there are bound to be on their best behaviour. Woo Suk Hwang\u2019s greatest coup in terms of regaining legitimacy was establishing a partnership in March 2013 with BGI in Shenzhen, China \u2014 the world\u2019s largest sequencing facility and a powerhouse in scientific publishing (see  Nature 464, 22\u201324; 2010 ). Together, they plan to look at modifications of chromosomes that determine how genes are expressed, a field called epigenetics. Analysing the variation between clones and how that may contribute to, for example, different coat patterns in dogs could be a powerful tool for such work. Yang Huanming, BGI\u2019s co-founder, says that he was impressed by the level of involvement from Woo Suk Hwang after watching him deliver a litter of cloned pups. \u201cPersonally, I like him, how hard he works, and how passionate he is for science,\u201d Yang says. Woo Suk Hwang has also earned support from the Korean government. Roughly 50% of the funding for Sooam now comes from government grants, which includes 3 billion won (US$2.8 million) over three years from Gyeonggi province, Seoul\u2019s neighbour, for two cow-cloning projects, according to Insung Hwang. In 2012 and 2013, the Rural Development Administration contributed nearly 190\u00a0million won for the interferon project and 140\u00a0million won for transgenic animal models of metabolic disease. But some scientists remain wary. \u201cIf you fabricated data once, how would one know that you will not do it again?\u201d asks Hans Sch\u00f6ler, a stem-cell biologist at the Max Planck Institute for Molecular Biomedicine in M\u00fcnster, Germany. Looking at the unlikely bid to clone a mammoth, Jeong-Sun Seo, director of the Genomic Medicine Institute at SNU, feels a sense of d\u00e9j\u00e0 vu. \u201cI am afraid that it seems to be just show,\u201d he says. Seo says that he is not opposed to Woo Suk Hwang getting grants for animal cloning, but he draws the line at research into human cloning. Hwang \u201cdoesn\u2019t know the trends in stem cells. He should stick to his strong animal-cloning technology,\u201d Seo says. \n               Line of inquiry \n             Nevertheless, Woo Suk Hwang intends to return to human therapeutic cloning. But he may be trying to ride a wave that has already passed. A competing technology \u2014 induced pluripotency, discovered in 2006 \u2014 creates stem cells from adult cells, skirting the difficulty of sourcing human eggs and the controversy of embryo destruction. Even the announcement 9  last year that a human stem-cell line had finally been created from a cloned embryo got a more muted reception than the carnival that greeted Hwang when he announced his now-discredited paper. In 2007, the Korean health ministry gave Sooam approval to do research using human embryos. However, approval to start specific human therapeutic cloning projects has so far been denied twice. Insung Hwang says that no explanation was given, but he thinks that ongoing efforts to prove that the NT-1 cell line was in fact derived from an authentic clone could pave the way to future approvals. Woo Suk Hwang has made some progress in convincing official bodies of NT-1\u2019s authenticity. In 2012, a Seoul court ordered the Korean Centers for Disease Control and Prevention to register the cell line \u2014 although this does not indicate its origins. The agency had initially refused on the grounds that eggs used in the experiments had been obtained unethically because donors were paid. But it was forced to relent because the eggs used to make NT-1 were obtained before the bioethics law banning the practice came into effect. In 2011, Canada issued a patent to Sooam that refers to NT-1 as a cloned cell line. And Insung Hwang says that other patents are pending from some half a dozen of what he considers to be the \u201cmost symbolic\u201d countries. Getting recognition for NT-1 from the scientific community will be difficult, however. The paper in which NT-1 was reported 1  was clearly fraudulent and has been retracted. And SNU\u2019s finding that the line was a product of parthenogenesis has been backed up by an analysis 10  by George Daley, a stem-cell biologist at Harvard University in Boston, Massachusetts. He looked at thousands of DNA sites in the cell line and found that the chromosomes had recombination patterns strikingly similar to those of mouse parthenotes \u2014 evidence that Daley calls \u201cunequivocal\u201d. But a 2011 study 11  by Eui-Bae Jeung of Chungbuk National University in Cheongju, South Korea, argues that NT-1 does come from a true clone. This analysis is based on the similarities between the way the genes are methylated and expressed in the cell line and in cells from the nuclear donor. Mahendra Rao, director of the US Center for Regenerative Medicine in Bethesda, Maryland, says that both analyses have their ambiguities. He says he believes that Daley\u2019s data are stronger, but that \u201cmore evaluation is required\u201d. The most convincing evidence against NT-1 being a real clone might be that from Woo Suk Hwang\u2019s own lab. In 2003, when the researchers were preparing the paper, several tests indicated that NT-1 might be a parthenote, according to team leader Young-Joon Ryu. The Seoul prosecutor\u2019s report notes that another researcher, Sung Keun Kang, a former SNU professor and a right-hand man to Hwang, went back and altered the test results. Many stem-cell scientists see Woo Suk Hwang\u2019s failure to publish NT-1 as a parthenote as a missed opportunity 12 . \u201cHe could have made a career studying parthenogenetic activation,\u201d says Sch\u00f6ler. \n               Second chances \n             Among the public, opinions of Woo Suk Hwang are mixed. His actions have left many patients feeling betrayed \u2014 although some continued to support him with fervour. Susan Fajt, who was paralysed in a car accident and whom Hwang pledged to make walk again, continued to believe him after the fraud was revealed. \u201cI talked with him for four hours. He had tears in his eyes. I don\u2019t think he would mislead anybody,\u201d she said in 2006. Fajt died in 2010. But the scandal did not seem to have as disastrous an impact on support for stem-cell research worldwide as had been feared. Some in South Korea even credit the episode as partly responsible for a recent boom in stem-cell funding in the country (see  Naturehttp://doi.org/qv5;2012 ). \u201cIt was helpful,\u201d says Hyo-Soo Kim, a stem-cell scientist at SNU Hospital. \u201cIt drew attention and interest from government and ordinary people.\u201d South Korea has now approved more stem-cell treatments than any other country. One such therapy, which uses stem cells derived from umbilical cords to tackle osteoarthritis, was approved in 2012 and is made by biotechnology firm Medipost in Seoul. Antonio Lee, chief executive of the company\u2019s US subsidiary, notes that immediately after the scandal the firm had trouble enrolling patients, \u201cbut at the same time it raised awareness among the general population about the potential of stem cells\u201d. Overall, the case did not lead to a major erosion of public trust, says Bernd Pulverer, head of scientific publications at the European Molecular Biology Organization in Heidelberg, Germany, although it did raise important questions about how the problems went undetected for so long. \u201cOne clear issue that emerged was the danger of focusing such intense expectations to perform, and to funnel so much funding to one individual,\u201d he says. \u201cAt some point, it was clear that the stakes were simply too high for Dr Hwang to fail.\u201d For the research enterprise as a whole, he adds, \u201cI am not sure anything changed fundamentally\u201d. For Woo Suk Hwang, once at the centre of so much media attention, things have undoubtedly changed. In Sooam\u2019s chilly cafeteria he dines with a thick jacket on, chatting quietly to a handful of staff. He will greet a journalist and shake hands, but he does not want to talk about what happened. Hwang is increasingly surrounded by people who indulge him in that \u2014 offering a space for his ambitions to expand without constant reminders of his failures. When lunch is finished, he steals away, back to his ever-multiplying dogs and his hopes for redemption. Additional reporting by Soo Bin Park. See Editorial  page 453 \n                     Don\u2019t rush to rehabilitate Hwang 2014-Jan-21 \n                   \n                     Leaked files slam stem-cell therapy 2014-Jan-07 \n                   \n                     Research ethics: 3 ways to blow the whistle 2013-Nov-27 \n                   \n                     Stem cells in Texas: Cowboy culture 2013-Feb-13 \n                   \n                     Stem-cell fraud hits febrile field 2012-Oct-16 \n                   \n                     Timeline of a controversy 2005-Dec-19 \n                   \n                     Nature  special: Woo Suk Hwang revisited \n                   \n                     Sooam Biotech Research Foundation \n                   Reprints and Permissions"},
{"file_id": "505280a", "url": "https://www.nature.com/articles/505280a", "year": 2014, "authors": [{"name": "Ron Cowen"}], "parsed_as_year": "2006_or_before", "body": "The supermassive black holes that lie at the centre of every large galaxy are full of mysteries. But astronomers are finally getting a clear look. Many of the astronomers and physicists invited to the meeting feared for their safety. Others felt that the event should be cancelled outright. To hold a conference in Dallas, Texas, only weeks after US President John F. Kennedy had been assassinated there \u2014 it just seemed disrespectful. In the end, the first Texas Symposium on Relativistic Astrophysics went ahead as scheduled, starting on 16\u00a0December 1963, and most of the invited scientists did go \u2014 after the mayor of Dallas sent them a telegram urging their attendance. But the shadow cast by Kennedy\u2019s death added to the already surreal mood as they grappled with a phenomenon that seemed unfathomable. That year, observers had discovered that a collection of mysterious \u2018quasi-stellar\u2019 objects, dubbed quasars, were not just oddball versions of ordinary stars. They were cosmically distant, glowing with radiation that had travelled for billions of years to reach Earth. They were prodigiously bright, able to outshine 100 galaxies containing billions of normal stars. And they were astonishingly small for such bright objects \u2014 no bigger than our own Solar System. The presence of so much energy in so small a volume would bend space-time, as described by Albert Einstein\u2019s general theory of relativity, and might even cause the matter there to collapse into a gigantic black hole: an exotic possibility that at the time seemed like pure science fiction. \u201cQuasars really changed everything,\u201d says Michael Turner, a cosmologist at the University of Chicago, Illinois, who gave a speech commemorating the 50th anniversary of that inaugural meeting last month at the 27th Texas symposium, again in Dallas. Einstein\u2019s theory, which until the 1960s had been considered a niche idea with little to do with practical astronomy, was pushed to the fore. \u201cThe floodgates had opened,\u201d says Turner: observations soon proved that the Universe was stranger and more violent than astronomers had ever imagined. Explosions and eruptions were common\u00adplace. And Solar System-sized black holes with masses measured in millions or billions of Suns turned out to lie not just inside quasars, but at the centre of every large galaxy in the cosmos \u2014 including our own. As last month\u2019s symposium made clear, giant black holes still pose many puzzles, ranging from how they produce and release enormous amounts of energy to how they grew rapidly in the early Universe. Researchers are now starting to glean important clues from instruments including NASA\u2019s Nuclear Spectroscopic Telescope Array (NuSTAR), which was launched in mid-2012 as the first spacecraft dedicated to studying these objects. And this year astronomers will get a rare chance to study the eating habits of the black hole at the centre of our own Galaxy, when it feasts on a cloud of gas set to stray too close to its gravitational trap. The basics of black holes\u2019 energy production are now well established. Stars, gas and dust moving through the core of a galaxy get pulled in and compressed by the black hole\u2019s gravity, growing hotter and hotter as they spiral inwards, forming an accretion disk. By the time the superheated material approaches a spinning black hole\u2019s event horizon \u2014 the point of no return, beyond which even light cannot escape \u2014 up to 42% of its mass has been converted to energy. That energy emerges in the form of heat, light and, often, jets of high-speed particles that rocket in opposite directions perpendicular to the accretion disk. These jets can extend for thousands or even millions of parsecs. If one happens to be aimed directly at Earth, astronomers see the object as a quasar. If the jets point sideways instead, astronomers see the object as a galaxy with a very bright \u2018active galactic nucleus\u2019. And if the black hole\u2019s food supply is somehow restricted, so that it accretes very little gas and dust, the object is effectively invisible. Within that general picture, however, the details can be perplexing. Starting in 2006, for example, several sky surveys began to indicate that jets were emerging from their parent black holes with three times more energy than was contained in the original fuel, producing what seemed to be a gross violation of the conservation of energy. \n               Magnetic boost \n             At last month\u2019s conference, physicist Roger Blandford of Stanford University in California described a possible solution based on simulations of jet formation 1 , 2 . He and his colleagues imagine a rapidly spinning black hole with a strong magnetic field, properties that are difficult to detect directly but are theoretically plausible. The lines of the magnetic field are assumed to go out to great distances, threading through the accretion disk like stiff wires and dragging the disk\u2019s gas along with them as they rotate. The simulations show that under the right circumstances, the magnetic field can transfer enough of the black hole\u2019s rotational energy into the disk to power the anomalously strong jets. NuSTAR recently made the first definitive measurement of a supermassive black hole, revealing that it is spinning very fast indeed. This work was prompted by simulations that suggested a way to gauge the rotation of a black hole using X-rays emitted from near the event horizon. Rapidly spinning black holes should pull material closer to that horizon and subject it to intense gravity that would shift escaping X-rays to redder, less energetic wavelengths. Although astronomers had seen hints of this gravitational imprint with earlier X-ray tele\u00adscopes, they could not rule out the possibility that gas clouds were blanketing the accretion disk and confounding the result. But NuSTAR is sensitive to X-rays that have ten times higher energies than its predecessors could measure, and that punch through any such clouds. At the December meeting, NuSTAR chief scientist Fiona Harrison, an astronomer at the California Institute of Technology in Pasadena, reported seeing a clear signal of red-shifted X-rays from a relatively nearby spiral galaxy known as NGC\u00a01365. Taken together with measurements at lower X-ray energies made by the European Space Agency\u2019s XMM-Newton satellite, the observations showed that NGC\u00a01365\u2019s central black hole was spinning at nearly the maximum rate allowed by Einstein\u2019s theory 3 . It had enough rotational energy to tear apart its entire home galaxy, if that energy could somehow be unleashed. NGC\u00a01365 may not be typical. But as NuSTAR and future spacecraft begin to measure black-hole spins further back in time, Harrison says, the data may shed light on another conundrum. Astronomers have found quasars that are powered by billion-solar-mass black holes dating back to some 750 million years after the Big Bang, when the Universe was less than 6% of its current age. How did they get so big so fast? A black hole\u2019s spin rate may be a kind of fossil trace of its formation, Harrison explains. Supermassive black holes are too big to have been formed by a star collapsing under its own gravity, like stellar-mass black holes. If the giant black holes were built from many smaller ones, each merger would have brought together black holes spinning in random directions. After millions or billions of years of such collisions, the full-grown beast would have a net spin close to zero. But if the giant black hole had been built by the merger of just a few medium-sized objects, the growth could have been quicker, the spins would not necessarily have cancelled one another out, and the net rotation could be quite high. The near-maximum spin of the black hole in NGC\u00a01365 suggests that at least some supermassive black holes grew through rapid mergers \u2014 although that still leaves the question of where the original medium-sized black holes came from. \n               Fast spin, slow growth \n             Yet high spin could be a problem for black-hole growth in the early Universe, says Avi Loeb of the Harvard-Smith\u00adsonian Center for Astrophysics in Cambridge, Massachusetts. A rapidly rotating black hole tends to drag the inner edge of the accretion disk along with it, pulling it inwards, so the infalling matter has to trace out a longer, slower spiral to reach the event horizon than it would if the black hole were spinning slowly. And that provides more time for its mass to be converted into radiation instead of adding to the hole\u2019s mass. It is conceivable that strong magnetic fields came to the rescue, says Loeb. By transferring the black hole\u2019s rotational energy to the outer disk, they could quickly slow its spin, allow more matter to dive inwards and help the earliest black holes to pack on mass. If that is so, then future measurements will show that supermassive black holes have relatively modest spins. But Loeb\u2019s favourite model for how black holes could grow in a hurry involves episodes in which the monster gorges itself on a stream of material so dense and opaque that photons do not have enough time to leak out before the gas makes its final plunge. The radiation is carried inwards instead of escaping, and the black hole swallows its energy as extra mass 4 . Sometimes, a strong magnetic field can stunt a black hole, rather than helping it to grow. That could be what is happening to Earth\u2019s closest giant black hole, Sagittarius A*, which lies just 8,300 parsecs from Earth at the heart of the Milky Way. As such objects go, our local specimen is on the small side, with a mass of only four million Suns. And its emissions are minimal. The question is, why? It may simply be that there is not much gas and dust in the Milky Way\u2019s centre for the black hole to swallow. Or maybe something else is at work, says Mitchell Begelman, an astrophysicist at the University of Colorado Boulder. \u201cThere is a lot of interesting speculation that some accretion flows are \u2018magnetically arrested\u2019,\u201d he says. Last year, for example, NuSTAR discovered a magnetar \u2014 a highly magnetized neutron star \u2014 in an orbit close enough to Sagittarius\u00a0A* for astronomers to use it to probe the black hole\u2019s magnetic field. A close examination of the magnetar\u2019s radio emissions shows that the magnetic field surrounding Sagittarius A* is both sizable and highly ordered 5  \u2014 perhaps enough to block the black hole\u2019s food supply and put it on a near-starvation diet. Our black hole does occasionally get a little nourishment. Observers are hoping to watch what happens this March, when a distended object called G2 is predicted to come dangerously close to Sagittarius A*. The object, either a gas cloud or a star with a distended gaseous envelope, will be torn apart by the black hole\u2019s gravitational tidal forces. If it is gas, the resulting fireworks could be spectacular. But if G2 is a star, the chances of fireworks will be slimmer: it will keep a firmer grip on the gas and less material will fall in, says Andrea Ghez, an astronomer at the University of California, Los Angeles (see  Nature 495, 296\u2013298; 2013 ). Either way, astronomers should get a better understanding of what really happens when something falls into a giant black hole. And they may well have a preview in the next few months. In observations unveiled at the Texas meeting, NuSTAR showed that the neighbourhood of Sagittarius A* contains an assortment of small, stellar-sized black holes and neutron stars. \u201cIt\u2019s a rare treat that we\u2019ve been given,\u201d says astrophysicist Zolt\u00e1n Haiman of Columbia University in New York City, who has helped to carry out simulations which suggest that G2\u2019s fateful journey may lead to a collision with one of the small black holes 6 . Sagittarius A* promises even more excitement as astronomers gain new observational tools. Over the next few years, all 64 of the radio dishes from the Atacama Large Millimeter/submilli\u00admeter Array in northern Chile are expected to join other radio telescopes around the world to create an Earth-sized network. This combination could get an ultra-high-resolution snapshot of how the black hole bends radiation from objects on its far side into a thin ring, or shadow, around Sagittarius A*. Everyone expects the shape of the shadow to conform to the predictions of Einstein\u2019s theory. But if it doesn\u2019t \u2014 if general relativity does not correctly describe space-time around a black hole \u2014 the network could offer crucial clues about what theory should replace it. \u201cThat\u2019s the big-picture question,\u201d says Jonathan McKinney, a physicist at the University of Maryland in College Park. Fifty years after the first Texas symposium, \u201ceveryone wants to know if Einstein was right\u201d. \n                     Simulations back up theory that Universe is a hologram 2013-Dec-10 \n                   \n                     Astronomy: Reflections from a black hole 2013-Oct-16 \n                   \n                     Rare star probes supermassive black hole 2013-Aug-14 \n                   \n                     A strong magnetic field around the supermassive black hole at the centre of the Galaxy 2013-Aug-14 \n                   \n                     Giant black hole stretches gas cloud to the limit 2013-Jul-17 \n                   \n                     Magnetar found at giant black hole 2013-May-14 \n                   \n                     Gas cloud hurtling towards Milky Way's black hole may harbour young star 2012-Sep-11 \n                   \n                     NuSTAR \n                   \n                     Texas Symposium on Relativistic Astrophysics \n                   Reprints and Permissions"},
{"file_id": "biodiversity-life-a-status-report-1.16523", "url": "https://www.nature.com/news/biodiversity-life-a-status-report-1.16523", "year": 2014, "authors": [], "parsed_as_year": "2011_2015", "body": "Of all the species that have populated Earth at some time over the past 3.5 billion years, more than 95% have vanished \u2014 many of them in spectacular die-offs called mass extinctions. On that much, researchers can generally agree. Yet when it comes to taking stock of how much life exists today \u2014 and how quickly it will vanish in the future \u2014 uncertainty prevails. Studies that try to tally the number of species of animals, plants and fungi alive right now produce estimates that swing from less than 2\u00a0million to more than 50\u00a0million. The problem is that researchers have so far sampled only a sliver of Earth\u2019s biodiversity, and most of the unknown groups inhabit small regions of the world, often in habitats that are rapidly being destroyed. The International Union for Conservation of Nature (IUCN) highlighted the uncertainty in the latest version of its Red List of Threatened Species, which was released in November. The report evaluated more than 76,000 species, a big increase over earlier editions. But that is just 4% of the more than 1.7\u00a0million species that have been described by scientists, making it impossible to offer any reliable threat level for groups that have not been adequately assessed, such as fish, reptiles and insects. Recognizing these caveats,  Nature  pulled together the most reliable available data to provide a graphic status report of life on Earth (see \u2018Life under threat\u2019). Among the groups that can be assessed, amphibians stand out as the most imperilled: 41% face the threat of extinction, in part because of devastating epidemics caused by chytrid fungi. Large fractions of mammals and birds face significant threats because of habitat loss and degradation, as well as activities such as hunting. Looking forward, the picture gets less certain. The effects of climate change, which are hard to forecast in terms of pace and pattern, will probably accelerate extinctions in as-yet unknown ways. One simple way to project into the future would be to assume that the rate of extinction will be constant; it is currently estimated to range from 0.01% to 0.7% of all existing species a year. \u201cThere is a huge uncertainty in projecting future extinction rates,\u201d says Henrique Pereira, an ecologist at the German Centre for Integrative Biodiversity Research in Leipzig. At the upper rate, thousands of species are disappearing each year. If that trend continues, it could lead to a mass extinction \u2014 defined as a loss of 75% of species \u2014 over the next few centuries. Conservation policies could slow extinctions, but current trends do not give much comfort. Although nations are expanding the number of land and ocean areas that they set aside for protection, most measures of biodiversity show that pressures on species are increasing. \u201cIn general, the state of biodiversity is worsening, in many cases significantly,\u201d says Derek Tittensor, a marine ecologist with the United Nations Environment Programme\u2019s World Conservation Monitoring Centre in Cambridge, UK. Despite all the uncertainty, researchers agree that they need to devote more attention to evaluating current and future risks to biodiversity. One approach is to develop comprehensive computer models that can forecast how human activities will alter ecosystems. These general ecosystem models, or GEMs, are in their infancy: earlier this year, Tittensor and his colleagues published initial results from the first global model that seeks to mimic all the major ecological interactions on Earth in much the same way as climate models simulate the atmosphere and oceans ( M.\u00a0B.\u00a0J.\u00a0Harfoot  et\u00a0al. PLoS Biol. 12, e1001841; 2014 ). Building the GEM took 3 years, in part because the model tries to represent all organisms with body masses ranging from 10\u00a0micrograms (about the weight of small plankton) to 150,000\u00a0kilograms (roughly the size of a blue whale). \u201cIt needs a lot more development and testing, and ideally there will be a lot more variety of these models,\u201d says Tittensor. But if they do a decent job of capturing the breadth of life in a computer, he says, \u201cthey have real potential to alert us to potential problems we wouldn\u2019t otherwise detect\u201d."},
{"file_id": "505276a", "url": "https://www.nature.com/articles/505276a", "year": 2014, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Sixteen years into the mysterious \u2018global-warming hiatus\u2019, scientists are piecing together an explanation. The biggest mystery in climate science today may have begun, unbeknownst to anybody at the time, with a subtle weakening of the tropical trade winds blowing across the Pacific Ocean in late 1997. These winds normally push sun-baked water towards Indonesia. When they slackened, the warm water sloshed back towards South America, resulting in a spectacular example of a phenomenon known as El\u00a0Ni\u00f1o. Average global temperatures hit a record high in 1998 \u2014 and then the warming stalled. For several years, scientists wrote off the stall as noise in the climate system: the natural variations in the atmosphere, oceans and biosphere that drive warm or cool spells around the globe. But the pause has persisted, sparking a minor crisis of confidence in the field. Although there have been jumps and dips, average atmospheric temperatures have risen little since 1998, in seeming defiance of projections of climate models and the ever-increasing emissions of greenhouse gases. Climate sceptics have seized on the temperature trends as evidence that global warming has ground to a halt. Climate scientists, meanwhile, know that heat must still be building up somewhere in the climate system, but they have struggled to explain where it is going, if not into the atmosphere. Some have begun to wonder whether there is something amiss in their models. Now, as the global-warming hiatus enters its sixteenth year, scientists are at last making headway in the case of the missing heat. Some have pointed to the Sun, volcanoes and even pollution from China as potential culprits, but recent studies suggest that the oceans are key to explaining the anomaly. The latest suspect is the El\u00a0Ni\u00f1o of 1997\u201398, which pumped prodigious quantities of heat out of the oceans and into the atmosphere \u2014 perhaps enough to tip the equatorial Pacific into a prolonged cold state that has suppressed global temperatures ever since. \u201cThe 1997 to \u201998 El\u00a0Ni\u00f1o event was a trigger for the changes in the Pacific, and I think that\u2019s very probably the beginning of the hiatus,\u201d says Kevin Trenberth, a climate scientist at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado. According to this theory, the tropical Pacific should snap out of its prolonged cold spell in the coming years.\u201cEventually,\u201d Trenberth says, \u201cit will switch back in the other direction.\u201d \n               Stark contrast \n             On a chart of global atmospheric temperatures, the hiatus stands in stark contrast to the rapid warming of the two decades that preceded it. Simulations conducted in advance of the 2013\u201314 assessment from the Intergovernmental Panel on Climate Change (IPCC) suggest that the warming should have continued at an average rate of 0.21\u2009\u00b0C per decade from 1998 to 2012. Instead, the observed warming during that period was just 0.04\u2009\u00b0C per decade, as measured by the UK Met Office in Exeter and the Climatic Research Unit at the University of East Anglia in Norwich, UK. The simplest explanation for both the hiatus and the discrepancy in the models is natural variability. Much like the swings between warm and cold in day-to-day weather, chaotic climate fluctuations can knock global temperatures up or down from year to year and decade to decade. Records of past climate show some long-lasting global heatwaves and cold snaps, and climate models suggest that either of these can occur as the world warms under the influence of greenhouse gases. But none of the climate simulations carried out for the IPCC produced this particular hiatus at this particular time. That has led sceptics \u2014 and some scientists \u2014 to the controversial conclusion that the models might be overestimating the effect of greenhouse gases, and that future warming might not be as strong as is feared. Others say that this conclusion goes against the long-term temperature trends, as well as palaeoclimate data that are used to extend the temperature record far into the past. And many researchers caution against evaluating models on the basis of a relatively short-term blip in the climate. \u201cIf you are interested in global climate change, your main focus ought to be on timescales of 50 to 100 years,\u201d says Susan Solomon, a climate scientist at the Massachusetts Institute of Technology in Cambridge. But even those scientists who remain confident in the underlying models acknowledge that there is increasing pressure to work out just what is happening today. \u201cA few years ago you saw the hiatus, but it could be dismissed because it was well within the noise,\u201d says Gabriel Vecchi, a climate scientist at the US National Oceanic and Atmospheric Administration\u2019s Geophysical Fluid Dynamics Laboratory in Princeton, New Jersey. \u201cNow it\u2019s something to explain.\u201d Researchers have followed various leads in recent years, focusing mainly on a trio of factors: the Sun 1 , atmospheric aerosol particles 2  and the oceans 3 . The output of energy from the Sun tends to wax and wane on an 11-year cycle, but the Sun entered a prolonged lull around the turn of the millennium. The natural 11-year cycle is currently approaching its peak, but thus far it has been the weakest solar maximum in a century. This could help to explain both the hiatus and the discrepancy in the model simulations, which include a higher solar output than Earth has experienced since 2000. An unexpected increase in the number of stratospheric aerosol particles could be another factor keeping Earth cooler than predicted. These particles reflect sunlight back into space, and scientists suspect that small volcanoes \u2014 and perhaps even industrialization in China \u2014 could have pumped extra aerosols into the stratosphere during the past 16\u00a0years, depressing global temperatures. Some have argued that these two factors could be primary drivers of the hiatus, but studies published in the past few years suggest that their effects are likely to be relatively small 4 , 5 . Trenberth, for example, analysed their impacts on the basis of satellite measurements of energy entering and exiting the planet, and estimated that aerosols and solar activity account for just 20% of the hiatus. That leaves the bulk of the hiatus to the oceans, which serve as giant sponges for heat. And here, the spotlight falls on the equatorial Pacific. \n               Blowing hot and cold \n             Just before the hiatus took hold, that region had turned unusually warm during the El\u00a0Ni\u00f1o of 1997\u201398, which fuelled extreme weather across the planet, from floods in Chile and California to droughts and wildfires in Mexico and Indonesia. But it ended just as quickly as it had begun, and by late 1998 cold waters \u2014 a mark of El Ni\u00f1o\u2019s sister effect, La Ni\u00f1a \u2014 had returned to the eastern equatorial Pacific with a vengeance. More importantly, the entire eastern Pacific flipped into a cool state that has continued more or less to this day. This variation in ocean temperature, known as the Pacific Decadal Oscillation (PDO), may be a crucial piece of the hiatus puzzle. The cycle reverses every 15\u201330\u00a0years, and in its positive phase, the oscillation favours El\u00a0Ni\u00f1o, which tends to warm the atmosphere (see \u2018The fickle ocean\u2019). After a couple of decades of releasing heat from the eastern and central Pacific, the region cools and enters the negative phase of the PDO. This state tends towards La\u00a0Ni\u00f1a, which brings cool waters up from the depths along the Equator and tends to cool the planet. Researchers identified the PDO pattern in 1997, but have only recently begun to understand how it fits in with broader ocean-circulation patterns and how it may help to explain the hiatus. One important finding came in 2011, when a team of researchers at NCAR led by Gerald Meehl reported that inserting a PDO pattern into global climate models causes decade-scale breaks in global warming 3 . Ocean-temperature data from the recent hiatus reveal why: in a subsequent study, the NCAR researchers showed that more heat moved into the deep ocean after 1998, which helped to prevent the atmosphere from warming 6 . In a third paper, the group used computer models to document the flip side of the process: when the PDO switches to its positive phase, it heats up the surface ocean and atmosphere, helping to drive decades of rapid warming 7 . A key breakthrough came last year from Shang-Ping Xie and Yu Kosaka at the Scripps Institution of Oceanography in La Jolla, California. The duo took a different tack, by programming a model with actual sea surface temperatures from recent decades in the eastern equatorial Pacific, and then seeing what happened to the rest of the globe 8 . Their model not only recreated the hiatus in global temperatures, but also reproduced some of the seasonal and regional climate trends that have marked the hiatus, including warming in many areas and cooler northern winters. \u201cIt was actually a revelation for me when I saw that paper,\u201d says John Fyfe, a climate modeller at the Canadian Centre for Climate Modelling and Analysis in Victoria. But it did not, he adds, explain everything. \u201cWhat it skirted was the question of what is driving the tropical cooling.\u201d That was investigated by Trenberth and John Fasullo, also at NCAR, who brought in winds and ocean data to explain how the pattern emerges 4 . Their study documents how tropical trade winds associated with La\u00a0Ni\u00f1a conditions help to drive warm water westward and, ultimately, deep into the ocean, while promoting the upwelling of cool waters along the eastern equatorial region. In extreme cases, such as the La Ni\u00f1a of 1998, this may be able to push the ocean into a cool phase of the PDO. An analysis of historical data buttressed these conclusions, showing that the cool phase of the PDO coincided with a few decades of cooler temperatures after the Second World War (see \u2018The Pacific\u2019s global reach\u2019), and that the warm phase lined up with the sharp spike seen in global temperatures between 1976 and 1998 (ref.  4 ). \u201cI believe the evidence is pretty clear,\u201d says Mark Cane, a climatologist at Columbia University in New York. \u201cIt\u2019s not about aerosols or stratospheric water vapour; it\u2019s about having had a decade of cooler temperatures in the eastern equatorial Pacific.\u201d \n               Heated debate \n             Cane was the first to predict the current cooling in the Pacific, although the implications weren\u2019t clear at the time. In 2004, he and his colleagues found that a simple regional climate model predicted a warm shift in the Pacific that began around 1976, when global temperatures began to rise sharply 9 . Almost as an afterthought, they concluded their paper with a simple forecast: \u201cFor what it is worth the model predicts that the 1998 El\u00a0Ni\u00f1o ended the post-1976 tropical Pacific warm period.\u201d It is an eerily accurate result, but the work remains hotly contested, in part because it is based on a partial climate model that focuses on the equatorial Pacific alone. Cane further maintains that the trend over the past century has been towards warmer temperatures in the western Pacific relative to those in the east. That opens the door, he says, to the possibility that warming from greenhouse gases is driving La\u00a0Ni\u00f1a-like conditions and could continue to do so in the future, helping to suppress global warming. \u201cIf all of that is true, it\u2019s a negative feedback, and if we don\u2019t capture it in our models they will overstate the warming,\u201d he says. There are two potential holes in his assessment. First, the historical ocean-temperature data are notoriously imprecise, leading many researchers to dispute Cane\u2019s assertion that the equatorial Pacific shifted towards a more La\u00a0Ni\u00f1a-like state during the past century 10 . Second, many researchers have found the opposite pattern in simulations with full climate models, which factor in the suite of atmospheric and oceanic interactions beyond the equatorial Pacific. These tend to reveal a trend towards more El\u00a0Ni\u00f1o-like conditions as a result of global warming. The difference seems to lie, in part, in how warming influences evaporation in areas of the Pacific, according to Trenberth. He says the models suggest that global warming has a greater impact on temperatures in the relatively cool east, because the increase in evaporation adds water vapour to the atmosphere there and enhances atmospheric warming; this effect is weaker in the warmer western Pacific, where the air is already saturated with moisture. Scientists may get to test their theories soon enough. At present, strong tropical trade winds are pushing ever more warm water westward towards Indonesia, fuelling storms such as November\u2019s Typhoon Haiyan, and nudging up sea levels in the western Pacific; they are now roughly 20\u00a0centimetres higher than those in the eastern Pacific. Sooner or later, the trend will inevitably reverse. \u201cYou can\u2019t keep piling up warm water in the western Pacific,\u201d Trenberth says. \u201cAt some point, the water will get so high that it just sloshes back.\u201d And when that happens, if scientists are on the right track, the missing heat will reappear and temperatures will spike once again. See Editorial  page 261 \n                     Cool heads needed 2014-Jan-15 \n                   \n                     Tropical ocean key to global warming \u2018hiatus\u2019 2013-Aug-28 \n                   \n                     Climate change: The forecast for 2018 is cloudy with record heat 2013-Jul-10 \n                   \n                     Water vapour could be behind warming slowdown 2010-Jan-28 \n                   \n                     The real holes in climate science 2010-Jan-20 \n                   \n                     Atmospheric science: Climate's smoky spectre 2009-Jul-01 \n                   \n                     IPCC \n                   \n                     NOAA ENSO \n                   \n                     NASA solar-cycle data \n                   Reprints and Permissions"},
{"file_id": "505472a", "url": "https://www.nature.com/articles/505472a", "year": 2014, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Ultra-pure synthetic diamonds offer advances in fields from quantum computing to cancer diagnostics. The 'magic Russian diamond', as some researchers have come to call it, was just 2 millimetres square, very clear and of a quality any jeweller would be happy to set in an expensive ring. J\u00f6rg Wrachtrup, a physicist at the University of Stuttgart in Germany, had spent much of 2005 looking for something just like it; his group finally found it by trawling through journals from the Russian Academy of Sciences, reading descriptions of the physical properties of such rare gems. But Wrachtrup wasn't interested in this diamond's beauty: what intrigued him was that the stone was very pure and perfectly flawed. Inside the Russian gem, the regular diamond lattice of carbon atoms was interrupted on rare occasions by a nitrogen atom, with a neighbouring carbon atom also missing. Within each such hole, an extra electron could become trapped (see 'A useful hole'). Such impurities are not in themselves unusual. But Wrachtrup and others had theorized that, in some specific cases, electrons in these holes could prove the perfect medium for storing information for quantum computing \u2014 an effort to vastly speed up computing calculations by exploiting the fuzzy world of quantum mechanics. Unlike other candidates for such information storage, these defects in diamond should do their job at room temperature. To test the idea, Wrachtrup's lab split the diamond and sent half of it to Mikhail Lukin, a physicist at Harvard University in Cambridge, Massachusetts. By the end of 2006, both groups had shown that the Russian stone proved the theory correct 1 , 2 . \u201cThis diamond showed behaviour we had never seen before,\u201d says Wrachtrup. Since then, the field has exploded. In 2005, just a handful of groups worldwide were working on the quantum possibilities of diamond; there are now about 75 in on the action. The Russian diamond has been cut up and divided between teams. Despite much searching, no other natural gems quite like it have been found. So researchers have turned their attention to making synthetic versions that are even better. As more teams have entered into the game, so have ideas for potential applications. The same properties that make diamonds useful for storing quantum information also make them ideal for sensing magnetic fields with incredible precision, which could be used to eavesdrop on the processes in living cells in real time. Tiny sensors could provide cellular-level imaging with one billion billion times more sensitivity than conventional magnetic resonance imaging (MRI), allowing investigators to map electrical activity in neurons or watch a cell's reaction to a drug. \u201cWe're really solving problems we haven't been able to solve before,\u201d says Wrachtrup.  \n               Grown from scratch \n             Diamond lovers are familiar with impurities for their ability to give the stones exotic hues: nitrogen can lend a yellow tone; boron turns them blue. What excites physicists is the 'spin' of the electrons trapped in such defects. That quantum property can be either up, down or somewhere in between \u2014 all at the same time. Such fuzziness is required for the basic unit of quantum computing, called quantum bits, or qubits. Unlike conventional computer bits that are either on or off, a qubit must have the capacity to exist in multiple states simultaneously, allowing a computer to perform parallel calculations. Quantum properties such as spin are delicate, and are easily influenced by any outside interference. Diamond makes a great candidate for qubits because its rigid crystal structure helps to isolate and protect trapped electrons' fragile quantum states from random perturbations. The spin can, however, be manipulated by microwaves and read out using lasers. Natural stones usually contain flaws at a level of about one-in-a-thousand atoms, which is much too many to make them useful for information storage: the defects are so close together that they interfere with each other, meaning that electrons cannot reliably hold any given spin state for long. By contrast, the Russian diamond contains fewer than one nitrogen atom per billion carbon atoms. Back in 2005, Wrachtrup's tests showed that electrons in the Russian diamond could maintain a defined spin state for almost a millisecond; the only other set-ups able to maintain a spin state for this long were those that were super-cooled to near absolute zero and maintained under a high vacuum. Diamond allows scientists to change and read the quantum state of a single electron at room temperature using everyday lab equipment. \u201cThat was a bit of a game changer,\u201d says David Awschalom, a physicist at the University of Chicago in Illinois, who was one of the first investigators to work on quantum-grade diamonds. Makers of synthetic quantum-grade diamonds try to achieve at least the same level of purity as that of the Russian diamond. Unlike stones made for jewellery or industrial cutting, these diamonds aren't grown by putting a lump of carbon under high temperature and pressure. Instead, gases such as methane and hydrogen are heated into a plasma, so that carbon atoms can be deposited onto a template layer by layer. Some academic labs can make such diamonds themselves, but the major hub for research into this type of diamond production is the UK-based labs of the company Element Six, which has been synthesizing diamond \u2014 originally for cutting and drilling \u2014 for more than 50 years. Its business is booming. In July 2013, the company opened a \u00a320-million (US$32.9-million) Global Innovation Centre in Harwell near Oxford, UK, to research and develop better diamond-production schemes for new applications. It now sells a few hundred off-the-shelf pure diamonds for quantum research each year, and its production of custom diamonds for specific projects has doubled annually since 2007, totalling 1,500 so far. In the lab where the custom diamonds are grown, a dozen machines hum away, teeming with feeding tubes that bring in the basic ingredients. Element Six now sells an ultra-pure diamond with impurities lower than one part per billion, into which scientists can implant desired defects. Those cost about $1,000 each. For their custom diamonds, the company works with researchers to put flaws in precise layers and to control the levels of different carbon isotopes, which can also affect a diamond's properties. \u201cBuilding it atom by atom gives you the ability to control impurities,\u201d says Geoff Scarsbrook, research and development operations manager at Element Six. The company provides these diamonds to researchers at no cost with the aim of developing intellectual property rights and opening promising new markets. \u201cWe are prepared to take quite a long view,\u201d says Scarsbrook. That they have a long outlook is just as well. Producing a single qubit is one thing, but producing a functional quantum computer with many cooperating qubits is quite another \u2014 as researchers working with other materials have discovered. Since the mid-1990s, a few systems have emerged as the leading candidates for qubits, including ions trapped by an electromagnetic field and superconducting circuits, which must be super-cooled. Scientists working with these systems still struggle to deal with interference and to hook multiple qubits up into usable systems. So far, the world's best all-purpose quantum 'computers' are toy models comprising little more than a dozen qubits that can do small tasks such as factoring the number 15 (with one stand-out exception of a controversial, specialized type of quantum system, see  Nature 498, 286\u2013288; 2013 ). Diamonds show substantial potential, however, and some gems can now keep qubits protected from interference for long enough to do something useful, says Ronald Hanson, a nanoscientist at Delft University of Technology in the Netherlands. In 2012, for example, Lukin's team reported 3  achieving a lifetime for a diamond qubit of more than one second, on a par with what has been achieved in trapped atoms and about 10,000 times better than in superconducting circuits. To do this, his team used the trapped electrons' spin only as a messenger. To actually hold information they used the quantum-spin properties of the neighbouring impurities \u2014 such as a nitrogen atom or a carbon-13 isotope \u2014 which are about 1,000 times less sensitive to interference than the spins of electrons are. A trick to control the electrons' spin when they are not acting as a messenger can theoretically extend the qubit's lifetime by up to a minute. \n               Quantum bits and pieces \n             But connecting up the qubits \u2014 which involves 'entangling' their states so that they can work together to perform calculations \u2014 is a greater challenge. Wrachtrup's approach is to carefully position diamond defects about 20 nanometres apart in an array, so that the trapped electrons are close enough to entangle. Yet manufacturers have a hard time fabricating diamonds with such precisely placed defects. And the proximity of the imperfections means that the spin of each electron must be precisely controlled if the quantum states are to survive \u2014 something that is ever more difficult to achieve as the systems scale up in size. In an alternative approach, Hanson's team last year reported connecting up diamond qubits that are 3 metres apart by using flying intermediaries: photons that entangle with the electron spins and with each other 4 . That could prove particularly useful for a quantum network used to exchange information over long distances. But for Hanson's system to work, the qubits have to entangle in a much shorter time than the qubit lifetime. That means entanglement should happen many times a second; so far, Hanson and his collaborators have only succeeded in producing entanglement once every 10 minutes. Physicists including Hanson, Lukin and Dirk Englund, an electronic engineer at the Massachusetts Institute of Technology in Cambridge, are trying to improve the entanglement rate by building tiny cavities and mirrors into thin films of diamond \u2014 this helps to bounce photons around and gives them more opportunities to interact with the electron qubits. Hanson thinks that this should make it possible to reduce entanglement times to fractions of a second. Teams are working on the best way to do this \u2014 some methods require thin films of diamond no more than a few hundred nanometres thick, laboriously ground from larger pieces. \u201cIt's very tedious to do,\u201d says Wrachtrup. \u201cIt's almost a work of art.\u201d So far, the most sophisticated quantum-computing systems made of diamond \u2014 achieved separately by two different groups 5 , 6  \u2014 involve four entangled qubits. Scaling up to more than about ten will require a concerted engineering effort, says Wrachtrup. But diamond remains a viable option for quantum computing, with its greatest selling point being its ability to hold quantum information for long periods of time, at room temperature and without a vacuum. \u201cIt's really that combination that shows promise,\u201d says Hanson. \n               Tiny magnets \n             While researchers continue to battle with quantum computing, other applications for diamond could come to fruition more quickly. Some of the first researchers to explore the quantum properties of diamond realized that the way in which delicate spin states can be affected by their environment could be put to good use. The electrons' spins have a magnetic moment, which makes them act like tiny bar magnets that are sensitive to other nearby magnetic fields. Sensing techniques such as MRI make use of a similar phenomenon \u2014 the spin inherent in hydrogen atoms \u2014 to spy inside the human body. But these require millions of atoms to get a signal. And for the greatest precision, the machines need to be cooled to very low temperatures. Diamond probes can be small enough and close enough to their target to pick up a signal from a single atom, at room temperature \u2014 the magnetic field of the atom affects the electrons' spin, which can be read with a laser. Sensors that use large numbers of diamond defects to measure relatively large magnetic fields are already in development. At small scales there have been proof-of-principle studies, including work measuring spins in a drop of oil just 5 cubic nanometres in size 7  and even in a single molecule 8 . In 2011, a team led by Lloyd Hollenberg at the University of Melbourne in Australia put nanodiamonds into living cells, allowing scientists to study tiny magnetic changes within them 9 . Wrachtrup says that a diamond-based probe should eventually be able to image the structure of a complex molecule such as a protein, monitor activity in the brain or track the action of a drug in a cell \u2014 all without altering the living system being observed. Lukin's group has also made use of nanodiamond probes to take temperature readings inside a cell to within a few hundredths of a degree 10 , by monitoring the response of trapped electrons' sensitive spin to the expansion and contraction of a diamond lattice as it heats and cools. Nanodiamond probes should be able to detect changes of a few thousandths of a degree, and could be used to infer biological processes such as tumour metabolism. However, making nanometre-sized ultra-pure diamonds for tiny probes is a real headache: the deposition method used by everyone, including Element Six, produces gems that cannot be separated from their template base. Most of the proof-of-principle work on nanodiamond probes has therefore been done using relatively impure diamonds, made through high pressure and temperature compression. This limits their sensitivity. Englund's team has come up with a better means of production, which is now being commercialized by Diamond Nanotechnologies in Boston, Massachusetts, a company Englund set up with a former postdoc. They paint gold palladium dots over pure diamond and then etch away the bits of surface left exposed, producing a series of gold-topped diamond posts that his team calls 'nano-grass'. These can be mowed, and the gold tops easily removed, to produce individual, minuscule diamond pillars. When made in this way, the electrons trapped in the diamond defects hold their spin for 100 times longer than those in conventional nanodiamonds 11 . The firm is using these pillars to build a prototype magnetic field sensor that is sensitive enough to detect the field from just a few electrons. \n               Diamond doubles \n             Researchers will need production improvements such as these if they want to squeeze all the promise out of diamonds. But there is still a long way to go to perfect precision doping of defects and the production of large thin films and complex diamond structures. Fulfilling specifications like these is routine for many semiconductor materials, including silicon. So Awschalom's group is exploring whether it might be possible to reproduce the seemingly unique properties of diamond in such materials. In 2011, his group showed that silicon carbide \u2014 a relatively cheap semiconductor that has for decades been manufactured in large, thin films for use in electronics \u2014 can host defects in which bound electrons exhibit the same quantum quirks as in diamond 12 . His group has made silicon carbide qubits. But these lack the main advantage of diamond qubits: so far, the lifetime of trapped electron spin states in silicon carbide at room temperature is 20 times shorter than in diamond \u2014 too short for most practical applications. Awschalom's group is among a number attempting various tricks to boost silicon carbide qubit lifetime, including purifying the isotopic composition of the material. And the team is collaborating with theorist and former colleague Chris Van de Walle at the University of California, Santa Barbara, to predict which defects in other crystalline materials \u2014 including gallium nitride, which is used in light-emitting diodes \u2014 might match diamond's properties. \u201cIt's definitely an extremely promising new direction,\u201d says Englund. \u201cThere could be many we just don't know about.\u201d But for most researchers, diamonds remain the material of choice. With their extreme purity and controllable spin states, synthetic stones now outshine any natural gem. Even so, the original magic Russian diamond continues to prove its worth. \u201cWe still have pieces in the lab, and once in a while we use them,\u201d says Wrachtrup. \u201cThey're still among the best we have.\u201d \n                     Nanothermometer takes the temperature of living cells 2013-Jul-31 \n                   \n                     Computing: The quantum company 2013-Jun-19 \n                   \n                     Diamond shows promise for a quantum Internet 2013-Apr-24 \n                   \n                     Diamond defects shrink MRI to the nanoscale 2013-Jan-31 \n                   \n                     Element Six \n                   \n                     Stuttgart lab: magnetic sensors \n                   \n                     Harvard lab: diamonds \n                   \n                     Diamond Nanotechnologies \n                   Reprints and Permissions"},
{"file_id": "505604a", "url": "https://www.nature.com/articles/505604a", "year": 2014, "authors": [{"name": "M. Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "Powerful X-ray lasers are getting to the heart of matter. In the foothills above Palo Alto, California, physicists have set up an extreme obstacle course for some of the world's fastest electrons. First the particles are accelerated through a 3-kilometre vacuum pipe to almost the speed of light. Then they slam through a gauntlet of magnets that forces them into a violent zigzag. They respond with a blast of X-rays so fierce it could punch through steel. But the scientists at the SLAC National Accelerator Laboratory have no interest in weaponry. Their machine, one of the world's most powerful X-ray free-electron lasers (XFELs), is a tool for studying challenging forms of matter, whether compressed to the kind of pressures and temperatures found deep inside a star, or folded into the complex tangle of a protein molecule. Structural biologists, in particular, stand to benefit greatly from XFELs. With X-ray pulses short enough to capture strobe-like images of molecular motions, and intense enough to image the multitude of biomolecules that have defied conventional methods, XFELs are giving biologists new ways to scan for potential drug targets, to probe the mechanics of photosynthetic molecules, and more. \u201cXFELs, without any doubt, are disruptive technology,\u201d says Keith Moffat, a crystallographer at the University of Chicago in Illinois who has served on the SLAC machine's scientific advisory board \u2014 \u201can advance that is so far beyond what has gone before that it alters the way you do things\u201d. But XFELs have also been controversial technology \u2014 especially the SLAC machine, known as the Linac Coherent Light Source (LCLS), which was one of the first and biggest. It was given the go-ahead by the US Department of Energy (DOE) in 2002 in the face of frequent criticism from researchers, many of whom doubted whether its scientific benefits would ever be worth its US$414-million cost \u2014 assuming that the unproven technology worked at all. Those concerns have ebbed since the LCLS began operation in 2009, says Moffat: \u201cThis thing worked, pretty much as advertised, pretty much right out of the box, on schedule, on budget.\u201d In its wake, Japan has built its own XFEL; Europe is following with an even more capable version set to open in 2015; and others are being planned for Switzerland and South Korea. Global investments in XFELs over the next few years will total billions of dollars. But to reach their full potential, these machines will have to surmount many more technical hurdles, from boosting their power and brightness to handling the deluge of data they produce. \u201cPhysicists, biologists, laser scientists, high-energy-density scientists \u2014 a completely new community is being formed, because you have to understand all the processes involved,\u201d says Janos Hajdu, a molecular biophysicist at Uppsala University in Sweden. \u201cThere are lots of developments that have to come together to make this work.\u201d \n               Corralling X-rays \n             The path towards XFELs began just over 100 years ago, when pioneering physicists including Max von Laue recognized the power of X-rays for studying matter (see  page 602 ). Only photons with extremely short wavelengths can image molecules or materials at the atomic scale \u2014 roughly 0.1 nanometres, or 1 \u00e5ngstr\u00f6m. But getting images from X-rays is tricky. There is no X-ray equivalent of a visible-light microscope, mainly because there are no good lenses for focusing the rays. So for the past century, physicists have relied on X-ray crystallography, in which they fire a beam of X-rays through a crystal lattice of identical molecules and record the resulting 'diffraction pattern' of scattered X-rays. They then work backwards from the pattern to mathematically reconstruct the original structure. In recent decades, this has been done mostly at synchrotrons: accelerators that generate X-rays by whipping electrons around in a circle. Dozens of these light sources have grown up around the world, and they have been a boon to structural biology: the international Protein Data Bank repository currently has nearly 100,000 structures on file, most obtained from synchrotrons. Unfortunately, many of the most scientifically interesting biomolecules, such as some membrane-bound protein complexes that mediate molecular traffic in and out of the cell, are still out of the reach of synchrotrons because they do not grow into crystals that are large enough and perfect enough to produce a usable diffraction pattern. Yet even the most crystallization-resistant macromolecules will often form nanocrystals a few dozen molecules across. Because the beams from synchrotrons are not bright enough to get usable diffraction patterns from such structures, researchers have turned to XFELs, which are at least a billion times brighter than synchrotrons. The basic principles of XFELs were worked out in the 1980s, building on an earlier generation of free-electron lasers that produced photons much less energetic than X-rays. In both types of laser, a beam of unconfined electrons passes through magnets that force it into an undulating path, and the beam emits photons along its line of flight. But at X-ray energies, the photons interact with the electrons in a manner that produces ferociously bright X-ray laser pulses lasting only a few femtoseconds (10 \u221215  seconds) each \u2014 short enough to essentially freeze the motion of molecules in the target (see 'X-ray vision'). In 1992, Claudio Pellegrini, a physicist at the University of California, Los Angeles, and the idea's leading champion, proposed to build one of these machines at SLAC, arguing that the facility's soon-to-retire 50-GeV electron beam could be adapted to make an XFEL operating at wavelengths of 1\u201340 \u00e5ngstr\u00f6ms. To the idea's many sceptics, Pellegrini admits, this was a fool's errand: no one had ever demonstrated a free-electron laser at these energies. \u201cThere was a lot of scepticism that you could really reach 1 \u00e5ngstr\u00f6m,\u201d he says. Still, says Pellegrini, there were also many physicists around the world who thought that the idea was worth pursuing. And through experiments and simulations during the 1990s, advocates systematically built a persuasive argument that XFELs would work. By the early 2000s, that case was solid enough for the DOE to commit to building the SLAC machine. Germany had already started to build the Free-Electron Laser in Hamburg (FLASH), a lower-energy 'soft' XFEL at the German Electron Synchrotron (DESY); and Japan and a group of European countries were initiating studies that would, a decade later, lead to their own machines. \n               Before the Explosion \n             Even as the first XFELs were taking shape, however, would-be users were grappling with a seemingly intractable problem \u2014 such bright beams would destroy any sample in their path. Only in 2000 did Hajdu and his team demonstrate an escape 1 : on a femtosecond timescale, even molecular explosions unfold slowly. It takes roughly 10 femtoseconds for photons to be absorbed, molecular bonds to break and atoms to start moving from their original positions. But all the while, the photons that are not absorbed \u2014 the ones that scatter off the individual atoms and produce the diffraction pattern \u2014 are racing through the crystal at the speed of light. The team's simulations confirming this idea, called diffract-before-destruction, were published just in time to help the DOE to make the science case for the LCLS. But that left the question of how to implement it. Unlike at synchrotrons, where large crystals of a sample can be mounted at a precise angle and measurements taken at leisure, repeatedly, at the LCLS researchers would somehow have to take nanocrystals too small to see or touch, and position them in front of X-ray pulses that would make them explode \u2014 with the machine firing 120 pulses per second.  Researchers had never contemplated a computational challenge of this magnitude  John Spence, a physicist at Arizona State University in Tempe, took up this challenge in collaboration with Henry Chapman, a physicist now at the University of Hamburg. \u201cBecause every sample is destroyed, you have to provide new ones,\u201d says Spence. The team's solution was a device that functioned much like an ink-jet printer: it would fire tiny droplets of water across the beam in a continuous stream with the nanocrystals in suspension. Furthermore, says Spence, because the beam would be zapping those drops and producing new diffraction patterns so often, \u201ca few days would give you 100 terabytes of data\u201d. And each pulse would catch its nanocrystal in some unknown, random orientation, he says, so you would need to process every terabyte to reconstruct the original molecule. \u201cThis was a shocking thing to the crystallography community,\u201d says Spence: such researchers had never contemplated a computational challenge of this magnitude. Only in 2008 did Spence's student Richard Kirian work out the algorithms required to do it 2 . In late 2005, Chapman had led a team that demonstrated the technique using FLASH's longer-wavelength soft X-rays 3 . But that did not convince sceptics that it would work in a 'hard' XFEL, says Petra Fromme, a biochemist at Arizona State who was contributing her expertise in nanocrystals to the effort. \u201cBy this time, we had submitted ten different grant proposals to investigate big membrane complexes in XFELs,\u201d she says \u2014 and had received ten rejections. So the group, with SLAC and the DOE, had a lot of credibility at stake in December 2009, when XFEL technology, the injector and diffract-before-destruction all came together: their membrane-complex experiment would be one of the first at the newly operational LCLS. And when the computer monitors lining the walls of the tiny, underground LCLS control room suddenly started flashing twice per second with diffraction patterns, the dozens of scientists and technicians crowded inside erupted into cheers, applause and hugs. \u201cThere is extraordinary excitement that is building up around this,\u201d Chapman wrote in an e-mail that evening. \n               Bigger and better \n             With this experiment 4  and the many that have followed, says Moffat, \u201cthe gamble was absolutely validated.\u201d Indeed, \u201cthousands of people have been coming out of the woodwork, salivating to use this machine\u201d. In 2013 alone, the published output of the LCLS ranged from a femtosecond-scale study of how matter is affected by an intense shock wave 5  to the previously unknown structure of cathepsin B, an enzyme (and potential drug target) found in the sleeping-sickness parasite  Trypanosoma brucei 6 . Demand for time on the machine is so high that the DOE is planning an upgrade dubbed LCLS-II, which would triple the number of simultaneously operating experimental stations by 2018. Last November, the US National Science Foundation committed $25 million over the next five years to fund a centre for Biology with X-Ray Free Electron Lasers (BioXFEL) at the University at Buffalo in New York. With Spence as scientific director, the centre will push the technology on multiple fronts, from improving the preparation of nanocrystals to watching proteins in action as they react with other compounds. Still, says John Tainer, a structural biologist at the Lawrence Berkeley National Laboratory in Berkeley, California, \u201cwe haven't yet shown XFEL's full potential\u201d. For example, biologists are interested in exploring structures including protein\u2013RNA complexes, proteins that can take on many different shapes, and highly flexible functional regions that allow one molecule to interact with others. \u201cWe haven't figured out how to use XFELs to solve those problems,\u201d he says. The good news is that the LCLS-II and a flurry of other new machines will give researchers plenty of opportunities. Since 2011, for example, Japan has been operating its SACLA XFEL in Harima. Utilizing a specially built compact accelerator, SACLA is six times brighter and slightly higher in energy than the SLAC machine. In 2015, a consortium of European research institutions expects to finish construction of the \u20ac1.15-billion (US$1.6-billion) European XFEL in Hamburg, which will be just as bright as SACLA, and a little more energetic still. Fromme is particularly excited about the European machine's pulse rate. The LCLS's 120 pulses per second sound like a lot, she says. But the machine struggles to keep up with the nanocrystal injector, which spits out 10,000 drops per second. The European XFEL will produce 27,000 pulses per second. Not only will this allow researchers to avoid wasting more than 99% of the expensive, hard-to-make nanocrystals, but it will also allow the machine to accommodate many more users. \u201cYou could get millions of diffraction patterns in five or ten minutes, instead of five or ten hours,\u201d says Fromme. That would allow researchers to make movies of molecular motion; in a day, they could capture images of 10,000 time steps. Right now, she says, because each frame would require looking at thousands of nanocrystals to get a full structural determination, \u201cyou'd have to go all day for each time step\u201d. But the increase in pulse speed will work only if the system can capture and process the tsunami of data, says Fromme. The current top speed for detectors is about 3,000 diffraction patterns per second; that will have to be improved. And so will the computers, says Hajdu. \u201cCurrently, in a single experiment, one comes home with 100 terabytes of data,\u201d he says. With the European XFEL, which will produce about 2 billion pulses per day, it will be 1,000 times that. \u201cWe'll have to develop methods to reduce data on the fly to allow us to deal with it,\u201d he says. Eventually, researchers hope to be able to get diffraction patterns from individual molecules, allowing them to watch biomolecules moving and interacting in a completely natural setting, surrounded by water, instead of trapped in the artificial environment of a crystal. \u201cThat's my future vision for crystallography,\u201d says Fromme. \u201cGet away from being a coroner imaging dead molecules, and instead get molecular movies.\u201d What makes this hard is that an isolated molecule does not have a host of identical twins to help it to scatter the incoming photons, as happens in a crystal. The only way to compensate is to hit it with a lot more photons to produce a stronger diffraction pattern \u2014 a flux between 1,000 and 10,000 times brighter than the current LCLS. The European XFEL will be only about a factor of ten brighter, says Fromme. \u201cSo there are new challenges on the physics side to increase beam brightness.\u201d Still, the LCLS upgrade is intended to get close, boosting brightness by a factor of 1,000. Fromme sees the goal in sight: \u201cI'm optimistic that we could get there in ten years.\u201d \n                     Labs vie for X-ray source 2013-Jul-30 \n                   \n                     Femtosecond X-ray protein nanocrystallography 2011-Feb-02 \n                   \n                     Synching Europe's big science facilities 2010-Mar-30 \n                   \n                     X-ray free-electron lasers fire up 2009-Oct-07 \n                   \n                     Protein structures: Structures of desire 2009-May-06 \n                   \n                     Nature  special: Crystallography at 100 \n                   \n                     SLAC Linac Coherent Light Source \n                   \n                     European XFEL \n                   \n                     FLASH \n                   \n                     Japanese SACLA XFEL \n                   Reprints and Permissions"},
{"file_id": "505602a", "url": "https://www.nature.com/articles/505602a", "year": 2014, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "100 years of crystallography. In 1914, German scientist Max von Laue won the Nobel Prize in Physics for discovering how crystals can diffract X-rays: a phenomenon that led to the science of X-ray crystallography. Since then, researchers have used diffraction to work out the crystalline structures of increasingly complex molecules, from simple minerals to high-tech materials such as graphene and biological structures, including viruses. With improvements in technology, the pace of discovery has accelerated: tens of thousands of new structures are now imaged every year. The resolution of crystallographic images of proteins passed a critical threshold for discriminating single atoms in the 1990s, and newer X-ray sources promise images of challenging proteins that are hard or impossible to grow into large crystals. \n               Birth of an idea \n             Von Laue hit on the idea that when X-rays passed through a crystal, they would scatter off the atoms in the sample and then interfere with each other like waves passing through a breach in a shore wall. In some places, the waves would add to each other; in others, cancel each other out. The resulting diffraction pattern could be used to back-calculate the location of the atoms that scattered the original X-rays. Von Laue and his colleagues proved his theory in 1912 with a sample of copper sulphate. \n               Going up \n             The Worldwide Protein Data Bank has been collecting resolved structures of proteins since 1971, and now holds nearly 100,000 entries. Other databanks, including the Crystallography Open Database (COD), include structures of everything from minerals to metals and small biological molecules. The COD is now adding instructions into its database for how to print three-dimensional models of some structures. \n               Getting clearer \n             Better techniques for both imaging and interpreting data have allowed researchers see finer details in some structures and tackle ever more complicated molecules. \n               100 years of crystallography \n             \n               1913: Diamond \n             Diffraction image allowed researchers to confirm the tetrahedral structure of carbon atoms in this famous crystal. \n               1923: Hexamethylenetetramine \n             The first organic molecule to be imaged, chosen because of its simple cubic symmetry. It proved that molecules, not just atoms, can make up the repeating elements of a crystal. \n               1925: Quartz \n             The determination of the structure of silicate minerals was fundamental to the field of mineraology. \n               1952: DNA \n             Rosalind Franklin\u2019s X-ray image of DNA, known as photo 51, helped James Watson and Francis Crick to create their famous model of the double helix. An atomic-resolution image of the structure proposed in 1953 was not taken until 1980. \n               1958: Myoglobin \n             The irregular folds seen in the structure of the first imaged protein were a huge surprise. \n               1965: Lysozyme \n             The first enzyme to be imaged, sourced from hen egg whites. \n               1970: Synchrotron \n             A study of insect muscle at the German Electron Synchrotron (DESY) in Hamburg was the first to use X-rays generated by a synchrotron. The use of these machines caused a boom in crystallography studies. \n               1978: Tomato bushy stunt virus \n             First atomic-scale image of a complete virus: in this case, a plant virus. It revealed structural rules that were found to hold true in human pathogens a few years later. \n               1984: Quasicrystals \n             The first crystals were identified with atomic arrangements that do not repeat exactly, defying general wisdom about crystals. \n               2000: Ribosome \n             The molecular machine that assembles proteins from instructions encoded in DNA. \n               2009: X-ray free-electron laser \n             The Linac Coherent Light Source at the SLAC National Accelerator Laboratory in Menlo Park, California, went into operation, opening up a new world of imaging possibilities (see  page 604 ). \n               2013: HIV trimer \n             An X-ray crystallographic image of the hook that HIV uses to bind to human cells helped to resolve a debate about what this important protein looks like. \n               The future \n             The \u2018most wanted\u2019 list of proteins that remain to be imaged includes the massive spliceosome, which helps to organize and edit messenger RNA, and the even larger nuclear-pore complex, which serves as a nucleus\u2019s gatekeeper. These structures can contain hundreds of proteins, making them hard to crystallize or keep still for an image. One strategy is to crystallize bits of these structures and piece them together like a jigsaw; the use of X-ray free-electron lasers should also help. Reprints and Permissions"},
{"file_id": "505601a", "url": "https://www.nature.com/articles/505601a", "year": 2014, "authors": [], "parsed_as_year": "2006_or_before", "body": "From aiding drug design to analysing soil samples on Mars, crystallography has helped to propel much of modern science over the past 100 years. While skiing in the Alps over Easter in 1912, the German physicist Max von Laue told his colleagues about an innovative idea: he posited that X-rays passing through a crystal would reflect off atomic centres in the lattice and interfere with each other to create a diffraction pattern. His skiing partners were sceptical, thinking that the thermal jiggling of atoms in a crystal would ruin any pattern. By June, however, von Laue's idea had been proved right; and in 1914 he was awarded the Nobel Prize in Physics \u201cfor his discovery of the diffraction of X-rays by crystals\u201d, a technique that not only elucidated the behaviour of X-rays but also allowed chemists to deduce the placement of atoms in a crystal. Since then, X-ray crystallography has gone on to inform almost every branch of science by providing a means to understand the structure of complex molecules and materials. In this special issue,  Nature  celebrates the International Year of Crystallography by examining the impact of von Laue's method and its descendants. A graphic on  page 602  summarizes the highlights and evolution of the field over the past century. Looking forwards, a News Feature on  page 604  describes how a number of countries have invested in expensive X-ray free-electron lasers to crack some of the most difficult problems in crystallography. And a News & Views Forum on  page 620  compares these with synchrotron X-ray sources for applications in structural biology. Despite the enormous successes of crystallographic research, there are concerns about its future. In a Comment on  page 607 , physicist Paulo G. Radaelli calls for a governing body to steer the development of large international X-ray and neutron facilities. And a Careers Feature on  page 711  explores how jobs in the field are evolving in ways that demand diverse skills. Taking a historical perspective can point the way to future development. In a Comment on  page 609 , author Georgina Ferry reflects on how women have had leading roles in crystallography over the past century. \u201cThe features of this field that have attracted, retained and encouraged women,\u201d she writes, \u201chave lessons to offer for the future of women's progress in science more generally.\u201d \n                     Femtosecond X-ray protein nanocrystallography 2011-Feb-02 \n                   \n                     X-ray free-electron lasers fire up 2009-Oct-07 \n                   \n                     Protein structures: Structures of desire 2009-May-06 \n                   \n                     Nature  special: Crystallography at 100 \n                   \n                     The International Year of Crystallography \n                   Reprints and Permissions"},
{"file_id": "506020a", "url": "https://www.nature.com/articles/506020a", "year": 2014, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Winter sports face an uncertain future as the planet warms. Skiers, snowboarders and other athletes got a bit of a shock when they arrived in Sochi, Russia, for the 22nd Olympic Winter Games. On the way into town from the airport, competitors passed rows of palm trees that thrive in the breezes blowing off the Black Sea. Forty kilometres away, on the ski slopes of Rosa Khutor, Sochi organizers have spent a year stockpiling manufactured snow as a hedge against the region\u2019s mild climate. Meteorologists may scoff at the decision to hold a winter sporting event in a city where February averages a balmy 6\u2009\u00b0C and temperatures hover just above freezing in the nearby mountains. But Sochi and its massive snow-making operation offer a glimpse of the future of skiing and the pressures that will confront Olympic planners as the world heats up. \u201cWe know things are going to get warmer, and eventually, when you have temperatures above freezing more commonly than not, you\u2019re going to see less snow,\u201d says David Robinson, a hydro-climatologist who runs the Global Snow Lab at Rutgers University in Piscataway, New Jersey. In the Northern Hemisphere, the snow season has shrunk by about three weeks since the early 1970s (see \u2018Shorter winters\u2019), and snow cover is projected to decline substantially by the end of the century, according to a report released in September by the Intergovernmental Panel on Climate Change. There is considerable uncertainty in regional forecasts for individual skiing regions, but climate researchers say that models agree on broad patterns. \u201cBy the second half of the twenty-first century, the models suggest we\u2019ll be seeing really big changes in temperature and precipitation,\u201d says Martin Beniston, a climate physicist at the University of Geneva in Switzerland. Already, signs of an unwelcome thaw have appeared at even the highest elevations. This season, the Verbier 4 Vall\u00e9es resort in Switzerland eliminated two chair lifts after the lower edge of Tortin Glacier, at 2,800\u00a0metres elevation, receded by 40\u00a0metres in just 15\u00a0years. The outlook is not so gloomy everywhere, at least initially(see \u2018Snow down under\u2019). A warmer atmosphere can hold more moisture, so rising temperatures may actually increase snow at some high-elevation sites \u2014 such as the peaks of New Zealand and parts of the Swiss Alps \u2014 for several decades, until winter temperatures inch above freezing (see \u2018Trouble in the Alps\u2019). In fact, average snowfall over the past decade at the Verbier resort has outpaced that in each of the previous three decades. But the area has also had to deal with more variability, warmer summers and a spate of hit-or-miss winters. \u201cThe extremes are much higher or much deeper,\u201d says Eric Balet, chief executive of T\u00e9l\u00e9verbier, the company that owns 4\u00a0Vall\u00e9es. That introduces an unwelcome element of unpredictability for resort managers. Skiing areas at low elevations face the worst forecasts. The US states of Connecticut and Massachusetts are home to a combined 17\u00a0skiing areas, and a study suggests that by 2039, none will sustain a viable skiing season \u2014 defined by industry as 100\u00a0days or more \u2014 even with artificial snow-making ( J.\u00a0Dawson and D.\u00a0Scott  Tourism Mgmt    35,  244\u2013254; 2013 ). But at least 94% of the 18\u00a0resorts in the more northerly state of Vermont are projected to be viable until 2070 or beyond. A big difference is altitude: all the resorts in Connecticut and Massachusetts have a peak elevation below 750\u00a0metres, whereas 16 of those in Vermont exceed that, many by hundreds of metres. \n               Quality and quantity \n             The prospect of losing small skiing areas worries Auden Schendler, vice-president for sustainability at Aspen Skiing Company, which runs the Aspen and Snowmass resorts high in central Colorado (see \u2018Rocky slopes\u2019). \u201cWe call those feeder resorts,\u201d he says, because their lower prices and gentler slopes attract new skiers to the sport. \u201cIt doesn\u2019t serve us for other resorts to go out of business.\u201d And small mountains can produce big stars. The 2010 Olympic downhill champion, Lindsey Vonn, started skiing at Buck Hill, a 364-metre mountain in Burnsville, Minnesota; reigning World Cup slalom champion Mikaela Shiffrin trained as a child at New Hampshire\u2019s Storrs Hill Ski Area, where the peak elevation is just 177\u00a0metres. It is not only the quantity of snow that is crucial for winter sports such as skiing and snowboarding. Quality matters too, says Anne Nolin, a snow hydrologist at Oregon State University in Corvallis. A warmer, moister atmosphere will produce heavier, wetter snow, not the dry, fluffy \u2018champagne powder\u2019 prized by many recreational skiers. Artificial snow created with snow-making cannons is often icy, perfect for laying the base of lightning-fast competition runs but less favourable for the average skier. And temperatures that skirt the freezing mark increase the risk that precipitation will fall as rain, not snow, and will raise the density of the snowpack. \u201cThese just aren\u2019t the kind of conditions that people go skiing for,\u201d says Nolin. It is not clear what the changing face of winter portends for future Olympic Games (see \u2018The dwindling Olympics\u2019). The competition has already been shaped by the vagaries of weather and climate, beginning with the decision decades ago to move figure skating, speed skating, ice hockey and curling indoors, says Daniel Scott, a geographer at the University of Waterloo in Canada. His research suggests that the pool of locations capable of hosting the games will shrink as the climate warms \u2014 and the colder mountain cities that may be the best fit may not have the infrastructure to handle a massive influx of athletes, spectators and organizers. That will force some difficult decisions, he says. \u201cIt\u2019s an interesting dilemma the International Olympic Committee will be caught in.\u201d \n                     Snow survey hopes for avalanche of data 2012-Nov-13 \n                   \n                     Arctic snow cover shows sharp decline 2012-Oct-31 \n                   \n                     The end for small glaciers 2011-Jan-08 \n                   \n                     Alpine snow taken down a notch 2008-Jun-18 \n                   \n                     Skiers take to man-made slopes 2006-Feb-10 \n                   \n                     Sochi 2014 \n                   \n                     Rutgers University Global Snow Lab \n                   \n                     Martin Beniston \n                   \n                     Anne Nolin \n                   \n                     Daniel Scott \n                   Reprints and Permissions"},
{"file_id": "506150a", "url": "https://www.nature.com/articles/506150a", "year": 2014, "authors": [{"name": "Regina Nuzzo"}], "parsed_as_year": "2006_or_before", "body": "P  values, the 'gold standard' of statistical validity, are not as reliable as many scientists assume. For a brief moment in 2010, Matt Motyl was on the brink of scientific glory: he had discovered that extremists quite literally see the world in black and white. The results were \u201cplain as day\u201d, recalls Motyl, a psychology PhD student at the University of Virginia in Charlottesville. Data from a study of nearly 2,000 people seemed to show that political moderates saw shades of grey more accurately than did either left-wing or right-wing extremists. \u201cThe hypothesis was sexy,\u201d he says, \u201cand the data provided clear support.\u201d The  P  value, a common index for the strength of evidence, was 0.01 \u2014 usually interpreted as 'very significant'. Publication in a high-impact journal seemed within Motyl's grasp. But then reality intervened. Sensitive to controversies over reproducibility, Motyl and his adviser, Brian Nosek, decided to replicate the study. With extra data, the  P  value came out as 0.59 \u2014 not even close to the conventional level of significance, 0.05. The effect had disappeared, and with it, Motyl's dreams of youthful fame 1 . It turned out that the problem was not in the data or in Motyl's analyses. It lay in the surprisingly slippery nature of the  P  value, which is neither as reliable nor as objective as most scientists assume. \u201c P  values are not doing their job, because they can't,\u201d says Stephen Ziliak, an economist at Roosevelt University in Chicago, Illinois, and a frequent critic of the way statistics are used. For many scientists, this is especially worrying in light of the reproducibility concerns. In 2005, epidemiologist John Ioannidis of Stanford University in California suggested that most published findings are false 2 ; since then, a string of high-profile replication problems has forced scientists to rethink how they evaluate results. At the same time, statisticians are looking for better ways of thinking about data, to help scientists to avoid missing important information or acting on false alarms. \u201cChange your statistical philosophy and all of a sudden different things become important,\u201d says Steven Goodman, a physician and statistician at Stanford. \u201cThen 'laws' handed down from God are no longer handed down from God. They're actually handed down to us by ourselves, through the methodology we adopt.\u201d \n               Out of context \n             P  values have always had critics. In their almost nine decades of existence, they have been likened to mosquitoes (annoying and impossible to swat away), the emperor's new clothes (fraught with obvious problems that everyone ignores) and the tool of a \u201csterile intellectual rake\u201d who ravishes science but leaves it with no progeny 3 . One researcher suggested rechristening the methodology \u201cstatistical hypothesis inference testing\u201d 3 , presumably for the acronym it would yield. The irony is that when UK statistician Ronald Fisher introduced the  P  value in the 1920s, he did not mean it to be a definitive test. He intended it simply as an informal way to judge whether evidence was significant in the old-fashioned sense: worthy of a second look. The idea was to run an experiment, then see if the results were consistent with what random chance might produce. Researchers would first set up a 'null hypothesis' that they wanted to disprove, such as there being no correlation or no difference between two groups. Next, they would play the devil's advocate and, assuming that this null hypothesis was in fact true, calculate the chances of getting results at least as extreme as what was actually observed. This probability was the  P  value. The smaller it was, suggested Fisher, the greater the likelihood that the straw-man null hypothesis was false. For all the  P  value's apparent precision, Fisher intended it to be just one part of a fluid, non-numerical process that blended data and background knowledge to lead to scientific conclusions. But it soon got swept into a movement to make evidence-based decision-making as rigorous and objective as possible. This movement was spearheaded in the late 1920s by Fisher's bitter rivals, Polish mathematician Jerzy Neyman and UK statistician Egon Pearson, who introduced an alternative framework for data analysis that included statistical power, false positives, false negatives and many other concepts now familiar from introductory statistics classes. They pointedly left out the  P  value. But while the rivals feuded \u2014 Neyman called some of Fisher's work mathematically \u201cworse than useless\u201d; Fisher called Neyman's approach \u201cchildish\u201d and \u201chorrifying [for] intellectual freedom in the west\u201d \u2014 other researchers lost patience and began to write statistics manuals for working scientists. And because many of the authors were non-statisticians without a thorough understanding of either approach, they created a hybrid system that crammed Fisher's easy-to-calculate  P  value into Neyman and Pearson's reassuringly rigorous rule-based system. This is when a  P  value of 0.05 became enshrined as 'statistically significant', for example. \u201cThe  P  value was never meant to be used the way it's used today,\u201d says Goodman. \n               What does it all mean? \n             One result is an abundance of confusion about what the  P  value means 4 . Consider Motyl's study about political extremists. Most scientists would look at his original  P  value of 0.01 and say that there was just a 1% chance of his result being a false alarm. But they would be wrong. The  P  value cannot say this: all it can do is summarize the data assuming a specific null hypothesis. It cannot work backwards and make statements about the underlying reality. That requires another piece of information: the odds that a real effect was there in the first place. To ignore this would be like waking up with a headache and concluding that you have a rare brain tumour \u2014 possible, but so unlikely that it requires a lot more evidence to supersede an everyday explanation such as an allergic reaction. The more implausible the hypothesis \u2014 telepathy, aliens, homeopathy \u2014 the greater the chance that an exciting finding is a false alarm, no matter what the  P  value is. These are sticky concepts, but some statisticians have tried to provide general rule-of-thumb conversions (see 'Probable cause'). According to one widely used calculation 5 , a  P  value of 0.01 corresponds to a false-alarm probability of at least 11%, depending on the underlying probability that there is a true effect; a  P  value of 0.05 raises that chance to at least 29%. So Motyl's finding had a greater than one in ten chance of being a false alarm. Likewise, the probability of replicating his original result was not 99%, as most would assume, but something closer to 73% \u2014 or only 50%, if he wanted another 'very significant' result 6 , 7 . In other words, his inability to replicate the result was about as surprising as if he had called heads on a coin toss and it had come up tails. Critics also bemoan the way that  P  values can encourage muddled thinking. A prime example is their tendency to deflect attention from the actual size of an effect. Last year, for example, a study of more than 19,000 people showed 8  that those who meet their spouses online are less likely to divorce ( p  < 0.002) and more likely to have high marital satisfaction ( p  < 0.001) than those who meet offline (see  Nature   http://doi.org/rcg ; 2013 ). That might have sounded impressive, but the effects were actually tiny: meeting online nudged the divorce rate from 7.67% down to 5.96%, and barely budged happiness from 5.48 to 5.64 on a 7-point scale. To pounce on tiny  P  values and ignore the larger question is to fall prey to the \u201cseductive certainty of significance\u201d, says Geoff Cumming, an emeritus psychologist at La Trobe University in Melbourne, Australia. But significance is no indicator of practical relevance, he says: \u201cWe should be asking, 'How much of an effect is there?', not 'Is there an effect?'\u201d Perhaps the worst fallacy is the kind of self-deception for which psychologist Uri Simonsohn of the University of Pennsylvania and his colleagues have popularized the term  P -hacking; it is also known as data-dredging, snooping, fishing, significance-chasing and double-dipping. \u201c P -hacking,\u201d says Simonsohn, \u201cis trying multiple things until you get the desired result\u201d \u2014 even unconsciously. It may be the first statistical term to rate a definition in the online Urban Dictionary, where the usage examples are telling: \u201cThat finding seems to have been obtained through  p -hacking, the authors dropped one of the conditions so that the overall  p -value would be less than .05\u201d, and \u201cShe is a  p -hacker, she always monitors data while it is being collected.\u201d  The  P  value was never meant to be used the way it's used today.  Such practices have the effect of turning discoveries from exploratory studies \u2014 which should be treated with scepticism \u2014 into what look like sound confirmations but vanish on replication. Simonsohn's simulations have shown 9  that changes in a few data-analysis decisions can increase the false-positive rate in a single study to 60%.  P -hacking is especially likely, he says, in today's environment of studies that chase small effects hidden in noisy data. It is tough to pin down how widespread the problem is, but Simonsohn has the sense that it is serious. In an analysis 10 , he found evidence that many published psychology papers report  P  values that cluster suspiciously around 0.05, just as would be expected if researchers fished for significant  P  values until they found one. \n               Numbers game \n             Despite the criticisms, reform has been slow. \u201cThe basic framework of statistics has been virtually unchanged since Fisher, Neyman and Pearson introduced it,\u201d says Goodman. John Campbell, a psychologist now at the University of Minnesota in Minneapolis, bemoaned the issue in 1982, when he was editor of the  Journal of Applied Psychology : \u201cIt is almost impossible to drag authors away from their  p -values, and the more zeroes after the decimal point, the harder people cling to them\u201d 11 . In 1989, when Kenneth Rothman of Boston University in Massachusetts started the journal  Epidemiology , he did his best to discourage  P  values in its pages. But he left the journal in 2001, and  P  values have since made a resurgence. Ioannidis is currently mining the PubMed database for insights into how authors across many fields are using  P  values and other statistical evidence. \u201cA cursory look at a sample of recently published papers,\u201d he says, \u201cis convincing that  P  values are still very, very popular.\u201d Any reform would need to sweep through an entrenched culture. It would have to change how statistics is taught, how data analysis is done and how results are reported and interpreted. But at least researchers are admitting that they have a problem, says Goodman. \u201cThe wake-up call is that so many of our published findings are not true.\u201d Work by researchers such as Ioannidis shows the link between theoretical statistical complaints and actual difficulties, says Goodman. \u201cThe problems that statisticians have predicted are exactly what we're now seeing. We just don't yet have all the fixes.\u201d Statisticians have pointed to a number of measures that might help. To avoid the trap of thinking about results as significant or not significant, for example, Cumming thinks that researchers should always report effect sizes and confidence intervals. These convey what a  P  value does not: the magnitude and relative importance of an effect. Many statisticians also advocate replacing the  P  value with methods that take advantage of Bayes' rule: an eighteenth-century theorem that describes how to think about probability as the plausibility of an outcome, rather than as the potential frequency of that outcome. This entails a certain subjectivity \u2014 something that the statistical pioneers were trying to avoid. But the Bayesian framework makes it comparatively easy for observers to incorporate what they know about the world into their conclusions, and to calculate how probabilities change as new evidence arises. Others argue for a more ecumenical approach, encouraging researchers to try multiple methods on the same data set. Stephen Senn, a statistician at the Centre for Public Health Research in Luxembourg City, likens this to using a floor-cleaning robot that cannot find its own way out of a corner: any data-analysis method will eventually hit a wall, and some common sense will be needed to get the process moving again. If the various methods come up with different answers, he says, \u201cthat's a suggestion to be more creative and try to find out why\u201d, which should lead to a better understanding of the underlying reality. Simonsohn argues that one of the strongest protections for scientists is to admit everything. He encourages authors to brand their papers ' P -certified, not  P -hacked' by including the words: \u201cWe report how we determined our sample size, all data exclusions (if any), all manipulations and all measures in the study.\u201d This disclosure will, he hopes, discourage  P -hacking, or at least alert readers to any shenanigans and allow them to judge accordingly. A related idea that is garnering attention is two-stage analysis, or 'preregistered replication', says political scientist and statistician Andrew Gelman of Columbia University in New York City. In this approach, exploratory and confirmatory analyses are approached differently and clearly labelled. Instead of doing four separate small studies and reporting the results in one paper, for instance, researchers would first do two small exploratory studies and gather potentially interesting findings without worrying too much about false alarms. Then, on the basis of these results, the authors would decide exactly how they planned to confirm the findings, and would publicly preregister their intentions in a database such as the Open Science Framework ( https://osf.io ). They would then conduct the replication studies and publish the results alongside those of the exploratory studies. This approach allows for freedom and flexibility in analyses, says Gelman, while providing enough rigour to reduce the number of false alarms being published. More broadly, researchers need to realize the limits of conventional statistics, Goodman says. They should instead bring into their analysis elements of scientific judgement about the plausibility of a hypothesis and study limitations that are normally banished to the discussion section: results of identical or similar experiments, proposed mechanisms, clinical knowledge and so on. Statistician Richard Royall of Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland, said that there are three questions a scientist might want to ask after a study: 'What is the evidence?' 'What should I believe?' and 'What should I do?' One method cannot answer all these questions, Goodman says: \u201cThe numbers are where the scientific discussion should start, not end.\u201d \n                 See Editorial \n                 page 131 \n               \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Number crunch 2014-Feb-12 \n                   \n                     Policy: NIH plans to enhance reproducibility 2014-Jan-27 \n                   \n                     Weak statistical standards implicated in scientific irreproducibility 2013-Nov-11 \n                   \n                     Uncertainty on trial 2013-Oct-02 \n                   \n                     Matters of significance 2013-Aug-29 \n                   \n                     Announcement: Reducing our irreproducibility 2013-Apr-24 \n                   \n                     Replication studies: Bad copy 2012-May-16 \n                   \n                     Blog post: Let's give statistics the attention it deserves in biological research \n                   \n                     Blog post: Statistics is the sexy in science \n                   \n                     Nature  special: Challenges in irreproducible research \n                   \n                     Psychological Science  tutorial on alternatives to the  P  value \n                   \n                     The BUGS (Bayesian inference Using Gibbs Sampling) Project \n                   \n                     Bayesian Cognitive Modelling: A Practical Course \n                   Reprints and Permissions"},
{"file_id": "506284a", "url": "https://www.nature.com/articles/506284a", "year": 2014, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The US Supreme Court years ago ruled against applying the death penalty to people unable to understand the legal process. Now it must grapple with the science of how intellectual disability is measured. Freddie Lee Hall loved to gamble, although he usually lost. Winning was better: then he gladly gave the money back to the friends he'd won it from, along with all the wages he earned picking fruit in rural Florida. His friends praised him for this. It made him feel good. And Hall needed to feel good \u2014 as court documents make abundantly clear. As a child growing up in the impoverished town of Webster, Florida, he had struggled to keep up with 16 brothers and sisters, who were much smarter than he was. If he failed to understand something, his mother beat him, once while he was tied up in a bag strung over a fire. He stuttered, never learned to read and feared the dark. He was unable to live alone. \u201cEven though he was full grown, mentally he was a child,\u201d his sister Diana told the court. \u201cI had hoped to protect Freddie Lee from the outside world.\u201d But the outside world found him. In 1978, Hall and his friend Mack Ruffin decided to rob a convenience store. They needed a car, so they forced 21-year-old Karol Hurst, who was pregnant, to drive into the woods, where they raped and killed her. Later, one of the pair also shot and killed a sheriff's deputy. When the two men were caught, tried and convicted of murder, the court decided that Hall was the likely ringleader. Ruffin was eventually sentenced to life in prison; Hall was sentenced to death. Next month, after 35 years of failed appeals to have that death sentence commuted to life imprisonment, Hall will have his case heard before the US Supreme Court. His guilt is not in question: the issue is Florida's use of IQ test scores in sentencing him to death. A 2002 Supreme Court ruling already bars the execution of people with an intellectual disability. But Hall's lawyers are expected to argue that many US states assess mental ability using outdated measures that take little or no account of current scientific research on the subject. Florida, in particular, is one of ten states in which anyone with an IQ score of above a certain number, usually 70, is automatically considered to be intellectually competent and is therefore eligible for the death penalty. Psychologists contend that IQ tests are not precise enough to draw such a 'bright line'. Hall's IQ scores range from 60 to 80, and many states would not consider him for the death penalty, say several specialists who have reviewed his case. Documents prepared for one of his trials quote clinicians saying that Hall \u201cis mentally retarded, has always been mentally retarded, and will be mentally retarded for the remainder of his life\u201d. There is a great deal resting on how the Supreme Court decides this case. According to one estimate, as many as 20% of the more than 3,100 people on death row in the United States may have some level of intellectual disability (R. Coyne and L. Entzeroth  Geo. J. Fighting Pov.   3 , 40; 1996 ). So a decision in Hall's favour could lead to hundreds of appeals, says Nancy Haydt, an attorney in Santa Barbara, California, who is compiling a database of pleas relating to intellectual disabilities in death-penalty cases. But many mental-health specialists hope that the court will rule more broadly. In briefs filed in the case in December, professional organizations, including the American Psychological Association (APA) and the American Association on Intellectual and Developmental Disabilities (AAIDD), advocated for the court to set a new legal standard that reflects current research on intelligence. IQ tests were never designed to assess the criminal mind, psychologists argue. They say that the modern definition of intelligence \u2014 which includes the ability to learn and solve problems, relate to other people and function in society \u2014 is much more relevant. \n               Cruel and unusual punishment \n             The confusion over the legal role of IQ began in 2002, when a Virginia man, Daryl Atkins, went before the Supreme Court to appeal his death sentence. Atkins and an accomplice had been arrested in 1996 for murdering a man. There were no witnesses, and Atkins's accomplice made a deal with prosecutors: in exchange for a life sentence, he testified that Atkins had held the gun. Atkins, who had an IQ of 59, smiled and doodled through his trial. The Supreme Court ruled that it was \u201ccruel and unusual\u201d to execute a person who could not understand the consequences of his actions or the legal proceedings. It sent the case back to the Virginia court system, which changed Atkins's sentence to life imprisonment. The Supreme Court also ruled that death is not a suitable punishment for anyone who has been diagnosed as \u201cmentally retarded\u201d by standards such as those of the American Association on Mental Retardation (now the AAIDD). This organization's definition has three criteria: an IQ score two standard deviations below average (about 70); difficulty adapting and functioning in society; and evidence that the disability began before age 18. However, the court left it up to individual states to decide how to implement the Atkins criteria. And the paths many have chosen have raised issues with all three (see 'Bright lines'). Looking at the IQ standard, for example, \u201cthe states took it as 'we can define intellectual disability however we want',\u201d says Harry Simon, an assistant federal defender in Sacramento, California. One result was Florida's bright line: an IQ score of above 70 would be enough to end a defendant's plea. Some states are even stricter: in Oklahoma, a single score above 75 from any test taken in a defendant's life automatically qualifies him or her for capital punishment. Kent Scheidegger, legal director of the Criminal Justice Legal Foundation, a non-profit organization in Sacramento that supports the death penalty, says that the problem is the Atkins decision itself. \u201cIt created a rule of law that we have to crisply divide people in two categories \u2014 retarded and not retarded \u2014 and treat them differently,\u201d he says. \u201cBecause there isn't a clear line in reality, that is inherently problematic.\u201d Each state now has to find some way to comply with that, Scheidegger says. The bright line rule, if nothing else, applies uniformly to all defendants, avoiding a situation whereby the outcome depends on which side has the better expert psychologist. The Florida Attorney General's office declined to comment for this article, citing the pending Supreme Court case, but its brief to the court argues that a ruling in Hall's favour would ensure that \u201cstates are constitutionally bound to vague, constantly evolving \u2014 and sometimes contradictory \u2014 diagnostic criteria established by organizations committed to expanding Atkins's reach\u201d. Yet psychologist Keith Widaman of the University of California, Davis, says that clinicians generally oppose a bright-line test, not least because IQ tests have an error margin of roughly ten points (see \u2018Drawing the line\u2019). Besides, most defendants have taken several IQ tests and achieved a range of scores, which can vary widely depending on the type of test and the version used. Widaman points out that one of the most commonly used IQ tests, the Wechsler Adult Intelligence Scale (WAIS), has only a few questions aimed at assessing people at the lower boundary of the normal intelligence range: right around 70. What is more, the tests themselves have evolved over time. Conventionally, they focused on 'crystallized' intelligence, which includes factors such as a person's knowledge and ability to comprehend, say, a text. But, especially during the past decade, Widaman says, test designers have been putting an increased emphasis on 'fluid' intelligence: how well an individual can absorb new information, make judgements and reason through a complex problem. Interpreting test scores is complicated even further by a phenomenon known as the Flynn effect: the average IQ score on a given test rises by roughly three points per decade across a population. No one is sure why; proposed explanations range from better nutrition and prenatal care to increased standardized testing in schools. Every ten years or so, psychologists must therefore renormalize IQ tests such as WAIS so that the population's average IQ remains at 100. This means that a death-row prisoner such as Kevin Green, who in 1991 scored 71 on an IQ test last normalized in 1972, might have scored only 65 on a test normalized to the year he took it. After Green was convicted and sentenced to death in 2000, his lawyers appealed, arguing that the court should correct for the Flynn effect. Nevertheless, Green's score exceeded Virginia's bright line of 70, and he was put to death in 2008. Whereas  Hall  v.  Florida  has focused on the standard error of measurement in IQ tests, some psychologists would like laws to reflect a broader understanding of intelligence. \u201cLooking at it as a single number is such an outmoded concept, with no scientific validity,\u201d says Stephen Greenspan, a forensic psychologist in Littleton, Colorado, who consults on Atkins cases. \n               No limits \n             This is why the latest version of the  Diagnostic and Statistical Manual of Mental Disorders  ( DSM-5 ), used by almost all US hospitals and health providers, deliberately avoided setting any IQ number as a limit for diagnosing intellectual disability, says James Harris, a psychiatrist at the Johns Hopkins University in Baltimore, Maryland, and the lead author of the  DSM-5 's chapter on the subject. IQ tests don't have much to say about a defendant's ability to function in society, he says. \u201cThey're not looking at what happens when someone says, 'I'm going to give you a reward if you go with me to rob the bank; it'll be a lot of fun and I'll even let you hold the gun.'\u201d But, he says, that kind of situation is likely to come up. This is the realm of the second Atkins criterion, 'adaptive functioning', which is given equal weight to IQ scores by the  DSM-5 . It involves factors ranging from empathy and social skills to impulse control and judgement, says Harris \u2014 none of which bear much relation to standard IQ scores, particularly when brain damage is involved. Take the case of Michael Zack, who has been on death row in Florida since 1997 for murdering a woman he met at a bar. Over the course of several trials, his lawyers and a psychologist argued that Zack had brain damage caused by his mother's heavy drinking during pregnancy. Although fetal alcohol spectrum disorder does not necessarily lower standard IQ scores, it severely damages the midbrain, which is involved in the ability to learn from experience and to anticipate the consequences of one's actions. This could explain why Zack scored 79 on an IQ test yet was diagnosed as having the emotional maturity of a ten-year-old. Psychologists assess adaptive behaviour using standardized tests that ask questions about real-life function, such as whether a person can tie their shoe-laces or write a cheque. These questionnaires are typically given to family members and close acquaintances rather than the individuals themselves, because people tend to exaggerate their own abilities. But the tests are frequently misused in legal settings, says William Hennis, an attorney with Florida's Commission on Capital Cases in Fort Lauderdale. They are often given to prison guards, who say that the defendant is getting along perfectly well in maximum security. \u201cIn a situation where you get all your meals provided and are under surveillance and your entire life is organized to the minute, that's not an environment where you can do an adaptive functioning [assessment] that makes sense,\u201d Hennis says. To get a fair determination, he maintains, the test needs to be given to people who knew the defendant before he or she was in prison. Some states have developed their own ways of measuring mental eligibility. Texas, which executes more prisoners than any other state, uses 'Brise\u00f1o factors': a set of seven behavioural criteria formulated by the Texas Court of Criminal Appeals in 2004. The factors include whether family and acquaintances think that the defendant is mentally disabled, and his or her ability to answer direct questions, lie and plan ahead. The judges in the case wrote that they were following AAIDD guidelines, and described the seven factors as an attempt to be specific about \u201cadaptive behaviour criteria [that] are exceedingly subjective\u201d. But the factors have become a lightning rod for critics. \u201cThey're criteria invented out of thin air by judges that have no validation in science,\u201d says Simon. Such non-professional assessments can miss an important reality, he says: many disabled defendants hide behind a 'cloak of competence' by copying the actions of others or collecting books they are unable to read in order to appear literate. \u201cA lot of people think they know what mental retardation looks like, but it doesn't look like anything,\u201d says Marc Tass\u00e9, a psychologist at Ohio State University in Columbus. Later this year, the AAIDD will release the first adaptive-behaviour test specifically designed to diagnose mild intellectual disability in young people, called the Diagnostic Adaptive Behavior Scale (DABS). \u201cThese death-penalty cases made us realize the importance of designing a test around the cut-off,\u201d says Tass\u00e9, who is heading the project. One of DABS's novel contributions will be questions about gullibility, which is a hallmark of intellectual disability. Criminals with an intellectual disability often have an accomplice, who might have led them into the crime, says Tass\u00e9. \n               Environmental damage \n             Often, the most difficult of the Atkins criteria for defence lawyers to prove is the third: has a defendant been intellectually disabled since before the age of 18? Clues can sometimes be found by looking at a defendant's early environment. Childhood neglect and abuse, for instance, can lower IQ substantially. Court documents such as Hall's brim with tales of abuse by parents and others, damaging the children's brains with blows to the head and creating traumatic memories. But records are often fragmentary or missing, forcing defence lawyers to rely on families' and teachers' subjective memories. Hennis once tried to find childhood records on a client, Dean Kilgore, who had grown up as the son of poor black sharecroppers in 1950s Mississippi. Only after days of searching did Hennis turn up 50-year-old juvenile-conviction records revealing that Kilgore had been described as \u201cbrain damaged\u201d by others at his work camp. Psychologists hoping for better courtroom science are encouraged by the Supreme Court's decision to hear  Hall  v.  Florida . Conceivably, the court could rule that states should abide by the  DSM-5 's diagnostic criteria, although Greenspan admits that such a broad ruling is unlikely. It is more probable that the court will decide that states must account for standard errors in IQ scores, or emphasize diagnoses by clinical psychologists. Florida contends that its method for assessing intellectual abilities meets the standards set out in Atkins and that a ruling in Hall's favour would unleash an unwarranted flood of appeals. As the state Attorney General's office wrote in its brief to the Supreme Court, \u201cfuture litigation would be endless\u201d. But advocates for some death-row prisoners are confident. \u201cThe smart better's money is that it looks good for Hall,\u201d says Lee Kovarsky, an attorney at the University of Maryland in Baltimore, who represented Marvin Wilson, a convicted killer with an IQ of 61 who was executed in Texas in 2012. In recent cases involving science, the Supreme Court has been very open to expert opinions \u2014 and there are plenty to choose from here. Among them are the briefs filed by the AAIDD and APA. Even a group of dozens of former judges and law-enforcement officials filed a brief in Hall's favour, encouraging the court to account for standard error of measurement in IQ assessments. \u201cI think it's a very powerful statement about the dilemma that we're in,\u201d Harris says of the briefs. \u201cWe cannot reduce the life of a human being to a single number.\u201d See Editorial  page 265 \n                     Intelligent testing 2014-Feb-19 \n                   \n                     Science in court: Arrested development 2012-Apr-18 \n                   \n                     Science in court: The fine print 2010-Mar-17 \n                   \n                     Science in court: DNA's identity crisis 2010-Mar-17 \n                   \n                     Science in court: Head case 2010-Mar-17 \n                   \n                     Nature  special: Science in court \n                   \n                     Hall  v.  Florida  court documents \n                   \n                     American Association on Intellectual and Developmental Disabilities \n                   \n                     Death Penalty Information Center \n                   Reprints and Permissions"},
{"file_id": "506024a", "url": "https://www.nature.com/articles/506024a", "year": 2014, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "A hard-won political victory for primate research is at risk of unravelling in pockets of Europe. The worst moment in neuroscientist Andreas Kreiter's 16-year struggle to defend his research came when his wife arrived home after the birth of their second child. Waiting for her was an envelope containing a death threat against their three-year-old. Kreiter, who uses macaques in his studies of the brain at the University of Bremen in Germany, is a veteran of the fierce and periodically violent tactics of animal-rights activists. When protests peaked in the late 1990s, he lived under police protection \u2014 but he still continued his research. \u201cI had thought very carefully before deciding to work with primates,\u201d he says. \u201cAnd I believe it is necessary if we are to understand the human brain.\u201d Later Kreiter found himself facing an unfamiliar foe: local authorities looking to restrict primate research in their city. In 2008, Bremen officials declined to renew Kreiter's licence to work with macaques. The fate of his research has been in legal limbo ever since. Kreiter's courtroom conflicts put him in good company. Across Europe, a particularly volatile patchwork of emerging local regulations threatens to distort the spirit of a recent European Union (EU) directive that explicitly allows research on non-human primates. Although some researchers say they have never felt so secure, others are facing new obstacles as activists change tack, from bullying researchers to putting pressure on regional policy-makers. The problems continue even as the EU is pushing for the translation of basic research into therapies \u2014 a transition that often requires the testing of experimental therapies in primates. And opportunities for translational research are growing thanks to recent technological breakthroughs. However, restrictions on primate experiments could hinder their development. Some European researchers are shifting their strategies, too, by talking more openly about their work with primates. But other scientists have simply stopped using monkeys altogether \u2014 or side-stepped the European quagmire by setting up controversial collaborations in other countries, particularly in Asia. \u201cPrimate researchers should always expect to be under pressure, because we are handling a valuable and sensitive resource,\u201d says Roger Lemon of University College London, UK, who hopes his work on how the brain controls fine hand movements might lead to therapies for recovering function after a stroke. \u201cBut it's a sad irony that key developments may be transferring to countries that don't have the high level of animal welfare we have here.\u201d \n               Stabilizing step \n             The pressures on primate researchers have taken many forms. In the United States, for example, commercial airlines have effectively ceased all primate shipments by air within the country, making it difficult for researchers to transport animals. Many airlines in Europe have taken similar steps, but Air France continues to provide service. Not long ago, the EU seemed to take a step towards stabilizing the environment for primate research. In September 2010, after more than a decade of anguished public debate, the EU adopted a directive governing the use of animals for research purposes. With its careful balance of animal-welfare and research needs, the directive seemed destined to ease tensions. Among other things, it established minimum welfare requirements for all animals, laid out definitions of pain intensity, and banned most research on great apes. It also included a hard-won clause \u2014 added at the last minute after intense lobbying by the biomedical community \u2014 explicitly permitting basic research on non-human primates, provided the work could not be carried out in any other species. EU member states were required to anchor the directive into national legislation by 1 January 2013. And they were forbidden to 'gold-plate' the regulation by making national law stricter than EU law. But animal-rights activists have continued their fight. They have honed their activities for greater media attention and have delayed implementation of the directive in several countries. Animal-rights organizations now focus on policy-makers rather than scientists, says Robert Molenaar, campaign manager for the Coalition Against Animal Experiments (ADC), which operates in the Netherlands and Belgium. The ADC is concentrating first on monkey research in universities, he says, because it is an easy way to get press coverage and influence political opinion. The ADC is also forging international links and works closely with a sister organization in the United Kingdom, the Anti Vivisection Coalition (AVC), headed by Luke Steele. Steele spent nine months in prison after being convicted in 2012 of harassing staff at Harlan Laboratories, a contract research company in Blackthorn, UK. The jail time was interesting, he says: he used it to reflect on strategies. \u201cResearchers themselves tend to be traditionalists who are not open to alternatives,\u201d he says. \u201cI realised we need to go for policy-makers.\u201d The AVC and the ADC were the main drivers of the Stop Vivisection Initiative, a petition calling for the EU animal-research directive to be abrogated and animal research to be banned altogether. The petition, launched in November 2012, collected more than a million signatures across the EU within a year. The signatures are now being verified; if they pass, the initiative will be granted hearings at the European Commission and the European Parliament. \u201cThis will reopen the debate \u2014 something we'd all rather do without, given the enormous effort that the commission, scientists and animal-welfare groups invested in achieving the compromise,\u201d says Stefan Treue, director of the German Primate Center in G\u00f6ttingen and an adviser to the European Commission on the 2010 directive. Treue doubts that the Stop Vivisection campaign will change European legislation \u2014 political demand for new therapies is too strong, he says. But, like many of his colleagues, he says that researchers working with monkeys should abandon their conventional tactic of keeping quiet, which cedes ground to the activists. Two months after the directive was approved, Treue helped to launch the Basel Declaration (see  Nature   468 , 742; 2010 ), which commits its signatories \u2014 so far more than 2,500 \u2014 to be open about their animal research and to engage in public dialogue. The declaration prompted a sea change, and many initiatives are emerging in its wake. For example, the Swiss Primate Competence Center for Research was launched last year in Fribourg to provide a training centre for scientists and technicians wanting to work with primates, and an educational one-stop shop for the public. Individual scientists are also speaking up on their websites. Neuroscientist Pieter Roelfsema at the Netherlands Institute for Neuroscience in Amsterdam, who works with monkeys, says that so far activists have not targeted researchers in his lab. But he fears this may soon change. Last spring, minority parties in the Dutch parliament \u2014 including the Dutch Party for the Animals \u2014 posed formal questions about whether research using monkeys is necessary, if it could be replaced by alternative methods, and if the number of government-funded research institutes using monkeys could be reduced. With these developments in mind, Roelfsema is planning a public-information webpage about the value of primate research, modelled on that of Nikos Logothetis, a director at the Max Planck Institute for Biological Cybernetics in T\u00fcbingen, Germany. Logothetis's site, which has thousands of visitors a week, emerged from a public-relations debacle. In 2009, he invited a team of investigative journalists from a national television company into his lab, imagining that the reporters would be impressed by his monkeys' luxurious accommodation, and surprised by how relaxed and content the animals seemed. Instead, the journalists portrayed a slightly mad scientist among suffering animals. The experience \u201cspectacularly demonstrated the need for a reaction of scientific organizations to the escalating absurdity of the anti-vivisectionists\u201d, Logothetis says. However, T\u00fcbingen \u2014 unlike Kreiter's Bremen \u2014 is a city where researchers enjoy a supportive political environment. Even the city's mayor, a member of the Green Party, which is not known for supporting animal experiments, has openly criticized flyers distributed by activists as untruthful, and described the harsh treatment of Logothetis as \u201cunacceptable\u201d. \u201cThis shows the power of local politics to influence how easy or difficult it can be to carry out research using monkeys in different European regions,\u201d says Treue, whose research centre also benefits from local political support in G\u00f6ttingen. For scientists such as Treue, the EU directive has brought a feeling of stability. \n               The Italian job \n             That feeling is largely absent in Italy. In 2012, activists attacked a beagle-breeding facility near Brescia. It was later closed down. In 2013, they sabotaged experiments at the University of Milan. And last month, activists posted flyers that included photographs, addresses and phone numbers of some of the university's researchers in their home neighbourhoods. By 2012, some populist politicians had adopted the animal-rights cause and used it to influence the Italian implementation of the EU directive. The proposed law went beyond the directive, calling for a ban on xenotransplantation and the use of animals in addiction research. Italian scientists woke up late to the threat, and by the time researchers had organized a petition defending animal research \u2014 signed by 13,000 people in just a few weeks \u2014 the course of the distinctly gold-plated law was already set. It passed through parliament in December. Researchers who use monkeys are also worried about ambiguities in how the Italian law interprets the EU directive's clause allowing research on non-human primates. \u201cIt's not clear at all whether basic research is allowed or not,\u201d says neurophysiologist Roberto Caminiti at the University of Rome La Sapienza, who chairs the Committee on Animals in Research for the Federation of European Neuroscience Societies. The law also requires all research proposals involving non-human primates, cats or dogs to be authorized by the High Health Council (Consiglio Superiore di Sanit\u00e0), the broad mandate of which includes drug licensing and approval of clinical protocols. This additional level of control, on top of the approval required from local ethical committees, would slow and destabilize the process, says Caminiti. The legislation is expected to become law in March. As soon as it does, Caminiti and his colleagues plan to file an appeal to the EU Court of Justice. \u201cGold-plating is not allowed,\u201d he says, \u201cso we are confident of winning.\u201d In the meantime, Caminiti predicts that Italian labs working with primates will all be able to argue that their work has health benefits for humans. In Belgium, the government is hurrying through a similar gold-plating decree that would also ban the use of primates in addiction studies, and require a national committee to approve projects involving non-human primates, even after approval by local ethics committees. The Belgian health minister would have the final say on whether a particular project could go ahead, raising concerns that final decisions would be based on politics, rather than on science or ethics. Political decisions are already affecting research in Switzerland, a non-EU country that is not bound by the 2010 animal-rights directive. In 2000, Switzerland's constitution was changed to protect the dignity of animals \u2014 a move that led courts to limit the use of monkeys to translational research. Researchers in Fribourg have been able to continue their studies of spinal-cord repair in primates, but local authorities in Zurich have not renewed licences for basic research using primates since 2004. Kevan Martin, a director at the city's Institute of Neuroinformatics, had to stop mapping the functional microcircuitry of the macaque brain in 2006, when his licence expired. Martin was shocked to learn that local authorities had declined to renew his licence because the work was unlikely to reap practical benefits for society in the near term. He was even more shocked when his appeal to Switzerland's supreme court was turned down. \u201cIs any applied research possible without basic research?\u201d he muses. \n               Working abroad \n             In this climate, some Swiss scientists are relying on their collaborations in other countries to carry out primate experiments. Botond Roska of the Friedrich Miescher Institute for Biomedical Research in Basel and his colleagues have used mice to develop an experimental treatment for a common type of blindness called retinitis pigmentosa. The method is now poised for human trials, to be run by the small Paris-based biomedical company GenSight Biologics, which Roska co-founded. \u201cBut you can't go directly from mice to humans because you can't be sure if the neural circuits are the same,\u201d says Roska. \u201cMice are simply not a good model of how people see.\u201d Rather than face uncertainty in Switzerland, Roska and his collaborators \u2014 GenSight and the Vision Institute in Paris \u2014 are conducting primate studies in France, where animal activists have less political support. Roska hopes the first human patient could be treated within the year. Like Roska, Per-Olof Berggren at the Karolinksa Institute in Stockholm has reached a translational turning point in his research. He has developed an experimental therapy for diabetes in mice, and now needs to test it in primates before moving to humans. He thinks he could have got a licence for this in Sweden, but knew that he could not have afforded it. Regulations in the country, where animal-rights and animal-welfare groups are very powerful, require particularly large, sophisticated \u2014 and consequently expensive \u2014 primate facilities. So Berggren decided to do the work in Singapore, where he says facilities are first-class and ethical standards are as high as in Europe. \u201cThey have a long tradition of working with monkeys there, and it doesn't cost so very much.\u201d Berggren is far from alone: many European researchers are taking their primate research to Asia, sparking a controversy that is dividing the scientific community. Some worry that standards of ethical oversight and animal welfare could be lower in certain Asian countries. And Martin points out that the trend exacerbates the loss of skills already apparent as the number of groups working on primates in Europe falls. (The number of primates used in the EU for scientific purposes shrank by more than 25% between 2008 and 2011, according to the European Commission.) \u201cThe loss is going to be much harder to reverse,\u201d he says. \u201cFinding anaesthetists and surgeons has already become more difficult.\u201d One European scientist, recently returned from two weeks at a leading institute in China, says that he found many Europeans setting up collaborations there \u2014 but they, like him, did not want to say so openly, for fear of damaging the reputations of their home institutions. The scientist insists that ethical concerns are out of place, and that standards at the institutes match those of Germany and the United States. \u201cIt is not a question of low standards but of forward-looking research,\u201d he says. \u201cAnd it is nice to enjoy the energy and optimism, and not always hear the word 'no'.\u201d Back in Bremen, Kreiter still hopes to hear a 'yes' in court. With the support \u2014 moral and financial \u2014 of his university, he has spent more than five years fighting local authorities in a string of courtroom battles. He is now awaiting yet another verdict from a high court in Leipzig. \u201cIt may be the last,\u201d he says. \u201cBut you never know how things will develop.\u201d \n                 See Editorial \n                 page 5 \n               \n                     Voice of Pro-Test 2013-May-08 \n                   \n                     Animal-rights activists wreak havoc in Milan laboratory 2013-Apr-22 \n                   \n                     Court orders temporary closure of Italian dog-breeding premises 2012-Aug-02 \n                   \n                     Italian scientists fight tightened rules on animal testing 2012-Jul-10 \n                   \n                     Activists ground primate flights 2012-Mar-20 \n                   \n                     Basel Declaration defends animal research 2010-Dec-06 \n                   \n                     Lab-animal battle reaches truce 2010-Apr-13 \n                   \n                     EU directive (2010) \n                   \n                     Logothetis on value of primate research \n                   \n                     Basel Declaration \n                   \n                     Swiss Primate Competence Center for Research \n                   \n                     Speaking of research \n                   Reprints and Permissions"},
{"file_id": "506281a", "url": "https://www.nature.com/articles/506281a", "year": 2014, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Before it shattered near the Sun, Comet ISON became a scientific celebrity. Now researchers are trying to piece together its lessons. Near the banks of the Potomac River, in an office cluttered with craft-beer coasters and a  Doctor Who  mug, Karl Battams keeps watch for daredevil comets that skim just above the surface of the Sun. A decade ago, when the astrophysicist joined the US Naval Research Laboratory in Washington DC, he had no deep interest in comets. But he was pressed into service because the lab operates instruments on two solar-physics missions that can spot objects passing very close to the Sun. They have detected some 2,600 such 'sun-grazing' comets so far, and it is part of Battams' job to catalogue those discoveries. He is the only dedicated sun-grazing-comet tracker in the world. \u201cHopefully, I'll be getting a summer student,\u201d he says one overcast January morning. \u201cBut pretty much it's just me.\u201d All of the Solar System's comets travel around the Sun, but sun-grazers are those that fly within about three solar radii of the star's centre (some 1.4 million kilometres above its surface). Battams rose to fame last autumn as the public face of a research group tracking the most famous sun-grazer of all, Comet ISON. As ISON sailed into the inner Solar System, expectations grew quickly among astronomers and amateur skywatchers. Many hoped that it might survive its close passage to become a dramatic sight in the night sky \u2014 and continued fodder for scientific study. Instead, the comet disintegrated spectacularly in November, just hours before it was set to sweep past the Sun. Scientists are left wondering why ISON suffered the fate it did. Early results suggest that it may have been just too small and too volatile to survive the Sun's searing heat (M. M. Knight and K. Battams Preprint at  http://arxiv.org/abs/1401.7028 ; 2014 ). ISON was a tiny, gassy comet making its first ever trip to the inner Solar System \u2014 a combination that may have doomed it from the beginning. Yet its death could mark a renaissance for the study of sun-grazing comets. ISON was spotted quite far out in the Solar System, and its unusual trajectory allowed spacecraft orbiting Earth, Mars and Mercury to photograph it from many vantage points. That made ISON the most studied sun-grazer yet. What researchers have learned so far suggests that sun-grazers have a lot to reveal about the diversity of comets, and how hard it is to predict what they might do. Even as they wring findings out of the ISON event, astronomers are gearing up for the next close cometary encounter, later this year. The sheer amount of observational firepower involved in studying ISON set a new standard for coordinating a flotilla of spacecraft and ground-based telescopes. \u201cIt was about bringing all of it together,\u201d says Battams. \u201cThat's never been done before.\u201d \n               Blaze of glory \n             For centuries, skywatchers have recognized objects that disappear into the Sun and re-emerge on the other side. In 1687, Isaac Newton published the first calculations of a sun-grazer's orbit, showing that the great comet of 1680 moved according to his laws of gravitation. But it was not until the era of satellites that people could watch sun-grazers up close. Amateur astronomers discover most sun-grazers, just days before they pass through the Sun's atmosphere, by trawling through images taken by the Solar and Heliospheric Observatory (SOHO) spacecraft. Launched in 1995, SOHO stares at the Sun with a set of three US Navy-built coronagraphs that block out the central disk of the Sun, allowing astronomers to see details in and around its blazing outer atmosphere. Once they have found a candidate comet, the amateurs alert Battams. Most sun-grazers belong to the 'Kreutz' family of comets, named after Heinrich Kreutz, a nineteenth-century astronomer who calculated many of their orbits. Kreutz comets probably trace their origins back to a single comet that broke apart millennia ago. On each pass near the Sun, the fragments either squeak past it and survive, or plunge to a fiery doom if they come too close. Every week or so, Battams watches one of these comet pieces incinerate itself. In 2011, however, a Kreutz comet swooped just 140,000 kilometres above the solar surface and survived \u2014 temporarily. After zipping through the Sun's upper atmosphere, Comet Lovejoy remained intact and put on a spectacular show in southern skies. Days later it fell apart, probably ripped to pieces by tidal forces induced by the Sun's powerful gravitational pull. Researchers took unprecedented measurements of Lovejoy's tail fluctuating in the Sun's powerful magnetic fields during the comet's brief passage through the solar atmosphere (C. Downs  et al .  Science   340 , 1196\u20131199; 2013 ). In September 2012, the spotlight shifted to another sun-grazer when a pair of Russian astronomers discovered a tiny dot in the sky in the constellation Cancer. Because their telescopes belonged to the International Scientific Optical Network, the comet was dubbed ISON. At the time, ISON was nearly one billion kilometres from the Sun, out past Jupiter. That is much farther than most comet discoveries, because comets become more active and more visible the closer they get to the Sun. The early discovery hinted that ISON was either monstrous in size or surprisingly active, prompting expectations that it would become a historic sight in the skies as it reached the inner Solar System. Doubts emerged in April 2013, when the Hubble Space Telescope photographed ISON. Although the observing team could not measure the comet's nucleus directly, the researchers concluded that the amount of water spraying off the icy core suggested that it could be no more than 6 kilometres across, a little less than average. Another opportunity to measure the comet came in late September as it flew past Mars. The High Resolution Imaging Science Experiment (HiRISE) on the Mars Reconnaissance Orbiter (MRO) \u2014 the sharpest-eyed camera ever to fly beyond Earth orbit \u2014 swung to look at ISON, and took a set of grainy, black-and-white photographs. These turned out to yield a better size estimate: ISON could be no more than 1.2 kilometres across. \u201cIt was a little thing,\u201d says Carey Lisse, who studies comets at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland. That worried astronomers. The smaller the comet nucleus, the less likely it is to survive a close pass by the Sun. Even so, some scientists thought ISON would make it (see  Nature   http://doi.org/rdm ; 2013 ). ISON's fate started to become apparent in the days before it reached the Sun. By 20 November, it was spraying off massive amounts of water vapour, at rates that suggested that it was no more than 500 metres across. A few days later it entered the field of view of the coronagraphs on the twin satellites of the Solar Terrestrial Relations Observatory (STEREO), on the opposite side of the Sun from Earth. The comet continued to brighten, then faded a bit, then ominously brightened again as if it were already flaming out. The closer it got to the Sun, the worse ISON looked. \u201cWhere we really went 'uh-oh' was the morning of close approach,\u201d says Matthew Knight, an astronomer at Lowell Observatory in Flagstaff, Arizona. On 28 November, the US Thanksgiving holiday, Knight, Battams and Lisse gathered on Kitt Peak in Arizona to watch for the comet. Knight was hoping to use a solar telescope there to take spectra of ISON as it flew 1.2 million kilometres past the Sun. He got up extra early, crunched the numbers on the comet's brightness, and realized that, overnight, it had faded beyond hope. It had shrunk to an unsustainable size \u2014 perhaps just 50 metres across \u2014 and was on the verge of shattering completely. For hours the team, plus comet fans around the world, watched as ISON flew through the SOHO and STEREO fields of view. It grew fainter as it approached the Sun, and could not be seen at all by a third solar probe peering closer to the star. On the far side of the Sun, where the nucleus would have emerged had ISON remained intact, a ghostly cloud of remnant dust appeared and quickly faded from view. Battams took the loss of ISON personally. \u201cIt was kind of a process of heartbreak, really,\u201d he says. \u201cBorn 4.5 Billion  BC , Fragmented Nov 28, 2013\u201d, he wrote in an obituary on an ISON-observing blog. \u201cSurvived by approximately several trillion siblings, Comet ISON leaves behind an unprecedented legacy for astronomers, and the eternal gratitude of an enthralled global audience.\u201d \n               Long tail \n             Although disappointed, Battams and other astronomers quickly moved on to glean clues from ISON's death. One major puzzle has been why ISON disintegrated and Lovejoy survived, when Lovejoy passed much closer to the Sun. The answer may lie in their ancient histories, says Knight. As a Kreutz-family comet, Lovejoy had travelled through the inner Solar System several times before, burning off its most volatile components. But ISON was a 'dynamically new' comet that had never before visited this region of space. It hailed directly from the Oort cloud, the icy reservoir of comets beyond the orbit of Pluto. It spent most of its life in this cloud until perhaps a few million years ago, when the gravity of a passing star nudged it into a new orbit (see 'Final journey'). As it approached the Sun for the first time, volatile molecules began flying off its icy nucleus. Simple organic compounds, such as methane and carbon monoxide, would have burned off first, followed by more complex ones \u2014 much like a steak left on a grill too long. All that early activity explains why ISON looked so bright early on. Never before have astronomers watched a dynamically new comet come so close to the Sun. The sequence and rate at which molecules burned off ISON are key data points for understanding the next one that comes in. \u201cWe've learned that dynamically new comets evolve and change,\u201d says Lisse. That is much more than astronomers managed to learn in 2011 from the sun-grazing Comet Elenin, which was also a relatively fresh visitor to the inner Solar System, but was too dim to provide much science before it plunged to its death. More broadly, the ISON experience may act as a template for future comet-observing campaigns. A record 14 missions photographed the comet from space, says Lisse, who coordinated the campaign for NASA. They included the Mercury Surface, Space Environment, Geochemistry, and Ranging (MESSENGER) spacecraft and the MRO at Mars. That experience will inform a big event this October, when a comet named Siding Spring is due to pass within 140,000 kilometres of Mars. It will be the closest such pass ever seen, and the red planet will be physically enveloped in the comet's coma, the shroud of ice and dust around the nucleus. In a manoeuvre practised with ISON, craft such as the MRO will swivel to photograph Siding Spring. \u201cIt's like a cheap comet flyby,\u201d says Lisse. More expensively, the European Space Agency is sending its Rosetta spacecraft to land on and study Comet 67P/Churyumov-Gerasimenko in November (see  Nature   505 , 269\u2013270; 2014 ). With the combination of Siding Spring, what is popularly called CG and the aftermath of ISON, some have labelled 2014 the year of the comet. That is just fine with Battams, who keeps a sharp eye on whatever might enter his Sun-centric field of view. \u201cNow it's just a case of sitting and waiting,\u201d he says, \u201cfor the next interesting thing to come along.\u201d \n                     Comet craft ready to wake 2014-Jan-15 \n                   \n                     Remnants suggest comet ISON still going 2013-Nov-29 \n                   \n                     Hubble Space Telescope spots unprecedented asteroid with six tails 2013-Nov-08 \n                   \n                     Comet expected to survive close Sun encounter 2013-Oct-09 \n                   \n                     The Sun as comet snatcher 2010-Jun-10 \n                   \n                     Sungrazing comets \n                   Reprints and Permissions"},
{"file_id": "506146a", "url": "https://www.nature.com/articles/506146a", "year": 2014, "authors": [{"name": "Katherine Sharpe"}], "parsed_as_year": "2006_or_before", "body": "Evidence is mounting that medication for ADHD doesn't make a lasting difference to schoolwork or achievement. Ben Harkless could not sit still. At home, the athletic ten-year-old preferred doing three activities at once: playing with his iPad, say, while watching television and rolling on an exercise ball. Sometimes he kicked the walls; other times, he literally bounced off them. School was another story, however. Ben sat in class most days with his head down on his desk, \u201ca defeated heap\u201d, remembers his mother, Suzanne Harkless, a social worker in Berkeley, California. His grades were poor, and his teacher was at a loss for what to do. Harkless took Ben to a therapist who diagnosed him with attention deficit hyperactivity disorder (ADHD). He was prescribed methylphenidate, a stimulant used to improve focus in people with the condition. Harkless was reluctant to medicate her child, so she gave him a dose on a morning when she could visit the school to observe. \u201cHe didn't whip through his work, but he finished his work,\u201d she says. \u201cAnd then he went on and helped his classmate next to him. My jaw dropped.\u201d ADHD diagnoses are rising rapidly around the world and especially in the United States, where 11% of children aged between 4 and 17 years old have been diagnosed with the disorder. Between half and two-thirds of those are put on medication, a decision often influenced by a child's difficulties at school. And there are numerous reports of adolescents and young adults without ADHD using the drugs as study aids. As the drugs have become more widespread, so has their cultural cachet. Stimulant medications have gained a reputation for turbo-charging the intellect. Even news stories critical of their use refer to them as \u201cgood-grade pills\u201d, \u201ccognitive enhancers\u201d and \u201cmental steroids\u201d. For most people with ADHD, these medications \u2014 typically formulations of methylphenidate or amphetamine \u2014 quickly calm them down and increase their ability to concentrate. Although these behavioural changes make the drugs useful, a growing body of evidence suggests that the benefits mainly stop there. Studies indicate that the improvements seen with medication do not translate into better academic achievement or even social adjustment in the long term: people who were medicated as children show no improvements in antisocial behaviour, substance abuse or arrest rates later in life, for example. And one recent study suggested that the medications could even harm some children 1 . After decades of study, it has become clear that the drugs are not as transformative as their marketers would have parents believe. \u201cI don't know of any evidence that's consistent that shows that there's any long-term benefit of taking the medication,\u201d says James Swanson, a psychologist at the University of California, Irvine. Now researchers are trying to understand why. The answer could lie in sub-optimal use of the drugs, or failure to address other factors that affect performance, such as learning disabilities. Or it could be that people place too much hope on a simple fix for a complex problem. \u201cWhat we expect medication to do may be unrealistic,\u201d says Lily Hechtman, a psychiatrist at McGill University in Montreal. \n               Unrealistic expectations? \n             In 1937, psychiatrist Charles Bradley noticed that problem children treated with a stimulant, benzedrine sulphate, became quieter, better behaved and more studious. Since then, studies have repeatedly demonstrated that stimulant medications reduce the core symptoms of ADHD, which include incessant, disruptive activity coupled with a lack of reflectiveness and inhibition. Stimulants work by increasing levels of the neurotransmitter dopamine in the brain, affecting regions involved in focus, self-control and the sense that an activity is rewarding. They take effect immediately, and they help as many as 80% of those with ADHD \u2014 one of the best response rates for a psychiatric drug. Years of lab and classroom studies attest that the medications help affected children to perform in school. Treated children fidget less. They do better on laboratory tests requiring concentration and short-term memory. And they take better notes and hand in more homework, making fewer careless mistakes. Nora Volkow, director of the National Institute on Drug Abuse in Bethesda, Maryland, says that these benefits carry over into the real world, at least in the short term. \u201cThey help you pay attention,\u201d she says. \u201cThe grades do improve.\u201d But the few studies that have examined the effects of ADHD medication much beyond a year have found that the benefits either vanish or shrink to clinically meaningless proportions. In the early 1990s, as rates of stimulant prescriptions were beginning to climb, the National Institute of Mental Health in Bethesda, Maryland, funded a study to compare different treatments for the disorder. Known as the Multimodal Treatment Study of Children with ADHD, or MTA, the study randomized 579 children aged between seven and ten with ADHD to receive one of four treatments: stimulant medication, behaviour therapy, medication and behaviour therapy combined or whatever care they had already been receiving. After 14 months, the groups treated with medication alone and medication plus behaviour therapy showed greater improvements in core ADHD symptoms than the other two groups. For academic achievement, only the group receiving medication and behaviour therapy combined outperformed the group receiving regular care 2 . By three years in, the four groups had become indistinguishable on every measure 3 . Treatment conferred no lasting benefit in terms of grades, test scores or social adjustment. Eight years later, it was the same story 4 . \u201cNothing we did could tease out and say there's a long-term effect,\u201d says Swanson, who was one of the lead investigators on the MTA. The MTA's findings are borne out in most of the studies that followed students for long periods of time. A literature review in 2012, which included studies that tracked children with ADHD for three years or more, found little evidence for a significant effect on standardised-test scores, grades or on the likelihood that a student would be held back a year 5 . A 2013 review of randomized controlled trials longer than 12 months similarly concluded that there is scant evidence for improvements in ADHD symptoms or academic performance lasting much beyond a year 6 . There is even some evidence that ADHD medication could worsen outcomes. In 2013, a team of economists published a study 1  examining the effects of a policy change in Quebec that resulted in thousands of children being given prescriptions for methylphenidate. The authors found that children who began taking it actually did worse at school and were more likely to drop out than those with similar levels of symptoms who did not receive drugs. Girls taking the drug had more emotional problems, and both sexes reported worse relationships with their parents. There are a few studies that do show long-term gains in academic performance, but the boost is not large. A study that tracked 594 students aged 5\u201311 with ADHD found that those using medication for at least a year scored 3 points out of 100 higher on standardized maths tests and 5 points higher on reading tests than those not taking medication 7 . But this was not enough to close the test-score gap between those with ADHD and those without. And the gains faded over time even if the children stayed on the drugs, according to study co-author Stephen Hinshaw, a psychologist at the University of California, Berkeley. In 2012, a study in Iceland \u2014 the only country where rates of stimulant medication use are comparable to those of the United States \u2014 found that although the scores of all children with ADHD declined, on average, on standardized maths tests between the ages of 9 and 12, those of students who started medication earlier during that period declined less than those who waited longer to start 8 . It is possible that there are long-term benefits that studies so far have not captured. But given the abundance and consistency of the data, the drugs cannot be doing much for most of the millions of children who take them, says Alan Sroufe, a psychologist emeritus at the University of Minnesota in Minneapolis. \u201cIf they were, it wouldn't be hard to detect.\u201d \n               Puzzling paradox \n             Researchers are beginning to address this paradox. How can medication that makes children sit still and pay attention not lead to better grades? One possibility is that children develop tolerance to the drug. Dosage could also play a part: as children grow and put on weight, medication has to be adjusted to keep up, which does not always happen. And many children simply stop taking the drugs, especially in adolescence, when they may begin to feel that it affects their personalities. Children may also stop treatment because of side effects, which can include difficulty sleeping, loss of appetite and mood swings, as well as elevated heart rate. Or it could be that stimulant medications mainly improve behaviour, not intellectual functioning. In the 1970s, two researchers, Russell Barkley and Charles Cunningham, noted that when children with ADHD took stimulants, parents and teachers rated their academic performance as vastly improved 9 . But objective measurements showed that the quality of their work hadn't changed. What looked like achievement was actually manageability in the classroom. If medication made struggling children appear to be doing fine, they might be passed over for needed help, the authors suggested. Janet Currie, an economist at Princeton University in New Jersey, says that she might have been observing just such a phenomenon in the Quebec study that found lower achievement among medicated students 1 . And it may simply be that drugs are not enough. Stimulant medications have two core effects: they help people to sustain mental effort, and they make boring, repetitive tasks seem more interesting. Those properties help with many school assignments, but not all of them. Children treated with stimulants would be able to complete a worksheet of simple maths problems faster and more accurately than usual, explains Nora Volkow. But where flexibility of thought is required \u2014 for example, if each problem on a worksheet demands a different kind of solution \u2014 stimulants do not help. \n               Beyond belief \n             In people without ADHD, such as students who take the drugs without a prescription to help with school work, the intellectual impact of stimulants also remains unimpressive. In a 2012 study of the effects of the amphetamine Adderall on people without ADHD, psychologists at the University of Pennsylvania in Philadelphia found no consistent improvement on numerous measures of cognition, even though people taking the medication believed that their performance had been enhanced 10 . Increased focus has benefits, say some experts, but many children with ADHD need help in more areas if they are to succeed at school. \u201cMany things go into grades,\u201d says Joshua Langberg, a psychologist at Virginia Commonwealth University in Richmond. \u201cOne of those is certainly a child's behaviour and ability to focus, which medication does a nice job of improving. But they also include a child's basic abilities in math and reading, their IQ and their ability to manage time and plan. It's not clear why we would expect medication to impact those things.\u201d  Only one in four kids are getting anything close to what we would say is good treatment.  Some researchers think that the lack of evidence for long-term academic benefits is a result of flawed study design. Peter Jensen, a leader on the MTA study, says he believes that if the children had been maintained on the study's protocol, the initial gains they made would have lasted. Longer randomly controlled trials would be challenging both from a technical and ethical standpoint, but the suggestion highlights another problem, namely the discrepancy between the optimal care given during a trial and that which most children receive. After the 14-month, randomized trial period, participants in the MTA study began to receive what Jensen calls treatment 'in the community'. He says it is typically of low quality. Few doctors monitor children closely enough to arrive at optimal dosage or identify and treat co-occurring conditions \u2014 such as depression and anxiety \u2014 that affect up to 70% of children with ADHD. \u201cOnly one in four kids are getting anything close to what we would say is good treatment,\u201d Jensen says. When the MTA team examined the follow-up data, it found that many non-medical factors play a big part in whether improvements last. The best predictor of a child's response to treatment wasn't which treatment they were assigned, but a cluster of factors that were present at the start. Children with more advantages \u2014 higher intelligence, better social skills, intact families, higher parental education, fewer conduct problems or higher socioeconomic status \u2014 were likely to make big strides and hold onto them no matter what the treatment was, whereas children without these advantages typically progressed more slowly and regressed after treatment stopped 2 , 3 , 4 . But disadvantaged children benefited when they received both medication and behaviour therapy. \u201cThe kids with the most problems needed the combination,\u201d says Jensen, who adds that parents should have easier access to proven behaviour therapies. The effects of behavioural treatment don't seem to be longer-lasting than those of medication, however: once active treatment stops, they dissipate. Future studies might explore whether medication offers subtle benefits that are not reflected in test scores or grades. Many researchers think that a stint on medication, when it is needed, can create an upward spiral of self-esteem that may make a crucial difference to a child's life \u2014 but there are no hard data to support this. \u201cIt may be that treatment doesn't translate into better grades\u201d in the long term, Volkow says. \u201cBut what I'd like to see is, are those kids overall better integrated?\u201d Some experts think that the focus on academic achievement is misguided \u2014 that the point of the drugs has never been to improve children's grades, or increase their chances of admission to the best universities. \u201cMedications are given for their short-term effects,\u201d says Swanson. \u201cDon't expect medication to get rid of every problem a child has. But if the problem right now is not passing the second grade, or not having any friends in the third grade, we can do something about that now.\u201d Some parents seem to understand that. Suzanne Harkless says that her hopes for medication are modest. She wants to keep Ben engaged in the fifth grade while she looks for a middle school that might provide him with the structure he needs. \u201cMy goal right now is not to get him into a good college,\u201d she says. \u201cMy goal is to keep him in school.\u201d Other parents may pin unrealistic hopes on these drugs as their use goes up around the world (see 'Popular prescriptions'). \u201cCompetition in today's global economy is fuelling the dramatic increase in the use of ADHD medications, especially in the United States,\u201d says Richard Scheffler, a health economist at the University of California, Berkeley, and co-author of a forthcoming book with Hinshaw on the growing popularity of ADHD drugs. For Currie, the question comes down to transparency. \u201cParents do care about how their children are doing in school,\u201d she says. \u201cIt's misleading to tell parents that this will help their children succeed, when there's no evidence that it's the case.\u201d \n                     Extra gene makes mice manic 2013-Oct-23 \n                   \n                     Mental health: On the spectrum 2013-Apr-24 \n                   \n                     Testing magnesium's brain-boosting effects 2012-Oct-26 \n                   \n                     http://blogs.nature.com/news/2009/08/problems_with_cognitive_enhanc.html \n                   \n                     The ADHD Explosion \n                   Reprints and Permissions"},
{"file_id": "507022a", "url": "https://www.nature.com/articles/507022a", "year": 2014, "authors": [{"name": "Virginia Hughes"}], "parsed_as_year": "2006_or_before", "body": "The roots of inheritance may extend beyond the genome, but the mechanisms remain a puzzle. When Brian Dias became a father last October, he was, like any new parent, mindful of the enormous responsibility that lay before him. From that moment on, every choice he made could affect his newborn son's physical and psychological development. But, unlike most new parents, Dias was also aware of the influence of his past experiences \u2014 not to mention those of his parents, his grandparents and beyond. Where one's ancestors lived, or how much they valued education, can clearly have effects that pass down through the generations. But what about the legacy of their health: whether they smoked, endured famine or fought in a war? As a postdoc in Kerry Ressler's laboratory at Emory University in Atlanta, Georgia, Dias had spent much of the two years before his son's birth studying these kinds of questions in mice. Specifically, he looked at how fear associated with a particular smell affects the animals and leaves an imprint on the brains of their descendants. Dias had been exposing male mice to acetophenone \u2014 a chemical with a sweet, almond-like smell \u2014 and then giving them a mild foot shock. After being exposed to this treatment five times a day for three days, the mice became reliably fearful, freezing in the presence of acetophenone even when they received no shock. Ten days later, Dias allowed the mice to mate with unexposed females. When their young grew up, many of the animals were more sensitive to acetophenone than to other odours, and more likely to be startled by an unexpected noise during exposure to the smell. Their offspring \u2014 the 'grandchildren' of the mice trained to fear the smell \u2014 were also jumpier in the presence of acetophenone. What's more, all three generations had larger-than-normal 'M71 glomeruli', structures where acetophenone-sensitive neurons in the nose connect with neurons in the olfactory bulb. In the January issue of  Nature Neuroscience 1 , Dias and Ressler suggested that this hereditary transmission of environmental information was the result of epigenetics \u2014 chemical changes to the genome that affect how DNA is packaged and expressed without altering its sequence. Biologists first observed this 'transgenerational epigenetic inheritance' in plants. Tomatoes, for example, pass along chemical markings that control an important ripening gene 2 . But, over the past few years, evidence has been accumulating that the phenomenon occurs in rodents and humans as well. The subject remains controversial, in part because it harks back to the discredited theories of Jean-Baptiste Lamarck, a nineteenth-century French biologist who proposed that organisms pass down acquired traits to future generations. To many modern biologists, that's \u201cscary-sounding\u201d, says Oliver Rando, a molecular biologist at the University of Massachusetts Medical School in Worcester, whose work suggests that such inheritance does indeed happen in animals 3 . If it is true, he says, \u201cWhy hasn't this been obvious to all the brilliant researchers in the past hundred years of genetics?\u201d. One reason why many remain sceptical is that the mechanism by which such inheritance might work is mysterious. Explaining it will require a deep dive into reproductive biology to demonstrate how the relevant signals might be formed in the germ line, the cells that develop into sperm and eggs and carry on, at a minimum, a person's genetic legacy. A mother might pass on effects of environmental exposures to a fetus during pregnancy. So, to study the phenomenon of transgenerational epigenetics cleanly, biologists are focusing on fathers, and have been looking at how sperm might gain and lose epigenetic marks. \u201cIn the past two to three years there's been a lot of new information,\u201d says Michelle Lane, a reproductive biologist at the University of Adelaide in Australia. But proposals for how it all works are themselves embryonic. \u201cIt's a huge black box,\u201d Lane says. \n               Monster plants and obese children \n             The epigenetics revolution hit in the early 2000s, when scientists began reporting that environmental factors \u2014 everything from neglectful mothering and child abuse to a high-fat diet and air pollution \u2014 can influence the addition or removal of chemical tags on DNA that turn genes on and off. This idea of an environmentally responsive genome still stirs debate (see  Nature   467 , 146\u2013148; 2010 ). But the notion that epigenetic marks are transmitted across generations is even more provocative. Swedish botanist Carl Linnaeus was among the first to spot changes resulting from this phenomenon. In the 1740s, he received a plant specimen that looked very similar to common toadflax ( Linaria vulgaris ), but with very different flowers. Linnaeus was shocked because this challenged his theory that plant species could be categorized by the structure of their flowers. \u201cThis is certainly no less remarkable,\u201d he wrote, \u201cthan if a cow were to give birth to a calf with a wolf's head.\u201d He named the plant  Peloria , after the Greek word for 'monster'. In the 1990s, plant biologist Enrico Coen at the John Innes Centre in Norwich, UK, found that in the monster plants, methyl groups litter a gene involved in flower structure called  Lcyc , completely shutting it down. (DNA methylation usually turns genes off.) Coen's team also showed that these methyl marks pass through seeds to later generations 4 . The public first started to take notice in the mid-2000s, after large epidemiological investigations in Europe began to show transgenerational effects in humans. One study of Swedish historical records showed that men who had experienced famine before puberty were less likely to have grandsons with heart disease or diabetes than men who had plenty to eat 5 . Similar work with children in Britain reported in 2005 that fathers who had started smoking before the age of 11 had an increased risk of having boys of above average weight 6 . But many scientists remained sceptical. Epidemiological studies are often messy, and it is impossible to rule out all confounding variables. In the past few years, however, several studies in rodents have supported these observations and begun to attribute the transmission of various traits to changes in sperm. \n               Sperm signatures \n             Male rats fed a high-fat diet, for example, beget daughters with abnormal DNA methylation in the pancreas 7 . Male mice fed a low-protein diet have offspring with altered liver expression of cholesterol genes 3 . And male mice with pre-diabetes have abnormal sperm methylation, and pass on an increased risk of diabetes to the next two generations 8 . \u201cWe and many other people have now shown these paternal effects,\u201d says Rando, who led the low-protein study. \u201cAnd we're all having a hell of a time figuring out how they work.\u201d The animal studies have triggered some strong debate. The most controversial results have come out of Michael Skinner's lab at Washington State University in Pullman. Skinner's team exposed pregnant rats to large doses of pesticides and fungicides, which led to organ damage in their adult offspring. The sperm of male offspring showed changes in DNA methylation that persisted for at least four generations 9 . But at least two groups failed to replicate the data, and in 2010, federal investigators found that one of Skinner's postdocs had fabricated data for a related paper, which the authors had retracted in 2009. Skinner says that some teams have replicated his results, and that those who have not were using inappropriate protocols. Last year, his own team reported successfully reproducing the results of the retracted paper 10 . \n               Methylation mechanism \n             Explaining how transgenerational epigenetics works has been difficult in part because most studies track outcomes \u2014 such as changes in glucose, cholesterol and fertility \u2014 that can be affected by a range of factors, making it tricky to tease out cause and effect. By contrast, Dias and Ressler's work with acetophenone takes advantage of specific biology: the chemical binds to a particular receptor in the nose that is encoded by a single gene, dubbed  Olfr151 . \u201cThis is the massive pro of their study,\u201d Rando says. Dias and Ressler do not claim to understand exactly what is going on, but they do have a working hypothesis. Somehow, the information about the frightening smell gets into a mouse's testes and results in lower methylation of the  Olfr151  gene in sperm DNA. The researchers even ran experiments using  in vitro  fertilization to make sure that the father was not in some way passing on a fear of acetophenone through interactions with the mother. The epigenetic tweak in the sperm is perpetuated in the offspring's DNA, leading to increased expression of the receptor in the animals' noses and, ultimately, enhanced sensitivity to the smell. But the chain of causation is loose. \u201cThere are a lot of disconnects there,\u201d says William Kelly, a developmental geneticist at Emory. \u201cIt's not beyond the realm of possibility or plausibility. It's just right now we don't know enough about how information is transferred between generations.\u201d The first question is how the effects of environmental exposure become embedded in an animal's germ cells \u2014 in this case, the mouse's sperm. Germ cells have been shown to express olfactory receptors 11 . So it is possible that  Olfr151  receptors in sperm respond to odorant molecules in the bloodstream and then change the methylation of the corresponding gene in sperm DNA. Alternatively, after being exposed to the odour and the pain, a mouse might produce RNA molecules \u2014 perhaps in the brain \u2014 that make their way into the bloodstream and then selectively target the  Olfr151  gene in sperm. Many studies in plants have hinted at this sort of systemic RNA shuttling. RNA molecules expressed in a plant's leaf, for example, can travel through its vascular system to many of its other tissues and affect gene expression 12 . But creating an epigenetic mark in the sperm is only the first step. To pass down through multiple generations, the signal needs to survive multiple rounds of rigorous epigenetic reprogramming. In mammals, the first of these happens just hours after conception, when most methylation is stripped from sperm DNA in the single-celled embryo. Then, as the embryo develops and divides, and cells begin to differentiate into various tissue types, methylation is gradually re-established. But even if some signal from the father were to survive this process, the embryo's own primordial germ cells, those that eventually become its sperm or eggs, undergo a second round of epigenetic scrubbing (see 'Without a trace'). Some genes manage to escape these periods of major reprogramming. The best example is genes that are imprinted \u2014 whereby one copy from the mother or father is robustly methylated and effectively silenced. These silencing marks crop up in the egg or sperm and are retained in the embryo. About 100 genes are known to be imprinted, but some non-imprinted genes may also escape the scrubbing through a similar mechanism. \u201cThere is a growing consensus that there are more regions than previously thought that escape reprogramming in sperm,\u201d says Sarah Kimmins, an epigeneticist at McGill University in Montreal, Canada. \u201cWhy this is, and how, is not yet known, although studying imprinted genes may reveal clues.\u201d Then again, even if  Olfr151  does escape reprogramming, it is hard to explain how that could lead to a noticeable difference in the behaviour of fully formed offspring. Dias and Ressler reported that in sperm samples from mice trained to fear acetophenone, about 86 out of every 100 sperm show  Olfr151  methylation, whereas in mice trained to fear a different odour it is about 95 out of every 100. This difference is statistically significant, but fairly small. And yet the behavioural effects in the second generation were robust: about half of the acetophenone-trained animals' offspring showed increased sensitivity to the odour. \n               'Something goofball'? \n             Although many are scratching their heads over the holes in the proposed mechanism, few are suggesting that the underlying phenomenon is a fairy tale. \u201cImpossible things are happening every day,\u201d says Kelly, quoting a line from Rodgers and Hammerstein's  Cinderella . It is possible, for example, that the DNA-methylation tweaks reported in the odour study are simply a by-product of an altogether different mechanism. One route might be chemical marks on histones, the proteins around which DNA wraps. Acetyl and methyl groups can attach to histones and affect the expression of nearby DNA. But during sperm-cell formation, DNA is stripped of most of its histones (and their attendant marks) and wraps instead around protamines, which pack it more tightly. Nevertheless, about 10% of human histones \u2014 and about 1% of mouse ones \u2014 are retained. These sites might carry information from one generation to the next. In 2011, researchers reported that, in nematode worms, certain histone marks correlate with long life and can be passed down through several generations 13 . And last December, Kimmins and her colleagues showed that feeding male mice a diet low in folate \u2014 a nutrient that provides the raw materials for methylation \u2014 led to significantly reduced methylation of histone proteins in the animals' sperm and more birth defects in their offspring 14 . Still other studies point to a mechanism involving short RNA molecules latching on to DNA and affecting gene expression. Twenty-eight microRNAs are expressed differently in the sperm of men who do and do not smoke, according to a study reported in 2012 (ref.  15 ). And these RNA patterns may persist through multiple generations. Last year, Lane's group found that obese male mice show abnormal expression of 11 microRNAs in their sperm \u2014 and that they pass on insulin resistance to the next two generations 16 . Then there is the possibility that the mechanism is, as Rando puts it, \u201csomething goofball\u201d. That might be prions \u2014 misfolded proteins that act as infectious agents \u2014 which have been shown to transmit heritable traits in budding yeast (see  Nature   482 , 294\u2013296; 2012 ). Or it could be something in semen besides sperm. Researchers reported in January 17  that mice born of fathers lacking seminal vesicles are fatter and have more metabolic problems than controls, suggesting that molecules in seminal fluid influence gene expression in sperm and the female reproductive tract. If the mechanism involves DNA methylation, histones or RNA, the field is likely to make great progress in the next few years, Rando predicts. \u201cBut if it's something completely novel,\u201d he says, \u201cMaybe it will take decades to Figure out.\u201d Dias has his fingers crossed for the former. He is going to Boston, Massachusetts, in April for a Keystone meeting on epigenetic inheritance, to get a sense of the most promising mechanistic avenues to follow. \u201cIf science has taught me anything,\u201d he says, \u201cit is to not discount the myriad ways of becoming and being.\u201d \n                     Behaviour and biology: The accidental epigeneticist 2013-Dec-30 \n                   \n                     Fearful memories haunt mouse descendants 2013-Dec-01 \n                   \n                     Epigenetics posited as important for evolutionary success 2013-Jan-09 \n                   \n                     Fat fathers affect daughters' health 2010-Oct-20 \n                   \n                     Neuroscience: In their nurture 2010-Sep-08 \n                   \n                     Nature Reviews Genetics : Epigenetics \n                   \n                     Nature Insight:  Epigenetics \n                   \n                     The Ressler Lab \n                   \n                     Oliver Rando \n                   \n                     Sarah Kimmins \n                   Reprints and Permissions"},
{"file_id": "507158a", "url": "https://www.nature.com/articles/507158a", "year": 2014, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Predators are supposed to exert strong control over ecosystems, but nature doesn\u2019t always play by the rules. In 2008, Kristin Marshall was driving through Yellowstone National Park in Wyoming. Marshall, a graduate student at the time, had come to the park to study willow shrubs \u2014 specifically, how much they were being eaten by elk. She pulled to the side of the road and was preparing to hike to one of her study plots when she ran into two sisters from the Midwest, who were touring the park. The women asked what Marshall was doing and she said, \u201cI am a researcher. I am working in that willow patch down there.\u201d The tourists gushed: \u201cWe watched all about the willows on this nature documentary. We hear that all the willows are doing so much better now because the wolves are back in the ecosystem.\u201d That stopped Marshall short. \u201cI didn\u2019t want to say, \u2018No, you are wrong, they aren\u2019t actually doing that well.\u2019\u201d Instead, she said: \u201cThe story is a probably a little more complicated than what you saw on the nature documentary.\u201d That was the end of the conversation; the tourists seemed uninterested in the more-complicated story of how beavers and changes in hydrology might be more important than wolves for willow recovery. \u201cI can\u2019t say I blame them,\u201d says Marshall, now an ecologist with the US National Oceanic and Atmospheric Administration in Seattle, Washington. \u201cWhat you see on TV is captivating.\u201d On television and in scientific journals, the story of how carnivores influence ecosystems has seized imaginations. From wolves in North America to lions in Africa and dingoes in Australia, top predators are thought to exert tight control over the populations and behaviours of other animals, shaping the entire food web down to the vegetation through a \u2018trophic cascade\u2019. This story is popular in part because it supports calls to conserve large carnivores as \u2018keystone species\u2019 for whole ecosystems. It also offers the promise of a robust rule within ecology, a field in which researchers have yearned for more predictive power. But several studies in recent years have raised questions about the top-predator rule in the high-profile cases of the wolf and the dingo. That has led some scientists to suggest that the field\u2019s fascination with top predators stems not from their relative importance, but rather from society\u2019s interest in the big, the dangerous and the vulnerable. \u201cPredators can be important,\u201d says Oswald Schmitz, an ecologist at Yale University in New Haven, Connecticut, \u201cbut they aren\u2019t a panacea.\u201d \n               Predators on top \n             In the early years of ecology, predators did not get so much respect. Instead, researchers thought that plants were the dominant forces in ecosystems. The theory was that photosynthesis from these primary producers determined how much energy was available in an area, and what could live there. Bottom-up control was all the rage. Interest in top-down trophic cascades emerged in 1963, when ecologist Robert Paine of the University of Washington in Seattle started to exclude predators from study plots at his coastal research site. He pried predatory starfish off intertidal rocks and hurled them into deeper waters. Without the starfish to control their numbers, mussels eventually carpeted the plots and kept limpets and algae from taking hold in the region. A new ecosystem emerged (see  Nature 493, 286\u2013289; 2013 ). After this and other aquatic studies, the conventional wisdom in the field was that top-down trophic cascades happened only in rivers, lakes and the sea. An influential 1992 paper 1  by Donald Strong at the University of California, Davis, asked: \u201cAre trophic cascades all wet?\u201d As if in answer, ecologists began looking for similar carnivore stories on land. They soon found them. In 2000, a review 2 tallied 41 terrestrial studies on trophic cascades, most of which showed that predation had significant effects on the number of herbivores in an area, or on plant damage, biomass or reproductive output. These studies were all on small plots involving small predators: birds, lizards, spiders and lots of ants. Research on terrestrial trophic cascades moved to much larger scales with the work of John Terborgh and William Ripple. In 2001, Terborgh, an ecologist at Duke University in Durham, North Carolina, reported 3  on dramatic ecosystem changes that came after a dam was built in Venezuela. Flooding from the dam created islands that were too small to support big predators such as jaguars and harpy eagles. The population densities of their prey \u2014 rodents, howler monkeys, iguanas and leaf-cutter ants \u2014 boomed to 10\u2013100\u00a0times those on the mainland. Seedlings and saplings were devastated. In the same year, Ripple, an ecologist at Oregon State University in Corvallis, published a key paper 4  on the most famous, and probably the best-studied, example of a terrestrial carnivore structuring an ecosystem: Yellowstone\u2019s wolves. The ecosystem offered a natural experiment because the US National Park Service had the park\u2019s exterminated wolves ( Canis lupus ) by 1926 and then reinstated them in the 1990s, after public sentiment and ecological theory had shifted. In 1995, 14\u00a0wolves from Alberta, Canada, were introduced into the park. Seventeen from British Columbia followed in 1996. By 2009, there were almost 100 wolves in 14 packs in the Yellowstone area. (That number is now down to 83 in 10 packs.) During the years when there were no wolves, ecologists grew increasingly worried about the aspen trees ( Populus tremuloides ) in the park. It seemed that intensive browsing by Rocky Mountain elk ( Cervus elaphus ) was preventing trees from reaching adult height, or \u2018recruiting\u2019. In the early twentieth century, aspen covered between 4% and 6% of the winter range of the northern Yellowstone herd of elk; by the end of the century, they accounted for only 1% (ref.  4 ). When Ripple and his co-authors checked aspen growth against the roaming behaviour of wolves in three packs, they found that aspen grew tallest in stream-side spots that saw high wolf traffic. That pattern hinted at an indirect behavioural cascade: rather than limiting browsing by reducing elk populations throughout the park, wolves apparently made elk more skittish and less likely to browse in the tightly confined stream valleys, where prey have limited escape routes (see \u2018The tangled web\u2019). A 2007 study 5  by Ripple and Robert Beschta, also of Oregon State, seemed to strengthen the behavioural-cascade hypothesis. It found that the five tallest young aspen in stream-side stands where there were downed logs \u2014 a potential trip hazard for elk \u2014 were taller than the five tallest young aspen in stands away from streams or without downed logs. Similar evidence of indirect wolf effects emerged from a study of willows. In 2004, Ripple and Beschta found 6 that the shrubs were returning in narrow river valleys, where the researchers thought that the chances of wolves attacking elk were greatest. More recently, Ripple has been documenting the regrowth of cotton\u00adwood trees. \u201cWhen we look around western North America, we see a big decrease in tree recruitment after wolves were removed. And when wolves returned to Yellowstone, the trees started growing again. It is just wonderful to walk through that new cottonwood forest.\u201d \n               Tales from trees \n             But some ecologists had their doubts. The first major study 7  critical of the wolf effect appeared in 2010, led by Matthew Kauffman of the Wyoming Cooperative Fish and Wildlife Research Unit in Laramie. When researchers drilled boreholes into more than 200 trees in Yellowstone and analysed growth patterns, they found that the recruitment of aspen had not ended all at once. Some trees had reached adult size as late as 1960, long after the wolves had gone. And some stands had stopped growing new adults as early as 1892, well before the wolves left. The aspen petered out over decades, as elk populations slowly grew, suggesting that the major influence on the trees is the size of the elk population, rather than elk behaviour in response to wolves. And although wolves influence elk numbers, many other factors play a part, says Kauffman: grizzly bears are increasingly killing elk; droughts deplete elk populations; and humans hunt elk that migrate out of the park in winter. When Kauffman and his colleagues studied 7  aspen in areas where risk of attack by wolves was high or low, they obtained results different from Ripple\u2019s. Rather than look at the five tallest aspen in each stand, as Ripple had done, they tallied the average tree height and used locations of elk kills to map the risk of wolf attacks. By these measures, they found no differences between trees in high- and low-risk areas. Questions have also emerged about the well-publicized relationship between wolves and willows. Marshall and two colleagues investigated the controls on willow shrubs by examining ten years\u2019 worth of data from open plots and plots surrounded by cages to keep the elk out. Her team found 8  that the willows were not thriving in all the protected sites. The only plants that grew above 2 metres \u2014 beyond the reach of browsing elk \u2014 were those in areas where simulated beaver dams had raised the water table. If beavers have a key role in helping willows to thrive, as Marshall\u2019s study suggests, the shrubs face a tough future because the park\u2019s beaver populations have dropped. Researchers speculate that the removal of wolves in the 1920s allowed elk to eat so much willow that there was none left for the beavers, causing an irreversible decline. \u201cThe predator was gone for at least 70 years,\u201d says Marshall. \u201cRemoving it has changed the ecosystem in fundamental ways.\u201d This work suggests that wolves did meaningfully structure the Yellowstone ecosystem a century ago, but that reintroducing them cannot restore the old arrangement. Arthur Middleton, a Yale ecologist who works on Yellowstone elk, says that such studies have disproved the simple version of the trophic cascade story. The wolves, elk and vegetation exist in an ecosystem with hundreds of other factors, many of which seem to be important, he says. \n               Dingo debate \n             Another classic example of a trophic cascade has come under attack in Australia. The standard story there is that the top predator, the dingo ( Canis lupus dingo ), controls smaller introduced predators such as cats and foxes, allowing native marsupials to thrive. But Ben Allen, an ecologist at the Department of Agriculture, Fisheries and Forestry in Toowoomba, has compared 9  areas where dingoes are poisoned with areas where they are left alone, and found no difference in marsupial abundance. He is quite cynical, he says, about \u201cthis idea that top predators are wonderful for the environment and will put everything back to the Garden of Eden\u201d. Allen\u2019s opponents counter that he has failed to show that the poisoning regimens actually reduce dingo population densities. Chris Johnson, an ecologist the University of Tasmania in Hobart, says he is \u201cvery critical\u201d of Allen\u2019s experimental design and methods. The dingo effect is real, says Johnson. Ripple is not worried about these debates, which he views as quibbling over details that do not undermine the overall strength of the tropic-cascade hypothesis. In fact, when he published a major review 10  this year of the effects that predators exert over ecosystems, he left out studies critical of the wolf and dingo trophic-cascade theories; he says that there was no room for them in the space he had to work with. Ripple is particularly concerned with documenting the impacts of Earth\u2019s top carnivores because so many are endangered. \u201cWe are losing these carnivores at the same time that we are learning about their ecological effects,\u201d he says. \u201cIt is alarming, and this information needs to be brought forth.\u201d The debate has been harsh at times, but in quieter moments the different factions all tend to talk in similar terms about the great complexity of ecosystems and the likelihood that the truth lies somewhere in the middle. James Estes, an ecologist at the University of California, Santa Cruz, and one of the fathers of the trophic-cascade idea, says that the evidence for cascades mediated by changes in animal behaviour rather than by changes in animal number is \u201cthin\u201d, at the moment \u2014 and that many of the effects that have been documented are spotty and badly need to be rigorously mapped out. Still, he adds, \u201cWhen all is said and done, and everyone is dead 100 years from now, Bill [Ripple] will be closer to right\u201d. Although Ripple stresses the role of the top carnivores, he agrees they are not the end of the story. \u201cI believe in the combination of top-down and bottom-up, working in unison,\u201d he says. \u201cThey are both playing out on any given piece of ground and the challenge will be to discover what determines their interactions and relative effects.\u201d Schmitz has some thoughts on how to do that. His own smaller-scale work on invertebrates has convinced him that neither bottom-up nor top-down theories adequately capture the story of ecosystems. He is starting to look at the middle players, such as elk, beavers and grass-eating grasshoppers. These herbivores, he says, integrate influences from both the top (such as predation pressure) and the bottom (such as the nutritional quality of plants). \u201cIt is not really bottom-up or top-down but trophic cascades from the middle out,\u201d he says. \u201cThat is where we will evolve. It is knowing what the middle guy is going to do that gives you the predictive ability.\u201d It remains to be seen whether theories such as this middle-out idea will grip researchers and the public as much as the theory of top-down cascades. Many researchers have doubts. They worry that tales of predators shaping their ecosystems are so attractive that they have unrivalled control over discourse. \u201cEveryone likes to think of the big wolf or the big bear looking after the environment,\u201d says Allen. \u201cWe do love a good story.\u201d See Editorial  page 139 Reprints and Permissions"},
{"file_id": "505150a", "url": "https://www.nature.com/articles/505150a", "year": 2014, "authors": [{"name": "Brendan Maher"}], "parsed_as_year": "2006_or_before", "body": "Violent incidents at academic institutions have spurred universities to adopt formal procedures designed to keep campuses safer. But do the tactics work? In many pictures of her online, Kayla Bourque looks like a typical college student: there are selfies of her on a coastal holiday, or smirking mischievously after an experiment in hair colour. But in 2012, Bourque, then a criminology student at Simon Fraser University in British Columbia, told a classmate that she fantasized about killing a homeless person and that she was studying forensics so that she could get away with it. She also talked about killing her family pets and neighbourhood cats. The classmate told a teaching assistant what Bourque had said, and the department chair called campus security. This triggered a formal process called a threat assessment, in which security, university administrators and outside consultants gathered evidence and evaluated Bourque's recent behaviour. They took the allegation seriously, says Stephen Hart, a forensic psychologist at Simon Fraser who advised on the case. \u201cOften something like this is a cry for help,\u201d he says. But her actions on several occasions suggested that she might pose a threat to other students, so simply referring her to the university's outpatient mental-health services would not suffice. The team notified the local police, and told Bourque that she would not be able to return to university without a thorough psychological evaluation. Then, while university employees were packing up her dorm room, they found what has been described in court documents as a 'kill kit': a bag containing a kitchen knife, a razor blade, latex gloves, a syringe and plastic ties \u2014 the kind used to restrain people. \u201cThey realized that this wasn't just a call for help,\u201d says Hart. The discovery led to a search warrant for her computer, on which police found violent pornography, disturbing artwork and more selfies, including one of her standing naked next to her disembowelled dog, Molly. Bourque spent nine months in custody in 2012 for killing Molly, as well as her cat Snowflake, and for possession of a weapon. When she was released it was with an impressive list of probationary conditions, including not using the Internet unsupervised, informing anyone she interacts with about her crimes, never owning a pet, and staying away from Simon Fraser. As horrifying as the case is, Hart sees it as a major triumph for the growing field of threat assessment. Brendan Maher and Gene Deisinger discuss how US university campuses are trying to guard against violent events Although they are exceedingly rare, the number of violent incidents reported on college and university campuses has been increasing. Recently, academic institutions have served as the backdrop to a series of highly publicized attacks \u2014 and sometimes scientists are the central figures. In 2010, Amy Bishop, a biology professor, gunned down three fellow faculty members at the University of Alabama at Huntsville after being denied tenure (see  Nature   465 , 150\u2013155; 2010 ). Two years later, James Holmes withdrew from his PhD studies in neuroscience at the University of Colorado Denver about a month before killing 12 people and wounding 58 at a cinema in Aurora. In many cases, such events are preceded by an escalation in threatening or aberrant behaviour. Holmes had told a university psychiatrist that he fantasized about killing, and Bishop's behaviour allegedly prompted a dean and provost at the university to request police protection months before the attack. Both of these cases are subjects of pending wrongful-death lawsuits. But could the attacks have been prevented? That is the goal of threat assessment, in which organizations adopt formal procedures to identify and mitigate a dangerous situation before it explodes into violence. Threat-assessment teams and plans are becoming standard at colleges and universities in the United States, and are mandatory in some states, including Virginia, Connecticut and Illinois. Other countries are following suit. \u201cThe biggest push we've seen has been in higher education,\u201d says Marisa Randazzo, a social psychologist and former US Secret Service agent who works with a threat-assessment consulting firm. It is difficult to prove that the tactics work, and there are concerns that they may tread on civil liberties, but many see threat assessment as a necessary part of emergency preparedness. \u201cWe live in one of the most violent societies,\u201d says Reid Meloy, a forensic psychologist at the University of California, San Diego. \u201cAnything we can do to mitigate risk is of value and something important to consider.\u201d \n               Roots of violence \n             Talk to anyone in the threat-assessment field about violence on college campuses, and Gene Deisinger's name will inevitably come up. Deisinger was clinical director of the counselling centre at Iowa State University in Ames when the institution decided to build a threat-assessment team. A number of events influenced that decision: in 1986, a former computer-science student set fire to the house of one of his professors, killing two of the professor's children. Then, in 1991, a young physicist at the University of Iowa in Iowa City killed five people and himself, reportedly because he had been passed over for a thesis prize. In response to these and some other incidents, Loras Jaeger, then chief of Iowa State's campus police department, asked Deisinger if he would help to create a threat-management team. \u201cI didn't know what one was, and so I started researching,\u201d Deisinger says. The US Secret Service \u2014 tasked with protecting the president and other public officials \u2014 had a long history of developing methods to assess threats, but that work was not publicly available at the time. Deisinger turned to research on dangerous behaviour, workplace violence and dealing with students in crisis. From that work, he developed an approach for identifying behavioural concerns and intervening in a campus setting. He had a team up and running by 1994. The duties grew quickly, he says, so Jaeger created a full-time position for him within the university police department. During the first month, Jaeger asked Deisinger to report to the state police academy for training, something the 33-year-old psychologist was not eager to do at that stage in his career. But he is glad that he relented. As \u201ca psychologist that carries a badge and a gun, a lot of doors open up\u201d, he says. A campus threat-assessment team is interdisciplinary, and includes law-enforcement professionals, psychologists, academic administrators, representatives from student services and human resources and legal counsel. When someone reports a suspicious behaviour, such as a threat from a student, the team often starts by confronting the person about the behaviour. They may talk to peers, advisers and teachers. By studying past attacks through the lens of psychology, researchers have identified a range of behaviours and environmental factors that may conspire to trigger violence. Individuals may exhibit extreme or sudden changes in behaviour, alienate themselves or others, or adopt unhealthy interests in weapons or violent acts. Environmental factors may include a tolerance to aggressive interactions in a workplace, an unresolved conflict, or the existence of cliques or pecking orders. And there are often precipitating events. These could be personal conflicts or work-life pressures \u2014 such as not getting tenure or a key grant \u2014 that an individual has had trouble dealing with appropriately. Empirical data on attacks suggest that there is a 'pathway to violence': there may be some form of grievance, the development of an intention to do harm, then research, planning and preparation. Bourque, for example, told psychologists that she had been taking a bus into town to check out potential victims, and her 'kill kit' suggested an advanced stage of preparation. But the data can tell only so much, because such attacks are rare. There are no simple checklists and no simple profile of an attacker. If concerns are legitimate and a threat-assessment team decides that a person may be on a trajectory towards violence, then the group works to manage the threat, often by putting the individual in touch with support or mental-health services, or by working out a way to resolve the environmental factors contributing to the situation. Team members may make regular visits, or what Deisinger describes as 'coffee dates'. These are meant to help to keep an eye on people, and unless the person has violated the law or a university rule they are considered voluntary. Most of them are cordial: \u201cI've established a rapport with you that you would at least allow me through the front door, which would allow me to see your living circumstances,\u201d says Deisinger. \u201cIs there evidence of psychotic deterioration? Are there weapons stacked in the corner? Are you taking care of yourself? Is there food there? Is your hygiene intact?\u201d It all sounds a bit Big Brother-ish, and Deisinger doesn't pretend otherwise. These individuals, he says, \u201cknow that I'm doing this. We don't play games with it, most of the time.\u201d Still, he says, it can be surprising how open people often are. Bourque \u201ctalked freely\u201d to the threat-assessment team that evaluated her, says Hart, and even gave them permission to pack up her residence, which was where they spotted the 'kill kit'. Threat assessment works only when people have signalled an intent to do harm. Luckily, these signals often appear. In the 1990s, the Secret Service looked at 83 individuals who had attacked or come close to attacking a prominent public official or public figure. It showed that 63% had communicated some sort of threat in advance, although rarely to the intended target 1 . \u201cThe people who carry out these acts, they typically tell someone what they're planning to do,\u201d says Randazzo. \u201cWe've seen many cases where they broadcast it on social media.\u201d \n               20/20 Hindsight \n             In November 2005, campus security at Virginia Polytechnic Institute and State University in Blacksburg received a report about Seung-Hui Cho, a South Korean-born student studying English who was allegedly harassing a female student. A room-mate added that Cho had made comments about contemplating suicide. Cho was assessed three times and said that the suicidal statements were a joke. He was briefly hospitalized. In February and March of 2007, Cho bought two pistols; in April, he killed 32 people in what is, so far, the deadliest campus shooting in history. The incident launched a national study on campus attacks by the Secret Service, the US Federal Bureau of Investigation and the US Department of Education. It collected information on 272 incidents in the United States between 1900 and 2008. The study showed that such events are rare \u2014 but that they are increasing in frequency 2 . For instance, the report catalogues only 25 incidents between 1970 and 1979, but 83 between 2000 and 2008 (see 'Dangerous trend'). The rise in student numbers is certainly a factor in the increase, and it is likely that more incidents are being reported than in the past. But those changes might not fully account for the trend, says Andre Simons, a behavioural scientist with the FBI who is working on a follow-up to the report. The study also revealed the varied nature of attacks occurring in a university setting. Students or former students accounted for 60% of the perpetrators, and another 11% were employees. But the remaining 29% were not official members of the campus. It is hard to say whether the individuals posed clear threats before their attacks. Nearly 30% of perpetrators displayed threatening behaviour, such as stalking or harassing, making verbal or written threats, or being physically aggressive towards their targets. Another 20% exhibited at least some sort of concerning behaviour to a friend, family member, work associate or police officer. But such behaviours could be vague and general, and were not always reported. In Cho's case, there were signs of aberrant behaviour, but no process was in place to follow him in an exhaustive way, says Deisinger. After the shooting, Deisinger consulted with Virginia Tech to help build a threat-assessment team there, and he was eventually hired as the university's chief of police. The Virginia Tech shooting was a pivotal case that spurred more universities to develop such teams, says Meloy, although how many exist is unclear. A self-reported survey from 2012 found that 92% of universities and community colleges in the United States have some sort of team in place 3 , but it included other kinds of behavioural-intervention teams that do not typically work directly with the police. The trend is not limited to the United States: universities in Australia have increasingly been taking an interest in threat-assessment procedures; and an estimated ten universities in German-speaking countries have established or developed plans for teams, says Jens Hoffmann, a psychologist at the Institute of Psychology and Threat Management in Darmstadt, Germany, and co-editor with Meloy of the  International Handbook of Threat Assessment  (Oxford Univ. Press, 2014). \n               Safe and sound? \n             These systems and tactics for managing threats cannot stamp out all targeted violence. In 2009, after Virginia Tech had established its threat-assessment team but before Deisinger had arrived, a graduate student in agricultural economics beheaded a woman who had rebuffed his romantic advances. And a team was in place at the University of Colorado where Holmes made threats to a mental-health professional, but Holmes left the university shortly after, making it difficult to follow up on the case. There are bound to be missed signals, says Deisinger. And threat assessment is only as good as the vigilance of a community, because it relies heavily on reporting. But in the wake of recent high-profile shootings, this vigilance has improved, says Randazzo. \u201cPeople are reporting things that seem not right in ways that they didn't in the past.\u201d Many cite the \u201csee something, say something\u201d campaigns that have blanketed New York City since the terrorist attacks of 11 September 2001 as having helped to encourage people to report suspicious behaviour. But a team is useless if no one knows about it, so Deisinger and others have tried to spread the word by creating websites and fliers, as well as holding training sessions on how to deal with inappropriate behaviour. There are costs to all this watchfulness, however, says Joe Cohn, legislative and policy director for the Foundation for Individual Rights in Education in Philadelphia, Pennsylvania. \u201cIt's not unusual for universities to engage in behaviours that chill freedom of speech in the name of safety,\u201d he says. He cites recent examples in which a student was expelled for protesting over the construction of a parking garage and a professor was reported to a threat-assessment team for hanging posters with aggressive messages outside his office. He urges teams to include civil libertarians to better ensure that universities do not encroach on people's rights. It is also difficult to prove that having a threat-assessment team makes a campus any safer. There are no standards for how to report a successful case, and privacy concerns make the sharing of data complicated. Deisinger says that his team tracks cases to see whether interventions have improved the situation for the individual and the people around him or her. \u201cMost of them, we can resolve to a level that is akin to the day-to-day moderately inappropriate behaviour,\u201d he says. It is not ideal, \u201cbut it's liveable\u201d, he adds. The field is trying to set standards and collect data on how well the process works. Phase two of the FBI's campus-attacks study, which will focus on attacks that happened between 1985 and 2010, may fill in some of these holes. These are all concerns that weigh heavily on Deisinger. But what worries him most is the thought that someone, somewhere, is planning something that no one can anticipate. \u201cI'm often asked, because of the cases we work, 'How do you sleep at night?'\u201d He does not worry so much about people who have already been identified by his team. \u201cIt's the cases I don't know about,\u201d he says, \u201cthat give me difficulty sleeping.\u201d \n                 See Editorial \n                 page 131 \n               \n                     Firearms research: The gun fighter 2013-Apr-24 \n                   \n                     Animal research: Battle scars 2011-Feb-23 \n                   \n                     University seeks to emerge from shooting's shadow 2011-Feb-08 \n                   \n                     Universities: Life after death 2010-May-12 \n                   \n                     Threat Assessment at Viginia Tech \n                   \n                     The Association of Threat Assessment Professionals \n                   \n                     National Behavioral Intervention Team Association \n                   \n                     Foundation for Individual Rights in Education \n                   Reprints and Permissions"},
{"file_id": "507026a", "url": "https://www.nature.com/articles/507026a", "year": 2014, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Chemists are reinventing rechargeable cells to drive down costs and boost capacity. The mobile world depends on lithium-ion batteries \u2014 today's ultimate rechargeable energy store. Last year, consumers bought five billion Li-ion cells to supply power-hungry laptops, cameras, mobile phones and electric cars. \u201cIt is the best battery technology anyone has ever seen,\u201d says George Crabtree, director of the US Joint Center for Energy Storage Research (JCESR), which is based at the Argonne National Laboratory near Chicago, Illinois. But Crabtree wants to do much, much better. Modern Li-ion batteries hold more than twice as much energy by weight as the first commercial versions sold by Sony in 1991 \u2014 and are ten times cheaper. But they are nearing their limit. Most researchers think that improvements to Li-ion cells can squeeze in at most 30% more energy by weight (see 'Powering up'). That means that Li-ion cells will never give electric cars the 800-kilometre range of a petrol tank, or supply power-hungry smartphones with many days of juice. In 2012, the JCESR hub won US$120 million from the US Department of Energy to take a leap beyond Li-ion technology. Its stated goal was to make cells that, when scaled up to the sort of commercial battery packs used in electric cars, would be five times more energy dense than the standard of the day, and five times cheaper, in just five years. That means hitting a target of 400 watt-hours per kilogram (Wh kg \u22121 ) by 2017. Crabtree calls the goal \u201cvery aggressive\u201d; veteran battery researcher Jeff Dahn at Dalhousie University in Halifax, Canada, calls it \u201cimpossible\u201d. The energy density of rechargeable batteries has risen only sixfold since the early lead\u2013nickel rechargeables of the 1900s. But, says Dahn, the JCESR's target focuses attention on technologies that will be crucial in helping the world to switch to renewable energy sources \u2014 storing up solar energy for night-time or a rainy day, for example. And the US hub is far from alone. Many research teams and companies in Asia, the Americas and Europe are looking beyond Li-ion, and are pursuing strategies that may topple it from its throne. \n               Lose the dead weight \n             Chemical engineer Elton Cairns suspected he had tamed a promising-but-wild battery chemistry early last year, when his coin-sized cells were still going strong even after a few months of continual draining and recharging. By July, his cells at the Lawrence Berkeley National Laboratory in Berkeley, California, had cycled 1,500 times and had lost only half of their capacity 1  \u2014 a performance roughly on a par with the best Li-ion batteries. His batteries are based on lithium\u2013sulphur (Li\u2013S) technology, which uses extremely cheap materials and in theory can pack in five times more energy by weight than Li-ion (in practice, researchers suspect, it will probably be only twice as much). Li\u2013S batteries were first posited 40 years ago, but researchers could not get them to survive past about 100 cycles. Now, many think that the devices are the technology closest to becoming a commercially viable successor to Li-ion. One of Li\u2013S's main advantages, says Cairns, is that it gets rid of the \u201cdead weight\u201d in a Li-ion battery. Inside a typical Li-ion cell, space is taken up by a layered graphite electrode that does little more than host lithium ions. These ions flow through a charge-carrying liquid electrolyte into a layered metal oxide electrode. As with all batteries, current is generated because electrons must flow around an outside circuit to balance the charges (see 'Radical redesigns'). To recharge the battery, a voltage is applied to reverse the electron flow, which also drives the lithium ions back. In a Li\u2013S battery, the graphite is replaced by a sliver of pure lithium metal that does double duty as both the electrode and the supplier of lithium ions: it shrinks as the battery runs, and reforms when the battery is recharged. And the metal oxide is replaced by cheaper, lighter sulphur that can really pack the lithium in: each sulphur atom bonds to two lithium atoms, whereas it takes more than one metal atom to bond to just one lithium. All of that creates a distinct weight and cost advantage for Li\u2013S technology. But the reaction between lithium and sulphur causes a problem. As the battery is charged and discharged, soluble Li\u2013S compounds can seep into the electrolyte, degrading the electrodes so that the battery loses charge and the cell gums up. To prevent this, Cairns uses tricks made possible by advances in nanotechnology and electrolyte chemistry \u2014 including adulterating his sulphur electrode with graphene oxide binders, and using specially designed electrolytes that do not dissolve lithium and sulphur so much. Cairns predicts that a commercial-sized cell could achieve an energy-density of around 500 Wh kg \u22121 . Other labs are reporting similar results, he says. Some researchers doubt that the academic cheer will translate into commercial success. Laboratories often use low proportions of sulphur and lots of electrolyte, which is relatively easy to work with but does not create an energy-dense battery. Bumping up the sulphur and decreasing the electrolyte makes the cell more likely to gum up, says Steve Visco, who has spent more than 20 years working on Li\u2013S at battery firm PolyPlus in Berkeley, just 5 kilometres west of Cairns' lab. Making a cheap commercial cell that works over a range of temperatures will also be hard, he says. At least one company stands by Li\u2013S's prospects: Oxis Energy in Abingdon, UK. It says it has run large cells for an impressive 900 cycles, at energy densities that match current Li-ion cells. Oxis is working with Lotus Engineering, headquartered in Ann Arbor, Michigan, on a project to reach 400 Wh kg \u22121  by 2016 for an electric vehicle. \n               Pack more punch per ion \n             As the world's lightest metal, lithium provides a huge weight advantage. But some researchers argue that the next generation of cells should switch to heavier elements such as magnesium. Unlike lithium ions, which can carry only one electrical charge each, doubly charged magnesium ions shuttle two at a time \u2014 instantly multiplying the electrical energy that can be released for the same volume. Magnesium comes with its own challenge, however: whereas lithium zips through electrolytes and electrodes, magnesium with its two charges moves as if through treacle. Peter Chupas, a battery researcher at Argonne National Laboratory who is working with the JCESR, is shooting high-energy X-rays at magnesium in various electrolytes to investigate why it experiences so much drag. So far, he and his colleagues have found that magnesium exerts a strong pull on oxygen atoms in any surrounding solvent, attracting clusters of solvent molecules that make it bulkier. That kind of basic research is key to creating a better battery, but it is not usually done by industry, says Crabtree. \u201cThe typical R&D operation operates on trial and error, not fundamental research,\u201d he says. This, he says, is where JCESR is bringing an advantage to the field. Materials scientist Kristin Persson at Lawrence Berkeley is using a supercomputer to simulate the innards of possible new batteries, trying to find a combination of electrodes and electrolytes that will allow magnesium to pass through more easily. \u201cRight now, we are crunching through around 2,000 different electrolytes,\u201d she says. Persson and Gerbrand Ceder, a materials scientist at the Massachusetts Institute of Technology in Cambridge, founded a company to develop these higher-charge-carrying batteries. Pellion Technologies, based in Cambridge, is tight-lipped about its results; it has published only one paper about electrolytes 2 . A spate of patents published in late 2013 hint that the company is developing more-open electrode structures to help the magnesium ions to flow. Major electronics firms such as Toyota, LG, Samsung and Hitachi are also working on such cells, releasing little information beyond occasional teasers. As companies jostle in secret, Persson continues to run through what she calls the \u201celectrolyte genome\u201d. The sifting-by-supercomputer approach could also help the search for batteries made with other multiple-charge-carrying (or 'multivalent') metals, such as aluminium and calcium. Ceder urges patience, pointing out that research into Li-ion battery chemistry has enjoyed a 40-year head start. \u201cWe have so little information about multivalent ions,\u201d he says. \n               Make batteries that breathe \n             Winfried Wilcke, who describes himself as \u201can extremely happy owner of a Tesla S\u201d electric car, credits the vehicle with changing his mind about battery-research priorities. Five years ago, Wilcke, who heads IBM's nanoscience and technology division in San Jose, California, launched a project to develop a car battery with an 800-kilometre range. At the start, he focused on the theoretical ultimate in energy-dense electrochemical storage: the oxidation of lithium with oxygen drawn from the air. Such 'breathing' batteries have a huge weight advantage over other types, because they do not have to carry around one of their main ingredients. A lithium\u2013oxygen (Li\u2013O) battery can, in theory, store energy as densely as a petrol engine \u2014 more than ten times better than today's car battery packs. But after driving more than 22,000 kilometres in his electric roadster, Wilcke is happy with the 400-kilometre range that its battery already provides. The real problem, he says, is money: battery packs for electric cars cost more than $500 kWh \u22121 . \u201cWhat's holding back the mass acceptance of electric cars is really the price rather than the energy density,\u201d he says. So Wilcke now favours a cheaper breathing battery based on sodium. Theory predicts that sodium\u2013oxygen (Na\u2013O) batteries could provide only half the energy density of Li\u2013O, but that is still five times better than Li-ion batteries. And sodium is cheaper than lithium, so Na\u2013O might, Wilcke hopes, get closer to the $100-kWh \u22121  goal that the JCESR and others have set for affordability. Wilcke's change of heart was undoubtedly influenced by the fact that many have given up hope on Li\u2013O. Researchers who have tried to make it work over the past 20 years have wrestled with unwanted side reactions: carbon in the electrolyte and electrode material react with the lithium and oxygen to form lithium carbonate, so that in every cycle, some 5\u201310% of the battery capacity is lost. After 50 cycles or so, the battery suffocates. \u201cThe bottom line is that Li\u2013O has zero chance for vehicles,\u201d says Stanley Whittingham at Binghamton University in New York, who invented the concept of Li-ion batteries in the 1970s and still focuses on squeezing the best performance out of them. Researchers hoping to resuscitate Li\u2013O include Peter Bruce, a chemist at the University of St Andrews, UK. \u201cWe are closer to what's needed than we were a few years ago,\u201d he argues. But many consider it a lost cause. Wilcke took an interest in the sodium breathing battery last year, following a surprising discovery by a team including J\u00fcrgen Janek and Philipp Adelhelm at the Justus-Liebig University of Giessen in Germany. They found that a Na\u2013O battery recharges more efficiently than Li\u2013O, without complicating side-reactions 3 . \u201cWe tried it and were pretty stunned,\u201d says Wilcke. Plus, he says, it works with cheap electrodes and electrolytes. Janek says that his team has now shown that its battery can work reversibly for at least 100 cycles \u2014 not bad for the early days of the technology. Chemicals giant BASF is now working with them. Dahn, for one, is not convinced. Debate rages about whether breathing batteries will require heavy filtering equipment to extract oxygen from the air, which would cut down or even eliminate their energy-per-weight advantage. \u201cNa\u2013O is just the latest craze,\u201d says Dahn. But Wilcke is willing to bet otherwise. \n               Go big for the grid \n             Donald Sadoway's vision of the future battery looks like a smelting plant: he envisions crates the size of shipping containers, each holding 20 refrigerator-sized steel blocks containing litres of molten metals and salts heated to 500 \u00b0C. Such batteries could never fit in a car, and cannot beat Li-ion on measures such as energy stored per unit weight. But when it comes to storing energy for the electricity grid \u2014 or other non-portable applications \u2014 size does not matter. Instead of a small, light battery that packs a powerful punch, what people need is a battery that cheaply bottles and releases small-to-large amounts of electricity without much maintenance. The JCESR wants such batteries to last for 7,000 cycles, or about 20 years. \u201cThe field is wide open,\u201d says Ceder. Grid suppliers have used banks of cheap, old-fashioned lead\u2013acid batteries, for example, or stacks of Li-ion. A dizzying array of other chemistries are in development, including zinc\u2013air and sodium-ion. Most technologies are doing well to cost five times as much as the JCESR's $100-kWh \u22121  target. Sadoway, a materials chemist at the Massachusetts Institute of Technology, is developing an alternative with two layers of molten metal as electrodes, separated by their different densities and by a layer of molten-salt electrolyte. The metal layers swell or shrink as ions pass between them, storing or releasing energy. Because everything is liquid, there is nothing that could crack after thousands of cycles, as solid electrodes might. Crabtree, Dahn and other researchers worry about the energy needed to keep the components molten. But Sadoway says that the charging and discharging processes produce enough heat on their own. His company \u2014 Ambri in Marlborough, Massachusetts \u2014 plans to install test batteries in Hawaii and at a military base on Cape Cod, Massachusetts, this year, each supplying tens of kilowatt-hours. Other research groups are pursuing less-radical flow batteries, in which the fuel consists of two liquids that pass ions to each other through a membrane. The liquids can be kept in tanks outside the battery and pumped in to flow past each other when needed, so it is possible to store larger amounts of energy indefinitely simply by using bigger tanks. But they do need pumps and valves, which Sadoway says will require maintenance. Commercial flow batteries use vanadium ions in the liquid on both sides of the barrier. But vanadium and the membranes are expensive: the world's largest flow battery, installed at a wind farm in China, probably costs $1,000 kWh \u22121 , estimates Huamin Zhang at the Chinese Academy of Sciences' Dalian Institute of Chemical Physics. \u201cThe cost of vanadium just kills you,\u201d says Michael Aziz, a materials scientist at Harvard University in Cambridge, Massachusetts. In January this year, a team including Aziz announced 4  that cheap organic chemicals called quinones could be used in a flow battery, partnered to a standard liquid electrode such as bromine. Aziz has cycled his system more than 100 times and it is still running strong. He hopes that he can get such batteries below the magic $100 kWh \u22121 , but \u201cthis is a toy in a fume hood in a laboratory right now\u201d, he says. \u201cThere is no way to know the true cost until you are mass-producing it.\u201d Crabtree calls the work \u201cpromising\u201d and says that the JCESR is also looking at organic chemicals for flow batteries. Another option it is pursuing is to use liquid Li\u2013S and solid lithium in a sort of half-flow battery. \u201cIt's early days: people are looking at really oddball systems, and everyone's trying to figure out how to get the lifetime up and the costs down,\u201d says Dahn. The JCESR, for one, is hoping that basic research can fill in the gaps and make these technologies work. \u201cThe beyond-lithium-ion space is rich with opportunity,\u201d says Crabtree, \u201cand mostly unexplored.\u201d \n                     Cheap battery stores energy for a rainy day 2014-Jan-08 \n                   \n                     Sulphur back in vogue for batteries 2013-Jun-26 \n                   \n                     Car industry: Charging up the future 2008-Nov-26 \n                   \n                     Building better batteries 2008-Feb-06 \n                   \n                     Joint Center for Energy Storage Research \n                   \n                     IBM Battery 500 project \n                   \n                     Oxis Energy \n                   \n                     Pellion \n                   \n                     Ambri \n                   \n                     US Energy Storage Association: Redox flow batteries \n                   Reprints and Permissions"}
]