[
{"file_id": "nature.2016.21225", "url": "https://www.nature.com/articles/nature.2016.21225", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Political compromise settles immigration row that could have severed Swiss\u2013EU research agreements. A row over immigration that threatened to exclude Swiss-based scientists from European Union research programmes has been resolved, although some politicians are pressing to reopen the debate next year. From 2017, Switzerland\u2019s scientists will once again enjoy full access to the EU\u2019s \u20ac80-billion (US$83-billion) Horizon 2020 research programme, the European Commission  announced on 20 December . Four days earlier, Switzerland\u2019s parliament had decided to water down controversial immigration controls that would have had the knock-on effect of severing Swiss\u2013EU research agreements. \u201cIt\u2019s not just about the money, it\u2019s about being part of the European scientific community,\u201d says Matthias Egger, an epidemiologist at the University of Berne who will become president of the Swiss National Science Foundation's research council in January. \u201cResearch is not something you do in isolation, and you need to compete with the best.\u201d Switzerland is not an EU member, but it has signed bilateral agreements with the bloc on key policy areas, including research. The country has been participating in EU research programmes since 1988, and in 2004, it became a full associate partner. That allowed Swiss-based scientists to lead EU-funded research consortia, and Swiss institutes to host scientists on prestigious European Research Council (ERC) grants. Switzerland pays into the EU research programme\u2019s budget for the privilege. But in February 2014, the Swiss public voted to limit immigration in a legally binding referendum. As a result, Switzerland\u2019s government could not sign an agreement with the European Commission to allow free movement of people from Croatia, at the time a new EU member state. And because the free movement of EU citizens is a non-negotiable tenet of membership of EU programmes,  Switzerland\u2019s relationship with Horizon 2020 was thrown into confusion . \n             Seeking compromise \n           By September 2014, negotiators had cobbled together an interim agreement for a \u2018partial\u2019 association, allowing continued participation in some parts of Horizon 2020, including competitive programmes in basic research such as the ERC and the Marie Sk\u0142odowska-Curie international postdoctoral programmes. But the agreement was scheduled to run out at the beginning of February 2017, when the outcome of the referendum vote had to be written into Switzerland\u2019s constitution. During this period, says Egger, \u201cwe didn\u2019t get so many letters asking us to collaborate on EU research proposals, and saw that foreign scientists were starting to see Switzerland as a less attractive place to work\u201d. This December, with time running out, the Swiss parliament found a compromise. It will not put limits on immigration, but employers in professions or regions where unemployment is above the national average must in future interview Swiss job seekers for any vacancy \u2014 although they will not be obliged to select them. The commission says this law is compatible with its principle of free movement, and it agreed that Switzerland could resume its status as associate member on 1 January. The debate isn\u2019t over. Some Swiss populist parties say that their parliament\u2019s compromise is a betrayal of the 2014 referendum vote \u2014 and may push for a second referendum on the migration issue, Swiss media report. That could plunge science into uncertainty again. \n                   Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                 \n                   Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                 \n                   EU\u2013Swiss research on shaky ground 2014-Feb-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21190", "url": "https://www.nature.com/articles/nature.2016.21190", "year": 2016, "authors": [{"name": "James Randerson"}], "parsed_as_year": "2006_or_before", "body": "Revelation from drug firm Bial prompts criticism from pharmacologists. Criticism of the drug company at the centre of a disastrous clinical trial that left one participant dead and four with long-term neurological symptoms has intensified following a revelation that the firm did not use certain data when deciding to administer a higher dose that proved deadly. On 15 December, during a conference presentation by a scientist from the Portuguese company, Bial, it emerged that the firm did not use certain readings, called pharmacodynamic (PD) data, on how the drug BIA 10-2474 was acting in participants who had received a lower dose, before taking the decision to increase the dosage. \u201cThis was a revelation as far as we are concerned,\u201d says David Webb, president of the British Pharmacological Society (BPS), which hosted the conference in London. The trial, which was carried out in Rennes, France,  took a tragic turn in January .\u00a0 \n             Safety evaluation \n           Helena Gama, head of Bial\u2019s pharmacovigilance and drug safety office, spoke for the company at the BPS meeting. When asked why the company had not included the PD data in its dose-escalation decision, she said: \u201cThe evaluation before starting a new drug escalation is based on safety evaluation and pharmacokinetic data\u201d \u2014 referring to other data on how the drug is absorbed, distributed, metabolized and excreted by the body. \u201cWe did not have any profile that precluded the path to the further dosage.\u201d Bial was not legally required to use PD data, and its trial protocol had been signed off by France\u2019s medical regulator, the National Agency for the Safety of Medicines and Health Products (ANSM). But experts in pharmacology and clinical-trial design say that the company should have included these readings. \u201cWithout the PD data, they were flying blind. That\u2019s when accidents happen,\u201d says Webb. \u201cI think that was negligent.\u201d Catherine Hill, a biostatistician who previously served on the ANSM\u2019s scientific advisory board, is also surprised that Bial did not take PD data. \u201cThis seems incredible,\u201d she says. \u201cFlying blind is a perfect image.\u201d\u00a0 It is best practice to use PD data, although not every trial does, notes Munir Pirmohamed, a molecular and clinical pharmacologist at the University of Liverpool, UK. \n             First in humans \n           The Bial trial was the first to test BIA 10-2474 in humans. It was designed to explore whether the drug, which had already been tested in mice, dogs, monkeys and rats, is safe to use in people. In particular, says Webb, it was important to collect PD data because BIA 10-2474 is relatively unselective, meaning that it could have effects in addition to its intended target in the body. The drug binds an enzyme called fatty acid amide hydrolase (FAAH) \u2014 an activity that might make it effective at treating anxiety and motor disorders associated with Parkinson\u2019s disease, as well as chronic pain in people with conditions such as cancer. PD data can reveal when the copies of the enzyme in the brain are close to being saturated with the drug, a point at which levels of free-floating drug may rise steeply with increasing dose, and potentially lead to unexpected \u2018off-target\u2019 effects on other enzymes. Critics at the BPS meeting suspect that because the company was not including PD data in its decision to up the dose, it did not realize that FAAH was already saturated. But Bial does not accept this conclusion. \u201cAll official reports about the trial were inconclusive and all have considered this event as unpredictable, and that there was no indication whatsoever, including in the pre-trials, that could have predicted this outcome,\u201d said a company spokesperson. Both French authorities and the European Medicines Agency in London have published updated guidance on first-in-human clinical trials since the tragedy. And a separate report by the ANSM made six recommendations to improve the conduct of future trials. \n             Memory loss \n           Gama also released new data on four trial participants who survived but became ill: she said that they had not yet recovered from neurological symptoms including memory loss, headaches, motor disorders and tremors. She also listed ten instances of neurological side effects, including dizziness and blurred vision, in other volunteers who were given lower doses of the drug, although she stressed that these were mild and transient. The long-term impact on the health of the more severely affected volunteers had not been clear previously, but the fact that they are still experiencing symptoms underlines the conclusion that the fatal reaction to the drug was not a one-off, says Webb. \u201cThat\u2019s the first time we know they are not well \u2014 that they are still damaged in some way.\u201d Since the trial, Bial has come under  intense pressure from the scientific community  to release all data relating to the trial and pre-clinical work. The BPS presentation revealed some such data, but calls for transparency are intensifying. \u201cIsn\u2019t it time that this whole amount of data is released officially so that we can all have a discussion about it?\u201d asked Adam Cohen, a clinical pharmacologist at Leiden University in the Netherlands, and editor-in-chief of the  British Journal of Clinical Pharmacology . In particular, he says, the company should release its \u2018investigator\u2019s brochure\u2019, the dossier of pre-clinical work on the drug, plus the full human data from the trial itself. When quizzed by Cohen and Webb on why the company has still not released the data 11 months after the fatal trial, Gama refused to make a specific commitment to release them. But she added: \u201cWe don\u2019t have any issue regarding releasing data to the scientific community.\u201d \n                   Researchers question design of fatal French clinical trial 2016-Jan-22 \n                 \n                   Scientists in the dark after French clinical trial proves fatal 2016-Jan-18 \n                 \n                   Fresh light thrown on tragic drug trial 2007-Jan-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21227", "url": "https://www.nature.com/articles/nature.2016.21227", "year": 2016, "authors": [{"name": "Lisa Vincenz-Donnelly"}], "parsed_as_year": "2006_or_before", "body": "Small study suggests long-sought biological marker for brain injuries. A test that records the way the brain processes sound might provide a simple and reliable measure of concussion, a small study suggests. If the method works, it could help scientists work out how best to treat the poorly understood brain injury. In a  paper published on 22 December in  Scientific Reports 1 , neuroscientist Nina Kraus of Northwestern University in Evanston, Illinois, and other researchers say that they have found that a particular signal in neural activity, recorded with electrodes placed on the head as children listen to 'da' sounds from a speech synthesizer, can objectively demarcate concussed children from a healthy control group. The research was done on just 40 people \u2014 a tiny group \u2014 and will have to be repeated in larger samples. But other researchers are still excited by the report, because concussion is hard to diagnose, particularly in children. The study \u201cmay for the first time offer a simple and objective biomarker to measure the severity of brain injuries\u201d, says Thomas Wisniewski, a neurologist at New York University\u2019s Langone Medical Center. There is intense interest in finding a clear-cut biological signature for concussion, he says. \u201cWe have been crying out for a reliable method.\" Millions of people enter hospitals every year with blows to the head, and some of have concussion, a minor brain injury that can betoken more serious damage. To diagnose it, physicians rely on subjective complaints of dizziness, coordination tests and sometimes more involved procedures, such as magnetic resonance imaging (MRI) or computed tomography (CT) scans. But there\u2019s no single objective way to detect concussion and measure its severity \u2014 and no simple test that can be administered regularly to determine when someone has recovered, a particularly important issue for athletes keen to be allowed back on the field. \n             Child-friendly tests \n           Besides brain scans, some companies have tried searching for particular proteins in the blood released after brain injuries \u2014 but haven\u2019t yet shown unambiguous proof that these are a consistent measure of concussion, Wisniewski says. And even if blood tests do work, they are hard to justify for young children who have hit their heads, notes trauma surgeon Christian Kammerlander of the university hospital at the Ludwig Maximilian University of Munich in Germany. \u201cWe always try to avoid the drama of taking blood from young children after a traumatic accident.\u201d Researchers are particularly interested in finding a way to track concussion in children, to measure its long-term effects on brain health. But children are difficult to diagnose with concussion, because they often report their symptoms less clearly than adults. Kraus thought that measuring brain activity in response to sound might provide an objective measure of the problem, because concussed people can find it hard to process sounds in noisy environments. She worked with Cynthia LaBella, a sports doctor at the Ann & Robert H. Lurie Children\u2019s Hospital of Chicago in Illinois, to study the brain activity of 20 children aged between 11 and 15, four weeks after clinicians had pronounced them to be concussed following sports accidents. The team compared the results with the brain activity of healthy children. \n             Signal from noise \n           Kraus says that her team picked out an objective neural signature that correctly identified 90% (18 out of 20) of the concussed children, and ruled out 95% (19 out of 20) of the healthy control group. \u201cThe sensitivity is impressive,\u201d says Wisniewski, \u201ceven though the number of children in the study is very small.\u201d The impairment seemed to be most pronounced in the children with the most serious symptoms. And when some of the children returned to the clinic and reported improvements \u2014 such as fewer episodes of dizziness or less difficulty concentrating \u2014 their neural responses to sound likewise improved. Much more work needs to be done on larger groups of people, says Kraus. Her team is now testing the auditory responses of athletes immediately after head injury and several weeks later. She hopes to commercialize her research, and is working with colleagues to reduce the cost and size of the hardware required, to create a concussion-detection kit for use in labs or at sports grounds. \n                   Researchers seek definition of head-trauma disorder 2015-Feb-25 \n                 \n                   Brain damage on the playing field 2011-Feb-24 \n                 \n                   Health problems linger in concussed veterans 2008-Jan-30 \n                 Reprints and Permissions"},
{"file_id": "540500a", "url": "https://www.nature.com/articles/540500a", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Includes storms from space, southern stars and a striking cell. In a year of political turmoil and shock, science, too, came up with surprises. To document some of these wonders, photographers roamed the world, revealing objects from the microscopic to the cosmic in scale. \n               STRIKING CRANES \n             Hundreds of thousands of sandhill cranes ( Grus canadensis ) converge on Platte River in Nebraska as part of their annual migration. Photographer Randy Olson was taking long-exposure shots in March when lightning struck, creating these ghostly outlines. \n               ANCIENT IVORY \n             The vast tusk of a long-dead mammoth is carried out of a forest in Yakutia, Siberia. Ancient ivory from mammoths has become so valuable that some prospectors now illegally \u2018mine\u2019 them from permafrost. A large tusk can be worth tens of thousands of dollars. \n               EN ROUTE \n             This long-exposure shot shows the November launch of a Soyuz spacecraft from the Baikonur Cosmodrome in Kazakhstan. It ferried Peggy Whitson, Oleg Novitskiy and Thomas Pesquet to the International Space Station. \n               FANTASTIC FOOT \n             This spectacular tarsus \u2014 the lowermost segment of an insect leg \u2014 is roughly\u20092\u00a0millimetres in diameter and belongs to a male diving beetle, which uses it to attach to a female\u2019s back during mating. \n               FIRST GLEAMING \n             The largest and most accurate radiosurvey of the southern sky was unveiled in October by the high-resolution Galactic and Extragalactic All-sky Murchison Widefield Array (GLEAM) project. The Milky Way flows through this image, which encompasses more than 300,000 galaxies. \n               CHINA CHANGES \n             China this year revealed ambitious plans to cut coal use and pollution and to embrace renewable energy. But this steel plant in Inner Mongolia is just one example of the many industries that stand in the way of that reform. \n               SPACE STORMS \n             Far below the International Space Station, lightning flashes illuminate the clouds, as human activity is revealed by clusters of lights. Two Russian spacecraft visiting the station can be seen in the foreground. \n               CRYSTAL STEPS \n             These strange structures are calcium carbonate crystals, imaged at 2,000\u00d7 magnification. \n               SACRED SYMBOLS \n             In April, remarkable images of ancient Egyptian tattoos found on a mummy were shown at a meeting of the American Association of Physical Anthropologists. The tattoos include two seated baboons and a symbol of protection on the mummy's neck. \n               SEE-THROUGH AND SMALL \n             In August, a team in Germany unveiled \u2018ultimate DISCO\u2019\u00a0\u2014\u00a0a technique that both renders tissues transparent and shrinks specimens, so that a whole animal can be imaged in one go. The technique can reveal the nervous system and organ systems within a body in unprecedented detail. \n               STRIKING CELL \n             This human stem cell is just 15 micrometres across, and was false-coloured after being imaged using cryogenic scanning electron microscopy. \n               A PERSONAL VIEW OF THE NEWS \n             In compiling this year\u2019s collection of stunning photographs, members of the  Nature  team each identified an image that said something special about science. Here is their personal take on the past 12 months. \n               SHARK WATCH \n             Lizzy Brown  (Associate media editor): \u201cThis picture of a blacktip reef shark ( Carcharhinus melanopterus ) was taken by James Lea on a field trip in the Seychelles earlier this year. Lea and his colleagues have been  tracking sharks \u00a0to test the effectiveness of local marine protected areas. The image stood out thanks to its simple composition and the way it evokes a sense of eerie calm, with the menace of the shark lurking just beneath the surface.\u201d \n               MIRROR IMAGE \n             Greg Kendall-Ball  (Media editor): \u201cWhen I came across this picture, I had to do a double-take to figure out what it was I was seeing. While some deployed specialist equipment to safely watch the 1 September annular eclipse, these people in Tanzania simply made use of a dark puddle. We\u2019re used to conventional photographic or television renderings of these phenomena, but this different angle, this improvisation, struck me.\u201d \n               CALM REFLECTION \n             Daniel Cressey  (Senior reporter): \u201cImages of flooding often focus on the dynamic power of these events \u2014 dramatic escapes from rising waters or items being carried away by raging cataracts. This is a different, and in many ways as scary, view \u2014 the total calm and absence of people in the aftermath of floods in Denham Springs, Louisiana, in August.\u201d \n               POWER PLAY \n             Ffion Cleverley  (Media editor): \u201cAlastair Philip Wiper\u2019s fascination with factory floors, machinery and negative space is always a joy to see. This unusual image from his visit to the High Voltage Laboratory at the Technical University of Denmark in June stuck with me for the rest of the year.\u201d \n               UP IN FLAMES \n             Chris Maddaloni  (Managing photo editor): \u201cI was quite taken with the apocalyptic scenes of the oil fires burning during the Mosul offensive in Iraq that came over the wires this year. Many of the photos emphasized the low, black skies or semi-posed people in front of the flames. Although the scale of the man in this photo, surrounded by raging flames, was compelling, it was the mysterious film-still-like tone to this image that really stood out. The massive environmental damage and scope of these fires seem to be a symbol of the human cost exacted in this region.\u201d \n               FINAL FROG \n             Kelly Krause  (Creative director): \u201cIf I have one photography soft spot, it\u2019s frogs. The shine, that smile, the eyes you fall into. This one, shot by legendary wildlife photographer Joel Sartore, is the world\u2019s last Rabbs\u2019 fringe-limbed tree frog ( Ecnomiohyla rabborum ), named Toughie. He died this year \u2014 his species is now extinct.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     2016 in news: The science events that shaped the year 2016-Dec-16 \n                   \n                     An expensive dodo, an even more expensive telescope, and a \u2018fog rainbow\u2019 2016-Dec-01 \n                   \n                     Martian clouds form, a frozen ship heads home and an orangutan goes climbing 2016-Oct-28 \n                   \n                     365 days: The best science images of 2015 2015-Dec-17 \n                   \n                     Nature  special: The year in review \n                   Reprints and Permissions"},
{"file_id": "540496a", "url": "https://www.nature.com/articles/540496a", "year": 2016, "authors": [{"name": "Alison Abbott"}, {"name": "Declan Butler"}, {"name": "Davide Castelvecchi"}, {"name": "Daniel Cressey"}, {"name": "Elizabeth Gibney"}, {"name": "Heidi Ledford"}, {"name": "Jane J Lee"}, {"name": "Lauren Morello"}, {"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Climate accords, controversial assisted reproduction and the CRISPR patent battle are among the year's top stories. From an election that stunned the world to catastrophic technical glitches in space, researchers weathered a turbulent year. But they also announced some remarkable advances \u2014 the direct detection of gravitational waves, the birth of a baby with DNA from three people and an artificial intelligence that cracked the one board game that computers had yet to master. \n               Catching a wave \n             Physicists bagged some big game this year. On 11\u00a0February, researchers announced that  they had finally sensed the ripples in the structure of space-time  known as\u00a0gravitational waves \u2014 capping a decades-long quest. The signal, spotted in September 2015 by the\u00a0twin detectors of the Laser Interferometer \u00adGravitational-Wave Observatory (LIGO) in Louisiana and Washington state, came from the merger of two black holes some 1\u00a0billion years before. The announcement was a stunning affirmation of Albert Einstein\u2019s general theory of relativity, almost 100\u00a0years after he had published it. And it provided the most direct evidence yet that  black holes \u2014 another prediction of Einstein\u2019s theory \u2014 exist . Astrophysicists hailed LIGO\u2019s feat as a triumph, saying that it heralded a new way of observing the\u00a0\u00adcosmos, enabling the  detection of phenomena that might not be picked up by other means . Just weeks after the LIGO announcement, another experiment demonstrated that the search for gravitational waves could one day occur in space. The European Space Agency\u2019s LISA Pathfinder mission  tested technologies for a future trio of probes  that would sense gravitational waves coming from even larger and more-distant objects than the ones LIGO observed. Particle physicists were not so lucky. They spent much of the year holding their collective breath. Two separate experiments at the Large Hadron Collider near Geneva, Switzerland, had reported anomalous measurements in late 2015 that suggested the existence of a  particle six times as massive as the Higgs boson . At the time, experimenters warned that the anomalies could be \u00adstatistical flukes. And more data released in August confirmed this. By then, theoreticians had  written hundreds of papers  in attempts to interpret the original data with a zoo of possible models. \n               New world order \n             A tumultuous US presidential campaign ended in a surprise victory for Republican businessman Donald Trump in November. Researchers struggled to understand how a Trump administration would treat science\u00a0\u2014 in part, because it  did not feature prominently on the campaign trail . Still, some of Trump\u2019s views were clear: he has alleged that climate change is a hoax perpetrated by the Chinese, and has pledged to withdraw the United States from the Paris climate agreement. He has also suggested a link between autism and childhood vaccinations. As Trump\u2019s administration began to take shape, researchers  started to lobby against  what they saw as an incoming president with little use for science. In late November, more than 2,300 scientists \u2014 including 22 Nobel laureates\u00a0\u2014 sent a letter to Trump urging him to \u201cadhere to high standards of scientific integrity and independence in responding to current and emerging public health and environmental health threats\u201d. The United Kingdom\u2019s 23\u00a0June vote to leave the European Union shook the country\u2019s scientific community.  Researchers remain worried  about the fate of millions of euros in annual research funding from the EU and the immigration status of UK university staff from non-British EU nations. Some UK researchers have reported being cut out of EU collaborations, and some foreign scientists say that they feel so unwelcome that they plan to leave the country. In happier news, the UK government\u00a0\u2014 led by a cabinet that came to power in the wake of the Brexit vote\u00a0\u2014 announced a  surprise funding boost in November  worth \u00a32\u00a0billion (US$2.5\u00a0billion) annually by 2020. A failed military coup in Turkey in July spelt upheaval of a different kind for academics: the Council of Higher Education promptly  fired more than 1,500 university deans . About 58% of the positions have since been refilled by their former occupants. But more than 6,500 professors have been dismissed on suspicion of involvement in the coup. Human-rights groups say that many of the dismissed are innocent. Political and economic woes rocked Venezuela, Brazil and South Africa this year\u00a0\u2014 and did not spare researchers. Rolling blackouts, food queues and increasing violence prompted  hundreds of scientists to leave Venezuela\u2019s universities , and, in some cases, the country. Brazil\u2019s researchers are facing drastic budget cuts and the demotion of the science ministry, and  protested against proposals to freeze federal science spending  and  weaken the country\u2019s environmental laws . And austerity measures in South Africa have led to  chronic underfunding of universities  and triggered a  rash of campus protests and violence . \n               To boldly go \n             In the year that saw the 50th anniversary of  Star Trek , technical glitches set back several space missions \u2014 but there were also notable victories. In March, the Japan Aerospace Exploration Agency\u2019s flagship Hitomi X-ray astronomy satellite failed just weeks after launch. Investigators determined that  a software error had caused the spacecraft to rotate out of control  and break apart. In July, NASA\u2019s  Juno probe arrived at Jupiter , but  problems with its main engine  delayed the rocket firing that would have shrunk its orbit into a tighter ellipse around the planet. The spacecraft continues to gather data on Jupiter\u2019s atmosphere and magnetosphere on every fly-by \u2014 just more slowly than planned. Meanwhile, the European Space Agency (ESA) mourned the end of two probes. In October, the Schiaparelli lander \u2014 part of the ESA\u2019s ExoMars mission \u2014  smashed onto the red planet\u2019s surface  after a measurement error caused its parachute and braking rockets to deploy at the wrong times. But at least its companion spacecraft managed to enter orbit around Mars. ESA\u2019s other loss was sad for some scientists, but deliberate. The pioneering Rosetta spacecraft  crashed onto the surface of Comet 67P/Churyumov\u2013Gerasimenko  in September as planned, radioing back close-up images before it lost contact \u2014 and bringing the mission to an end. Rising space power China garnered several wins. In August, it launched the first ever quantum satellite, aimed at testing ways to extend secure quantum communication into space. In September, the country completed construction on the world\u2019s largest single-dish tele\u00adscope, the  Five-hundred-meter Aperture Spherical Radio Telescope  in the southwestern province of Guizhou. And in November, China launched the Long March 5 rocket, one of the world\u2019s most powerful. It is meant to send people, rovers and heavy-duty planetary probes into space. Finally, two Chinese astronauts broke their country\u2019s record for the longest-duration space mission when they spent a month aboard the Tiangong\u00a02 space laboratory in October and November. \n               CRISPR in court\u2002 \n             The development of new applications for the genome-editing tool CRISPR\u2013Cas9 continued apace. On 28\u00a0October, a patient with lung cancer at West China Hospital in Chengdu became the  first person to be treated with cells edited using CRISPR\u2013Cas9 . As part of a clinical trial, researchers disabled a gene that normally holds a cell\u2019s immune system in check, in the hope that the edited cells would mount an immune response against the cancer. More  cancer trials using treatments based on CRISPR\u2013Cas9 are expected  in the United States and China next year. But the commercial landscape for CRISPR\u2013Cas9 therapies remains uncertain. The battle over US patent rights to the gene-editing technique  reached fever pitch  after the US Patent and Trademark Office declared  an \u2018interference\u2019 proceeding between two research teams  in January. The proceeding, which could conclude early next year, aims to  determine who first invented the technique . Each team applied for patents that could be crucial for commercial applications. Meanwhile, research using CRISPR\u2013Cas9 in human embryos expanded this year. It is a controversial area of research that has raised concerns about the potential for designer babies \u2014 but regulators in some countries have approved projects in this field. Teams in  China , the  United Kingdom  and  Sweden  announced their intentions to use the technique to optimize its use in embryos and to study human development. Work in the United States is expected to follow, despite a prohibition on the use of federal funds to study human embryos or to modify human eggs or sperm. \n               Climate crunch \n             Representatives of a record 174 countries and the European Union gathered on Earth Day, 22\u00a0April, to sign the international climate agreement forged in Paris in December 2015. But for the accord to come into force, more than 55\u00a0countries accounting for at least 55% of global greenhouse-gas emissions needed to submit ratification or acceptance documents. The biggest boost came in September, when the United States and China \u2014 which together account for 38% of global emissions \u2014 formally joined the agreement. Brazil and 30 other countries joined a few weeks later, and  the EU sealed the deal on 5\u00a0October . The pact came into effect on 4\u00a0November. But that wasn\u2019t the only global climate deal afoot. On 6\u00a0October, the United Nations\u2019 International Civil Aviation Organization  curbed emissions from international flights . And on 15\u00a0October, 197 countries agreed to amend the Montreal Protocol \u2014 designed to protect the ozone layer \u2014 to phase out hydrofluorocarbons, powerful greenhouse gases commonly used in air conditioners. Countries also broke a four-year-long impasse on 28\u00a0October to create  the world\u2019s largest marine reserve  in the Ross Sea off the coast of Antarctica. All the while, global warming continued. An epic El\u00a0Ni\u00f1o in the tropical Pacific Ocean helped set global-temperature records in the first five months of the year. This put 2016 on track to become the third straight warmest year in a row. The blazing warmth  prompted corals around the world to bleach , a process in which the stressed animals expel the algae that help to keep them alive. The El Ni\u00f1o faded away in May, but coral bleaching continued throughout the year and is expected to continue into 2017. \n               Zika spreads \n             In February, the World Health Organization (WHO) declared that clusters of birth defects linked to outbreaks of Zika virus in Brazil constituted a global public-health emergency. These birth defects included severe cases of microcephaly, a condition in which fetuses or newborns have abnormally small heads and brains. But the expected explosion in microcephaly cases and other Zika-linked birth defects across the Americas has not materialized, despite the virus\u2019s spread across the continents. Even in Brazil, extremely high rates of microcephaly remained confined to the country\u2019s northeast region \u2014 and researchers began to suspect  the influence of confounding factors . In July, Brazilian authorities launched a study to find out whether environmental, socio-economic or biological elements, when combined with Zika infection, could explain the odd distribution of elevated rates. They expect preliminary results early next year. On 18 November, the WHO declared the end of the international public-health emergency on the grounds that the link between Zika and birth defects had been established, and that the focus needed to shift to understanding the consequences of Zika infections, including the birth defects, and developing a vaccine. Several ongoing international research projects should produce results next year on a  number of Zika-related questions , such as what proportion of infected pregnant women go on to have babies with birth defects. \n               Mind games \n             In January,  a computer program beat a world-class human player  at the ancient game of Go for the first time. But the  ultimate showdown was in March , when the artificial intelligence (AI), called AlphaGo, trounced Lee Sedol \u2014 one of the world\u2019s top players. The AI, developed by the Google-owned company DeepMind in London, opened with three consecutive wins in the five-round tournament. Lee took the fourth game and nearly won game five, but AlphaGo triumphed. In October, DeepMind researchers debuted another AI, one  capable of navigating the London Underground  without any previous knowledge. The sophisticated program combined memory with the ability to learn from experience. This brought AI a step closer to performing human-like tasks such as reasoning. AI also helped to  reduce errors in machine translation of languages by around 60% , and aided physicists looking for  new super materials . These advances were largely powered by deep learning, which harnesses huge data sets and a hierarchical, brain-like method of computing. \n               Controversial conception \n             After decades of research, assisted-reproduction techniques that mix DNA from three people are bearing fruit. These procedures prevent children from inheriting metabolic diseases caused by flaws in mitochondria, the cell\u2019s energy-producing structures. In September, researchers working in a Mexican clinic reported the  birth of the first healthy baby conceived through one such procedure . A baby in China was also reportedly born using the same technique. And in October, a clinic in Ukraine announced that  two previously infertile women had conceived through a similar procedure . On 15\u00a0December, following scientists\u2019 advice, the United Kingdom\u2019s Human Fertilisation and Embryology Authority  said that the technique was ready for clinical use , which could start as soon as 2017. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Nature\u2019s 10 2016-Dec-19 \n                   \n                     2016 in pictures: The best science images of the year 2016-Dec-16 \n                   \n                     Donald Trump's US election win stuns scientists 2016-Nov-09 \n                   \n                     Computing glitch may have doomed Mars lander 2016-Oct-25 \n                   \n                     Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                   \n                     Juno becomes first spacecraft to visit Jupiter in 21 years 2016-Jul-05 \n                   \n                     Nature  special: The year in review \n                   \n                     Nature  special: Gravitational waves \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21185", "url": "https://www.nature.com/articles/nature.2016.21185", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "The top picks from  Nature \u2019s coverage of science and culture. In a bumper crop of picks at the nexus of science and culture, we present our top 10 book reviews, and top 10 blog posts from our arts and culture blog,  A view from the bridge  \u2014 and the  Books & Arts editor\u2019s top 20 picks . \n             Reviews \n           \n             \n                 Genomics: DNA and diasporas \n               \n           Fatimah L. C. Jackson weighs up a study on the cultural politics of genetic testing among African Americans.  20 January 2016 \n             \n                 Drug discovery: A life of tumult and triumph \n               \n           Marian Turner reviews the memoir of \u00e9migr\u00e9 virologist and millionaire philanthropist Jan Vilcek.  10 February 2016 \n             \n                 Museums: Ethics of exhibition \n               \n           David Hurst Thomas explores the controversies over collections of human remains and plundered artefacts.  16 March 2016 \n             \n                 Technology: Beyond the 'InterNyet' \n               \n           Michael D. Gordin reviews a history of the Soviets' failed national computer network.  27 April 2016 \n             \n                 Energy: Oilman at the peak \n               \n           Gregor Macdonald applauds a biography of prescient geologist and energy theorist Marion King Hubbert.  6 April 2016 \n             \n                 Epidemiology: Chasing epidemics \n               \n           Tilli Tansey engages with the medical autobiography of a pioneer in the field of HIV/AIDS.  25 May 2016 \n             \n                 Ecology: The sea-otter whisperer \n               \n           Jane Lubchenco applauds James Estes's chronicle of his 45 years studying the complexities of an apex predator.  18 May 2016 \n             \n                 Q&A: Fabulous fact fisher \n               \n           Biomechanist Adam Summers of the University of Washington's Friday Harbor Laboratories has spent much of his life working out how fish move. But he has another role that some would consider more prestigious \u2013 as Pixar's 'fabulous fish guy'.  15 June 2016 \n             \n                 Science fiction: The science that fed Frankenstein \n               \n           Richard Holmes ponders the discoveries that inspired the young Mary Shelley to write her classic, 200 years ago.  27 July 2016 \n             \n                 Conservation: Geniuses of place \n               \n           Ethan Carr traces the arc of influence in landscape creation and preservation from 'Capability' Brown to Frederick Law Olmsted and the US National Park Service.  6 July 2016 \n             A view from the bridge \n           \n             \n                 Breaking barriers: the US space programme\u2019s black women mathematicians \n               \n           Alexandra Witze extols Hidden Figures, a book celebrating the African American women mathematicians behind the US space programme.   6 September 2016 \n             \n                 The equations of love \n               \n           Mathematical biologist Marten Scheffer looks at how the laws of dynamical systems play out in love.   20 May 2016 \n             \n                 Reflections of a Moonwalker \n               \n           Elizabeth Gibney follows the trajectory of Apollo astronaut Gene Cernan in documentary The Last Man on the Moon.   4 April 2016 \n             \n                 The art of engineering: \n                 9 Evenings \n                 revisited \n               \n           Barbara Kiser marks the 50th anniversary of 9 Evenings, a seminal collaboration between Bell Labs engineers and avant-garde artists.  27 October 2016 \n             \n                 Share the repair \n               \n           Sustainability expert Martin Charter reveals a circular-economy revolution in \u2018share and repair\u2019 communities.   23 March 2016 \n             \n                 Industrial optimist: Moholy-Nagy revisited \n               \n           Jeff Tollefson is energized by a show on the Bauhaus \u2018industrial artist\u2019 L\u00e1zl\u00f3 Moholy-Nagy.  13 June 2016 \n             \n                 CRISPR patent belongs to aliens \n               \n           Sara Reardon checks out the CRISPR-esque storyline in this year\u2019s reboot of The X-Files.   29 February 2016 \n             \n                 Charlotte Bront\u00eb\u2019s brushes with science \n               \n           Barbara Kiser explores Victorian novelist Charlotte Bront\u00eb\u2019s close encounters with the science of her day.   20 April 2016 \n             \n                 Smoke on the water \n               \n           Rich Monastersky assesses Hollywood\u2019s take on the Deepwater Horizon blowout in Peter Berg\u2019s eponymous film.   12 October 2016 \n             \n                 An artist on Mars: Georgia O\u2019Keeffe \n               \n           Barbara Kiser relishes an exhibition on artist Georgia O\u2019Keeffe, whose visual paeans to geomorphology changed the face of nature painting.  10 August 2016 Reprints and Permissions"},
{"file_id": "nature.2016.21215", "url": "https://www.nature.com/articles/nature.2016.21215", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "The racket that Egyptian fruit bats make when jammed next to each other contains information about food, sleeping arrangements and mating attempts. The high-pitched squeals of the humble bat may be as complex as the calls of dolphins and monkeys, researchers have found. A  study  published on 22 December in  Scientific Reports 1  reveals that the fruit bat is one of only a few animals known to direct its calls at specific individuals in a colony, and suggests that information in the calls of many social animals may be more detailed than was previously thought. Bats are noisy creatures, especially in their crowded caves, where they make calls to their neighbours. \u201cIf you go into a fruit-bat cave, you hear a cacophony,\u201d says Yossi Yovel, a neuroecologist at Tel Aviv University in Israel who led the study. Until now, it has been difficult to separate this noise into distinct sounds, or to determine what prompted the individual to make a particular call. \u201cAnimals make sounds for a reason,\u201d says Whitlow Au, a marine-bioacoustics scientist at the University of Hawaii at Manoa. \u201cMost of the time, we don\u2019t quite understand those reasons.\u201d \n             Bat chat \n           To find out what bats are talking about, Yovel and his colleagues monitored 22 captive Egyptian fruit bats ( Rousettus aegyptiacus ) around the clock for 75 days. They modified a voice-recognition program to analyse approximately 15,000 vocalizations collected during this time. The program was able to tie specific sounds to different social interactions captured by video, such as when two bats fought over food. Using this tool, the researchers were able to classify more than 60% of the bats\u2019 sounds into four contexts: squabbling over food, jostling over position in their sleeping cluster, protesting over mating attempts and arguing when perched in close proximity to each other. The algorithm allowed researchers to identify which bat was making the sound more than 70% of the time, as well as which bat was being addressed about half the time. The team found that the animals made slightly different sounds when communicating with different individuals. This was especially true when a bat addressed another of the opposite sex \u2014 perhaps in a similar way, the authors say, to when humans use different tones of voice for different listeners. Only a few other species, such as dolphins and some monkeys, are known to specifically address other individuals rather than to broadcast generalized sounds, such as alarm calls. \n             Cave quarrels \n           The bats seemed to be particularly vocal when annoyed with other bats. They might be communicating such things as \u2018Hey, get out of my way!\u2019 or \u2018Stop, that\u2019s my food!\u2019, suggests Sonja Vernes, a neurogeneticist and bat researcher at the Max Planck Institute for Psycholinguistics in Nijmegen, the Netherlands, who was not involved in the study. Bats may have a lot more to tell us, Yovel says. Most communication research has been performed on songbirds, because the vocalizations of dolphins, whales and monkeys are more difficult to study. But in the past few years, scientists have begun adopting bats as another model organism for this research. \u201cThe bat vocal communication field is like where the songbird field was 60 years ago,\u201d says Michael Yartsev, a neurobiologist at the University of California, Berkeley, who studies neural circuits in bats. Yovel says his group is now trying to determine how well bats respond to the different types of call. The team's findings, he says, suggest that communication researchers should look deeper into the context when analysing the sounds of animals \u2014 their everyday chit-chat might be much more sophisticated than it seems. \n                   Geneticists hope to unlock secrets of bats\u2019 complex sounds 2016-Nov-18 \n                 \n                   Frogs tune call to hole 2002-Nov-05 \n                 \n                   Dolphin hear, dolphin do 2002-Aug-21 \n                 \n                   The Bat Lab for Neuro-Ecology \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21165", "url": "https://www.nature.com/articles/nature.2016.21165", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "NASA-funded project monitors ice across the planet as the world warms. San Francisco, California Scientists have a new tool to systematically track the evolution of glaciers and ice sheets as the climate warms. The US$1-million system, which is funded by NASA and uses  data from the Landsat\u00a08 satellite , was unveiled this week at the American Geophysical Union meeting in San Francisco, California. The Global Land Ice Velocity Extraction project (GoLIVE) is the first to provide scientists with regular, semi-automated measurements of ice movement across the entire world. Landsat covers the planet every 16 days, and by comparing landmarks and subtle features in ice from one image to another, researchers are able to trace the flow of ice over weeks, seasons and years. \u201cWe now are watching  all of the outlet glaciers on Earth change in real time ,\u201d says Mark Fahnestock, a glaciologist at the University of Alaska Fairbanks who helped to develop GoLIVE. \u201cOur eyes are open.\u201d Scientists have been using satellite imagery and radar to track the movement and evolution of glaciers from space for decades, but until now, doing so has required painstaking analysis. Advances in satellite technology, computer algorithms and processing power are now enabling them to expand their reach. The goal is to understand how quickly glaciers and ice sheets will melt \u2014  and consequently how fast oceans will ris e \u2014 as temperatures increase. Similar efforts to build a record of ice flow are underway for Greenland and Antarctica; these use data from multiple satellites, including visual imagery from Landsat 8 and  the European Sentinel 1 satellite s. \n             Eyes in the sky \n           But some scientists think that radar will ultimately prevail because, unlike visible-light satellite imagery, it can track ice through clouds and at night. This is particularly important in places such as Greenland and Antarctica, where the bulk of the world\u2019s ice is shrouded in complete darkness for much of the winter, says Ian Joughin, a glaciologist at the University of Washington in Seattle who is using the Sentinel 1 radar data and other satellite observations to map Greenland\u2019s ice flow. \u201cThey are doing a nice job with the data, but it\u2019s not so different from what we are doing already,\u201d he says. But GoLIVE is the first global project to provide scientists with a regular stream of processed data that can quickly be incorporated into existing research projects, says Ted Scambos, a glaciologist at the National Snow and Ice Data Center in Boulder, Colorado, which is hosting the GoLIVE data. \u201cIt\u2019s near-real-time global coverage that is available to users within a few weeks,\u201d he says. With just 3.5 years of data collected since Landsat 8 launched, GoLIVE is already shedding new light on how glaciers behave, says Twila Moon, a glaciologist at the University of Bristol, UK, who is working on the project. Her initial analysis of glaciers across Greenland revealed that different areas showed varying seasonal movement patterns, probably associated with regional topography. Some glaciers surge early in the spring and slow down by late summer,\u00a0whereas others build momentum more slowly, peaking by midsummer and then slowly declining. \u201cWe\u2019re getting to the point where we have enough data to see patterns,\u201d says Moon. \u201cIt\u2019s a whole new realm of potentially being able to predict glacier behaviour.\u201d Daniel McGrath, a glaciologist at Colorado State University in Fort Collins who was not involved in the project, is already using the data to study a rift in Antarctica\u2019s Larsen C ice shelf. His team is using a detailed model to investigate how the rift propagates and affects the rest of the ice sheet. And rather than relying on ice-flow estimates that are several years old, he says, he and his colleagues can now incorporate current data and track changes over time. \u00a0 \u201cThat\u2019s not something we could do previously,\u201d he says.  \n                   Greenland once lost nearly all its ice \u2014 and could again 2016-Dec-07 \n                 \n                   How much longer can Antarctica\u2019s hostile ocean delay global warming? 2016-Nov-16 \n                 \n                   Giant, deadly ice slide baffles researchers 2016-Aug-23 \n                 \n                   180,000 forgotten photos reveal the future of Greenland\u2019s ice 2016-Jul-27 \n                 \n                   Antarctic model raises prospect of unstoppable ice collapse 2016-Mar-30 \n                 \n                   Earth observation enters next phase 2014-Apr-08 \n                 \n                   Landsat 8 to the rescue 2013-Feb-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21162", "url": "https://www.nature.com/articles/nature.2016.21162", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "A selection of the best and most popular long reads from  Nature  this year. \n             \n                 Does it take too long to publish research? \n               \n           Scientists are becoming increasingly frustrated by the time it takes to publish a paper. Something has to change, they say.  Kendall Powell \n             \n                 The spectrum of sex development: Eric Vilain and the intersex controversy \n               \n           The geneticist built a career studying aspects of sex that make some people uncomfortable. Now things are getting uncomfortable for him.  Sara Reardon \n             \n                 On the hunt for a mystery planet \n               \n           Scientists are searching for an unseen world at the fringes of the solar system.  Alexandra Witze \n             \n                 The quiet revolutionary: How the co-discovery of CRISPR explosively changed Emmanuelle Charpentier\u2019s life \n               \n           The microbiologist spent years moving labs and relishing solitude. Then her work on gene-editing thrust her into the scientific spotlight.  Alison Abbott \n             \n                 How to raise a genius: lessons from a 45-year study of super-smart children \n               \n           A long-running investigation of exceptional children reveals what it takes to produce the scientists who will lead the twenty-first century.  Tom Clynes \n             \n                 The secret history of ancient toilets \n               \n           By scouring the remains of early loos and sewers, archaeologists are finding clues to what life was like in the Roman world and in other civilizations.  Chelsea Wald \n             \n                 Should you edit your children\u2019s genes? \n               \n           In the fierce debate about CRISPR gene editing, it\u2019s time to give patients a voice.  Erika Check Hayden \n             \n                 The sparrow with four sexes \n               \n           Elaina Tuttle spent her life trying to understand the bizarre chromosome evolution of a common bird \u2014 until tragedy struck.  Carrie Arnold \n             \n                 Can a video game company tame toxic behaviour? \n               \n           Scientists are helping to stop antisocial behaviour in the world's most popular online game. The next stop could be a kinder Internet.  Brendan Maher \n             \n                 24 hours at the X-ray factory \n               \n           Behind the scenes at Europe\u2019s massive synchrotron \u2014 where science never sleeps.  Richard Van Noorden Reprints and Permissions"},
{"file_id": "nature.2016.21193", "url": "https://www.nature.com/articles/nature.2016.21193", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Ability to do spectroscopy on antihydrogen may provide new test of fundamental physics. In a technical tour-de-force, physicists have made the first measurements of how antimatter atoms absorb light. Researchers at CERN, the European particle physics laboratory outside Geneva, trained an ultraviolet laser on antihydrogen, the antimatter counterpart of hydrogen. They measured the frequency of light needed to jolt a positron \u2014 an antielectron \u2014 from its lowest energy level to the next level up, and found no discrepancy with the corresponding energy transition in ordinary hydrogen. The null result is still a thrill for researchers who have been working for decades towards antimatter spectroscopy, the study of how light is absorbed and emitted by antimatter. The hope is that this field could provide a new test of a fundamental symmetry of the known laws of physics, called CPT (charge-parity-time) symmetry. CPT symmetry predicts that energy levels in antimatter and matter should be the same. Even the tiniest violation of this rule would require a serious rethink of the standard model of particle physics. Randolf Pohl, a spectroscopist at Johannes Gutenberg University in Mainz, Germany, could barely contain his excitement. \u201cWOW,\u201d he told  Nature  in an email. \u201cAfter all these years, these guys have finally managed to do optical spectroscopy in antihydrogen. This is a milestone in the investigation of exotic atoms.\u201d \u201cIt is amazing that one can control antimatter to an extent that this is possible,\u201d says Michael Peskin, a theoretical physicist at the SLAC National Accelerator Laboratory in Menlo Park, California. \n             Cold anti-hydrogen \n           Studying antimatter is extremely difficult, because it annihilates whenever it comes into contact with ordinary matter. In 2010, CERN\u2019s ALPHA collaboration demonstrated  how to hold antihydrogen in a magnetic trap  \u2014 and since then, have been working towards studying its interactions with light. Every 15 minutes or so, the ALPHA group can produce around 25,000 antihydrogen atoms. To make them, the physicists combine positrons, emitted by a radioactive substance, with antiprotons, produced by a particle accelerator and then slowed down and cooled. Most of these atoms are too \u2018hot\u2019 \u2014 moving too fast, and in too high an energy state \u2014 for spectroscopy studies. So the researchers must let them escape the magnetic trap, leaving just a handful of the slowest, lowest-energy antihydrogen atoms. Perfecting this technique took years, says ALPHA spokesperson Jeffrey Hangst. \u201cMaking antihydrogen is relatively easy; making cold antihydrogen is really difficult,\u201d he says. Finally, the ALPHA team was able to see whether, when the researchers shone a laser at a particular frequency, the antihydrogen atoms would act like their hydrogen counterparts. The group says they do: the energy transition is consistent to a precision of 2 parts in 10 billion, they  report on 19 December in  Nature 1 . \u201cYou put so much effort into something, and it finally succeeds. There are almost no words to describe it,\u201d says Hangst. Next, the researchers hope to probe the antihydrogen with a large range of laser energies. That could provide a more stringent test of matter\u2013antimatter equivalence and of CPT symmetry. Many theories \u2014 such as string theory \u2014 that venture beyond the standard model by combining gravity with the three other fundamental forces of subatomic physics, do involve some kind of CPT violation, says Peskin. \u201cSo it is not at all clear that CPT is a true symmetry of nature,\u201d he says. Two other experiments at CERN \u2014 called ATRAP and ASACUSA \u2014 were competing with ALPHA to measure antimatter spectroscopy. Gerald Gabrielse, the leader of ATRAP and a physicist at Harvard University in Cambridge, Massachusetts, says he first proposed nearly 30 years ago measuring the particular energy transition in antihydrogen that the ALPHA team have reported. \u201cWe started ten years earlier and they got to this result first,\u201d he says. \u201dCongratulations to ALPHA.\u201d \n                   Proton's magnetism measured with greatest precision yet 2014-May-29 \n                 \n                   Antimatter trapped for more than 15 minutes 2011-Jun-06 \n                 \n                   Antimatter held for questioning 2010-Nov-17 \n                 \n                   50,000 atoms of anti-hydrogen made 2002-Sep-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21192", "url": "https://www.nature.com/articles/nature.2016.21192", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Data highlight a slow year for the US Food and Drug Administration. US drug approvals are on track to drop by more than half in 2016 compared to 2015, according to a 14 December  presentation by the US Food and Drug Administration (FDA) . The agency had approved 19 new drugs this year as of 9 December, putting it on track for its lowest yearly tally since 2007. The decline is made more dramatic by 2015\u2019s bumper crop of approvals. The FDA approved 45 new drugs last year \u2014 the highest total in nearly 20 years. John Jenkins, director of the Office of New Drugs in the FDA\u2019s Center for Drug Evaluation and Research, attributed the decline to a reduction in submissions and to the speedy review of five drugs approved ahead of schedule in 2015. The agency also rejected more drugs, he noted: in 2016, 61% of the FDA\u2019s decisions were approvals, compared to more than 95% in 2015. The data come as the agency waits to find out who will be its next commissioner under US president-elect Donald Trump. Trump has said that he wants to speed up drug approvals and cut through \u201cthe red tape at the FDA\u201d. And on 13 December, President Barack Obama signed into law the 21st Century Cures Act, which includes measures \u2014  some of them controversial  \u2014 intended to streamline drug approvals. \n                   US health-reform legislation clears big hurdle 2016-Dec-01 \n                 \n                   Tracking the Trump transition, agency by agency 2016-Nov-30 \n                 \n                   Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                 \n                   FDA should stand firm on stem-cell treatments 2016-Jul-05 \n                 \n                   FDA 2016 Drug Approvals \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21206", "url": "https://www.nature.com/articles/nature.2016.21206", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Have you been paying attention to the science news this year? Reprints and Permissions"},
{"file_id": "nature.2016.21218", "url": "https://www.nature.com/articles/nature.2016.21218", "year": 2016, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Drive to preserve mitochondrial quality might explain why organisms develop sex cells at different stages of development. Animals and plants prepare their cells for sex in very different ways \u2014 but no one knows why. A team of UK researchers now thinks that it has worked out the puzzle. Humans and animals set themselves up for sex well before the act will ever take place. At the earliest stages of life, in the embryo, our germ cells begin to develop. These are the cells that will go on to form the sperm and the egg, with half the usual number of chromosomes. In females, eggs are set aside and kept in arrested development until they are needed. After puberty, males produce sperm continuously throughout life, but a specialized germ line is created early on from which sperm are made. But corals, sponges and plants make no such cellular plans. They initially develop only body (somatic) cells, each with a full complement of chromosomes. When the time comes to mate, they produce their sex cells, or gametes, as needed by forming them out of stem cells from adult tissue. Why the difference? According to biochemist Nick Lane of University College London, more complex animals create a devoted germline to preserve the quality of their mitochondria \u2014 specialized energy-producing structures in cells that sit outside the nucleus and have their own genes. \n             Mutation quandary \n           In a mathematical model published on 20 December, Lane and his coworkers lay out their argument. According to the team, the problem for humans and other complex animals is that if cells were allowed to divide repeatedly and form adult tissues before some of them were turned into gametes, then their mitochondria would rapidly accumulate genetic mutations and errors. Some of the gametes might acquire a high load of these mutated mitochondria, leading to poor-quality tissues in the offspring. Producing all the eggs needed early on avoids this problem. The idea of \u2018protecting\u2019 mitochondrial DNA in quiescent eggs has been suggested previously 1 . But there\u2019s a problem with that picture: some mutation is good for our mitochondria. Mutation is the engine of evolution, enabling advantageous mitochondrial genotypes to arise. Gametes made out of repeatedly replicated adult cells could therefore have useful variation. Evolution could preserve \u2018good\u2019 mutations and eliminate \u2018bad\u2019 ones, ultimately improving mitochondrial quality.  There\u2019s a delicate balance between the benefits and drawbacks of having a germline. How do you get enough variation between gametes for selection to act, without building up mutations that will impair an organism made from those gametes? \n             Evolutionary gamble \n           The model devised by Lane and colleagues,  reported in  PLoS Biology 2 , offers a potential explanation for why various organisms find different compromises. In more complex animals, the error rate in mitochondrial gene replication is relatively high. In that case, the best solution is to have a limited burst of cell division to form the female gamete precursors, giving many more germline cells than are needed, and then to cull most of them to produce a random selection of variants. This process, called atresia, is found in many organisms, including humans, but its function had puzzled scientists. Once a nicely varied population of female gametes is obtained, further division is stopped so as not to risk accumulating too many mitochondrial mutations later in development. Such mutations do accumulate in sperm, which undergo many more rounds of cell division than do eggs. But that doesn\u2019t matter, because their mitochondria are jettisoned when an egg is fertilized, and so are not passed on to the next generation. But in plants and \u2018basal\u2019 animals such as corals and sponges, the error rate in mitochondrial gene replication is quite low. In this case, there\u2019s less need to avoid replicating mitochondrial genes, and so gametes are formed later in development, reaping the benefits of genetic variation without risking poor-quality mitochondria. Quite why the difference in replication error rates exists in the first place is still a mystery. It could be because changes in feeding strategy as early animals diversified \u2014 from filter feeding to mobile predation \u2014 drove an increase in aerobic activity, requiring more oxygen and therefore the need to pack more mitochondria into a cell, raising the error rate of replication. \n             Testing difficulties \n           The new work is \u201ca thought-provoking study\u201d, says biomathematician Iain Johnston of the University of Birmingham, UK. \u201cTheir case is plausible and rather inventive.\u201d But he points out that the error rate of mitochondrial DNA replication, even within a species, is not a given \u2014 it, too, can change under selective pressure. The model explains several diverse aspects of sexual reproduction, says Lane, but testing it will be challenging. \u201cThere is no possible experiment that could give an insight into such a broad sweep of natural history,\u201d he says. \u201cOnly theory and modelling has the potential to get at it.\u201d Johnston, however, says the model is partly testable, and at least falsifiable. \u201cThe discovery of an organism with a high copying error rate that hasn\u2019t sequestered a germ line \u2014 or one with a low error rate that has \u2014 would provide evidence against the theory,\" he says.Lane adds that it should also be possible, using the model, to generate predictions about the relationship between atresia and the mitochondrial variance between gametes. Those predictions could then be checked against data from real organisms. \n                   First road map of human sex-cell development 2012-Dec-16 \n                 \n                   Variety sparks sexual evolution 2010-Oct-13 \n                 \n                   Biodiversity: On the origin of bar codes 2009-Nov-18 \n                 \n                   Sex chromosomes linked to evolution of new species 2009-Sep-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21187", "url": "https://www.nature.com/articles/nature.2016.21187", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Looking for a new challenge in the new year? Find sage advice and practical tips in this collection of careers content. \n             \n                 Reproducibility: Seek out stronger science \n               \n           Want to learn how to design an experiment or analyse data? Training is there if you look.  Monya Baker \n             \n                 Quest for the holy grant \n               \n           Looking for funding? Here's a smart guide for sources off the beaten track.  Ingrid Eisenstadter \n             \n                 Peer review: Close inspection \n               \n           To improve your own papers, learn how to evaluate other scientists' work.  Quirin Schiermeier \n             \n                 Scientific literature: Information overload \n               \n           Trying to navigate the growing deluge of data from has become a second job. These tips from career scientists can help you to cope.  Esther Landhuis \n             \n                 Management: When jobs go wrong \n               \n           Having to dismiss lab members is not easy, but there are ways to make the process less painful for all involved.  Chris Woolston \n             \n                 Mental health: Caught in a trap \n               \n           The pressures of a scientific career make it especially important to look after your mental health.  Emily Sohn \n             \n                 Research protocols: A forest of hypotheses \n               \n           Falling in love with a single theory can cut off fruitful avenues of enquiry. Here's how to keep your mind open.  Julia Rosen \n             \n                 Human behaviour: Find your voice \n               \n           Technology and practice can help introverted researchers deliver great presentations.  Julia Rosen \n             \n                 Global jobs: A taste for travel\u00a0 \n               \n           Moves in science are common, exhilarating \u2014 and challenging. Read on for survival tips.  Emily Sohn \n             \n                 Science illustration: Picture perfect  \n               \n           Enlisting the help of an illustrator can add impact to research papers and outreach projects.  Jyoti Madhusoodanan Reprints and Permissions"},
{"file_id": "540492a", "url": "https://www.nature.com/articles/540492a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Concerned by president-elect\u2019s choice of advisers, researchers take steps to defend their fields. San Francisco, California Incoming US president Donald Trump\u2019s government is beginning to take shape, and Earth scientists are getting nervous. Trump\u2019s latest Cabinet appointments include former Texas governor Rick Perry, a climate sceptic, for energy secretary, and ExxonMobil chief executive Rex Tillerson for secretary of state\u00a0\u2014 a position that would make him the United States\u2019 lead emissary on climate change. The pair helps to fill out a roster of advisers with strong ties to industry and a distaste for government regulation. Trump\u2019s transition team also asked the Department of Energy (DOE) for the names of employees who had worked on climate-change issues, further unsettling researchers. \u201cIt feels like a war on science, and on climate science in particular,\u201d says Alan Robock, a climatologist at Rutgers University in New Brunswick, New Jersey. \u201cThat\u2019s very upsetting.\u201d Scientists won a small battle on 14\u00a0December, when Trump\u2019s team disavowed the memorandum it sent to the DOE seeking information on climate-change programmes. The request sparked widespread outrage and drew a rebuke from the department after it was leaked on 9\u00a0December. At the Fall Meeting of the American Geophysical Union (AGU) last week in San Francisco, California, some researchers billed the episode as a blueprint for how they might defend their interests after Trump takes office on 20\u00a0January. \u201cThere is power, even with an administration that never admits a mistake, in bringing things to light,\u201d says Andrew Rosenberg, who heads the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts. Other researchers are copying government climate-data sets, to preserve them in case the Trump administration and the Republican-controlled Congress follow through on proposals to cut back Earth-science research at NASA or otherwise restrict studies of global warming. One rescue effort had archived 11 of 91 data sets on its list for preservation as of 16\u00a0December; these include a global temperature record maintained by NASA and palaeoclimate archives held by the National Oceanic and Atmospheric Administration (NOAA). Marcia McNutt, president of the US National Academy of Sciences, says that private foundations have expressed interest in \u201cfunding up to the order of billions of dollars\u201d for climate-change research if the Trump administration reduces support for such work. But McNutt\u00a0\u2014 who directed the US Geological Survey (USGS) from 2009 to 2013\u00a0\u2014 is not ready to give up on government science. \u201cI don\u2019t want that to be an excuse for the government to pull away\u00a0\u2014 to say private philanthropy can do this, the government doesn\u2019t need to fund it,\u201d she told journalists at the AGU meeting. The road ahead for scientists looks tough. Perry dealt with energy issues as governor of Texas, but he lacks experience with key areas of the DOE portfolio, says John Deutch, a chemist at the Massachusetts Institute of Technology in Cambridge. Deutch, who leads the department\u2019s advisory board, says that Trump should identify a deputy energy secretary who understands the agency\u2019s programmes on basic science, nuclear weapons and national security. And Perry is not the only climate sceptic poised to join Trump\u2019s inner circle. Trump\u2019s pick to lead the US Environmental Protection Agency is Oklahoma attorney-general Scott Pruitt, who has sued the federal government to overturn greenhouse-gas and air-quality rules. The president-elect has not announced whom he would like to run NASA, NOAA or the USGS, among other science agencies. McNutt says that the National Academies of Science, Engineering, and Medicine have provided his transition team with a list of potential candidates, but none of those people has been contacted by Trump staff. Some scientists argue that even if policies to fight climate change are weakened or struck down under Trump, his latest nominations hint that there may be ways to promote clean energy. Tillerson has said that a carbon tax is the best way to address global warming. And although Perry is a strong proponent of fossil fuels, Texas\u2019s wind-power production grew significantly during his governorship. \u201cThose are places to insert a progressive agenda into an otherwise kind of ugly and cloudy landscape,\u201d says Daniel Kammen, an energy researcher at the University of California, Berkeley. McNutt advises scientists to stay clear-eyed as they confront whatever challenges the Trump administration brings. \u201cI see so many people in this country freaked out,\u201d she says. \u201cThat is exactly what those who want to disrupt science are hoping to achieve.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Is Donald Trump pushing more scientists towards political activism? 2016-Dec-13 \n                   \n                     Trump's pick for energy secretary once sought to eliminate DOE 2016-Dec-13 \n                   \n                     What Trump\u2019s pick for secretary of state could mean for climate policy 2016-Dec-13 \n                   \n                     Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                   \n                     Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                   \n                     Nature  special: Science and the US election \n                   \n                     Trump transition website \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21093", "url": "https://www.nature.com/articles/nature.2016.21093", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Poor experimental design and statistical analysis could contribute to widespread problems in reproducing preclinical animal experiments. Less than one-fifth of Swiss scientists who sought permission to experiment with animals in 2008, 2010 and 2012 reported the use of methods to curb biases and reduce chance findings, according to a study published this month in  PLOS Biology 1 . Research planned without such precautions  can produce distorted findings  that could be contributing to  the widespread difficulty in reproducing published results in biomedical science . Hanno W\u00fcrbel, an animal behaviourist at the University of\u00a0Bern, Switzerland, and colleagues analysed 1,277 applications for animal experiments, and some of the publications that resulted from them. The scientists found that relatively few applicants reported the use of methods such as sample randomization when designing their experiments. And in a companion paper published in  PLoS ONE , W\u00fcrbel's team present the results of a detailed survey of animal researchers in Switzerland, asking about  measures to lessen the risk of bias . The survey was sent to all 1,891 researchers registered for animal experimentation in the country, and 302 of the 530 responses were sufficiently complete to be included in the analysis. The responding scientists reported a greater use of methods to reduce bias than found in the published literature 2 . \u201cWhat we learned from the survey and interviews we conducted with scientists is that there\u2019s still a lack of awareness of the problem,\u201d says W\u00fcrbel. \u201cMany scientists think that this so-called reproducibility crisis is exaggerated and it\u2019s not all that bad.\u201d In Switzerland and the European Union countries, scientists who want to conduct experiments with animals \u2014 including vertebrates and some invertebrates \u2014 must seek authorization from local or national authorities. In most countries, the process involves an ethical review, including a harm\u2013benefit analysis that also assesses the experiments' scientific validity, such as whether they have statistical analysis plans and whether the study methods are suitable for achieving the expected benefit. \n             Design choices \n           The  PLoS Biology  study reveals that only 8% of the applications mentioned whether a sample-size calculation had been performed, ensuring that the number of animals to be studied would be large enough to robustly test the effect the researchers were looking for. Only 13% of the applications mentioned whether the animals had been assigned randomly to treatment groups, and just 3% reported whether the researchers would measure the outcome of the experiment without knowing which treatment group each animal belonged to (blinding). In contrast, 69% of researchers who responded to the survey published in  PLoS ONE  said that they had performed sample-size calculations. Eighty-six percent said that they used randomization and 47% said they used blinding. But only a small fraction of researchers said they had reported such measures in their latest publication: 18%, 44% and 27 %, respectively. The situation \u201cis probably even worse than these papers suggest,\u201d says Ulrich Dirnagl, a neurologist at\u00a0the Charit\u00e9 Medical University in Berlin.\u2028 He says that some scientists simply tick a box on the application form, saying that they randomized their animal groups, without knowing what it means. Others do a \u2018sample-size samba\u2019, manipulating the expected size of the measured effect to justify the desired sample size, a reversal of the usual statistical calculation. \u2028\u2028Researchers in many different fields face problems like this in every phase of their experiments, from design to data analysis, says Jelte Wicherts, a psychologist at Tilburg University in the Netherlands who has written a checklist to guide scientists' planning 3 . But it is not clear that such advice is reaching researchers. The UK National Centre for the Replacement, Refinement and Reduction of Animals in Research (NC3Rs) in London developed study guidelines in 2010, called 'Animal Research: Reporting of\u00a0In Vivo\u00a0Experiments' (ARRIVE). They were widely disseminated, says Nathalie Percie du Sert, an experimental-design specialist at NC3Rs, but W\u00fcrbel\u2019s survey showed that half of the Swiss respondents didn't even know about them. W\u00fcrbel says that increasing the number of scientists who pregister their studies, declaring in advance how they will be done and analysed, would help reduce the risk of bias. Wicherts agrees, arguing that this makes it less likely that a scientist will be solely focused on obtaining a significant result or their desired outcome from a study. \n                   1,500 scientists lift the lid on reproducibility 2016-May-25 \n                 \n                   Web tool aims to reduce flaws in animal studies 2016-Feb-29 \n                 \n                   Surge in support for animal-research guidelines 2016-Feb-01 \n                 \n                   Missing mice: gaps in data plague animal research 2016-Jan-05 \n                 \n                   Poorly designed animal experiments in the spotlight 2015-Oct-13 \n                 \n                   UK funders demand strong statistics for animal studies 2015-Apr-15 \n                 \n                   Nature  special: Challenges in irreproducible research \n                 \n                   Animal Research: Reporting of In Vivo Experiments (ARRIVE) guidelines \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21134", "url": "https://www.nature.com/articles/nature.2016.21134", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Programme aims to prevent crises similar to the recent Ebola epidemic. Three years after the start of the world\u2019s worst  Ebola epidemic , the World Health Organization (WHO) has created a programme to improve its response to disease outbreaks and to  prevent another such calamity . In June, WHO director-general Margaret Chan named medical epidemiologist Peter Salama to lead a new health-emergencies programme intended to streamline the agency\u2019s response to crises. As part of that programme, the WHO has launched the Emerging Diseases Clinical Assessment and Response Network (EDCARN) to provide guidance on how to care for people during disease outbreaks. Global-health experts say that the changes are a step in the right direction, but both developing and wealthy nations must do much more  to avert another devastating epidemic . Some are also concerned that the WHO programme will have trouble getting the funding it needs to succeed, because of a lack of monetary support from member nations. \u201cAfrican countries are still so dependent on international and global outfits that the return of Ebola or any other disease will be another d\u00e9j\u00e0 vu of national unpreparedness,\u201d says virologist Oyewale Tomori at Redeemer\u2019s University in Ede, Nigeria. Tomori says that many developing nations still don\u2019t have sufficient capacity for recognizing and responding to an emerging infectious disease. \n               Building a bridge \n             The WHO\u2019s new programme aims to strengthen local health systems and to bridge global, organizational and governmental efforts to prevent the next outbreak. Daniel Bausch, EDCARN\u2019s technical lead, says that the network aims to fill huge gaps exposed during the Ebola crisis: a lack of knowledge about how best to care for people who have such serious diseases, and a shortage of physicians and experts who are prepared to provide that care. \u201cClinical management of patients during infectious-disease outbreaks has been one of the neglected areas of public health,\u201d Bausch says. \u201cWe\u2019ve realized that it\u2019s one of the many areas where international support is extremely important.\u201d So EDCARN is bringing together specialists in diseases that are likely to spark outbreaks \u2014 including Ebola, Middle East respiratory syndrome (MERS) and Crimean\u2013Congo haemorrhagic fever. These people could be deployed to affected areas along with nurses, logistics experts and infection-control specialists to advise non-governmental agencies, governments and others on the ground who would be caring for patients. The hope is that this will prevent some of the problems with patient care and health-worker protections seen in the Ebola epidemic, in which many  local and foreign health workers were among the 11,310 who died . \n               Funding worries \n             Public-health policy analysts, such as Lawrence Gostin at Georgetown University in Washington DC, are optimistic about EDCARN. \u201cI think it is a helpful initiative, and is in line with some of the ideas put forward by the Ebola commissions,\u201d says Gostin, who served on two of the five international panels that have recommended major reforms to the global-health system in the wake of the Ebola crisis. Other health initiatives that were started in the aftermath of the Ebola epidemic have run into problems, which have tempered expectations for EDCARN. A US-led effort to boost domestic health systems has met with local resistance, and a WHO-led programme with similar goals does not have enough long-term funding to keep going, Gostin says. To succeed, the WHO\u2019s new health-emergencies programme must raise US$485\u00a0million for the 2016\u201317 fiscal year, and is  currently only 56% funded . Gostin hopes that stinginess among the WHO member countries won\u2019t doom the fledgling attempts to head off another crisis. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Erika_Check \n               \n                     Ebola experience leaves world no less vulnerable 2015-Nov-22 \n                   \n                     Ebola failures prompt WHO rethink 2015-May-13 \n                   \n                     Nature  special: Ebola epidemic \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21133", "url": "https://www.nature.com/articles/nature.2016.21133", "year": 2016, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "'G-putty' is so sensitive that it can track even the steps of a small spider. A dash of graphene can transform the stretchy goo known as Silly Putty into a pressure sensor able to monitor a human pulse or even track the dainty steps of a small spider 1 . The material, dubbed G-putty, could be developed into a device that continuously monitors blood pressure, its inventors hope. It also demonstrates a form of self-repair that may herald smarter graphene composites. Since  graphene  was first isolated in 2004, researchers have added these atom-thin sheets of carbon to a panoply of different materials, hoping to create composites that benefit from its superlative strength and electrical conductivity. But there have been surprisingly few attempts to blend it with 'viscoelastic' materials such as Silly Putty, which behaves as both an elastic solid and a liquid. Leave a lump on top of a hole, for example, and it will slowly ooze through. Conor Boland, a researcher working in Jonathan Coleman\u2019s nanotechnology lab at Trinity College Dublin, wondered what would happen if he brought the two materials together. \u201cI\u2019d like to be able to say it was carefully planned, but it wasn\u2019t,\u201d laughs Coleman. \u201cWe\u2019ve just got a tradition in my group of using household stuff in our science.\u201d (In 2014, his team found that they could make graphene by blitzing graphite in a kitchen blender 2 ). \n             Medical uses \n           The researchers mixed graphene flakes, roughly 20 atomic layers thick and up to 800 nanometers long, with homemade Silly Putty, a silicone polymer, to produce dark grey G-putty that conducted electricity. Crucially, its electrical resistance changed dramatically when the researchers applied even tiny amounts of pressure. The putty was at least ten times more sensitive than other nanocomposite sensors. When they wired up a lump of G-putty and held it to a student\u2019s neck, the pulse from his carotid artery was clearly visible in those resistance changes. In fact, the pulse profile was so detailed that they could convert it into an accurate blood-pressure reading. The sensor could also monitor respiration when placed on the student\u2019s chest. And, as a slightly bizarre encore, it recorded the individual steps of a spider weighing just 20 milligrams. \u201cThey did a really extensive demonstration of how versatile it can be,\u201d says Vincenzo Palermo, a materials scientist at the National Research Council of Italy in Bologna. \u201cI think it\u2019s remarkable work, really original.\u201d The study is  published in  Science 1 . \n             Mobile flakes \n           Coleman\u2019s team found that the graphene flakes form a conducting network within the putty, and deforming the material breaks that network apart, rapidly increasing its electrical resistance. G-putty\u2019s low viscosity then allows the graphene flakes to move back into position and reform the network. \u201cIt\u2019s a self-healing phenomenon,\u201d he says. Coleman is already talking to medical-device companies who are interested in using G-putty for continuous physiological monitoring. Blood pressure measurements, for example, often rely on bulky cuffs around a patient\u2019s arm and offer only a snapshot reading. A cheap, small and non-invasive sensor could provide a simple way to monitor patients at home 3 . Companies such as Nokia are interested in graphene sensors for health applications, says Sanna Arpiainen, senior scientist for graphene research at VTT, a large contract research organization near Helsinki. But G-putty would have to clear a series of hurdles \u2014 including proving that it can be made in large-scale quantities, and real-world testing to assess its long-term performance \u2014 before it could be commercialized, she cautions. \u201cFor real applications, you need it to work the same way thousands of times,\u201d agrees Palermo. One experiment with G-putty in the lab did hit an unexpected hitch. Boland had wanted to conduct a comparison test between two spiders, but after leaving them unattended he returned to discover that the larger spider had consumed its smaller cousin. \u201cHe didn't anticipate the difficulties of working with animals,\u201d Coleman says. \n                   The inside story on wearable electronics 2015-Dec-01 \n                 \n                   Graphene booms in factories but lacks a killer app 2015-Jun-17 \n                 \n                   Graphene: The quest for supercarbon 2013-Nov-20 \n                 \n                   Electronic sensor rivals sensitivity of human skin 2012-Jul-29 \n                 \n                   Chemistry: The trials of new carbon 2011-Jan-05 \n                 \n                   How to make graphene in a kitchen blender \n                 \n                   Jonathan Coleman's lab \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21184", "url": "https://www.nature.com/articles/nature.2016.21184", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "From artificial intelligence to ancient shipwrecks, via brain mapping and Donald Trump: it's our multimedia editors' top picks of 2016. \n             The computer that mastered Go \n           Go is an ancient Chinese board game, often viewed as the game computers could never play. Now researchers from Google-owned company DeepMind have proven the naysayers wrong, creating an artificial intelligence - called AlphaGo \u2013 which  has beaten a professional Go player for the first time . We went behind the scenes to learn about the game, the programme and what this means for the future of AI. \n             Future generations \n           A special episode about the future. How can we future-proof our world, or fight our natural bias against planning for the future? And what does the science of today mean for the health of tomorrow? \n             24 hours in a synchrotron \n           A synchrotron is a high powered X-ray generator, running 24 hours day and night to provide high frequency light beams for scientific research. In order not to waste any time or money, the researchers make full use of every second they are allotted.  We spent a day and a night at the European Synchrotron Radiation Facility  to reveal the science that never sleeps. \n             Music, health gadget data, cancer-fighting bacteria \n           The perils of tech in health, tumour fighting bacteria, and the science of what sounds good. \n             Skeleton uncovered at ancient Antikythera shipwreck \n           The famous shipwreck that brought us the mysterious Antikythera mechanism has revealed a new secret: a two-thousand-year-old human skeleton. The team hopes to extract DNA from the skull - a feat never attempted before on bones this old that have been underwater. \n             Conflict \n           A special issue on conflict. The psychological toll of war, how to count the dead, and predicting conflict in the 21st century. \n             The brain dictionary \n           Where exactly are the words in your head? Scientists have created an interactive map showing which brain areas respond to hearing different words. The map reveals how language is spread throughout the cortex and across both hemispheres, showing groups of words clustered together by meaning. The beautiful interactive model allows us to explore the complex organisation of the enormous dictionaries in our heads. \n             Trump on science, Trump on climate,  \n             Nature \n              on politics \n           Donald Trump\u2019s impact on research and climate action, and how  Nature  should discuss politics. \n             Back to the thesis: Sara Seager \n           Astrophysicist Sara Seager accidentally founded a field when she did her PhD on extrasolar planets in the late 1990s. We take her back to the thesis in the second episode of our  three-part series . \n             'Try Catch Throw': A science fiction motion comic \n           To celebrate 50 years of Star Trek and 150 years since the birth of H. G. Wells, Nature commissioned a short graphic novel, adapted here as a motion comic. Reprints and Permissions"},
{"file_id": "nature.2016.21216", "url": "https://www.nature.com/articles/nature.2016.21216", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Freeze on genetic technology would have been a disaster, say scientists, but activists plan to renew the fight. World governments at a United Nations biodiversity meeting this week rejected calls for a global moratorium on gene drives, a technology that can rapidly spread modified genes through populations and could be used to engineer entire species. But environmental activists\u2019 appeals for a freeze on gene-drive field trials, and on some lab research, are likely to resurface in the future. \u201cI\u2019m very relieved,\u201d says Andrea Crisanti, a molecular parasitologist at Imperial College London, who is part of an effort  that seeks to use gene drives to control malaria . He and others worry that a moratorium would make research on the technology more difficult, scare away funders and prevent field tests. \u201cIt would have been a disaster for developing the technology,\u201d he says. But the calls for a ban, discussed at the meeting of the UN Convention on Biodiversity (CBD) in Canc\u00fan, Mexico, on 4\u201317 December, are not going to go away, he says. \u201cThose who are opposed to this technology will be more organized next time.\u201d The idea of a moratorium found support among some countries. But a final agreement released on 16 December merely urged caution in field-testing the products of synthetic biology, including gene drives, while supporting better risk-assessment of the products\u2019 potential effects. \u201cIt\u2019s a way of governments saying \u2018we need to know more about these technologies before making these decisions. At the same time, we are worried they may have impacts on biological diversity,\u2019\u201d says Calestous Juma, a former executive secretary of the CBD and an expert on science and technology policy at Harvard University in Cambridge, Massachusetts. \n             Rapid spread \n           When the CBD last met in South Korea in 2014, gene drives were a largely theoretical idea. They are genetic elements that can quickly spread through sexually reproducing populations. In general, an organism's two copies of a gene \u2014 known as alleles \u2014 each have a 50% chance of being passed on to its offspring. This limits the pace at which a genetic modification can spread through a population. But gene-drive technology tilts the odds, so that a specific change to one allele is inherited by a higher proportion of progeny. In theory, an entire population could quickly carry the same modification. In the past two years, researchers have lab-tested gene drives in  yeast 1 ,  fruit flies 2 \u00a0and  mosquitoes 3 , 4 \u00a0that are based on a gene-editing technology called CRISPR\u2013Cas9. Crisanti\u2019s team, for instance, is working on gene drives in the malaria-carrying mosquito  Anopheles gambiae  that perpetuate mutations causing females to become infertile. Spread of this mutation could mean that mosquito populations plummet to levels that do not support the transmission of malaria. The researchers' project, called Target Malaria, has attracted tens of millions of dollars in funding, and the scientists hope to conduct field trials in Africa as early as 2024. Other groups are developing gene drives to quell island rodents and other pests. Individual countries can regulate gene-drive research and field trials. But there is no international framework that specifically governs the technology's use, even though its effects can spread across borders \u2014 a problem noted in a 2016 assessment of the technology by the US National Academies of Sciences, Engineering, and Medicine. That report highlighted the UN Convention on Biodiversity as a potential tool with which to regulate gene drives, including how, when and even whether they are deployed. Signed by nearly 200 countries \u2014 with the notable exception of the United States \u2014 the convention's treaty was drafted to meet a series of biodiversity goals, but also includes provisions on the movement of genetically modified organisms across borders. \u201cIt\u2019s a perfect place to start putting together the governance of gene drives,\u201d says Jim Thomas, a research programme manager at the ETC Group, an environmental organization in Ottawa, Canada, that supports a moratorium \n             Environmental concerns \n           Many saw this year\u2019s CBD meeting in Canc\u00fan as an opportunity for bringing their concerns to the negotiating table. Environmental activists who proposed a moratorium on both lab research and field trials say the consequences of an accidental release are too severe for the work to proceed without having safeguards and international rules in place. \u201cRight now, given the state of the labs, we shouldn\u2019t do it,\u201d says Jaydee Hanson, a policy director at the International Center for Technology Assessment in Washington DC who helped to organize a coalition of environmental activist groups pushing for a freeze on the technology. \u201cWe need to pause in order to thoroughly and thoughtfully figure out what we need to have in place for the responsible use of this technology,\u201d adds Dana Perls, a senior food and technology campaigner at Friends of the Earth, which is part of the coalition. But political scientist Kenneth Oye at the Massachusetts Institute of Technology in Cambridge says a moratorium would have hurt efforts to reign in gene drives as well as to understand their risks. \u201cThat\u2019s the research that is needed to inform judgement on whether and how to proceed,\u201d he says. For instance, if gene drives could be limited to a specific area \u2014 an idea being tested in nematode worms reared in a lab \u2014 their risk of spreading out of control would be cut. Oye hopes that such data will be available by the time the CBD next convenes in 2018. Evolutionary engineer Kevin Esvelt at the Massachusetts Institute of Technology, who works on gene drives, opposed the moratorium. But he wanted the convention to  call for greater transparency  in how the technology is studied in labs and deployed in the field, for instance by creating a mandatory gene-drive registry. \u201cI suppose you can say it\u2019s a victory for the status quo,\u201d he says. \u201cThey didn\u2019t do anything ruinous to either side. They didn\u2019t do anything productive either.\u201d \n                   Fast-spreading genetic mutations pose ecological risk 2016-Jun-08 \n                 \n                   Gene editing can drive science to openness 2016-Jun-08 \n                 \n                   Mosquitoes engineered to pass down genes that would wipe out their species 2015-Dec-07 \n                 \n                   'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                 \n                   Safety upgrade found for gene-editing technique 2015-Nov-16 \n                 \n                   Caution urged over editing DNA in wildlife (intentionally or not) 2015-Aug-04 \n                 \n                   Target Malaria \n                 \n                   UN Convention on Biodiversity \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21131", "url": "https://www.nature.com/articles/nature.2016.21131", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Elsevier\u2019s CiteScore uses a larger database \u2014 and provides different results for the quality of journals. One of science\u2019s most contentious metrics has a flashy new rival. On 8 December, publishing giant Elsevier launched the  CiteScore index  to assess the quality of academic journals. Although the index ranks journals with a formula that largely mimics the influential Journal Impact Factor (JIF), it covers twice as many journals \u2014 22,000 to the JIF\u2019s 11,000 \u2014 and its formula includes tweaks that produce some notably different results, including lower scores for some high-JIF journals. If CiteScore becomes popular, these quirks could change the behaviour of journals hoping to maximize their score, say analysts. But CiteScore comes at a challenging time for such metrics. It\u2019s not obvious that there is an appetite for a similar competitor to the JIF, and scientists note that no matter what differences CiteScore provides, it will have to survive  the same criticisms that are lobbed at its rival  \u2014 most notably that the JIF is so commonly promoted by publishers as a yardstick for \u2018quality\u2019 that researchers are judged by the impact factor of the journal in which their work appears, rather than by what they actually write. \u201cIn my view, journal metrics should always be accompanied by health warnings that are at least as prominent as the ones you see on cigarette packets,\u201d says Stephen Curry, a structural biologist at Imperial College London. \u201cSuch metrics are at the root of many of the current evils in research assessment.\u201d \n               Crowded field \n             Amsterdam-based Elsevier has for many years provided a suite of analytical indicators, including journal metrics that have never become as popular as the JIF. It says that it has launched CiteScore owing to \u201coverwhelming demand\u201d from authors and editors. The publisher is uniquely placed to challenge the JIF\u2019s hegemony. It owns the Scopus database, a record of article abstracts and their reference lists. Aside from Web of Science, on which the JIF is based, it is the world\u2019s only reasonably comprehensive and carefully curated citation database. But Scopus is bigger, enabling scientists, librarians and funders to check the popularity of many more journals. Furthermore, unlike the JIF, which is available only to subscribers, CiteScore figures will be free online for anyone to view and analyse, although full details of the documents included in the calculations are visible only to subscribers. When it comes to their underlying formulae, CiteScore and JIF are near-doppelg\u00e4ngers. To score any journal in any given year, both tot up the citations received to documents that were published in previous years, and divide that by the total number of documents. The most popular version of the JIF looks at research articles published in the previous two years, whereas CiteScore stretches back to the previous three. But one significant difference leads some high-JIF journals, such as  Nature, Science  and  The Lancet , to do worse in CiteScore. The new metric counts all documents as potentially citable, including editorials, letters to the editor, corrections and news items. These are less cited by scholars, so they drag down the average.  The Lancet , for instance, drops from a healthy average of 44 in JIF \u2014 putting it in 4th position overall \u2014 to a mere 7.7 in CiteScore, where it is outside the top 200. Such a distinction could have major consequences for the behaviour of publishers. \u201cAs there is intense competition among top-tier journals, adoption of CiteScore will push editors to stop publishing non-research documents, or shunting them into a marginal publication or their society website,\u201d predicts Phil Davis, a publishing consultant in Ithaca, New York. \n               Nuanced content \n             The Lancet, Nature  and other journals declined to comment on CiteScore. But Jeremy Berg, the editor-in-chief of  Science , says that the journal is \u201cvery proud of our content that lies outside traditional research reports and articles\u201d and that \u201cany metric that is based on citation data alone will undervalue the impact of such non-research content\u201d. \u201cThe portfolio performance of all publishers may look a bit different using CiteScore metrics, including Elsevier, but all publishers gain in that they can explore the performance of more of their titles because of the broader coverage of Scopus,\u201d says Lisa Colledge, director of research metrics at Elsevier. She says that CiteScore should be used only to compare related journals, not to compare raw scores across different fields. For example, the index ranks\u00a0 The Lancet \u00a025th out of 1,549 \u2018general medicine\u2019 journals \u2014 putting it in the top 98th percentile of journals in that subject category. After the index was released, scientists at the Eigenfactor project, a research group at the University of Washington in Seattle, published a  preliminary calculation  finding that Elsevier\u2019s portfolio of journals gains a 25% boost relative to others if CiteScore is used instead of the JIF. That is because any publisher with journals that produce lesser-cited \u2018non-research\u2019 documents will see its portfolios drop under CiteScore, says Colledge, whereas those whose journals mainly publish only research articles \u2014 such as Wiley, the American Chemical Society and Elsevier \u2014 will see a relative gain. \u201cScopus has included all document types in CiteScore metrics because this is the most simple and transparent approach that also acknowledges every item\u2019s potential to cite and be cited,\u201d she says. Clarivate Analytics in Philadelphia, which bought the JIF and the Web of Science earlier this year from Thomson Reuters, says that it doesn\u2019t see any new insights in CiteScore. Other, more complex metrics \u2014\u2013 including several published by Elsevier and Thomson Reuters \u2014 have been developed to rank journals in the past, but none has yet proved as popular as the JIF. \u201cIf anything, another, different metric will reinforce the status that the JIF has as the definitive assessment of journal impact,\u201d says Clarivate spokesperson Heidi Siegel. Some even wonder whether Elsevier, which publishes more than 2,500 journals, should be producing CiteScore at all. The JIF has always been owned by non-publishers. \u201cI question the appropriateness of a publisher getting involved with the metrics that evaluate the very content that it publishes,\u201d says Joseph Esposito, a publishing consultant in New York City. But Elsevier says that it is \"a provider of information solutions as well as a publisher\", and treats all the publishers it analyses equally. \n                     Time to remodel the journal impact factor 2016-Jul-27 \n                   \n                     \u2018Web of Science\u2019 to be sold to private-equity firms 2016-Jul-12 \n                   \n                     Beat it, impact factor! Publishing elite turns against controversial metric 2016-Jul-08 \n                   \n                     Transparency promised for vilified impact factor 2014-Jul-29 \n                   \n                     Science publishing: The golden club 2013-Oct-16 \n                   \n                     Elsevier's CiteScore metrics \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21129", "url": "https://www.nature.com/articles/nature.2016.21129", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "His plans for the job are a mystery, but past presidents have used their chief scientific aide in a number of ways. US president-elect Donald Trump has chosen people for key jobs overseeing national security, defence and  environmental policy . But he has not addressed whether he will fill the most important job in US science: presidential science adviser. Historically, many incoming presidents \u2014 who are elected in November \u2014 have designated a science adviser in December, as they transition to the White House. But Trump\u2019s transition team has not yet been in touch with the White House Office of Science and Technology Policy (OSTP), led by  President Barack Obama\u2019s influential science adviser, physicist John Holdren , to discuss the changeover. Many researchers worry that if Trump does not pick an adviser soon, science will have a much weaker voice during the next four years. \u201cI have some questions as to whether Trump is going to want a science adviser at all,\u201d says Albert Teich, a science-policy expert at George Washington University in Washington DC. \u201cHe doesn\u2019t like briefings, he doesn\u2019t like to listen to people. I can\u2019t imagine that whoever he appoints would have a very influential position.\u201d Still, some of Trump\u2019s earliest moves as president may involve scientific topics. He has said that on his first day in office, 20 January,  he will repeal many of the executive orders Obama has used  to set policy \u2014 including those on energy and climate. \n               Official business \n             Getting a science adviser in place early would help Trump to understand  the scientific implications of such issues , says Neal Lane, a physicist at Rice University in Houston, Texas, who advised President Bill Clinton from 1998 to 2001. \u201cThe president could make really good use of advice from someone he has chosen who\u2019s knowledgeable about science and technology,\u201d Lane says. Given Trump\u2019s lack of ties to the academic or scientific communities, some speculate that he will seek technical advice from business or high-tech leaders. His transition team includes Silicon Valley billionaire Peter Thiel, who \u2014 among other things \u2014 funds a fellowship for young adults to bypass college and develop business ventures. \u201cWe\u2019re going to have a whole new set of people in Washington, names that we\u2019ve never heard before,\u201d says Deborah Stine, a science-policy expert at Carnegie Mellon University in Pittsburgh, Pennsylvania, who served in the Obama White House for three years. Trump may also prove open to arguments about how research can strengthen US competitiveness. Stine points to an influential report released in 2005, during George W. Bush\u2019s administration, that described the importance of research to the national economy. Put together by a committee led by  aerospace chief executive Norman Augustine , the analysis helped shape bipartisan legislation to support innovation \u2014 with strong backing from the White House. To influence science in the Trump presidency, Stine says, \u201cyou need Norm Augustine types\u201d. \n               Early-bird special \n             Being named early in a president\u2019s administration increases the chance a science adviser can influence both who will lead science agencies and the annual wrangling over government spending on research. Trump will submit his first budget request to Congress next spring for the 2018 fiscal year that starts on 1 October 2017. But he is likely to sign his first budget into law in April next year. That is when  the stopgap spending measure now being negotiated would expire , and Congress would have to hash out a plan for further funding. Presidents Clinton and Obama both chose their science advisers the month after they were elected. But not every recent president has moved so quickly: George W. Bush  took seven months to choose physicist John Marburger . (All of the presidential science advisers have been male, and nearly all have been physicists.) By the time Marburger started the job, the Bush administration had made several crucial science-related announcements, such as  restricting funding for research with human embryonic stem cells . Many scientists complained that the stem-cell ban stifled research, and later criticized Marburger for serving in what some called an anti-science administration. But the adviser\u2019s job is to provide technical input into policy decisions, not to make the decisions themselves, says Roger Pielke Jr, a science-policy expert at the University of Colorado Boulder, who has studied the history of the position. \u201cThe science adviser is not a philosopher-king,\u201d he says. At times, presidents have sidelined their science advisers onto pet topics. Ronald Reagan assigned his to the Strategic Defense Initiative, an anti-ballistic missile defence system. \u201cA science adviser is only as influential as the president wants him or her to be,\u201d Teich says. \n               Office politics \n             Although the OSTP is codified in law, the president does not have to make use of it. Several members of Trump\u2019s transition team came from the Heritage Foundation, a conservative think-tank in Washington DC that issued a policy paper in June suggesting that the office be eliminated to reduce bureaucracy. \u201cPresidents are fully capable of creating the resources and finding the people that they need without a formal office like OSTP,\u201d says Katie Tubb, a policy analyst at Heritage and a co-author of the report. Only Congress could shrink or eliminate the OSTP, but there is precedent for doing so. In 1995, lawmakers effectively dismantled another technical advisory entity, the Office of Technology Assessment, by refusing to fund it. Many in the Washington science-policy world still bemoan the loss of this office, which produced in-depth technical reports that shaped federal policies and served as a model for technology-assessment agencies in Europe. Even reducing the size of the OSTP would hurt US science, says Rosina Bierbaum, an environmental scientist who headed the office for eight months in 2001 until Marburger took over. That\u2019s because it coordinates funding for science across government agencies, and is the main entity looking for redundancies and gaps in those portfolios. \u201cThere\u2019s so much interconnection across the disciplines of science needed to solve increasingly complex issues,\u201d says Bierbaum, who now splits her time between the University of Michigan in Ann Arbor and the University of Maryland in College Park. She points to the US Global Change Research Program, which spans 13 agencies, and the cross-government BRAIN neuroscience initiative as examples. Wherever it comes from, science advice in the Trump administration will be crucial, says Lewis Branscomb, a physicist who has served on various presidential advisory groups stretching back to the administration of President Lyndon Johnson in 1964. \u201cThe new president is going to need all the help he can get \u2014 that he will take.\u201d \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     Integrity policy unveiled at last 2010-Dec-20 \n                   \n                     John Holdren: adviser on science, fish and wine 2009-Feb-18 \n                   \n                     US scientists fight political meddling 2006-Feb-22 \n                   \n                     Nature  special: US election 2016 \n                   \n                     Office of Science and Technology Policy \n                   \n                     Trump transition team \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21128", "url": "https://www.nature.com/articles/nature.2016.21128", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Analysis of nail points to zinc deficiency as culprit in 170-year-old mystery. Detailed chemical mapping of a dead man\u2019s fingernail has illuminated the fate of a sailor in an ill-fated expedition to the Arctic. In one of the biggest unsolved mysteries of the north, a 129-member crew, led by English explorer John Franklin, disappeared in 1845 during its search for the Northwest passage. Some researchers have blamed the deaths on lead poisoning \u2014 caused by the metal leaching from food tins or the pipes that routed drinking water around the expedition's ships. Lead exposure can trigger symptoms including neurological problems, which could have ultimately doomed the exhausted explorers. But scientists have now discovered that one of the few sailors whose bodies have been found had a zinc deficiency \u2014 and suggest that it was this, not lead exposure, that led to his death. \u201cThere\u2019s increasing evidence that lead was not the issue,\u201d says Jennie Christensen, formerly a toxicologist at Stantec Consulting in Sidney, Canada, who is now at TrichAnalytics in North Saanich, Canada. She and her colleagues measured levels of copper, zinc and lead at different places along a toenail and a thumbnail from crewmember John Hartnell. He and two other sailors died during the expedition\u2019s first overwintering on Beechey Island in 1845\u201346, and were buried there. By studying the accumulated growth of Hartnell's nails, Christensen\u2019s team could pick out week-by-week changes in his body. They reported the findings on 6 December in the  Journal of Archaeological Science: Reports 1 . \u201cYou can actually see what the levels of lead were with John Hartnell, over the period of time he was present on the expedition,\u201d says Keith Millar, a clinical psychologist at the University of Glasgow who has studied the expedition members\u2019 health 2 . \u201cThat is a pretty unique insight.\u201d \n             Nailed it \n           Christensen had been working on ways to study metal exposure over time, such as mercury accumulating in grizzly bear hairs from the salmon in the animals' diet 3 . She drew on those techniques to track Hartnell's levels of lead as well as copper and zinc, low amounts of which can reflect a lack of meat or seafood in a person's diet. Her team used the  Canadian Light Source , a synchrotron particle accelerator in Saskatoon, and other instruments to build a picture of the metals inside Hartnell over time. They found that he suffered from a severe zinc deficiency, which could have suppressed his immune system. The researchers propose that this made him more vulnerable to tuberculosis and pneumonia, diseases that are thought to have ultimately killed him. Hartnell had relatively high levels of lead only during his last few weeks, when his dying body probably broke down and released long-stored lead from his bones into his blood and nails, Christensen says. \u201cThe lead theory is pretty much dismantled by this point,\u201d says Ron Martin, an analytical chemist at Western University in London, Canada. In 2013, he analysed bone fragments from several crewmembers including Hartnell, and concluded that they had experienced consistent lead exposure throughout their lives, with no spike during the expedition 4 . Further evidence pointing away from lead poisoning comes from the expedition\u2019s two ships,  the HMS  Erebus  and  the HMS  Terror , which sank about 100 kilometres apart. Archaeologists with Parks Canada located the two ships in 2014 and 2016 respectively, after years of searching. Exploration of the  Terror  showed that items had been carefully stowed away, arguing that the crew had not been experiencing the hallucinations or delirium that often come with lead exposure, says Millar. No nail samples are available for any of the expedition members other than Hartnell, so the work cannot be extended beyond his particular death. But zinc deficiency could help explain why other Arctic expeditions also suffered from poor health, Christensen says. \n                   Blog: Arctic archaeologists find Franklin expedition ship \n                 \n                   Parks Canada on the Franklin Expedition \n                 \n                   TrichAnalytics \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21139", "url": "https://www.nature.com/articles/nature.2016.21139", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Italy\u2019s youngest leader failed to walk the talk when it came to boosting research, academics say. Italian politics is in turmoil after the resignation of Prime Minister Matteo Renzi \u2014 but researchers say that they are not particularly sad to see him go. In his almost three years in charge, Renzi promised improvements for universities and science but failed to raise the status of research in the country, according to scientists who complain that he also directly interfered in academic affairs. \u201cRenzi became prime minister at a time of serious economic and social crisis, and he injected a sense of energy and optimism into the university and research sector,\u201d says biologist Cesare Montecucco of the University of Padua. \u201cOur expectations were raised, but they were mostly disappointed.\u201d Renzi resigned on 7 December, three days after constitutional reforms he proposed were defeated in a referendum. He stayed on to push through a 2017 budget that sees no significant increase for Italy\u2019s  chronically underfunded  university and research system. (Exact figures for research spending have not yet been released.) \n               Funding falls \n             Italy\u2019s research and university funding per head is among the lowest in Europe \u2014 although the country does produce a greater share of highly cited research papers than the European Union average. Little has changed on that score during Renzi\u2019s tenure, say Montecucco and other scientists. Renzi has not delivered what they have long campaigned for: less bureaucracy for research institutions and a new research-grants agency along the lines of the US National Science Foundation. Most controversial has been Renzi\u2019s decree in November 2015 creating a \u20ac1.5-billion (US$1.7-billion) centre for genomics in Milan. Known as the Human Technopole, it will focus particularly on personalized medicine and nutrition. The new budget foresees annual funding of well over \u20ac100 million beginning in 2018. Although some are grateful for the research funding,  many scientists have complained  that the major investment in a single new project is inappropriate when most other public research institutes are starving for cash. They also strongly objected to the fact that it was planned by Renzi with a few chosen scientists behind closed doors. In September 2016, Renzi floated the idea of creating 500 elite professorships known as Natta chairs (after Italian chemist and Nobel laureate Giulio Natta), to be awarded mainly to Italians working abroad. They would be selected through 25 evaluation panels whose chairs the prime minister would nominate. Thousands of academics signed an open letter in October complaining that Renzi designed the programme without discussing it with universities \u2014 and protesting the involvement of politics in the selection. Regulations for the Natta selection procedure have not yet been published, so scientists hope that the next government will ensure that the process remains inside the academic community. \u201cNomination of panel chairs by the prime minister is just not acceptable,\u201d says physicist Giorgio Parisi of the University of Rome La Sapienza, a prominent critic of the process. \u201cIt is a political choice to do the selection independently of Italian universities, but then you could turn to external academic organizations, like Europe\u2019s national academies.\u201d \n               Budgetary blues \n             Parisi is also unhappy with aspects of the 2017 universities budget. In particular, a \u20ac271-million portion of it will now be reallocated to the university departments that are judged by the national evaluation agency ANVUR to have the best research performance. Parisi thinks that new money should be made available to reward high performers, rather than being transferred from the general university budget, which is already stretched thin. \u201cThis government reallocation means that weaker universities in the south will lose even more money, and this would be a social disaster,\" he says. An interim government will hold down the fort until new elections are held, which could take place next year. Uncertainty is set to continue. Populist and protest parties, particularly the Five Star Movement led by comedian Beppe Grillo, are likely to make substantial gains in the next election. These parties do not have strong scientific agendas. Italian senator-for-life Elena Cattaneo, who is also a neuroscientist at the University of Milan, is taking a wait-and-see perspective. \u201cOne or two populists in the current parliament have shown themselves to be more open to discussion on scientific topics than members of mainstream parties,\u201d she says. \n                     Row over proposed Italian biomedical centre intensifies 2016-May-11 \n                   \n                     Strikes could 'break' Italy's universities 2010-Jun-30 \n                   \n                     Italy introduces performance-related funding 2009-Jul-28 \n                   \n                     Saving Italian science 2006-Mar-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21135", "url": "https://www.nature.com/articles/nature.2016.21135", "year": 2016, "authors": [{"name": "Zeeya Merali"}], "parsed_as_year": "2006_or_before", "body": "Gravitational-wave data show tentative signs of firewalls or other exotic physics. It was hailed as an elegant confirmation of Einstein\u2019s general theory of relativity \u2014 but ironically the  discovery of gravitational waves earlier this year  could herald the first evidence that the theory breaks down at the edge of black holes. Physicists have analysed the publicly released data from the Laser Interferometer Gravitational-Wave Observatory (LIGO), and claim to have found \u201cechoes\u201d of the waves that seem to contradict general relativity\u2019s predictions 1 . The echoes could yet disappear with more data. If they persist, the finding would be extraordinary. Physicists have predicted that  Einstein\u2019s hugely successful theory  could break down in extreme scenarios, such as at the centre of black holes. The echoes would indicate the even more dramatic possibility that relativity fails at the black hole\u2019s edge, far from its core. If the echoes go away, then general relativity will have withstood a test of its power \u2014 previously, it wasn\u2019t clear that physicists would be able to test their non-standard predictions. \u201cThe LIGO detections, and the prospect of many more, offer an exciting opportunity to investigate a new physical regime,\u201d says Steve Giddings, a black-hole researcher at the University of California, Santa Barbara. The LIGO team says that it is aware of the prediction and searching its data for echoes. \n             Beyond reach? \n           The edge of a black hole, known as its event horizon, was long thought to lie beyond experimental reach. According to general relativity, anything that crosses the barrier will be captured by the black hole and have no chance of escape. It will be drawn to the black hole\u2019s core, where all of the hole\u2019s matter is concentrated. \u201cBlack holes were thought to be like bottomless pits,\u201d says cosmologist Niayesh Afshordi at the University of Waterloo in Canada. In the standard picture, this leaves nothing at the event horizon, and someone unlucky enough to cross it wouldn\u2019t notice any sudden change in the environment. But in 2012, physicists based in California realized that if quantum physics is correct, then the event horizon should be  replaced by a firewall , a ring of high-energy particles that would burn any matter that passes through to a crisp \u2014 and that contradicts general relativity 2 . The alternative is that black holes are firewall-free, but this would imply that quantum theory is wrong. Other exotic theories that contradict general relativity also predict some structure at the horizon; for instance, some versions of string theory say that black holes are really \u2018fuzzballs\u2019: tangled up threads of energy with a fuzzy surface in place of a sharply-defined event horizon 3 . However, there did not seem to be any way to peer at the event horizon to find out what, if anything, was there, says Afshordi. \n             Strange deviations \n           That changed in February, when LIGO announced the first direct detection of  gravitational waves , or ripples in space-time. The waves were generated when  two black holes merged 4 . Soon after, a team of physicists led by V\u00edtor Cardoso at the Superior Technical Institute in Lisbon proposed that if there are any strange deviations from general relativity \u2014 such as a firewall \u2014 these black-hole mergers would also release a series of echoes after the initial gravitational-wave burst. The echoes arise because a firewall or any other kind of structure would effectively create a smeared-out region at the traditional event horizon. The inner edge of this region is the conventional event horizon, the boundary beyond which no light particles, or photons, can escape. The outer edge is more porous: a typical photon that crosses this boundary will be trapped by the black hole, but some will be able to escape, depending on their angle of approach. The effect would also partly trap gravitational waves released by the black-hole merger. They would bounce back and forth between the inner and outer edge with some escaping each time. Afshordi\u2019s team set up a simple model in which the black hole is surrounded by mirrored walls, rather than just a conventional event horizon, and applied to it properties of each of the three black-hole mergers so far captured by LIGO. This revealed what the precise time interval between repeated echoes should have been if the black holes have any structure at their event horizons \u2014 around 0.1 seconds, 0.2 seconds and 0.3 seconds. And when they looked at the LIGO data, they found that the release of gravitational waves in all three mergers was followed by successive echoes at exactly those intervals. \n             Improved sensitivity \n           The echoes could be a statistical fluke, and if random noise is behind the patterns, says Afshordi, then the chance of seeing such echoes is about 1 in 270, or 2.9 sigma. To be sure that they are not noise, such echoes will have to be spotted in future black-hole mergers. \u201cThe good thing is that new LIGO data with improved sensitivity will be coming in, so we should be able to confirm this or rule it out within the next two years.\u201d\u00a0 LIGO member Alessandra Buonanno, a physicist at the Max Planck Institute for Gravitational Physics in Potsdam, Germany, says that LIGO scientists are working on an analysis of echo signals. The simple mirror model used by Afshordi is too crude to say whether firewalls, fuzzballs or something else created the echoes. More-sophisticated models could potentially discriminate between these alternatives, he says, by predicting the amplitudes of the echoes, and how quickly they die out. But although the team\u2019s paper offers \u201ctantalizing hints\u201d of a departure from general relativity, so far these are just hints, says Giddings. And he questions whether Afshordi\u2019s mirror model can ever reveal the cause of the deviations from general relativity \u2014 in part because the theories that predict them only provide vague descriptions of what replaces the event horizon, making it tough to accurately model them. A \u201cbasic problem here is we don\u2019t know what is a good physical description of a firewall, or fuzzball\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Black-hole fireworks win big in multimillion-dollar science prizes 2016-Dec-05 \n                 \n                   The black-hole collision that reshaped physics 2016-Mar-23 \n                 \n                   Black holes shrink but endure 2013-Oct-29 \n                 \n                   Astrophysics: Fire in the hole! 2013-Apr-03 \n                 \n                   Gravitational waves \n                 \n                   LIGO \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21142", "url": "https://www.nature.com/articles/nature.2016.21142", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Evidence to parliamentary inquiry puts some figures on the uncertainty hanging over EU university staff. British universities fear losing large swathes of their research staff as the country faces up to Brexit, the split with the European Union. More than 31,000 academics at UK universities are non-British EU citizens, and so may lose their rights to live in the United Kingdom after Brexit. Last week, a UK parliamentary committee  published evidence  from British institutions and funding agencies on the problem, as part of its inquiry into the effects of Brexit on the UK higher education system. It is \"crucial that the long-term position of non-UK EU nationals is clarified as soon as possible\", said Research Councils UK, the umbrella body for the country's seven main grants-funding agencies, in its written statement. Unless the government guarantees EU national academic staff the right to remain, it may not be easy for them to stay. Many have not lived in the United Kingdom long enough to be classified as permanent residents under current rules, and a large fraction do not earn enough on academic salaries to stay by gaining a \u2018skilled worker\u2019 visa.  Nature  runs through the numbers to illustrate the scale of the problem. \n             Science shock \n           On average, some 16% of university researchers are from non-UK EU states. If these EU nationals were to leave, basic science research would be hit harder than other disciplines. Statistics sent to the parliamentary inquiry by the UK Department for Education show that 23% of academic staff in biology, mathematics and physics are EU nationals. \n             Status anxiety \n           EU citizens gain permanent residency rights in the United Kingdom if they have lived there for five years. In the past year, the number of EU nationals applying for cards to prove their residency rights has tripled, according to media reports. But many academics have not lived in the United Kingdom long enough to qualify for permanent residency. At Imperial College London, for example, only 30% of non-UK EU staff are currently eligible to apply for the cards. The university told the House of Commons inquiry committee that it has had \u201ca few examples of scholars choosing not to join Imperial citing the referendum result as a factor\u201d. \n             Salary woes \n           Another route for people to remain in the United Kingdom is to obtain a visa: the \u2018Tier 2\u2019 visa designated for skilled workers. But the Russell Group \u2014 a set of 24 leading research universities \u2014 says that 5,880 EU staff, or around 26% of those institutions\u2019 total workforce, earn less than \u00a330,000 (US$38,000). That salary will be the cut-off for a Tier 2 visa from April 2017. And if non-UK staff do need skilled-worker visas, they\u2019ll have to find more money to pay for the cost of obtaining a visa. The University of Cambridge told the inquiry that visa costs for its non-UK EU staff would amount to some \u00a31.25 million per year. \n             The Scottish quarter \n           Scotland could be particularly at risk from staff problems. Its universities employ 4,595 EU nationals, who make up 17% of academic staff, and an even higher proportion (almost 25%) of research-only staff, according to Universities Scotland. \n                   London super-lab opens under cloud of Brexit 2016-Sep-01 \n                 \n                   UK government gives Brexit science funding guarantee 2016-Aug-15 \n                 \n                   Nature special: Brexit and Science \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21153", "url": "https://www.nature.com/articles/nature.2016.21153", "year": 2016, "authors": [{"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "ExxonMobil chief Rex Tillerson draws scepticism and scorn \u2014 but looks progressive compared with other Trump selections. President-elect Donald Trump has selected Rex Tillerson, chief executive of oil giant Exxon Mobil, to represent the United States abroad as secretary of state \u2014 which would make him the United States' top emissary on climate change. Tillerson took the helm of ExxonMobil, the world\u2019s largest publicly owned oil company, in 2006. He has earned a reputation as an astute businessman, negotiating deals to advance oil and gas exploration around the world. As secretary of state, Tillerson would be likely to take a lead role in carrying out Trump\u2019s  pledge to pull the country out of the Paris climate accord . But first he must win Senate confirmation, which could be a tricky task given that some lawmakers \u2014 including top Senate Republicans \u2014 have raised concerns over his business dealings with Russia. ExxonMobil\u2019s relationship with global warming is complicated and controversial. In the past, the company has funded climate sceptics and organizations that lobby against climate regulation. It is currently under investigation by New York and other states for misleading investors about the risks that climate regulation pose to its business model. But ExxonMobil has softened its opposition to climate policies under Tillerson. The company publicly endorsed the  2015 Paris climate agreement  and has long favoured a carbon tax. This suggests that Tillerson is more progressive than others in Trump\u2019s inner circle: Scott Pruitt, nominated to lead the US Environmental Protection Agency,  does not acknowledge mainstream climate science . \u201cPresident-elect Trump is creating a government of, by, and for the oil and gas industry,\u201d said Ken Kimmell, the president of the Union of Concerned Scientists, an advocacy group in Cambridge, Massachusetts. \u201cNever before have we seen such a concentration of extreme wealth and privilege in a single cabinet.\u201d \n             Mixed reactions \n           Although some environmentalists lampooned Trump\u2019s choice of Tillerson, others took a more cautious stance. \u201cWhile the company has recently acknowledged the human role in climate change and declared support for the Paris Agreement, Tillerson would need to go much further\u201d as secretary of state, said Andrew Steer, president of the World Resources Institute, a think-tank in Washington DC, in a statement. \u201cOne of the critical tests at his confirmation hearings must be his demonstration of a true commitment to America\u2019s leadership on climate action.\u201d And some see Tillerson as a potentially positive force on climate issues within the Trump administration. The climate agenda will certainly take a hit under Trump, \"but frankly I don't think it will be completely disregarded\u201d, says John Deutch, a chemist at the Massachusetts Institute of Technology in Cambridge and former director of the Central Intelligence Agency under President Bill Clinton. \"I would speculate that Rex Tillerson, if he becomes secretary of state, would be more on the side of doing something than doing nothing.\" Still, over the past year, ExxonMobil\u2019s sponsorship of the American Geophysical Union (AGU) has also sparked controversy. Many scientists argued that the AGU should reject the company\u2019s funding, noting ExxonMobil\u2019s history of funding climate sceptics. The AGU declined to do so, but in November the society announced that ExxonMobil had withdrawn its funding. In 2015 that support had been US$35,000 for a student breakfast at the organization's annual meeting. AGU president Margaret Leinen defended her organization\u2019s decisions during a session at the AGU Fall Meeting in San Francisco on 12 December. She said the AGU board had investigated and determined that in the most recent year studied, ExxonMobil has given more money to support climate-change research than to organizations that would seek to undermine that research. This explanation failed to appease critics. Naomi Oreskes, a historian of science at Harvard University in Cambridge, Massachusetts, pointed out that the tobacco industry funded 'good' things \u2014 such as hospitals and cancer-treatment centres \u2014 at the same time that it supported researchers who denied a link between smoking and disease. \"That's how these organizations operate \u2014 they buy our goodwill,\u201d Oreskes said at the meeting. \"What you just told us confirms that the ExxonMobil strategy is the tobacco strategy.\" \n                   Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                 \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Nature  special: Science and the US election \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21155", "url": "https://www.nature.com/articles/nature.2016.21155", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Colleagues travel to visit Adl\u00e8ne Hicheur, who by renouncing French citizenship will soon have his house arrest lifted. Particle physicist Adl\u00e8ne Hicheur has not been able to attend scientific meetings since July, when he was  mysteriously deported from Brazil  and placed under house arrest in the small town of Vienne, in southeastern France. So, in a remarkable show of solidarity, his colleagues working at the Large Hadron Collider (LHC) have brought a workshop to him.\u00a0 This morning, researchers from the LHCb experiment at Europe\u2019s particle-physics laboratory CERN, near Geneva in Switzerland, jumped into shared cars and drove across the French border for the 2-hour journey to Vienne. Around 30 researchers are there: some took trains or flights to reach the town, and another 15 researchers, including some in China, the United States and Brazil, are giving talks by video link-ups. The one-day workshop being held at a business school near Vienne, entitled \u201cBc physics and semileptonic B decays in the LHC era\u201d, includes a 30-minute afternoon break for Hicheur to report to the police station, under the terms of his house arrest. Hicheur himself is giving a talk on the properties of a kind of particle called a charmed B meson. \u201cSeveral of my colleagues and I organized the workshop to give concrete support to Adl\u00e8ne, and show him that a large fraction of our community is close to him,\u201d says Vincenzo Vagnoni, physics coordinator of the LHCb and a researcher at Italy\u2019s National Institute of Nuclear Physics in Bologna. The Vienne workshop also serves as a poignant farewell to Hicheur, says Vagnoni. That is because Hicheur has found a way to have his house arrest lifted \u2014 but it requires that he move to Algeria, where it will be very difficult for him to establish a high-energy physics group. Hicheur is Franco-Algerian, and in October, he took the drastic step of informing the French government that he would renounce his French nationality, and asking to be allowed to leave the country. French authorities have agreed, provided that they are given clear details of how Hicheur intends to leave and that police escort him to the airport. Hicheur says that he intends to fly out in the next two weeks. \u201cHe will likely have to leave the only passion of his life \u2014 physics. This workshop in Vienne is also to tell him goodbye and wish him all the best for the continuation of his life,\u201d says Vagnoni. \n             Solidarity in physics \n           In Brazil, Hicheur had been building a new life at the Federal University of Rio de Janeiro, after serving just over three years in prison in France without trial. In 2012, he was  eventually convicted  of an offence: allegedly plotting with al-Qaeda\u2019s North African branch to carry out attacks on economic and military targets on French soil. Having served his jail time, he was released a few days later. Hicheur and his supporters, including scientific colleagues, have long argued that this conviction was  a miscarriage of justice  based on flimsy evidence. Hicheur\u2019s July deportation from Rio de Janeiro \u2014 after which French authorities immediately placed him under house arrest \u2014 sparked protests from colleagues who say it was unjustified and arbitrary. \"I think Adl\u00e8ne was extremely unlucky to fall into the alignment of three non-trivial things: the political crisis in Brazil, the upcoming Olympic Games and the state of emergency in France,\u201d says Vagnoni. Other researchers have supported Hicheur, too. Last month, organizers of the  Latin American Symposium on High Energy Physics , in Antigua, Guatemala, arranged for Hicheur to give his plenary talk by video from his home in Vienne at around midnight his time, and to provide him with an opportunity to explain his personal situation to the audience. The arrangement was an expression of solidarity from the community, says John Ellis, a CERN theoretical physicist at King\u2019s College, London, who helped to organize the video link and introduced Hicheur's plenary. But it was also important for science that the Brazilian LHCb arm had chosen Hicheur to present their latest results on their behalf, he says. \u201cAll of what has happened is a tragedy for Adl\u00e8ne,\u201d he adds. \u201cI am very touched by these gestures,\u201d says Hicheur. \u201cBeyond the all-important support of my family, the support of colleagues during difficult times has been fundamental.\u201d He says that he intends to continue to pursue legal proceedings in Brazil challenging the legality of his deportation. Hicheur does not yet have firm future plans for when he moves to Algeria. But he says that he intends to stay in science, perhaps initially teaching physics at a university in Algeria, or pursuing his interests in sustainable development, and perhaps resuming his particle-physics career elsewhere. He is stoic about his experiences. \u201cI try to be positive even in the worst situations,\u201d he says. \u201cWhat happened was a rich experience \u2014 it\u2019s an asset.\u201d \n                   Researchers should join protests over detained scientist 2016-Sep-14 \n                 \n                   Mystery deportation of particle physicist leads to swell of protest 2016-Sep-14 \n                 \n                   French standoff raises fears for incarcerated physicist 2012-Mar-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21160", "url": "https://www.nature.com/articles/nature.2016.21160", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Former Texas governor Rick Perry lacks the technical background of the agency's recent leaders. President-elect Donald Trump plans to nominate former Texas governor Rick Perry to lead the Department of Energy (DOE). Perry, a former farmer and US Air Force pilot, led Texas from 2000 to 2015. Unlike the last three energy secretaries, he has no technical background in the physical sciences, technology or nuclear weapons \u2014 subjects at the core of the department's mission. And when he sought the Republican presidential nomination in 2012, Perry proposed abolishing the energy department (and famously forgot its name during a primary debate). \u201cIf you don\u2019t have the technical background and you don\u2019t have the exposure to the weapons labs, you have to be on a really fast learning curve,\u201d says Michael Lubell, a physicist at the City College of New York. \u201cTime will tell what happens with Perry, but he starts with a great disadvantage.\u201d Perry does have experience in dealing with Texas' powerful oil and gas industry. As governor, he supported fossil-fuel production \u2014 and questioned the science underlying climate change. But the state also significantly boosted its share of renewable energies such as wind and solar during Perry's tenure.\u00a0 \n             An awkward transition? \n           Salo Zelermyer, a lawyer at the firm Bracewell in Washington, DC and former DOE counsel under President George W. Bush, says Perry embraced an \u201call-of-the-above\u201d approach to energy policy in Texas. \u201cThis track record will serve Perry well not only in leading DOE but also in becoming a significant part of the new Administration\u2019s approach to issues like regulatory reform and infrastructure investment,\u201d Zelermyer said in a statement. Lubell notes that Perry would not be the first energy secretary without a technical background, nor even the first who has proposed eliminating the DOE. Spencer Abraham, who served under President Bush, once did the same. Having a technical background does not guarantee success in leading the department, Lubell adds, but it does make it easier to manage the agency's science portfolio and  its sprawling complex of nuclear weapons laboratories . John Deutch, a chemist at the Massachusetts Institute of Technology in Cambridge and former director of the Central Intelligence Agency under President Clinton, says his biggest concern is Perry\u2019s lack of experience with the energy department's broader portfolio. He says that Trump should identify a deputy energy secretary who understands national defense and the weapons programme, as well as experienced experts to lead the energy and basic science programmes. Deutch, who leads the energy department's advisory board, says there is reason to hope for a smooth transition. He had a leadership post at the department under President Jimmy Carter and witnessed the changeover when Ronald Reagan entered the White House. The switch was not as disruptive as many feared it would be, he says. \u201cPerhaps with the dimming memories of an old man, I have hope that this transition will be positive,\u201d Deutch adds. \u201cNot better, but positive.\u201d Perry would succeed Ernest Moniz,  an accomplished and politically savvy nuclear physicist  who helped President Barack Obama's administration  negotiate a nuclear deal with Iran  last year. Obama's first energy secretary was  physicist and Nobel laureate Steven Chu , who overcame resistance from Republicans in Congress to boost and diversify the department's clean-energy research. Perry\u2019s nomination comes at a tense moment within the DOE. Trump\u2019s transition team has riled staff by circulating a memorandum calling for the names of department officials who have been involved in climate policy \u2014 raising fears of blacklisting or retaliation. The department has refused to comply with the request, and says that it will only provide the transition team with publicly available information. \n                   What Trump\u2019s pick for secretary of state could mean for climate policy 2016-Dec-13 \n                 \n                   Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                 \n                   Nuclear summit a test for Obama's legacy 2016-Mar-30 \n                 \n                   Iranian researchers welcome nuclear deal 2015-Jul-15 \n                 \n                   Physicist tipped for US energy post 2013-Feb-25 \n                 \n                   US science: The Obama experiment 2012-Sep-26 \n                 \n                   Nature  special: Science and the US election \n                 \n                   Scientists confront Perry administration over censorship in Texas \n                 \n                   Trump transition website \n                 Reprints and Permissions"},
{"file_id": "540328a", "url": "https://www.nature.com/articles/540328a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "How to rouse the immune system against tumours has proved elusive. Could predictive algorithms be the key to creating a successful cancer vaccine? Two US nonprofit organizations plan to find out by pitting a range of computer programs against each other to see which can best predict a candidate for a personalized vaccine from a patient\u2019s tumour DNA. The Parker Institute for Cancer Immunotherapy in San Francisco, California, and the Cancer Research Institute of New York City announced the algorithmic battle on 1\u00a0December. It is part of a multimillion-dollar joint project to solve a major puzzle in the  nascent field of cancer immunotherapy : which of a patient\u2019s sometimes hundreds of cancer mutations could serve as a call-to-arms for their immune system to attack their tumours. If the effort succeeds, it could spur the development of personalized cancer vaccines that use fragments of these mutated proteins to fire up the body\u2019s natural immune responses to them. Because these mutations are found in cancer cells and not healthy ones, the hope is that this would provide a non-toxic way to battle tumours. The idea is gaining traction. In 2014, news that vaccines containing such mutated proteins had vanquished tumours in mice set off a mad dash to  find out whether the approach would work in people . A generation of biotechnology companies has been founded around the concept, and clinical trials run by academic labs are under way. Still, a challenge remains. To be a good candidate for a vaccine, a mutated cancer protein must be visible to T cells, the soldiers of the immune system. And for that to happen, tumour cells must chew up the protein into fragments. Those fragments then must bind to specialized proteins, which are shipped to the cell\u2019s surface to be displayed to passing T cells. The trick that vaccine researchers must master is using a tumour\u2019s DNA to predict which mutations to home in on. \u201cWe can do the sequencing and find out the mutations, but it\u2019s very hard to know which of these tens or hundreds or thousands of mutations are actually going to protect people from the growth of their cancers,\u201d says Pramod Srivastava, an immunologist at the University of Connecticut School of Medicine in Farmington. One approach is to use algorithms to predict which bits of a mutated protein might be seen by a T cell. These work by analysing where the proteins could be cleaved, for example, and which of the resulting fragments will bind tightly to the molecules that put them on display. But each laboratory has a different \u201csecret sauce\u201d, says Robert Schreiber, a cancer immunologist at Washington University in St. Louis, Missouri. And most are not very predictive: Robert Petit, chief scientific officer of biotechnology company Advaxis in Princeton, New Jersey, estimates that the algorithms are typically less than 40% accurate. To solve the problem, the Parker Institute and the Cancer Research Institute launched their challenge. They have arranged for 30\u00a0laboratories that already use such algorithms to apply their secret sauces to the same DNA and RNA sequences. The sequences will come from cancers such as melanoma and lung cancer, which tend to have many hundreds of mutations (see \u2018Mutation map\u2019) and thus could provide ample possibilities for a vaccine. A handful of other laboratories will then test whether any T cells in the tumour recognize those fragments, and are stimulated by them\u00a0\u2014\u00a0a sign of a good vaccine target. The alliance will not publicly announce a winner, but hopes to use the most accurate algorithms to design vaccines for clinical trials. Algorithms can provide a quick answer to a complicated question \u2014 crucial if personalized vaccines are to be deployed on a large scale. But ultimately, Srivastava says that the best way to improve the algorithms is to collect more data from animal studies to learn about how T cells naturally respond to mutations. His lab and others are making hundreds of putative vaccines tailored to an individual tumour, and administering them to mice to see which are capable of fighting the cancer. And Drew Pardoll, a cancer immunologist at Johns Hopkins University in Baltimore, Maryland, worries that algorithms may never account for some factors that influence T-cell responses. For example, mutations may be less suitable for a vaccine if they have arisen early in tumour development, giving the immune system time to begin viewing them as \u2018normal\u2019. Pardoll argues that the field needs faster, easier and more accurate laboratory tests to determine which mutations best trigger a T-cell response. \u201cWe don\u2019t yet know enough about the rules to make perfect predictions,\u201d he says. \u201cYou can algorithm until the cows come home and you\u2019re not really going to know if you\u2019re improving things.\u201d But in the absence of speedy lab tests, companies need algorithms, argues Robert Ang, chief business officer at Neon Therapeutics of Cambridge, Massachusetts. \u201cThere is already evidence to show that this approach works despite the imperfect algorithms,\u201d he says. \u201cImproving the algorithms even more could be very meaningful.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Researchers push for personalized tumour vaccines 2016-Apr-22 \n                   \n                     Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                   \n                     Tumour mutations harnessed to build cancer vaccine 2015-Apr-02 \n                   \n                     Immune system offers clues to cancer treatment 2014-Nov-26 \n                   \n                     Nature Collection: Cancer immunotherapy \n                   \n                     US National Cancer Institute: Cancer vaccines \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21130", "url": "https://www.nature.com/articles/nature.2016.21130", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Researchers are reaching out to the US president-elect with science advice \u2014 and criticism. Kelly Ramirez was distraught as she watched the US presidential election results come in on 9 November. The soil microbial ecologist at the Netherlands Institute of Ecology in Wageningen started texting friends \u2014 all women scientists \u2014 back in the United States. They were appalled at the eventual winner, Republican Donald Trump, for what they saw as his cavalier attitude towards facts and discriminatory actions against groups  such as Muslims , Latinos and women. Although few of the scientists had any experience with political activism, they felt an urge to respond to Trump\u2019s victory. \u201cBy Thursday I said, \u2018enough crying about it: let\u2019s do something,\u2019\u201d Ramirez says. The result was  a pledge signed by more than 11,000 women scientists  in which they commit \u201cto build a more inclusive society and scientific enterprise\u201d. It is just one manifestation of the scientific community\u2019s unusually active response to the incoming president. Around the world, individual researchers and representatives of scientific societies are signing letters of protest or advice, offering to counsel Trump\u2019s transition team and ramping up efforts  to communicate the value of science to the public . \u201cIt is an encouraging sign that there is a \u2018Trump effect\u2019 on scientists\u2019 willingness to stand up for science,\u201d says Geoffrey Supran, a climate scientist at Harvard University and the Massachusetts Institute of Technology, both in Cambridge. Supran, who has a history of climate activism, helped to organize  a letter to Trump on climate policy  that was signed by more than 800 Earth scientists. Other recent open letters to Trump include a 30 November missive signed by 2,300 scientists \u2014 including 22 Nobel prizewinners \u2014 urging \u201ca strong and open culture of science\u201d in the executive branch of government; it was organized by the Union of Concerned Scientists (UCS), an advocacy group in Cambridge, Massachusetts. And the leaders of 29 scientific societies signed a 23 November letter encouraging Trump to  choose a \u201cnationally respected\u201d science adviser   without delay . Although scientific societies sent a similar message to Barack Obama just after his election in 2008, there was increased interest in this year\u2019s letter, says organizer Rush Holt, chief executive of the American Association for the Advancement of Science. \u201cThis election represented such a large change and threw such uncertainty onto the place of science in American government that we really had to reach out right away to the president-elect,\u201d he says. \n             'We heart science' \n           Some scientists are taking their protests to the streets. At the American Geophysical Union meeting in San Francisco on 13 December, researchers participated in a \u201cstand up for science\u201d rally held near the convention centre. About 30 scientists donned lab coats and held up signs such as \u201cIce has no agenda \u2014 it just melts\u201d on the steps behind a red-brick Catholic church. The hundred-plus people in the crowd of onlookers appeared to contain few, if any, dissenters. They held signs such as \u201cWe heart science\u201d and, on cue, burst into chants of \u201cStand up for science\u201d. Kim Cobb, a palaeoclimatologist at the Georgia Institute of Technology in Atlanta, told the crowd that she learned of Trump's win while on a research expedition in the tropical Pacific. The implications didn\u2019t sink in until she returned to the laboratory where she studies links between climate change and coral die-offs. \u201cThe nightmare continues and keeps getting worse every day,\u201d she said. Cobb told  Nature  that she is worried about the long-term safety of US government climate datasets and other federal research infrastructure. Trump\u2019s transition team recently asked the Department of Energy for lists of government employees who worked on climate-change policy ( a request the department has refused ). Cobb fears that the Trump administration will interfere with the work of researchers inside and outside the government. \u201cNow is the time to say something,\u201d she said. \"How many thousands of our peers are still in the poster halls?\" \n             A sense of urgency \n           Andrew Rosenberg, director of the Center for Science and Democracy at the Union of Concerned Scientists, says that researchers seem more eager to voice opinions on Trump than they did for previous presidents. Scientists were much slower to add their names to an open letter to George W. Bush that the UCS organized in 2004, says Rosenberg \u2014 which he sees as  a reflection of uneasiness about Trump , but also a sign that younger scientists are more comfortable taking public positions on policy. Other researchers disagree with the friendly tone of many of the Trump letters, given the president-elect\u2019s policy positions \u2014 which include  questioning the science underlying climate change  and  proposing to build a wall along the US border with Mexic o. Such objections led the American Physical Society to withdraw a 9 November press release that congratulatedTrump on his election and urged him to help the United States \u201creclaim its scientific leadership, which it has lost during the past decade\u201d. The statement continued: \u201cAPS believes that such policies will help the Trump administration achieve its goal captured by its slogan, \u2018Make America Great Again.\u2019\u201d But Jamie Vernon, director of science communications and publications for Sigma Xi, a scientific honour society in Research Triangle Park, North Carolina, thinks that researchers should offer to help Trump for the sake of society. Refusing to work with the new administration, he says, \u201ccreates a void where others who don't agree with the scientific consensus will fill those positions\u201d. Jacquelyn Gill, a palaeoecologist at the University of Maine in Orono, understands the theory behind this approach, even if it makes her uncomfortable. \u201cIt is fine if you want to sign respectful letters, but that better not be all you do,\u201d she says. For those who are looking to step up their activism, Representative Bill Foster has a suggestion: run for office. Foster, an Illinois Democrat who is the only PhD-holding scientist in Congress, says that entering politics might seem daunting to a person who has spent her career in the lab \u2014 but he is willing to help. \u201cAny scientists who are interested should contact my office,\u201d says Foster, a physicist. \u201cIt is something I plunged into without any training and ending up doing all right. Ultimately, that is the way the feedback loop of our democracy operates.\u201d  Alexandra Witze contributed reporting from San Francisco, California. \n                   Does it matter if Donald Trump has a science adviser? 2016-Dec-08 \n                 \n                   Trump\u2019s pick for environment agency chief sued government over climate rules 2016-Dec-07 \n                 \n                   How to trump group-think in a post-truth world 2016-Dec-02 \n                 \n                   Tracking the Trump transition, agency by agency 2016-Nov-30 \n                 \n                   Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                 \n                   Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                 \n                   How scientists reacted to the US election results 2016-Nov-09 \n                 \n                   Nature  special: Science and the US election \n                 \n                   Open letter to Trump on climate science \n                 \n                   Women scientists' pledge \n                 \n                   Scientific societies' letter to Trump on the need for a US science adviser \n                 Reprints and Permissions"},
{"file_id": "540323a", "url": "https://www.nature.com/articles/540323a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Artificial-intelligence algorithms can learn a lot from playing immersive 3D video games. The  Minecraft  video game was familiar to Jos\u00e9 Hern\u00e1ndez-Orallo long before he started using it for his own research. The computer scientist, who devises ways to benchmark machine intelligence at the Polytechnic University of Valencia in Spain, first watched his own children play inside the 3D\u00a0virtual world, which focuses on solving problems rather than shooting monsters. In 2014, Microsoft bought  Minecraft , and its science arm, Microsoft Research, gave its own researchers access to a new version of the game that allowed computer programs, as well as people, to explore and customize the 3D environment. Then, after inviting a small group of outside researchers that included Hern\u00e1ndez-Orallo to download the machine-friendly version of the world, last July, Microsoft made it freely available to anyone, with the goal of speeding up progress in artificial intelligence (AI). Now other companies have followed suit. On 5 December, DeepMind, a unit of Google headquartered in London, opened up its own 3D virtual world, DeepMind Lab, for download and customization by outside developers. The company initially created the world to train its own AI programs. Also on 5 December, OpenAI, a research company in San Francisco, California, co-founded by entrepreneur Elon Musk, released a \u2018meta-platform\u2019 that enables AI programs to easily interact with dozens of 3D games originally designed for humans, as well as with some web browsers and smartphone apps. All three releases provide researchers and software developers with easy ways to test programs in previously unseen situations, and for the programs to acquire new skills by teaching themselves to navigate novel situations that resemble real-world scenarios. \u201cEnvironments like these have a very important role to play in the future of AI,\u201d says Pedro Domingos, a machine-learning researcher at the University of Washington in Seattle. \n               Atari algorithm \n             Games have been test beds for AI for decades, but, typically, the algorithms have played them following predefined strategies. In recent years, the focus has shifted to machines that could learn from their own experience. In early 2015, DeepMind unveiled an algorithm that taught itself how to play classic Atari arcade games better than any human, by trial and error, without being told the goals of the games. Such games are simple 2D worlds, though. \u2018First-person\u2019 3D video games such as  Minecraft \u00a0\u2014\u00a0which visually embed the player in the environment\u00a0\u2014\u00a0are a much closer approximation to the real world, and so make more sophisticated test beds. Minecraft  enables users to interact with virtual bricks, and use them to build structures, in addition to navigating and interacting with predefined structures. The version now available to developers, called Malmo, allows algorithms to do the same. Hern\u00e1ndez-Orallo, for example, is using this to explore whether the environment can be used to create benchmarks for machine intelligence. Algorithms could compete to arrange bricks into something that looks the most like a certain object, say, or to navigate a maze\u00a0\u2014\u00a0testing a much wider range of skills than  the Turing test , the most famous test of machine intelligence, which focuses on the ability of an AI to chat like a human. One of the things that made  Minecraft  attractive for conversion into an AI test bed is that it already enabled players to communicate using text messages. This could help an AI to learn to collaborate with humans in the real world, says computer scientist Katja Hofmann of Microsoft Research in Cambridge, UK, who led the team that created Malmo. \n               Robot rehearsal \n             Virtual worlds are also particularly useful for developing AIs that are destined to eventually operate as physical robots, says Hofmann, because such environments are cheaper to customize, and faster and safer to practise in than the real world. They also allow robotics researchers to focus purely on the intelligence part of the equation\u00a0\u2014\u00a0the mechanical challenges of physical robots can be a distraction. In addition to Hern\u00e1ndez-Orallo, Microsoft Research has collaborations with a handful of research labs that are using Malmo projects. But Hofmann suspects that many more are using it, perhaps around 100. DeepMind Lab similarly allows researchers to create structures such as mazes, and their algorithms can learn to collect rewards as well as to navigate. DeepMind has also been experimenting with integrating \u201cmore naturalistic elements\u201d, such as undulating terrains and plants, into the platform, says a spokeswoman. Now that the environment is open, the company hopes that other researchers will help to make the environments more challenging for the algorithms. \u201cBy open-sourcing it, we are allowing the wider research community to get involved in shaping this,\u201d she says. OpenAI\u2019s meta-platform, Universe, takes things even further. By providing multiple, radically different environments for the same AI to sample, it could help to attack one of the hardest problems in the field: creating algorithms that can use previous experience when faced with new situations. For instance, deep neural networks, which mimic the layers of brain cells in the visual cortex, can quite quickly learn to navigate a 3D maze, but cannot transfer the knowledge to navigate another maze. \u201cIf you change the colour of the maze, the system is completely lost,\u201d says Hern\u00e1ndez-Orallo. \u201cState-of-the-art technology fails dramatically.\u201d Microsoft is now working to make Malmo available through Universe. \u201cHaving a community platform will accelerate everyone,\u201d says Greg Brockman, co-founder and chief technology officer of OpenAI. \n               \n                 Tweet \n                 Follow @NatureNews \n                 Follow @dcastelvecchi \n               \n                     AI talent grab sparks excitement and concern 2016-Apr-26 \n                   \n                     Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                   \n                     Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                   \n                     Project Malmo \n                   \n                     DeepMind Lab \n                   \n                     OpenAI Universe \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21163", "url": "https://www.nature.com/articles/nature.2016.21163", "year": 2016, "authors": [{"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "Rare winter expedition near northern Norway finds weak ice that is increasingly vulnerable to storms. San Francisco, California A daring 2015 expedition that collected rare measurements of the Arctic in winter found that sea ice near the North Pole was thinner and weaker than expected. \u201cThis  thinner and younger ice in the Arctic today  works very differently than the ice we knew,\u201d says Mats Granskog, a sea-ice researcher at the Norwegian Polar Institute in Troms\u00f8 and chief scientist on the expedition, called the Norwegian Young Sea Ice (N-ICE2015) project. \u201cIt moves much faster. It breaks up more easily. It\u2019s way more vulnerable to storms and winds.\u201d The team froze its research vessel,  Lance , into the ice pack north of Norway\u2019s Svalbard archipelago in January 2015. As the ship drifted in the ice, the research crew gathered data and camped on nearby ice floes. The campaign, which ended in June 2015, was the first major effort to collect winter data in that part of the Arctic, says Granskog. The only other large expedition to observe the region's winter ice was the Surface Heat Budget of the Arctic (SHEBA) project; between October 1997 and October 1998, researchers funded by the US National Science Foundation monitored conditions north of Alaska. \u201cMeasurements from the Arctic in winter are quite rare,\u201d says Von Walden, an atmospheric researcher at Washington State University in Pullman who participated in the Norwegian expedition. \u201cThey are very difficult to obtain because quite honestly it\u2019s dangerous work.\u201d \n             On thin ice \n           The team had to move its operations several times because of instability in the ice floes where it camped. \u201cWe had to battle the dark, the cold, violent storms, ice that broke up under our feet many times,\u201d Granskog says. \u201cWe had to escape from the ice and rescue our camps. We had to look out for polar bears that looked friendly, but weren\u2019t always so friendly to us or our equipment.\u201d The Norwegian project cost roughly US$5 million and involved more than 70 researchers from 10 countries. The researchers presented some of the first results from the expedition this week at the American Geophysical Union\u2019s Fall Meeting in San Francisco. Measurements made during summer expeditions have shown widespread thinning of Arctic sea ice, but researchers were not sure what the conditions were like in winter. \u201cWe saw a new Arctic where the ice is much thinner, only 3 to 4 feet thick,\u201d says Granskog. \u201cAnd this ice functions very differently than it did 10 years ago.\u201d That had ripple effects below the ice, says Amelie Meyer, an oceanographer at the Norwegian Polar Institute. \u201cWhen  storms came through , it moved the ice so fast that it actually stirred water under the ice. This helped bring warm water from below much closer to the surface and actually induced some melt of the ice from below.\u201d As spring returned to the Arctic, the ice melted much faster than expected in some areas. On one morning near the end of the expedition, the researchers awoke to a rapidly growing crack in the ice where they had made their camp. The team had to scramble to collect its gear and equipment before the items \u2014 and the data \u2014 sunk into the sea. \u201cIt was a little epic,\u201d says Meyer. \u201cWe did recover absolutely everything.\u201d The researchers were surprised to find an explosion of phytoplankton growth under the snow-covered pack ice in mid-May. This is the earliest and more northern phytoplankton bloom ever witnessed, they say. \n             Regime change \n           Arctic researchers say that the observations from the Norwegian project will help to fill gaps in knowledge about  the rapidly changing region . Thirty years ago, the majority of the winter ice in the Arctic ocean was thick multi-year ice that grew over multiple winters. But now, more than three-quarters of the ocean in late winter is covered by much younger and thinner first-year ice. The SHEBA project studied multi-year ice and researchers do not have much information about first-year ice, says Donald Perovich, chief scientist of SHEBA and a sea ice researcher US Army Corps of Engineers' Cold Regions Research and Engineering Laboratory in Hanover, New Hampshire. \u201cOne of the things that\u2019s really important about N-ICE is that it\u2019s looking at first year ice in an Arctic ocean that\u2019s dominated by first-year ice,\u201d he says. An international team is now planning to freeze a German icebreaker into Arctic sea ice in October 2019 for a year-long investigation that will focus mostly on first-year sea ice.  \n                   No safe haven for polar bears in warming Arctic 2016-Sep-14 \n                 \n                   Speedier Arctic data as warm winter shrinks sea ice 2016-Mar-01 \n                 \n                   Summer storms bolster Arctic ice 2013-Aug-28 \n                 \n                   Arctic sea ice declines to record low \n                 \n                   Norwegian Young Sea Ice Project \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21144", "url": "https://www.nature.com/articles/nature.2016.21144", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Tallest specimen deduced from 3.7-million-year-old footprints in Tanzania. The sound was more like a squish than a thud, as the tall male australopith strode across the East African savannah. A volcanic eruption had left a patina of grey ash underfoot, while rainstorms that followed transformed the earth into wet cement. Squish, squish. Four smaller individuals walked not far behind. Squish, squish, squish. Later, ash rained down from the sky again, covering their tracks for 3.66 million years. The first traces of this journey \u2014 tracks from three individuals that are the oldest-known footprints of any ancient human relative \u2014 were discovered in the 1970s in northern Tanzania by the anthropologist Mary Leakey and her team 1 . Now, 40 years later, researchers have found more hominin footprints at the world-famous site, called Laetoli. They comprise tracks from two more individuals, including those of a man who would have weighed 48 kilograms and stood 1.65 metres tall, larger than any other  Australopithecus  in the fossil record. Researchers have named him Chewie, after the 2-metre-tall Star Wars character Chewbacca. (The Swahili word for leopard, chui, is also pronounced in a similar way, they note). The new Laetoli footprints, described in  a 14 December study in the journal  eLife 2 , suggest that early hominins may have had a social structure similar to that of gorillas, in which a large male dominates a group of smaller females. The prints also raise tough questions about how to stop the impressions from eroding away, scientists say. \n             Fragile footprints \n           The new tracks were discovered because of efforts to preserve the original 23-metre-long trail of footprints. They are  threatened by tree roots, water and erosion  and have been covered with soil for protection for most of the time since the 1990s. The Tanzanian government had approved  a plan to build a museum at the site , including a protective covering for the tracks. In preparation, archaeologist Fidelis Masao, at the University of Dar es Salaam in Tanzania, dug trenches to survey the area and in October 2014 uncovered a large hominin footprint. Further excavations \u2014 at a site 150 metres from the original prints \u2014 found 12 more large prints, creating a 32-metre-long track, and an additional footprint from a smaller individual. The original Laetoli prints have been attributed to  Australopithecus afarensis  \u2014 the same species as  the 3.2-million-year-old remains from Ethiopia known as Lucy  \u2014 and Masao and Cherin\u2019s team think the new prints were probably made by individuals in the same social group. Both sets of prints were made by individuals walking in the same north-westerly direction, and probably during a single trip, Masao and his colleagues suggest. They were found in the same layer of volcano ash and, therefore, were likely created by identical conditions. \u201cIt\u2019s really amazing to think about this group walking in the same direction with the same speed,\u201d says Marco Cherin, a vertebrate palaeontologist at the University of Perugia, Italy, who co-led the study. \"Walking to where, we don\u2019t know. They were probably just walking like all the other animals who left their footprints in Laetoli.\u201d Chewie's footprints stand out as much larger than the others: they are 27 centimetres long, nearly as long as Cherin's size 10 (UK) feet. Cherin says the new footprints point to much greater variation in body size among early hominins than previously suspected, while challenging the idea that they evolved large bodies only when their brains grew bigger in the past 2.5 million years. His team estimates that the other individuals at Laetoli would have stood between 1.11 m and 1.49 m tall. \n             Bodies great and small \n           The range of body sizes at Laetoli may also relate to the social structure of the hominins there. The team suggests that the largest prints were made by an adult male, whereas the other prints belong to two adult females and two juveniles or smaller females. Gorilla groups, in which a silverback male associates with a harem of much smaller females and their offspring, show a similarly wide range of body sizes, notes Cherin, who thinks that australopiths may have adopted a similar setup. But Neil Roach, a palaeoanthropologist at Harvard University in Cambridge, Massachusetts, says the relationship between social structure and body-size differences between sexes is not so clear-cut. Nevertheless, he thinks the new tracks support current thinking that  A. afarensis  was a species that lived in groups composed of multiple males and females, and that there were large differences in body sizes between the sexes. Bruce Latimer, a palaeoanthropologist at Case Western Reserve University in Cleveland, Ohio, agrees that conclusions about  Australopithecus  social groups should be taken with a pinch of salt. But Latimer, who has worked on the original prints, calls the new set \u201ca dramatic and exciting discovery\u201d that adds to evidence that individuals at Laetoli had feet that were not so different from those of present-day humans. \u201cThe Laetoli prints would not attract attention on a modern beach,\u201d he adds. Plans for the museum are on hold while researchers look for more footprints and examine the state of the original tracks, says Charles Musiba, an anthropologist at the University of Colorado, Denver, who is involved with the conservation efforts. The current plan, he says, is to build research and education facilities outside a 1.5-kilometre buffer zone from the site, while investigating the best place for a museum to protect and display the footprints, which have all been reburied. \u201cWe\u2019re going to leave them the way they are for now,\u201d Musiba says. After Masao discovered the newest prints, he says the first person he phoned was Richard Leakey, one of the sons of Mary Leakey (who died in 1996). \u201cHe said \u2018Well, Fidelis, much as I congratulate you, I also pity you. Nature has preserved them for 4 million years. How will you make sure they stay intact for millions of years to come?\u2019\u201d Masao says. \u201cI did not have an answer.\u201d Reprints and Permissions"},
{"file_id": "540180a", "url": "https://www.nature.com/articles/540180a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers in the country have only just started using homegrown human embryonic stem cells Fabi\u00e1n D\u00edaz achieved a milestone last year when he derived the first human embryonic stem-cell line from cells of Mexican origin. Biologists across Mexico now use the stem cells, which D\u00edaz \u2014 a researcher at the National Institute of Perinatology in Mexico City \u2014 created using embryos discarded by a fertility clinic. But in recent months, D\u00edaz has put his stem-cell research on hold. He is waiting to see whether Mexico\u2019s legislature will approve an amendment to the national health law that would ban experiments with human embryos. The proposal is winding its way through the legislature\u2019s lower house, the Chamber of Deputies. To become law, it would have to be approved by the legislature and by Mexico\u2019s president, Enrique Pe\u00f1a Nieto. \u201cThey want to eliminate an entire area of research in Mexico,\u201d says Ren\u00e9 Drucker-Col\u00edn, a neurobiologist at the National Autonomous University of Mexico (UNAM) in Mexico City who hopes to use embryonic tissue as a treatment for people with Parkinson\u2019s disease. The amendment is intended to regulate assisted reproduction, including the payment of surrogate mothers, donations to egg and sperm banks and the fertilization of more than three eggs at a time. But it would also ban the creation of human embryos for any purpose except reproduction and any research with existing human embryos. Such restrictions are intended to address Mexico\u2019s thriving reproductive tourism industry, which has few protections for surrogate mothers. But the proposed amendment would have prohibited a scientific world first that took place in Mexico: the conception of a  baby with DNA from three people . The child was born in April. His parents, who are from Jordan, used the treatment to prevent their baby from inheriting a disease that would otherwise be passed down through his mother\u2019s mitochondrial DNA. The proposed changes to Mexico\u2019s health law have the backing of the National Action Party (PAN) and Pe\u00f1a Nieto\u2019s Institutional Revolutionary Party (PRI), but researchers worry that they are too broad. \u201cWe\u2019re not against the regulation,\u201d says Diana Escalante, a neurodevelopmental biologist at UNAM. \u201cBut the way in which they are doing it is just forbidding everything.\u201d The amendment would prevent the creation of new embryonic stem-cell lines, she says, as well as a standard way to test whether the cells can develop into any cell type in the body. The penalties for violating the restrictions would include heavy fines and imprisonment. Human-rights groups have joined scientists in opposing the proposed amendment, which would restrict artificial reproduction to heterosexual couples. Only Mexican-national couples would be able to use surrogate mothers, who would be limited to their relatives. Opponents of the plan say that it discriminates against same-sex couples and people without family members of reproductive age. But Rosa Velez, a spokesperson for Sylvana Beltrones, the legislator who authored the amendment, says that the restrictions would protect human dignity and the legal rights of children who are created using fertility techniques and their parents. She adds that scientists would be able to study stem cells obtained from adults. Researchers have protested against the plan. On 24 October, more than 60 Mexican scientists sent a letter to the newspaper  El Universal  critizing the proposed amendment. Drucker-Col\u00edn says that he has also asked Mexico\u2019s National Academy of Sciences to intercede with the politicians. \n               Early developments \n             The amendment would make it harder for scientists to study the earliest stages of human development, says Iv\u00e1n Velasco, a neurodevelopmental biologist at UNAM and president of the Mexican Society for Stem Cell Research. \u201cIt\u2019s possible people will train abroad, but if they want to come back they won\u2019t be able to do it here,\u201d he says. Yet Velasco thinks that his own work, which uses existing human embryonic stem-cell lines, would be permitted. Others are worried about how a ban on the use of embryonic stem cells would affect clinical research. \u201cWe are close to beginning working with [embryonic stem] cells, and these laws are going to trash everything,\u201d says Raymundo Ca\u00f1ales de la Fuente, a research gynaecologist at the Hospital Angeles Pedregal in Mexico City whose group looks for ways to improve the efficacy of assisted reproductive techniques. The amendment would limit the use of routine techniques used in fertility clinics, including a method used to screen embryos for genetic mutations before they are implanted into the mother. Such screening can prevent the transmission of severe genetic diseases, and help some infertile couples to understand why they are having trouble conceiving. If the technique is banned, researchers would need to rely on older, less precise methods to determine whether embryos are likely to survive implantation, says Patricia Grether, a geneticist at the National Institute of Perinatology. Clinicians could also send patients to the United States for treatment, but that is too expensive for many Mexicans. Velez says that the intent of the proposed amendment is to improve assisted reproduction, not to ban it. But Ca\u00f1ales de la Fuente says that the proposal would prevent many reputable clinics from offering such services. Clinicians would be limited to fertilizing three eggs at a time, reducing their success rates. They would also have to verify that a couple is not storing fertilized eggs at another clinic. With more than 100 such clinics in Mexico City alone, there is no practical way to do this. \u201cWe need to make a new law,\u201d Ca\u00f1ales de la Fuente says. \u201cCompletely different from this one, with a scientific basis and a medical basis to be practical \u2014 and from the ministry of health, not from the congressmen.\u201d \n                     Reports of \u2018three-parent babies\u2019 multiply 2016-Oct-19 \n                   \n                     \u2018Three-parent baby\u2019 claim raises hopes \u2014 and ethical concerns 2016-Sep-28 \n                   \n                     Controversial stem-cell company moves treatment out of the United States 2013-Jan-30 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21140", "url": "https://www.nature.com/articles/nature.2016.21140", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The animals are giving scientists a glimpse into the pattern of neurons responsible for communication. Baltimore, Maryland The din of what sounds like a high-pitched cocktail party fills the lab of neuroscientist Xiaoqin Wang at Johns Hopkins University in Baltimore. But the primates making the racket are dozens of marmosets, squirrel-sized monkeys with patterned coats and white puffs of fur\u00a0on either side of their heads. The  animals chatter to each other , stopping to tilt their heads and consider their visitors with inquisitive expressions. Common marmosets ( Callithrix jacchus ) are social and communicative in captivity, unlike the macaque that is more commonly used as a model primate. And in January, Wang and his colleagues revealed that marmosets are also the only non-human animal that can hear different pitches, such as those found in music and tonal languages like Chinese, in the same way people can 1 . This makes the marmoset the closest proxy researchers have to the human brain when it comes to  hearing and speech , says Quianjie Fu, an auditory researcher at the University of California, Los Angeles, who was not involved with the paper. Until recently, researchers have relied on songbirds for such work, but the birds\u2019 brains are so different from human ones that the insights they provide are limited. Wang hopes that marmosets will improve researchers\u2019 understanding of the evolution of communication and help them  refine devices such as cochlear implants  for deaf people. In a 7 December paper 2  in the  Journal of Neuroscience , Wang and his colleagues described the results from an electrical stimulation study in marmosets that were free to interact with each other as they normally would. The team showed for the first time that electrical stimulation \u2014 such as that provided by a cochlear implant \u2014 does not activate the auditory portions of the brain in the same way that sound does. This new map gives researchers a starting point to answer questions about why cochlear implants cannot distinguish pitch well \u2013 a longstanding problem with the devices. And one of the world\u2019s largest manufacturers of cochlear implants, Advanced Bionics in Valencia, California, is now beginning to test its next-generation devices in the marmosets. The primates will be invaluable for these kinds of improvements, says Abhijit Kulkarni, director of research and development at the company, which was not involved in the current study. \n             Cutting through the noise \n           Cochlear implants are generally considered a medical success story, despite their problems with pitch, including a failure to pick up high-pitched sounds or to pick out a voice from background noise. But improving them is tough. Researchers only have feedback from people to tell whether an experimental device is working. Linking that feedback with what\u2019s going on in the brain would show exactly which pattern of circuits leads to distinguishing features of sound such as tone and pitch, says Fu. But observing the activity of individual neurons in humans isn\u2019t possible. \u00a0In their latest paper, Wang and his colleagues described how they looked at the activity of neurons in the auditory cortex \u2014 the brain\u2019s hearing centre \u2014 of four adult marmosets that were deaf in one ear, as they were exposed to electrical and acoustic stimulation. Electrodes implanted in this region recorded how more than 1,400 individual neurons reacted to sounds played in the normal ear, and how they responded to electrical stimulation similar to currents produced by cochlear implants in the deaf ear. The researchers found that the electrical stimulation failed to activate many of the neurons that respond to sound, including some involved in pitch perception. The most likely explanation, they say, is that the electrical current spreads across the brain, turning on neurons that are supposed to stay inactive during the processing of sounds. This disrupts the pattern of activation and deactivation in the brain\u2019s circuits that enables normal hearing. \u201cThe really fascinating question from this paper is the failure of cochlear implants to successfully provide information to the brain,\u201d says James Phillips, a neurophysiologist at the University of Washington in Seattle, who was not involved in the study. \u201cI do think [the study] is incredibly valuable, not only as providing insight into the way this works, but some explanation for why.\u201d \n             Looking forward \n           These findings could lead to better cochlear implants if those devices were designed to selectively stimulate the neurons that did not respond to the electrical pulses, says Julie Bierer, a neuroscientist at the University of Washington in Seattle, who wasn\u2019t involved in the paper. But she says that some of the discrepancies between the auditory and electrical stimulation could be due to the fact that the devices were not switched on constantly, as they would be in a person with a cochlear implant. This could prevent the auditory system from adapting to the new signal by rewiring itself over time. Wang says that his group is planning to do this next, and to test whether the pattern is different in baby monkeys, whose brains are more malleable. They have also built a soundproof room in which multiple marmosets with the electrical stimulation devices can run around and interact with one another. This will allow the researchers to connect the wirelessly transmitted brain recordings with recordings of the sounds the animals make, allowing them to determine how the brain processes communication during behaviours like fighting or eating. \n               Tweet \n               Follow @NatureNews \n               Follow @Sara_Reardon \n             \n                   Marmosets are stars of Japan\u2019s ambitious brain project 2014-Oct-08 \n                 \n                   Marmosets prove to be polite conversationalists 2013-Oct-17 \n                 \n                   Brain cells tune in to music 2005-Aug-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21183", "url": "https://www.nature.com/articles/nature.2016.21183", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Third global fleet will soon be joined by Asian counterparts, setting the atmosphere abuzz with scientifically-useful radio-wave signals. After soaring costs and years of delays, Europe\u2019s global satellite navigation system, Galileo, finally began beaming its first signals to receivers in smartphones and cars on 15 December. The 18-strong fleet of satellites promises travellers another way to accurately locate their position on Earth, ending Europe\u2019s dependence on the US Global Positioning System (GPS) and Russia\u2019s GLONASS. But Galileo, which was first proposed in 1999, is a big deal for science too, says Richard Langley, an expert in navigation-satellite systems at the University of New Brunswick in Fredericton, Canada. What most excites scientists is the prospect of combining signals from multiple satellite networks, which should enable new kinds of atmospheric and Earth-sciences research. Galileo\u2019s constellation of satellites should reach its its full complement of 30 in 2020, by which time China\u2019s BeiDou system, comprising 35 satellites, is scheduled to enter service. Japan and India are also building regional systems. Altogether, the number of global navigation satellites encircling the Earth is set to rise from around 90 today to at least 130 over the next decade, estimates Oliver Montenbruck, a physicist at the German Aerospace Center in Oberpfaffenhofen, Germany. At the same time, existing satellite fleets such as GPS and GLONASS will be modernized to carry higher-precision clocks and transmit more advanced signals. Earth\u2019s atmosphere will then be streaming with many more kinds of radio-wave signals at a greater variety of frequencies \u2014 each carrying information about the time and the position of the satellite that sent it. Sat-nav receivers rely on information from multiple satellites to pinpoint their own position. So simply having more satellites overhead will help stop irritating signal loss, particularly in areas where high-rise buildings or mountains interfere with reception, and will provide more accurate position fixes for both travellers and scientists, says Langley. \u201cThe more satellites you have, the greater the precision,\u201d adds Tonie Van Dam, an Earth scientist at the University of Luxembourg who studies how climate change is affecting how water circulates between the ocean, atmosphere and land. She uses receivers mounted on bedrock to monitor how Earth\u2019s crust deforms and rebounds in response to a shifting weight of water or ice. Cross-checking data from several satellite constellations is the only way to correct errors in Earth-system models, she adds. \n               Mapping the sea and the sky \n             Skies increasingly crowded with radio waves will also benefit researchers who use the refraction of navigation-satellite signals in the Earth\u2019s atmosphere to make measurements of atmospheric temperature, pressure, density and water-vapour content \u2014 data used for weather forecasting and climate research. And the signals can similarly be exploited to measure electron density in Earth\u2019s ionosphere, the electrically charged layer in the upper atmosphere. Such data are used to track space weather and also to monitor tsunamis and earthquakes, notes Philippe Lognonn\u00e9, a geophysicist at the Institute of Earth Physics of Paris. These events disturb the air around them so violently that they send acoustic and gravity waves up to the ionosphere where they perturb electrons. With fully operational Galileo and BeiDou systems, researchers should be better able to estimate tsunami heights, Lognonn\u00e9 says. Scientists also plan to use multiple navigation-satellite constellations to vastly improve measurements of ocean wind speeds, sea-surface roughness and the height of waves, says Jens Wickert, a scientist at the GFZ German Research Centre for Geosciences in Potsdam. Today\u2019s remote-observation maps of the oceans are built largely by bouncing radar waves off the sea from aircraft or spacecraft, and combining those data with information from other satellite-borne instruments. The best current maps have a spatial resolution of around 80 kilometres and are updated every 10 days. Wickert aims to improve on that by taking measurements using orbiting receivers for navigation-satellite signals. A European experiment called GEROS-ISS, which Wickert is leading, aims to fly a receiver on the International Space Station in 2019. The experiment would measure navigation-satellite signals as they reflect off the sea, and by combining data from Galileo, BeiDou, GPS and GLONASS could map the oceans at spatial scales down to a few kilometres every four days or less. Many ocean phenomena, such as eddies, occur at these scales, so better maps would help to improve weather and climate-change models. A fleet of receivers in space could provide even finer resolution. In a step in that direction, NASA on 15 December launched its own ocean-reflection research mission, the Cyclone Global Navigation Satellite System. The fleet of eight microsatellites, each carrying four navigation-satellite receivers, will measure wind speeds and ocean roughness in the eyes of storms and hurricanes at unprecedented resolutions of a few kilometres every few hours, with the goal of improving forecasts. Chris Ruf, Cyclone's principal investigator and a remote-sensing scientist at the University of Michigan in Ann Arbor, says that the first mission will use GPS only, but he is keen to integrate data from Galileo and BeiDou in follow-ups. Much research on how to usefully fuse signals from different global navigation-satellite systems is taking place under the auspices of a voluntary federation of more than 200 agencies, universities and research centres in more than 100 countries. Over the past four years, researchers within the federation have been testing signals from GPS, GLONASS, Galileo and other systems, to develop the algorithms and software that will be needed for scientists to combine data from multiple satellite constellations in their research. Montenbruck, who heads this effort, cautions that it may take more than five years after Galileo and BeiDou enter full service before scientists can fully exploit their possibilities. \"Today's use of GPS benefits from 30 years of experience and an excellent understanding and characterization of all the dirty details,\" he says. \"All that still needs to be carried out for Galileo and BeiDou.\" \n                 Tweet \n                 Follow @NatureNews \n               \n                     Wayward satellites repurposed to test general relativity 2015-Nov-12 \n                   \n                     Microsatellites aim to fill weather-data gap 2012-Nov-28 \n                   \n                     Galileo gets ready for take off 2011-Oct-19 \n                   \n                     Atom takes a quantum leap 2009-Jan-22 \n                   \n                     Galileo \n                   \n                     BeiDou \n                   \n                     US Global Positioning System \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21074", "url": "https://www.nature.com/articles/nature.2016.21074", "year": 2016, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "Consortium backed by US National Institutes of Health is first major biology programme to mandate online publication of results ahead of peer review. Biologists  have been slow to embrace preprints , but for some it\u2019s no longer a choice. The 4D Nucleome, a major research consortium funded by the US National Institutes of Health (NIH), is now requiring that all manuscripts related to its US$120-million, five-year programme are posted to an online preprint server ahead of peer review. And a privately funded, US$600-million biomedical research initiative in California is considering whether to demand its investigators do the same. Proponents of these mandates say that they will help to foster wider acceptance of pre-publication in the life sciences, a practice that is gaining popularity among biologists but still remains the exception rather than the rule. However, some worry that forcing scientists to use preprint servers is the wrong way to go about  persuading the biomedical research community of the value of sharing papers  ahead of formal journal publication. \u201cIt is a very progressive way of promoting preprints and reasonable as a policy for a private foundation. But the hope would be that, over time, biologists grow to see the value and want to do this, just like the physicists do, rather than being forced into it,\u201d says Ron Vale, a cell biologist at the University of California, San Francisco, and the founder of the preprint advocacy group ASAPbio. \u201cBeing forced to do something is not necessarily the best way to win over someone\u2019s heart.\u201d \n             Thou shalt preprint \n           Some lab groups have voluntarily pledged to post all their papers to preprint servers such as bioRxiv. However, no funding bodies or multi-institutional initiatives had made such a measure obligatory for biologists until the 4D Nucleome programme enacted its policy this month. The project seeks to determine the genetic architecture of the cell's nucleus in space and time. \u201c This is the way of the future, and for a consortium effort like this, it's something we should be doing,\u201d says John Lis, a molecular biologist at Cornell University in Ithaca, New York. Lis is one of the nine voting members of the 4D Nucleome steering committee, which ruled that all of the project's 50-plus principal investigators must now share their manuscripts on a preprint server before or concurrently with submission to a peer-reviewed journal, unless granted an exception or extension to protect intellectual property. And soon, a project funded by Facebook co-founder Mark Zuckerberg and his wife, physician Priscilla Chan, could be the first philanthropic effort to adopt a similar policy. In September,  the pair unveiled the Chan Zuckerberg Biohub , a $600-million, 10-year initiative to elucidate disease mechanisms and develop new technologies. The Biohub will support around 45 investigators at 3 universities in and around San Francisco, California, all of whom may be required to post preprints on or before the date of submission to a journal. Such a rule was included in a call for applications posted online and e-mailed to staff at member institutions. But that was done in error, according to Biohub co-director Stephen Quake, a bioengineer at Stanford University in California. \u201cThere\u2019s going to be some sort of publication policy,\u201d he says. \u201cBut we\u2019re still finalizing the details.\u201d The NIH has no formal policy on pre-publication, but it is warming to the idea. The agency is currently soliciting feedback on how best to consider preprints in grant applications and reports. And it is supporting the 4D Nucleome programme's pre-publication mandate. \n             Nucleating the idea \n           \u201cWe\u2019re enthusiastic about open sharing,\u201d says Judy Mietz, a programme director for 4D Nucleome at the NIH's National Cancer Institute. \u201cThe NIH expects broad sharing in these tools generating groups.\u201d But according to an internal poll of principal investigators in the consortium, about 30% oppose the publication policy. Ultimately, however, the programme's leadership was convinced of the policy\u2019s benefits. \u201cThere are really lots of positives to this,\u201d says Nils Gehlenborg, a bioinformatician at Harvard Medical School in Boston, Massachusetts, who co-chairs the 4D Nucleome policy working group. He points to the speedier dissemination of knowledge, earlier discussions of findings among scientists and the ability to plant a flag of priority when scientists develop a new idea. \u201cThere\u2019s no need to have unnecessary delays,\u201d Gehlenborg says. Jessica Polka, director of ASAPbio in Cambridge, Massachusetts, commends the consortium\u2019s decision. \u201cIt\u2019s so encouraging that this is a scientist-driven choice,\u201d she says. \u201cThere may not be a complete consensus among them, but the fact that there\u2019s this sub-community that\u2019s ready to change their own culture \u2014 that, to me, is extremely exciting.\u201d Another major NIH initiative, the Extracellular RNA Communication consortium, also encourages its members to submit manuscripts to preprint servers. But it only requires titles and abstracts to be shared on an internal database at the time of journal submission. According to Ananda Roy, a programme leader at the NIH\u2019s Office of Strategic Coordination, none of the other 30 or so programs funded by the agency\u2019s Common Fund \u2014 which supports multidisciplinary, multi-investigator initiatives \u2014 has any pre-publication policy.  \n                   Facebook couple commits $3 billion to cure disease 2016-Sep-21 \n                 \n                   Social-sciences preprint server snapped up by publishing giant Elsevier 2016-May-17 \n                 \n                   Biologists urged to hug a preprint 2016-Feb-16 \n                 \n                   Does it take too long to publish research? 2016-Feb-10 \n                 \n                   The arXiv preprint server hits 1 million articles 2014-Dec-30 \n                 \n                   Preprints come to life 2013-Nov-12 \n                 \n                   Geneticists eye the potential of arXiv 2012-Jul-31 \n                 Reprints and Permissions"},
{"file_id": "540017a", "url": "https://www.nature.com/articles/540017a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Advances in neuroscience are driving the development of therapies that could save thousands of the most vulnerable patients. Neuroscientists and physicians have embarked on what they hope will be a revolution in treatments to prevent brain damage in newborn babies. As many as 800,000 babies die each year when blood and oxygen stop flowing to the brain around the time of birth. And thousands develop brain damage that causes long-lasting mental or physical disabilities, such as cerebral palsy. Physicians have few tools to prevent this, but they are optimistic that clinical trials now under way will change things. The trials were sparked by neuroscientists\u2019 realization in the 1990s that some brain injuries can be repaired. That discovery spurred a flurry of basic research that is just now coming to fruition in the clinic. In January, a US study will start to test whether the hormone erythropoietin, or EPO, can prevent brain damage hours after birth when combined with hypothermia, in which babies are cooled to 33.5\u2009\u00b0C. A trial in Australia is already testing this treatment. Physicians in countries including the United States, China and Switzerland are testing EPO in premature babies, as well as other treatments, such as melatonin, xenon, argon, magnesium, allopurinol and cord blood in full-term babies. \u201cThe world has really changed for us,\u201d says neurologist Janet Soul at Boston Children\u2019s Hospital in Massachusetts. Therapeutic  hypothermia was the first success : clinical trials over the past decade have shown that it  decreases the risk of death and of major brain-development disorders  by as much as 60%. It is now standard treatment for babies in developed countries whose brains are deprived of blood and oxygen during birth. \u201cI can\u2019t tell you how great it was to be able to do something for these babies rather than stand there and watch them have seizures,\u201d Soul says. But because hypothermia does not work for all babies 1 , scientists decided to see whether combining it with other treatments would help. EPO was known to boost the production of red blood cells even before its discovery 2  in mouse brain cells in 1993, and is regularly used by physicians to treat anaemia. Neuroscientist Sandra Juul at the University of Washington in Seattle wondered what a blood-boosting hormone was doing in the brain. In subsequent animal studies, she found that the hormone stopped brain cells from dying and helped the brain to repair itself 3 . That led a few years later to the first clinical trials showing that EPO prevents brain damage in babies. \n               Moving on \n             In June, a study conducted by Juul and her colleagues reported the results of giving EPO or a placebo, along with inducing hypothermia, just after birth to dozens of babies at risk of brain injury. Those who received EPO were less likely than those given the placebo to show signs of brain damage on magnetic resonance imaging tests done five days later 4 .  I can\u2019t tell you how great it was to be able to do something for these babies.  Those results led to the forthcoming clinical study. Co-led by Juul and Yvonne Wu, a paediatric neurologist at the University of California, San Francisco, the trial will enrol 500 babies at risk of brain injury from 17 hospitals across the United States during their first 24 hours of life. All the babies will be treated with hypothermia. Half will then receive five doses of EPO over seven days; the other half will get saline injections. The US$10-million trial will measure whether the hormone boosts the children\u2019s mental and physical health at 2 years of age. Researchers are also testing EPO in babies born as early as 23 weeks in the United States and Europe. Such premature babies are more likely to develop brain injury than are full-term babies, and smaller studies have produced conflicting results about the benefits of EPO in these very early cases. But neonatologist Giancarlo Natalucci of the University of Zurich, who was part of a Swiss trial that found EPO didn\u2019t improve the health of two-year-olds who had been treated as premature babies 5 , says that factors such as dose may account for such results. He still thinks that the treatment merits study. The trials are difficult to conduct because it\u2019s hard to tell whether a symptom is a side effect of treatment or the result of a baby\u2019s underlying injuries. But despite the hurdles, Juul and other researchers press on, driven by their desire to aid the world\u2019s smallest patients. \u201cThey\u2019re in such desperate need of help,\u201d Juul says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Erika_Check \n               \n                     Cooling protects oxygen-deprived infants 2014-Jul-09 \n                   \n                     Hope for premature babies with brain injuries 2011-Jun-26 \n                   \n                     Neuroscience: The most vulnerable brains 2010-Jan-13 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21032", "url": "https://www.nature.com/articles/nature.2016.21032", "year": 2016, "authors": [{"name": "Jeff Tollefson"}, {"name": "Sara Reardon"}, {"name": "Alexandra Witze"}, {"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Nature 's list of the key issues and appointments facing US government science agencies. As US president-elect Donald Trump begins to  sketch out the priorities of his administration ,  Nature  tracks the key issues and likely leaders of vital science and research agencies. \n             National Institutes of Health \n           The National Institutes of Health (NIH) has dreamed big under the current US president, Barack Obama. Now the future of major projects  to study the brain, personalize medical treatments and cure cancer  is in flux. The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative seems likely to survive, given that the US Congress has increased its funding each year since its launch in 2013. The future of the Precision Medicine Initiative, which launched in 2015, is uncertain, but  the Cancer Moonshot proposed this year  seems unlikely to get the funding it needs to get off the ground. Human embryonic stem-cell research and the stem-cell lines that the NIH has established could also once again become a flashpoint.  Obama legalized federally funded stem-cell research in 2009  through an executive order, and Trump could repeal that order at will. And research involving fetal tissue will also continue to be contentious: on 16 November, Congress approved US$800,000 for a panel to continue investigating whether researchers who use this tissue and their suppliers have broken laws. NIH director Francis Collins  has said that he plans to submit a pro forma resignation in early December, as required by statute. Collins has not said whether Trump has asked him to stay on, or whether he would consider such a request. But on 29 November, Trump\u2019s transition team announced its pick to lead the Department of Health and Human Services, which includes the NIH. Congressman Tom Price (Republican, Georgia), is a physician  who favours repealing Obamacare  and has opposed Obama's Cancer Moonshot. \n             Food and Drug Administration \n           Widespread speculation that Trump will push to relax drug approval standards at the Food and Drug Administration (FDA) has sent pharmaceutical stocks rising and set consumer watchdogs on edge. Those who watch the agency \u2014 which is widely considered to have insufficient resources to enforce  its ever-increasing regulatory mandate  \u2014 are also concerned about Trump\u2019s talk of a federal hiring freeze. And Trump\u2019s campaign-trail musings about \u201cthe FDA food police\u201d suggests that food-safety regulations may also be in jeopardy. Trump will be able to appoint a new FDA commissioner, but so far has not indicated whom he will pick. Some Republican lawmakers have urged him to keep the current commissioner, cardiologist Robert Califf, whose  decades of running clinical trials  have brought him into close contact with industry. \n             Centers for Disease Control and Prevention \n           One of the few strong statements that Trump has made on public health was in 2014, when he advocated banning people from Ebola-infected areas from entering the United States \u2014 a position opposed by public-health officials and scientists. In August, the Centers for Disease Control and Prevention (CDC) proposed creating a rule to update its policies on quarantine after an outbreak of such a disease. The future of that rule is uncertain. The CDC could also suffer if Trump and Congress repeal Obamacare. Striking down the health-care law could also abolish the Prevention and Public Health Fund, which that law created. This fund \u2014 $1.4 billion in 2016 \u2014 has been used to bulk up a number of programmes at the CDC. \u2028 \n             Environmental Protection Agency \n           Trump, who has railed at the \u201cdraconian\u201d environmental policies of Obama, has pledged to roll back many of them. These include  climate regulations formulated by the Environmental Protection Agency (EPA) ; among these are rules to reduce greenhouse-gas emissions from power plants. The EPA is required by law to regulate carbon and and conventional air pollutants, and environmentalists are prepared to launch lawsuits to ensure that it does. But the Trump administration could cut the agency\u2019s budget to hamper its ability to make new rules or enforce existing ones. Trump has appointed Myron Ebell, a high-profile climate sceptic at the Competitive Enterprise Institute in Washington DC, to lead the EPA transition. Jeffrey Holmstead, a lawyer at the firm Bracewell in Washington DC, is among the top candidates to head the agency; he led the EPA\u2019s Office of Air and Radiation under former president George W. Bush. Others rumoured to be in contention include Robert Grady, a venture capitalist at Gryphon Investors in San Francisco, California, who helped to craft new air-quality regulations under the administration of George H.W. Bush in 1990; state officials such as Kathleen Hartnett White, former chairwoman of the Texas Commission on Environmental Quality; and Ebell himself. \n             Department of Energy \n           The Department of Energy\u2019s Office of Science spends more than $5 billion on research each year, on topics such as high-energy physics, energy, climate change and biology. The energy department\u2019s National Nuclear Security Administration also oversees  the nation\u2019s $8.8-billion nuclear-weapons programme . The Obama administration tried  to increase investments in applied clean-energy research , but Trump could shift the focus back to advanced fossil fuels and nuclear power. Rumoured candidates for secretary of energy include Robert Grady, James Connaughton \u2014 a former utility executive who headed the White House Council on Environmental Quality under George W. Bush \u2014 and former Texas governor Rick Perry. Harold Hamm, chief executive officer of the Oklahoma oil and gas company Continental Resources, was considered a leading candidate, but Hamm has said he isn\u2019t interested. \n             National Oceanic and Atmospheric Administration \n           The National Oceanic and Atmospheric Administration (NOAA)  monitors the nation\u2019s weather  and fisheries and Earth\u2019s climate. It operates research ships and aeroplanes, satellites and its own uniformed service while spending about $490 million each year on atmospheric, oceanic and ecosystems science. Obama surprised scientists in December 2008, just a month after his election, when he announced his intent to nominate marine ecologist Jane Lubchenco to head the agency \u2014 which normally is not among the top priorities of an incoming president. By contrast, it remains unclear when Trump\u2019s transition team might consider candidates to lead NOAA. But rumours are swirling about Trump\u2019s choice to lead NOAA\u2019s parent, the Department of Commerce. Billionaire investor Wilbur Ross, one of Trump\u2019s economic advisers, appears to be the leading candidate. Others in the running are Dan DiMicco, who formerly headed the steel company Nucor, and financier Lewis Eisenberg, who co-founded the investment firm Granite Capital International Group. \n             US Geological Survey \n           The $1-billion agency coordinates scientific research into natural hazards, resources such as water and minerals, and the environment. Budget cuts during the Obama administration  have threatened stream gauges to track flooding , as well as volcano and earthquake monitoring. Its programme on climate and land-use change may come under fire in a new administration. The current director, Suzette Kimball, is a political appointee who is almost certain to leave before a new administration begins. Deputy director William Werkheiser would probably become acting director until a permanent leader is approved. The agency's leadership position requires Senate confirmation and can get mired in political disagreements; Kimball spent nearly three years as acting director before being confirmed to the position in December 2015. \n             NASA \n           The US space agency may soon find itself looking away from Earth and  Mars  and towards the Moon. Several of Trump\u2019s advisers, such as former Congressman Newt Gingrich, are fans of sending astronauts back to the Moon as the next step in deep-space exploration. And two Trump space advisers have proposed  cutting NASA\u2019s Earth-observing programmes  or shifting them to other agencies, such as NOAA. And the Obama administration\u2019s plan to drag an asteroid to lunar orbit for further study seems likely to face the cutting block. Current NASA administrator Charlie Bolden, a former astronaut and Obama loyalist, is sure to leave in January as Trump takes office. Names being discussed as possible replacements include former NASA head Michael Griffin; Representative Jim Bridenstine (Republican, Oklahoma), who is active on space issues; and former astronaut Eileen Collins, who spoke at the Republican convention that nominated Trump in July. \n             National Science Foundation \n           The National Science Foundation (NSF) funds a wide array of basic research, to the tune of roughly $7.5 billion annually. In recent years, Republicans in Congress  have questioned its spending on the social sciences and geoscience , including climate-change research.\u00a0 NSF directors are appointed for six-year terms and frequently serve across administrations. Astrophysicist France C\u00f3rdova took over in March 2014, and plans to serve out the remainder of her term. By comparison, Obama took office in 2009 but did not nominate his first NSF director, materials scientist Subra Suresh, until June 2010 \u2014 after Arden Bement had finished his term. \n                   Trump's pick for US health secretary has pushed to cut science spending 2016-Nov-29 \n                 \n                   Immigrant and minority scientists shaken by Trump win 2016-Nov-22 \n                 \n                   What scientists should focus on \u2014 and fear \u2014 under Trump 2016-Nov-11 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Science under President Trump 2016-Nov-09 \n                 \n                   Nature  special: 2016 US election \n                 \n                   Trump presidential transition website \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21091", "url": "https://www.nature.com/articles/nature.2016.21091", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "But the European Space Agency's participation in a mission to deflect an asteroid moon is now cancelled. The European Space Agency (ESA) has secured the \u20ac436 million ($464 million) that it needs to land its first rover on Mars \u2014 despite rising costs and the failure of its Mars lander, Schiaparelli, in October.\u00a0 \u201cAfter the many challenging, difficult and rewarding moments of 2016, this is a great relief and a fine result for European space exploration,\u201d says Don McCoy, ESA\u2019s project manager for the overall mission that includes the rover, called ExoMars. ExoMars 2020, a  joint Mars rover mission with the Russian space agency Roscosmos  that will launch in 2020, had already been delayed from  a planned launch in 2018  \u2014 a major cause of the cost increase \u2014 and its future looked on shakier ground following  the failure of Schiaparelli , which was designed to test Europe\u2019s ability to land a craft on the red planet, as part of the ExoMars project. At a meeting of European government ministers in Lucerne, Switzerland, on 1\u20132 December, ESA member states agreed to provide an extra \u20ac339 million for ExoMars 2020, on top of the more than \u20ac1 billion already committed to the ExoMars programme. ESA also announced that it will find a further \u20ac97 million by moving funds internally. Speaking at a press briefing after the meeting,  ESA director-general Jan W\u00f6rner  said that this would be done \u201cwithout detriment\u201d to ESA\u2019s wider science budget. But not all projects were so fortunate. Member states did not commit the \u20ac250 million needed to fund a plan for ESA to participate in a mission to deflect the moon of an asteroid, although they left the door open to future, similar projects. \n               Now or never \n             The meeting was a crunch point for the ExoMars mission. ESA officials had hinted that if member states did not commit to coughing up the extra funding, there was little point in proceeding at all. ESA hopes to learn lessons from the Schiaparelli crash. Last week, the agency confirmed that the crash was caused by errors in the sensor systems, which made the craft behave as if it was closer to the Martian surface than in actuality. This prompted Schiaparelli to jettison its parachute too early, before falling from a height of about 3.7 kilometres. \u201cWe will have learned much from Schiaparelli that will directly contribute to the second ExoMars mission,\u201d said David Parker, ESA\u2019s director of human spaceflight and robotic exploration who is based at the European Space Research and Technology Centre in Noordwijk, the Netherlands, in a statement. If successful, the rover will be the first one that either Europe or Russia has operated on Mars\u2019s surface. Its major selling point is a 2-metre drill which would allow the robot to dig to a depth where signs of ancient life could have been preserved, protected from the red planet\u2019s harsh radiation. \n               Didymoon fail \n             But it\u2019s lights out for the Asteroid Impact Mission (AIM), which was designed to test a strategy for protecting Earth from incoming asteroids by subtly changing their course using projectiles. Insiders say that the mission missed its target sum by perhaps a few tens of millions of euros. \u201cA cool project has been killed because of a lack of vision \u2014 even short term \u2014 and courage, and this is really sad,\u201d says Patrick Michel, a planetary scientist at the French National Centre for Scientific Research in Nice, who leads the AIM project. W\u00f6rner suggested that a similar, smaller asteroid mission could still go ahead. And ministers supported making a smaller amount of funding available to explore ways of taking planetary-protection projects forward, he said. But the original project will not continue. AIM would have sent a probe, two miniature satellites known as cubesats and a lander to the asteroid Didymos. There the scientists planned to watch a NASA craft, known as the Double Asteroid Redirection Test (DART), smash into a 165-metre wide rock that orbits the asteroid, known as Didymoon. Scientists had hoped to study how the impact would alter the moon\u2019s orbit. In 2022 Didymos will be close enough to Earth to monitor the deflection from the ground, meaning that DART \u2014 which is awaiting its own approval decision in March 2017 \u2014 can go ahead without AIM. But the ESA craft would have provided more-detailed knowledge, says Michel. \u201cThis knowledge is crucial to be able to use our impact models with higher confidence for a real deflection mission.\" \n               Bitter disappointment \n             AIM also included a plan to study the asteroid system and land a probe on its moon. Its cancellation means that ESA now has no small-body missions planned for at least the next 15 years, a particularly bitter disappointment following the success of ESA\u2019s  Rosetta mission , which orbited and  landed on  a comet. \u201cWe have now a lot of expertise, thanks to Rosetta, that we need to teach to new generations, and this expertise will be lost,\u201d adds Michel. The mission would also have been ESA\u2019s first test of laser communication in deep space, and of its  interplanetary cubesats . Overall, ESA was able to obtain \u20ac10.3 billion of the roughly \u20ac11-billion sum it had requested from its 22 member states, plus Slovenia and Canada, for a variety of programmes, ranging from satellite communications to Earth observations. The sum includes commitments to continue to fund the International Space Station up to 2024, and to fund a future space-weather mission in cooperation with NASA and the Japanese space agency, JAXA. \n               Moon hope \n             Ministers also agreed to further finance plans for ESA to work with Roscosmos on a moon craft, the Russian lander Luna 27,  a collaboration first pitched in 2014 . ESA will spend around \u20ac30 million on preparatory work for the mission, which is scheduled for 2020. European scientists and industry hope to contribute landing, communications and drilling and analysis instruments to the craft, which is designed to study soil and the atmosphere at the Moon\u2019s south pole. The collaboration also lays the foundation for ESA to work with Russia on its planned follow-up mission to bring back the first samples from the Moon\u2019s south pole, says Ian Crawford, a planetary scientist at Birkbeck, University of London. Roscosmos is planning that sample-return mission for the early 2020s. \n                     Computing glitch may have doomed Mars lander 2016-Oct-25 \n                   \n                     Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                   \n                     Europe proposes joint Moon trips with Russia 2014-Dec-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21083", "url": "https://www.nature.com/articles/nature.2016.21083", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Illegal land clearing hits highest levels since 2008 as environmental policies come under attack. Illegal  deforestation in the Brazilian Amazon  has spiked since 2015, bringing the rate to its highest level in 8 years. The finding has raised fears that the country could lose a decade\u2019s worth of progress in forest protection. In an analysis of satellite data released on 29 November, Brazil\u2019s National Institute for Space Research (INPE) in S\u00e3o Jos\u00e9 dos Campos estimates that 7,989 square kilometres of land \u2014 nearly the size of Puerto Rico \u2014 was cleared between August 2015 and July 2016. The total was 29% above the previous year and 75% above the 2012 level, when deforestation hit a historic low of 4,571 square kilometres (see \u2018Going up\u2019). The current trends illustrate a growing sense of impunity as well as betrayal among landowners who have yet to benefit from the sustainable-development agenda, says Daniel Nepstad, a tropical ecologist who heads the Earth Innovation Institute, an environmental organization in San Francisco, California. \u201cThere\u2019s been a lot of talk about improving the lives and the bottom lines of farmers and ranchers if they stop clearing the forest,\u201d Nepstad says, \u201cand they are still waiting.\u201d Brazil basked in the international limelight for nearly a decade  after deforestation began to drop in 2005 , thanks in part to stronger government enforcement as well as high-profile commitments to halt deforestation by the beef and soya-bean industries. But the government\u2019s success sparked a political backlash. The Brazilian Congress  relaxed the country\u2019s forest protections  in 2012 , and many Brazilian lawmakers are  pushing to further relax environmental laws  to promote development across the Amazon. Meanwhile, the country\u00a0has been rocked by economic recession and ongoing political-corruption scandals. This has diverted both money and attention away from environmental enforcement, emboldening ranchers and illegal land traders to resume clearing land, says Paulo Barreto, a senior researcher at the Amazon Institute of People and the Environment, an activist group in Bel\u00e9m. Barreto notes that beef prices have risen, as has the size of the forest tracts that are being cleared \u2014 a sign that the major players are investing in illegal deforestation. With the Brazilian government as weak as it is, Barreto says that he hopes the beef industry in particular will bolster its efforts to prevent the sale of cattle from newly cleared land. This would be an act of self-interest, he adds, because the industry's public image, at home and abroad, depends on Brazil's continued success in protecting the Amazon. \u201cIn the end, this is bad for Brazil, not only in environmental terms but also in terms of agricultural markets.\u201d \n                     Political upheaval threatens Brazil\u2019s environmental protections 2016-Nov-08 \n                   \n                     Warning to forest destroyers: this scientist will catch you 2016-Oct-04 \n                   \n                     Dry Amazon could see record fire season 2016-Jun-29 \n                   \n                     Stopping deforestation: Battle for the Amazon 2015-Apr-01 \n                   \n                     Brazilian National Institute for Space Research\u00a0 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21067", "url": "https://www.nature.com/articles/nature.2016.21067", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Scientists say mitochondrial-replacement therapy is ready for tests in the clinic. The United Kingdom may soon become the first country to explicitly permit the birth of children from  embryos modified to contain three people\u2019s DNA . At the same time, new research backs up concerns that such a treatment \u2014 which aims to erase diseases transmitted by the DNA found in cellular structures called mitochondria \u2014  may not always be 100% effective . Scientists advising the UK Human Fertilisation and Embryology Authority (HFEA) said on 30 November that, after two decades of research, the therapy is ready for limited clinical testing. It exchanges a mother's faulty mitochondria for healthy ones from another woman\u2019s egg. The result: a \u2018three-parent\u2019 baby with DNA from its father, mother and a third donor. The HFEA will decide whether to allow clinical trials of the therapy at a meeting on 15 December. If it does, the first procedures, approved on a patient-by-patient basis, could occur as soon as March or April 2017, a spokesperson says. \u201cWe\u2019ll be ready, I hope, to press the button if we get the green light,\u201d says Mary Herbert, a reproductive biologist who is part of a team at Newcastle University, UK, seeking to offer the treatment to women. The UK government  legalized mitochondrial-replacement therapy in 2015 , but the HFEA, which was given the power to regulate the technique, had asked for more research before allowing any clinic to trial it. Fertility doctors said this year that they had  already performed the procedure in countries such as Mexico and Ukraine , which do not have laws preventing it. That makes approval in the United Kingdom all the more urgent, some researchers say. Dieter Egli, a stem-cell scientist at the New York Stem Cell Foundation who has studied mitochondrial-replacement therapies, thinks that it is very important to allow the therapies to go forward in UK clinics. He worries that people will increasingly seek the procedures on their own. \u201cMaybe it\u2019s not the best choice, but they will go elsewhere, even if it means greater risk, less oversight and less expertise. I think we can\u2019t blame them for that.\u201d \n             Not always effective \n           Studies testing the therapy in human eggs have suggested that it might not always prevent mitochondrial disease. And research published today by a group led by mitochondrial geneticist Shoukhrat Mitalipov, at Oregon Health & Science University in Portland further supports that concern 1 . In mitochondrial-replacement therapy, researchers transfer the nuclear genome of an egg that has mutant mitochondria into a healthy donor egg. But a small number of mutant mitochondria \u2014 usually less than 2% of the cell\u2019s total \u2014 are also transferred, a phenomenon known as carry-over. Previous studies by Egli and others have suggested that these mutant mitochondria can out-compete the healthy donor mitochondria, rising to levels in cell culture that could cause disease if they occurred in a child\u2019s tissue 2 , 3 . In the latest research, published in  Nature , a team led by Mitalipov performed the procedure with eggs from four women carrying mitochondrial mutations that had caused diseases in their families (and in some cases in their children), and eggs donated by healthy women. The resulting embryos were all virtually free of carry-over mitochondria, suggesting that the procedures had worked. But embryonic-stem-cell lines cultured from 3 of these 15 embryos regained the mother\u2019s original set of mitochondria. In other experiments, Mitalipov\u2019s team simulated development by making brain, heart and other cells from stem cells derived from the new embryos. In some cases, the carry-over mitochondria came roaring back. If the same thing happens when an embryo is developing, it means that a child could retain some mutant mitochondria, Mitalipov says \u2014 and if they rose to high enough quantities, they could cause disease. \u201cThe question will need to be asked: what do we need to do to avoid that,\u201d says Egli. \n             Matching donors? \n           Here scientists disagree. Mitalipov\u2019s study hints that specific genetic differences between mitochondria could explain why some replicate faster than others. Choosing egg donors and patients with otherwise similar mitochondrial DNA (or haplotypes) could reduce the chances of mutant mitochondria out-competing healthy counterparts in the cells of a developing child, says Iain Johnston, a biomathematician at the University of Birmingham, UK, who studies mitochondrial inheritance. \u201cI would be more comfortable if these therapies were implemented with haplotype matching.\u201d But Herbert is not convinced that Mitalipov\u2019s explanation is correct and says that it might be difficult to find matching donors. \u201cYou\u2019re setting up an arms race between the two mitochondrial genotypes and keeping your fingers crossed. I think a better use of time and money would be to redouble our efforts to get the carry-over as close to zero as we possibly can,\u201d she says, an area of research her team is working on. The advisory report suggests that haplotype matching should be considered \u201cas a precautionary step in donor selection\u201d, but does not recommend it be mandatory. \u201cIt\u2019s not perfect. There\u2019s this chance of something going wrong,\u201d says Robin Lovell-Badge, a developmental biologist at the Francis Crick Institute in London who was part of the HFEA panel. People considering the treatments, he adds, \u201cmust understand it\u2019s impossible to ensure total safety until clinical trials have taken place\u201d. In September, John Zhang, a fertility doctor at New Hope Fertility Center in New York City, said that he had administered mitochondrial replacement therapy in Mexico to prevent the inheritance of a disease called Leigh syndrome - and that a  baby boy had been conceived from the treatment . Zhang shared some of his team\u2019s unpublished data with the HFEA panel. So far, the child seems healthy. In some of his tissues, the mutant mitochondria are undetectable, but in others, they are present at levels of up to 9.2%, according to the HFEA report. Zhang says that a paper describing the work was rejected this month by the  New England Journal of Medicine , but he hopes to publish the data soon. Researchers say that they have  also tried the therapy in Ukraine , but details have not been published.  \u201cThe more we hold off, patients will seek treatments elsewhere,\u201d says Mitalipov. He hopes that the techniques can also be tested in the United States, where the Food and Drug Administration would have to approve any use. \u201cThe whole idea of conducting it in the UK and US is that we do it in a few clinics under strict oversight as a clinical trial, so we can evaluate these clinical outcomes.\" Reprints and Permissions"},
{"file_id": "nature.2016.21075", "url": "https://www.nature.com/articles/nature.2016.21075", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "November\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Hunting Orion\u00a0 \n           \n             Looking in the mirror \n           \n             Photo awards \n           \n             White light \n           \n             Mosul burns \n           \n             Dodo $keleton \n           \n                   Martian clouds form, a frozen ship heads home and an orangutan goes climbing 2016-Oct-28 \n                 \n                   Drone lights, cameras and sucking up to a whale 2016-Sep-30 \n                 \n                   Floods, fires, Zika and a hidden portrait 2016-Aug-26 \n                 \n                   Cruising sharks, fiery dragons and invisible dust 2016-Jul-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21084", "url": "https://www.nature.com/articles/nature.2016.21084", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Institutions struggle to respond after court blocks regulations that would have increased wages for junior researchers. An ongoing fight over overtime pay rules has left many US postdocs in financial limbo. Labour regulations set to take effect on 1 December would have  effectively increased wages  for many of these researchers, but on 22 November a US federal judge in Texas temporarily blocked the new rules. Some universities are proceeding with planned salary increases for postdocs, but others have cancelled \u2014 or at least, temporarily halted \u2014 changes to researchers' pay. The uncertainty over how the legal battle will play out is already affecting some postdocs' career and family plans. \u201cThe injunction coming down, especially right before the holiday weekend, was really disheartening,\u201d says Colm Atkins, a postdoc at the University of Texas Medical Branch in Galveston. His institution is cancelling the raises it had planned to comply with the overtime rule. \u201cI know postdocs with spouses and families that were really looking forward to having that safety net.\u201d One couple, both postdocs at the University of Massachusetts Medical School in Worcester, had decided to try for a baby because their combined pay rises would have allowed them to afford childcare, says Sonia Hall, a fellow postdoc at the same school. But the institution has decided not to go ahead with the increases, so now they can\u2019t, she adds. The US Department of Labor finalized the new wage rule in May. The regulation made overtime pay, set at 1.5 times a worker\u2019s hourly wage, mandatory for people making less than US$47,476 per year, once they work for more than 40 hours in one week. The average postdoc salary in the United States is about $45,000 per year, and many of the researchers surpass the 40-hour cut-off. The previous overtime pay threshold was $23,660 per year. Because it would probably have been cheaper and logistically easier to raise salaries than to  count the hours a postdoc worked , many universities and government agencies had planned to increase annual wages. \n               Follow the leader \n             The US National Institutes of Health (NIH) will stick to its plan to raise the minimum salary for postdocs paid through its grants to $47,484. This is a 9% increase over previous NIH guidelines. \u201cA lot of places follow the NIH\u2019s example,\u201d says Kate Sleeth, chair of the board of the National Postdoctoral Association in Washington DC, which has been advocating for a minimum postdoc salary of $50,000 for more than two years. \u201cI\u2019m hoping everyone follows suit. And to be honest, if institutions don\u2019t increase their salaries, or they go hourly, I think eventually the numbers of postdocs who are  attracted to those institutions will dwindle .\u201d Even though they are no longer legally compelled to, many other institutions \u2014 including Duke University in Durham, North Carolina, the University of Minnesota in Minneapolis and Boston University in Massachusetts \u2014 are going ahead with their plans to raise postdocs\u2019 minimum salaries above the $47,476 cut-off. For those that aren\u2019t \u2014 such as the University of Michigan in Ann Arbor \u2014 it is not clear whether they are temporarily pausing such plans or abandoning them entirely. The Future of Research, an advocacy group for junior researchers, is tracking institutional responses to the regulation and its suspension  on its website .\u00a0 \n               Sending a message \n             Sleeth was not surprised to hear that the regulation had been suspended. \u201cWe were kind of waiting to see if someone was going to challenge it,\u201d she says. Twenty-one states and a coalition of businesses filed a case against the rule in October, arguing that the Department of Labor had overreached its authority. The judge blocked the rule from taking effect on 22 November, until he could decide on the case. It's unclear when he will do so, or if the Department of Labor will challenge the ruling. The timing of the injunction couldn\u2019t have been worse, coming so close to when the regulation was supposed to kick in, says Sleeth. \u201cIt\u2019s almost cruel.\u201d \u201c When you're at the bottom of the pecking order, even when you're highly educated and skilled and motivated, it's hard to ask for a raise,\u201d says Tess Eidem, a biochemistry postdoc at the University of Colorado Boulder. Her institution will let individual researchers decide whether to raise the pay of their postdocs. The increased wages would have been more than a pay rise, Hall says. They would have sent a message that  postdocs are respected  and their work is valued. \u201c They\u2019re a major driving force  of the data collection and discovery in the scientific enterprise, and they want to feel like they\u2019re not hiding in the shadows anymore.\u201d \n                     Young scientists ditch postdocs for biotech start-ups 2016-Nov-01 \n                   \n                     Crunch time 2016-May-24 \n                   \n                     US law could increase postdoc pay \u2014 and shake up research system 2016-May-19 \n                   \n                     Massive pool of US biomedical postdocs starts to shrink 2015-Oct-22 \n                   \n                     The future of the postdoc 2015-Apr-07 \n                   \n                     Give postdocs a career, not empty promises 2011-Mar-02 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21095", "url": "https://www.nature.com/articles/nature.2016.21095", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Researchers criticize University of Copenhagen for firing Hans Thybo on apparently \"flimsy\" grounds. The sacking of an eminent geoscientist from the University of Copenhagen has shocked and bewildered other Earth scientists, who are questioning why he lost his job. Seismologist Hans Thybo is president of the European Geosciences Union (EGU) and vice-president of the Royal Danish Academy of Sciences and Letters. He was fired last month over what university documents say was \u201cunacceptable and completely untenable\u201d behaviour. But other researchers at the university say that the firing was poorly handled, and 21 international geoscientists have signed a letter urging the university to reconsider its move. According to documents seen by  Nature , the university informed Thybo on 15 September that it would be sacking him for two reasons. First, that he put pressure on a postdoc to give an unfavourable opinion of the university management in an employment survey, and second, that he used his private e-mail for work purposes, although he had been warned not to. \u201cThe faculty in the light of your repeated violations of the employment relationship no longer trust that you can handle the senior and highly trusted position (\u2026) in which you are employed,\u201d the university\u2019s letter said. The university\u2019s stated grounds for dismissal have caused anxiety among other researchers there, says Dorthe Dahl-Jensen, a climate scientist at the university\u2019s Niels Bohr Institute. \u201cIf such grounds are to be taken at face value, many of us, and especially those who have a critical attitude to management dispositions, could be sacked as well,\u201d she says.\u00a0 \u201cMany colleagues at the University of Copenhagen have expressed concern about their jobs and security,\u201d Dahl-Jensen and three other faculty representatives wrote in their university\u2019s newsletter in November; the letter later appeared in the Danish media. \u201cWe are left with the impression that faculty members who irritate the leadership of the University of Copenhagen, are at risk of dismissal without management having to provide any real justification,\u201d the letter continues. \u201cWe do not address the purely individual aspects of the dismissal, including the specific facts of the matter, only the grounds offered for the decision.\u201d \n             Questions over handling \n           Many researchers think that there may be more behind the sacking than the university\u2019s stated grounds for dismissal. Sources who do not want to be named say that Thybo is known to be a headstrong character who has clashed with university management. He was dismissed as a group leader in his department in June 2015, and in July 2016 he received a disciplinary warning for an unapproved absence. \u201cI do not know what shadowy things might have led to this sad outcome,\u201d says Dahl-Jensen. \u201cBut I do know that our university handled that affair in a way that is quite unacceptable and damaging.\u201d Thybo, who received his final dismissal letter on 4 November, says he thinks that the situation is based on \u201cmisunderstandings and personal grudges\u201d. In October, he had written to the university rejecting all allegations of inappropriate behaviour (including the alleged unapproved absence). He told  Nature  that he is now looking to challenge the dismissal on legal grounds, and hopes that he will be allowed to resume his job. John Renner Hansen, dean of science at the University of Copenhagen, confirmed Thybo\u2019s dismissal to  Nature , but declined to comment on the reasons for it because \u201cthe case is definitely not closed from a legal point of view\u201d.\u00a0 On the specifics of the dismissal letter, Thybo says that he did send a 16 June e-mail from his private account, reminding his Egyptian postdoc Mohammad Youssof Soliman to \u201cPlease remember to fill in the questionnaire from KU [University of Copenhagen] about work environment, and remember that you do not need to be kind to management.\u201d Youssof, who left the University of Copenhagen to take up a new position this month at King Abdullah University of Science and Technology in Thuwal, Saudi Arabia, says\u00a0that he felt no pressure to criticize the university\u2019s management. He also says that he didn\u2019t take part in the voluntary survey, adding that he was shocked when he heard that Thybo had been sacked. \u201cI never figured something like this could happen in Denmark on such inconsequential grounds,\u201d he says. \u201cIt\u2019s just so sad and depressing.\u201d Meanwhile, a group of 21 eminent geoscientists \u2014 none of whom is from Denmark \u2014 have signed a letter dated 14 November that urges the University of Copenhagen to reconsider its move. \u201cThe university\u2019s reasoning is by any measure flimsy and odd,\u201d says Jonathan Bamber, a polar researcher at the University of Bristol, UK, who co-signed the letter. \u201cThe evidence they\u2019ve provided is just not commensurate with firing an internationally respected scientist. It rather seems the bizarre outcome of personal differences that should have been solved in a more urbane fashion.\u201d The affair will not affect Thybo\u2019s ability to remain at the helm of the EGU, says Bamber, who will take over the EGU presidency in April. \u201cHe has been an exemplary, fair and, at times, firm leader in whom we still have complete confidence,\u201d he says. \n                   Corporate culture has no place in academia 2016-Oct-03 \n                 \n                   Medical Nobel prize committee deals with surgical scandal 2016-Sep-14 \n                 \n                   Danish court quashes ruling against physiologist 2015-Feb-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21087", "url": "https://www.nature.com/articles/nature.2016.21087", "year": 2016, "authors": [{"name": "Zeeya Merali"}], "parsed_as_year": "2006_or_before", "body": "Breakthrough awards announce winners in physics, life sciences and mathematics. Posing problems in science can be just as rewarding as solving them. The discovery of the  black-hole firewall paradox  \u2014 one of the most confounding puzzles to emerge in physics in recent years \u2014 has bagged its co-founder a share of one of this year\u2019s US$3-million Breakthrough Prizes, the most lucrative awards in science. Joseph Polchinski, at the University of California, Santa Barbara, is one of three string theorists to share the fundamental-physics prize \u2014 announced along with the life-sciences and mathematics awards on 4 December at a glitzy ceremony at NASA\u2019s Ames Research Center in Mountain View, California. Polchinski co-authored an analysis in 2012 that concluded that either black holes are surrounded by a ring of high-energy particles known as a firewall \u2014 a possibility that contradicts the general theory of relativity \u2014 or physicists\u2019 understanding of quantum theory is wrong 1 . As yet, there is no consensus as to which of these two cornerstones of physics has to give. \u201cI made a list of about 11 distinct solutions proposed by some of the biggest names in physics, but none are quite convincing, and none are clearly wrong,\u201d says Polchinski. \u201cI\u2019m completely mystified.\u201d Andrew Strominger and Cumrun Vafa, both at Harvard University in Cambridge, Massachusetts, share the physics prize with Polchinski. All three have examined black-hole physics from the perspective of string theory, which posits that at the fundamental level, elementary particles are made up of strings that are anchored to higher-dimensional membranes, or \u2018branes\u2019. \n             Theories without experiments \n           The Breakthrough physics prizes have previously been  criticized for honouring string theorists  because string theory lies  beyond the reach of direct experimental testability . But the prize\u2019s founder, Russian billionaire Yuri Milner, argues that this helps to set the prize apart from awards such as the Nobels, which require ideas to be backed up by experiments. \u201cThe physics prizes are really recognizing intellectual achievement,\u201d he says. In this case of firewalls, he adds, \u201cthis can be in the asking of a question, rather than the finding of an answer\u201d. This May, the Breakthrough prizes cemented another distinction from the Nobels by  announcing  a special collective prize to 1,015 people working on the LIGO project. In February, researchers working at LIGO announced the  first detection of gravitational waves , ripples in the fabric of space-time created when two black holes merge. The Nobel prizes honour at most three people in their science categories. The three LIGO project leaders \u2014 physicists Ronald Drever and Kip Thorne at the California Institute of Technology in Pasadena, and Rainer Weiss of the Massachusetts Institute of Technology in Cambridge \u2014 will share $1 million; the remaining $2 million will be distributed among the other 1,012 physicists who worked on the project. This continues a trend set last year, when  1,377 neutrino physicists split the mega-prize . \u201cThe physics prize selection committee want to send a clear message here that experimental physics is collaborative,\u201d Milner says. \n             Life-sciences awards \n           Harry Noller, a molecular biologist at the University of California, Santa Cruz, was honoured with a life-sciences prize for his research revealing the centrality of RNA to protein synthesis. Some argue that he missed out on winning the  2009 Nobel Prize in Chemistry  because of the award\u2019s limitation to three winners. And t his year\u2019s Nobel laureate for physiology or medicine , Yoshinori Ohsumi at the Tokyo Institute of Technology, in Japan, also picked up a Breakthrough gong for his work on autophagy, cells\u2019 recycling system. The other life-sciences winners were: geneticist Stephen Elledge at Harvard Medical School in Boston, Massachusetts, for elucidating how cells sense and respond to DNA damage; developmental biologist Roeland Nusse at Stanford University in California for pioneering  research into the Wnt signalling pathway, which transmits signals from outside to inside cells ; and geneticist Huda Zoghbi at Baylor College of Medicine in Houston, Texas, for discovering the causes of the neurological disordersspinocerebellar ataxia and Rett syndrome. The Breakthrough prize in mathematics went to Jean Bourgain at the Institute for Advanced Study in Princeton, New Jersey, for work on the geometry of multidimensional spaces and techniques for solving partial differential equations, with applications to quantum physics, and other research. Bourgain also won the $1-million Shaw Prize in mathematics in 2010. The award ceremony, hosted by movie star Morgan Freeman, also honoured six early-career scientists, and the winner of a junior science video-making prize. \n                   Medicine Nobel for research on how cells 'eat themselves' 2016-Oct-03 \n                 \n                   The black-hole collision that reshaped physics 2016-Mar-23 \n                 \n                   Mega science prize split between 1,377 physicists 2015-Nov-09 \n                 \n                   Science prizes: The new Nobels 2013-Jun-12 \n                 \n                   Astrophysics: Fire in the hole! 2013-Apr-03 \n                 \n                   The Breakthrough Prize \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21097", "url": "https://www.nature.com/articles/nature.2016.21097", "year": 2016, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Prime Minister Justin Trudeau looks to fulfil a key campaign pledge to researchers. Canada has officially launched its search for a chief government science adviser,  fulfilling a campaign promise  by Prime Minister Justin Trudeau.  Science Minister Kirsty Duncan  announced the move on 5 December, after  spending the past year consulting scientists  about the exact role that such an adviser should have. The government will accept applications for the job until 27 January 2017. It is not yet clear how large the adviser\u2019s staff will be, or how the post will be funded. Scientists in Canada cheered the development. \u201cWe\u2019re very happy,\u201d says Rees Kassen, an evolutionary biologist at the University of Ottawa. \u201cThis is something the community has been asking for.\u201d Trudeau proposed creating a chief science officer (CSO) during his 2015 campaign. But the position has morphed into a chief science adviser (CSA), and observers see a subtle difference. Mehrdad Hariri, chief executive and co-founder of the annual Canadian Science Policy Conference, described it succinctly earlier this year: a CSO is in charge of \u201cpolicy for science\u201d; a CSA is in charge of \u201cscience for policy\u201d. Both counsel the prime minister, but the latter focuses on ensuring that scientific evidence feeds into policy decisions and acts more independently; the former typically works to ensure good management of the scientific enterprise, and acts within existing ministries. Canada\u2019s new adviser will help to ensure that federal science is available to the public and that scientists can speak freely about their work, while advising the government and the prime minister,  according to the government\u2019s job description . He or she will have a dedicated team and office. \u201cWe\u2019re feeling very pleased,\u201d says Kathleen Walsh, executive director of the non-profit science-advocacy group Evidence for Democracy in Ottawa, who says the government has listened to the community\u2019s requests for an independent adviser. Many other countries have science adviser posts or councils , including the United Kingdom and the United States. \u201cCanada is catching up internationally,\u201d says Walsh. The country had a national science adviser within its ministry of industry from 2004 until 2008, when the post was eliminated.  \n                   Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                 \n                   Canada\u2019s top scientist faces tough challenge 2015-Dec-22 \n                 \n                   Canada creates science-minister post 2015-Nov-04 \n                 \n                   Canadian election brings hope for science 2015-Oct-20 \n                 \n                   Canadian election spotlights scientists' frustrations 2015-Sep-17 \n                 \n                   Scientific advice: Crisis counsellors 2014-Aug-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21101", "url": "https://www.nature.com/articles/nature.2016.21101", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The University of California, Berkeley, and the Broad Institute are vying for lucrative rights to the gene-editing system. Alexandria, Virginia It was a tough day in US patent court for the University of California, Berkeley. On 6 December, lawyers for the university laid out its claim to  the gene-editing tool called CRISPR\u2013Cas9  during a hearing at the US Patent and Trademark Office (USPTO) \u2014 and drew intense, sometimes sceptical, questioning from the three judges who will decide the fate of patents  that could be worth billions of dollars . Berkeley and its rival, the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, are each  vying for the intellectual property underlying CRISPR\u2013Cas9 , which is adapted from a system that bacteria use to fend off viruses. During the hearing in Alexandria, Virginia, the USPTO judges challenged Berkeley\u2019s central claim: that once its researchers demonstrated that CRISPR\u2013Cas9 could be used to edit DNA in bacteria, any reasonably skilled person could have adapted the technique for use in more complex cells. If the court decides that is true, it would invalidate the patent now held by the Broad Institute. But the Berkeley argument is a difficult one to make, given that it hinges on \u201ca really subjective standard\u201d \u2014 especially when applied to extraordinarily accomplished scientists such as those at Broad, says Jacob Sherkow, a legal scholar at New York Law School in New York City. \n               Byzantine battle \n             The patent fight began in May 2012, when Jennifer Doudna, a molecular biologist at Berkeley, filed for a patent after her research team used CRISPR\u2013Cas9 to alter specific stretches of bacterial DNA. In December 2012, synthetic biologist Feng Zhang of the Broad Institute filed his own patent claim, demonstrating use of the gene-editing technique in more-complex eukaryotic cells, such as those from mice and humans. Zhang asked for \u2014 and was granted \u2014 an expedited review for his patent application. The USPTO awarded him the rights to CRISPR\u2013Cas9 in 2014. Berkeley then  asked the patent office to investigate  who first invented the gene-editing technique \u2014 a process known as a 'patent interference'. That review began in January. Over the past 11 months, the rival research institutions have filed hundreds of pages of documents with the court. The 6 December hearing was the first and only time that the two sides will speak to the judges before the court rules on the patent rights. An hour before the hearing began, the line of people waiting to watch the arguments wrapped around the Christmas tree in the lobby of the USPTO and filled two overflow rooms. Each side\u2019s lawyer had only 20 minutes to present his case to the three judges. During the hearing, Broad\u2019s lawyers quoted liberally from news articles and interviews in which Doudna said that her lab had struggled to adapt CRISPR\u2013Cas9 to eukaryotic cells. \u201cThis is the antithesis of something that would have been obvious,\u201d said Broad\u2019s lawyer Steven Trybus. Berkeley\u2019s lawyer Todd Walters downplayed these difficulties, saying that Doudna did not immediately publish CRISPR\u2013Cas9 to edit eukaryotic cells because she knew it would work. Once the technology\u2019s ability to edit DNA had been proven, he told the judges, \u201cthe only thing left was to do it\u201d. \n               A question of intent \n             But the judges seemed to disagree, and grilled Walters far harder than they did Trybus, who represented the Broad. \u201cI\u2019m not buying that everyone who does an experiment believes it would work,\u201d said Judge Richard Schafer. Rather, he added, a scientist such as Doudna may simply hope that her research will succeed. This exchange suggests that Berkeley will have a hard time convincing the court that Doudna expected CRISPR\u2013Cas9 to work in eukaryotes, Sherkow says. The university\u2019s lawyers \u201cwere trying to clarify what a biologist in 2012 would have contemplated\u201d, he notes. But biochemist Dana Carroll of the University of Utah in Salt Lake City, who wrote a declaration to the court on Berkeley\u2019s behalf, disagrees. \u201cTo embark on a project takes a certain amount of time, effort and money,\u201d he says. \u201cI don\u2019t think you'd do that unless you had some expectation of success.\u201d He points out that several other groups began working on CRISPR\u2013Cas9 in eukaryotes at the same time as Zhang did. Several experts who watched the proceedings say that the Broad\u2019s prospects look brighter now, given the judges\u2019 heavy questioning of Berkeley\u2019s lawyer. \u201cMy impression is both will end up with something,\u201d says legal scholar Robert Cook-Deegan of Arizona State University's campus in Washington DC. The Broad has hedged its bets by filing 13 patents related to CRISPR. Several of these deal with  an alternative CRISPR system  in which the DNA-cutting enzyme is taken from a different species of bacteria. Because it was developed independently, Sherkow doubts that Berkeley could claim any rights to it. He expects that the USPTO will decide the case in the next two months, although there is no deadline by which it must do so.  \n                     Titanic clash over CRISPR patents turns ugly 2016-Sep-21 \n                   \n                     The unsung heroes of CRISPR 2016-Jul-20 \n                   \n                     The quiet revolutionary: How the co-discovery of CRISPR explosively changed Emmanuelle Charpentier\u2019s life 2016-Apr-27 \n                   \n                     CRISPR: Pursuit of profit poisons collaboration 2016-Apr-13 \n                   \n                     How the US CRISPR patent probe will play out 2016-Mar-07 \n                   \n                     Bitter fight over CRISPR patent heats up 2016-Jan-12 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21102", "url": "https://www.nature.com/articles/nature.2016.21102", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Machine can re-load its latex springs fast enough to perform two jumps in a row. Meet Salto, a one-legged robot that jumps off walls with the ease of a Parkour athlete. Such agility could prove crucial in disaster scenarios, where searching for survivors or inspecting damage can require navigating uneven terrain. Salto is not the highest-jumping robot ever. But the springs in earlier machines typically took a while to reload. Salto, by contrast, can re-load in just 120 milliseconds, fast enough to produce multiple jumps in a row, and in particular to reach higher by stepping on a wall \u2013 a trick also deployed in Parkour. \u201cWhen it\u2019s contacting the wall, the motor pumps more energy into the system,\u201d says Duncan Haldane, a mechanical engineer at the University of California at Berkeley. \u201cIt\u2019s not just bouncing off the wall.\u201d To create Salto, Haldane and his collaborators took inspiration from one of nature\u2019s best jumpers, the galago ( Galago senegalensis ), a small African primate. Before taking a leap, galagos crouch to load energy in their stretched tendons. When they spring they get 15 times more acceleration than if they used muscle force alone. Salto emulates that biomechanical feat thanks to the latex spring between the robot\u2019s motor and its leg. The robot, whose name comes from the Latin verb saltare which means \u2018to jump\u2019, stands about 30 centimeters tall with its thin legs stretched out \u2013 and can jump to a maximum height of one metre in a single leap. So far it can only do two jumps in a row because it lacks the ability to stabilize itself in three dimensions, but Haldane says that future versions will fix that. Practical applications are farther off, and a useful machine would probably need two legs to walk as well as jump, say the researchers. Haldane\u2019s team publishes its results on 6 December in  Science Robotics 1 . \n                   Meet the soft, cuddly robots of the future 2016-Feb-03 \n                 \n                   'Instinctive' robot recovers from injury fast 2015-May-27 \n                 \n                   Exoskeleton boots improve on evolution 2015-Apr-01 \n                 \n                   Walking 2.0 2015-Apr-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21112", "url": "https://www.nature.com/articles/nature.2016.21112", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Proposal would keep funding flat for most research agencies, but cuts could come early next year. In what has become a year-end tradition in Washington DC, the US Congress is getting ready to approve a stopgap spending measure before it adjourns for the holidays. The legislation introduced yesterday in the House of Representatives would hold spending flat at most science agencies, with some limited increases. These include an extra US$872 million to implement provisions of the 21st Century Cures Act,  a bill that would reform drug development and biomedical research . The money would be split between the National Institutes of Health, the Food and Drug Administration and state governments. The House passed the Cures Act on 29 November, the Senate approved the bill on 7 December and President Barack Obama is expected to sign it. The stopgap funding bill, which would expire on 28 April, also allows for extra funding to keep a handful of major multiyear space programmes on track. These include the National Oceanic and Atmospheric Administration\u2019s Joint Polar Satellite System, a series of probes designed to monitor Earth\u2019s weather and climate, as well as NASA efforts to explore deep space and develop a replacement for the retired space shuttle. But for most science programmes, funding would remain at roughly the same level as in the past fiscal year. And continuing to operate under a temporary funding measure means that agencies cannot start new programmes or end old ones without explicit permission from Congress. \u201cEvery time you delay a [final] spending bill, it prevents the science agencies from doing the planning they need, and it keeps them in limbo,\u201d says Lexi Shultz, director of public affairs for the American Geophysical Union in Washington DC. Operating the government under a series of short-term bills can create uncertainty for scientists who depend on federal research grants. Each time a spending bill is passed, it takes weeks for agencies to divvy up their funds between various programmes. \u201cI feel bad for people waiting for a new grant. How do you sustain a career when you don\u2019t know what you\u2019re doing in six months?\u201d says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. \n             New president, new worries \n           The current fiscal year runs until 30 September 2017, about five months after the stopgap bill would expire. The House is expected to vote on the stopgap measure on 8 December; to become law, it would also need to be approved by the Senate and signed by Obama. But many researchers are more worried about what might come after this temporary funding extension, if it is approved. When president-elect Donald Trump takes office on 20 January 2017, Republicans will control the White House and both houses of Congress \u2014 and  their science priorities are very different  from those of outgoing President Barack Obama, a Democrat. Trump and other prominent Republicans \u2014 such as  Representative Lamar Smith, the Texan who leads the House Committee on Science, Space, and Technology  \u2014 have  criticized research in the Earth sciences , especially  studies of climate change . Scientists who work in these fields worry that politicians will move in 2017 to slash government funding for such research. And in recent years, Republican legislators including Smith and Representative John Culberson of Texas have sought to curb funding for the social sciences at the National Science Foundation. Smith has also introduced legislation that would require the agency to  certify that each grant it awards serves \u201cthe national interest\u201d . Democrats, and some science groups, have suggested that this is a tactic to reduce support for research on topics such as social science and climate change. \u201cThe election didn\u2019t result in a loss of our major critics, unfortunately,\u201d says Wendy Naus, executive director of the Consortium of Social Science Associations in Washington DC. \n                   US science agencies face budget limbo 2016-Sep-06 \n                 \n                   US budget deal could ease uncertainty over science spending 2015-Oct-28 \n                 \n                   US budget deal averts government shutdown 2015-Sep-30 \n                 Reprints and Permissions"},
{"file_id": "540182a", "url": "https://www.nature.com/articles/540182a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Economic woes wrought by globalization are only part of the cause. Waves of nationalist sentiment are reshaping the politics of Western democracies in unexpected ways\u00a0\u2014  carrying Donald Trump to a surprise victory  last month in the US presidential election, and pushing the United Kingdom to vote in June  to exit the European Union . And nationalist parties are rising in popularity across Europe. Many economists see this political shift as a consequence of globalization and technological innovation over the past quarter of a century, which have eliminated many jobs in the West. And political scientists are tracing the influence of cultural tensions arising from immigration and from ethnic, racial and sexual diversity. But researchers are struggling to understand why these disparate forces have combined to drive  an unpredictable brand of populist politics . \u201cWe have to start worrying about the stability of our democracies,\u201d says Yascha Mounk, a political scientist at Harvard University in Cambridge, Massachusetts. He notes that the long-running World Values Survey shows that people are increasingly disaffected with their governments\u00a0\u2014 and more willing to support authoritarian leaders. But this has played out in different ways across the West. Austria rejected the extreme-right Freedom Party presidential candidate Norbert Hofer in favour of Alexander Van der Bellen, a former Green Party leader, on 4\u00a0December. The same day, anti-establishment forces prevailed in Italy, where Prime Minister Matteo Renzi said he would resign after voters rejected his proposed constitutional reforms. In France, Marine Le Pen has worked to cleanse the far-right National Front of its anti-Semitic roots and build a broader working-class base. Those efforts could make the party, a minor player in French politics since the 1970s, a force during the presidential elections next year. The bulk of the party\u2019s new support is coming from deindustrialized areas in northern France, says Douglas Webber, a political scientist at the global business school INSEAD\u2019s French campus in Fontainebleau. \u201cA lot of the industrial workers arguably have made the transition from the extreme left to the extreme right,\u201d he says. In the United States, the regions hardest hit by globalization have become more politically extreme, according to a working paper published in September by David Autor, an economist at the Massachusetts Institute of Technology in Cambridge, and his colleagues. They found that these areas elected more hard-line candidates of both stripes to Congress between 2002 and 2010\u00a0\u2014 Republicans in majority-white communities and Democrats in ethnically and racially mixed areas. A separate, as-yet unpublished analysis by the team suggests that the trend towards extreme candidates favoured Republicans in presidential elections from 2000 to 2016\u00a0\u2014 perhaps enough to win Trump the White House this year. \u201cIt was just a matter of time before someone sought to tap into the rich electoral potential inside of a group of people as sizeable as the white working class,\u201d says Justin Gest, a political scientist at George Mason University in Arlington, Virginia. His polling this year suggests that 65% of white US voters would support a hypothetical new protectionist and xenophobic political party. Gest adds that Trump prevailed in part because he gave voters somebody to blame for their economic woes. Some academics have explored potential parallels between the roots of the current global political shift and the rise of populism during the Great Depression, including in Nazi Germany. But Helmut Anheier, president of the Hertie School of Governance in Berlin, cautions that the economic struggles of middle-class citizens across the West today are very different, particularly in mainland Europe. The Nazis took advantage of the extreme economic hardship that followed the First World War and a global depression, but today\u2019s populist movements are  growing powerful in wealthy European countries  with strong social programmes. \u201cWhat brings about a right-wing movement when there are no good reasons for it?\u201dAnheier asks. In the United States, some have suggested that racism motivated a significant number of Trump voters. But that is too simplistic an explanation, says Theda Skocpol, a sociologist at Harvard University. \u201cTrump dominated the news for more than a year, and did so with provocative statements that were meant to exacerbate every tension in the US,\u201d she says. Trump also prevailed in part because the structure of the US electoral college gives outsized influence to Republican-leaning rural areas over Democratic urban centres. And some of his predominantly white supporters voted for President Barack Obama, a Democrat, in past elections. \n               Outlook hazy \n             Le Pen has called Trump\u2019s win \u201ca sign of hope\u201d for her own campaign, but Webber is sceptical. The latest polls suggest that Le Pen would pick up less than one-third of the vote in a run-off with former prime minister Fran\u00e7ois Fillon, who is running under the banner of the centre-right Republican party, and France\u2019s economy is fairly stable. \u201cI\u2019m not as pessimistic as some,\u201d Webber says. The rise of nationalism in France has been going on for longer, and seems to have progressed more slowly, than similar surges in many other countries, he says. Mounk says the broader trend towards nationalism caught political scientists off-guard because they are often too focused on finding new ways to answer mundane questions. Academics must redouble their efforts to understand the nationalist wave and help policymakers to address it, he adds. \u201cIn times of freedom and prosperity, it was nice for us to sit around and pretend to be scientists,\u201d Mounk says. \u201cBut right now, if you are twiddling your thumbs with your statistical models instead of thinking about how we can save liberal democracy, you are doing something immoral.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Donald Trump's US election win stuns scientists 2016-Nov-09 \n                   \n                     Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                   \n                     The elephant in the room we can\u2019t ignore 2016-Mar-16 \n                   \n                     Eurovision voting shows strain of economic crisis 2013-Jan-25 \n                   \n                     Nature  Special: US election 2016 \n                   \n                     Nature  Special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21127", "url": "https://www.nature.com/articles/nature.2016.21127", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Oklahoma attorney-general Scott Pruitt has sought to reverse federal limits on greenhouse-gas emissions and air pollution. President-elect Donald Trump has chosen Oklahoma attorney-general Scott Pruitt to lead the US Environmental Protection Agency (EPA). Pruitt, who must be confirmed by the US Senate, is an ardent opponent of federal regulations to curb climate change and has questioned the science underlying global warming. He is one of dozens of state officials who have mounted a legal challenge to President Barack Obama\u2019s  limits on greenhouse-gas emissions from power plants  \u2014 regulations that Trump has promised to repeal. That case is  pending review by the US Supreme Court . If the court agrees to hear the case, the outcome could hinge on whom Trump nominates to fill a vacancy on the nine-member panel of judges. Some experts say that the EPA itself could also seek to repeal the regulations after Trump takes office. In May, Pruitt made his views on climate science clear in  a guest editorial in the  National Review  that he wrote with Alabama attorney-general Luther Strange. \u201cScientists continue to disagree about the degree and extent of global warming and its connection to the actions of mankind,\u201d the pair wrote. \u201cThat debate should be encouraged \u2014 in classrooms, public forums, and the halls of Congress. It should not be silenced with threats of prosecution. Dissent is not a crime.\u201d \n             Strong reactions \n           Environmentalists blasted Trump for choosing Pruitt, whom they say has put the interests of the fossil-fuel industry before those of the environment and the people of Oklahoma. As well as challenging Obama\u2019s climate regulations, Pruitt has sued the EPA to halt a series of regulations intended to keep air and water clean. In doing so, he has often worked in concert with the same oil, gas and coal companies that he would regulate as EPA chief. \u201cIt\u2019s hard to imagine a more alarming person to run the nation\u2019s Environmental Protection Agency,\u201d says Jeremy Symons, associate vice-president for climate and political affairs at the Environmental Defense Fund, an activist group in New York City. \u201cIt\u2019s an unprecedented gamble with an agency that has protected the air we breathe and the water we drink across Republican and Democratic administrations for more than 40 years.\u201d But Pruitt will have plenty of support from industry officials \u2014 many of whom have long asserted that the EPA has overreached its regulatory authority, particularly on climate change. Scott Segal, a lawyer at the firm Bracewell in Washington DC, which has represented many industry interests, calls Pruitt \u201ca measured and articulate student of environmental law and policy\u201d. Segal adds that Pruitt understands and respects states' roles in environmental policy, and that his decisions to challenge federal regulations should not disqualify him for the EPA job. \u201cThere is no conflict in faithfully representing your state on litigation dealing with rules of general applicability and then serving your nation as a federal administrative official,\u201d Segal says. To win Senate approval for the EPA post, Pruitt would require only a simple majority of 51 senators in a body where Republicans will hold at least 51 seats. (A 52nd seat is up for grabs in a 10 December run-off election in Louisiana.) This means that Republicans should have enough votes to approve Pruitt if they stick together. \n                   Tracking the Trump transition, agency by agency 2016-Nov-30 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                 \n                   US Supreme Court puts Obama climate regulations on hold 2016-Feb-10 \n                 \n                   Nature  special: US election 2016 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20993", "url": "https://www.nature.com/articles/nature.2016.20993", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "A discovery that was supposed to help reveal how the bursts arise only thickens the plot. What causes split-second blasts of radio waves that appear in the sky from  billions of light years away  is  one of the most perplexing mysteries in astronomy.  Now, for the first time, astronomers have seen a flash of high-energy \u03b3-rays that looks as if it was emitted by the same event that produced a fast radio burst (FRB) \u2014 a correlation that was predicted to help whittle down the zoo of possible explanations for the origin of FRBs. \u201cIf FRBs have \u03b3-ray counterparts, it would be hugely constraining of models and extremely interesting,\u201d says Victoria Kaspi, an astrophysicist at McGill University in Montreal, Canada. But as well as exciting astronomers, the nature of this particular finding offers no clear answers and deepens the FRB riddle. \u201cThe association, should it turn out to be true, is an entirely unexpected and astonishing development,\u201d says Shri Kulkarni, an astronomer at the California Institute of Technology in Pasadena. \n             Orbiting observation \n           The \u03b3-ray signal, described in a paper published on 11 November in  The Astrophysical Journal Letters 1 , turned up in data from a NASA orbiting \u03b3-ray observatory called Swift. A team from Pennsylvania State University (Penn State) in University Park found that a \u03b3-rays flare at around the same time and from the same direction as FRB 131104, a burst named for the date it was seen by the Parkes Observatory radio telescope in Australia, on 4 November 2013. One puzzle is that the two signals portray different pictures of the underlying source, which seems to be as much as 10 billion light years (3.2 gigaparsecs) away. Whereas the radio burst lasted just a few milliseconds, the \u03b3-ray signal lasted between two and six minutes, and it released much more energy in total than the radio burst. \u201cWe\u2019ve pumped up the energy budget more than a billion times,\u201d says study co-author Derek Fox, an astrophysicist at Penn State. This has big implications for the FRB\u2019s origin. One leading theory suggests that FRBs are flares from distant magnetars \u2014 neutron stars with enormous magnetic fields that could generate short, energetic blasts of energy, and do so repeatedly,  as at least one FRB is known to do . Although magnetars are thought to produce \u03b3-rays, they would not emit such high energy and over such a long time, says Fox. \u201cThis is a severe challenge for magnetar models,\u201d he says. \n             Black-hole contender \n           Instead, the \u03b3-ray signal resembles events that Swift has observed previously, which scientists identified as either a shock-wave blast from a supernova or a surge in radiation from a supermassive black hole as it swallowed a star, says Fox. The problem with both of these options is that neither is expected to produce radio bursts. Another possibility is that both the \u03b3-radiation and radio burst came from a collision between neutron stars. But if that is true, it would not offer an explanation for all FRBs: colliding neutron stars are thought to be relatively rare, whereas estimates suggest that FRBs are common, occurring around once every ten seconds somewhere in the sky. (Astronomers have so far detected only around 20 FRBs, largely because radio telescopes usually only look at small patches of sky). Fox notes that there are already hints that FRBs could be generated by more than one type of source. Many astronomers also need convincing that the FRB and the \u03b3-ray signal detected by Swift come from the same source. Statistically, the chance that the \u03b3-ray burst would occur at the same time and from the same place as the FRB by pure chance, if there were no real association, is just 1 in 800, says Fox. And there is not any other known source in that direction that could produce the \u03b3-ray burst, he adds. Although such a result would usually pass the statistical threshold needed to conclude that the two signals are produced by the same source, Kaspi says that the finding is so unprecedented that more evidence is needed. \u201cExtraordinary claims demand extraordinary evidence,\u201d she says. \n             More data needed \n           Kulkarni is also cautious. \u201cThe association could be due to chance coincidence of a blip in the \u03b3-ray sky with a single FRB,\u201d he says. \u201cWe would definitely need a few more such associations to take this hypothesis seriously.\u201d Fox hopes to find more. As new and existing telescopes begin to hunt for FRBs, the number of known bursts should rise from the current count of around 20 to more like 200. If that happens, Swift should be able to check more than a dozen of these locations for correlated \u03b3-ray bursts using the centre of its field of view. Detecting \u03b3-ray signals centrally would produce more statistically significant results than for FRB 131104, which was picked up at the edge of the telescope\u2019s field of view, where noise can more easily mimic signals. And this, in turn, would increase scientists\u2019 certainty that a signal\u2019s correlation with an FRB is not just due to chance. \u201cThen the confidence level would be one in a billion,\u201d says Fox. \n                   Why ultra-powerful radio bursts are the most perplexing mystery in astronomy 2016-Jun-28 \n                 \n                   Fresh confusion over origins of enigmatic radio-wave blasts 2016-Mar-02 \n                 \n                   Microwave oven blamed for radio-telescope signals 2015-May-08 \n                 \n                   Mystery extra-galactic radio bursts could solve cosmic puzzle 2013-Jul-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21031", "url": "https://www.nature.com/articles/nature.2016.21031", "year": 2016, "authors": [{"name": "Brigitte Osterath"}], "parsed_as_year": "2006_or_before", "body": "Imbalance exists even though supply of reviewers outstrips demand, study suggests. In 2010, researchers Jeremy Fox and Owen Petchey issued a stark warning about the sustainability of scientific peer review. \u201cThe peer review system is breaking down and will soon be in crisis,\u201d they wrote in  The Bulletin of the Ecological Society of America 1 . As the number of published articles was rising each year, demand for reviews would soon outstrip supply, they said. But a new calculation argues that there\u2019s no need for alarm. In 2015, the number of scientists in the life sciences far exceeded the demand on them for peer review, according to Michail Kovanis, a computational physicist at the French National Institute of Health and Medical Research (INSERM) in Paris, and his colleagues. In fact, the supply of scientists is rising faster than the demand for reviewers, the researchers say. Yet their study also suggests \u2013 based on data obtained from a rapidly-growing website of peer-review activity \u2013 that 20% of the scientists undertook between 69% and 94% of reviews last year, lending credence to some researchers\u2019 complaints that they are overburdened. \u201cThese \u2018peer-review heroes\u2019 may be overworked, with risk of downgraded peer-review standards,\u201d Kovanis and colleagues write in a paper published in  PLOS One  earlier this month 2 . \n             Modelling peer review \n           Kovanis\u2019s team examined published papers listed in Medline, a database of life-sciences research, for 1990\u20132015. For each year, they estimated the reviews required by making assumptions on what fraction of papers go through multiple rounds of review. For the 1.1 million papers published in 2015, for example, the researchers estimated that those studies needed 9 million reviews (although they added that the figure could be as high as 30 million reviews). All those reviews would suck up a total of 63.4 million hours, they say, basing those estimates on earlier peer-reviewer surveys by Dutch publisher Elsevier. To find out how many manuscripts a scientist typically reviews each year, the team used data from the website Publons, covering the activity of more than 70,000 researchers who had uploaded peer-review records (in part,  to receive recognition for their work ). On that basis, scientists who are active reviewers conduct around five reviews each year on average, the team says, although some get through dozens and others only do one. In 2015, they suggest, 1.8 million reviewers were needed to meet demand. The number of scientists available always exceeds the demand for reviewers, say the researchers. In 2015, for example, around 6.4 million authors were listed on life-science research papers \u2013 giving journal editors a vast over-supply of people to ask. Even if editors only asked specific authors to be reviewers \u2014 for example, those in prestigious first and last positions in the author list \u2014 they still had 2.1 million candidates.\u00a0 \n             Unequal burden \n           In general, \u201cthe maths makes sense, and the numbers should hold true,\u201d says Tim Vines, who runs the peer-review agency Axios Review in Vancouver, Canada, although experts will argue with some of the assumptions of Kovanis\u2019s model, he says. Phil Davis, a publishing consultant in Ithaca, New York, says that while the so-called \u2018crisis\u2019 may indeed not be affecting elite journals, lesser-known journals that receive a lot of badly written manuscripts may well be struggling to find reviewers, a possibility that the  PLOS One  paper doesn\u2019t analyse. Petchey, now at the University of Zurich in Switzerland, says that it\u2019s good to know there are enough reviewers available, and notes that his earlier critique was based on anecdotal, not quantitative, evidence. \u201cThat means that it is OK for me to say \u2018no\u2019 to an editor from time to time,\u201d he says.\u00a0 But the Publons data also suggest that a small number of reviewers do most of the work. That, says Vines, holds true in his experience as managing editor of the journal  Molecular Ecology  between 2008 and 2015. At that time, he says, the journal\u2019s top 300 reviewers \u2014 who were 8% of the journal\u2019s reviewing pool \u2014 took more than a quarter of the manuscripts. This was in part because some researchers refused to review, but also because editors leant heavily on reviewers they knew and trusted, he says. Bernd Pulverer, chief editor of the  EMBO Journal  in Heidelberg, Germany, says he is not sure that the data from Publons accurately represents how many reviews researchers actually do, since many scientists aren't yet registered with the site. Still, he says, editors do need to broaden their referee pool to include younger researchers, as well as people in Asia. \u201cWe are too restrained in where we turn for reviewers,\u201d he says. A 2014 Elsevier  survey  found that Chinese researchers wrote substantially more papers than they reviewed, simply because they were not asked to be reviewers. Martijn Arns, a neuroscientist at Utrecht University in the Netherlands, cautions that even if there are enough potential reviewers available, this doesn\u2019t mean that they conduct their reviews thoroughly. As their administrative tasks pile up, pressured scientists may feel they can skimp on time put into reviews, causing a crisis of poor reviewing. \u201cQuantity does not equal quality,\u201d he says. \n                   Open peer review finds more takers 2016-Nov-10 \n                 \n                   Let\u2019s make peer review scientific 2016-Jul-05 \n                 \n                   Open access is tiring out peer reviewers 2014-Nov-25 \n                 \n                   Company offers portable peer review 2013-Feb-12 \n                 \n                   No crisis in supply of peer reviewers 2010-Dec-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20994", "url": "https://www.nature.com/articles/nature.2016.20994", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Drilling into Mexico\u2019s Chicxulub basin also finds shattered rock where underground life could thrive. Drilling into  ground zero of the asteroid impact that killed off the dinosaurs  66 million years ago has uncovered the origin of its mysterious ring of mountains. The drill core penetrated a circle of mountains, known as a peak ring, in Mexico\u2019s buried Chicxulub crater. Only the largest impacts are powerful enough to form peak rings. Understanding how these mountains formed at the 200-kilometre-wide Chicxulub could help to reveal how cosmic collisions shaped other bodies, such as the Moon and Venus. The work also shows how,  despite killing the dinosaurs , the impact may have created an environment where other life could thrive. The cosmic smash-up fractured rocks, opening up spaces and warm habitats for microbes to move in. \u201cWe got a core better than we could reasonably have imagined,\u201d says David Kring, a geologist at the Lunar and Planetary Institute in Houston, Texas. \u201cIt is absolutely extraordinary.\u201d He and his colleagues describe the findings on 18 November in  Science 1 . \n               Drilling down \n             After a decade of planning, the project penetrated 1,335 metres into the sea floor off the coast of Progreso, Mexico, in April and May. Drillers hit the first peak-ring rocks at a depth of 618 metres, and a pinkish granite at 748 metres. Geologists know that the granite must have come from relatively deep in the crust \u2014 perhaps 8\u201310 kilometres down \u2014 because it contains big crystals. The size of these crystals suggests that they formed by the slow cooling of deep, molten rock; in contrast, rapid cooling at shallow depth tends to form small crystals. Finding the granite relatively high in the drill core means that something must have lifted it up and then thrown down it on top of other rocks. That rules out one idea of how craters form, in which the pulverized rock stays mostly in place like hot soup in a bowl. Instead, the core confirms the \u2018dynamic collapse\u2019 model of cosmic impacts, in which the asteroid punches a deep hole in the crust, causing the rock to flow like a liquid and spurt skyward. That rock then falls back to Earth, splattering around in a peak ring. \u201cThe ring of mountains we observe is made of deep material uplifted and flipped on its head,\u201d says Sean Gulick, a geophysicist at the University of Texas at Austin. Gulick co-led the Chicxulub expedition with Joanna Morgan, a geophysicist at Imperial College London. \n               Free space \n             Knowing that Chicxulub formed through dynamic collapse opens new ways to explore other worlds, says Kring. Last month, he and his colleagues showed that, like Chicxulub, the peak ring of the Moon\u2019s 320-kilometre-wide Schr\u00f6dinger crater is made of material from deep in the crust 2 . This means that robots or astronauts could visit Schr\u00f6dinger to pick up samples of the lunar interior.\u00a0 Chicxulub is the only good example of a peak-ring crater on Earth. Studying peak rings in impact basins on other worlds could confirm whether the dynamic collapse model holds true for in different environments, says David Baker, a planetary scientist at NASA's Goddard Space Flight Center in Greenbelt, Maryland, who has published on peak-ring formation 3 . The Chicxulub core also explains a long-standing geophysical mystery \u2014 why seismic waves move surprisingly slowly in the peak-ring rocks. The answer is that the impact fractured the granite so much that it became much less dense than typical granite, slowing the waves\u2019 progress. Lower density also means that rock is more porous, providing space for microbes to move around inside. After the sterilizing heat of the Chicxulub impact had dissipated, organisms may have taken advantage of the lingering warmth. \u201cSomehow life finds its way into these high-porosity targets and takes advantage of the habitat created,\u201d says Gulick. An underground biosphere could have evolved over millions of years, surviving off chemical energy and warmth without sunlight. Project scientists have found cells and microbial DNA in the Chicxulub core, but are holding details for future publications. \n                     Geologists to drill into heart of dinosaur-killing impact 2016-Mar-31 \n                   \n                     Asteroid impact may have gassed Earth 2009-May-13 \n                   \n                     'Dinosaur-killing' impact did not start global wildfires 2009-Feb-23 \n                   \n                     Volcanoes implicated in death of dinosaurs 2008-Dec-16 \n                   \n                     IODP Chicxulub expedition \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21013", "url": "https://www.nature.com/articles/nature.2016.21013", "year": 2016, "authors": [{"name": "Valeria Rom\u00e1n"}], "parsed_as_year": "2006_or_before", "body": "Researchers chafe at spending cuts and fear a brain drain. Researchers in Argentina are incensed about budget cuts that look set to hit the nation\u2019s science ministry especially hard next year \u2014 even though President Mauricio Macri pledged to boost science spending when he took office last December. \u201cScience in Argentina faces a critical situation,\u201d says Dora Barrancos, a gender-issues researcher at the National University of Quilmes in Buenos Aires. She fears that the cuts, after years of budget increases, may presage a return to the troubles of the twentieth century, when scientists fled the country in their thousands. \u201cIf young scientists do not have opportunities here, the brain drain is going to restart.\u201d In September this year, Macri\u2019s government proposed to cut overall science spending to around 32\u00a0billion pesos (US$2 billion) in 2017, a fall of around 6% in real terms, according to government estimates of domestic inflation. As part of that proposal, the science ministry would have seen a cut of more than 50% in real terms. In October, scientists poured out onto the streets in protest. A revamped budget, passed by Argentina\u2019s lower house of parliament on 3 November, has added around 1.3 billion pesos to overall science spending, limiting the damage to around 2%. Still, the science ministry will take a real-terms cut of 36% \u2014 and researchers remain unhappy. Argentina\u2019s Senate is due to vote on the budget by the end of November. Particularly galling is that Macri had promised dramatic increases to the country\u2019s research spending in his campaign. He proposed raising the share of the economy dedicated to science and technology from around 0.6% of gross domestic product in 2014 to 1.5% by 2019. Instead, he has prioritized paying off Argentina\u2019s debt, notes Jorge Aliaga, a physicist at the University of Buenos Aires. Aliaga also points out that the government's overall budget is rising in real terms. Taking that into account, he argues that the science budget is 8.5% down on where it would be if it had kept pace with overall spending. \n             Street protests \n           Aliaga is part of Science and Technology Argentina (CyTA), a group of concerned scientists who in October coordinated a petition against Macri\u2019s first budget. More than 33,000 researchers and university teachers signed it, and CyTA and university-student associations organized protests in 9\u00a0cities, including outside the parliament in Buenos Aires. The noise got parliament\u2019s attention, and helped prompt the revised budget. But the damage-limitation hasn\u2019t been enough, researchers say. The National Scientific and Technical Research Council (CONICET), a research institute that employs some 9,600 research staff, now gets a 6% real-terms raise to around 10 billion pesos ($660 million). Most of the institute's cash is swallowed up in paying salaries for researchers. It planned to increase its research staff by 10% annually until 2019 \u2014 and had hired 920 young researchers this year \u2014 but will only be able to pay 400 new staff in 2017. As a result, \u201cyoung scientists will go abroad, and the setback will be very difficult to revert\u201d, says Andrea Gamarnik, a virologist at the Leloir Institute Foundation in Buenos Aires. Lorena Coria, a 33-year-old biologist on a CONICET postdoc fellowship to develop oral vaccines for children, is one researcher who applied to be hired by the institute this year \u2014 but as a result of the constrained budget, now does not know if she will be taken on. \"I know there are good opportunities abroad,\" she says. The science ministry takes the worst hit. In particular, its National Agency for the Promotion of Science and Technology, which funds both basic and applied research, had been set for a 60% real-terms budget drop in September\u2019s version of the budget. With November\u2019s parliamentary adjustment, and by borrowing money from credit organizations such as the Inter-American Development Bank, the agency may yet recover some of its lost spending power, says science minister Lino Bara\u00f1ao. Bara\u00f1ao also insists that there will be no brain drain. He prefers to take the long view, noting that science and technology funding has steadily increased since 2007. And parliamentary budgets do not set funding in stone: this year\u2019s spending on science, for example, looks set to be around 4% higher than the 2016 settlement that was agreed by parliament. The same could happen in 2017, he says. \n                   A tale of two governments: the politician behind Argentina's science growth 2016-Aug-16 \n                 \n                   What Argentina\u2019s financial woes mean for science 2014-Aug-21 \n                 \n                   Argentina: The come back 2008-Nov-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20995", "url": "https://www.nature.com/articles/nature.2016.20995", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The ability to control very small groups of neurons could have big implications for brain science. San Diego, California Lasers shone into the brains of mice can now activate individual neurons \u2014 and change the animals' behaviour. Scientists have used the technique to increase how fast mice drink a milkshake, but it could also help researchers to map brain functions at a much finer scale than is currently possible. Neuroscientists at Stanford University in California conducted their experiments on mice that were genetically engineered to have light-sensitive neurons in a brain region called the orbitofrontal cortex. That area is involved in perceiving, and reacting to, rewards. By shining a laser at specific neurons, the researchers increased the pace at which the mice consumed a high-calorie milkshake. The results, reported on 12 November at the annual meeting of the Society for Neuroscience in San Diego, California, illustrate for the first time that the technique,  known as optogenetics , can control behaviour by activating a sequence of individual cells. One goal of optogenetics is to create automated systems that manipulate the brain on the fly using only light, says Michael H\u00e4usser, a neuroscientist at University College London, UK. This might be done by engineering neurons to contain one protein that makes the cell fire when activated by a flash of coloured light, and another that causes the cell to flash in a different colour when it fires. A device that detected this second colour could quickly determine sites of activity associated with certain behaviours and customize which cells the first light would stimulate in response. Such a system might be able to alter the neural processes that link alcohol with reward in addiction, or a visual trigger with flashbacks in post-traumatic stress disorder. It would also require precision beyond the capability of current optogenetic techniques, which activate clusters of cells. In some cases, activating just one neuron can change an animal\u2019s behaviour  2 , so accidentally  hitting a cell\u2019s neighbour could confuse efforts to map the brain . 1 \n             Laser focus \n           In the mice experiment, the Stanford team led by neuroscientists Joshua Jennings and Karl Deisseroth shone a laser through a device that scatters the light into a pattern that hits specific neurons. To ensure that the cells they targeted were specific to food rewards, the researchers mapped cells involved in social rewards, which are mixed in with the calorie-reward cells but drive very different behaviours. They allowed a baby mouse to run around in a tube inside the microscope and touch noses with the mouse whose brain was being imaged and then mapped which neurons responded when the two animals interacted. When the researchers repeated the first experiment with the high-calorie drink, but stimulated the social neurons rather than the food-reward ones, the mouse continued to lick up the water at the same speed. The team is now trying to determine whether activating the social neurons will make the animal act as though it is sensing pheromones by, for example, moving its whiskers, even when the baby mouse isn\u2019t present. The behaviour modification is an important step in exploring the potential of single-cell stimulation, says Weijian Yang, a neuroengineer at Columbia University in New York City. At the meeting, he and neuroscientist Luis Carrillo Reid presented a different approach to behaviour modification, artificially linking neurons that are normally involved in very different behaviours. The pair trained mice to lick at a reward only when they see a certain pattern shown on a screen, and mapped the neurons that respond to the image and those that respond to the reward. Carrillo Reid says that repeatedly stimulating these unrelated neurons using optogenetics will eventually cause them to fire in sync, so that stimulating just one of them will cause the mouse to see the pattern and lick, even when the pattern isn\u2019t there. H\u00e4usser is impressed with the work and says that the next step is to figure out the entire neural pathway that is being changed. It will also be important to work out what the mouse perceives when its brain is stimulated, so that any changes can be made to feel as natural as possible. \u201cThe real potential of all-optical control has yet to be unlocked,\u201d he says. \n                   Brain-manipulation studies may produce spurious links to behaviour 2015-Dec-09 \n                 \n                   Neuroscience: Solving the brain 2013-Jul-17 \n                 \n                   Neuroscience: Illuminating the brain 2010-May-05 \n                 \n                   Society for Neuroscience annual meeting \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21014", "url": "https://www.nature.com/articles/nature.2016.21014", "year": 2016, "authors": [{"name": "Claudio Angelo"}], "parsed_as_year": "2006_or_before", "body": "Cap at current spending levels could spell \u2018end of science in Brazil\u2019, researchers say. Brazil\u2019s science budget has shrunk by more than 40% in the past 3 years. But researchers are now trying to escape an even worse crisis: federal science spending could be frozen at its current low level for the next two decades, under a constitutional amendment to cap public spending to inflation-level rises. On 16 November, 19 institutions representing higher education and research  sent a letter  to Brazil\u2019s Senate asking that politicians exclude science and education from the  amendment , which is President Michel Temer\u2019s top legislative priority as he aims to halt the country\u2019s spiralling fiscal crisis. The amendment passed the lower house of Brazil\u2019s National Congress last month; the Senate is due to vote on it by the end of this month. If Temer\u2019s legislation does end up constricting federal science spending, \u201cit will be the end of science in Brazil\u201d, warns physicist Luiz Davidovich, who is president of the Brazilian Academy of Sciences in Rio de Janeiro, which co-authored the letter. Last month, scientists joined protests in Rio and other cities against the amendment, which they called the #PECdoFimDoMundo (amendment of the end of the world). \n               Science in crisis \n             Brazil\u2019s public spending does need to be reined in, says Carlos Am\u00e9rico Pacheco, chief executive of the S\u00e3o Paulo Research Foundation, a state science-funding agency. \u201cIt\u2019s a bitter medicine, but it\u2019s inevitable: you won\u2019t be able to fix public finance without a major effort to cut expenses,\u201d he says. But scientists say that they\u2019ve had enough pain. In 2013, the science ministry budget stood at 7.9 billion reais (US$2.3 billion). After the economy slumped, it has now fallen to 4.6 billion reais \u2014 the lowest level in 7 years (see \u2018Funding nosedive\u2019), and the lowest in a decade when inflation is accounted for. And that includes the budget of the communications ministry, which Temer  merged with the science ministry  to create the Ministry of Science, Technology, Innovations and Communications (MCTIC) when he took office in May. As a result of the cuts, some Brazilian scientists have left the country; others are making do on less funding. And officials at major planned facilities such as the 850-million-real Multipurpose Research Reactor outside S\u00e3o Paulo \u2014 which aims to generate medical radioisotopes \u2014 and the 1.75-billion-real Sirius synchrotron, in Campinas, have complained that they haven\u2019t yet received their 2016 funds. Freezing the science budget at these low levels could be disastrous, says Helena Nader, president of the Brazilian Society for the Advancement of Science. Federal science spending is currently around 1.1% of Brazil\u2019s gross domestic product (GDP), but that figure will fall if spending is frozen and GDP grows over the coming years. Nader compares that with science spending in China, which is planned to grow from 2.1% of GDP now to 2.5% in 2020. The MCTIC says that the amendment will not necessarily affect the science budget. Science might even get more money \u2014 provided that other areas of federal funding get less. But critics say that\u2019s unlikely in a country with other pressing needs, including chronically underfunded public education and health and a collapsing pensions system. \n               Next year\u2019s budget \n             MCTIC minister Gilberto Kassab is trying to increase the science budget ahead of the amendment. His 2017 request, included in a government proposal that has not yet been voted on by Congress, would increase the budget by 28% to 5.9 billion reais. \u201cThe MCTIC has managed to include in the annual budget a value that\u2019s enough to meet the needs of the sector,\u201d a spokesperson told  Nature . Davidovich disagrees. He says that, after accounting for inflation, research needs at least 10 billion reais to match the federal science spending levels of three years ago \u2014 so it is well under par. To scientists\u2019 further dismay, the National Council for Scientific and Technological Development \u2014 a federal funding agency \u2014 has been further demoted within the new structure of the MCTIC. The council used to be an independent body whose president would report directly to the science minister; now it and other institutions such as the Brazilian Space Agency will report to a director who in turn will report to a vice-minister for science. \u201cWe [science] have been shoved to the fourth level,\u201d says Nader. The political downgrading will make it harder for the council to fight for resources, say Nader and Davidovich. Last month, the Brazilian Society for the Advancement of Science and the Brazilian Academy of Sciences delivered a joint letter to Kassab protesting against the move. The minister said that he would review the changes in January. For now, Brazilian science faces a cloud of uncertainty. As researchers have asked, the amendment could be altered to spare sensitive areas such as education and research. Senators might also try to spare a specific slice of the MCTIC budget that comes from the revenue of some businesses (such as oil and telecommunications), Davidovich thinks. It is hard to predict how the amendment might unfold in the Senate, he says. \u201cBut then again, someone has said that, in Brazil, even the past is unpredictable.\u201d \n                     Political upheaval threatens Brazil\u2019s environmental protections 2016-Nov-08 \n                   \n                     Brazil's scientists start street protests against ministry merger 2016-Jun-10 \n                   \n                     Demotion of science ministry angers beleaguered Brazilian researchers 2016-May-12 \n                   \n                     Brazilian science paralysed by economic slump 2015-Sep-30 \n                   \n                     Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21015", "url": "https://www.nature.com/articles/nature.2016.21015", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Influential committee says researchers need assurances that they can stay after UK leaves European Union. The UK government should immediately guarantee that all European Union researchers living in the country can stay after it leaves the EU, an influential group of politicians has said. The recommendation comes in  a report on the impacts of Brexit on science , released on 18\u00a0November by the House of Commons science and technology select committee. The report also urges the government to set out a broader vision for science \u2014 including committing to a hefty raise in UK science spending. \u201cUncertainty over Brexit threatens to undermine some of the UK\u2019s ongoing international scientific collaborations. Telling EU scientists and researchers already working in the UK that they are allowed to stay is one way the Government could reduce that uncertainty right away,\u201d said Stephen Metcalfe, the chair of the committee and Conservative MP for South Basildon and East Thurrock, in a statement. Ever since June\u2019s Brexit referendum, scientists have  fretted about the uncertainty caused  for non-British EU nationals, who have been left unsure what their employment rights may be in a few years\u2019 time. There are around 31,000 such researchers in the United Kingdom, according to a Royal Society estimate, and they make up about 15% of UK universities' academic staff. The committee\u2019s inquiry heard from many researchers who were \u201cseriously considering\u201d leaving the country, and the report concludes that reassurances are needed to avoid a brain drain. A group at University College London\u2019s Institute of Neurology told the committee that it had polled 67 postdocs, of whom 18% were actively seeking jobs outside the United Kingdom because of Brexit. \u201cSome immediate reassurance would be in the interest of the science base and the country,\u201d says Graeme Reid, a science-policy researcher at University College London. \n             Vision for science \n           The committee \u2014 whose members come from all sides of the political divide \u2014 also worries that the government isn\u2019t paying enough attention to science as it prepares to leave the EU. \u201cWe are not convinced that the needs of science and research are at the heart of the Department for Exiting the European Union\u2019s (DExEU) thinking and planning for Brexit,\u201d the report says. For example, whereas most UK government departments have a chief science adviser (CSA), DExEU \u2014  dubbed the Brexit ministry  \u2014 doesn\u2019t. In a confused episode during the inquiry, science minister Jo Johnson and junior Brexit minister Robin Walker told the committee that they were advertising to fill the role, but later withdrew their statement. Now, says the report, DExEU should recruit someone as a matter of urgency. The committee adds that the government should commit to raising public and private spending on research to 3% of UK gross domestic product. It stood at 1.7% in 2014, below the EU\u2019s 2% average. The report notes that the 3% figure has been suggested many times before, by the committee itself and by science lobby groups. And earlier this week it got another airing, when the four UK national academies \u2014 the Academy of Medical Sciences, the British Academy, the Royal Academy of Engineering and the Royal Society \u2014 also called on the government to set a 3% target. \n             Action points \n           Nick Hillman, director of the Higher Education Policy Institute in Oxford, says it is good that the report contains sensible, practical suggestions for science advice and job security, rather than vague requests. \u201cHaving a CSA is a clear, practical recommendation that is easily fixed,\u201d he says. Researchers are now  waiting anxiously for 23 November , when Philip Hammond, the chancellor of the exchequer, may signal the government\u2019s intentions for science in the annual Autumn Statement on government spending. \u201cThat\u2019s quite an important date for the science and research community,\u201d says Hillman. \u201cI wouldn\u2019t place all my bets on an Autumn Statement announcement,\u201d says Reid. But he thinks that the government does recognize that science has an important role in the United Kingdom\u2019s future. Another political controversy was partially addressed earlier this week, when the government announced a series of amendments to  controversial plans to reform the governance of higher education . The plans aim to bring together several funding bodies \u2014 including the seven research councils \u2014 into a central funder called United Kingdom Research and Innovation, and to overhaul university governance. But some researchers fear that it  might remove universities\u2019 autonomy , including their ability to choose what to teach and when. Johnson  says the changes  include measures to ensure the autonomy and financial sustainability of universities \u2014 including not allowing the government to tell institutions that they must stop or start particular courses. \n                   Brexit government\u2019s anti-immigration stance spooks UK scientists 2016-Oct-06 \n                 \n                   UK government gives Brexit science funding guarantee 2016-Aug-15 \n                 \n                   E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                 \n                   Nature  special: Brexit and science \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21022", "url": "https://www.nature.com/articles/nature.2016.21022", "year": 2016, "authors": [{"name": "Daniel Cressey"}, {"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Questions remain around commitment to boost science investment. UK scientists have welcomed a surprise government promise to invest an extra \u00a32 billion (US$2.5 billion) per year into research and development (R&D) by 2020 \u2013 although details of the pledge will not be made clear for at least another two days. In a  speech  delivered in London on 21 November to the Confederation of British Industry, Prime Minister Theresa May declared that her government would \u201ccommit to substantial real terms increases in government investment in R&D \u2014 investing an extra \u00a32 billion a year by the end of this Parliament to help put post-Brexit Britain at the cutting edge of science and tech\u201d. May said that some of the investment would be made through a new Industrial Strategy Challenge Fund, which, she added in an article for the  Financial Times , would be used to back R&D in technologies such as robotics, artificial intelligence and industrial biotechnology. \"I'm impressed. The Prime Minister's commitment to make our strength in science and innovation the cornerstone of the UK's future couldn't be clearer,\u201d said Sarah Main, the director of the London-based Campaign for Science and Engineering. \n             Where will it go? \n           A  government statement  noted that the promised investment would be \u201cworth \u00a32 billion per year by 2020\u201d, a wording that implies that it could be made in the form of subsidies other than direct funding, such as tweaks to the tax credits that companies are offered for performing research-related activities.\u00a0Some researchers, including James Wilsdon, who studies research policy at the University of Sheffield, immediately questioned how much of the investment would take that form. The government says that it currently invests around \u00a36.3 billion directly in R&D (not including separate funding for higher-education institutions) and more than \u00a32 billion in R&D tax credits. But details about the new investment are scarce: government press officers said they could not provide details until after  an annual statement on government spending , to be delivered on 23 November. \n             University fears \n           University researchers also worry whether the investment will cover a  potential loss of research funding after Brexit . They fear that, depending on the terms of the split, less research money will flow to the United Kingdom from the European Union. Science minister Jo Johnson said in a tweet that the money was \u201ccoming to our world class scientists through UKRI\u201d \u2014 referring to UK Research and Innovation, an agency that has not yet been created, but is  expected to unite several now-separate organizations : the UK\u2019s seven public research-grant agencies and an innovation funder called \u2018Innovate UK\u2019, as well as enveloping some higher-education funding. \u201cThis is excellent news for science and innovation, with substantial new money for UKRI. As I understand it, UKRI will have considerable discretion over how the money will be spent, having regard for priority areas,\u201d said John Krebs, a zoologist at the University of Oxford, and president of the British Science Association, in a statement issued by the London-based Science Media Centre (SMC). Researchers are now waiting for the 23 November statement for further details about the investment. But the news has alleviated some post-Brexit gloom. \u201cI would broadly welcome Theresa May\u2019s announcement today, though clearly the devil will be in the detail,\u201d says Stephen Curry, a biologist at Imperial College London, in another SMC-issued statement. \n                   UK politicians demand Brexit guarantee for EU scientists 2016-Nov-18 \n                 \n                   Brexit chancellor\u2019s annual address is a science nail-biter 2016-Nov-09 \n                 \n                   Wanted: UK science czar. Generous compensation. Not for the faint-hearted. 2016-Sep-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20997", "url": "https://www.nature.com/articles/nature.2016.20997", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Project to sequence the DNA of more than 1,000 species seeks to reveal how bats learn to communicate. San Diego, California Some bats sing or call just as birds and humans do. But how they learn their calls and melodies is a mystery \u2014 one that scientists will try to solve by sequencing the genomes of more than 1,000 bat species.The project, called Bat 1K, was announced on 14 November at the annual meeting of the Society for Neuroscience in San Diego, California. Its organizers also hope to learn more about the flying mammals\u2019  ability to navigate in the dark  through echolocation, their strong immune systems that can shrug off Ebola and their relatively long lifespans.\u201cThe genomes of all these other species, like birds and mice, are well-understood,\u201d says Sonja Vernes, a neurogeneticist at the Max Planck Institute for Psycholinguistics in Nijmegen, the Netherlands, and co-director of the project. \u201cBut we don\u2019t know anything about bat genes yet.\u201d Some bats show babbling behaviour, including barks, chatter, screeches, whistles and trills, says Mirjam Kn\u00f6rnschild, a behavioural ecologist at Free University Berlin, Germany. Young bats learn the songs and other sounds from older male tutors. They use these sounds during courtship and mating, when they retrieve food and as they defend their territory against rivals. Scientists have studied the vocal sounds of only about 50 bat species so far, Kn\u00f6rnschild says, and they know much less about bat communication than about birds\u2019. Four species of bats have so far been found to learn vocal sounds from each other, their fathers and other adult males,  just as a child gradually learns how to speak  from its parents 1 . The four species are: the greater sac-winged bats ( Saccopteryx bilineata ), the Egyptian fruit bat ( Rousettus aegyptiacus ), the pale spear-nosed bat ( Phyllostomus discolor ) and the greater spear-nosed bat ( Phyllostomus hastatus ). The bats exhibit diversity in their geographic locations, gender and age of vocalizing and frequency and types of sounds. \n               Winged singers \n             Genetic studies have identified at least one gene in bats that is linked to speech and language,  called  FOXP2 2 . The gene is also known to have a role in how people learn language, and in vocal learning in songbirds. The versions of  FOXP2  found in these species are often very similar, but bats are an exception.  FOXP2  seems to have evolved to be much more diverse in bats than in people, Kn\u00f6rnschild says. The reason why is a mystery. Researchers working on the Bat 1K project expect to find that other genes are also involved in communication, and that many more bat species have the ability to learn songs, calls or other sounds. \u201cIt's not a rare trait,\u201d Kn\u00f6rnschild says. \u201cI'm becoming convinced that there\u2019s a whole continuum in bat vocal learning, and it\u2019s more widespread than just four species.\u201dBats\u2019 echolocation ability has been studied for many years, partly because of its applications to sonar and radar. But scientists know very little about the acoustic communication and social behaviour that drive how bats learn their songs and sounds, says Michael Yartsev, a neurobiologist at University of California, Berkeley. The study of vocal learning in bats is \u201cnearly completely untapped\u201d, he says \u2014 likening it to the state of research into birdsong 60 years ago.Songbirds have been studied in detail,  especially the zebra finch  ( Taeniopygia guttata ), which is easy to breed in a lab, says Tecumseh Fitch, a cognitive biologist at the University of Vienna. But birds don\u2019t have a mammalian brain or use a larynx to make sounds. Some mammals, including elephants, whales, pinnipeds and dolphins, display vocal learning, but bats are much more practical to study. \u201cMy hope is that bats will become the model species for vocal learning,\u201d Fitch says. \n                     The woman who sees like a bat 2015-Jan-13 \n                   \n                     'Bat-nav' system enables three-dimensional manoeuvres 2014-Dec-04 \n                   \n                     Babies learn to babble like birds learn to sing 2013-May-29 \n                   \n                     Bats adjust squeaks to focus sonar 2012-Nov-21 \n                   \n                     'Language gene' speeds learning 2011-Nov-18 \n                   \n                     Bat 1K genome-sequencing consortium \n                   Reprints and Permissions"},
{"file_id": "539476a", "url": "https://www.nature.com/articles/539476a", "year": 2016, "authors": [{"name": "Heidi Ledford"}, {"name": "Sara Reardon"}, {"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Worries include job prospects, discrimination \u2014 and safety. As the US presidential election results rolled in, Naglaa Shoukry watched a door slam shut. An immunologist at the University of Montreal in Canada, she had been contemplating a move to the United States in search of better research funding. But when  Donald Trump clinched the presidency , she knew that she would probably not go. Shoukry, a Muslim from Egypt, did postdoctoral research in Ohio and was there when the United States tightened security after the terrorist attacks of 11 September 2001. When Trump pledged to use \u201cextreme vetting\u201d to determine which immigrants could enter the country, Shoukry recalled the hum\u00adiliations her family experienced when travel\u00adling to see her in Ohio. \u201cYou have an interesting name,\u201d a US border official once told her brother, Mohamed, before detaining him for extra security checks. Under\u00a0Trump, Shoukry\u00a0decided, it would surely be worse. Shoukry is not the only scientist shaken by the result of the 8 November election, nor is she alone in reconsidering whether to work or study in the United States. Trump\u2019s campaign rhetoric was at times insulting to women,  immigrants  and under-represented minorities, and there are signs that his victory has further inflamed racial tensions. The Southern Poverty Law Center, a civil-rights advocacy group in Montgomery, Alabama, collected 437\u00a0reports of intimidation and harassment in the five days after the election \u2014 many of which explicitly referenced president-elect Trump. Fifteen per cent of the incidents reported to the centre took place at universities. Such events have led several universities and scientific societies to re\u00adaffirm their commitment to diversity. \u201cTake concrete steps to protect and advocate for colleagues and students who are particularly vulnerable right now,\u201d urges a letter signed by ten astronomers on the Astronomy in Color blog, which advocates for diversity in the field. \u201cWe must reiterate how absolutely essential it is\u00a0to the core values of our community, and also to the well-being of our society and world, that all persons be treated with the dignity and respect they deserve,\u201d wrote Amy Gutmann, president of the University of Pennsylvania in Philadelphia, when black undergraduates there\u00a0received racist e-mails after the election. \u201cWe all stand together in solidarity with our Black students.\u201d Still, scientists around the country have reported harassment. M\u00f3nica Feli\u00fa-M\u00f3jer, a science communicator originally from Puerto Rico, is nervous about speaking Spanish in some public places after hearing a passer-by shout \u201cBuild that wall!\u201d \u2014 referencing  Trump\u2019s plan to build a wall along the US\u2013Mexico \u00adborder . The 12 November incident took place in San Diego, California, where Feli\u00fa-M\u00f3jer was attending the Society for Neuroscience annual meeting. Patrick Freeman, an ecologist at the Carnegie Institution for Science in Stanford, California, was out driving on the day after the election when a person in a truck with a Trump bumper sticker started honking at him \u2014 \u00adperhaps because Freeman\u2019s car sports a sticker in support of Trump\u2019s Democratic opponent, Hillary Clinton, and of lesbian, gay,\u00a0bisexual, transgender and queer people. The truck driver pulled up alongside Freeman and repeatedly pantomimed shooting him before speeding away. For some scientists, the post-election \u00adatmosphere has been stifling. Nicole Cabrera Salazar, an astronomy graduate student at Georgia State University in Atlanta who was born in Chile, says she is mindful that her field is dominated by white males \u2014 and that 63% of white males who voted supported Trump. Cabrera Salazar was once outspoken in support of marginalized students, but she has begun to hold back for fear of a backlash. \u201cIt\u2019s a toxic environment for women of colour,\u201d she says. Some foreign researchers even question whether to travel to the United States for conferences. Shaaban Mousa, an anaesthesiologist at Charit\u00e9 University Hospital in Berlin, comes to the Society for Neuroscience meeting every year, but considered skipping it this year because of the election result. \u201cI was not relaxed,\u201d he said last week at the meeting. \u201cI came because I have my ticket.\u201d And Razi Nalim, an engineer at Indiana University-Purdue University in Indianapolis, worries that he\u2019ll have difficulty recruiting Muslim students and postdocs to work in his department. About 2% of scientists in the United States are Muslim immigrants, according to a survey of biologists and physicists led by Elaine Howard Ecklund, a sociologist at Rice University in Houston, Texas. And 64% of them say they have experienced religious discrimination \u2014 a higher proportion than for any other racial or religious group in Ecklund\u2019s study. The US Federal Bureau of Investigation\u2019s annual hate-crimes report suggests that number may grow: hate crimes against Muslims in the United States climbed by 67% last year. But several Muslim scientists contacted by  Nature  still feel comfortable in the United States. Some, such as a husband and wife studying neuroscience at the Medical University of South Carolina in Charleston,  were pleased to see Trump win . \u201cIt's a good change for the US,\u201d says the husband, who asked not to be named over concerns about his career. He and his wife say they have never experienced racism or Islamophobia during their time in South \u00adCarolina \u2014 a state where Trump won 55% of the vote \u2014 and they have been shocked by mass e-mails from their professors calling Trump supporters \u00adracist and hateful. Shoukry says that some of her Muslim \u00adcolleagues in the United States are troubled by the thought of raising children in an increasingly hostile environment. Islam Hussein, an Egyptian virologist who is a research scientist at the Massachusetts Institute of Technology in Cambridge, says his children were nervous about going to school the day after the election. But after a decade in the United States, Hussein wants to stay. His family has always felt welcome, he says, and his wife, who wears a hijab, has a flourishing career as a pre-school teacher. After the election, friends rushed to offer the family support. \u201cThis is the spirit of America that we should all keep embracing,\u201d Hussein told  Nature  on 14 November. The next day, Hussein contacted  Nature  again: his wife had just been accosted at their local pharmacy. \u201cWhy are you still here?\u201d a man shrieked at her, then hopped into his car and fled. \u201cI think he meant: \u2018Why are you still here after Trump\u2019s election?\u2019,\u201d says Hussein. \u201cThis is the first explicit act of discrimination we have encountered in ten years.\u201d Additional reporting by Erika Check Hayden. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Science and innovation policies for Donald Trump 2016-Nov-15 \n                   \n                     What scientists should focus on \u2014 and fear \u2014 under Trump 2016-Nov-11 \n                   \n                     The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                   \n                     Donald Trump's US election win stuns scientists 2016-Nov-09 \n                   \n                     The scientists who support Donald Trump 2016-Oct-18 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     Nature  special: Science and the US election \n                   \n                     Donald Trump\u2019s immigration policies \n                   Reprints and Permissions"},
{"file_id": "539475a", "url": "https://www.nature.com/articles/539475a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "SESAME project is set to revolutionize science in the region but is strapped for cash. The Middle East\u2019s first major international research centre has weathered political unrest, international sanctions and even the  assassination of two delegates . Now, the Synchrotron-light for Experimental Science and Applications in the Middle East, or SESAME, is on the brink of circulating its first subatomic particles. The machine, which lies outside Amman, Jordan, will start accelerating electrons around its 133-metre ring in December and begin using the resulting beams of intense radiation to do science from May 2017. Strapped for cash, SESAME will initially operate at half its planned capacity. But its location in the Middle East means that it will make a significant contribution to science. \u201cIt will set the stage for a culture of state-of-the-art technology and science in our region,\u201d says director Khaled Toukan. SESAME is a collaboration between Bahrain, Cyprus, Egypt, Iran, Israel, Jordan, Pakistan, the Palestinian Authority and Turkey. Created under the auspices of the United Nations Educational, Scientific and Cultural Organization (UNESCO), it has also received funding from other countries and from the European Union. The machine will generate light in a range of wavelengths and then channel it into intense \u2018beamlines\u2019 of specific frequencies (see \u2018Open SESAME\u2019). These can be used to reveal the structure of materials, biological samples and artefacts down to the atomic scale. SESAME has space for 24 beamlines. The plan was initially to open with four of the slots filled, but a lack of funding means that it will open with just two \u2014 one infrared and one X-ray. \u201cSESAME is in a part of the world where you have very difficult times politically, and a lot of instability, and the money just didn\u2019t come,\u201d says Toukan. Iran couldn\u2019t pay its contribution until January, owing to sanctions that prevented it from transferring money internationally. Cyprus has not paid its share of the running costs since it was hit by a financial crisis in 2011, says Toukan, and Pakistan has paid only half of its dues this year. Jordan and Turkey are the only countries to have paid their annual and capital contributions in full, he says. Politics has touched SESAME, too: two Iranian physicists killed in car-bomb attacks in 2009 and 2010 were members of its council. Still, engineers are expected to have finished testing the synchrotron by May, and a group of 260 researchers, largely from universities in the Middle East and in fields from pharmacology to physics, will then be able to apply for time on the two beamlines. Toukan hopes that the facility will ease brain drain from the region, boost collaboration between the scientific community and industry and create opportunities for researchers who lack the funds to leave the Middle East. Because of its proximity to many of the world\u2019s archaeological treasures, the facility presents a fresh opportunity for studying the region\u2019s cultural heritage. Jan Gunneweg, an archaeometrist at the Hebrew University of Jerusalem, hopes that scientists will use SESAME to collaborate on understanding their shared history. Many artefacts \u2014 such as Egyptian mummies and delicate papyrus \u2014 are fragile and must be insured at high cost if they are to travel long distances. \u201cIf that material has to go in the air, you destroy it,\u201d says Gunneweg. He wants to use the synchrotron to further his studies of the composition, and therefore origins, of parchments including the Dead Sea Scrolls, the oldest known biblical texts. SESAME cost around US$110 million to build, just one-sixth of the price of the  European Synchrotron Radiation Facility  in Grenoble, France, one of the world\u2019s most advanced synchrotrons. Pared-back ambition helped, but SESAME also relied on parts donated from dismantled European facilities, and was built on land that was given for free. Two more beamlines are due to be installed by the end of 2018. SESAME has secured $2\u00a0million from the Jordanian Scientific Research Fund for its third beam, which will perform protein crystallography. And Toukan is confident that the collaboration will find funds for a fourth beam dedicated to materials science. Beyond these four beams, there is no set schedule for filling the remaining 20 slots. \u201cA few tens of million of dollars could make this dream come true,\u201d says Roy Beck, a biophysicist at Tel Aviv University in Israel and a committee member of the SESAME users\u2019 group. He laments that more nations have not been willing to swallow national differences for the sake of science. Some Gulf countries will not take part because of Israel\u2019s participation, he says, and the  United States has made only a small contribution , which both Beck and Toukan attribute to political considerations. Advocates hope that SESAME will foster peace in the same way that CERN, Europe\u2019s particle-physics laboratory, near Geneva, Switzerland, helped to  heal the wounds of the Second World War  and brought Soviet and Western scientists together at the height of the cold war. But crucial factors in that success were CERN\u2019s communal spaces, where scientists could share a coffee and get to know each other, says Beck. SESAME is scheduled to open without a cafeteria or dedicated accommodation, although a committee is trying to raise US$32,000 in donations to create the former. \u201cI hope people from all round will understand that this is a true chance for people within the Middle East to join hands and talk about things that unite them,\u201d says Beck. See Editorial  page 468 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Middle East X-ray factory is a source of hope 2016-Nov-22 \n                   \n                     Synchrotron sources accelerate 2015-Apr-29 \n                   \n                     Clashing nations back SESAME 2012-Mar-21 \n                   \n                     Synchrotron project weathers Middle-East storm 2011-Feb-03 \n                   \n                     Middle East synchrotron on the lookout for funds 2008-Nov-19 \n                   \n                     SESAME \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21020", "url": "https://www.nature.com/articles/nature.2016.21020", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Applying electrical currents to mouse skulls suggests method to activate remote regions in the brain without the need for surgery. San Diego, California A  new technique  might allow researchers and clinicians to stimulate deep regions of the brain, such as those involved in memory and emotion, without opening up a patient\u2019s skull. \u2028\u2028 Brain-stimulation techniques that apply electrodes to a person\u2019s scalp seem to be safe, and proponents say that the method  can improve some brain functions,  including enhancing intelligence and relieving depression. Some of these claims are much better supported by research than others. But such techniques are limited because they cannot reach deep regions of the brain. By contrast, implants used in deep brain stimulation (DBS) are much more successful at altering the inner brain. The devices can be risky, however, because they involve surgery, and the implants cannot be repaired easily if they malfunction. \u2028 At the annual Society for Neuroscience conference, held in San Diego, California, last week, neuroengineer Nir Grossman of the Massachusetts Institute of Technology in Cambridge and his colleagues presented their experimental method that adapts  transcranial stimulation  (TCS) for the deep brain. Their approach involves sending electrical signals through the brain from electrodes placed on the scalp and manipulating the electrical currents in a way that negates the need for surgery. The team used a stimulation device to apply two electric currents to the mouse's skull behind its ears and tuned them to slightly different high frequencies. They angled these two independent currents so that they intersected with each other at the hippocampus. The brain\u2019s neurons respond to low frequencies, and so these high-frequency currents passed through the tissue without affecting it. But at the point where the currents crossed, they mostly cancelled each other out. The remaining difference between the two frequencies created what the neurons interpreted as a single, low-frequency field, which triggered them to fire in response. When the researchers dissected the animals' brains, they found that cells in the hippocampus had fired, whereas the cells in outer parts of the brain had not. \u2028 \n             Human test phase \n           The team is now testing the technique in human volunteers, says Alvaro Pascual-Leone, a neurologist at Harvard Medical School in Boston, Massachusetts, who is collaborating with Grossman. While each volunteer lies in a brain scanner, the researchers can measure how brain activity in his or her hippocampus changes in response to TCS in real time. But they have not yet tested whether this stimulation can affect behaviour, for example, by  improving performance on memory tests . Grossman says that the technique still requires a lot of fine-tuning and testing. In particular, the electrical field is imprecise and seems to have stimulated large portions of the hippocampus in the rats. Angel Peterchev, a neuroengineer at Duke University in Durham, North Carolina, is sceptical of the technique. He points to some evidence suggesting that the frequencies used by the researchers in their study might still be too low to pass cleanly through the brain and could cause some off-target effects 1 . \u2028\u201cIt\u2019s a slow road,\u201d says Joel Voss, a neuroscientist at Northwestern University\u2019s Feinberg School of Medicine in Chicago, Illinois. His group is using a similar method called transcranial magnetic stimulation (TMS) to activate neurons on the brain\u2019s surface and direct them so that the signal propagates along neuronal tracts until it reaches deep regions. By targeting the hippocampus in this way, they have been able to temporarily improve memory in healthy volunteers 2 . \n             Filling a need \n           Voss says that he dislikes TCS as a method because it is not always reliable, but is glad that people are working on ways to stimulate the deep brain that do not involve implants or surgery. \"I think there\u2019s a huge need for things like this,\u201d he says. \u2028\u2028 Pascual-Leone acknowledges the concerns, and says that the group is looking to improve the technique\u2019s precision by altering the frequencies or priming specific cell types with drugs so that they will be more responsive to stimulation. \u201cI find it very exciting because of its potential,\u201d he says. But the neurologist also realizes that the technique has yet to deliver on its promise. Still, psychiatrist Helen Mayberg of Emory University in Atlanta, Georgia, doubts that transcranial methods will replace implants any time soon, especially because DBS works well as a therapy for many people. \u201cAt this moment in time, we are at a point in the trajectory where we have something we can offer patients,\u201d she says. Ten years from now, she says, doctors hopefully won\u2019t have to resort to such invasive options. \n                   Memory-boosting devices tested in humans 2015-Nov-03 \n                 \n                   Brain stimulation in children spurs hope \u2014 and concern 2015-Sep-23 \n                 \n                   Neuroscience: Brain buzz 2011-Apr-13 \n                 \n                   Society for Neuroscience annual meeting\u2028 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21038", "url": "https://www.nature.com/articles/nature.2016.21038", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Cash to include fund modelled on DARPA, the US defence department\u2019s research arm \u2014 but how much will go to basic research is unclear. British scientists are not used to hearing about large increases in national research spending. So when Prime Minister Theresa May promised on 21 November that her government would invest an extra \u00a32 billion (US$2.5 billion) per year in research and development (R&D) by 2020,  scientists gave the speech a cautious welcome . But the funding hike seems to be no financial sleight of hand, according to  UK Treasury documents  released on 23 November after Chancellor of the Exchequer Philip Hammond gave an address on the nation\u2019s finances. The government is expecting to spend an extra \u00a34.7 billion on R&D between now and 2020\u201321, it says, and the final year\u2019s \u00a32-billion boost will represent a rise of around 20% in total government R&D spending. \u201cIt seems that this is genuinely new money, which is fantastic news,\u201d says James Wilsdon, who studies research policy at the University of Sheffield, UK. Still, it remains unclear how the cash will be allocated, and how much will make its way to funding basic, blue-skies research. \u201cIt is a real boost to see UK strength in science being championed by the prime minister and backed with what is the most significant investment in R&D I can remember,\u201d says Sarah Main, director of the London-based Campaign for Science and Engineering. \n               Industrial challenges \n             Some of the money will go directly to applied R&D through a new Industrial Strategy Challenge Fund, modelled on the US Defense Advanced Research Projects Agency (DARPA), the Pentagon\u2019s high-risk research arm. That fund will be aimed at supporting cross-disciplinary \u201ccollaborations between business and the UK\u2019s science base\u201d, according to Treasury documents, and will \u201cset identifiable challenges for UK researchers to tackle\u201d. It will be managed by Innovate UK, a government body that funds R&D primarily through businesses, and by the seven UK research councils, agencies that mainly fund university research. The money will be allocated according to an \u201cevidence-based process\u201d, the Treasury says. Other cash will go towards \u201cinnovation, applied science and research\u201d. Although the Treasury was vague on what exactly this entailed, it said that the extra funding would be used \u201cto increase research capacity and business innovation, to further support the UK\u2019s world-leading research base and to unlock its full potential\u201d. UK Research and Innovation (UKRI) \u2014 an agency that has not yet been created, but is  expected to unite the research councils and Innovate UK  \u2014 will award the funding on the basis of \u201cnational excellence\u201d, with grant funding through Innovate UK getting a \u201csubstantial increase\u201d, said the Treasury. The documents make no clear reference to spending any of the new cash on basic research, but Main says she would be surprised if it was excluded. \u201cI think it will be really important that this funding goes to both blue-skies and challenge-driven research. It is clear from the document that there is money there just to increase the UK\u2019s research capacity, and that this money is going to be channelled through UKRI. It will be important for UKRI to consider the balance of how that money is distributed,\" she says. Funding will begin to ramp up next year, when the government plans to spend an extra \u00a3425 million compared with 2016\u201317, followed by an additional \u00a3820 million in 2018\u201319, \u00a31.5 billion in 2019\u201320 and \u00a32 billion in 2020\u201321. The government said that it also plans to review the nation\u2019s R&D tax-credit system; a Treasury spokesperson confirmed that any changes, which could provide tax breaks for companies carrying out R&D, would not count towards the extra funding. \n               Brexit ahead \n             Scientists had been  eagerly awaiting the speech, known as the Autumn Statement , hoping that it would signal the new government\u2019s approach to science. The budget was dominated by forecasts of the country\u2019s slowed economic growth as a result of Brexit, its forthcoming exit from the European Union. But research and innovation also took top billing, with Hammond beginning the announcement of a string of new investments by reiterating the \u00a32-billion pledge. \u201cWe do not invest enough in research, development and innovation,\u201d he said. \u201cAs the pace of technology advances and competition from the rest of the world increases, we must build on our strengths in science and tech innovation to ensure the next generation of discoveries is made, developed and produced in Britain.\u201d Scientists were also pleased with an infrastructure announcement: a new direct rail link between Oxford and Cambridge, which researchers shuttling between universities in the two cities have been wanting for decades. Hammond called it a \u201ctransformational tech-corridor drawing on the world-class strengths of our two best-known universities\u201d. But what was \u201csorely missing\u201d from the statement was any reference to the impact on science from Brexit, says Stephen Curry, a structural biologist at Imperial College London and a member of the advisory board for the campaign group Science is Vital. \u201cI\u2019d like to know how the loss of EU funding will impact decisions on allocation of the new investments announced today.\u201d Hammond\u2019s opposition counterpart, Labour Party shadow chancellor John McDonnell, responded to his speech by saying that the rise in R&D funding was not enough: it would lift the proportion of UK gross domestic product spent on R&D from 1.7% to only 1.8%, whereas the Organisation for Economic Co-operation and Development recommends that developed countries should be spending 3%. \n                     Cautious welcome for UK government's vague \u00a32-billion research pledge 2016-Nov-21 \n                   \n                     UK politicians demand Brexit guarantee for EU scientists 2016-Nov-18 \n                   \n                     Brexit chancellor\u2019s annual address is a science nail-biter 2016-Nov-09 \n                   \n                     Brexit government\u2019s anti-immigration stance spooks UK scientists 2016-Oct-06 \n                   \n                     UK government gives Brexit science funding guarantee 2016-Aug-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21023", "url": "https://www.nature.com/articles/nature.2016.21023", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "String of publications describes attempts \u2014 mostly unsuccessful \u2014 to use proposed CRISPR rival. A heated dispute over gene-editing that began in blogs and social media is now playing out in the scientific literature. Six months ago, Chinese researchers reported that an enzyme called NgAgo could be used to edit mammalian genes \u2014 and that it might be more accurate and more versatile than the popular CRISPR\u2013Cas9 gene-editing technique 1 . But almost immediately, other scientists complained that they  could not replicate the experiment . Now, a paper with 20 authors, published in  Protein & Cell 2 , lists multiple attempts that failed to replicate the original experiment \u2014 and another, published in  Cell Research 3 , suggests that NgAgo may only block, but not edit, genes when it is injected into zebrafish ( Danio rerio ) embryos. Nature Biotechnology , which published the first NgAgo paper 1 , has also published a report of three failed attempts to replicate the original experiment 4  and an \u2018 expression of concern \u2019 to accompany the original paper. \u201cWe are in contact with the authors, who are investigating potential causes for the lack of reproducibility,\u201d writes  Nature Biotechnology . Han Chunyu, a biologist at Hebei University of Science and Technology in Shijiazhuang and the lead author on the original NgAgo paper, says that he stands by his team\u2019s original claims, and that the latest  Nature Biotechnology  report \u201cprovides us some clues as to why others are having problems\u201d. He says that he hopes to submit a scientific paper explaining why others are having difficulty by the end of the year. Nature Biotechnology  says that it will give Han\u2019s team the opportunity to investigate and respond to the criticisms in the latest report by January 2017. \u201cAn update will be provided to the community at that time,\u201d said a spokesperson.  Nature Biotechnology  is editorially independent of  Nature \u2019s news team and is owned by  Nature \u2019s publisher, Springer Nature. \n               Biomedical storm \n             Gene-editing techniques that precisely disable or modify very specific sections of a genome have taken the biomedical world by storm. The technique described by Han\u2019s team is one of several  proposed alternatives  to the  most popular one, CRISPR\u2013Cas9 .\u00a0 The 20 authors of the  Protein & Cell  paper 2  describe how they attempted without success to use NgAgo to edit a variety of genomes. Eight of the labs then tried again, adhering as closely as possible to Han\u2019s experiment, using genetic materials provided by Han, targeting the same genes and also applying the technique to human cells. They all failed. The paper urges Han\u2019s team to \u201cclarify the uncertainty surrounding NgAgo and provide all the necessary details for replicating the initial, very important results\u201d. But one of the authors, Wensheng Wei, a molecular biologist at Peking University, has already made his mind up about NgAgo. \u201cIt simply doesn't work, period,\u201d he says. Zhang Xiaoxue, managing editor at  Protein & Cell  in Beijing, China \u2014 which  also published  the  first report of gene-editing in human embryos in 2015  \u2014 says that the journal made an effort to publish the NgAgo paper quickly because of the ongoing debate over the work. \u201cIn China, it\u2019s not just a scientific issue. It\u2019s also an ethical and political issue,\u201d she says. The failed replications described in  Nature Biotechnology 4  were carried out by three more groups; all also used genetic materials provided by Han, targeted the same genes and applied the technique to human cells. \n               Cyclops eyes \n             In the  Cell Research  paper 3 , researchers report an attempt to use NgAgo to edit a gene thought to be related to eye development in zebrafish embryos. Some of the embryos developed either one very small eye and one largely normal eye, or eyes that were fused and that formed, according to the paper, on the top of the head \u201clike a cyclops\u201d, as one would expect if NgAgo had knocked out the gene. But when the researchers sequenced the genomes of the fish, they found to their surprise that the gene was still intact.\u00a0 The lead author, Liu Dong, a molecular biologist at Nantong University in China, offers an explanation: the NgAgo molecules clamp onto the genome, but instead of cutting the target gene, just reduce its expression. Because the NgAgo protein can be easily prepared in the laboratory, Liu says that this capability could make it a cheaper, more accessible alternative to current methods of temporarily blocking gene function in zebrafish.\u00a0But if he is right, then NgAgo would not make permanent changes that are passed on to the next generation and would therefore not be considered a gene editor. Liu offers little insight into the controversy over the original NgAgo experiments, which he notes were done in human cells  in vitro . Rather, he says, it raises the possibility of a new use for NgAgo, as a cheap tool to block but not edit genes. But critics say Liu\u2019s paper is further evidence that the claims in the original NgAgo paper 1  don\u2019t stand up. \u201cThis is another report, now published in a peer-reviewed journal, confirming that NgAgo does not work as gene editor,\u201d says Lluis Montoliu, a geneticist at the Spanish National Centre for Biotechnology in Madrid, who has  previously criticized the Han paper . \u201cThis needs to be highlighted.\u201d \n               Too hot? \n             Gaetan Burgio, a geneticist at the Australian National University in Canberra and  one of the first to post online a failed attempt to replicate\u2019s Han\u2019s experiments , says he doesn\u2019t think that NgAgo can function at the temperatures used in either Han\u2019s or Liu\u2019s experiment. Both were carried out at much cooler temperatures than the environment in which the protein\u2019s source \u2014 a bacterium \u2014 lives. Burgio thinks the zebrafish abnormalities might have formed because of a toxicity unrelated to the activity of NgAgo. Liu says his data convince him that NgAgo can reliably block genes, but acknowledges that he needs more evidence to show this conclusively. He says he is working on assembling that now. Han told  Nature  that he has discovered a problem that would not have been obvious to others and that could explain why others are having difficulty replicating his results. He says that he is currently running confirmatory experiments so that he can publish data and a protocol that satisfy his critics.\u00a0\u201cI cannot say right now because the media in China jumps on everything I say,\u201d he told  Nature . \u201cI need a little bit of time.\u201d Last week, in response to the NgAgo papers in  Protein & Cell 2  and  Cell Research 3 , a spokesperson for  Nature Biotechnology  said that it had been contacted by a number of individuals and groups critical of Han\u2019s NgAgo paper, and that it had considered or was considering them carefully, alongside any published critiques of the research. \u201cOur investigations into the paper are continuing at this time,\u201d said the spokesperson. Following the publications in the journal on 28 November, a spokesperson told  Nature  that the journal has now carefully considered all comments relating to the original paper. \n               NgAgo in action \n             One of the few scientists who previously told  Nature  that he had corroborated Han\u2019s findings \u2014 but has not published these results \u2014 now says that he is using NgAgo for experiments related to his research, and that he hopes to publish soon. But another who previously noted positive initial results with NgAgo says now that the \u201cdata are confusing\u201d and \u201cwe cannot make a conclusion\u201d. Neither wanted to be named for fear of being dragged into the controversy. The debacle has raised questions about a 224-million-yuan (US$32-million) gene-editing centre that Han\u2019s university \u2014 Hebei University of Science and Technology \u2014 announced in August that it would build, to be paid for with local government money. \u201cWithout Han's  Nature Biotechnology  paper and the hype after that, it's impossible for the school to get such huge funding to establish the gene-editing research centre,\u201d says Fang Shimin, a former biochemist who has\u00a0 become famous for exposing fraudulent scientists . He was one of the first to publicize criticism of Han\u2019s paper. He says that aside from Han\u2019s NgAgo claims, the university lacks gene-editing expertise. So if Han's work doesn't stand up, \u201cthe centre will lose its legitimacy\u201d. Wei too is critical of the decision to build the gene-editing centre, which he also attributes to the excitement over Han's paper. \u201cIt\u2019s not a bad idea to have one in China considering that it is such a hot area,\u201d he says, \u201cbut the only reason such centre is built in Hebei is because of Han\u2019s publication.\u201d The university has declined requests from  Nature 's news team to discuss the centre. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Beyond CRISPR: A guide to the many other ways to edit a genome 2016-Aug-08 \n                   \n                     Replications, ridicule and a recluse: the controversy over NgAgo gene-editing intensifies 2016-Aug-08 \n                   \n                     CRISPR, the disruptor 2015-Jun-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21045", "url": "https://www.nature.com/articles/nature.2016.21045", "year": 2016, "authors": [{"name": "Alison Abbott"}, {"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "The drug, and others based on the \u2018amyloid hypothesis\u2019, are still being tested in other, different trials. A drug that was  seen as a major test of the leading theory behind Alzheimer\u2019s disease  has failed in a large trial of people with mild dementia. Critics of the \u2018amyloid hypothesis\u2019, which posits that the disease is triggered by a build-up of amyloid protein in the brain, have seized on the results as evidence of its weakness. But the jury is still out on whether the theory will eventually yield a treatment. Proponents of the theory note that the particular way in which solanezumab, the drug involved in the trial, works could have led to the failure, rather than a flaw in the hypothesis itself. And many trials are ongoing to test whether solanezumab \u2014 or others that target amyloid \u2014 could work in people at risk of the disease who have not yet shown symptoms, or even in people with Alzheimer\u2019s, despite the latest negative result. \u201cI\u2019m extremely disappointed for patients, but this, for me, doesn\u2019t change the way I think about the amyloid hypothesis,\u201d\u00a0says Reisa Sperling, a neurologist at the Brigham and Women\u2019s Hospital in Boston, Massachusetts. She is leading one of several ongoing \u2018prevention\u2019 trials that is testing solanezumab, and other drugs that aim to reduce the build-up of amyloid \u2018plaques\u2019, in people at risk of developing Alzheimer\u2019s. \n               Blood protein \n             Solanezumab is an antibody that mops up amyloid proteins from the blood and cerebrospinal fluid. The proteins can go on to form plaques in the brain. Eli Lilly, the company that developed solanezumab, announced on 23 November that it would abandon the drug as a treatment for patients with mild dementia. The outcome adds to a long list of promising Alzheimer\u2019s drugs that have flopped in the clinic, many of which, like solanezumab, targeted amyloid. The Lilly trial, known as EXPEDITION3, involved more than 2,100 people diagnosed with mild dementia due to Alzheimer\u2019s disease. Half received monthly infusions of solanezumab and the other half a placebo. They were followed for 18 months and tested in a range of cognitive tasks. Analysis of people with comparable symptoms in earlier studies of solanezumab had  seemed encouraging , but this latest trial indicated only small benefit, not enough to warrant marketing the drug. \u201cWe are disappointed for the millions of people waiting for a potential disease-modifying treatment for Alzheimer\u2019s disease,\u201d said Lilly\u2019s chief executive, John Lechleiter, in a statement. At a press conference, the company said that it had spent around US$3 billion on Alzheimer\u2019s research and development in the past 27 years. \n               Prevention hope \n             Lilly has also been running prevention trials to see whether solanezumab might help people at especially high risk of the disease. The company says it will now discuss with its trial partners whether to continue with those. Sperling\u2019s trial is one of these, and tests solanezumab in people who have elevated amyloid levels in the brain but have not shown any symptoms of dementia. \u201cAn amyloid therapy has to be started before there\u2019s significant neuronal loss,\u201d she says. Researchers at Washington University in St Louis, Missouri, are also trialling solanezumab, and another similar antibody made by drug company Roche, in people who are currently healthy but are genetically at high risk of developing Alzheimer\u2019s. Meanwhile, the Banner Alzheimer\u2019s Institute in Phoenix, Arizona, is testing the effects of three therapies that target amyloid production, one of which is an antibody, in people at high genetic risk of Alzheimer\u2019s. The Lilly outcome \u201cdoesn\u2019t disprove the amyloid hypothesis, and it really increases the importance of these longer prevention trials\u201d,\u00a0says Eric Reiman, the institute\u2019s executive director and leader of the trials. The latest negative finding, he says, \u201cbegs the question: Were we too little too late? And we\u2019ll see.\u201d\u00a0 \n               Blood trap \n             Lilly\u2019s result may say more about the characteristics of solanezumab than the accuracy of the underlying amyloid hypothesis, says Christian Haass, head of the Munich branch of the German Centre for Neurodegenerative Diseases. The antibody targets soluble forms of amyloid, he points out, so it \u201ccould be trapped in the blood without ever reaching the actual target in the brain in sufficient quantities\u201d. Biogen, a company based in Cambridge, Massachusetts, is testing a different antibody called aducanumab, which targets amyloid plaques in the brain. In early clinical testing, the antibody  showed signs of clearing amyloid and alleviating memory loss  in people with mild Alzheimer's disease; results from phase III trials are expected in 2020. \u201cUntil the aducanumab data read out, we have not truly put amyloid to the test,\u201d says Josh Schimmer, a biotechnology analyst at Piper Jaffray in New York City. Still, the negative trial findings have emboldened critics of the amyloid theory, who are weary of its failure to yield a treatment. \u201cThe amyloid hypothesis is dead,\u201d says George Perry, a neuroscientist at the University of Texas at San Antonio. \u201cIt\u2019s a very simplistic hypothesis that was reasonable to propose 25 years ago. It is not a reasonable hypothesis any longer.\u201d \u201cWe\u2019re flogging a dead horse,\u201d adds Peter Davies, an Alzheimer\u2019s researcher at the Feinstein Institute for Medical Research in Manhasset, New York. \u201cThere\u2019s no sign of anybody getting better, even for a short period, and that suggests to me that you have the wrong mechanism.\u201d Regardless of what Lilly decides about its other solanezumab trials, the company isn\u2019t giving up on Alzheimer\u2019s. In partnership with AstraZeneca, it is testing an inhibitor of an enzyme involved in the synthesis of amyloid, and is progressing with a handful of early-stage therapies aimed at other Alzheimer\u2019s targets. \n                     How to defeat dementia 2016-Nov-09 \n                   \n                     The red-hot debate about transmissible Alzheimer's 2016-Mar-16 \n                   \n                     Antibody drugs for Alzheimer\u2019s show glimmers of promise 2015-Jul-22 \n                   \n                     Neuroscience: The plaque plan 2008-Nov-12 \n                   \n                     Nature Outlook: Ageing\u00a0 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21037", "url": "https://www.nature.com/articles/nature.2016.21037", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Modified bacterial enzyme taught to make bonds that evolution avoids. Silicon is all around us: after oxygen, it is the most abundant element in Earth\u2019s crust. So why living beings never incorporate it into their biochemistry has long been a puzzle. Now chemical engineers have discovered that living organisms can be nudged to bind carbon and silicon together. They showed that a natural enzyme from a bacterium that lives in hot springs can form C\u2013Si bonds inside living  Escherichia coli  cells \u2014 when the cells are fed the right silicon-containing compounds. And by engineering the enzyme, the researchers created a biological catalyst that performs the reaction more efficiently than any artificial one. The finding could help chemists to develop new pharmaceuticals and industrial catalysts \u2014 and perhaps explain why evolution has almost completely shunned silicon. \n             No room for silicon? \n           Nature exploits a number of common metals in biochemistry: notable cases include iron in red blood cells and magnesium in chlorophyll. But silicon (an element that has properties both of metals and non-metals) seems to occur only in bioinorganic compounds, such as those in the silica shells of the single-celled algae diatoms. It never makes its way into the carbon-based chains of organic life. \u201cPoor silicon, abundant in the Earth, but rejected by the biosphere for its wondrous evolutionary tinkering,\u201d says Roald Hoffmann, a Nobel-prizewinning chemist at Cornell University in Ithaca, New York. Researchers have learned to bind carbon and silicon together using artificial catalysts. But Frances Arnold, a chemical engineer at the California Institute of Technology in Pasadena, wanted to test whether some of life\u2019s enzymes could do that too, given the opportunity. By scouring protein databases, she and her colleagues found a few dozen promising enzymes. After some screening, they settled on one from an extremophile bacterium that lives in Icelandic underwater hot springs, called  Rhodothermus marinus . They synthesized the gene for this protein and inserted it into  E. coli  bacteria. Their guess turned out to be correct: the enzyme could catalyse silicon\u2013carbon bonding \u2014 if fed the right silicon-containing precursors. (The enzyme would not normally do this, because bacteria don\u2019t naturally produce silicon-containing compounds). \u201cIt\u2019s remarkable that nature is poised to do all sorts of wild things in the presence of this new manmade food,\u201d Arnold says. \n             Efficiency boost \n           Still, the engineered  E. coli  were not very efficient at producing silicon-organic compounds. So the team introduced mutations into the active region of the enzyme and selected the bacteria that showed an improvement. A few generations were sufficient to enhance the yields \u2014 beating those of artificial catalysts.  The results appear in  Science 1  on 24 November. \u201cThe Arnold group paper combines good chemistry and directed evolution to create enzymes that form carbon\u2013silicon bonds in very specific ways,\u201d Hoffmann says. \u201cBeautiful work, creating new chemistry.\" Arnold developed the directed-evolution technique in the 1990s 2  and it is now used in countless applications, from improving laundry detergents to synthesizing medicinal drugs. She won this year\u2019s \u20ac1-million (US$1.1-million)  Millennium Technology Prize for that work . \u201cThis opens up entirely new opportunities in pharmaceutical research and may lead to the discovery of new drugs,\u201d says Yitzhak Apeloig, who specializes in organic chemistry at the Technion Israel Institute of Technology in Haifa. The findings could also help to address basic questions about the early evolution of life, Arnold says, and in particular whether its disdain of silicon was happenstance or not. \u201cWe can start to explore what are the costs and benefits of incorporating silicon into life.\u201d \n                   \u2018Radically rewritten\u2019 bacterial genome unveiled 2016-Aug-18 \n                 \n                   First life with 'alien' DNA 2014-May-07 \n                 \n                   Five hard truths for synthetic biology 2010-Jan-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21064", "url": "https://www.nature.com/articles/nature.2016.21064", "year": 2016, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "Brussels-based advocacy group aimed to provide single voice for scientists in the EU \u2013 but is losing members. Influential research organizations are pulling out of Science Europe, the Brussels-based advocacy group that aims to champion researchers\u2019 interests with European Union policymakers. All but one of France\u2019s research-funding organizations are preparing to leave the group at the end of this year,  Nature  has learned \u2014 including Europe\u2019s largest basic-research agency, the CNRS, which controls an annual budget of \u20ac3.3 billion (US$3.5 billion). Germany\u2019s Helmholtz Association, which runs 18 national research centres, and France\u2019s agricultural research agency (INRA) both left quietly last year. The loss is \u201cdefinitely a blow, and may be a deadly one\u201d, says Peter Tindemans, the secretary-general of EuroScience, a grassroots association of researchers in Europe. He thinks that Science Europe is struggling to balance the different priorities of its members, because some are grant-awarding organizations, whereas others are institutes that primarily perform research. But Science Europe itself is not fazed by the exits, says its president, Michael Matlosz. Science Europe was  formed in 2011  to give the many national research organizations scattered across Europe a stronger, united voice on EU policy. Collectively, these organizations control most of the continent\u2019s basic science funding \u2014 but, individually, it can be hard for them to navigate the Brussels lobbying jungle to influence policymakers.  Science Europe runs events to push scientists\u2019 interests with politicians, and publishes reports on research policy. In October, for example, it released position papers on the EU\u2019s Horizon 2020 funding programme and on open access. At the start of last year, it represented 50 organizations, but by the end of 2016, its membership looks set to have fallen to 43. \n             Struggling to be heard \n           The departing French agencies all declined to comment. But sources familiar with the situation told  Nature  that the organizations filed applications to leave at the end of 2015, to comply with the one-year notice period. Matlosz told  Nature  that the CNRS and France\u2019s atomic energy commission (CEA) are definitely leaving, but that the country's medical research agency, INSERM, and its research institute for development (IRD) haven\u2019t yet confirmed their decision. \u201cScience Europe is a living organization, we have members coming out and in,\u201d he said. \u201cAll members pay an annual fee to be part of our activities, so for many it depends on financial constraints.\u201d Matlosz is also chief executive of the national research agency (ANR), the only French organization that isn\u2019t preparing to leave Science Europe. \u201cWe are very satisfied with it,\u201d says an ANR spokeswoman. The organizations that left last year give differing reasons for their exits. \u201cIn Science Europe, it was very difficult for research organizations to have a voice. At some point, it just ran itself without any involvement of the members,\u201d says a member of staff at INRA who was involved in INRA\u2019s departure but did not want to be named. \u201cAt INRA, we just did not have enough capacity to be in the different work groups, where you have to be strongly involved to be able to give your opinion and influence the organization\u2019s processes.\u201d A price hike triggered the exit of the Helmholtz Association. Science Europe\u2019s annual fee doubled, causing an internal review of costs and benefits, says Annika Thies, director of the association\u2019s Brussels office. \u201cThere were several activities we considered to be positive and useful, but others of less relevance for us,\u201d she says \u2014 although she declined to say what they were. \n             Repeated criticism \n           Science Europe has reconfigured itself a few times since its creation \u2014 causing rearrangements that have brought criticism from its members. Matlosz is its third president in three years. In 2015, the organization decided to form a single advisory committee consisting of 30 researchers from around Europe, ditching its previous structure of six committees. The final minutes of one of these dissolved groups (which provided the viewpoint of engineering and technical sciences) noted members\u2019 regret that \u201cScience Europe does not use the structural importance of its Member Organisations in the European research system to engage more aggressively with the European Commission on policy issues\u201d. The exodus may be a case of history repeating itself. Science Europe was built from two former advocacy groups: the European Science Foundation (ESF) \u2014 a funder of coordinated projects between research funders within and outside the EU \u2014 and EUROHORCS, which represented the heads of the European research councils. In 2011, many research organizations left the ESF in protest after they failed to achieve a two-thirds majority to reform and strengthen their voices. Science Europe was meant to be a response to this shake-up, with the goal of taking over the ESF\u2019s advocacy and lobbying efforts in Brussels. Tindemans thinks that the dissatisfaction in Science Europe may be due in part to the national funding agencies concentrating on lobbying policymakers, instead of also working together to fund joint projects, as they used to do in the ESF. Departees from Science Europe have other bodies that can offer them support and influence in Brussels. The Helmholtz Association, for example, is a member of EARTO, the European association of research and technology organizations. INRA, meanwhile, works closely with COST (European Cooperation in Science and Technology), a network that supports trans-national cooperation between European researchers. Meanwhile, Science Europe is readying itself for a busy 2017, Matlosz says, with a focus on the mid-term review of Horizon 2020 and a planned lobbying push to support basic research in the European Research Area. \u201cWe continue to have a strong consensus on this among members, so we can speak out strongly.\u201d \n                   Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                 \n                   New Science Europe head questions centralized approach to research 2014-Jun-06 \n                 \n                   Policy: A single market for European research 2013-Sep-11 \n                 \n                   Scientists promised 'one voice' in European policy 2011-Aug-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21066", "url": "https://www.nature.com/articles/nature.2016.21066", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Tom Price, Republican congressman from Georgia, has a thin track-record on science and research issues. Republican congressman Tom Price of Georgia is US President-elect Donald Trump\u2019s pick to head the US Department of Health and Human Services. If he is confirmed by the Senate, Price would oversee the National Institutes of Health (NIH), the Centers for Disease Control and Prevention (CDC) and the Food and Drug Administration (FDA). Price, an orthopaedic surgeon who heads the House of Representatives\u2019 budget committee, is a staunch opponent of the Affordable Care Act, the health-care reform law known as Obamacare. Trump has said that repealing the law is one of his top priorities as president. But Price\u2019s stance on biomedical research issues is harder to parse. He has taken few public positions on science, but has consistently pushed to cut overall federal spending. Last year, he voted against  a bill that would overhaul FDA regulations  and provide US$8.75 billion in mandatory funding to the NIH over five years. Price also opposes President Barack Obama\u2019s  proposed $755-million Cancer Moonshot , which seeks to double the pace of cancer research over the next decade. \u201cWe\u2019re all in favour of increasing funding for cancer research,\u201d Price told STAT News in January. \u201cThe problem that the administration has is that they always want to add funding on, they never want to decrease funding somewhere else. That\u2019s what needs to happen.\u201d Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Rockville, Maryland, says that her conversations with Price and his staff suggest that he is at least a \u201cgeneric\u201d supporter of science. \u201cMy impression so far is he understands the NIH,\u201d she says. \u201cThe issue will be convincing him that it\u2019s a good agency to fund.\u201d But Georges Benjamin, executive director of the American Public Health Association in Washington DC, is much more concerned about Trump\u2019s choice of Price. \u201cHe\u2019s a physician \u2014 a very smart guy \u2014 and understands the value of research, but I question his commitment to invest in it,\u201d Benjamin says. \n             Split opinions \n           Benjamin says that Price\u2019s record in public-health policy is particularly worrying. In 2008, for instance, Price voted against allowing the FDA to regulate tobacco as a drug. Price has also pushed to repeal the Public Health and Prevention Fund (PHPF), a roughly $1 billion to $2 billion fund provided yearly to the CDC to support public-health programmes. Owing to past budget cuts, the agency has used this money to bolster spending on existing programmes, such as research on lead toxicity. Price has criticized the PHPF as a \u201cslush fund\u201d, but Benjamin says that it has been essential for the agency. \u201cShould he be confirmed, we\u2019d be working very hard to try and change his mind to convince him that prevention is an important issue he should champion,\u201d he says. And Price has also consistently opposed embryonic stem cell research, saying in 2009 that  Obama\u2019s executive order to permit such research  would \u201cforce taxpayers to subsidize research that will destroy human embryos\u201d. He has also supported numerous efforts to defund the reproductive non-profit healthcare group Planned Parenthood, an effort that intensified after videos produced by an anti-abortion group suggested that Planned Parenthood sold fetal tissue to researchers for profit. Several states have investigated that claim and found no evidence to support it. Kevin Wilson, legislative director at the American Society for Cell Biology in Bethesda, Maryland, worries that both issues could become active again during the Trump administration. Still, Wilson is not discouraged that Trump has picked Price for HHS director. \u201cThe thing about Tom Price that I'm hopeful for \u2014 and I am hopeful \u2014 is that his past experience as an orthopaedist will inform him about the life of a biomedical researcher,\u201d he says.  \n                   Tracking the Trump transition, agency by agency 2016-Nov-30 \n                 \n                   The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                 \n                   Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                 \n                   Scientists worry as cancer moonshots multiply 2016-Apr-27 \n                 \n                   US lawmakers seek to revamp biomedical research 2015-Jan-28 \n                 \n                   Obama overturns stem-cell ban 2009-Mar-09 \n                 \n                   Nature  special: US election 2016 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20960", "url": "https://www.nature.com/articles/nature.2016.20960", "year": 2016, "authors": [{"name": "Katherine Bourzac"}], "parsed_as_year": "2006_or_before", "body": "At a conference in San Francisco, a group drafted proposals to add more planets, instruments and other science icons to the keyboard. Science lovers, rejoice! More emoji designed for the nerd in all of us are on their way. This weekend, at the first-ever Emojicon in San Francisco, California, a group of science enthusiasts and designers worked on proposals for several new science-themed emoji. If these are approved, in a year or two, people could be expressing themselves with a heart\u2013eye emoji wearing safety goggles. On 6 November, the science emoji group submitted a formal proposal to the Unicode Consortium, the organization that oversees the official list of these icons, to include emoji for the other planets \u2014 aside from Earth \u2014 and  Pluto . A second proposal, which the team plans to submit in the coming weeks, includes lab equipment (a beaker, Bunsen burner, fire extinguisher, Petri dish and goggles), a DNA double helix, a microbe, a chemical-element tile for helium, a mole (to represent the unit of measure and the animal) and a water molecule. These would join existing official science-related emoji, such as a microscope, a telescope and a magnifying glass. There\u2019s also an alembic \u2014 a piece of equipment used to distil chemicals \u2014 along with common plants and charismatic megafauna such as pandas. Unofficial sets of science-themed emoji include caricatures of Albert Einstein. \n               Inclusion \n             Emojicon attendees learnt about the software that encodes the images, which people use to make digital communications such as text messages more expressive, and the evaluation process Unicode uses when determining whether to add new emoji and standardize the glyphs. At the three-day event, people were also able to advocate for emoji they would like to see added to the official list and participate in a hackathon to develop new ones. Those in the group working on science designs said it was important for current and  future scientists  to see their interests reflected in the universal emoji offerings. \u201cWhere\u2019s my frowny-face scientist emoji to show that my experiment went wrong?\u201d asks team leader Jessica Morrison, an editor at  Chemical & Engineering News  and a former intern with Nature News. Seeing an emoji of something has a normalizing effect, says entrepreneur Alli McKee, who helped design the science group\u2019s new emoji. Anna Smylie, a designer who also helped to create the new illustrations, says seeing science emoji would keep the subject at the forefront of people's thoughts. \n               For the future \n             But science enthusiasts may have to wait a while. That\u2019s because there's a strict procedure for adding emoji to the official list. Anyone can petition to add a new character or emoji to Unicode, as long as they can write the proposal in English. The consortium considers proposals in the autumn, sending candidates through various subcommittees that may have further questions. Approved characters must then be encoded and added to the next version of Unicode, which is updated every summer. A few months later, they appear on phone keyboards after they're included in operating-system upgrades by manufacturers such as Apple and Samsung. The consortium adds about 70 new emoji a year. Unicode subcommittee member Jennifer 8. Lee, a journalist, film producer and co-creator of the dumpling emoji, started recruiting for the science emoji group prior to the conference. She invited the American Chemical Society to attend Emojicon because the society had previously developed a chemistry-themed sticker app called Chemoji. The app has more than 13,000 downloads, which the subcommittee regards as providing an important demonstration of the potential popularity of more science-themed emoji. Craig Cummings, vice-chair of Unicode's technical committee who advised the science emoji team, says that the planet emoji proposal could be fast-tracked for inclusion in the 2017 summer update. Implementation of the second collection of science emoji, if they're approved, could take longer. Cummings says they could be considered for the 2018 summer update. \n                     Climate, kissing and computer art: studies that set social media abuzz in 2015 2015-Dec-17 \n                   \n                     Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                   \n                     Conference tweeting rule frustrates ecologists 2015-Aug-19 \n                   \n                     Online collaboration: Scientists and the social network 2014-Aug-13 \n                   Reprints and Permissions"},
{"file_id": "539150a", "url": "https://www.nature.com/articles/539150a", "year": 2016, "authors": [{"name": "Gautam Naik"}], "parsed_as_year": "2006_or_before", "body": "Biomedical funders worldwide are adopting the US agency\u2019s free Relative Citation Ratio to analyse grant outcomes. A little-known algorithm that scores the influence of research articles has become an important grant-management tool at the world\u2019s largest biomedical funding agency, the US National Institutes of Health (NIH). In 2015, the NIH\u2019s Office for Portfolio Analysis (OPA) in Bethesda, Maryland,  devised the tool  to compare the performance of articles from different fields more fairly. Now, one of the NIH\u2019s biggest institutes is using the metric \u2014 the Relative Citation Ratio, or RCR\u00a0\u2014\u00a0to identify whether some types of grant deliver more bang for their buck. Other funders have adopted the RCR, which the agency offers freely online. In the United Kingdom, biomedical charity the Wellcome Trust is using the RCR to analyse its grant outcomes; in Italy, Fondazione Telethon, a charity that supports research into genetic diseases, is testing the RCR as a way to evaluate its funding initiatives. \u201cIt\u2019s getting a very good reception both inside and outside the NIH,\u201d says George Santangelo, director of the OPA. Santangelo\u2019s team, an 18-strong group of scientists, statisticians and data wranglers, was founded five years ago to devise tools to analyse NIH funding opportunities. Asked to measure which NIH research has had the most influence, the team chose not to judge articles simply by the journal in which they were published. That approach gives articles in highly cited journals higher scores, but it has  acknowledged flaws . An important study might be underestimated because it was not published in an elite journal, for instance. Simply counting citations, meanwhile, fails to capture the idea that articles should be judged relative to similar papers: an algebra paper with a few dozen citations, for example, may have a greater impact in mathematics than a widely cited cancer study would have in oncology. Algorithms that compare articles with others in their field are offered by commercial analysis firms such as Elsevier, but Santangelo\u2019s team argue that its metric is technically as good, if not superior\u00a0\u2014\u00a0and, importantly, more accessible. (The NIH has posted help files and its  full code  online.) \u201cNo other metric we\u2019ve seen is as transparent as RCR,\u201d Santangelo says. The algorithm is complex. It defines an article\u2019s research \u2018field\u2019 as the cluster of papers that it has been co-cited with: a dynamic cohort that grows all the time. It then calculates the background field\u2019s citation rate\u00a0\u2014\u00a0the average citations of the field\u2019s journals each year. After a few months of accrued citations, an article\u2019s actual performance can then be benchmarked against this background \u2014\u00a0although in some cases one has to wait a year, says Santangelo. To put this benchmarking in context, the team compares it to how NIH-funded papers in the same field and year performed ( B.\u00a0I.\u00a0Hutchins  et\u00a0al .  PLOS Biol.    14, e1002541; 2016 ). This boils everything down to a simple number, the RCR. An RCR of 1.0 means that an article has had exactly as much influence as the median NIH-funded paper in the same year and field; 2.0 means a paper has had twice as much influence, and so on (see \u2018A measure of influence\u2019). Anyone can upload PubMed papers at a website called  iCite  to find out their RCR score. The new metric  has critics . \u201cOur analysis shows that it is not better than other indicators,\u201d says Lutz Bornmann, a bibliometric specialist at Germany\u2019s Max Planck Society in Munich. The society has been using at least three other field-normalized metrics for several years to evaluate its institutions, but has no plans to adopt the RCR. It says that the metric is too complicated and too restrictive because it has been applied only to the PubMed database, which contains largely biomedical papers, so doesn\u2019t work for physical-sciences analysis. The RCR, however, is starting to gain ground as an analysis tool. At the US National Institute of General Medical Sciences (NIGMS) in Bethesda, a team used the metric to compare the impact of large, multimillion-dollar \u2018programme project\u2019 grants\u00a0\u2014\u00a0which fund teams of researchers\u00a0\u2014\u00a0with smaller grants for individual principal researchers. Papers produced by both grants had similar scores. \u201cIt has helped us take a very hard look at our support for team science,\u201d says NIGMS director Jon Lorsch. Another question that the NIGMS asked was whether scientists who get more money produce better outcomes than those who get less funding. Again, when the RCR numbers were tallied, it turned out that more NIH money didn\u2019t lead to higher-RCR papers. \u201cSo maybe we shouldn\u2019t fund scientists who are already well-funded,\u201d says Michael Lauer, deputy director for extramural research at the NIH. The tool is also catching on outside the NIH. Jonathon Kram, a research analyst at the Wellcome Trust, says that his group uses the RCR to analyse grants, and to benchmark the performance of the trust\u2019s funding schemes against other funders\u2019 grants. Unlike other normalized metrics, he says, the RCR \u201chas a transparent methodology and is available free\u201d. Software firm \u00dcberResearch in Cologne, Germany, has built a database of grants awarded by some 200 funders, and has begun publishing RCR scores for each publication in its grant database. \u201cWe use RCR to better judge the history of the researchers listed in our database,\u201d says Stephen Leicht, a co-founder of \u00dcber-Research. (It is part-owned by Digital Science, a firm operated by the Holtzbrinck Publishing Group, which has a share in  Nature \u2019s publisher.) And Fondazione Telethon, the Italian charity, says that it is testing the RCR and hopes to adopt it. \u201cWe are not going to use it to help decide funding decisions but more as a tool for analysis,\u201d says Lucia Monaco, the charity\u2019s chief scientific officer. \u201cWe want to make sure that every euro we invest is in excellent research.\u201d\n \n                     Beat it, impact factor! Publishing elite turns against controversial metric 2016-Jul-08 \n                   \n                     NIH metric that assesses article impact stirs debate 2015-Nov-06 \n                   \n                     We need a measured approach to metrics 2015-Jul-08 \n                   \n                     NIH\u2019s \u2018iCite\u2019 website for calculating RCR \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20968", "url": "https://www.nature.com/articles/nature.2016.20968", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Most surveys did not predict Donald Trump\u2019s victory over Hillary Clinton. What went wrong? That\u2019s the question that many political pollsters in the United States are asking themselves in the aftermath of the 8 November presidential election.  Republican candidate Donald Trump won in an electoral landslide , but for months most polls forecast a victory for his Democratic opponent, Hillary Clinton. Many types of poll, including randomized telephone polls and online polls that people opt into, indicated a tightening of the gap between the two candidates in the weeks leading up to the election \u2014 but still pointed to a Clinton win. \u201cThe industry is definitely going to be spending a lot of time  doing some soul-searching about what happened  and where do we go from here,\u201d says Chris Jackson, head of US public polling at Ipsos, a global market-research and polling firm based in Paris. The most recent national polls \u2014 including those conducted by ABC News/ Washington Post , Ipsos, YouGov and Fox News \u2014 all estimated a Clinton lead of 3\u20134% over Trump. Minor-party candidates, such as Gary Johnson of the Libertarian Party and Jill Stein of the Green Party, were forecast to win single-digit support. Yet as this article was published, as the last votes were being counted, Clinton leads the popular vote by a razor-thin margin: just 0.2%. The majority of states have tipped for Trump, awarding him their valuable electoral-college votes and ensuring his victory. Poll aggregators such as FiveThirtyEight and  The New York Times  nonetheless forecast Clinton\u2019s chances of victory at 71% or higher, and  The Huffington Post  predicted a Clinton landslide. This dramatic polling failure could have been due to factors such as poorly assessed likely voters, people misreporting their voting intentions, or pollsters inadequately surveying some segments of the population.\u201cIt\u2019s a big surprise that such a wide variety of polls using such a wide variety of methodologies have all the errors fall in the same direction,\u201d says Claudia Deane, vice-president of research at the Pew Research Center in Washington DC. \n               State of confusion \n             The University of Southern California Dornsife/ Los Angeles Times  presidential election poll, which included an online panel of nearly 3,000 people, was the only major national poll to forecast a Trump lead days before the election. \u201cBut we\u2019re not sure we were right either,\u201d says Jill Darling, survey director at the university\u2019s Center for Economic and Social Research in Los Angeles. She notes that Trump did not defeat Clinton by 3%, as her group\u2019s most recent poll predicted. On a state level, pollsters forecast Clinton\u2019s chances as higher than Trump\u2019s in North Carolina, Pennsylvania and Florida \u2014 which the current US president, Barack Obama, had won in 2012 \u2014 and yet Trump managed to win them this year. They expected Clinton to easily defeat Trump in Virginia and Michigan, but the races in those states became nail-biters. In Wisconsin, Trump not only pulled off a surprise upset, but did so by a whole percentage point.Most of the midwestern states, including Wisconsin, Michigan and Pennsylvania, tilted towards Trump, despite predictions to the contrary. Jackson says that polls might not have reached enough rural white people without university educations, who are concentrated in this \u2018rust belt\u2019, where manufacturing is on the decline. Exit polls show that this population accounted for a large number of Trump voters. \n               Busy signal \n             With each election,  pollsters have a harder and harder time reaching people . Now that Americans have fewer landlines and more mobile phones with caller ID, they don\u2019t respond to calls from unfamiliar numbers. Online surveys also struggle to recruit sufficient numbers of participants. To make a statistically significant estimate, for every poll, pollsters want at least 1,000 participants who are representative of the general population with respect to gender, race, education, income level and geographic distribution.Pollsters strive to assess not just who supports whom, but also who will be likely to vote on Election Day, which is not a national holiday in the United States. This year, 119 million people voted, accounting for 55.6% of registered voters, according to Michael McDonald, a political scientist at the University of Florida in Gainesville. That is the lowest percentage since the 2000 presidential race between George W. Bush and Al Gore. There were also more undecided voters this year than in previous presidential elections, perhaps because Trump and Clinton were historically unpopular candidates. Undecided voters may show up less in polls, yet may tilt towards one candidate more than others, Darling says. Only 53% of poll respondents felt comfortable disclosing the candidate they would vote for, lower than the 70% in earlier elections, she adds. Furthermore, people overestimate their own likelihood of voting.\u201cIt seems like Trump voters were more enthusiastic about turnout and less enthusiastic about responding to polls. That\u2019s a deadly combination,\u201d says Andrew Gelman, a statistician and political scientist at Columbia University in New York City.Polling experts in Britain conducted a formal inquiry following polling failures in last year\u2019s general election, when polls underestimated the turnout of older, Conservative voters. Now, in the United States, the American Association for Public Opinion Research has already named an ad-hoc committee to dig into the data and conduct a post-mortem on the election polls. They aim to produce findings by next May, Deane says. \n                     Donald Trump's US election win stuns scientists 2016-Nov-09 \n                   \n                     The polling crisis: How to tell what people really think 2016-Oct-19 \n                   \n                     The scientists who support Donald Trump 2016-Oct-18 \n                   \n                     The power of prediction markets 2016-Oct-18 \n                   \n                     Why the polls got the UK election wrong 2015-May-08 \n                   \n                     Nature  special: 2016 US election \n                   Reprints and Permissions"},
{"file_id": "539148a", "url": "https://www.nature.com/articles/539148a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Government\u2019s first Autumn Statement could reveal how it regards science. Since the United Kingdom voted to leave the European Union, science has existed under a cloud of uncertainty. The future of international collaboration and  the mobility of scientists is in limbo . And the government overhaul that followed the June vote included a reshuffle of government ministers, the creation of two departments to implement Brexit and a new prime minister. Hints of how the new guard (see \u2018Science in flux\u2019) regards science could come on 23 November, when the Chancellor of the Exchequer Philip Hammond lays out his financial plans in the Autumn Statement. The annual address on the nation\u2019s finances will be the first from the  new \u2018Brexit government\u2019 . \u201cThe Autumn Statement is a real nail-biter for scientists,\u201d says cell biologist Jennifer Rohn at University College London, an executive board member of the lobby group Science is Vital. \u201cIn the past, even when we\u2019ve been unsure of the specific outcomes, we\u2019ve at least been familiar with the Treasury\u2019s general stance on the importance of science. With a change of guard, everything is up in the air.\u201d \u201cThe signalling of intent is almost more important than sums of money that may or may not be dished out,\u201d adds Sarah Main, director of the Campaign for Science and Engineering in London. \u201cWe\u2019ll be looking for political signals and financial commitments.\u201d Main is even \u201cquite hopeful\u201d that a new agenda might provide fresh science opportunities. Former chancellor George Osborne was vocal about the importance of blue-sky research, and protected the science budget from cuts that hit many areas under his austerity programme. But he did not increase investment in real terms and during his tenure the United Kingdom dropped to the bottom of the G8 countries in terms of the percentage of gross domestic product its government spends on research and development (R&D). Hammond may be more willing than Osborne to spend public money, having already announced that he does not plan to hit Osborne\u2019s targets for cutting the United Kingdom\u2019s deficit. Whether this will translate into increased funds for science is unclear. Stephen Curry, a structural biologist at Imperial College London and a member of the advisory board for Science is Vital, describes Hammond\u00a0\u2014\u00a0who wanted to remain in the EU\u00a0\u2014\u00a0as a \u201cfairly steady head\u201d. But he says the jury is out on whether he will be a science-friendly chancellor. Other positive signals come from  newly appointed business secretary and former science minister Greg Clark , who told Parliament on 31\u00a0October that being at \u201cthe cutting edge of research and development\u201d was a cornerstone of the new government\u2019s industrial strategy, a range of policies aimed at boosting the economy. Main sees the strategy as an opportunity for the government to increase the country\u2019s investment in R&D. \u201cAt the moment there\u2019s a stalemate with both government and industry saying the other needs to invest more,\u201d she says. But she cautions that the industrial strategy could also tempt the government to predict, and then pick, specific \u2018winning technologies\u2019 to fund, instead of boosting the research base more broadly. Others doubt that science will be regarded as important enough to feature in the Autumn Statement. Navigating the path to Brexit is \u201cmore than a full-time job\u201d, says Kieron Flanagan, a science-policy researcher at the University of Manchester. He notes that after the Brexit vote, it took the government seven weeks to announce that it  would guarantee replacement funding for existing EU-funded research projects , even after the United Kingdom leaves the EU. \u201cThat it took so long to agree on that shows they\u2019re elsewhere,\u201d he says. If science is mentioned in the statement, he predicts it is likely to be \u201can easy, shiny project to announce\u201d rather than anything of substance. Funding is only one direction in which UK science needs reassurance. \u201cIt\u2019s just as important for the government to start making friendly noises to our overseas colleagues in a way that  they distinctly haven\u2019t been over the past month or two ,\u201d says Curry. The terms on which the United Kingdom leaves the EU and builds new international relations\u00a0\u2014\u00a0to be negotiated by two new bodies, the Department for Exiting the European Union and the Department for International Trade\u00a0\u2014\u00a0will dictate whether the country remains part of EU research programmes post-Brexit. Scientists should also be watching the Brexit \u2018war cabinet\u2019, a collection of government ministers that Prime Minister Theresa May has tasked with making the ultimate decisions on the EU exit, according to leaked documents. Although Hammond, Clarke and Damian Green\u00a0\u2014\u00a0who made the case for why remaining would be good for universities ahead of the referendum\u00a0\u2014\u00a0are members, they might find themselves sidelined by the half of the committee who campaigned to leave the EU, says Mike Galsworthy, who is programme director for the lobby group Scientists for EU in London. \u201cIf there is war within the \u2018war\u2019 cabinet, then the champions of universities, European collaboration and science investment will lose.\u201d Main notes that the changing of the guard requires organizations like hers to set out the value of science to the economy and to society all over again. \u201cThere is a whole new cast of characters now for us to meet with and make that case to.\u201d \n                     Brexit government\u2019s anti-immigration stance spooks UK scientists 2016-Oct-06 \n                   \n                     UK government gives Brexit science funding guarantee 2016-Aug-15 \n                   \n                     Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                   \n                     Science\u2019s status shifts in new Brexit government 2016-Jul-14 \n                   \n                     Winners and losers emerge in UK funding shake-up 2016-May-19 \n                   \n                     Nature  special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "539152a", "url": "https://www.nature.com/articles/539152a", "year": 2016, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Sub-Saharan project could one day help ecosystems to resist climate change and improve agriculture. One thousand ziplocked bags of soil from ten countries will form the basis of the first large-scale survey of the microbial life hidden underground in sub-Saharan Africa. The leaders of the African soil microbiology project hope that the data will one day help to drive better agricultural practices and to protect ecosystems and crops in the face of climate change. \u201cSoils are critical and soil health is vital for human and animal livelihoods,\u201d says Don Cowan, director of the Centre for Microbial Ecology and Genomics at the University of Pretoria in South Africa. He launched the project on 8 October at the consortium\u2019s first meeting in Pretoria. Researchers increasingly recognize the importance of soil microbes to ecology and agriculture. Some bacteria and fungi colonize plant roots, promoting the plant\u2019s growth. A diverse population of soil microbes helps to regulate an ecosystem\u2019s climate, and maintains the fertility of the soil and its ability to support crops. And biotechnology companies including Monsanto are testing additives that contain soil microbes for their ability to improve agricultural productivity.  Yet the diversity and sheer number of soil microbes\u00a0\u2014 as well as the extent to which populations vary across the planet\u00a0\u2014 is not well understood, says microbial ecologist Noah Fierer, who researches microbes in diverse environments at the University of Colorado at Boulder. A 2014 study of Central Park in New York revealed that the majority of its soil microbes were new to science. \u201cWe know surprisingly little about the soil microbiome,\u201d says Fierer. This is particularly true for sub-Saharan Africa. South Africa, a scientific leader in the region, has a long history of soil science, but until now, its researchers have focused on soil chemistry rather than soil microbes. An understanding of the soil microbiome and its effect on crops is especially relevant now because microbial communities are expected to be affected by climate change. Funded by the US Agency for International Development (USAID), the African project will take samples in South Africa, Namibia, Botswana, Zimbabwe, Mozambique, Zambia, Kenya, Ethiopia, C\u00f4te d\u2019Ivoire, and Nigeria. The goal of the three-year initiative is to create a broad survey of soil chemistry and microbiology across a range of regions and climates.Its researchers, led by Cowan, will use climate, topography and geology to choose 1,000 sample locations most likely to capture the maximum diversity. At each point, scientists will record data about the area, including temperature and altitude, and take photos of the site as well as digging the samples, which they will send back to Cowan\u2019s lab in South Africa. Each country is responsible for its own sample collection using a standardized method. Cowan\u2019s team, in collaboration with researchers sent from partner countries, will extract the DNA from the samples\u00a0\u2014\u00a0and amplify and sequence sections containing specific DNA tags that mark them out as bacteria. The researchers expect to find unknown bacterial genomes as well as known ones. In the project\u2019s next phase, they will look at soil fungi. There are practical challenges ahead. Zimbabwe is under US sanctions and not eligible for USAID support, so Cowan must find alternative funding to undertake sampling there. And the project may run up against anti-biopiracy legislation, which restricts the movement of samples across borders. \u201cIf it proves to be impossible to get all the appropriate permits from partner nations, we\u2019ll just have to leave them out,\u201d says Cowan. The project \u201crepresents a key step to charting the diversity of the soil microbiome and mapping the hidden biodiversity found below ground\u201d, says Fierer. Although valuable for creating a baseline for further studies, these kinds of data can provide only a superficial understanding of the microbiome, notes plant molecular biologist Simona Radutoiu at Aarhus University in Denmark. Her work involves in-depth studies of how soil bacteria interact with plants, which is necessary to understand the role of microbes in plant health. \u201cThis is a very good initiative,\u201d she says, \u201cbut is a start and should be continued, improved and sustained.\u201d \u201cThe resolution is not great,\u201d acknowledges Cowan, \u201cbut the novelty is enormous.\u201d He adds: \u201cWe don\u2019t have the resources to do the coverage and analyses that would take the project to a more sophisticated level.\u201d He hopes that the project will develop as more African scientists are trained to perform microbiome analyses, allowing more samples to be taken and a higher resolution of sampling. \u201cWe know our partners are struggling to build cutting-edge labs,\u201d he says. \u201cWe can\u2019t help them build their laboratories, but we can bring students here to train them in the practicalities.\u201d \n                     Temporal dynamics of hot desert microbial communities reveal structural and functional responses to water input 2016-Sep-29 \n                   \n                     Agricultural policy: Govern our soils 2015-Nov-23 \n                   \n                     Linking soil bacterial biodiversity and soil carbon stability 2014-Oct-28 \n                   \n                     Turnover of soil bacterial diversity driven by wide-scale environmental heterogeneity 2013-Feb-05 \n                   \n                     Microbes en masse: The sequencing machine 2012-Jul-11 \n                   \n                     Effects of soil type and farm management on soil ecological functional genes and microbial activities 2010-Apr-08 \n                   \n                     Nature  blogpost: Deep influence of soil microbes \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20952", "url": "https://www.nature.com/articles/nature.2016.20952", "year": 2016, "authors": [{"name": "Jeff Tollefson"}, {"name": "Lauren Morello"}, {"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Republicans sweep White House and US Congress, with uncertain implications for research. Republican businessman and reality-television star Donald Trump will be the United States\u2019 next president. Although science played only a bit part in this year\u2019s dramatic, hard-fought campaign, many researchers expressed fear and disbelief as Trump defeated former secretary of state Hillary Clinton on 8 November. \u201cTrump will be the first anti-science president we have ever had,\u201d says Michael Lubell, director of public affairs for the American Physical Society in Washington DC. \u201cThe consequences are going to be very, very severe.\u201d Trump has  questioned the science underlying climate change  \u2014 at one point suggesting that it was a Chinese hoax \u2014 and pledged to pull the United States out of the Paris climate agreement. Although he has offered few details on policies for biomedical research, Trump said last year that he has heard \u201cterrible\u201d things about the US National Institutes of Health; he has also derided NASA as a \u201clogistics agency for low-Earth orbit activity\u201c, and said he would expand the role of the commercial space industry in the US space programme. Trump\u2019s hard-line positions on immigration \u2014 including  a pledge to bar Muslims from entering the United States , and a plan  to build a wall along the US border with Mexico  \u2014 have worried research advocates who say such stances could dissuade talented foreign scientists from working or studying at US institutions. \u201cI think at the very least it would put a chilling effect on the interest of scientists from other countries in coming here,\u201d says Kevin Wilson, director of public policy and media relations at the American Society for Cell Biology in Bethesda, Maryland. Some researchers are already thinking about leaving the United States in the wake of the election. \u201cAs a Canadian working at a US university, a move back to Canada will be something I'll be looking into,\u201d  tweeted  Murray Rudd, who studies environmental economics and policy at Emory University in Atlanta, Georgia. ( Read more reaction from scientists. ) \n             Numbers game \n           Trump surpassed 270 electoral votes, the margin needed for victory, just before 3 a.m. on 9 November in New York City, where he was watching the election results unfold. Clinton \u2014 who held a slim lead in polls leading up to election day \u2014 scored strong support among women, minorities and college graduates, but that wasn\u2019t enough to overcome  Trump\u2019s unexpectedly strong performance . Republicans also swept Congress, retaining control of the House of Representatives and the Senate. That will make it easier for Trump to push through his policy priorities and nominees for key positions \u2014 including the leaders of science agencies such as NASA and the National Oceanic and Atmospheric Administration, and for a current vacancy on the Supreme Court. \"It's going to be critically important for researchers to stand up for science,\u201d says Jennifer Zeitzer, director of legislative relations at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. That means making sure that the Trump administration understands how federally funded research benefits the country, Zeitzer says. Many scientists reacting to the election results on social media said that the possibility of funding cuts is a major worry. \u201cI do breast cancer research for my PhD,\u201d  tweeted  Sarah Hengel, a graduate student at the University of Iowa in Iowa City. \u201cScared not only for my future but for the future of research and next years @NIH budget.\u201d \u201cThis is terrifying for science, research, education, and the future of our planet,\u201d  tweeted  Mar\u00eda Escudero Escribano, a postdoc studying electrochemistry and and sustainable energy conversation at Stanford University in California. \u201cI guess it's time for me to go back to Europe.\u201d \n             Uncertain climate \n           The Supreme Court vacancy could put the fate of one major plank of  US President Barack Obama\u2019s climate-change strategy  in Trump\u2019s hands. The court is reviewing a regulation to curb emissions from existing power plants. Republicans have blocked Obama\u2019s attempt to nominate a justice to fill the court vacancy, but Trump should be able to quickly fill the position. His nominee, not yet named, could cast the deciding vote in the climate case. Fulfilling his pledge to exit  the Paris agreement  could take longer; legally, he would not be able to do so for four years. But Trump's election could factor into climate negotiations currently under way in Marrakesh, Morocco, where countries are hashing out how they will implement the Paris agreement. The United States is the world\u2019s second-largest emitter, and Obama played a key part in crafting the Paris accord. David Victor, a political scientist at the University of California, San Diego, says that the international community is likely to keep soldiering on with the agreement. One possibility, he says, is that China could emerge as the global leader on climate change. Victor also says that Trump\u2019s election will have enormous implications for international relations generally. \u201cIt\u2019s going to badly tarnish the image of the United States,\u201d he says. \u201cRoughly half of the population has voted for somebody who by almost any measure is unfit to serve as president.\u201d \n                   Beyond Trump vs Clinton: A scientist\u2019s guide to the US election 2016-Nov-01 \n                 \n                   The polling crisis: How to tell what people really think 2016-Oct-19 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 \n                   Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                 \n                   Nature  special: 2016 US election \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20967", "url": "https://www.nature.com/articles/nature.2016.20967", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Swiss researchers travel to China to conduct pioneering experiment. For more than a decade, neuroscientist Gr\u00e9goire Courtine has been flying every few months from his lab at the Swiss Federal Institute of Technology in Lausanne to another lab in Beijing, China, where he conducts research on monkeys with the aim of treating spinal-cord injuries. The commute is exhausting \u2014 on occasion he has even flown to Beijing, done experiments, and returned the same night. But it is worth it, says Courtine, because  working with monkeys in China  is  less burdened by regulation than it is in Europe and the United States . And this week, he and his team report 1  the results of experiments in Beijing, in which a wireless brain implant \u2014 that stimulates electrodes in the leg by recreating signals recorded from the brain \u2014 has enabled monkeys with spinal-cord injuries to walk. \u00a0 \u201cThey have demonstrated that the animals can regain not only coordinated but also weight-bearing function, which is important for locomotion. This is great work,\u201d says Gaurav Sharma, a neuroscientist who has worked on restoring arm movement in paralysed patients, at the non-profit research organization Battelle Memorial Institute in Columbus, Ohio. The treatment is a potential boon for immobile patients: Courtine has already started a trial in Switzerland, using a pared-down version of the technology in two people with spinal-cord injury. \u201cThis study helps to open exciting new pathways to clinical studies and new bioelectronic treatment options for patients living with paralysis,\u201d says bioengineer Chad Bouton, who  researches medical devices used to bypass spinal-cord injuries  at the Feinstein Institute for Medical Research in Manhasset, New York. \n             From rats to primates \n           The experiments are more of a progression than a sudden breakthrough: they are based on a decade of work in rats, Courtine says, and the monkeys reacted in very similar ways. The team first mapped how electric signals are sent from the brain to leg muscles in healthy monkeys, walking on a treadmill. They also examined the lower spine, where electric signals from the brain arrive before being transmitted to muscles in the legs. Then they recreated those signals in monkeys with severed spinal cords, focusing on particular key points in the lower part of the spine.\u00a0 Microelectrode arrays implanted in the brain of the paralysed monkeys picked up and decoded the signals that had earlier been associated with leg movement. Those signals were sent wirelessly to devices that generate electric pulses in the lower spine, which triggered muscles in the monkeys' legs into motion. \u201cThe whole team was screaming in the room as we watched,\u201d says Courtine, who has seen many failed experiments to restore walking ability. The rhythm of the leg movement was imperfect, but the monkeys\u2019 feet were not dragging and the movement was coordinated enough to support the primates\u2019 weight. Researchers have previously used brain-reading technology to enable paralysed people to move a robotic arm, give themselves a drink or to move their own hand and play a video game. The brain signals involved in activating muscles in a paralysed leg are less complex than those that guide the hand and all its digits, says Courtine. But researchers studying arm and hand movement have the advantage that even incremental improvements are useful. \u201cA small improvement in the ability to grasp changes your quality of life, but \u2018almost walking\u2019 doesn't help much,\u201d Courtine says. \u201cWith the legs, it\u2019s all or nothing.\u201d He is now working with monkeys to try to ensure better leg-muscle control, so that the primates can not only support their own weight but also maintain their balance and avoid obstacles. \n             Human applications \n           Doing the same thing with humans will be more complex, says Courtine: the brain decoding is much more complicated. The primate study, for example, used electrical activity recorded from the spinal cord before the injury and \u201cplayed it back\u201d to restore movement, notes Bouton. \u201cThat\u2019s an approach that wouldn\u2019t be practical after an actual spinal-cord injury,\u201d he says. And Sharma says that further research will have to take into account other elements of walking. Rhythmic coordination of gait, for example \u2014 which the monkeys didn\u2019t demonstrate \u2014 is controlled by a different group of neurons. Devices to enable human locomotion in paralysed patients would ideally include brain\u2013computer interfaces, electrical stimulation for activating muscles, an exoskeleton-like device to help bear weight, and smarter electrical processing to enable gait control, he says. Courtine has started a clinical trial at the CHUV University Hospital of Lausanne, geared towards rehabilitation by helping to stimulate coordinated walking in people who are paralysed. Two people have had the electric-pulse generators implanted in their lower spines. (The trial will not implant microelectrode arrays in the people's brains, however, so they will not be able to control the movement themselves.) As clinical trials proceed in Switzerland, Courtine is still regularly travelling back to China. Although the positive results have allowed him to negotiate the use of five monkeys at a Swiss primate laboratory, some of his experimental work still takes place in Beijing. China\u2019s welcoming attitude to primate research will reap benefits for the country, Courtine says. \u201cThis is going to provide China with a tremendous leverage for translational medicine.\u201d\n           Read the related News & Views article: ' Neural interfaces take another step forward '. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Pioneering brain implant restores paralysed man's sense of touch 2016-Oct-13 \n                 \n                   Monkey kingdom 2016-Apr-20 \n                 \n                   First paralysed person to be 'reanimated' offers neuroscience insights 2016-Apr-13 \n                 \n                   Monkeys move paralysed muscles with their minds 2008-Oct-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20965", "url": "https://www.nature.com/articles/nature.2016.20965", "year": 2016, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Trump victory generates shock, disbelief and fear of funding cuts. Nature  rounds up reaction from researchers to  Donald Trump's election as the next US president . Trump, a Republican, had trailed his Democratic opponent, Hillary Clinton, in polls leading up to the 8 November election day, but pulled out a surprising victory. \n             Some foreign researchers working in the United States started thinking about leaving the country. \n           \n             Around the world, researchers expressed sympathy and wondered how the election results might upset US research. \n           \"I feel sad for the United States and its scientists, and would like to welcome good scientists to work and live in China.\" \u2014Yi Rao, a neuroscientist at Peking University. \"I have heard too many negative things about this very first 'anti-science' US president, however, as a scientist, I would avoid predicting the unpredictable. Sometimes, people under unfavourable situations can do good science as well. it may force us to choose more significant research projects, more fundamental scientific questions to tackle, not just follow the flow of funding.\" \u2014Can Xie, a biophyicist at Peking University. \n             Other researchers said they were scared that a Trump presidency might reduce funding for science. \n           \n             Some researchers expressed concern over the future of climate science. \n           \"With a climate skeptic as President and a creationist as vice-president, scientists can only be worried.\" \u2014Albert Descoteaux, a biologist studying host-parasite reactions at McGill University in Montreal, Canada. \"President-elect Donald Trump's stance on global warming is well known. Science cannot expect any positive climate action from him. The world has now to move forward without the US on the road towards climate-risk mitigation and clean-technology innovation.\" \u2014Hans Joachim Schellnuber, director of the Potsdam Institute for Climate Impact in Germany, in a press statement. \"The kind of work we are doing here [at the United Nations' COP22 climate meeting] today takes a new importance right now. Political events do not and cannot change the reality of climate change.\" \u2014Philip Duffy, president of the Woods Hole Research Center in Falmouth, Massachusetts. \n             And some scientists had more existential worries. \n           \"Unlike the day after the EU referendum vote, when I was bitterly upset, I just feel numb today. I don't know if that is a kind of despair settling in because despair is precisely the wrong type of reaction to Trump winning the presidential election. Throughout the campaign he showed himself to be a facist and racist, who bragged about his mis-treatment of women. He showed scant regard for truthfulness and espoused denialist views on climate change. It seems unlikely that the scientific and research prowess of the USA will flourish under such a president.\" \u2014Stephen Curry, a structural biologist at Imperial College London. \"I am confused, angry, depressed. I feel much like I do when I receive the comments on a rejected paper that the reviewers have torn apart. This morning I realized that I don't actually know a Trump supporter who I could talk to about the election. How can I reach the public if I'm only speaking to my own circle?\" \u2014Peter Peregrine, an anthropologist at Lawrence University in Wisconsin and the Santa Fe Institute in New Mexico. \n             With reporting by Nature staff. \n           \n                   The polling crisis: How to tell what people really think 2016-Oct-19 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 \n                   Trump\u2019s border-wall pledge threatens delicate desert ecosystems 2016-Aug-16 \n                 \n                   Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                 \n                   Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                 \n                   Nature  special: US election 2016 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20973", "url": "https://www.nature.com/articles/nature.2016.20973", "year": 2016, "authors": [{"name": "Brigitte  Osterath"}], "parsed_as_year": "2006_or_before", "body": "Experiments also reveal that rats are ticklish in similar places to humans. Like people, rats are ticklish. Now, by implanting electrodes in the brains of these laboratory workhorses, researchers have identified the brain region that seems to drive the trait \u2014 an insight that could illuminate the origins of ticklishness in people. The work, published in the 11 November issue of  Science 1 , also reveals that rats' susceptibility to tickling is affected by mood, rather like in people. Separate from the study, the researchers say they have found that rats are ticklish in similar places to people \u2014 on their tummies and back paws, but not on their backs or on their front paws. In the late 1990s, neuroscientist Jaak Panksepp, who was then of the Bowling Green State University in Ohio, discovered that rats make ultrasonic \u2018chirps\u2019 when being tickled and while playing 2 , which may be similar to human laughter.  Several other animals are ticklish, including dogs and chimps, but rats seem particularly so, and are easy to handle in the lab. So neuroscientists Michael Brecht and Shimpei Ishiyama of the Bernstein Center for Computational Neuroscience in Berlin decided to use the animals to probe what is going on in the brain. \n             Backs, bellies, tails \n           They inserted eight wire electrodes into the tiny somatosensory area \u2014 the part of the mammalian brain that responds to touch on the skin \u2014 into five rats. Then they tickled the animals on their backs, bellies and tails and recorded the ultrasonic chirps. The neurons in the trunk of the somatosensory cortex fired intensely in response to belly tickling, but less to tickling on the back and hardly at all to that on the tail. The intense firing correlated with a specific chirp pattern. Brecht and Ishiyama then investigated whether they could get the animals to make the sound simply by stimulating the trunk of the somatosensory cortex \u2014 and found that they could, concluding that the region is key to ticklishness. When the pair tickled rats while they were on an elevated platform under bright light, a situation designed to induce anxiety, the usual chirping-response was reduced: they conclude that fear suppresses activity in the somatosensory cortex. The fact that rats are ticklish in the same spots as humans, meanwhile, suggests ticklishness may have a hard-wired neural anatomy that is shared between some animals, they say. \n             Chirping like crazy \n           The researchers recorded activity in the somatosensory cortex not only during tickling, but also when the rat chasing their hands, says Brecht, even when they didn\u2019t touch the animal. This chimes with what some researchers, including Panksepp, suspect is why ticklishness evolved: to promote social bonding and play. \u201cThe first animal I tickled chirped liked crazy. And the ones that chirped the most also started to chase our hands for fun,\u201d recalls Panksepp, who is now at Washington State University in Pullman. The finding fits with the observation that lab mice do not seem to be ticklish \u2014 and are also not playful like rats. Panksepp is delighted that other scientists have built on his earlier research, and commends the work. But he would like to see an experiment that probes whether the rats actively seek out direct stimulation of the somatosensory cortex to confirm that the chirping produced when this part of the brain is directly stimulated is a sign of enjoyment. Another suggestion comes from Chris Frith, neuropsychologist and professor emeritus at the Wellcome Trust Centre for Neuroimaging at University College London. In 1998, he used brain scans to show that most people will not respond to self-tickling because the region of the brain called the cerebellum, which seems to predict what kind of feeling a movement will cause, cancels out the tickling sensation 3 . People with schizophrenia, who have difficulty distinguishing sensations from the outside world and those that they trigger, can tickle themselves, though. \u201cThe next step would be to look at self-tickling in rats,\u201d he says. But he acknowledges that \u201cit might be difficult to get rats to tickle themselves\u201d. \n                   Neurophilosophy: My brain and I 2013-Jul-17 \n                 \n                   Evolution: Tickle tree 2009-Jun-10 \n                 \n                   Human-ape links heard in laughter 2009-Jun-04 \n                 \n                   Why you can?t tickle yourself 1998-Oct-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20974", "url": "https://www.nature.com/articles/nature.2016.20974", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Nine experts reflect on where researchers should direct their efforts during the next US administration. How should researchers prepare for  the presidency of Donald Trump ?  Nature  asked nine experts in science and the humanities to lay out their advice and concerns ahead of the next US administration. Douglas Sipp: Beware of plans to lower drug standards Daniel M. Kammen: Back clean energy to create jobs Stuart Russell: Tiptoe through the nuclear minefield Lars Brozus & Oliver Geden: Study policymaking John Krige: Preserve the post-war contract Elena Cattaneo: Draw strength from past struggles David Kaiser: Share the joy of science Nathaniel Comfort: Reinstate Enlightenment values Cassidy Sugimoto: Strengthen study of disparities and stay global \n             Beware of plans to lower drug standards \n           \n             Douglas Sipp, Riken Center for Developmental Biology, Kobe, Japan \n           Supporters of the idea that drugs should be tested for efficacy before being sold are in for a long four years. In recent years, Republican majorities in the Senate and in the House of Representatives have backed several bills that would drastically reduce the authority of the US Food and Drug Administration (FDA), and its ability to require that new medical products are demonstrated to be safe and effective before they are marketed. Most concerning is the Republican push for a federal \u2018right to try\u2019 law, which would indemnify companies and individual physicians that sell experimental drugs to dying patients after only preliminary safety testing. Similar laws have been enacted in 32 states. But these have had little impact, being superseded by federal code. A federal right-to-try law would effectively make phase I clinical trials (which test safety) the threshold for marketing new products. This would have profound consequences \u2014 on how new drugs are brought to market, and for clinical-trial enrolment. The right-to-try movement is making overtures overseas too. In Canada, for example, all members of its parliament received a coordindated e-mail\u00a0calling on them to endorse such a law. Then there\u2019s the US REGROW Act. This seeks to  lower standards for cell\u00a0 therapy products  \u2014 such as stem-cell treatments \u2014 and has been stalled in a Senate committee since this spring. Major scientific groups have issued statements opposing the act, including the International Society for Stem Cell Research, the International Society for Cellular Therapy, and the Alliance for Regenerative Medicine. The bill\u2019s prospects had seemed grim. Substantive amendments in recent months had, for instance, removed an alarming call for Congress to prohibit the FDA from requiring phase III clinical trials, typically the final hurdle for therapies to be approved for market for most investigational cell therapy products. Now, under a Republican-dominated government, its dim chances seem to have brightened. Other attempts at deregulation may also take advantage of the new, effectively one-party government. These include proposals to lower evidence standards for drug approval across the board, and to undermine FDA authority over the promotion of \u2018off-label\u2019 uses of approved drugs. \n             Back clean energy to create jobs \n           \n             Daniel M. Kammen, Director of\u00a0Renewable and Appropriate Energy Laboratory (RAEL), University of California, Berkeley \n           If Trump\u2019s business bona fides are all he claims, he should see that the smart money is on clean energy. Clean-energy projects  generate more jobs than do the coal and natural-gas sectors . With solar and wind projects creating\u00a0energy prices between 2.5 and 4 \u00a2 per kilowatt-hour, the economic case is compelling \u2014 as is the argument for these technologies being the fastest way to provide energy access to the global poor,  boosting their economic opportunities and capacity .  The economic benefits of clean energy are even more profound if combined with domestic manufacturing of electric vehicles, which bring new research growth to the high-tech sector. Renewable-energy options, in some cases supported by natural gas, are a  faster route out of energy and economic poverty than are coal-energy projects . And the global energy markets are embracing the clean-energy transition. Jordan, Kenya, Morocco, Nicaragua and many other nations are merging the business and environmental case to push for and beyond the goals of the Paris climate agreement, which became legally binding last week and from which Trump has pledged to withdraw the United States. These countries are building gigawatt-scale clean-energy plants, and ramping up their innovation and industrial sectors at the same time. As shown by the activity at COP22, the United Nations climate summit currently happening in Marrakesh, Morocco, the world will be pursuing clean-energy and climate-friendly goals with or without the United States. It would be folly not to want to lead and profit from this transition. \n             Tiptoe through the nuclear minefield \n           \n             Stuart Russell, Director of the Center for Intelligent Systems, University of California, Berkeley \n           I have two concerns about defence policy. First, I\u2019m not optimistic that the White House will understand the negative humanitarian and strategic consequences  posed by lethal autonomous weapons systems . The Obama administration took the views of the scientific community seriously in formulating foreign and military policy. Secondly, I fear for the Comprehensive Nuclear-Test-Ban Treaty, one of the pillars of global nuclear non-proliferation policy. Trump has disparaged the  Iran nuclear agreement  to limit that country's nuclear programme; the deal is widely supported by arms-control experts. He has said that he has no objection to allowing several countries in Asia and the Middle East to have nuclear weapons. He has announced his intention to retaliate with nuclear weapons against a terrorist attack by ISIS (where, exactly, would he detonate them?). The world has been tiptoeing through a nuclear minefield for seven decades and perhaps the exit was in sight. With Trump, we could plunge back into the minefield, running blindfold and flailing our arms. \n             Study policymaking \n           \n             Lars Brozus & Oliver Geden, German Institute for International and Security Affairs, Berlin \n           Trump\u2019s election presents a unique opportunity for social scientists to conduct in-depth studies on an important research question: how relevant are policymakers for policymaking? The question is not as frivolous as it sounds. For decades, social scientists have come up with different claims about who and what influences political decisions and governmental action. Two broad camps have emerged: one, mostly led by historians, stipulates that it is \u2018big men\u2019 (historically) that make \u2018big policy\u2019. The other camp, mostly peopled by political scientists,  explains policies as the product of opportunities, interests and timing . The hostile takeover of Washington\u2019s bureaucracy by a deeply divided Republican party will shed more light on these questions. \n             Preserve the post-war contract \n           \n             John Krige, Professor in the School of History and Sociology, Georgia Institute of Technology, Atlanta \n           I fear that the humanities will be targeted as being economically irrelevant. I fear that social-science research that is deemed too\u00a0critical of government policy or of social trends (police or gun violence, or toxic poverty, for example)\u00a0will suffer as being driven by 'liberal bias'. The commercialization of universities, already under way, will accelerate. The right to carry guns on campus, and into classrooms, is likely to be aggressively asserted. As funding decreases, US public\u00a0universities will\u00a0increasingly\u00a0view foreign\u00a0students as a\u00a0commodity who can be charged\u00a0full\u00a0out-of-state\u00a0tuition. Applicants from abroad will balance the benefits of being trained at cutting-edge research universities against a rising tide of xenophobia, tightened restrictions on knowledge circulation with non-US citizens, and increased costs. International scientific and technological\u00a0exchange, especially with China, is threatened, and will be caught in the backlash of the\u00a0trade wars envisioned by Trump during his campaign. Major international agreements on climate change and on controlling the spread of nuclear weapons could be shredded. Trump's victory, along with the Republican-controlled Congress, accelerates the end of the post-war contract between science, technology, higher education and the state.\u00a0 \n             Draw strength from past struggles \n           \n             Elena Cattaneo, Director of the Centre for Stem Cell Research, University of Milan, Italy \n           The US scientific community has shown that its commitment to reasoned argument can prevail in the most difficult circumstances. When George W. Bush banned public funding for embryonic stem-cell research in 2001, researchers mobilized in a landmark campaign. They tapped every resource, from private foundations and associations to the public. That focus on strong, pragmatic debate saw the prohibition reversed in 2009. Yet all the while, the nation\u2019s scientists have delivered remarkably solid results that we all have been using to further our own research. My high regard for US scientists gives me hope that their bold, empirical thinking can provide the \u2018antibodies\u2019 to contain and temper any risk to the noble and democratic traditions of a United States that still has so much to offer the world. \n             Share the joy of science \n           \n             David Kaiser, Professor of the History of Science, and of Physics, Massachusetts Institute of Technology, Cambridge \n           The biggest immediate challenge for science and scientists will likely be further pressure to cut federal funding for research. This is likely to exacerbate the current trend of funding short-term projects that might promise short-term pay-off, combined with greater uncertainty from one grant-cycle to the next. These trends have made it difficult to do any sort of responsible planning for medium-term \u2014 let alone long-term \u2014 projects.\u00a0 Think of LIGO. The research collaboration\u2019s  successful detection of gravitational waves  last year was the culmination of decades of sustained support from the US federal government, through the National Science Foundation. Project leaders could plan responsibly for next steps and recruit young scientists and technicians to the project with some confidence about continued ability to support their roles. It is difficult to imagine big, complicated projects that require even a fraction of the time that LIGO needed receiving reliable support today, and that was true even before the election. Scientists and scholars must continue to articulate the value of supporting research. Some of that value has and will continue to come from technology transfer \u2014 in the form of commercialized products or health-related advances. But there is also a real need to raise awareness about the less-tangible, long-term benefits that are less evident to taxpayers and politicians.\u00a0 I am heartened by the incredible interest that the LIGO discovery generated throughout the world. Many people remain fascinated by big-picture, imaginative research \u2014 even that which does not lead quickly to better gadgets or drugs. Similar excitement greeted the  Higgs-boson discovery in 2012 . More than ever, we must make the case that abstract, long-term projects deserve taxpayer support. \n             Reinstate Enlightenment values \n           \n             Nathaniel Comfort, Professor, Department of the History of Medicine, Johns Hopkins University, Baltimore, Maryland \n           Trump\u2019s success is the crescendo of a long devaluation of the Enlightenment idea that facts are the rightful basis of action. Reason itself is under fire. This mistrust of expertise is a serious threat to the sciences and the humanities. Science is in the business of making knowledge. History is founded on the principle that informed reflection is superior to ignorance. Devaluing evidence and manufacturing doubt can be a powerful strategy \u2014 as climate-change deniers and the tobacco industry have shown. Their push for short-term gain threatens our health and environment. The history of science, broadly construed, must shoulder some of the blame. Perhaps the central insight of my field in the past 40 years is that facts are socially constructed. Truth has a social history. But even the most extreme social constructionists still value expertise; they are not the ones trying to destroy the fabric of reality. This subtlety has been lost on the wider public, and to some extent on scientists. The rift between the arts and sciences \u2014 the pillars of the university \u2014 now threatens all who value reason.\u00a0 The sciences and humanities must join forces and push back. We must reinstate Enlightenment values \u2014 modulated now by an appreciation of their social nature \u2014 in politics and culture. Together we can restore trust in expertise, by re-enrolling non-experts in our projects. Make the public once again feel invested in knowledge. Speak truth to power. \n             Strengthen study of disparities and stay global \n           \n             Cassidy Sugimoto, School of Informatics and Computing, Indiana University Bloomington  \n           My research examines who gets to make knowledge, share knowledge, and be given credit for that knowledge. I explore how  gender and other biases frame credibility and authority . I study how social disparities are reproduced and legitimized in the academic sphere: how do disparities suppress the voice and labour of some, while disproportionately magnifying others? This election cycle reconfirmed the realities of these disparities, with immediate repercussions for science. The devaluing discourse of the campaign endangers the strides we have made towards equality in the scientific workforce. The platform of isolationism threatens the ability of the United States to fully engage in the global knowledge economy. The strength of the scientific workforce in the United States depends on the ability to recruit and retain a diverse and global scientific workforce. US Nobel prizes and other great discoveries are largely attributed to scholars both born and educated in other countries. High impact work \u2014 and the knowledge economy \u2014 require international mobility and collaboration. If US policies and rhetoric inhibit our ability to work at the global level, the strength of the United States, both scientifically and economically, will decline. As educators and scholars, we must use the election to teach our students about critical thinking and civil discourse. We must continue to demonstrate to all students \u2014 regardless of race, gender, sexuality, ability or religion \u2014 that they are valuable and can contribute to knowledge and society. We must strengthen our bonds with scholars from across the world. We must demand that the government continue to invest in public education \u2014 the cornerstone of a functioning democracy. Finally, we must continue to conduct research that helps us to understand the forces that perpetuate disparities and the ways in which we can, individually and collectively, ensure that all people can contribute to and have access to knowledge. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Donald Trump's US election win stuns scientists 2016-Nov-09 \n                 \n                   Science under President Trump 2016-Nov-09 \n                 \n                   Pollsters struggle to explain failures of US presidential forecasts 2016-Nov-09 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20971", "url": "https://www.nature.com/articles/nature.2016.20971", "year": 2016, "authors": [{"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}, {"name": "Alexandra Witze"}, {"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Climate-change and immigration policies raise alarm, but much of the incoming US president's agenda is simply unknown. The long campaign for the White House is over \u2014 but incoming US president Donald Trump\u2019s work is just starting. With just two months before his inauguration on 20 January, he and his staff are busy vetting candidates for top government jobs and clarifying the agenda for his first few months in office. Some scientists have  expressed fear  about how Trump\u2019s presidency  will affect research  in the United States. The president-elect has  questioned the science underlying climate change  and has linked autism to childhood vaccinations; his vice-president, Indiana governor Mike Pence, does not believe in evolution or that human activities have caused climate change. Still, some science advocates caution against a rush to judgement about how the Trump administration will approach science and research issues. \u201cThe verdict remains out,\u201d says Tobin Smith, vice-president for policy at the Association of American Universities in Washington DC. \u201cThere are many people who have been strong supporters of science you might not have been expecting.\u201d Smith says that a prime example is Newt Gingrich, the former Republican congressman for Georgia, who is rumoured to be up for a top job in Trump's administration. As speaker of the US House of Representatives in the 1990s, Gingrich supported a plan to double the budget for the National Institutes of Health (NIH) over 10 years. Since leaving Congress, he has advocated significant spending hikes for the National Science Foundation and other science-funding agencies. But it\u2019s hard to draw any conclusions about Trump\u2019s views on science, given his limited comments on such issues during his presidential campaign, other policy specialists caution. \u201cHe speaks positively of innovation, but \u2018innovation\u2019 is a big word,\u201d says Kevin Wilson, director of public policy and media relations at the American Society for Cell Biology in Bethesda, Maryland. \u201cYou can drive a truck through innovation. We don\u2019t know what that means.\u201d Here,  Nature  looks at key science issues that Trump will confront as he prepares to take power, and during his first few months in office. \n               Biomedical science \n             Trump has said that one of his priorities after taking office will be to reverse several executive orders that the current president \u2014 Democrat Barack Obama \u2014 issued on topics ranging from  climate change  to immigration. Some biomedical researchers are worried that Trump will cancel an Obama order that  authorized experiments with human embryonic stem cells  in the United States. \u201cIt\u2019s something very tangible that could be done,\u201d says Wilson. \u201cHe could do away with it on day 1.\u201d There\u2019s precedent for such actions: Obama instituted his executive order on stem cells in March 2009, less than two months after taking office. In doing so, he reversed limits put in place by his predecessor, Republican George W. Bush. And vice-president-elect Pence opposed Obama\u2019s decision to authorize research with human embryonic stem cells on ethical grounds. \u201cIt is morally wrong to create human life to destroy it for research,\u201d he wrote in a March 2009 newspaper commentary. \u201cNot only that, I believe that it is morally wrong to take the tax dollars of millions of pro-life Americans, who believe that life is sacred, and use it to fund the destruction of embryos for research.\u201d Overall, however, Trump has said little about biomedical science \u2014 aside from an oft-quoted 2015 radio interview in which he called the NIH \u201cterrible\u201d. Mary Woolley, president of the advocacy group Research!America in Arlington, Virginia, worries that this silence on biomedical science suggests that it will not be a priority for Trump's administration. \u201cA lot of it is not really controversial,\u201d she says. \u201cWe tend in this country to take progress for granted.\u201d \n               Climate change \n             If Trump keeps his promises, the United States will reverse course on global warming. The president-elect has blasted the US Environmental Protection Agency (EPA) and said that he will repeal  Obama\u2019s climate regulations . And Myron Ebell, a prominent climate sceptic who directs energy and global warming policy at the Competitive Enterprise Institute in Washington DC, is leading Trump\u2019s transition team for the EPA. \u201cI take Trump at his word,\u201d says Jeffrey Holmstead, an attorney at the firm Bracewell in Washington DC who worked at the EPA under President George W. Bush. \u201cAnd I think they won\u2019t have any difficulties.\u201d Trump\u2019s first target will likely be the Clean Power Plan, Obama\u2019s set of regulations to reduce greenhouse-gas emissions from power plants, which roughly two dozen states are challenging in court. The case is expected to reach the Supreme Court as early as next year. By then, Trump may have filled the court\u2019s current vacancy, tipping the panel\u2019s ideological balance towards the conservative. That would put the climate regulations in jeopardy. But it would be easy enough for the Trump administration to just revoke the Clean Power Plan on its own, Holmstead says. The administration could also revise a regulation that essentially bans the construction of new coal-fired power plants unless they are equipped to capture and bury a portion of their carbon emissions. And Trump could repeal the moratorium on new federal coal leases with the stroke of a pen. Trump\u2019s vow to pull the United States out of the  Paris climate accord  is still sinking in at the United Nations climate talks in Marrakesh, Morocco, where delegates are busy  hashing out a plan to implement the agreement . \u201cWe\u2019re sort of in the denial stage now,\u201d says Jake Schmidt, international programme director at the Natural Resources Defense Council in New York City. \u201cI suspect there will be some disappointment and anger starting to bubble up in the next couple of days.\u201d Trump would not be able to formally withdraw the United States from the Paris pact for four years, but his election raises questions about how participants should move forward, Schmidt adds. Already, many nations are looking to China for international leadership on climate. The country  leads the world in renewable-energy investment  because it views clean energy as a necessity and an opportunity, says Andrew Steer, president of the World Resources Institute, an environmental think tank in Washington DC. He hopes that Trump will come to see tough climate-change policies as a tool to ensure that the United States remains competitive in the development of energy technology. \n               Space \n             Trump himself has said little about space policy, but astronaut Eileen Collins \u2014 the first woman to command a space shuttle \u2014 spoke at the Republican national convention in July. Collins called for the United States to reassert its leadership in space exploration. In October, two of Trump\u2019s campaign advisers wrote a pair of commentaries in  SpaceNews  laying out possible directions for space policy under a new president. The articles argued that NASA should focus more on deep-space exploration and less on what they called \u201cpolitically correct environmental monitoring\u201d. NASA\u2019s Earth-observing missions account for more than one-third of the agency\u2019s science budget, an expense that has  come under fire from congressional Republicans . \u201cIt\u2019s conceivable that the Trump White House could go after NASA Earth science,\u201d says John Logsdon, former director of the Space Policy Institute at the George Washington University in Washington DC. The Trump advisers also argued for more public\u2013private partnerships in civilian space. Such efforts are already under way with  private companies now ferrying US cargo , and soon US astronauts, to the International Space Station. One of the commentary authors is former Congressman Bob Walker (Republican, Pennsylvania), who runs a lobbying firm in Washington DC and has served on various aerospace and space advisory panels over the years. Other experts who may play a part during the transition are Mark Albrecht, an aerospace executive who advised President George H. W. Bush on space issues, and Scott Pace, the director of the Space Policy Institute at George Washington University, who advised Republican nominee Mitt Romney during the 2012 presidential race. Walker has floated the idea of restoring the National Space Council, last active in 1993, to establish and oversee the nation\u2019s space goals. Aerospace industry leaders and others have sporadically argued to bring back the council, which has been traditionally headed by the vice-president. Pence, however, has little track record on space issues. But Gingrich, another of Trump\u2019s advisers, is  a space fan who promised a Moon base  when he ran for president in 2012. Casey Dreier, director of space policy for the Planetary Society in Pasadena, California, says that space is likely to be a low priority for Trump during his first 100 days as president. Dreier will be looking instead at whether the new Congress works to cut government spending. \u201cIf that\u2019s the case, NASA will be impacted by that along with every federal agency,\u201d he says. \n               Immigration \n             Trump reinvigorated the national debate on immigration with his campaign pledges  to build a wall along the US border with Mexico  and to  temporarily ban Muslims from entering the United States . \u201cOur hope is that the rhetoric of the election was only a fa\u00e7ade for something hopeful that\u2019s going to be more pragmatic and engaging communities,\u201d says Carl Saab, a neuroscientist at Brown University in Providence, Rhode Island, and the outgoing president of the Society for Arab Neuroscientists. \u201cWhether that\u2019s going to happen or not it\u2019s too early to say.\u201d Trump has variously said that the ban would apply to all Muslims and to anyone from \u201cnations tied to Islamic terror\u201d, drawing vigorous criticism from civil-liberties groups that say applying such a policy to one religion would violate the US Constitution. He has also proposed deporting more people who are in the United States illegally, which could include those who came to the country as children. Some researchers worry that such policies would threaten US research dominance. About 5% of US university students come from other countries, including more than 380,000 people studying science, engineering, technology or mathematics. \u201cThe rhetoric that Mr Trump ran under has frightened lots of immigrants,\u201d says Benjamin Corb, director of public affairs for the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. \u201cI certainly hope that we don\u2019t end up losing some brilliant minds as a result of some near-sighted policies.\u201d Saab says that he and other Muslim scientists he knows are anxious, but waiting to see how Trump\u2019s immigration policy pans out. \u201cWe\u2019re not going to predict negative or positive outcomes for now,\u201d Saab says. \u201cWe hope that with enough conversations down the line, what we do would surface as a positive and something to nurture rather than something to suppress.\u201d  \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Donald Trump's US election win stuns scientists 2016-Nov-09 \n                   \n                     Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                   \n                     Trump\u2019s border-wall pledge threatens delicate desert ecosystems 2016-Aug-16 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     Obama overturns stem-cell ban 2009-Mar-09 \n                   \n                     Nature  special: 2016 US election \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20969", "url": "https://www.nature.com/articles/nature.2016.20969", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Journal experiments and surveys suggest scientists are coming round to the idea of publishing review reports. When Kevin Sinclair reported that 13 cloned sheep his lab had studied lived long and healthy lives 1 , he wanted to be as transparent as possible about what has been a controversial research area. Sinclair had invited journalists to see the sheep while the experiment was in progress at the University of Nottingham\u2019s School of Biosciences in Loughborough, UK. And when his paper was published, in July 2016, he agreed that  its peer-review reports  should also be made public. The developmental biologist was taking part in a trial by  Nature Communications , in which the journal offered authors the option to have their reviews published. The goal was to find out whether scientists would see the practice as a way to make research more reliable and egalitarian \u2014 or as a needless nod to transparency that could harm peer review. A few journals, such as  PeerJ , the  BMJ  and  F1000Research , already embrace open peer review in various different forms. Some forbid it. Other publishers and journals, including  Nature Communications , are treating the practice as a frigid swimming pool: they are dipping their toes in the water, but are reluctant to plunge in. \n               Positive feedback \n             So far, scientists seem willing to give open peer review a try. On 10 November,  Nature Communications  announced that around 60% of its authors in 2016 had agreed to have their reviews published, and that it would therefore  continue to offer scientists the option  \u2014 although would not make it mandatory. (Reviewers can choose to withhold their names, but cannot otherwise influence the process, besides decline to take part altogether in an 'open review' paper). Meanwhile, an online survey funded by the European Commission (EC), which is not yet published, has found that more than half of its 3,062 respondents thought that open peer review should become routine, although they expressed some qualms about specifics (see Graphic, 'Opening up peer review'). More than half said that open reports would make peer review better; nearly 20% said that this would make it worse. Almost half worried that making the identity of reviewers known would worsen the process.  One challenge is that the concept of open peer review means different things to different people, says Anthony Ross-Hellauer, an information scientist at the G\u00f6ttingen State and University Library in Germany, who ran the survey for the EC-funded  'OpenAIRE' project  on open science. Some think that it implies only naming the reviewers, but not making their reports available; others think that unsigned reports should be public, and still others argue for conducting the entire process of peer review openly and allowing anyone to contribute. \u201cIt makes it really difficult to talk about what works in what circumstances if we\u2019re not using the same language,\u201d Ross-Hellauer says. Some scientific communities seem to embrace open review reports more than others, notes Joerg Heber, executive editor of  Nature Communications . During his journal\u2019s trial, authors on more than 70% of eligible papers in ecology and evolution, molecular biology and Earth sciences adopted open reports, whereas physics papers saw the lowest uptake. \n               Experiment spread \n             For nearly two years, Dutch publisher Elsevier has published unsigned peer-review reports for five of its titles, including  Engineering Fracture Mechanics  and the  International Journal of Surgery . On the basis of that trial,  which 33% of editors said led to better reports , Elsevier plans to bring open review to other journals next year. And some journals allow reviewers to post their pre-publication reviews at other websites. One of those is  Publons.com , which  encourages scientists to make their peer reviews public , if journals permit. So far, says the site\u2019s co-founder Andrew Preston, almost 500 journals have chosen to set specific permissions policies for Publons, and 16% of these allow the full text of reviews to be posted there. Advocates say that the benefits of open peer review are straightforward. \u201cIt\u2019s about making the process fairer and more transparent, so people can be held accountable if something goes wrong,\u201d says Jonathan Tennant, a palaeontologist at Imperial College London and communications director at ScienceOpen, an open research publishing network. \n               Continued hesitation \n             But Stephen Heard, an ecologist at the University of New Brunswick in Fredericton, Canada,  has misgivings . He worries about scientists posting peer-review reports without the knowledge or permission of reviewers. Heard also says that if he knew his reviews would end up public, it would make the job harder because he would feel obliged to cut back on technical language and jargon to make the review readable to a wider audience. \u201cI would inevitably do fewer reviews,\u201d he says. It\u2019s also not clear who actually reads the reports once they are made public, Heard says. Tennant says that they\u2019re the first thing he reads after a paper\u2019s abstract, and Heber says that download figures will be assessed by  Nature Communications . (The journal is published by  Nature 's publisher, Springer Nature;  Nature \u2019s news and comment team is editorially independent of the publisher\u2019s research editorial teams). Sinclair has not yet heard from anyone who has read the peer-review report to his paper. And although his lone experience was encouraging \u2014 the reports were largely positive, and the paper sailed through review \u2014 he is not ready to become an open-peer-review evangelist. \u201cI think most people, and I would include myself, are apprehensive,\u201d Sinclair says. \u201cThis has been a new experience. As far as I\u2019m concerned, the jury\u2019s out.\u201d \n                     Let\u2019s make peer review scientific 2016-Jul-05 \n                   \n                     Peer review: Troubled from the start 2016-Apr-19 \n                   \n                     Publishing: The peer-review scam 2014-Nov-26 \n                   \n                     The scientists who get credit for peer review 2014-Oct-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20964", "url": "https://www.nature.com/articles/nature.2016.20964", "year": 2016, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Semantic Scholar triples in size and Microsoft Academic's relaunch impresses researchers. A free AI-based scholarly search engine that aims to outdo Google Scholar is expanding its corpus of papers to cover some 10 million research articles in computer science and neuroscience, its creators announced on 11 November. Since its  launch last year , it has been joined by several other AI-based academic search engines, most notably a relaunched effort from computing giant Microsoft. Semantic Scholar , from the non-profit Allen Institute for Artificial Intelligence (AI2) in Seattle, Washington, unveiled its new format at the Society for Neuroscience annual meeting in San Diego. Some scientists who were given an early view of the site are impressed. \u201cThis is a game changer,\u201d says Andrew Huberman, a neurobiologist at Stanford University, California. \u201cIt leads you through what is otherwise a pretty dense jungle of information.\u201d The search engine first launched in November 2015, promising to sort and rank academic papers using a more sophisticated understanding of their content and context. The  popular Google Scholar  has access to about 200 million documents and can scan articles that are behind paywalls, but it searches merely by keywords. By contrast, Semantic Scholar can, for example, assess which citations to a paper are most meaningful, and rank papers by how quickly citations are rising \u2014 a measure of how \u2018hot\u2019 they are. When first launched, Semantic Scholar was restricted to 3 million papers in the field of computer science. Thanks in part to a collaboration with AI2\u2019s sister organization, the Allen Institute for Brain Science, the site has now added millions more papers and new filters catering specifically for neurology and medicine; these filters enable searches based, for example, on which part of the brain part of the brain or cell type a paper investigates, which model organisms were studied and what methodologies were used. Next year, AI2 aims to index all of PubMed and expand to all the medical sciences, says chief executive Oren Etzioni. \u201cThe one I still use the most is Google Scholar,\u201d says Jose Manuel G\u00f3mez-P\u00e9rez, who works on semantic searching for the software company Expert System in Madrid. \u201cBut there is a lot of potential here.\u201d \n             Microsoft\u2019s revival \n           Semantic Scholar is not the only AI-based search engine around, however. Computing giant Microsoft quietly released its own AI scholarly search tool,  Microsoft Academic , to the public this May, replacing its predecessor, Microsoft Academic Search, which the company stopped adding to in 2012. Microsoft\u2019s academic search algorithms and data are available for researchers through an application programming interface (API) and the  Open Academic Society , a partnership between Microsoft Research, AI2 and others. \u201cThe more people working on this the better,\u201d says Kuansan Wang, who is in charge of Microsoft's effort. He says that Semantic Scholar is going deeper into natural-language processing \u2014 that is, understanding the meaning of full sentences in papers and queries \u2014 but that Microsoft\u2019s tool, which is powered by the semantic search capabilities of the firm's web-search engine Bing, covers more ground, with 160 million publications. Like Semantic Scholar, Microsoft Academic provides useful (if less extensive) filters, including by author, journal or field of study. And it compiles a leaderboard of most-influential scientists in each subdiscipline. These are the people with the most \u2018important\u2019 publications in the field, judged by a recursive algorithm (freely available) that judges papers as important if they are cited by other important papers. The top neuroscientist for the past six months, according to Microsoft Academic, is Clifford Jack of the Mayo Clinic, in Rochester, Minnesota. Other scholars say that they are impressed by Microsoft\u2019s effort. The search engine is getting close to combining the advantages of Google Scholar\u2019s massive scope with the more-structured results of subscription bibliometric databases such as Scopus and the Web of Science, says Anne-Wil Harzing, who studies science metrics at Middlesex University, UK, and  has analysed the new product . \u201cThe Microsoft Academic phoenix is undeniably growing wings,\u201d she says. Microsoft Research says it is working on a personalizable version \u2014 where users can sign in so that Microsoft can bring applicable new papers to their attention or notify them of citations to their own work \u2014 by early next year. Other companies and academic institutions are also developing AI-driven software to delve more deeply into content found online. The Max Planck Institute for Informatics, based in Saarbr\u00fccken, Germany, for example, is developing an engine called DeepLife specifically for the health and life sciences. \u201cThese are research prototypes rather than sustainable long-term efforts,\u201d says Etzioni. In the long term, AI2 aims to create a system that will answer science questions, propose new experimental designs or throw up useful hypotheses. \u201cIn 20 years\u2019 time, AI will be able to read \u2014 and more importantly, understand \u2014 scientific text,\u201d Etzioni says. \n                   Artificial-intelligence institute launches free science search engine 2015-Nov-02 \n                 \n                   Google Scholar pioneer on search engine\u2019s future 2014-Nov-07 \n                 \n                   How to tame the flood of literature 2014-Sep-03 \n                 \n                   Online collaboration: Scientists and the social network 2014-Aug-13 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20975", "url": "https://www.nature.com/articles/nature.2016.20975", "year": 2016, "authors": [{"name": "Lesley Evans Ogden"}], "parsed_as_year": "2006_or_before", "body": "Lawsuits and a new study raise questions about the project's environmental impact. The controversy surrounding a proposed liquefied natural-gas plant in British Columbia, Canada, continues to intensify. The project, which the Canadian government approved in September, now faces three separate lawsuits. And new research at the proposed site on the Skeena River estuary reveals that some salmon species spend over a month in the area, feeding and growing during their migration to the sea. In contrast, a marine fish survey conducted by Stantec Consulting on behalf of the project characterized the habitat as low value. Although Fisheries and Oceans Canada (DFO) rejected that conclusion, the agency determined that any harm from construction could be mitigated to produce only negligible impacts on salmon. The Skeena natural-gas liquefaction and export facility would be one of Canada's largest resource-development projects. It is spearheaded by an international consortium led by PETRONAS, the Malaysian state oil company. A study led by ecologist Jonathan Moore at Simon Fraser University in Burnaby, British Columbia now finds that the Skeena River estuary near the plant's proposed site is likely to be more valuable habitat for salmon populations than previously thought. The researchers used stable isotopes of sulfur, carbon and nitrogen as chemical clocks to estimate how long four salmon species spent in the area. They published their findings on 9 November in  Marine Ecology Progress Series 1 . \n             Pit stop \n           Migratory salmon pick up a freshwater chemical signal from the area where they hatch. That signal slowly changes to the chemical signature of the more brackish river mouth, where the fish stop on their seaward migration. \u201cTheir placement along that chemical signature gradient can tell us how long they've been in the estuary,\u201d says Moore. Understanding the stopover time is important, because it can tell environmental managers how important the area is to the fish, he adds. His team found that 25% of Chinook salmon ( Oncorhynchus tshawaytscha ) spent at least 33 days in the estuary, compared with 30, 22 and 5 days for pink ( O. gorbuscha ), coho ( O. kisutch ) and  sockeye  ( O. nerka ), respectively. These results confirm most of what scientists had suspected, says Charles Simenstad, a salmon expert at the University of Washington in Seattle. The study also presents a clearer picture of species such as pink and sockeye salmon that some thought didn\u2019t use estuaries very much, he adds. \n             No say \n           In three separate lawsuits filed on 27 October, environmental and indigenous groups criticized the environmental-assessment process, expressed concerns over the project\u2019s future greenhouse-gas emissions and highlighted a lack of universal support by indigenous groups. The lawsuits have requested a judicial review of the project\u2019s approval. \u201cIt\u2019s being built at a location that I think most scientists would agree is the worst possible from the perspective of fish and fish habitat,\u201d says Chris Tollefson, executive director of the Pacific Centre for Environmental Law and Litigation in Victoria, British Columbia and legal counsel for the lawsuit launched by SkeenaWild Conservation Trust. The Gitanyow and Gitwilgyoots First Nations argued in their lawsuits that the federal government failed to adequately include them in project consultations. Chief Yahaan (Donnie Wesley) of the Gitwilgyoots, one of a group of nine allied tribes, says that questions he asked about the impacts of the PNW LNG project went unanswered. Sedimentologist Patrick McLaren of SedTrend in Brentwood Bay, British Columbia, says he also felt  dismissed by government officials  at a technical consultation meeting held by the Canadian Environmental Assessment Agency (CEAA) in January 2015. The First Nations group the Lax Kw'alaams Band, representing the nine tribes, brought in McLaren as an independent consultant to review the reliability of a model used by PNW LNG to predict the construction\u2019s impact on river sediments. But when he tried to point out potential weaknesses in the PNG LNG model, McLaren says the CEAA chair of the meeting prevented him from discussing it. \n             Proceed with caution \n           The CEAA has, however, imposed more than 190 conditions under which this project will be allowed to proceed. Those include mitigation measures aimed at protecting fish species and their habitats, says Carmel Lowe, regional director of science for DFO in Nanaimo, British Columbia. But some fish scientists are sceptical, given that 'offsetting' lost habitat has had mixed success, and is particularly tricky for areas that contain eelgrass, such as the Skeena River estuary. Whether lawsuits and the low price of natural gas will halt, or only temporarily postpone, this project on the Skeena estuary remains to be seen. \n                   Scientific challenges loom for Canada\u2019s popular prime minister 2016-Oct-25 \n                 \n                   Nine years of censorship 2016-May-03 \n                 \n                   Government 'confusion' is harming sockeye salmon 2012-Nov-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20970", "url": "https://www.nature.com/articles/nature.2016.20970", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "GOES-R can snap an image every 30 seconds and will improve responses to severe storms. The most scientifically capable weather satellite the United States has ever launched is slated to soar into orbit on 19 November. From its vantage point 35,800 kilometres up \u2014 nearly one-tenth of the way to the moon \u2014 the Geostationary Operational Environmental Satellite-R Series (GOES-R) will snap images of weather and atmospheric phenomena as they roll across the United States. GOES-R can take pictures as often as every 30 seconds, much faster than the several-minute intervals of current GOES weather satellites. That rapid-fire imagery allows the satellite to track developing changes in thunderstorms, hurricanes and other severe storms. It also enables meteorologists to follow plumes of wildfire smoke or volcanic ash as they spread. And it helps emergency responders to better prepare for where to deploy resources as a storm advances, says Louis Uccellini, director of the  National Weather Service. The next-generation satellite can also take pictures with a sharper focus and in a broader range of wavelengths than the current GOES satellites. \u201cIt\u2019s like going from black-and-white to a super-high-definition television,\u201d says Stephen Volz, an assistant administrator with the National Oceanic and Atmospheric Administration (NOAA) in Silver Spring, Maryland. GOES-R is comparable to the Japan Meteorological Agency\u2019s  Himawari-8 satellite , which launched in 2014, and Himawari-9, launched on 1 November. All carry an advanced imaging instrument that observes Earth in 16 different wavelength bands, ranging from visible to near-infrared, for different views of atmospheric phenomena. Already, the images produced by Himawari-8 are enabling meteorologists to precisely measure the spread of pollutants across East Asia 1 . \n             Test runs \n           US meteorologists have been testing the new forecasting capabilities of GOES-R with the two current  GOES  satellites (there are always two operational at any given time: one positioned over the eastern United States and one over the west). At various points over the past several years, including during Hurricane Sandy in 2012, NOAA switched one of the GOES into an experimental super-fast scan mode that refreshed data as fast as every minute. By examining these test data, forecasters could better identify the beginnings of strong atmospheric mixing, a precursor to severe storms 2 , and track wildfires as they developed \u2014 sometimes dispatching firefighters before anyone even called for help 3 . Other tests tracked the appearance and decay of fog at major airports, helping flight controllers to more efficiently route planes in and out. GOES-R has other jobs as well. It carries a suite of updated space-weather instruments to measure particles streaming from solar outbursts. It also has a sophisticated  lightning  mapper to catalogue flashes day and night every 20 seconds or faster. All this technology comes at a price: nearly US$11 billion in total for GOES-R and the three similar satellites that will follow it sequentially through the year 2036. After launch, GOES-R will go into a temporary orbit as operators calibrate its instruments. Then NOAA will guide it into a permanent position over either the eastern or western part of the country. \n                   Scientists probe lightning hotspot to predict future strikes 2016-Aug-15 \n                 \n                   Mobile-phone expansion could disrupt key weather satellites 2016-Jul-12 \n                 \n                   Earth observation enters next phase 2014-Apr-08 \n                 \n                   Microsatellites aim to fill weather-data gap 2012-Nov-28 \n                 \n                   GOES-R \n                 Reprints and Permissions"},
{"file_id": "539342a", "url": "https://www.nature.com/articles/539342a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Country's progress on public health and science prompts funding shift to more-troubled nations. Rwanda has made major public-health strides since the country's genocide against the Tutsi people ended in June 1994, but declines in foreign aid now threaten that progress. Donors such as the US President\u2019s Emergency Plan for AIDS Relief and the Global Fund to Fight AIDS, Tuberculosis and Malaria have reduced assistance to Rwanda by 40% over the past three years, jeopardizing advances in a country seen as a development success story. The situation will be hotly discussed at the annual meeting of The World Academy of Sciences in Kigali on 14\u201317 November. \u201cIf the decline in funding continues, there are a lot of things to lose rather than to gain,\u201d says Sabin Nsanzimana, who manages initiatives on HIV and other blood-borne diseases at the Rwanda Biomedical Center in Kigali, which runs the country\u2019s health programmes. The declining foreign aid is part of two broader trends in development: redirecting money to countries that have the highest number of sick people, and urging developing countries to fund more of their own development work. The former has reduced aid to Rwanda, a small country that has slashed the incidence of diseases such as HIV. Like many other developing nations, Rwanda doesn\u2019t have the resources to move money from priority areas such as education into health, says Nsanzimana, citing a study by Anna Vassall, an epidemiologist at the London School of Hygiene & Tropical Medicine 1 . Vassall estimates that even if sub-Saharan African nations more than triple their spending on HIV in the next five years, most could only raise half the money they need to meet the goal set by the Joint United Nations Programme on HIV/AIDS of  ending the epidemic's global threat by 2030 . Fredrick Kateera, director of research for the Rwanda office of the non-profit organization Partners in Health, says that funding cuts could imperil the research that is needed to fight diseases such as malaria in Rwanda and elsewhere. \u201cSetting up surveillance systems costs just as much money as just giving out drugs and bed nets,\u201d Kateera says. \n               Proof of concept \n             Rwanda has long been seen as a prime example of how science can aid development. After the genocide in 1994, Rwanda's President Paul Kagame invested in building roads, high-speed Internet access and  applying science to local problems . The country slashed maternal and infant deaths, new HIV infections, AIDS deaths and mother-to-child HIV transmission 2 . Kagame has also used his authority to ensure that science conducted by local and foreign scientists promotes domestic development. In 2012, the country\u2019s ministry of health published guidelines compelling all foreign research projects to strengthen Rwandan research capacity, such as training its scientists or building infrastructure. Rwandan researchers routinely appear as first and last authors on studies conducted in the country, in contrast to other African nations where  native researchers often don\u2019t benefit from foreign collaborations . \u201cYou can\u2019t just be a global health researcher who drops in, gets some data, publishes it with your name as first author and never comes back,\u201d says epidemiologist Edward Mills of the Institute for Health Metrics and Evaluation in Seattle, Washington, and an adjunct professor at the University of Rwanda in Kigali. Staff at clinics and ministries who fail in their roles to meet stringent health targets can also be reassigned or sacked. In July, for instance, Kagame removed Agn\u00e8s Binagwaho from her post as minister of health. The highly regarded paediatrician earned the US$100,000 Roux Prize for using data to improve public health in April 2015, but was let go after malaria cases in the country quadrupled to 2 million between 2012 and 2015. \n               Shift in strategy \n             Human-rights groups have chafed at Kagame\u2019s authoritarian tendencies, but he has kept corruption low in Rwanda compared with other sub-Saharan African nations. This made the country a favourite of donors for much of the 2000s. But that shifted after 2013, when organizations such as the US Institute of Medicine questioned donors\u2019 generosity towards Rwanda compared to nations with much higher HIV burdens \u2014 such as Swaziland. In response, donors recalibrated; in 2014, for instance, the Global Fund to Fight AIDS, Tuberculosis and Malaria began using a new formula that allocated funding in part according to a country\u2019s burden of disease. In June, the fund said that it had reworked its formula again in response to protests from countries such as Rwanda that it punished them for their success. Still, Rwandan researchers are feeling the pinch. \u201cThe willingness to do research is there, but many institutions are lacking funding,\u201d says physician and molecular biologist Etienne Karita, who is country director for Projet San Francisco, an HIV-prevention programme in Kigali. Despite the funding constraints and bureaucratic restrictions, Rwandan researchers who train abroad often return to their home nation, attracted by the prospect of playing their part in rebuilding. Kateera, for instance, earned his medical degree in Uganda, where universities have partnerships with prestigious institutions in Europe, the United States and Asia. Tiny Rwanda, with one-third the population and one-ninth the area of Uganda, doesn\u2019t have that same wealth of opportunities. But Kateera feels that he can make more of a difference in Rwanda: \u201cYou can make a big impact and measure it much more easily here compared to in a larger country,\u201d he says. He and other researchers hope that donors will hear their case, and make sure that this impact continues.  \n                     Rwanda: From killing fields to technopolis 2016-Aug-31 \n                   \n                     Research: Africa's fight for equality 2015-May-05 \n                   \n                     Science in Africa: The view from the front line 2011-Jun-29 \n                   \n                     Give the new generation a chance 2011-Jun-29 \n                   \n                     The World Academy of Sciences \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20925", "url": "https://www.nature.com/articles/nature.2016.20925", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Supercomputer calculation suggests hypothesized particle may be heavier than thought. An ambitious supercomputer calculation has brought good and bad news for physicists hunting the \u2018axion\u2019 \u2014 a hypothetical particle that is considered a leading candidate for dark matter. The result shows that the axion, if it exists, could be at least ten times heavier than previously thought. If true, that\u2019s a useful clue on how to find the particle. But it also suggests that an experiment that has been hunting the axion for two decades might be unlikely to find it, because the detector was designed to search for a lighter version. The axion was hypothesized in 1977 as a potential solution to a paradox arising from how the strong nuclear force \u2014 which binds particles in the nucleus of an atom together\u2014 affects antimatter and matter. (It would explain an unexpected symmetry whereby that force has the same effect on matter as it does on antimatter.) But researchers also think that the axion might be one of the components of dark matter, the invisible stuff thought to make up about 85% of the Universe\u2019s mass. So if the particle exists, it would solve two problems at once. \n             A hunt in the dark \n           Physicists are desperately seeking  the exotic particles that constitute dark matter , which has been spotted only indirectly, by its gravitational pull on galaxies. But so far, every experiment designed to find dark matter components has  come up empty-handed  or produced  controversial results . Most of these experiments have tried to detect or produce so-called weakly interacting massive particles, or WIMPs. The  Axion Dark Matter eXperiment (ADMX)  has been leading the charge for an alternative explanation: the axion. The experiment consists of a metal cylinder that uses strong magnetic fields, which theoretically should convert some axions into photons that could be detectedin the radio-wave spectrum. It began at Lawrence Livermore National Laboratory in California in 1996, and moved to the University of Washington in Seattle in 2010. Early calculations had suggested that the axion should have a mass of around 5 microelectronvolts (\u00b5eV), about 100 billion times lighter than the electron, says Pierre Sikivie, a theoretical physicist at the University of Florida in Gainesville. So he and his collaborators designed ADMX to be most sensitive to masses in that range. But in a paper published on 2 November in  Nature 1 , Zoltan Fodor, a theoretical physicist at the University of Wuppertal in Germany, and his collaborators report the results of a large, complicated calculation showing that \u2014 under certain assumptions \u2014 the axion\u2019s mass is most likely to fall in the range between 50 and 1,500 \u00b5eV. That would put it outside the range of ADMX, which is currently sensitive to masses between about 0.5 \u00b5eV and 40 \u00b5eV. \u201cI think it is not very good news for ADMX,\u201d Fodor says. \n             A matter of inflation \n           The team used a supercomputer at the J\u00fclich Supercomputing Centre in Germany to simulate the creation of elementary particles moments after the Big Bang, going back to times when temperatures soared above a million billion degrees, ten times hotter than those achieved in previous simulations. This was when axions \u2014 if they exist \u2014 would have been produced in abundance. To get there, the team had to develop techniques to speed up their calculations, which otherwise might have taken millions of years to complete, says Fodor. The simulation allowed the team to calculate the axion\u2019s mass, under the assumption that it was created after inflation \u2014 a brief period during which the Universe expanded at an exponential rate. In a scenario in which the axion was created before inflation, the team worked out the way the particle would have formed, but were not able to deduce its mass. The paper is \u201ca tour de force\u201d, says Leslie Rosenberg, an experimental physicist at the University of Washington who leads ADMX. \u201cMy hats off to these people.\u201d If the post-inflation scenario is correct, then the team\u2019s results could mean that his experiment won\u2019t detect anything, he admits. But he adds that, in the pre-inflation case, what Fodor's team found could actually make a lighter mass more plausible, and would put it right in ADMX\u2019s \u201csweet spot\u201d. Another detector  being built at the Center for Axion and Precision Physics Research in Daejeon, South Korea , may be sensitive to higher masses, and so would the  proposed MADMAX experiment , which was first suggested by one of the co-authors of the  Nature  paper. Guido Martinelli, a theoretical physicist at the Sapienza University of Rome, agrees that it is too soon to write off ADMX\u2019s hunt entirely. Researchers are not sure which of the two scenarios \u2014 pre- or post-inflation \u2014 is more plausible, he says. Moreover, he argues, the team\u2019s results are not conclusive, even in the post-inflation scenario. \u201cSome of their assumptions are a bit hasty,\u201d he says. \u201cIt is certainly necessary for other groups to verify these results.\u201d Read the related News & Views article, \" Particle physics: Axions exposed \". \n                   Why South Korea is the world\u2019s biggest investor in research 2016-Jun-01 \n                 \n                   Controversial dark-matter claim faces ultimate test 2016-Apr-05 \n                 \n                   Largest-ever dark-matter experiment poised to test popular theory 2015-Nov-12 \n                 \n                   Dark-matter search considers exotic possibilities 2014-Jan-03 \n                 \n                   ADMX \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20873", "url": "https://www.nature.com/articles/nature.2016.20873", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "The small birds spend most of their lives on the wing. Some common swifts spend ten months in flight without taking a break, setting a flight record that would be the envy of Amelia Earhart and Charles Lindbergh. Researchers report these long hauls, which occurred during migrations between Scandinavia and central Africa, on 27 October in  Current Biology 1 . Ornithologists and birdwatchers have speculated about the long-distance prowess of common swifts ( Apus apus ) since the 1960s. People had seen the birds fill the sky in Liberia, for example, but couldn't find any nearby roost sites where the birds might land. Scientists attached tags that combined tiny data loggers and accelerometers to the 40-gram birds to record their route and flight activity during their annual journey. The team tracked 13 individual birds, some for multiple seasons, starting and ending at their breeding grounds in Sweden. The researchers found that some of the birds made a few brief night landings in winter but remained airborne for 99% of the time. Three birds didn't touch down once in the entire ten months. \u201cThese long-term flights confirm what everybody suspected for quite some time now,\u201d says Felix Liechti of the Swiss Ornithological Institute in Sempach. \n             Built to go the distance \n           Other birds can remain aloft for long periods. Alpine swifts ( Tachymarptis melba ) fly nonstop for half the year during their migrations 2 . And the much larger  frigate birds  ( Fregata minor ) off the coast of Ecuador can go for two months without landing while they forage for food in the ocean. They can even sleep on the wing 3 . But common swifts are in a class of their own. \u201cCommon swifts have evolved to be very efficient flyers, with streamlined body shapes and  long and narrow wings , generating lift force at low cost,\u201d says Anders Hedenstr\u00f6m, a study co-author and a biologist at Lund University in Sweden. The birds even eat while airborne, snatching flying termites, ballooning spiders and other aerial insects for in-flight meals. Hedenstr\u00f6m says that common swifts have adapted to a low-energy lifestyle, but his team does not yet know whether the birds sleep while aloft. \u201cMost animals suffer dramatically from far less  sleep loss ,\u201d says Niels Rattenborg, a neurobiologist at Max Planck Institute for Ornithology in Seewiesen, Germany. \u201cBut these birds seem to have found a trick through evolution that allows them to get by on far less sleep.\u201d If it weren't for an evolution in tracking devices, the secrets of these tiny birds would still be a mystery. \u201cAs the technology continues to decrease in size, it\u2019s allowing us to measure smaller species and revealing more of these astounding migratory feats,\u201d says Bill Deluca, an ecologist at University of Massachusetts, Amherst. \n                   Zoology: Wind powers weeks of non-stop flight 2016-Jul-06 \n                 \n                   Birds fly best on a full tank 2001-Oct-18 \n                 \n                   Short flight, high cost 2000-May-12 \n                 \n                   Anders Hedenstr\u00f6m's Animal Flight Lab at Lund University \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20900", "url": "https://www.nature.com/articles/nature.2016.20900", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Antarctic agreement follows years of failed discussions and represents the first major conservation effort in the high seas. It is a milestone for ocean conservation and Russia\u2019s relationship with the rest of the world. After years of unsuccessful talks, 24 nations and the European Union agreed on 28 October to create the largest marine reserve in the world, around twice the size of Texas, in the Southern Ocean off the coast of Antarctica. The international deal takes effect in December 2017 and will set aside 1.55 million square kilometres of the Ross Sea, a deep Antarctic bay 3,500 kilometres south of New Zealand, from commercial fishing and mineral exploitation. It is the first time that countries have joined together to protect a major chunk of the high seas \u2014 the areas of ocean that are  largely unregulated because they do not fall under the jurisdiction of any one nation . Signed by members of the Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR) amid cheering and applause at a meeting in Hobart, Australia, the deal became possible because of assent from Russia, which had  long blocked the agreement . \u201cRussian support of any agreement is a very positive signal in the current political situation,\u201d says Peter Jones, a specialist on marine environmental governance at University College London. Scientists hope now to see an acceleration of international marine-protection efforts around the globe, in particular, other ecologically precious regions around Antarctica. The designated reserve is a \u201cfirst dent into the notion that we can\u2019t do anything to protect the high seas\u201d, says Daniel Pauly, a marine biologist at the University of British Columbia in Vancouver, Canada, who has long sounded the alarm over the state of the world's oceans and declining fish harvests. \n               Russian U-turn \n             Members of the CCAMLR\u00a0had discussed the Ross Sea proposal since it was made by the United States and New Zealand in 2012. Observers think that Russia\u2019s change of heart might have been the result of intense, behind-the-scene discussions on the issue in recent months between US secretary of state, John Kerry, and his Russian counterpart, Sergey Lavrov. In politically turbulent times, Russia is \u201cpleased to be part of this collaborative international effort\u201d, Sergei Ivanov, special representative on ecology to the Russian President Vladimir Putin,  told the BBC . Although still relatively healthy, the Ross Sea has experienced a growth in fishing, which has begun to decimate stocks of the Antarctic toothfish ( Dissostichus mawsoni ), a predator. Also in decline is the Antarctic krill ( Euphausia superba ), a shrimp-like crustacean that is one of the largest protein sources on Earth and a key creature in the marine food web off Antarctica. The deal includes some compromises. These might have been necessary to winning the support of Russia, which operates a large fishing fleet in the region, says Jones. Most of the reserve \u2014 1,117,000 km 2  \u2014 will be closed to all commercial marine activities. But a further 322,000 km 2  \u201ckrill research zone\u201d will allow controlled fishing, known as \u201cresearch fishing\u201d and another 110,000 km 2 will be a \"special research zone\u201d open for limited fishing of both krill and toothfish. This means that although the total area of the marine reserve is bigger than the next largest \u2014 Papah\u0101naumoku\u0101kea Marine National Monument near Hawaii \u2014 the area that is completely restricted is slightly smaller. And for now, a \u2018sunset clause\u2019 specifies that the designated zone expires in 35 years, meaning it would not fully qualify as a marine protected area (MPA) under the strict rules set by the International Union for Conservation of Nature. \u201cWe do regret this,\u201d says Mike Walker, project director of the Antarctic Ocean Alliance, a campaign group, in Washington DC. \u201cBut we are confident that decision-makers will come to realize that the best way to conserve the ocean is to protect it forever.\u201d \n               Scientific praise \n             On the whole, scientists reacted enthusiastically to the decision. \u201cThis is unprecedented protection for the Southern Ocean,\u201d says Kirsten Grorud-Colvert, a marine biologist at Oregon State University in Corvallis. The Ross Sea contains one of the least-altered ecosystems on Earth, she says. But that ecosystem is vulnerable to human disturbance and the effects of climate change. \u201cSetting aside an area free from fishing stresses in this marine reserve provides a reference point and a place for research to evaluate how systems respond to climate change and to learn how to foster resilience,\u201d she says. \u201cIt means we will protect one of the last parts of the world with a functioning natural ecosystem, with a complete array of marine mammals, seabirds and other marine life,\u201d adds Pauly. But others caution that ocean protection zones alone will not stop the decline in marine biodiversity, and do not provide a solution to overfishing because they may just move fishing to another spot. \u201cIf fishing is the problem then they should reduce fishing pressure, not move it around,\u201d says Ray Hilborn, a fisheries specialist at the University of Washington in Seattle. \u201cIndeed, MPA might also stand for \u2018Move Problems Elsewhere\u2019.\u201d The CCAMLR will discuss further proposals next year to create protected zones of roughly similar size off the coast of East Antarctica and in the Weddell Sea. Chile and Argentina, meanwhile, are working on a proposal to protect the high seas surrounding the Antarctic Peninsula, the most rapidly warming part of the frozen continent. \n                     Policy: Marine biodiversity needs more than protection 2016-Jul-13 \n                   \n                     Negotiations to tame marine Wild West begin 2016-Apr-06 \n                   \n                     Third time unlucky for Antarctic protection bid 2013-Nov-01 \n                   \n                     Shock as Antarctic protection plans scuppered 2013-Jul-16 \n                   \n                     Disappointment as Antarctic protection bid fails 2012-Nov-01 \n                   \n                     CCAMLR \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20897", "url": "https://www.nature.com/articles/nature.2016.20897", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "October\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Painless rats \n           \n             Wildlife Photographer of the Year \n           \n             Maud \n             \u00a0returns \n           \n             Small world \n           \n             Fire station aflame \n           \n             Fog roll \n           \n             Southern gleaming \n           \n             Carbon credits \n           \n             Mars maven \n           Additional reporting by Smriti Mallapaty. \n                   Drone lights, cameras and sucking up to a whale 2016-Sep-30 \n                 \n                   Floods, fires, Zika and a hidden portrait 2016-Aug-26 \n                 \n                   Cruising sharks, fiery dragons and invisible dust 2016-Jul-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20898", "url": "https://www.nature.com/articles/nature.2016.20898", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Living Planet Report  predicts that by 2020, populations will have declined by two-thirds from 1970. The populations of Earth\u2019s wild mammals, birds, amphibians, fish and other vertebrates declined by more than half between 1970 and 2012, according to a report from environmental charity WWF and the Zoological Society of London (ZSL). Activities such as deforestation, poaching and human-induced climate change are in large part to blame for the decline. If the trend continues, then by 2020 the world will have lost two-thirds of its vertebrate biodiversity, according to the  Living Planet Report 2016 . \u201cThere is no sign yet that this rate will decrease,\u201d the report says. \u201cAcross land, freshwater and the oceans, human activities are forcing species populations and natural systems to the edge,\u201d says Marco Lambertini, director-general of WWF International. The main threat facing declining populations is habitat loss \u2014 caused by logging, agriculture and the disruption of freshwater systems such as rivers. Freshwater populations, which declined by 81%, are increasingly thought to be faring worse than those living in terrestrial regions. \u201cAn average decline in population abundance exceeding 80% is, frankly, terrifying,\u201d says Mike Hoffmann, senior scientist to the International Union for Conservation of Nature\u2019s Species Survival Commission in Cambridge, UK. \u201cThis is arguably the most damning evidence yet of the damage we are wreaking on our freshwater environments.\u201d \n             Data gaps \n           The analysis, which is\u00a0published every two years, pulls together data from more than 3,000 sources that consistently track populations, including short-term and long-term monitoring projects. It tracks the status of 14,152 populations of some 3,700 vertebrate species. But it does not claim to be comprehensive: although several hundred species (many of them fish) have been added since the 2014 edition, the data set has \u201cmajor geographic gaps\u201d, the report acknowledges, with much of its data concentrated in western Europe. Another bias of the study is that monitoring attention may be disproportionately focused on populations that are already declining, notes Hoffman. The overall pattern of decline will be hiding some population increases, he says. Still, Hoffmann says that the biases are likely to diminish as new monitoring schemes contribute data from under-sampled regions or species. Rhys Green, a conservation scientist at the University of Cambridge, UK, agrees that the data may have a bias, but says that the methods and data are substantially improved from the 2014 report. \u201cNo data set or statistical procedure can yield a perfect result, but this is the best indicator we have, and it is valuable for policymaking,\u201d he says. Read a previous Trend Watch: ' Investors flee as firm scraps RNA-interference drug candidate ' \n                   US endangered-species recovery surges to record high 2016-Aug-17 \n                 \n                   Biodiversity: The ravages of guns, nets and bulldozers 2016-Aug-10 \n                 \n                   Conservation: The Endangered Species Act at 40 2013-Dec-18 \n                 \n                   One-fifth of invertebrate species at risk of extinction 2012-Sep-03 \n                 \n                   Conservation offers hope for biodiversity decline 2010-Oct-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20880", "url": "https://www.nature.com/articles/nature.2016.20880", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "DSCOVR\u2019s computer may be suffering from radiation-induced glitches, months after it became the primary sentinel for incoming solar storms. A US space-weather satellite that is supposed to alert Earth to incoming solar storms has temporarily dropped offline five times in the year since it became operational. Its onboard computer may be experiencing hiccups caused unexpectedly by galactic cosmic rays. The Deep Space Climate Observatory (DSCOVR) went out of action most recently on 11 October. In each case, it unexpectedly entered a \u2018safe hold\u2019 in which scientific data stopped flowing and engineers had to scramble to try to recover the spacecraft. In total, DSCOVR\u2019s space-weather forecasting instruments have been offline for more than 42 hours since 28 October 2015, when the US National Oceanic and Atmospheric Administration (NOAA) took the spacecraft over from NASA, which built and launched it. Each outage lasts for only a few hours, and the total downtime amounts to 0.48% of its time in space \u2014 well below NOAA\u2019s requirement that the spacecraft operate at least 96% of the time. The 11 October outage did not significantly affect predictions of a minor geomagnetic storm that arrived a few days later, says Robert Rutledge, head of the forecast office at  NOAA\u2019s Space Weather Prediction Center in Boulder, Colorado . But the outages mean that DSCOVR could be offline when a major solar storm erupts, leaving Earth essentially blind to the incoming onslaught. \u201dAre they problematic? Yes,\u201d says Douglas Biesecker, a solar physicist at the Boulder centre. \n               Storm warning \n             Other heliophysics spacecraft monitor solar eruptions, but DSCOVR delivers unique information from its location at the gravitationally stable L1 point, about 1.5 million kilometres from Earth in the direction of the Sun. The spacecraft's instruments directly measure the speed, magnetic field and other properties of the charged particles streaming off the Sun. Those data translate into  better forecasts of what could happen when a solar storm hits Earth , such as disruptions to satellite electronics or fluctuations in electrical power grids. DSCOVR is NOAA\u2019s main tool for forecasting space weather, but  it began life as Triana , a NASA Earth-observing spacecraft built in the late 1990s to gaze constantly at the planet. A pet project of Al Gore, then the US vice-president, Triana was shelved in 2001, then repurposed in 2008 for NOAA\u2019s space-weather needs. \u201cIt was never designed from the beginning to be a space-weather satellite,\u201d says Steven Clarke, head of NASA\u2019s heliophysics division in Washington DC. The satellite launched on 11 February 2015 and experienced its first outage four months later, when its onboard computer spontaneously rebooted. On average, the safe holds happen every 74 days, but two came just eight days apart. They are not correlated with solar storms. A NASA internal review board convened to study the problem could not definitively pinpoint the cause, but concluded that it was most likely to be galactic cosmic rays randomly striking the spacecraft, causing high-energy ionization that reboots the computer. The computer, which was built by NASA in 2000, contains a processor card that is similar to those flying aboard many other missions and is meant to withstand the radiation hazards of deep space. \n               Knowledge gap \n             NOAA does have a back-up data stream, from the Advanced Composition Explorer (ACE) spacecraft that is also orbiting the L1 point. That was the primary source of solar-wind data until NOAA forecasters switched to DSCOVR in July. But ACE is 19 years old, and intense solar storms can swamp its forecasting instruments, causing problems when data are needed the most. NOAA has requested an extra US$1.5 million from Congress to improve how it handles DSCOVR data, including its responses to the outages. The satellite is supposed to last until 2022, when a follow-up mission is slated for launch. Historically, NOAA has cobbled together its space-weather observations where and when it could, but the US government is starting to demand a more coherent approach. On 13 October, President Barack Obama signed  an executive order  that, among other things, requires NOAA to \u201censure the continuous improvement of operational space weather services\u201d. \n                     US sharpens surveillance of crippling solar storms 2016-Sep-20 \n                   \n                     Al Gore\u2019s dream spacecraft gears up for launch 2015-Jan-14 \n                   \n                     UK bolsters defences against crippling solar storms 2013-Dec-26 \n                   \n                     DSCOVR \n                   \n                     NOAA's Space Weather Prediction Center \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20902", "url": "https://www.nature.com/articles/nature.2016.20902", "year": 2016, "authors": [{"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "The congressional races and state ballot measures that could shape US science. The presidential race  between Hillary Clinton and Donald Trump  is dominating the discussion about the upcoming US election, but it\u2019s not the only contest to watch on 8 November. Choices that voters make will influence other levels of government \u2014 and some of these decisions will steer the course of science and science policy. \n             Will Congress change hands? \n           Winning the White House is only half the battle for the next president. The political balance of the two houses of Congress \u2014 the US House of Representatives and the Senate \u2014 can determine whether a president\u2019s policies become law or die on the vine. The Republican Party currently controls both houses. But on 8 November, all 435 seats in the House of Representatives are up for grabs, as are 34 of the 100 seats in the Senate. Although the House seems likely to remain in Republican hands, a Democratic take-over of the Senate is possible. That would benefit Clinton \u2014 a Democrat \u2014 if she prevails over Trump: the latest  polls suggest she has a narrow lead . A Democratic Senate would be more likely to back her funding and policy priorities, such as increasing science spending and fighting climate change, and to approve her nominees for government posts at NASA, the National Science Foundation (NSF) and other agencies key to science. And if the Senate ends up split with 50 Democrats and 50 Republicans, the vice-president \u2014 who is also president of the Senate \u2014 would break the tie, handing control to the party that wins the White House. \n             Congressional races to watch \n           Individual House and Senate races \u2014 and retirements \u2014 are set to change the political landscape for US science agencies in subtler ways. Take  Maryland , whose senior senator, Barbara Mikulski, is retiring after 30 years in office. Mikulski is not only the highest-ranking Democrat on the powerful Senate Appropriations Committee, which formulates the Senate\u2019s spending bills. She's also the top Democrat on the Senate subcommittee that oversees funding for the NSF, NASA and the National Oceanic and Atmospheric Administration (NOAA), and has pushed to increase spending on science over the years. That interest is home-grown: NASA\u2019s Goddard Space Flight Center and several NOAA facilities, including the agency\u2019s satellite operations centre, are located in Maryland. Many Earth, climate and space\u00a0scientists\u00a0consider Mikulski to be a powerful ally. Although her replacement is likely to be a fellow Democrat, that person won\u2019t have her seniority or inherit her science-friendly committee posts. Similarly,  California  will say good-bye to Democratic senator Barbara Boxer, who has made environmental issues a focus during nearly a quarter of a century in the Senate. Boxer has led several attempts to enact comprehensive climate-change legislation as a leader of the Senate Environment and Public Works Committee; all failed in what she now says is her biggest regret as she heads into retirement. As with Mikulski, Boxer is likely to be replaced with another Democrat. In  New Hampshire , Republican senator Kelly Ayotte is fighting a close race to keep her seat. She\u2019s one of just five Republican senators who voted in favour of a 2015 amendment that declared climate change to be real\u00a0\u2014 and caused by human actions. Ayotte\u2019s track record on environmental issues is mixed: she backed the Keystone XL oil pipeline, for example. But if she loses to her Democratic opponent, the Senate will lose one of its few Republicans who believe in climate change. And in  Missouri , long-time Republican senator Roy Blunt is in a surprisingly close race with a Democratic challenger. Blunt heads the Senate panel that helps to set funding for the US National Institutes of Health (NIH), the world\u2019s largest basic-research agency. In recent years, he has pushed to increase NIH spending even as his party has sought to reduce the government\u2019s overall budget. \n             States get scientific \n             \n                   Hillary Clinton will make a fine US president 2016-Oct-19 \n                 \n                   The polling crisis: How to tell what people really think 2016-Oct-19 \n                 \n                   @ScientistTrump will make science great again 2016-Oct-19 \n                 \n                   The scientists who support Donald Trump 2016-Oct-18 \n                 \n                   The power of prediction markets 2016-Oct-18 \n                 \n                   Trump\u2019s border-wall pledge threatens delicate desert ecosystems 2016-Aug-16 \n                 \n                   Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                 \n                   Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                 \n                   Nature  special: 2016 US election \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20903", "url": "https://www.nature.com/articles/nature.2016.20903", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Continued opposition at Hawaii construction site drives the Thirty Meter Telescope\u2019s backers to consider a plan B. The Thirty Meter Telescope (TMT) could move to La Palma, in Spain\u2019s Canary Islands, if opposition from some Native Hawaiians prevents the next-generation observatory from being built atop the Hawaiian mountain of Mauna Kea, as planned. The decision, announced on 31 October by the TMT International Observatory\u2019s board of governors, creates an alternative path forward for the troubled mega-telescope. The project\u2019s opponents blocked access to the Mauna Kea site in April 2015, halting construction, although work on the telescope\u2019s components continues at sites around the world. Some Native Hawaiians regard the decision to build the TMT on Mauna Kea as  the continued desecration of a sacred mountain top  that hosts 13 other telescopes, some of which are being decommissioned. In December, Hawaii\u2019s state supreme court  nullified the permit  that would have allowed construction of the TMT to proceed. A fresh round of hearings began this month, in which TMT officials are seeking a new permit from the state\u2019s Board of Land and Natural Resources. \u201cWe\u2019ll be watching the situation in Hawaii carefully, hoping that continues to move forward,\u201d says Fiona Harrison, an astrophysicist at the California Institute of Technology in Pasadena and a member of the TMT board of governors. \u201cAnd the success of those efforts will determine whether we can build the TMT in Hawaii.\u201d \n             Running out of time \n           Mauna Kea remains the TMT board\u2019s preferred site, but the path to build the US$1.5-billion telescope there is narrowing. TMT officials want to start construction no later than April 2018. But the legal battle surrounding the telescope could drag on for months. \u201cWe just want a mountain to start building on,\u201d says Christophe Dumas, a scientist with the TMT International Observatory in Pasadena. The Observatorio del Roque de los Muchachos, on La Palma, won out for the second-place spot over San Pedro M\u00e1rtir on Mexico\u2019s Baja California peninsula and two sites in Chile. Existing infrastructure \u2014 such as a road going up the mountain, and dormitories for work crews \u2014 helped to tip the balance in La Palma\u2019s favour, Harrison says. The exact site has not yet been decided, but there is a spot just outside the current observatory boundaries that could work for the TMT, she says. \u201cWe could really move forward quickly should things not work out\u201d at Mauna Kea, she says. \n             Observing conditions \n           Because La Palma\u2019s elevation of 2,250 metres is substantially lower than that of the 4,050-metre-high Mauna Kea site, there is more atmosphere between it and the stars that the TMT would observe. This means there would be more water vapour in the telescope\u2019s line of sight that might block mid-infrared wavelengths and degrade measurements. Mid-infrared instruments, such as some proposed for the TMT, can penetrate dust-obscured areas, such as the centres of galaxies and star-forming regions. Harrison says that the telescope's operators might be able to accommodate mid-infrared astronomy by scheduling observations when conditions are best, and by developing sophisticated adaptive optics to sharpen measurements. Matt Mountain, president of the Association of Universities for Research in Astronomy in Washington DC, notes that other organizations have chosen Mauna Kea because conditions there allow infrared observing. But such considerations might not be as important now, because the James Webb Space Telescope \u2014 which works in the infrared \u2014 is slated for launch in 2018. The TMT board chose Mauna Kea in 2009 because of its superb observing conditions, including cool temperatures and low humidity. The runner-up at that time was Cerro Armazones in Chile, which the  European Extremely Large Telescope  chose the following year for its planned 39-metre observatory. A second large facility, the 24.5-metre  Giant Magellan Telescope , is under way on a different Chilean mountain. \n             Hawaii battle ongoing \n           Some Native Hawaiians have long objected to astronomical development atop Mauna Kea. Protests against the TMT  have taken on new significance  as part of a push to restore sovereignty to Native Hawaiians \u2014 and a broader movement to recognize indigenous rights. The Hawaiian proceedings about the future of the Mauna Kea site continue. Retired judge Riki May Amano is hearing testimony from both sides, despite complaints from TMT opponents that Amano has a conflict of interest because her family had maintained a membership in an astronomy-education centre in Hilo. The hearings are expected to conclude in November, at which point the state\u2019s Board of Land and Natural Resources will decide again whether to issue a construction permit. No matter the outcome, that decision is likely to be appealed to the state supreme court, a process that could take months. Work continues on the TMT\u2019s components outside of Hawaii. Meanwhile, the University of Hawaii has  announced plans to remove 3 of Mauna Kea\u2019s 13 summit observatories , in response to an order in May 2015 from Hawaii\u2019s governor. The university leases land atop the mountain as a science reserve for astronomy \u2014 an arrangement set to continue through 2033. Despite the TMT's woes, another big telescope destined for Hawaii received a rare bit of good news this month. On 6 October, the state supreme court upheld the permit that allowed the Daniel K. Inouye Solar Telescope to be built atop the mountain of Haleakal\u0101 on the neighbouring island of Maui. Its enormous telescope enclosure has already been built on the mountain, although its insides and instrumentation must be completed before the facility opens in 2019. Ramin Skibba contributed reporting from Pasadena, California. \n                   Hawaiian court revokes permit for planned mega-telescope 2015-Dec-03 \n                 \n                   The mountain-top battle over the Thirty Meter Telescope 2015-Sep-29 \n                 \n                   Hawaiian telescope project sparks protests at astronomy meeting 2015-Aug-04 \n                 \n                   Hawaii prunes Mauna Kea telescope hub 2015-Jun-02 \n                 \n                   Hawaiian telescope fight prompts new rules for Mauna Kea 2015-May-27 \n                 \n                   Hawaiian telescope project seeks way forward amid protests 2015-Apr-22 \n                 \n                   Thirty Meter Telescope \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20916", "url": "https://www.nature.com/articles/nature.2016.20916", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Cull of papers follows similar discoveries in 2015. A tranche of  58 articles  authored by 282 Iran-based researchers were retracted today by a leading scientific publisher, which said it had found signs that the peer review and publication processes had been compromised. BioMed Central (BMC) will retract 28 articles and investigate another 40, whereas Springer will pull 30 papers and investigate another 9. Both organizations are run by  Nature 's publisher, Springer Nature. ( Nature's  news and comment team is editorially independent of the publisher). The actions follow an investigation, prompted by a whistleblower, that found \u201cevidence of plagiarism, peer review and authorship manipulation, suggestive of attempts to subvert the peer review and publication system to inappropriately obtain or allocate authorship,\u201d according to a  press release .\u00a0 All the papers that Springer is retracting showed evidence of authorship manipulation and peer-review manipulation, and 70% showed evidence of plagiarism. For the BMC papers, all showed evidence of authorship manipulation, 57% showed evidence of peer-review manipulation and 93% showed evidence of plagiarism, says BMC spokeswoman Amy Bourke-Waite. Last year, Springer  retracted 64 articles  over concerns that they had been compromised by \u2018fake peer-review\u2019 schemes, in which fabricated peer-review reports were submitted from bogus e-mail addresses linked to the names of real scientists, and BMC  withdrew another 43  for similar reasons earlier in 2015. Several other major publishers have reported  similar discoveries of fake peer review . Both organizations said they would clamp down on fake peer review after those incidents, and BMC ended the practice of allowing researchers to directly suggest potential reviewers in its submission system. Now, such suggestions mostly come via a cover letter, with evidence of the potential reviewer\u2019s authenticity, says Bourke-Waite. BMC has also made it more difficult to alter the authorship of papers during the publication process, she says. The authors of the papers have been notified and some have responded, according to Bourke-Waite. The retractions appear in three Springer journals \u2013 one in  Comparative Clinical Pathology , four in the  Journal of Parasitic Diseases , and 25 in  Tumour Biology  \u2013 and four BMC journals, including 23 papers in  Diagnostic Pathology , two each in  Cancer Cell International  and the  Journal of Ovarian Research  and one in the  World Journal of Surgical Oncology . \n                   Faked peer reviews prompt 64 retractions 2015-Aug-18 \n                 \n                   Publishing: The peer-review scam 2014-Nov-26 \n                 \n                   Investigating journals: The dark side of publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "539014a", "url": "https://www.nature.com/articles/539014a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Many biologists are founding their own firms as venture capitalists show increased interest in science. Vindication was three years coming for  Ethan Perlstein . On 19\u00a0October, his California biotechnology company, Perlara, announced a deal with Novartis. The Swiss drug giant will test a compound that Perlara has identified as a possible treatment for a rare childhood disease, and will invest an undisclosed sum in the smaller firm. Numerous biotech investors turned Perlstein away before he started Perlara in San Francisco in 2014, because he wasn\u2019t the tenured professor that most venture capitalists saw as founder material. \u201cThey pretty much told me to take a hike,\u201d he recalls. But he persevered, and is now part of the vanguard of young biomedical scientists who have started companies instead of taking the conventional academic path and pursuing postdoctoral studies after their PhDs. Among the factors driving this change are an infusion of money into  early-stage biotech investing , the emergence of biotech incubators and  the scarcity of academic jobs in science . \u201cWe\u2019re starting to see a renaissance of investors embracing the idea that scientists can build businesses,\u201d says Ryan Bethencourt, programme director of IndieBio, a biotech accelerator in San Francisco that began in 2014. Previously, Bethencourt says, investors preferred to fund companies started by established professors who focused on the science, while investors installed a management team to take care of the business side. But that has changed as crucial technologies, such as genetic sequencing, have become cheaper and  lab work has become automated . The cost of starting biotech companies is falling, lowering the risk for investors to fund new science-based companies. IndieBio and Y\u00a0Combinator\u00a0\u2014 an information-technology incubator in Mountain View, California, that started accepting biotech companies in 2014 \u2014 provide funding and mentoring to entrepreneurs in exchange for shares in the companies. \n               Fork in the road \n             Y\u00a0Combinator, which provides US$120,000 in seed funding per company, invested in Perlara this year; IndieBio, which provides $250,000 per start-up, has funded 42\u00a0companies in a variety of fields. Last year, biotech firms in the United States and Europe raised $3.5\u00a0billion in early-stage financing \u2014 more than in any previous year, according to the consultancy Ernst & Young. Much of this was from investors who have already made money in technology. \u201cMost of the venture guys I know want to change the world for the better,\u201d says Dan Widmaier, co-founder and chief executive of Bolt Threads in Emeryville, California, which uses genetic engineering to manufacture textiles. Widmaier went to work for the company three days after completing his PhD in 2010. \u201cAs they see it, being able to serve up an ad faster probably isn\u2019t changing the world for the better as much as being able to solve climate change or cure disease.\u201d  Most of the venture guys I know want to change the world for the better.  Conventional academic paths are also becoming less appealing. On average, young scientists earn their first US National Institutes of Health R01 grant \u2014 the bread-and-butter support for most biomedical scientists \u2014 at the age of 42. When Anitha Jayaprakash earned her genetics PhD from the Icahn School of Medicine at Mount Sinai in New York City in 2014, she saw scientists all around her stuck in postdocs. Many had no hope of finding their own tenure-track academic jobs \u2014 a phenomenon that Perlstein has dubbed the \u201cpostdocalypse\u201d. \u201cIt gave me a very depressing feeling about the whole academic space,\u201d says Jayaprakash. So she started Girihlet, a genetic-sequencing company in Berkeley, California, that has received funding from IndieBio and other investors. Alexander Lorestani felt the same way when he left a joint graduate and medical-degree programme in 2015 to co-found Geltor in San Leandro, California, which makes a vegan alternative to animal gelatin. He and his co-founder are 29 and 30 years old, and felt ready to use science to serve humanity. \u201cI couldn\u2019t imagine waiting another five to ten years to dive into doing what I think of as my life\u2019s work,\u201d Lorestani says. It\u2019s not an easy road. Most young biotech firms fail. Widmaier says that he never expected Bolt Threads to raise $90\u00a0million and last for 6 years. He says it has been rewarding to thrive long enough to be doing groundbreaking science \u2014 and to have a rare degree of independence. \u201cAnywhere else, you join someone else\u2019s vision for what a perfect workplace is,\u201d he says. \u201cThe most valuable thing about building a company is that you get to build the place where you go to work every day.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Erika_Check \n               \n                     Synthetic biology lures Silicon Valley investors 2015-Nov-04 \n                   \n                     The future of the postdoc 2015-Apr-07 \n                   \n                     The automated lab 2014-Dec-03 \n                   \n                     Start-up investor bets on biotech 2014-Apr-23 \n                   \n                     Turning point: Ethan Perlstein 2012-Oct-03 \n                   Reprints and Permissions"},
{"file_id": "539016a", "url": "https://www.nature.com/articles/539016a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "As gene editing opens doors, plant researchers are hamstrung by the need for better ways to slip their molecular tools into cells. When crop engineers from around the world gathered in London in late October, their research goals were ambitious: to make rice that uses water more efficiently, cereals that need less fertilizer and uberproductive cassava powered by turbocharged photosynthesis. The 150 attendees of the Crop Engineering Consortium Workshop were awash with ideas and brimming with molecular gadgets. Thanks to advances in synthetic biology and automation, several projects boasted more than 1,000\u00a0engineered genes and other molecular tools, ready to test in a researcher\u2019s crop of choice. But that is where they often hit a wall. Outdated methods for generating plants with customized genomes \u2014 a process called transformation \u2014 are cumbersome, unreliable and time-consuming. Asked what hurdles remain for the field, plant developmental biologist Giles Oldroyd of the John Innes Centre in Norwich, UK, had a ready answer: \u201cThe big thing would be to improve plant transformation,\u201d he said. \u201cWhat we\u2019re all facing is this delivery problem,\u201d says Dan Voytas, a plant biologist at the University of Minnesota in Saint Paul. \u201cWe have powerful reagents, but how do you get them into the cells?\u201d At issue is the decades-old problem that it is difficult to modify plant genomes and then regenerate a whole plant from a few transformed cells. Genome-editing techniques such as CRISPR\u2013Cas9 hold out the promise of sophisticated crop engineering that would once have been unthinkable \u2014 making it all the more frustrating when researchers run up against an old roadblock. On 28 September, the US National Science Foundation (NSF) recognized this frustration by announcing that it would fund research into better transformation methods. That focus is one of four in a new plant-genome research programme that will receive a total of US$15\u00a0million. \u201cEverybody agrees that it really is the bottle\u00adneck for genome engineering,\u201d says Neal Stewart, a plant biologist at the University of Tennessee, Knoxville, who co-organized an NSF workshop about plant transformation last November. \u201cAnd I think there\u2019s enough interest now in trying to come up with ways to fix the problem for major crops.\u201d \n               Obstinate crops \n             Some plants, such as the diminutive thale cress ( Arabidopsis thaliana ), the \u2018lab rat\u2019 of plants, are easily transformed using a bacterium that can add genes to plant genomes. Researchers insert the genes they want to test into the bacterium ( Agrobacterium tumefaciens ), and then coax the microbe to infect the reproductive cells of the plant. When the plant then produces offspring, some of them express the new genes. But this does not work for many crops, and use of  Agrobacterium  triggers extra scrutiny from government agencies such as the US Department of Agriculture because it is considered a plant pest. As an alternative, researchers can use \u2018gene guns\u2019 that fire DNA-coated gold beads into plant cells. Those cells are then bathed in growth hormones and coaxed to regenerate a full plant. Some plants, such as maize (corn), readily bend to this treatment. Others, such as wheat and sorghum, do not. For recalcitrant crops, it can take months of painstaking cell-culture work \u2014 optimizing growth conditions and hormone concentrations \u2014 to regenerate the full plant. The conditions needed for success vary not only from crop to crop, but also between plants of the same species. Plant-transformation experts are a rare breed, says Joyce van Eck, one such specialist at Cornell University in Ithaca, New York. \u201cThere\u2019s a lot of art in what we do,\u201d she said at the London workshop. \u201cIt\u2019s difficult to find people with that training.\u201d Add to that a dearth of funding for new methods, and researchers are left having to rely on decades-old techniques. \n               A better way \n             But that could change as the hunt for alternatives heats up. Stewart and his collaborators have developed a robot that performs an established technique called protoplast transformation faster and more accurately than is possible by hand. The method uses enzymes to digest the cell wall, making it easier for researchers to introduce new genes. The problem of regenerating the whole plant, however, remains. Researchers used a similar approach, without robots, to perform CRISPR\u2013Cas9 gene editing in a variety of plants,  including lettuce and rice . The cell-culture steps are still difficult. Stewart says that one person in his lab laboured unsuccessfully for two years to transform a tall grass that he uses for biofuel research. But the declining cost of enzymes allows researchers to perform more experiments, and the robotics improve throughput. Stewart is so enamoured with his creation that he has  composed a song for it . \u201cIt\u2019s our baby right now,\u201d he says. Others, such as Fredy Altpeter of the University of Florida in Gainesville, are hunting for a suite of genes that, when switched on or off, would make plant cells more amenable to transformation and regeneration from culture. \u201cI think it will lead to much broader application of this technology, and will enable people who are not experts in cell culture to make those improvements,\u201d he says. But researchers can\u2019t afford to wait for those developments, says Oldroyd. His project, which aims to develop cereals that use nitrogen from the soil more efficiently, will plough through tests of hundreds of transgenes using the old, cumbersome methods. \u201cWe just have to be patient,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Beyond CRISPR: A guide to the many other ways to edit a genome 2016-Aug-08 \n                   \n                     Science stars of China 2016-Jun-20 \n                   \n                     Gene-editing surges as US rethinks regulations 2016-Apr-12 \n                   \n                     Transgenics: A new breed 2013-May-01 \n                   \n                     Nature  special: CRISPR \n                   \n                     Crop Engineering Consortium \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20924", "url": "https://www.nature.com/articles/nature.2016.20924", "year": 2016, "authors": [{"name": "Carrie Arnold"}], "parsed_as_year": "2006_or_before", "body": "Genetic analysis suggests connection between the Americas emerged millions of years earlier than previously thought. Colliding tectonic plates pushed up a strip of land from the watery abyss that once divided North and South America, forming the isthmus of Panama. But a study now hints that this happened millions of years earlier than scientists had thought. Evolutionary and population-genetics data from  Eciton  army ants, which can only travel on dry ground, suggest that the isthmus formed 4\u20138 million years ago. The research, published on 25 October in  Molecular Ecology 1 , challenges the long-held idea that the link between continents emerged no more than 3 million years ago. \u201cOur genomic data is very strong evidence that the army ants crossed this region much earlier in time than the model of the simple closure of the isthmus suggests,\u201d says Corrie Moreau, associate curator at the Field Museum in Chicago, Illinois, and co-author of the study. She notes that recent geological studies have also hinted that the isthmus may have emerged earlier than 3 million years ago. Moreau began the study as an attempt to understand diversity among army ants, top predators in many Latin American rainforests, but soon found herself in the middle of a geological controversy.  Eciton  ant queens and workers lack wings, making them unable to travel across water. New colonies form only when a queen takes half of her original colony and relocates it, a huge barrier for long-distance dispersal. \u201cShe picked the perfect species for this kind of study,\u201d says Brian Fisher, an entomologist at the California Academy of Sciences in San Francisco. \n             Genetics and geology collide \n           Moreau and her colleagues used a technique called genotyping to sequence small fragments of DNA from the genomes of multiple individuals from all nine  Eciton  species, which are found from Brazil to southern Mexico. This allowed the researchers to compare genetic variations both between species and within different individuals of the same species. Camilo Montes, a geologist at the University of the Andes in Bogot\u00e1, Colombia, notes that the date of isthmus formation suggested by the genetic study is in line with results he obtained from dating uranium in zircon crystals preserved in rocks near the isthmus. \u201cThis molecular data is completely independent of our geological results. It provides another view of how these events happened, which is why this study is so important,\u201d he says. Other recent biological and geological evidence also suggests that the isthmus emerged earlier, through a more complex process, than previously thought. That evidence includes fossil teeth from ancient monkeys, which suggest that the  primates crossed the gap between the continents 18 million years ago . And 20-million-year-old plant fossils found during the excavation of the new Panama Canal in 2012 also challenge the accepted age of the isthmus 2 . Still, these results can\u2019t and won\u2019t end the debate among geologists. Fisher notes that a sister group of army ant,  Neivamyrmex , was able to travel to the Caribbean, perhaps rafting over on large debris from hurricanes or landslides. This leaves the option open for  Eciton  as well, especially if the gap between continents was relatively small. Anthony Coates, a geologist at the Smithsonian Tropical Research Institute in Panama City, is sceptical of any evidence contradicting the isthmus\u2019s 3-million-year age. \u201cThere are still a series of investigations in different disciplines that all converge on the same number of around three million years ago. This is extremely rigorous evidence,\u201d Coates says. The geological battle lines, it seems, have been drawn. Whether they can form an ideological land bridge similar to the physical one that researchers are studying remains to be seen. \n                   Monkey teeth tell tale of ancient migration 2016-Apr-20 \n                 \n                   Why the tropics are an evolutionary hotbed 2013-Apr-26 \n                 \n                   Species mix across Panama Canal 2004-Aug-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20926", "url": "https://www.nature.com/articles/nature.2016.20926", "year": 2016, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "New equation also suggests way to predict a researcher's potential to produce top work. Hoping that your next paper will be the big one? It just might be \u2014 the chance that your next article will be your best-cited is as good as ever, no matter where you are in your career. That\u2019s the finding of a team led by Albert-L\u00e1szl\u00f3 Barab\u00e1si at Northeastern University in Boston, Massachusetts. The researchers analysed the papers of thousands of scientists from different disciplines. Considering their publication records as a sequence of articles, the most highly-cited were equally likely to be found at the beginning, middle or end of the sequence 1 . \u201cWe scientists are random,\u201d Barab\u00e1si says. \u201cEvery time we publish a paper, we have the same chance of publishing our biggest hit as we do with any other paper.\u201d This might seem to conflict with the well-documented finding that big discoveries and high-impact work tend to happen early in a scientist\u2019s career. But there\u2019s no contradiction, because the new work also shows that productivity \u2014 the number of papers produced per year \u2014 tends to slowly decline over a typical career. A scientist\u2019s chance of securing a \u2018greatest hit\u2019 accordingly decreases over time, simply because they have fewer shots at it. \n             Innate potential? \n           But the researchers also make a more contentious calculation. They devise a simple mathematical model that describes the probability that any particular paper will be a hit. This depends on only two factors, they argue: an element of luck, and a certain quality, or  Q  factor, that measures an individual scientist\u2019s ability to boost the impact of any project. Testing their model against the publication records of 2,887 physicists, the team found that the equation implies that the \u2018luck\u2019 factor is the same for all scientists. The  Q  factor is obtained from a researcher\u2019s citation record: it is proportional to the logarithm of the number of citations that a scientist has received over a certain time frame. The researchers anticipated that  Q  would increase over the course of a scientific career, as an individual becomes more experienced. To their surprise, they found that it remains mostly constant. That\u2019s shocking because it seems to imply that  Q  \u2014 the multiplier that makes someone capable of capitalizing on luck to produce a big hit \u2014 is a quality that a scientist brings to their work at the outset, and which they cannot easily change thereafter. \u201cI hate to call it innate,\u201d Barab\u00e1si says, \u201cbut it seems to be a combination of your ability and education. Once you start your career, you have it and it stays with you.\u201d And it does seem to carry predictive value: high  Q  values pick out Nobel laureates and other prize-winning physicists more reliably than do other metrics, such as the widely-used  h -index, which measures cumulative productivity and the impact of publications. (A scientist with an  h -index of 20 has published 20 papers, each of which has at least 20 citations. Q  is predictive even early in a scientific career, the team says. Calculating a scientist\u2019s  Q  value after they have published 20 papers enables accurate prediction of what their  h -index will be after 40 papers for 74% of researchers studied. But a high  Q  alone doesn\u2019t guarantee a glittering career. Scientists need to sustain their motivation, too: the chance of writing a \u2018hit paper\u2019 depends not just on Q and a degree of luck but also on productivity. \u201cThe novelty here is that one can extract a measure of individual potential that could indicate whether or not someone will ever achieve greatness, if she has not already,\u201d says Santo Fortunato, a physicist who specializes in informatics at Indiana University Bloomington. \n             Predicting impact \n           Barab\u00e1si and his colleagues have previously described a model that allows them to  predict how many citations a paper will gain  on the basis of its previous citation history 2 . But attempts to predict scientists\u2019 future performance have had  mixed results . Q,  then, might be destined to join the group of indices \u2014 the  h -index most prominently among them \u2014 by which scientists are ranked and potentially assessed. Barab\u00e1si has mixed feelings about whether that\u2019s a good thing, but says that it is up to the community to decide how  Q  is applied. If metrics are to be used at all, he says, then diversity is good, not least because it can avoid over-dependence on a few metrics that might be applied beyond their limitations. \u201cThe h-index is not always being well used,\" he says. \u201cI wouldn\u2019t favour the idea of supporting only the highest- Q  scientists,\u201d says Anthony van Raan, who conducts quantitative studies of science at Leiden University in the Netherlands. But he admits that such preferential support \u201ccould be interesting in this time of so many scientists and restricted resources\u201d. But perhaps, says Barab\u00e1si,  Q  is already a kind of selection factor, whereby individuals with a low  Q  score drop out of an academic scientific career at an early stage. The challenge now, he feels, is to work out what determines  Q . If education does indeed play a big part, then maybe the knowledge can be used to assess and improve the way scientists are trained. \n                   Divinations of academic success may be flawed 2013-Nov-08 \n                 \n                   Who is the best scientist of them all? 2013-Nov-06 \n                 \n                   Formula predicts research papers' future citations 2013-Oct-03 \n                 \n                   Halt the avalanche of performance metrics 2013-Aug-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20929", "url": "https://www.nature.com/articles/nature.2016.20929", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Multi-lab experiment fails to validate decades-old report that facial expressions can affect emotional state. A large, multi-lab replication study has found no evidence to validate one of psychology\u2019s textbook findings: the idea that people find cartoons funnier if they are surreptitiously induced to smile. But an author of the original report \u2014 published nearly three decades ago \u2014 says that the new analysis has shortcomings, and may not represent a direct replication of his work. In 1988, Fritz Strack, a psychologist now at the University of W\u00fcrzburg, Germany, and colleagues found that people who held a pen between their teeth, which induces a smile, rated cartoons as funnier than did those who held a pen between their lips, which induced a pout, or frown 1 . Strack chose cartoons from Gary Larson's classic 1980s series,  T he Far Side . Strack\u2019s study has been quoted as a classic demonstration of what\u2019s known as the \u2018facial feedback hypothesis\u2019 \u2014 the idea that facial expressions can influence a person\u2019s own emotional state. The paper has been cited more than a thousand times, and has been followed by other research into facial feedback. In 2011, for example, researchers reported that injections of Botox, which affects the muscles of facial expression, dampen emotional responses 2 . But as part of  a growing trend to reproduce famous psychology findings , a group of scientists revisited the experiment. They describe the collective results of 17 experiments, with a total of nearly 1,900 participants, in a paper published on 26 October in the journal  Perspectives on Psychological Science 3 . \n             Funniness ratings \n           Overall, the experiments found no difference in the way people with pen-induced smiles or frowns rated the cartoons. And 16 of the experiments tested enough people for there to be statistical confidence that even if the studies had been repeated many more times, the researchers would have found the same null result, says Eric-Jan Wagenmakers, a psychologist at the University of Amsterdam who led the analysis. \u201cIt\u2019s quite convincing,\u201d he says. But Strack disagrees. He wrote a commentary 4 , which was published along with the replication study, in which he argued that the studies may have been affected by two potential shortcomings. Unlike in the 1988 study, the experimenters used a video camera to record the participants in order to exclude those not holding the pen correctly, which could have made them self-conscious and suppressed their emotional responses. And Strack says that  The Far Side  cartoons may have been dated or inappropriate for the participants, who were university students in multiple countries. Wagenmakers defends the researchers\u2019 selection of cartoons. \u201cWe piloted them to make sure they\u2019re not hilarious and they\u2019re not boring; otherwise you won\u2019t see an effect. They need to be medium funny,\u201d he says. He adds that the cartoons that the experimenters picked, which were different to those used by Strack, had similar funniness ratings. Because of such differences, however, Strack says \u201cthere\u2019s no such thing as a real direct replication\u201d of his work. If later researchers use different participants, offer different stimuli or have other different conditions, that could matter \u2014 especially if the induced emotion effect is subtle. If he were to test facial feedback again, he says, he wouldn\u2019t use the pen experiment \u2014 the Botox study, for example, may be a better test. \n             Pre-registered replications \n           The study is one of several multi-lab efforts to replicate psychology findings, after the field was rocked by  high-profile accusations of fraud and faulty statistical analyses . Last year, hundreds of psychologists reported attempts to replicate the findings of 98 papers, and said that  they could validate fewer than half of them . Like some other replication efforts, Wagenmakers\u2019 project had its protocol vetted \u2014 and published details of that protocol \u2014 before the independent validation studies began. The teams agreed in advance to publish the results regardless of the outcome, and also to  make their data and analysis available online . Strack had originally agreed to work with the scientists who were replicating his study by providing his experiment\u2019s materials to help them to develop their own, as well as their analysis plan. But he later withdrew, saying that the replication would benefit from a division of labour, and Ursula Hess, a psychologist at Humboldt University of Berlin, vetted the study\u2019s procedures instead. Although the new study did not replicate Strack\u2019s original finding, Wagenmakers says that he does not believe that the facial feedback theory is necessarily wrong. He thinks that there may be problems with the \u2018pen-in-mouth\u2019 method used to explore the effect. For example, he says, getting people to hold pens in particular ways can sometimes cause them to drool, which could obscure their reactions to cartoons. But the failed replication still challenges the original work, he says: \u201cThe ball is now in the court of the proponents.\u201d \n                   Psychologists fail to replicate well-known behaviour linked to learning 2016-Sep-26 \n                 \n                   Go forth and replicate! 2016-Aug-24 \n                 \n                   1,500 scientists lift the lid on reproducibility 2016-May-25 \n                 \n                   Psychology\u2019s reproducibility problem is exaggerated \u2013 say psychologists 2016-Mar-03 \n                 \n                   How many replication studies are enough? 2016-Feb-26 \n                 \n                   Over half of psychology studies fail reproducibility test 2015-Aug-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20930", "url": "https://www.nature.com/articles/nature.2016.20930", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Computerized search of trial registry lists worst offenders. An automated tool has trawled through thousands of records on the world\u2019s leading clinical-trials database to reveal which drug firms and academic institutions are failing to publish the results of their trials (see 'Unreported clinical trials'). The failure is already well documented: multiple studies have variously reported that 25\u201350% of clinical-trial results remain unpublished years after the trials are completed. And in September, the  US Department of Health and Human Services announced tougher rules  to push the researchers that it funds to publish clinical-trial designs and results. But software, such as the tool described in a paper published online at  F1000Research 1  on 3 November, allows for a more comprehensive search than was previously possible, says the paper's corresponding author Ben Goldacre, a clinical-research fellow at the University of Oxford, UK. (The publication has yet to be peer reviewed.) Automating the process also means that results can be updated regularly, which keeps the pressure on trial sponsors who fail to report \u2014 and enables them to take action to improve their scores. \n               Unreported clinical trials \n               \u201cIf anyone wants to improve their score or improve their ranking, all they have to do is publish their results,\u201d says Goldacre. \n               Computerized check \n             Goldacre and his Oxford-based co-author Anna Powell-Smith developed the tool to search the  ClinicalTrials.gov  database for trials that were completed at least two years ago. The computer then attempted to match those trials with results published in that database or in the research repository PubMed.\u00a0 Of nearly 26,000 trials evaluated, 45.2% had no published results. The team also built  a website  that enables users to view clinical-trials sponsors in order of who is the best \u2014 or worst \u2014 at publishing their results. The lists contain a mix of academic and industry sponsors from around the world. Automated, rather than manual, analyses are increasingly the norm for studies that scan for clinical-trial transparency, says Jennifer Miller, a medical ethicist at New York University\u2019s Langone Medical Center. She points to the  Good Pharma Scorecard  initiative, founded by Bioethics International, a charity that Miller founded. The initiative ranks new drugs and companies on clinical-trial transparency, on the basis of automatic analyses and machine learning. But it is careful to check its work manually and to confirm its findings with clinical-trial sponsors, she says. The Scorecard, she says, searches other clinical trials registries and research databases, including Google Scholar, which could capture a bigger pool of trials and papers than does Goldacre's tool. Automating the search can lead to a sacrifice in precision, Goldacre acknowledges. For example, the search might miss published results if they are not tagged with a number assigned by the  ClinicalTrials.gov  database, or if the journal in which they are published is not listed in the research repository PubMed. But although Goldacre says that his team did find some discrepancies in how individual studies were scored, overall trends from his tracker are similar to those previously published by manual surveys on smaller subsets of data. And he hopes that the ability to regularly update results will incentize trial sponsors to improve their score. \u201cThis is such a serious business,\u201d he says. \u201cWe need to maintain the pressure.\u201d \n                     Europe\u2019s drug regulator opens vaults of clinical-trials data 2016-Oct-20 \n                   \n                     US toughens rules for clinical-trial transparency 2016-Sep-16 \n                   \n                     Academics fall short in reporting results of clinical trials 2016-Feb-22 \n                   \n                     Make journals report clinical trials properly 2016-Feb-02 \n                   \n                     Trials Tracker \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20933", "url": "https://www.nature.com/articles/nature.2016.20933", "year": 2016, "authors": [{"name": "Kendall Powell"}], "parsed_as_year": "2006_or_before", "body": "In an online poll, almost two-thirds of readers say they have considered quitting research. A poll answered by thousands of  Nature  readers suggests that nearly two-thirds have considered quitting research, and that almost 40% work more than 60 hours in a week. The fight for funding is the greatest challenge facing early-career scientists, readers said. When researchers were asked how the challenges in research have influenced their careers, 65% said they had considered quitting research, and 15% that they had actually quit. Around one-third felt that they had been judged solely on the number of papers they had published, and another one-third said that they had published a paper they were not proud of. And 16% said they had cut corners in research. (Readers could choose more than one answer.) The online poll accompanied a News Feature published last week on the  frustrations that young investigators face  in starting up their own research groups. \u201cThe numbers are definitely sobering. But I don\u2019t know if they are surprising, given how long these issues have been discussed,\u201d says Chris Pickett, director of the advocacy organization Rescuing Biomedical Research in Washington DC. He says that the survey reflects that \u201cthe reality of a career in science doesn\u2019t add up to what most expected it to be when they started\u201d. Pickett says that the fall-out from these pressures could increase suspicion about the quality of scientific results and suppress creativity. \u201cIf people feel they have to check boxes for securing grants or publishing papers, they\u2019re not necessarily going to be as creative if that would risk continuing their livelihood.\u201d When asked to choose the biggest challenge facing early-career scientists, 44% of some 12,000 respondents overwhelmingly picked \u2018the fight for funding\u2019. This result aligns closely with the answers of the 3,000-plus people who responded to  Nature \u2019s 2016 salary survey , just under half of whom ranked \u2018competition for funding\u2019 as the biggest challenge to their career progression. The next biggest challenges identified in the reader poll, \u2018lack of work\u2013life balance\u2019 and \u2018progression judged too heavily on publication record\u2019 received just under one-fifth of the total vote each. Jon Lorsch, head of the US National Institute of General Medical Sciences in Bethesda, Maryland, says that the survey results echo what he hears from early-career scientists as he travels the country. \u201cWe risk losing a generation of researchers at the prime of their creativity and energy.\u201d He points to the skewed distribution of grant funding in investigators funded by the US National Institutes of Health as a large factor. The top 20% of investigators share 58% of the funding, he says, and the other 80% have to divvy up the rest. \u201cTo support more scientists \u2014 including the next generation \u2014 we need to redistribute some of the grant dollars from the most well-funded labs,\u201d says Lorsch. \u201cWe also need to find ways to improve the stability of funding for investigators. That\u2019s how we will get the best science and ensure a healthy scientific enterprise for the future.\u201d Finally, it\u2019s no surprise that scientists work long hours. But just how long came as a bit of a shock: almost 5,000 of nearly 13,000 responses (38%) say they work upwards of 60 hours per week. \u201cIt\u2019s bad for science that research positions are so undesirable compared to the alternatives,\u201d says a reader with an MD\u2013PhD who lives in the United States and is contemplating quitting research in favour of practising medicine and asked for their name to be withheld. \u201cThere are an incredible number of talented brilliant individuals who have and will continue to bypass a research career for a more desirable alternative. There is no question that science as a whole suffers from this fact.\u201d \n                   Young, talented and fed-up: scientists tell their stories 2016-Oct-26 \n                 \n                   Early-career researchers need fewer burdens and more support 2016-Oct-26 \n                 \n                   Young scientists under pressure: what the data show 2016-Oct-26 \n                 \n                   Salaries: Reality check 2016-Sep-21 \n                 \n                   The future of the postdoc 2015-Apr-07 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20932", "url": "https://www.nature.com/articles/nature.2016.20932", "year": 2016, "authors": [{"name": "Inga Vesper"}], "parsed_as_year": "2006_or_before", "body": "Calculation suggests papers with women first-authors have citation rates pushed down by 10%. Citation rates in astronomy are stacked against women, a study that uses machine learning to quantify bias has found. Researchers from the Swiss Federal Institute of Technology in Zurich, Switzerland, estimate that, as a result of gender bias, papers whose first authors are women receive around 10% fewer citations than do those that are first-authored by men. Gender disparities in citation patterns have been  documented across science  before. But researchers have not previously tried to quantify how much of the differences are the result of gender bias. For instance, men and women may publish different types of papers; women may work in different scientific fields, and may hold less-senior positions. But the new paper, which has not yet been peer-reviewed and was posted on the arXiv preprint server on 27 October 1 , tries to account and correct for these factors. The authors declined to comment on the paper, because they hope to submit it to  Nature Astronomy . But other specialists say that the analysis seems solid. \u201cThe novelty of this paper is in dispelling the myth that gender disparity in citation can be attributed to specifics of the paper, rather than to gender,\u201d says Cassidy Sugimoto, an informaticist at Indiana University Bloomington. Sugimoto has also published work on gender bias in science publications 2 , and says that the paper\u2019s findings are \u201cat once both terrible and terrific\u201d. \n             Estimating gender bias \n           For their study, the researchers analysed 200,000 papers in 5 journals from 1950 to 2015. First, they trained a machine-learning algorithm to accurately calculate the citations for each paper first-authored by a man using as many non-gender-related factors as possible \u2014 such as the journal, field and year in which the paper was published, where the first author was located and for how many years that author had been publishing. Then they unleashed their algorithm on the papers with female first authors. This set of papers (from 1985 onwards) had actually received around 6% fewer citations than their male-authored counterparts. But the algorithm predicted that the papers should have got 4% more citations than did those authored by men. The authors say that the result is their \u201cbest effort\u201d to measure gender bias, but that their results should be taken with care, because other factors might need to be weighed into their algorithm. \u201cThis means women and men of equal quality will have unequal records,\u201d says Meg Urry, director of Yale Center for Astronomy and Astrophysics in New Haven, Connecticut, who gave advice to the Swiss researchers as they conducted their study. She adds that being cited less is likely to result in fewer grants, invitations to talks and recommendation letters. \u201cGiven how heavily our hiring process depends on these metrics, it\u2019s not surprising that women have not reached equity in academia,\u201d she says. \n             Suppressed citations \n           A good track record of citations is essential for research career progression, so the findings could go some way towards explaining the dearth of women in senior academic positions, says Karen Masters, an astronomer at the University of Portsmouth, UK. \u201cI have had people tell me that they won't shortlist for permanent faculty jobs unless the candidates have 100 citations on a first-author paper,\u201d she says. \u201cSo, I think it's really in getting on shortlists for jobs that this suppression in citation rate for women is going to be hurting them.\u201d The new study also notes that women publish 19% fewer articles than men in the 7 years after their first published paper. Astrophysicist Anna Scaife, who heads the Interferometry Centre of Excellence at Jodrell Bank observatory in the United Kingdom, says that this factor could be even more damaging than the low citation rates. \u201cThe 4\u20136 years following PhDs are crucial for producing the output that contributes to their first application for a permanent position,\u201d she says. To address the problem, Masters suggests a solution straight from the astronomer\u2019s toolbox. The number of citations that women receive, she says, could be multiplied by 1.1 to eradicate the intrinsic bias. \u201cWe often correct systematic biases like that empirically in trends we view in astronomy,\u201d she says. \u201cSo I think this could be treated similarly.\u201d \n                   Gender bias found in Earth-science society journals 2016-Sep-29 \n                 \n                   Hubble telescope time preferentially goes to men 2014-Sep-19 \n                 \n                   Bibliometrics: Global gender disparities in science 2013-Dec-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20861", "url": "https://www.nature.com/articles/nature.2016.20861", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Researchers sift through clues after Schiaparelli crash in hopes of averting mistakes in 2020 mission. Photos of a huge circle of churned-up Martian soil  leave few doubts: a European Space Agency (ESA) probe that was supposed to test landing technology on Mars crashed into the red planet instead, and may have exploded on impact. The events of 19 October may be painful for ESA scientists to recall, but they will now have to relive them over and over again in computer simulations. The lander, called Schiaparelli, was part of ESA's ExoMars mission, which is being conducted jointly with the Russian Space Agency Roscosmos. It was a prelude to a planned 2020 mission, when researchers aim to land a much larger scientific station and rover on Mars, which will drill up to 2-metres down to look for signs of ancient life in the planet\u2019s soil. Figuring out Schiaparelli\u2019s faults and rectifying them is a priority, says Jorge Vago, project scientist for ExoMars. \u201cThat\u2019s super important. I think it\u2019s on everybody\u2019s mind.\u201d \n               Anatomy of a crash \n             Unlike the British-led and ESA-operated Beagle 2 mission, which  disappeared during its landing  on Mars on Christmas Day 2003, Schiaparelli sent data to its mother ship during its descent. Preliminary analysis suggests that the lander began the manoeuvre flawlessly, braking against the planet\u2019s atmosphere and deploying its parachute. But at 4 minutes and 41 seconds into an almost 6-minute fall, something went wrong. The lander\u2019s heat shield and parachute ejected ahead of time, says Vago. Then thrusters, designed to decelerate the craft for 30 seconds until it was metres off the ground, engaged for only around 3 seconds before they were commanded to switch off, because the lander's computer thought it was on the ground. The lander even switched on its suite of instruments, ready to record Mars\u2019s weather and electrical field, although they did not collect data. \u201cMy guess is that at that point we were still too high. And the most likely scenario is that, from then, we just dropped to the surface,\u201d says Vago. The craft probably fell from a height of between 2 and 4 kilometres before slamming into the ground at more than 300 kilometres per hour, according to estimates based on  images of the probe\u2019s likely crash site , taken by NASA\u2019s Mars Reconnaissance Orbiter on 20 October. The most likely culprit is a flaw in the craft\u2019s software or a problem in merging the data coming from different sensors, which may have led the craft to believe it was lower in altitude than it really was, says Andrea Accomazzo, ESA\u2019s head of solar and planetary missions. Accomazzo says that this is a hunch; he is reluctant to diagnose the fault before a full post-mortem has been carried out. But if he is right, that is both bad and good news. European-designed computing, software and sensors are among the elements of the lander that are to be reused on the ExoMars 2020 landing system, which, unlike Schiaparelli, will involve a mixture of European and Russian technology. But software glitches should be easier to fix than a fundamental problem with the landing hardware, which ESA scientists say seems to have passed its test with flying colours. \u201cIf we have a serious technological issue, then it\u2019s different, then we have to re-evaluate carefully. But I don\u2019t expect it to be the case,\u201d says Accomazzo. The ExoMars team will try to replicate the mistake using a virtual landing system designed to simulate the lander\u2019s hardware and software, says Vago, to make sure that scientists understand and can deal with the issue before redesigning any aspects of ExoMars 2020.\u00a0 \n               2020 vision \n             The rover mission has already been delayed by two years, owing to hold-ups on both Russian and European sides, but Vago believes that making tweaks to its design will not push the mission back. \u201cAt this point, no one wants to think about flipping to 2022. It was painful enough to go from 2018 to 2020,\u201d he says. The 2020 mission still has a budget shortfall of around \u20ac300 million (US$326 million), which ESA will request from European Union member states at a meeting of ministers in December. Asked at a press briefing on 20 October whether Schiaparelli\u2019s failure would jeopardize the mission, ESA director general Johann-Dietrich W\u00f6rner said it wouldn\u2019t have any impact. \u201cWe have the function which we need for the 2020 mission, so we don\u2019t have to convince them, we just have to show them,\u201d he told reporters. But Vago is more pragmatic. \u201cIt would have been much nicer to be able to go to the ministers with a mission where both elements had performed flawlessly.\u201d ESA is keen to stress that overall, the ExoMars mission can be seen as a triumph: Schiaparelli sent back test data from the majority of its descent, and its sister craft \u2014 the Trace Gas Orbiter \u2014 successfully manoeuvred into Martian orbit. The orbiter is the more scientifically valuable of the two halves of the mission: from December 2017, it will study Mars\u2019s atmosphere, aiming to find evidence for possible biological or geological sources of methane gas. It will also be a communications relay for the 2020 rover. \u201cAs it is, we have one part that works very well and one part that didn\u2019t work as we expected,\u201d says Vago. \u201cThe silver lining is that we think we have in hand the necessary information to fix the problem.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Mars lander\u2019s potential crash site spotted 2016-Oct-21 \n                   \n                     Europe\u2019s probe feared lost on Mars 2016-Oct-19 \n                   \n                     Europe and Russia prepare for historic landing on Mars 2016-Oct-17 \n                   \n                     Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                   Reprints and Permissions"},
{"file_id": "538303a", "url": "https://www.nature.com/articles/538303a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Five years in, the US EarthCube programme has struggled to deliver on its promises. A US National Science Foundation programme to help geoscientists handle ever-increasing amounts of data is facing a mid-life crisis. Called EarthCube, the five-year-old geoinformatics effort was conceived as a game-changer: it would put obscure data online, link and enrich existing databases across disciplines and develop software tools for scientists. But in March, an external advisory panel warned that EarthCube still lacked a clear definition and might not be sustainable. The project\u2019s leaders have been working to overhaul it, and by the end of this month they aim to release what could be a make-or-break plan for the US$13-million programme. \u201cWe need to make changes in order to show progress and to pull the community back in,\u201d says Kerstin Lehnert, a geologist at the Lamont\u2013Doherty Earth Observatory in Palisades, New York, who heads EarthCube\u2019s leadership council. \u201cWe have to make this work, now.\u201d EarthCube is the broadest effort yet to bring US geoscience into the modern data era. Some fields are more up to date than others, says Catherine Constable, a palaeomagnetist at the Scripps Institution of Oceanography in La Jolla, California, who co-led the recent review. She notes that US seismologists have  compiled their earthquake recordings  into well-managed products that are easy to access, whereas geochemists tend to  collect individual measurements on individual rock samples  that stay mostly in their labs. \u201cThere are areas of geoscience with data hidden away in people\u2019s drawers,\u201d Constable says. EarthCube is supposed to change that by providing tools to give scientists access to rich troves of otherwise-hidden data. \u201cIt\u2019s the embodiment of a vision that many of us have had for many years,\u201d says Dawn Wright, a marine geologist and chief scientist at Esri, a data-mapping company in Redlands, California. \u201cBut there are a lot of growing pains.\u201d The programme\u2019s early efforts focused on integrating data across disciplines. The iSamples initiative built a rich database describing physical samples, from  sea-floor cores  and river-water samples to fossils, so that researchers could track studies being done with each specimen. The GeoLink project developed a way to mine information from published resources, including research papers, field reports and laboratory analyses. But many say that EarthCube has yet to deliver on its early promise. Charles Connor, a volcanologist at the University of South Florida in Tampa, received EarthCube funding to develop software tools for tracking ash and other volcanic hazards, but says his colleagues are happy with the popular VHub.org research platform. And an ambitious computer-science effort called CINERGI, which was meant to compile data sets and documentation across many fields, has yet to move beyond pilot demonstrations. EarthCube may be a victim of its ambition, trying to do too much for too many people. The March review noted that five years in, the programme still had poorly defined goals. \u201cThere wasn\u2019t a uniform vision of what they wanted to do,\u201d Constable says. That may be because EarthCube has been a grass-roots effort, led by a small group of passionate volunteers. The review recommended reorganizing with fewer leaders to set clear priorities for the entire research community. Lehnert says that EarthCube\u2019s leaders are taking the criticism to heart. They pulled together a rapid-response team that has been outlining ways to restructure the programme, including introducing metrics \u2014 such as the number of software downloads \u2014 to assess its performance. There will be more details in the draft plan set for release later this month, she says. \u201cPeople need to be patient. EarthCube will help tremendously, but development does take time.\u201d Eva Zanzerkia, the EarthCube programme manager at the NSF, notes that technology develops rapidly, whereas the social aspects of sharing data take a while to develop. \u201cThis contrast is something EarthCube grapples with regularly,\u201d she says. There are some promising EarthCube tools on the horizon. Constable points to the Geoscience Papers of the Future project, which encourages researchers to publish their findings with all the metadata and tools needed for others to replicate their studies. It launched in 2015 and is run by early-career scientists who are pushing for transparency in research. Five years from now, EarthCube should be nimble enough to quickly give scientists the rich, interlinked data they need, says Lisa Park Boush, a palaeobiologist and palaeoclimatologist at the University of Connecticut in Storrs who helped to set up the programme. \u201cWe\u2019ll be able to do in an easy way what would take days, weeks or months now,\u201d she says. \n                     Democratic databases: science on GitHub 2016-Oct-03 \n                   \n                     Interactive notebooks: Sharing the code 2014-Nov-05 \n                   \n                     'Boot camps' teach scientists computing skills 2014-Sep-03 \n                   \n                     Going paperless: The digital lab 2012-Jan-25 \n                   \n                     Blogpost: US seeks to unleash power of \u2018big data\u2019 \n                   \n                     EarthCube \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20816", "url": "https://www.nature.com/articles/nature.2016.20816", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Caupchin monkeys in Brazil unintentionally make rock fragments that resemble ancient stone tools. In January, archaeologist Tomos Proffitt was examining a set of stone artefacts that his colleague Michael Haslam had brought to him. Some of the quartz pieces looked like sharpened stone tools made by human relatives in eastern Africa, some 2\u20133 million years ago. But Haslam told Proffitt that the artefacts had been made the previous year by capuchin monkeys in Brazil. \u201cI was pretty gobsmacked,\u201d he says. \u201cI did my PhD looking at hominin stone tools. I\u2019ve learnt how to make these things. I was looking at this material, and it looked like it had been made by humans.\u201d A team led by Proffitt and Haslam, both at the University of Oxford, UK, now describes the artefacts in a paper published in  Nature  on 19 October 1 . The capuchins make the fragments unintentionally while bashing rocks into dust, the researchers find. Some scientists say that the results call into question whether some stone tools have been incorrectly attributed to hominins \u2014 including 3.3-million-year-old artefacts from Kenya that are the oldest on record. \u201cThis is a landmark paper,\u201d says Susana Carvalho, a primate archaeologist also at Oxford. \u201cThese capuchins are, in fact, producing without intention something that has to be labelled as a stone tool.\u201d \n             Tool history \n           Several primate species have been observed using crude tools. When Jane Goodall described chimpanzees using sticks to gather termites, Louis Leakey famously responded: \u201cNow we must redefine tool, redefine Man, or accept chimpanzees as humans\u201d. And capuchin monkeys are among the most habitual tool-users in the animal world. In Serra da Capivara National Park in Brazil, wild bearded capuchin monkeys ( Sapajus libidinosus ) use rocks to pound nuts,  dig holes  and even to exhibit sexual displays. In 2005, scientists observed for the first time the park\u2019s capuchins wielding rocks in a peculiar way. Next to an eroding cliff, the monkeys picked up quartz rocks, repeatedly bashed them against another rock and then licked up the resulting dust. Proffitt speculates that the quartz could provide mineral supplements, improve gut health or merely feel nice on their tongues. \u201cWhy they lick it, we don\u2019t know.\u201d Previous research on the quartz-dust-licking capuchins had examined the size and shape of the larger stones broken off 2 . Proffitt says that no one had ever collected the smaller pieces \u2014 until Haslam did so recently. To Proffitt\u2019s eye, many of those pieces resembled the kind of sharp \u2018flakes\u2019 first recovered by Leakey in Olduvai Gorge, Tanzania, in the 1930s. Dating from about 2.5 to 1.7 million years ago, these \u2018Oldowan\u2019 stone tools were thought to have been made by striking a hammer stone against an anvil at a glancing angle, causing sharp flakes to break off from the hammer. (Cut marks on bones found nearby suggest that the hominins used the flakes to butcher animals.) \n             A question of intent \n           About half of the flakes made by the capuchins bore the hallmarks of Oldowan tools called choppers, says Proffitt. One set of flakes seemed to have been broken off of the same hammer stone in succession, \u201csomething that\u2019s only ever been associated with humans\u201d, says Proffit. Yet he emphasizes that the monkeys make the tools unintentionally and \u201cat no point do they use these flakes. They\u2019re just hitting stones together\u201d. He does not think that the Oldowan tools have been attributed incorrectly to ancient human relatives, as they have been found with hominin remains and other evidence linking them to human relatives. But Proffitt says that archaeologists scouring Africa for even older stone tools should be careful when attributing fragments to hominins in the absence of other evidence: ancient apes or monkeys behaving like the capuchins might have made them instead.\u00a0 Proffitt still thinks that the 3.3-million-year-old artefacts found recently at  a Kenyan site called Lomekwi 3  \u2014 considered to be the oldest examples of tool-making \u2014 were made by human relatives, but Carvalho is less sure. \u201cCould that assemblage be a product of a non-hominin species? Technically speaking, with this data from the capuchins, it could,\u201d she says. H\u00e9l\u00e8ne Roche, an archaeologist at Paris-Nanterre University in France who was part of the team who discovered the Lomekwi tools, says that there is no mistaking the bulky artefacts (some as heavy as 15 kilograms) for the slighter capuchin-made tools. \u201cThe observation is very nice and very important, but I think it\u2019s very important on the capuchin side,\u201d she says \u2014 not so much for understanding early humans. Palaeoanthropologist Bernard Wood of George Washington University in Washington DC accepts that the monkey tools closely resemble some hominin artefacts. But he is unconvinced that the findings have implications on palaeoanthropology. \u201cWhat I\u2019m grappling with is what the hell that means,\u201d he says. \n                   Oldest stone tools raise questions about their creators 2015-Apr-21 \n                 \n                   Apes in Africa: The cultured chimpanzees 2011-Aug-17 \n                 \n                   Butchering dinner 3.4 million years ago 2010-Aug-11 \n                 \n                   Hungry monkeys can dig it 2004-Dec-09 \n                 Reprints and Permissions"},
{"file_id": "538300a", "url": "https://www.nature.com/articles/538300a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Chairman Lamar Smith has turned once-placid panel into investigative powerhouse. Lamar Smith has made his mark on science. As chairman of the US House Committee on Science, Space, and Technology, the  Texas Republican  has launched dozens of investigations into alleged wrongdoing by scientists, environmental groups and government officials. And he shows no signs of slowing down. Since 2013, Smith has probed everything from  individual National Science Foundation grants  to government air-quality regulations \u2014 issuing an unprecedented 24 subpoenas along the way. And although the Republican presidential candidate, Donald Trump, is foundering in the polls, the party is poised to retain control of the House of Representatives in the 8\u00a0November election. That means that Smith is likely to remain at the helm of the science committee for at least two more years. Whatever the future brings, one thing is clear: the panel has shed its long-standing reputation as a bastion of collegial, bipartisan debate. \u201cThis committee is a microcosm of Congress as a whole,\u201d says David Goldston, who served as chief of staff to former chairman Sherwood Boehlert (Republican, New York) from 2001 to 2006. \u201cThings have gotten ever more polarized, and at some point, the science committee wasn\u2019t going to be an exception.\u201d Although he won the chairmanship four years ago, Smith didn\u2019t shift his investigations into high gear until 2015. That\u2019s when the committee voted along party lines to grant him unilateral authority to issue subpoenas \u2014 a powerful tool to compel witness testimony or access to sensitive documents. At that point, the panel had not issued a subpoena since the early 1990s, when it probed safety and pollution violations at a US government nuclear-weapons\u00a0facility in Colorado. But Smith has taken liberal advantage of his new authority, aided by an influx of staff recruited from another House committee that specializes in investigations. \u201cIt\u2019s just been one case after another,\u201d says Representative Eddie Bernice Johnson of Texas, the highest-ranking Democrat on the panel. \u201cMembers of the committee seem to be somewhat perplexed that we got to this point.\u201d But the panel\u2019s Republican staff says that such complaints are sour grapes, and note that Smith has sought a role for Democrats in several probes. \u201cThere is a knee-jerk reaction \u2014 no matter what investigation it is \u2014 to criticize the majority,\u201d says Mark Marin, the Republican staff director for two of the science panel\u2019s subcommittees. \n               Getting warmer \n             Many of Smith\u2019s highest-profile investigations have targeted the science underlying global warming and policies intended to reduce greenhouse-gas emissions. Last year,  he sought to compel the US National Oceanic and Atmospheric Administration  (NOAA) to release documents related to a study that  disputed the idea of a global warming \u2018pause\u2019  around the turn of the twenty-first century ( T. R. Karl  et al. Science   348 , 1469\u20131472; 2015 ). Smith  suggested that NOAA scientist Thomas Karl had altered data  to advance an \u201cextreme climate-change agenda\u201d, which drew a sharp rebuke from the agency and science organizations. In July, Smith subpoenaed the attorneys-general of New York and Massachusetts over their push to determine whether oil giant Exxon Mobil misled investors about the financial liabilities posed by climate change. Smith, who has accused the state officials of trying to stifle legitimate scientific debate, is seeking documents and other communications regarding the states\u2019 probe. He has also issued subpoenas to eight environmental groups that have sought to determine whether fossil-fuel companies knowingly spread false information about climate science. Smith declined  Nature \u2019s request for an interview. In a statement, he said that his investigations are meant to defend the \u201cfreedom of scientific inquiry\u201d \u2014 and the interests of taxpayers. \u201cI plan on carrying out my responsibility to protect the First Amendment rights of scientists and continuing our  constitutional oversight responsibility ,\u201d he wrote. Thus far, many of Smith\u2019s subpoenas have come to naught. In some cases, such as the Exxon probe, the committee\u2019s targets have argued that Smith has overstepped his constitutional authority. The Massachusetts and New York attorneys-general and the eight environmental groups have declined to comply with the science panel\u2019s subpoenas. In the case of the NOAA climate study, the agency briefed the committee and provided some documents, but withheld internal communications between its scientists. To enforce a disputed subpoena, the full House would need to vote in favour of holding the recipient in contempt of Congress by the end of the year \u2014 an unlikely scenario. Nonetheless, Smith can start afresh when the new Congress convenes in early 2017. Marin hints that this is likely for the Exxon probe, at least. \u201cThe chairman is interested in continuing this investigation until he gets what he is looking for,\u201d he says. \n                     US lawmakers expand probe of climate study 2016-Feb-26 \n                   \n                     US science agency refuses request for climate records 2015-Oct-28 \n                   \n                     US lawmakers advance controversial science-policy bill 2015-May-21 \n                   \n                     Critics allege misuse of funds by US ecology project 2014-Dec-03 \n                   \n                     Social scientists hit back at grant rules 2013-Nov-12 \n                   \n                     Republicans put 'national interest' requirement on US science agency 2013-Nov-05 \n                   \n                     Quiet Texan to head science committee 2012-Dec-04 \n                   \n                     https://science.house.gov/ \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20838", "url": "https://www.nature.com/articles/nature.2016.20838", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Mission control loses contact with Schiaparelli lander while sister craft successfully enters Martian orbit. Hopes are fading for a European probe that was scheduled to land on Mars on 19 October. Schiaparelli, a craft operated by the European Space Agency (ESA), was supposed to touch down on the red planet at 14:48 UTC, in what would have been a first for the agency. But despite the probe waking up as scheduled and broadcasting from its descent phase, its signal disappeared at some point during its  complex six-minute landing procedure . ESA scientists have yet to unravel what happened, but admitted that the situation did not look good. \u201dIt\u2019s clear that these are not good signs, but we need more information,\u201d said Paolo Ferri, head of mission operations at the European Space Operations Centre (ESOC) in Darmstadt, Germany, in a briefing. The lander is just one part of the ExoMars 2016 mission, which ESA is jointly operating with the Russian space agency Roscosmos. The other half, the ESA-designed Trace Gas Orbiter (TGO), successfully entered Martian orbit to the glee of ESOC engineers, who celebrated with hugs and high-fives. \"It looks very good for the TGO mission around Mars,\" said Michel Denis, flight director for ExoMars. \n             Team effort \n           Ahead of the landing, confidence had been high at mission control. Denis even joked that the landing would be \"six minutes of serene waiting\", in contrast to the 'seven minutes of terror' coined to describe the  landing of NASA\u2019s Curiosity rover in 2012. After the ill-fated British-led and ESA-operated Beagle 2 mission, which  famously disappeared during its landing on Christmas Day 2003 , ESA scientists tried to make sure that whatever happened, they would have data about Schiaparelli\u2019s landing. This included the craft having constant contact with Earth through the Giant Metrewave Radio Telescope in Pune, India, and beaming precise details of the descent to its mothership. The landing had multiple stages, including slowing on entry into Mars\u2019s atmosphere, deploying a parachute, using thrusters to decelerate and finally landing on an impact-absorbing base. Live tracking of the lander initially showed the probe descending, but its signal apparently disappeared just moments before impact. A relay of the same signal beamed back an hour later by Mars Express \u2014 an existing ESA orbiter \u2014 also showed the descent, but remained inconclusive as to whether Schiaparelli had landed safely. NASA's Mars Reconnaissance Orbiter was due to pass overhead and communicate with Schiaparelli in the following hours, and if the uplink had worked, ESA had been expected to broadcast a status update at 18:27 UTC. However, neither ESA nor NASA have reported that this was successful. In Pasadena, California, planetary scientists nervously awaited the signal at a watch party hosted at a meeting of the American Astronomical Society's Division for Planetary Sciences and the European Planetary Science Congress. Failure \"would be a drawback\", says Norbert Krupp, a researcher at the Max Planck Institute for Solar System Research in Goettingen, Germany. He is involved in the 2020 rover mission and says that a successful Schiaparelli landing would set the stage for those operations. \"It's very important that the first step will go right.\" A Schiaparelli failure will affect plans for the 2020 mission, \u201cbut not dramatically\", ESA planetary scientist Olivier Witasse told reporters at the meeting. Many technologies have been redesigned for the rover's landing system, he said. \"It's not a one-to-one reuse of technology.\" \n             All is not lost \n           It is clear that ESA is not giving up on the craft quite yet. Ferri said in a briefing that there could be many reasons for the signal to be lost, and that the TGO mothership had recorded housekeeping data about the lander. He also stressed that the point of Schiaparelli was to learn about landing on Mars, and that even if the probe did not land successfully, ESA could still learn from the experience. \u201cWe should remember, this landing was a test, and the point of the test is you want to know what happened,\u201d he said. NASA\u2019s Opportunity rover, which was parked just 15 kilometres outside the landing zone, was to attempt to take time-lapse pictures of the parachute descent. Whether it was able to capture the images will depend on the exact trajectory Schiaparelli took. If the probe is still working on the surface, it will have between three and ten days\u2019 worth of battery life, providing multiple opportunities to re-establish a communication link with one of three satellites currently orbiting Mars. As of the morning of 20 October, ESA had still not heard from the probe. In an ESOC press briefing, ESA's head of solar and planetary missions, Andrea Accomazzo, said that Schiaparelli had entered Mars\u2019s atmosphere as expected and deployed its parachute, meaning that its heat shield worked \u201cflawlessly\u201d. At the point at which Schiaparelli released the parachute, things went off script in some way, and its radio signal disappeared around 50 seconds before its planned landing. The retro thrusters fired, but for just 3 or 4 seconds, much shorter than the 30 seconds expected. Accomazzo added that there were multiple explanations for what could have gone wrong, including that the parachute detached either too early or too late, leaving the craft too high or too low. Further data processing should show how fast Schiaparelli was going when it touched the ground. \u201cWe should be able to detect whether there was a hard signal of touchdown,\u201d said Accomazzo. \n             Science to come \n           Schiaparelli (named after Giovanni Schiaparelli, an Italian astronomer who mapped Mars's surface from Earth in the nineteenth century) is designed to test landing technology ahead of the ExoMars 2020 rover mission. The rover is equipped with a 2-metre drill to hunt for signs of ancient life on the red planet. But Schiaparelli, which is about the size of a Smart car, had also planned to conduct a two-to-four-day science mission, studying the red planet's dust storms, electric field and weather. ESA scientists will take joy from knowing that the TGO \u2014 which is by far the more scientifically important part of the mission \u2014 is safe and sound. Starting in March 2018, it will investigate the possible biological or geological origins of Martian gases, including methane. Before then, the craft must manoeuvre itself into a circular, 400-kilometre-high orbit, including by braking against the Martian atmosphere over a period of months. If Schiaparelli survives unscathed, it will be the first non-NASA probe to operate successfully on the red planet. (Mars 3, a 1971 Soviet Union probe, failed after 20 seconds on the surface.) But ESA may now have to wait until 2020 for that accolade. Alexandra Witze contributed reporting from Pasadena. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Europe and Russia prepare for historic landing on Mars 2016-Oct-17 \n                 \n                   Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                 \n                   British Mars lander find is bittersweet victory 2015-Jan-16 \n                 \n                   Curiosity rover sniffs Martian methane 2014-Dec-16 \n                 \n                   7 minutes of terror 2012-Aug-01 \n                 \n                   Europe looks to Russia after NASA falls short on ExoMars 2011-Oct-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20830", "url": "https://www.nature.com/articles/nature.2016.20830", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Florida ecologist uses a parody Twitter account as a way of highlighting issues in science and academia. As the US presidential election grinds into the final stretch, there is one version of Republican nominee Donald Trump that is laser-focused on research. The  @ScientistTrump  Twitter account showcases a fictional \u201cDonald Trump, PhD\u201d, who does the biggest, best science anywhere in the world. He hounds \u201cweak\u201d leaders of funding agencies and the \u201cfailing\u201d academic journals that don\u2019t endorse him. \u201cOnly I can Make Science Great Again,\u201d he tweets. The man behind @ScientistTrump \u2014 an ecologist named Emilio Bruna at the University of Florida in Gainesville \u2014 is no stranger to social-media antics. Last year, as editor-in-chief of the ecology journal  Biotropica , he instigated  rap battles  with the Twitter accounts of other science journals. Bruna started the Trump parody account in July after joking with fellow editors that they should review papers as the presidential candidate would. The feed went viral immediately, amassing more than 6,400 followers. Bruna aims to amuse, but the account is also a tool for him to point out real problems in science and academia, including  sexual harassment . @ScientistTrump frequently praises  journal paywalls  and expensive proprietary software. \u201cIf Donald Trump likes it, it\u2019s probably something we\u2019d like to change about our profession,\u201d Bruna says.\u00a0 \n               Not ok \n             The ecologist runs the account alone, closely monitoring the real Trump\u2019s prolific Twitter feed and speech transcripts. He modifies the candidate\u2019s remarks only slightly to preserve Trump trademarks, such as frequent uppercase text and his braggadocious style. \u201cIt\u2019s amazing how much this has really ruined my life,\u201d Bruna says. \u201cI feel like I know this person\u2019s brain intimately, and it\u2019s really not cool.\u201d The ecologist finds the real-life candidate\u2019s comments repulsive, particularly those that disparage minorities and  promise to deport immigrants . Bruna, who is a US citizen, was born in Mexico, and his wife is a US resident alien. He says his 11-year-old son has come home from school crying, worried that his mother would be deported under Trump. \u201cI don\u2019t think this election is funny anymore,\u201d Bruna says. He plans to continue with the @ScientistTrump account, regardless of the election\u2019s outcome. The response has been overwhelmingly positive, although he receives occasional hateful tweets from people who, presumably, don\u2019t realize that it\u2019s a joke. \n               For the future \n             Bruna has been able to parlay @ScientistTrump\u2019s notoriety into a political-action committee (PAC) that can collect donations for candidates or causes. His plans for the \u2018Make Science Great Again\u2019 PAC include supporting science education and ecology organizations. The PAC website collates the real Trump\u2019s tweets about science and plans to sell Make Science Great Again bumper stickers. He has not received any donations to date. In the final weeks before the election, Bruna expects that the real Trump will keep him particularly busy. \u201cThese days, it\u2019s been a killer because he just won't put his cell phone down,\u201d Bruna says. \u201cI wish he\u2019d do that because I\u2019ve got a manuscript to work on.\u201d Nature  decided to catch up with @ScientistTrump to get his thoughts on  the state of US science  \u2014 in character, of course. The interview has been edited for length and clarity. The Trump campaign did not respond to a request for comment for this article. \n               What do you think about the state of science in the United States? \n             US science used to be great, but now it\u2019s a disaster. You know it, we all know it. NIH [National Institutes of Health] and NSF [National Science Foundation] are imploding, they\u2019re very bad. We are facing the threat of Radical Open Access. Also\u00a0so many in the Postdoctoral-American community are doing so badly, they\u2019re living in Hell \u2014 poverty &  rejections  way up, jobs & grants way down,\u00a0tremendous problems. Only I can Make\u00a0Science Great Again. \n               As president, what will you do to Make Science Great Again? \n             The first thing I\u2019m going to do is build a huge paywall around Open Access journals and make PLoS pay for it.\u00a0And then we are going to\u00a0publish lots of papers because of all the grants I have created\u2026people are going to get tired of how many papers they have! Only I can do this \u2014 I have a very rich lab, and I have a huge  H factor . I\u2019ve been building my H factor all my life with only a small number of citations from my adviser to get me started. \n               What makes you a better candidate than your opponent? \n             My opponent has never been a data creator, and won\u2019t ever say the words \u201cRadical Open Access\u201d. Her former collaborator also *did* far worse things with his graduate students than I ever said to mine. It was just lab bench talk, I\u2019m not proud of it. I\u2019ve apologized to my lab group. \n               As president, who would you appoint as director of the NIH, NSF, DoE and NASA? \n             I am looking to appoint agency directors very much in the mold of Dr. Oz or Senator James Inhofe [Republican, Oklahoma]. I\u2019ve actually picked ten candidates already \u2014 highly thought of, and actually very beautifully reviewed by just about everybody. Tremendous scientists. \n               What do you think about the news that China just built the  \n               \n                   world's biggest telescope \n                 \n               ? Is the United States falling behind? \n             I love NASA. Space is terrific. But right now, we have bigger problems. We've got to stop the flood of scientists coming into our country. When Mexico sends its scientists, they\u2019re not sending the best. They\u2019re bringing data. They\u2019re Bayesians. Not all are terrible \u2014 some are nice people. I have had dozens of Mexican postdocs\u00a0work for me & they like me very much. \n               What do you think of the new Nobel laureates? \n             Several of them spoke at Mar-A-Lago years ago. I didn\u2019t attend because they're boring & often wrong \u2014 total dopes! \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     US election special \n                   \n                     Make Science Great Again PAC \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20855", "url": "https://www.nature.com/articles/nature.2016.20855", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "EMA becomes first major drugs agency to publish clinical-study reports online. In a move lauded as a landmark for transparency in medical science, the London-based European Medicines Agency (EMA) has begun to publish details of the full clinical-trial data that it receives from pharmaceutical companies. On 20 October, the agency  published  some 100 clinical reports about two EMA-approved medicines (carfilzomib, a cancer drug, and lesinurad, a gout treatment) that together run to around 260,000 pages. The disclosures make the EMA the first major drug regulatory agency to publish the warts-and-all results of clinical investigations that drug developers submit when they apply for the agency\u2019s approval to market medicines in the European Union. These clinical study reports (CSRs) are  much more detailed  than the papers that drug firms publish in scientific journals \u2014 which studies have shown are an \u201cincomplete source of information on new medicines\u201d, says Larry Peiperl, the chief editor of  PLoS Medicine . The CSRs include both positive and negative results, and details of drugs\u2019 adverse effects. The EMA\u2019s CSR policy \u2014 which it  adopted in 2014  \u2014 \u201cwill benefit academic research and the practice of medicine as a whole\", says EMA executive director Guido Rasi. He says that it will help academics to independently reanalyse data after a medicine has been approved, and also help drug developers to learn from the experiences of others. Previously, the EMA had released some results only when third parties asked for them using freedom-of-information requests, under rules the agency brought in six years ago. Those rules led to some  drug firms taking the agency to cour t to try to prevent their data being released, arguing that the information was commercially confidential. \n               Transparency campaign  \n             \u201cPatients and clinicians have been waiting a long time for clinical-trial data,\u201d says Yann Le Cam, chief executive of the rare-disease patient lobby group EURORDIS-Rare Diseases Europe, and a member of the EMA management board. Some 700 medical and patient organizations had lobbied for the data release under the auspices of the  AllTrials  campaign.  The EMA says that it intends to release all CSRs in applications that have been submitted since 1 January 2015, whether or not the applications were approved, rejected or withdrawn. Once it has cleared its backlog, the agency says that it expects to offer public access to around 4,500 clinical reports each year. The EMA will redact some commercially confidential information and, to start with, individual patient data. (In the 260,000 pages released on 20 October, almost all the redactions are made to anonymize patient data; only two pages included redactions for commercially confidential information.) The agency says that it will publish individual patient data when it has agreed with drug firms and other stakeholders how to guarantee patient confidentiality, in compliance with the EU\u2019s complex data-protection rules. \"We all now hope that other global medicines regulators will follow the European Medicines Agency\u2019s great lead,\u201d says S\u00edle Lane, who spearheads the AllTrials campaign at the London-based campaigning group Sense About Science. That includes the US Food and Drug Administration, which does not release clinical-study reports for drugs it considers for approval. \u201cThe EMA policy on the publication of clinical data serves as an example for the US medical community,\u201d says April Clyburne-Sherin, the campaign manager of AllTrials USA. Some drug firms are continuing to resist the release of their data to third-party freedom-of-information requests by the EMA under its 2010 policy. In the latest legal battle, an interim judicial EU court order this July blocked the EMA from releasing toxicity studies on a veterinary medicine called Bravecto (fluralaner) and clinical-study reports on Translarna (ataluren), a treatment for Duchenne muscular dystrophy. The two drug firms concerned \u2014 Intervet and PTC Therapeutics \u2014 have argued that release of the data would infringe their rights to protect commercially confidential information. The EMA appealed against both decisions on 29 September, and says that it sees the cases as a test of its policy.\n \n                     US clampdown on clinical-trial reporting is long overdue 2016-Sep-20 \n                   \n                     Secrets of trial data revealed 2013-Oct-08 \n                   \n                     Drug-company data vaults to be opened 2013-Mar-27 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20849", "url": "https://www.nature.com/articles/nature.2016.20849", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Claims of infants created using mitochondrial-replacement techniques stir scientific and ethical debate. Salt Lake City, Utah A baby boy conceived using a controversial technique that  mixes DNA from three people  seems to be healthy, according to a hotly anticipated talk by the leader of the team that created the child. John Zhang, a physician at New Hope Fertility Clinic in New York City, offered few other details during his presentation at the American Society for Reproductive Medicine\u2019s annual meeting on 19 October. But one thing is clear: that \u2018three-parent\u2019 baby may soon have company \u2014 if it does not already.  Natur e has learnt that a paper in review at an unnamed journal claims that a child conceived using the technique has been born in China. And on 13 October, researchers from Ukraine announced that two women are pregnant with fetuses created with DNA from three people. Meanwhile, politicians in Mexico \u2014 where New Hope\u2019s  \u2018three-parent\u2019 baby was conceived in its Guadalajara clini c \u2014 are mulling over laws to restrict use of the technique. The circumstances of that birth, first reported last month by  New Scientist , have also drawn criticism from scientists and bioethicists. They question why New Hope did its work in Mexico, where rules governing human-embryo modification are less stringent than those in the United States or the United Kingdom. Techniques to create three-parent babies seek to prevent mothers from passing on metabolic diseases caused by faulty mitochondria, the structures that provide cells with energy. To do this, researchers exchange the diseased mitochondria of a prospective mother with those of a healthy, unrelated donor: the \u2018third parent\u2019. Zhang\u2019s team worked with a woman who carries a rare neurological disease called Leigh syndrome. The researchers transplanted the nucleus of one of the woman\u2019s egg cells into a donor egg, leaving the donor\u2019s healthy mitochondria intact. They then fertilized the modified egg with sperm from the woman\u2019s husband, and implanted it in her uterus. \n             Questions remain \n           At the meeting in Salt Lake City, Utah, Zhang presented new data behind his team\u2019s claims, which had initially drawn scepticism. Zhang told meeting attendees that nearly 100% of the mitochondrial DNA in the mother\u2019s eggs contained the mutation that causes Leigh syndrome. But after the woman\u2019s nucleus was transferred to the donor egg, the percentage of faulty mitochondria in the modified egg dropped to less than 5%, on average\u201cI do believe the study is true,\u201d says Dietrich Egli, a stem-cell scientist at the New York Stem Cell Foundation in New York City. \u201cIt\u2019s good to hear the technique has resulted in an apparently healthy baby.\u201d But Egli says that there are still concerns about the  safety and efficacy of the technique , called \u2018mitochondrial-replacement therapy\u2019 (MRT). These include whether the presence of mitochondria from two women will affect the resulting baby\u2019s health, and whether the donated mitochondria will affect any of that baby\u2019s eventual offspring. Zhang says that the group will soon perform a comprehensive medical examination of the baby, including testing whether the levels of diseased mitochondria hold steady. Numerous scientific groups and government agencies are debating whether the procedure should be allowed in clinical use. Most conclude that mitochondrial replacement should be performed only under the auspices of a clinical trial and with independent oversight. Many of these groups have also recommended that MRT be limited to male embryos. Because only mothers pass mitochondria to offspring, a male baby conceived using the technique would not be able to pass his modified mitochondria to any children. Alejandro Chavez-Badiola, New Hope\u2019s medical director, says that his team implanted a male embryo because it was the only one that survived. Zhang says that the New Hope team will work with any future patients to determine whether implanting a female embryo would be ethical. And one of the two women treated in Ukraine is pregnant with a female fetus. George Daley, a stem-cell researcher at Children\u2019s Hospital Boston in Massachusetts, has led several efforts to examine the ethical and scientific aspects of MRT. He is concerned that Zhang and his colleagues at New Hope did not follow the recommendation of these advisory groups. \u201cGoing to Mexico is a way to evade the stricter regulatory regime in the US and UK,\u201d Daley says. \u201cThe danger is to the families and the infants who are being born with this procedure. They\u2019re taking all the risk before really being fully aware of the success rate and failure rate.\u201d \n             Looking ahead \n           Daley worries that any substandard clinical research in this area could jeopardize approval for other groups that have been working within existing regulatory frameworks. In 2015, the UK government approved the use of MRT in limited cases, yet the technique remains controversial and has not been used in the clinic. Chavez-Badiola says that the team worked in Mexico partly because no specific law there bans the procedure. But he notes that Mexico does have laws governing patient safety: New Hope\u2019s Guadalajara clinic is inspected by Mexico\u2019s regulatory agency, COFEPRIS, and the MRT work was approved by an ethics review board. \u201cI think this is scientific chauvinism,\u201d Chavez-Badiola says of Daley\u2019s criticism. \u201cWhy in the UK is it fine, why in Mexico is it morally questionable? We have the technology, we have the training, we have what it takes.\u201d He adds that a paper describing the New Hope team\u2019s procedure and outcomes is under consideration at a peer-reviewed journal. And Valery Zukin, the Ukrainian team\u2019s leader, notes that his work was approved by an ethical-review board of the Ukrainian Association of Reproductive Medicine. Unlike the woman that Zhang treated, Zukin\u2019s patients did not carry mitochondrial disease. But they had been infertile for years, seemingly because of a mitochondrial defect that caused embryos to suddenly stop growing. Replacing the mother\u2019s mitochondria with cellular components from a donor\u2019s egg seems to have fixed the problem, and both babies are due early in 2017, Zukin said in a 13 October presentation at the ART World Congress in New York City. But a surprise announcement, such as that of the New Hope baby, may be the only way to get regulators and scientists to make clear decisions about any limits on mitochondrial-replacement techniques. \u201cI think the scientists and doctors showed a lot of courage exposing themselves to this type of criticism in doing this treatment,\u201d Egli says. \u201cI think there is an imbalance in regulation and oversight in some places, putting novel treatments on the long bench, and therefore it had to be done that way.\u201d \n                   \u2018Three-parent baby\u2019 claim raises hopes \u2014 and ethical concerns 2016-Sep-28 \n                 \n                   Three-person embryos may fail to vanquish mutant mitochondria 2016-May-19 \n                 \n                   Reproductive medicine: The power of three 2014-May-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20834", "url": "https://www.nature.com/articles/nature.2016.20834", "year": 2016, "authors": [{"name": "Sanjay Kumar"}], "parsed_as_year": "2006_or_before", "body": "But UN flagship has handed out barely any money. The United Nations\u2019 Green Climate Fund (GCF) has now approved more than US$1 billion for projects to help developing countries to tackle the effects of climate change \u2014 although almost none of the money has yet been handed out. The fund, a UN flagship programme to channel cash for climate mitigation and adaptation to poorer countries, was established in 2010. But it took years to get off the ground, and has been  widely criticized  for a lack of accountability and transparency. Before last December\u2019s climate talks in Paris, it had been pledged $10.2 billion by rich nations, but had approved only $168 million for 8 climate projects. This year, it has  vowed to hire more staff  and approve some $2.5 billion in funds. In July, it approved $256.6 million for 9 proposals. And at a board meeting last week at its headquarters in Songdo, South Korea, the fund cleared 10 new proposals worth $745 million, bringing its total so far to $1.17 billion for 27 projects. The latest approvals include $39.3 million to Morocco to plant 10,000 hectares of argan trees \u2014 to sequester carbon dioxide and protect against desertification \u2014 and $80 million to develop geothermal plants in five east Caribbean countries. A private investment bank, the London-based European Bank for Reconstruction and Development, was awarded the largest single amount: $378 million to support a variety of sustainable energy projects in an expected 13 countries. Only one approved project has yet received any cash: $5.35 million has been given to a private-equity investment fund that aims to bring off-grid solar power to households in Rwanda and Kenya. \u201cTo turn GCF into a driving force for global climate finance, we will need to allocate funds more quickly, and we will need to disburse resources for projects swiftly after they have been approved,\u201d says Javier Manzanares, the GCF\u2019s interim executive director. \u201cOur ambition is currently limited by our capacity. We must recruit senior talent to the fund promptly, so we can deliver on our mandate,\u201d he adds. Civil-society groups that attended last week\u2019s meeting had hoped that the GCF would distinguish itself from existing climate-finance mechanisms (such as clean-energy projects financed by the World Bank) by consulting more closely \u2014 and at an early stage \u2014 with local groups in developing nations. But Liane Schalatek, who attended last week's board meeting as a 'civil society observer' sent by developed nations, says that does not seem to be happening. \u201cWe are very concerned that the fund is simply replicating conventional climate financing mechanisms and that its projects often have insufficient local consultation and transparency,\u201d says Schalatek, who is associate director of the North American arm of the Heinrich-B\u00f6ll Foundation,\u00a0a non-profit group affiliated with the German Green Party. Also at the meeting, the GCF appointed its new executive director: Howard Bamsey, a former director-general of the Global Green Growth Institute in Seoul and Australia\u2019s special envoy on climate change. He will replace H\u00e9la Cheikhrouhou, who has taken over as Tunisia\u2019s energy minister. \n                   Green Climate Fund vows to up its game 2016-Mar-30 \n                 \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Green Climate Fund faces slew of criticism 2015-Nov-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20854", "url": "https://www.nature.com/articles/nature.2016.20854", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Two gene-expression studies could explain why people of African descent respond more strongly to infection, and are more prone to autoimmune diseases. DNA acquired from breeding with Neanderthals may explain why people of European descent respond differently to infection than those of African descent, two studies suggest. The findings might also offer insight into why people of African descent are more prone to autoimmune diseases caused by an overactive immune system. In a paper 1  published on 20 October in  Cell , geneticist Luis Barreiro of the University of Montreal in Canada and his colleagues collected blood samples from 80 African Americans and 95 people of European descent. From each sample, they isolated a type of immune cell called macrophages, which engulf and destroy bacteria, and grew these cells in a dish. Next, they infected each culture with two types of bacteria and measured how the cells responded. Macrophages from African Americans, they found, killed the bacteria three times faster than those of European Americans. The researchers then measured how gene expression changed in response to the infection. About 30% of the approximately 12,000 genes that they tested were expressed differently between the two groups, even before infection. And many of the genes whose activity changed the most during the immune reaction had sequences that were very similar between Europeans and Neanderthals, but not Africans. \n             Immune mixing \n           Barreiro suspects that when modern humans first left Africa \u2014  some time between 100,000 and 60,000\u00a0years ago  \u2014 they had to adapt to a different set of pathogens on the European continent. Breeding with Neanderthals, and obtaining their different immune response, probably helped them to better fight off the new kinds of infections that they encountered there. In the second study 2 , population geneticist Lluis Quintana-Murci and his colleagues at the Pasteur Institute in Paris collected samples from 200 people living in Belgium, half of whom were of African descent and the other half of European descent. The researchers grew a different type of immune cells called monocytes in a dish and infected them with bacteria and viruses. Once again, the two groups showed differences in the activity of numerous genes, and Neanderthal-like gene variants in the European group played a major role in altering their immune response. The differences were especially stark in the way that the two groups responded to viral infection. Paul Norman, an immunogeneticist at Stanford University in California, says that the two studies are unusual in looking at how the level of gene expression differs in response to infection, rather than just comparing the genome sequences of individuals. Norman now wants to see the study repeated in more types of immune cell. Immune systems tend to evolve rapidly because infections produce immediate evolutionary pressure, says computational biologist Janet Kelso of the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. So it makes sense that European ancestors would have held onto any advantage they could get from the Neanderthals. \u201cThere\u2019s an appreciation now that contributions are coming from many sources, and archaic humans are one,\u201d she says.\u00a0 \n             Trigger behind the change \n           Kelso says that the studies cannot reveal exactly what drove the evolution \u2014 such as a particular viral outbreak in Europe, for instance. For some diseases, such as tuberculosis, a lower immune response tends to help with survival, and modern humans in Europe adopted the Neanderthal traits that helped with this. \u201cMaybe the most important thing is to live in peace with the microbes,\u201d Quintana-Murci says. Overactive immune systems could help to explain why African American women, for instance, are up to three times more prone to the autoimmune disease lupus than white Americans, Barreiro says. The differences seem to persist irrespective of socioeconomic status and other environmental factors such as smoking and diet, although these probably have a role. Determining how much of the difference is due to genetics could help researchers to tease out the role of environmental factors, and therefore could guide public-health efforts. Norman says that more research should include genomes and biological samples from different ethnic groups. About 80% of people included in genome-wide association studies are of European descent, and a Comment 3  in  Nature  last week called for more racial diversity in genomic databases. Norman says that the latest studies show how useful this diversity can be in elucidating the roots of diseases. \u201cWe need to look at African populations as well, not just because some diseases affect Africans worse, but because we can get to the answers easier.\u201d \n                   Genomics is failing on diversity 2016-Oct-12 \n                 \n                   Teeth from China reveal early human trek out of Africa 2015-Oct-14 \n                 \n                   Neanderthals had outsize effect on human biology 2015-Jul-29 \n                 \n                   US tailored-medicine project aims for ethnic balance 2015-Jul-21 \n                 \n                   Ancient DNA shaped our immune system \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20832", "url": "https://www.nature.com/articles/nature.2016.20832", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Juno probe goes into safe mode hours before second fly-by of the giant planet. Pasadena, California NASA\u2019s Juno spacecraft put itself into a temporary shutdown at 10:47 p.m. US Pacific Daylight Time on 18 October as it approached a fly-by of Jupiter. It was the mission's second glitch in a week, following a problem with its propellant system. Juno remains safe and is looping around Jupiter on a 53.4-day elliptical orbit. But the spacecraft did not gather scientific data as it whizzed 5,000 kilometres above the giant planet\u2019s cloudtops on its second close pass  since arriving at Jupiter on 4 July . \u201cWe\u2019ll just hang out for a couple of days while we figure out what went wrong,\u201d says Scott Bolton, a planetary scientist at the Southwest Research Institute in San Antonio, Texas, and the mission\u2019s principal investigator. \n             Delayed burn \n           Juno slipped into 'safe mode', possibly in response to an onboard computer reboot, a little more than 13 hours ahead of its closest approach to Jupiter. The mission has been in safe mode several times since its 2011 launch; operations are typically restored within hours to days. Engineers are working through a series of steps to restore communications. If and when Juno starts talking again, they will turn towards resolving a separate, apparently unrelated propellant issue. On 14 October, NASA announced that Juno would delay burning its engines as planned during the 19 October close fly-by, or perijove. The engine burn would have nudged the craft from its 53.4-day orbit to a 14-day orbit. But two helium valves needed for the procedure did not respond as expected while being pressurized in the lead-up to the burn. Mission managers decided to put it off, hastily scheduled a series of science observations for the upcoming perijove \u2014\u00a0and then, four days later, saw their spacecraft enter safe mode. Juno can stay in its 53.4-day orbit indefinitely and still achieve nearly all of  the science it had been planning to gather at Jupiter , Bolton says, including unravelling the mysteries of the planet's origin and whether or not it has a core. The science discoveries come mostly at each close fly-by, so stretching out the time between each perijove means that researchers gather data more slowly. \n             An early look \n           Despite Juno's current issues, there was a spot of good news. Bolton presented early results from Juno\u2019s first, 27 August fly-by of Jupiter at a joint meeting in Pasadena, California, of the American Astronomical Society\u2019s Division for Planetary Sciences and the European Planetary Science Congress. The data included one of the best looks yet into Jupiter\u2019s deep swirling clouds. A microwave instrument on Juno has found that Jupiter\u2019s atmospheric cloud bands extend as much as 400 kilometres deep into the gas giant \u2014 although the bands display new twists and turns the deeper they go. \u201cDeep down Jupiter is similar but also very different from what we see on the surface,\u201d Bolton says. Juno\u2019s camera has captured new visual details on the storms that rage across Jupiter, such as the famous Great Red Spot. Unlike other spacecraft that have visited the gas giant, Juno is whizzing up and over the planet\u2019s poles, giving researchers the first-ever view of the northern and southern extremes. The spacecraft's first fly-by found that  Jupiter\u2019s north pole  lacks the mysterious hexagon of swirling clouds that dominate Saturn's north pole. Another new image shows a towering cyclone, its clouds illuminated from the side as the Sun rises on Jupiter. At 7,000 kilometres across and 100 kilometres tall, \u201cit is a truly towering beast of a storm\u201d, Bolton says. Other data not yet made public include information on Jupiter\u2019s powerful magnetic and gravity fields, as well as its shimmering auroras. \u201cEvery data set has a discovery aspect in it that we\u2019re in the middle of trying to understand,\u201d says Bolton. The next fly-by is scheduled for 11 December. \n                   Juno becomes first spacecraft to visit Jupiter in 21 years 2016-Jul-05 \n                 \n                   NASA\u2019s Juno spacecraft prepares to probe Jupiter\u2019s mysteries 2016-Jun-28 \n                 \n                   Europe plans mission to Jupiter 2012-May-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20848", "url": "https://www.nature.com/articles/nature.2016.20848", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Specimen suggests people and ancient fish had more in common than previously thought. A new fossil fish ( Qilinyu rostrata ) found in Yunnan, China, has filled in a gaping hole in how researchers thought the vertebrate jaw evolved. The 423 million years old specimen \u2014 part of an ancient group of armoured fish called placoderms \u2014 is the oldest fossil ever found with a modern three-part jaw, which includes two bones in the upper jaw and one in the lower jaw. Researchers reported their find on 20 October in the journal  Science 1 . Scientists thought that placoderm jaws, such as those seen in  Dunkleosteus , were completely unrelated to the three-part jaw that humans have. This was because the bones in placoderm jaws sat further inside their mouths than they do in humans and didn\u2019t contribute to the outer structure of the face like human jaw bones do, says Per Ahlberg, palaeontologist at Uppsala University in Sweden and a study co-author. The placement of bones in this new fossil jaw is halfway between an ancient placoderm jaw and a modern jaw, the kind that bony fish and land vertebrates, including humans, have. \u201cThey contribute to the face, but the bits inside the mouth look suspiciously like\u201d placoderm jaw bones, says Ahlberg. This rewrites the previous understanding that placoderm jaws and modern jaws evolved completely independently and were only very distantly related. \u201cYou know that old thing where you have a picture of a vase and you\u00a0suddenly\u00a0realize that it\u2019s two human profiles facing each other?\u00a0It was like that,\u201d Ahlberg recalls. \u201cYou realize that\u00a0what everybody else has ruled out is in fact not only  not  ruled out, but is in fact the crushingly obvious interpretation.\u201d \n             Something to chew on \n           This  new view of jaw evolution was first suggested , though not entirely confirmed, by the 2013 discovery of a fossil fish called  Entelognathus primordialis . A group led by paleontologist Min Zhu at the Chinese Academy of Sciences in Beijing discovered this new fossil fish at the same site. The current fossil is older than the 419-million-year old  Entelognathus , and provides an example of a jaw that is more clearly intermediate between ancient placoderms and modern bony fish. Qilinyu rostrata was about 20 cm long and looked like a catfish with a flat pointy bit sticking out of its snout. \u201cIt reminded me of a platypus, having this big snout with a flat bill,\u201d says John Long, a palaeontologist at Flinders University in Adelaide, Australia. The most complete fossil, which was used to describe the new species, was uncovered from the Xiaoxiang site\u2019s muddy limestone in 2012, but it was missing its lower jaw. Early in 2016, Zhu\u2019s group found a lower jaw from another specimen, then four more lower jaws from other individuals, giving them a complete picture of the animal\u2019s jaw bones. \n             Ancient tropical paradise \n           \u201cIt confirms what the scientific consensus has been leaning toward for the last two years,\u201d since Zhu\u2019s group found  Entelognathus , says Sam Giles, a palaeobiologist at Oxford University in the UK. The find also shows how early placoderms filled very different ecological niches, she says.  Qilinyu \u2019s mouth is located on its underside, indicating it was most likely a bottom-feeder, whereas  Entelognathus \u2019s forward-facing mouth indicates a different style of feeding. Xiaoxiang is \u201ca spectacular site,\u201d says Giles. \u201cBefore this locality, everyone thought there wasn\u2019t much going on in this period.\u201d But it\u2019s turned out to be incredibly diverse, she notes. Theancient tropical bay at this site was both geographically and biologically isolated from other oceans, says Zhu. That isolation cultivated a diversity that he has not even come close to fully cataloguing. Zhu says his team has collected over 20 other new fossil forms that are waiting to be prepared and described. \n                   Ancient fish face shows roots of modern jaw 2013-Sep-25 \n                 \n                   Evolution: Mouth to mouth 2009-Sep-09 \n                 \n                   The oldest pregnant mum 2008-May-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20853", "url": "https://www.nature.com/articles/nature.2016.20853", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "NASA\u2019s rebooted mission, K2, seeks out new worlds closely orbiting stars smaller than the Sun. NASA\u2019s Kepler observatory has spotted 20 planets that orbit cool, small stars \u2014 the largest such haul so far. These long-lived stars, known as K and M dwarfs, are ubiquitous in the Milky Way and could turn out to host numerous habitable planets. After the Kepler spacecraft  experienced a mechanical failure in 2013  that made it impossible for it to keep observing its original targets, astronomers gave it a new mission, called K2. It now uses pressure from sunlight to help stabilize the craft. The latest observations with K2 revealed 87 planet candidates,  on top of 667 previously announced candidates , almost all with sizes between those of Mars and Neptune. Although the original Kepler mission examined many Sun-like stars, the majority of stars in our Galaxy are smaller, fainter, cooler stars, known as red dwarfs. Such stars make up nearly half the targets of the K2 mission. \u201cThere are more than 250 of them within 30 light-years \u2014 all over the place \u2014 which is why some other astronomers here might call them the vermin of the sky,\u201d says Courtney Dressing, an astrophysicist at the California Institute of Technology in Pasadena who presented the research at a joint meeting of the American Astronomical Society's Division for Planetary Sciences and the European Planetary Science Congress in Pasadena on 19 October. \u201cSince these stars are the most common ones in the Galaxy, they help us learn how common life might be,\u201d says Victoria Meadows, an astronomer at the University of Washington in Seattle. Of the confirmed planets, 63 are smaller than Neptune, and a few could be even smaller than Earth. But these small candidates remain to be confirmed. Dressing believes that these are probably \u201cfalse positives\u201d caused by other phenomena such as cosmic rays or an instrumental glitch. Five of the confirmed planet candidates are in or near their star\u2019s \u2018habitable zone\u2019, the region that\u2019s neither too close to the star, nor too far from it, for life to arise. In our Solar System, the zone is roughly between the orbits of Venus and Mars. Red dwarf stars give off less energy than larger, hotter stars, so their planets\u2019 habitable zones are closer in, often closer to their star than Mercury is to the Sun. Such planets transit frequently, some orbiting their star within just a few weeks, making it easier to use Kepler\u2019s instruments to detect the tell-tale dimming of stellar light. The focus on red dwarfs stems partly from the K2 mission\u2019s constraints, which allow the astronomers less then three months to observe stars in its field of viewbefore having to rotate the craft. Moving from field to field poses a challenge, but it also gives the team an opportunity to investigate more objects. \u201cIt\u2019s fun to study a new set of stars every 80 days,\u201d Dressing says. Dressing\u2019s research also paves the way for more sensitive future missions designed to look for Earth-sized planets, says Christa van Laerhoven, a planetary scientist at the Canadian Institute for Theoretical Astrophysics in Toronto. Such missions include NASA\u2019s Transiting Exoplanet Survey Satellite, scheduled to launch in December next year. \n                   Kepler spacecraft rakes in nearly 1,300 planets 2016-May-10 \n                 \n                   Kepler spacecraft in emergency mode 2016-Apr-10 \n                 \n                   Rebooted Kepler spacecraft hauls in the planets 2016-Jan-07 \n                 \n                   NASA Kepler & K2 mission website \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20856", "url": "https://www.nature.com/articles/nature.2016.20856", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA\u2019s New Horizons mission plumbs complex interplay between the dwarf planet's surface and its sky. Pasadena, California Pluto\u2019s icy heart beats with a planetary rhythm. When NASA\u2019s New Horizons spacecraft  whizzed by the dwarf planet  in July 2015, it famously spotted a heart-shaped feature just north of the equator. Now, researchers are recognizing how that enormous ice cap drives much of Pluto\u2019s activity, from its frosty surface to its hazy atmosphere. Planetary scientists revealed their latest insights this week at a joint meeting of the American Astronomical Society\u2019s Division for Planetary Sciences and the European Planetary Science Congress in Pasadena, California. Many of those discoveries revolve around Sputnik Planitia, the icy expanse that makes up the left lobe of Pluto\u2019s \u2018heart\u2019. \u201cAll roads lead to Sputnik,\u201d says William McKinnon, a planetary scientist at Washington University in St. Louis, Missouri. Researchers already knew that Sputnik Planitia (formerly dubbed Sputnik Planum) is made mostly of nitrogen ice,  churning and flowing in massive glaciers 1 . But its sheer size \u2014 1,000 kilometres across and at least several kilometres deep \u2014 means that it exerts extraordinary influence over the dwarf planet\u2019s behaviour. The heart may have even knocked Pluto on its side. At the meeting, James Tuttle Keane of the University of Arizona in Tucson showed how the feature\u2019s formation could have altered Pluto\u2019s tilt. Sputnik Planitia may be a crater punched by a giant meteorite impact, which later filled with ice. The sheer mass of all that ice caused the dwarf planet to rotate relative to its spin axis, Keane says, so that Sputnik Planitia ended up permanently facing away from Pluto\u2019s biggest moon, Charon. \u201cPluto followed its heart,\u201d he says. (Other scientists, such as Douglas Hamilton of the University of Maryland in College Park, have suggested that Sputnik Planitia might have accumulated ice without an impact, and that the hole instead comes from the sheer weight of the ice depressing the ground beneath it.) The enormous reservoir of Sputnik Planitia also feeds  Pluto\u2019s complicated atmosphere . Volatile chemicals such as nitrogen, methane and carbon monoxide start out as ices on the surface, often within Sputnik, then sublimate into the air when temperatures warm. As the atmosphere cools, the volatile gases condense and fall back to the surface, coating it with a fresh layer of frost. Pluto is currently moving away from the Sun and so temperatures are growing colder. 2 \n               A clearer view \n             New Horizons, which analysed light passing through Pluto\u2019s thin atmosphere, showed just how complicated the interplay between the surface and the atmosphere is, says  Leslie Young , a planetary scientist at the Southwest Research Institute in Boulder, Colorado. As dawn breaks over Sputnik Planitia, sunlight warms the icy plain and allows a pulse of nitrogen to waft upwards. \u201cI think of this piston of cold air being pushed into the bottom of the atmosphere every day and then dropping back down,\u201d says Young. New data also reveal how the seasonal frosts behave on the surface. Silvia Protopapa, a planetary scientist at the University of Maryland, showed maps of how methane and nitrogen are distributed across Pluto\u2019s surface, as seen by an infrared-sensing instrument on New Horizons. The ices typically co-exist in a mix in which one substance or the other dominates. In Sputnik Planitia, temperatures and sunlight combine to create an environment where nitrogen rules. Farther north, above about 55 degrees latitude, constant summer sunlight seems to have stripped most of the nitrogen away, leaving behind plains of methane ice at Pluto's north pole. \u201cWe\u2019ve had continuous illumination northward for the past 20 years,\u201d says Protopapa. The work is to appear in the journal  Icarus . Sputnik Planitia\u2019s influence reaches the highest levels of Pluto\u2019s atmosphere. Its volatile gases drift upwards, and photochemical reactions create new carbon and nitrogen compounds. These form layered hazes that extend more than 200 kilometres above the surface. That\u2019s higher than researchers would have predicted, because temperatures at this level are too warm for particles to condense out directly. Instead, dust raining in from interplanetary space might serve as nuclei around which haze particles can form, says Andrew Cheng, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland. Haze particles then begin to clump together, growing bigger and more rounded the lower they drift in the atmosphere, Cheng says. Eventually they settle out on to Pluto\u2019s surface, and coat it afresh until warming begins and they are once again lofted. New Horizons has slowly been trickling data back to Earth since  its record-setting fly-by , and final observations from its encounter are due to be returned on the night of 22\u201323 October. They will show pictures of the dark vastness of space surrounding Pluto \u2014 photographed just in case a tiny unknown moon or other cosmic discovery still happens to be lurking in the New Horizons data. \n                     Weird and wonderful Pluto spills its secrets 2016-Mar-17 \n                   \n                     Icy volcanoes may dot Pluto's surface 2015-Nov-09 \n                   \n                     Pluto\u2019s geology is unlike any other 2015-Oct-15 \n                   \n                     'Snakeskin' Pluto revealed in planetary close-up 2015-Sep-24 \n                   \n                     Pluto snow forecast poses atmospheric conundrum 2015-Sep-01 \n                   \n                     Nitrogen glaciers flow on Pluto 2015-Jul-24 \n                   \n                     Nature  special: Pluto & Ceres \n                   \n                     NASA's New Horizons site \n                   \n                     New Horizons mission site \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20860", "url": "https://www.nature.com/articles/nature.2016.20860", "year": 2016, "authors": [{"name": "Jane J. Lee"}], "parsed_as_year": "2006_or_before", "body": "Images from NASA orbiter suggest that Europe\u2019s Schiaparelli probe smashed on impact. A NASA spacecraft may have spotted the remains of  the European Space Agency\u2019s (ESA\u2019s) missing Mars lander.  Two new surface features in images from the Mars Reconnaissance Orbiter (MRO) are probably signs of the Schiaparelli lander, ESA announced on 21 October. The lander was the second part of a  European mission  that reached the red planet on 19 October. The first portion, the Trace Gas Orbiter (TGO), successfully took up position around Mars, while the lander began its descent to the surface. But at some point during the six-minute landing procedure, Schiaparelli\u2019s minders lost contact with it. On 20 October, the MRO captured a still image of the area where Schiaparelli is thought to have landed, which researchers compared with a picture of the same area taken in May this year. The before-and-after series shows a dark smudge appearing in the top left quadrant of the landing zone, along with a bright white dot near the bottom right. The bright dot is probably the lander\u2019s 12-metre-diameter parachute, deployed during the descent\u2019s second stage. The darker smudge is probably evidence of the lander. Either Schiaparelli\u2019s impact or a possible explosion could have disturbed the Martian surface, uncovering darker material that resulted in the black blob on the photograph, according to a  statement  put out by ESA. Researchers estimate that the premature shutdown of the lander\u2019s thrusters put it into freefall between 2 and 4 kilometres above the surface of Mars. Schiaparelli would have hit the ground at more than 300 kilometres per hour. Because the fuel tanks for its thrusters were probably still full, it\u2019s possible that the lander exploded on impact, ESA says. Researchers are still reviewing data from the TGO, which monitored the lander\u2019s descent. And they plan to take higher-resolution images of the landing area using the MRO\u2019s HiRISE camera over the next two weeks. Using these, together with information from ESA\u2019s Mars Express orbiter and data from the Giant Metrewave Radio Telescope near Pune, India, the scientists hope to piece together exactly what happened to their lost lander. Alexandra Witze contributed reporting. \n                   Europe\u2019s probe feared lost on Mars 2016-Oct-19 \n                 \n                   Europe and Russia prepare for historic landing on Mars 2016-Oct-17 \n                 \n                   Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                 \n                   ESA ExoMars website \n                 \n                   Mars Reconnaissance Orbiter \n                 Reprints and Permissions"},
{"file_id": "538440a", "url": "https://www.nature.com/articles/538440a", "year": 2016, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Protests over rising tuition fees have stopped classes, closed institutions and slowed research. A heavy security presence awaits academics at the University of KwaZulu-Natal campus in Westville, South Africa. After a library at the university\u2019s nearby Durban campus was torched last month, police officers now regularly search staff and their cars for petrol bombs, says Kavilan Moodley, an astrophysicist there. Still, the institution remains open for research and teaching. On the other side of the country, all classes and lab-based research at the Cape Peninsula University of Technology (CPUT) in Cape Town have ground to a halt. The lockdown follows a non-fatal attack late on 11 October in which three men were locked in a university building that was then set on fire. \u201cThe physical lockdown has been about a week. Since the arson attacks, we could not guarantee staff and students\u2019 safety,\u201d says Mellet Moll, assistant dean for research in the engineering faculty. Campus violence is affecting many of South Africa\u2019s 26 universities \u2014 and the impact is spilling over into research.  Student protests against rising tuition fees began in 2015  as the #FeesMustFall campaign, which secured a freeze on fees for this academic year. But the protests flared up again and have become increasingly physically destructive since September, when the government announced that an 8% hike in fees would be permitted for the 2017 academic year. Many undergraduate classes around the country have been stopped, including those at the University of Cape Town (UCT), where face-to-face teaching has been suspended in all faculties. Last week, two security guards were attacked. The effects on research are uneven. Scientists at the UCT, the University of the Witwatersrand in Johannesburg and the University of Pretoria say that, despite the distraction of protests and security, and difficulties in getting packages delivered, they are able to continue with their work. At the CPUT and the University of the Western Cape (UWC) in Cape Town, however, protests have been catastrophic for research. A senior academic at the UWC says that the situation is dire. With the university closed, funding is going unspent, causing international study visas and bursaries for master\u2019s and doctoral students to expire with research not yet complete. University administrators are in a bind. Steadily rising fees have enraged students, who connect the issue to the social and racial disadvantage that persists two decades after the end of apartheid. But higher-education institutions say that they rely on those fees to make up for declining government subsidies. \u201cIt\u2019s a crisis we are all facing,\u201d Moll says. \u201cBut it\u2019s something that the universities themselves cannot do a lot about. We\u2019ve become the battle-ground between the government and the youth.\u201d Academics are also worried that, in the longer term, the violence could damage universities\u2019 reputations \u2014 which could put off foreign students and international collaborators, even at institutions that have not otherwise been affected by the protests. \u201cI\u2019m concerned that if we don\u2019t resolve this within a reasonable timescale, we\u2019ll be seen as dysfunctional, even if it\u2019s not true,\u201d says Don Cowan, director of the University of Pretoria\u2019s Genomics Research Institute. Researchers are also  concerned at the prospect of falling budgets  as the government \u2014 struggling with a combination of the student crisis, the country\u2019s worst drought in decades and slow economic growth \u2014 looks to trim other areas of spending. The South African Medical Research Council, for example, has been given a 7% budget cut for the year 2017\u201318, says council head Glenda Gray. For now, undergraduates are the main concern: universities across the country are holding emergency meetings, general assemblies and peace accords in a desperate bid to keep the academic year alive. \u201cWe are now reaching the \u2018point of no return\u2019 in terms of saving the academic year,\u201d said UCT vice-chancellor Max Price in a notice to students and staff last week. \n                     South African academics warn of universities on the brink 2016-Aug-26 \n                   \n                     South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                   \n                     South Africa ushers in a new era for HIV 2016-Jul-13 \n                   \n                     Giant SKA telescope rattles South African community 2016-Jun-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20862", "url": "https://www.nature.com/articles/nature.2016.20862", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Some autism symptoms reduced in children six years after their parents receive communications training. Teaching parents of children with autism how to interact more effectively with their offspring brings the children benefits that linger for years, according to the largest and longest-running study of autism interventions. The training targeted parents with 2\u20134-year-old children with autism. Six years after the adults completed the year-long course, their children showed better social communication and reduced repetitive behaviours, and fewer were considered to have \u201csevere\u201d autism as compared to a control group, according to results published on 25 October in  The Lancet 1 . \u201cThis is not a cure,\u201d says child psychiatrist Jonathan Green of the University of Manchester, and an investigator on the study. \u201cBut it does have a sustained and substantial reduction in severity and that\u2019s important in families.\u201d John Constantino, a child psychiatrist at Washington University in St. Louis, Missouri, says that the results are \u201cmonumentally important\u201d, because there has been little evidence showing that interventions for autism at an early stage are effective \u2014 even though researchers already broadly endorse the idea. \"It is a rare long-term randomized controlled trial in a field in which there exists almost no data of this kind,\" he says. But he adds that the magnitude of the improvement was a disappointment, and that there were signs that the effects of treatment were diminishing over time. And although the therapy benefited communication skills and decreased repetitive behaviours, it did not lessen childrens' anxiety \u2014 another key symptom of autism. \u201cPerhaps most of all, this underscores how desperately important it is that we develop higher-impact interventions,\u201d he says. \n             Video training \n           More than 1% of US children are diagnosed with autism spectrum disorder, a condition in which their ability to communicate is impaired. There is no treatment that has been definitively shown to address the core symptoms of autism, says Green. The idea behind early intervention therapies for autism is that they stand a greater chance of having an impact because symptoms are not as severe and the brain is at an earlier stage of development. Green and his colleagues launched the Preschool Autism Communication Trial (PACT) to test those assumptions. They enrolled 152 children with autism, many of them with severe symptoms of the disorder. About half of the children were randomly assigned to receive an intervention; the other half served as a control. The two groups began the study with similar scores on a measure of autism symptom severity. The therapy, however, was aimed at their parents. Training was tailored to each family: twice a month for six months, parents watched videos of their interactions with their children. A therapist paused the video periodically to discuss methods that parents could use to better engage their children and bolster their communication skills. The parents received more support sessions for the next six months, and agreed to do about half an hour of planned activities with their children each day throughout the year. After that, the therapy sessions stopped. At the end of that treatment, the children who received the treatment had less-severe symptoms of autism. And six years later, the follow-up with 121 of the original study participants showed that the effects of that therapy were still evident. On a scale that indicates autism severity, scores were lower in children whose families had received the training: 7.3 versus 7.8 in children who had not received the intervention. Among those in the intervention group, 46% were considered to have \u201csevere\u201d autism. That proportion was 63% in the untreated children. The data are sufficient to support wider use of similar interventions, says Green. \u201cWe think this could be and should be part of an overall provision for children with autism.\u201d \n                   Monkeys genetically modified to show autism symptoms 2016-Jan-25 \n                 \n                   Neuroscience: The hard science of oxytocin 2015-Jun-24 \n                 \n                   Diuretic drug prevents autism in mice and rats 2014-Feb-06 \n                 \n                   Autism symptoms seen in babies 2013-Nov-06 \n                 \n                   Nature Special: The austism enigma \n                 \n                   Pre-school Autism Communication Trial \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20781", "url": "https://www.nature.com/articles/nature.2016.20781", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Archives reveal the most-nominated researchers who missed out on a Nobel Prize. Seven deserving researchers won the 2016 Nobel science prizes, announced last week. But spare a thought for the scientists who attract large numbers of nominations for a Nobel medal \u2014 yet never receive the coveted call from Stockholm. The Nobel Foundation keeps details of nominees confidential for at least 50 years, but releases most older records to an online database.  Nature  analyzed the public archive to find the most hard-done-by nominees. The \u2018winner\u2019 is  Gaston Ramon , who received a remarkable 155 separate nominations for the Nobel Prize in Physiology or Medicine between 1930 and 1953 (the latest year for which the Nobel Foundation has released nominee information for that prize). But he never found favour with the Nobel judges. Ramon was a French veterinarian and biologist who in the 1920s developed a vaccine against diphtheria, which at the time was a leading cause of death. He inactivated the toxin responsible for the disease using formalin, creating a weakened form that could be injected into people to provoke an immune response. Ramon's method, which produced a reliable, standard dose, enabled mass vaccination against diphtheria. Another crucial diphtheria researcher who went unrewarded was  Emile Roux , a French physician and researcher who received 115 nominations between 1901 and 1932. Roux discovered the diphtheria bacterial toxin in the late nineteenth century (along with Alexandre Yersin, whose name lives on in his discovery of the Yersinia  bacterium that causes bubonic plague).  \n             So near to a Nobel \n             Roux (who also co-developed the rabies vaccine with Louis Pasteur) and Ramon may have lost out because several Nobels had already been given for discoveries in immunology and infectious diseases, says Erling Norrby, a virologist who researches the Nobel archives and who was permanent secretary of the Royal Swedish Academy of Sciences from 1997 to 2003. In 1901, for example, Emil von Behring was rewarded for his discovery that serum containing antibodies to the diphtheria toxin could be used to treat the disease. \n             Against the grain \n           But in other cases,  biases or internal power plays  among the small selection committees that decide the Nobel prizes might have been to blame, says Robert Marc Friedman, a science historian at the University of Oslo. Under the prize procedures, the Nobel selection committees invite a group of nominators to submit names for consideration, along with supporting arguments. In physics, the selection committee in the early years was dominated by Swedish experimentalists, Friedman says, who had little time for theory. That could have contributed to some physicists missing out on an award, such as French mathematician  Henri Poincar\u00e9  (51 nominations between 1904 and 1912), although they had clear support in the scientific community. The most-nominated chemist never to win the chemistry Nobel \u2014 British researcher  Sir Christopher Kelk Ingold , with 68 nominations between 1940 and 1965 \u2014 probably lost out because his papers on reaction mechanisms similarly ran up against the distaste of the Nobel committee at the time for theoretical work, Friedman says. Committees have also often preferred candidates with internationally diverse backing, says Nils Hansson, a historian at the Heinrich Heine University of D\u00fcsseldorf in Germany. That might have scuppered the chances of  Ren\u00e9 Leriche , a French surgeon who received 79 nominations between 1930 and 1953 \u2014 largely from French peers \u2014 and  Ferdinand Sauerbruch , a German surgeon who received 56 nominations \u2014 again largely from his own nation\u2019s scientists \u2014 between 1914 and 1951. Many scientists, no doubt, missed out on the prize because there were simply more prize-worthy researchers than medals, says Hansson. But the Nobel archives \u2014 bundles of yellowed nomination letters and deliberations \u2014 have thrown up some surprising details. Take US physician  Harvey Cushing , considered to be the father of neurosurgery, and an obvious frontrunner for the medicine prize, who had 38 nominations from 1917 to 1939. Hansson is convinced that Cushing failed to win simply because his nomination letters did not do justice to his seminal work. \u201cWith nominators like that, who needs enemies?\u201d he says. \u201cA kaleidoscope of human agency is necessarily involved in awarding the Nobel Prize, as with any other prize,\u201d says Friedman. \u201cThere are no grounds for assuming the winners of the Nobel Prize constitute a unique population of the very \u2018best\u2019 in science.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Where Nobel winners get their start 2016-Oct-07 \n                 \n                   World\u2019s tiniest machines win chemistry Nobel 2016-Oct-05 \n                 \n                   Physics of 2D exotic matter wins Nobel 2016-Oct-04 \n                 \n                   Premature burial, show business and the Nobel prize 2016-Oct-04 \n                 \n                   Medicine Nobel for research on how cells 'eat themselves' 2016-Oct-03 \n                 \n                   Spats, sniping and science: the rows behind the Nobels 2016-Sep-26 \n                 \n                   The Nobel Prize's Nomination Archive \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20769", "url": "https://www.nature.com/articles/nature.2016.20769", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Struggling RNAi field faces another blow as its first treatments near the clinic. A prominent developer of drugs that use RNA interference (RNAi) has abandoned one of its leading candidates amid safety concerns \u2014 sending a fresh wave of worry through a field that has  long struggled  to bring treatments to market. The news, released on 5 October, sent stock in Alnylam Pharmaceuticals of Cambridge, Massachusetts, plummeting by about 50%, reducing the value of the company by nearly US$3 billion in one day. The scrapped experimental drug, called revusiran, was in advanced clinical trials in people with a rare and devastating disorder called ATTR-amyloidosis with cardiomyopathy, a condition that has no treatment and is often fatal within five years of diagnosis. It was one of Alnylam\u2019s most mature drug candidates. But investors are worried about more than just the loss of one experimental drug, says analyst Alan Carr of the investment bank Needham & Company in New York City. \u201cThey\u2019re concerned that this safety signal may be an issue for the rest of the platform,\u201d he says. \u201cThat\u2019s why we\u2019ve had such a strong reaction.\u201d Alnylam chief executive John Maraganore quickly responded to counter those fears. \u201cIt is important to emphasize that the discontinuation of revusiran does not affect any other Alnylam investigational RNAi therapeutic programme in development,\u201d he said during a presentation to investors on 5 October. Yet Maraganore\u2019s assurances fell on investors who were already feeling skittish about biotechnology companies, says Carr. A  biotechnology investment boom  over the last four years pumped cash into the sector, but began to cool off late last year, he notes.\u00a0 \n             Lengthy struggle \n           First discovered in nematode worms in the late 1990s, RNAi is the process in which small strands of RNA bind to the RNA that a cell uses to translate genes into proteins, thereby interfering with gene expression. Researchers have harnessed it to study gene function. Alnylam\u2019s revusiran announcement came just three days after the field had celebrated the tenth anniversary of the  2006 Nobel Prize for Physiology or Medicine , which was awarded for the discovery of RNAi. Although experts immediately saw medical potential in RNAi, drug developers have struggled to translate the technique into a therapy, and none has yet reached the clinic. In particular, they have wrestled with delivering RNA molecules \u2014 notoriously prone to degradation \u2014 safely to their target. Alnylam has become a pioneer in that field, developing methods for shuttling RNAi around the body. The company\u2019s lead compound, called patisiran, is also in late-stage clinical trials to treat another form of ATTR-amyloidosis. Data from that trial are expected to be released next year, and several other RNAi drug candidates are in early clinical testing. Concerns about revusiran were first raised when several trial participants reported severe nerve pain. Alnylam called for a committee to review the clinical-trial data; it found that the nerve pain was not likely a result of the treatment. But it also discovered that more participants had died in the treatment arm than in the placebo arm of the trial. On reviewing the data, Alnylam decided to scrap the programme altogether. A few days before the revusiran announcement, on 28 September, the firm had announced that it had dropped another drug candidate after early tests showed that it elevated liver enzymes \u2014 a possible sign of liver toxicity. But a search through the company\u2019s safety database \u2014 which contains data from more than 800 people treated with Alnylam\u2019s RNAi drug candidates \u2014 has revealed no broader safety concerns, says Akshay Vaishnaw, Alynylam\u2019s vice-president of research and development. And revusiran, Carr notes, used an older technology to stabilize the RNA in the body. As a result, it required higher and more frequent doses than would many of Alnylam\u2019s newer drug candidates. \u201cMy view is that this reaction is overblown,\u201d he says. \u201cBut at this point, I\u2019m obviously in the minority.\u201d Read a previous Trend Watch: ' Mass production of review articles is cause for concern ' \n                   RNA interference rebooted 2014-Apr-22 \n                 \n                   Drug giants turn their backs on RNA interference 2010-Nov-23 \n                 \n                   Experimental RNA drug may cause blindness 2008-Aug-27 \n                 \n                   Youthful duo snags a swift Nobel for RNA control of genes 2006-Oct-05 \n                 \n                   Video animation: RNA interference \n                 \n                   Alnylam Pharmaceuticals: product pipeline \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20782", "url": "https://www.nature.com/articles/nature.2016.20782", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Studies in mice highlight the promises \u2014 and challenges \u2014 of CRISPR\u2013Cas9 gene editing. A mutation in a single DNA letter causes a painful and debilitating disease known as sickle-cell anaemia. Researchers have wrestled with this illness for more than 65 years, and have now added CRISPR\u2013Cas9 gene editing to their armoury. In a paper published 12 October in  Science Translational Medicine 1 , researchers reported some success in correcting the mutation in mice, though they concede that human applications are still years away. The efficiency of the process is also slightly too low for practical use, cautions author Jacob Corn, a biochemist at the University of California, Berkeley. But the advance \u2014 and other recent efforts \u2014 has given Corn hope that the first treatment to address the cause of sickle-cell anaemia could be only a few years away. \u201cWe now finally may have some paths to address the cause of the disease rather than the symptoms,\u201d he says. About 250,000 children around the world are born with sickle-cell anaemia each year. It is caused by a mutation that affects the shape of the oxygen-carrying protein haemoglobin in red blood cells. The result can be clogged blood vessels that block oxygen delivery to tissues and cause excrutiating pain. \n             A single tweak \n           On paper, curing the disease seems almost straightforward: rewrite the mutated sequence in the blood-generating stem cells of the bone marrow so that it's normal, and a patient would, in theory, be free of the illness. \u201cIt\u2019s a single base change,\u201d says Stuart Orkin, who studies blood diseases at the Dana-Farber Cancer Institute and the Boston Children\u2019s Hospital in Massachusetts. \u201cYou\u2019d think this would be the poster child of gene correction.\u201d But companies and academics alike have struggled to make progress, and even CRISPR\u2013Cas9, for all of  its ease and utility , is not yet up to the task. Researchers can target the Cas9 enzyme \u2014 or other gene-editing enzymes \u2014 to cut specific sites of the genome, but what happens next depends on the natural DNA-repair processes in the cell. Most often, that repair causes small DNA deletions. A separate repair process inserts a new sequence at the cut site. But that correction occurs with vanishing frequency in the sleepy, infrequently dividing stem cells of the bone marrow that would be the target of a sickle-cell therapy. Corn and his colleagues found a way to make the modification more efficient. They used a short DNA strand carrying the corrected sequence of the sickle-cell gene and engineered it to bind to the DNA strand left dangling after the Cas9 enzyme cuts. When used in cells taken from human sickle-cell patients, the technique increased the efficiency with which they could repair the defective genes by up to 25%. \n             Disappointing drop \n           The team then introduced these edited cells into lab mice. There, the efficiency of their technique plummeted: cells with a DNA deletion seemed to proliferate better in mice than cells with the corrected form of the gene. In mice, only up to 5% of the transplanted, edited cells produced the normal form of haemoglobin. This is right at the threshold of what might be required to alleviate patients\u2019 distress, says Corn. He adds that some physicians who have seen his data said they would be willing to try the approach in clinical trials. But Corn argues that it would be best to improve efficiency before it is deployed in people. The refined technique will be a boon for researchers looking at other applications of gene editing, says Michael Holmes, vice-president of research at Sangamo Biosciences in Richmond, California. But it also highlights another problem: the attempts at gene editing leave plenty of genes with a deletion where the Cas9 enzyme cut. Some of those deletions could result in abnormal haemoglobin production \u2014 causing another serious condition called \u03b2-thalassaemia. Sangamo also ran up against this problem, Holmes says, and decided to try a different approach. The company, and several others in the field, are using gene editing to disrupt expression of a gene that suppress the production of fetal-haemoglobin: a form of haemaglobin that is expressed in the developing fetus and resists sickling. Boosting the production of fetal-haemoglobin could thereby reduce the amount of sickle-shaped haemoglobin in adults. The latest results with CRISPR\u2013Cas9 support the idea that targeting fetal haemoglobin may still be the safer appraoch, says Holmes . \u201c There's still a long way to go towards finding ways to safely correct the gene.\u201d \n                   Promising gene therapies pose million-dollar conundrum 2016-Jun-15 \n                 \n                   Should you edit your children\u2019s genes? 2016-Feb-23 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   CRISPR: The good, the bad, and the unknown \n                 \n                   US National Institutes of Health: What is sickle cell disease? \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20777", "url": "https://www.nature.com/articles/nature.2016.20777", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Hundreds of fresh impact craters hint at possible dangers for future lunar bases. Meteorites have punched at least 222 impact craters into the Moon's surface in the past 7 years. That\u2019s 33% more than researchers expected, and suggests that future lunar astronauts may need to hunker down against incoming space rocks. \u201cIt's just something that's happening all the time,\u201d says Emerson Speyerer, an engineer at Arizona State University in Tempe and author of a 12 October paper in  Nature 1 . Planetary geologists will also need to rethink their understanding of the age of the lunar surface, which depends on counting craters and estimating how long the terrain has been pummelled by impacts. Although most of the craters dotting the Moon's surface formed millions of years ago, space rocks and debris continue to create fresh pockmarks. In 2011, a team led by Ingrid Daubar of NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, compared some of the first pictures taken by  NASA\u2019s Lunar Reconnaissance Orbiter  (LRO), which launched in 2009, with decades-old images taken by the  Apollo  astronauts. The scientists spotted  five fresh impact craters  in the LRO images. Then, on two separate occasions in 2013, other astronomers using telescopes on Earth spotted bright flashes on the Moon; LRO later flew over those locations and photographed the freshly formed craters 2 , 3 . \n             Forever young \n           LRO has taken about a million high-resolution images of the lunar surface, but only a fraction cover the same portion of terrain under the same lighting conditions at two different times. Speyerer\u2019s team used a computer program to automatically analyse 14,092 of these paired images, looking for changes between the two. The 222 newfound craters are distributed randomly across the lunar surface, and range between 2 and 43 metres in diameter. There are more fresh craters measuring at least 10 metres across than standard cratering calculations would suggest. This could mean that some young lunar surfaces may be even younger than thought, says Daubar. She calls the work \u201ca significant advance in the field of crater chronology\u201d, noting that it can even be used to compare cratering rates on the Moon and Mars. Meteorites can churn up the lunar surface in several ways. Along with the fresh craters, Speyerer's team found more than 47,000 \u2018splotches\u2019, formed when material gets kicked up by the main impact and rains down \u2014 sometimes tens of kilometres away. And that means a bigger risk for any future lunar habitats, says Stephanie Werner, a planetary geologist at the University of Oslo. The chances of a lunar base being nailed by a direct meteorite hit are relatively small, but the splattered material could pose a hazard. Werner is part of a team that has proposed  a combined orbiter\u2013lander mission  to the European Space Agency, which would study impact flashes at the Moon and quantify the risk. Read the related News & Views article: ' Moon churn ' \n                   Ice may lurk in shadows beyond Moon's poles 2012-Sep-28 \n                 \n                   A closer look at cosmic impacts 2010-Jul-27 \n                 \n                   Moon shadows even colder than thought 2009-Dec-17 \n                 \n                   Lunar impact tosses up water and stranger stuff 2009-Nov-13 \n                 \n                   Moon mission tackles water question 2009-Jun-10 \n                 \n                   Lunar Reconnaissance Orbiter \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20775", "url": "https://www.nature.com/articles/nature.2016.20775", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "CITES conference hailed as a \u201cgame changer\u201d for vulnerable species. Elephants, pangolins and parrots are among the species that were given stronger trade protections at a meeting of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), which ran from 24 September to 5 October in Johannesburg, South Africa. The 17th meeting of the CITES convention was its largest ever, attended by more than 3,500 people, including representatives of 152 governments. Delegates took decisions on 62 trade-restriction proposals in what John Scanlon, secretary-general of CITES, said was \u201ca game changer for the planet\u2019s most vulnerable wild animals and plants\u201d. Here,  Nature  picks out some of the most significant and keenly anticipated decisions \u2014 including whether particular species should be listed in Appendix I or Appendix II of the CITES treaty. The first is for species at immediate threat of extinction, for which countries agree that trade in those species or their products should be largely banned; Appendix II is for those that could face extinction in future if trade restrictions were not implemented. \n             African elephants \n           Threatened by:  Ivory poaching. Adopted protections : CITES members agreed to close the currently legal domestic ivory markets, in which ivory can be openly bought and sold. These domestic markets can be a route for the laundering of poached elephant ivory into legal trade. But delegates rejected placing southern populations of African elephants ( Loxodonta africana  and  L. cyclotis ) on Appendix 1, which would have meant a total ban of all trade in ivory and elephant products from those populations. They also rejected a proposal to legalize sales of ivory in some circumstances, which would have allowed some African governments to sell ivory stockpiles to other countries. Reaction : The agreement to close domestic markets is not binding on those who voted for it, but the Zoological Society of London nonetheless considered it \u201ca potential turning point for Africa\u2019s embattled elephants\u201d. \n             Pangolins \n           Threatened by : Poaching for traditional medicine and meat. Adopted protections:  Pangolins ( Manis  spp.) have been upgraded from CITES Appendix II to Appendix I \u2014 meaning a total trade ban in all listed species. Reaction : \u201cThis decision will help give pangolins a fighting chance.\u201d \u2014 Susan Lieberman of the Wildlife Conservation Society, headquartered in New York. \n             Sharks and rays \n           Threatened by : Overfishing. Adopted protections : Three species of thresher sharks ( Alopias  spp.), nine species of devil rays ( Mobula  spp.) and the silky shark ( Carcharhinus falciformis ) have now been added to CITES Appendix II \u2014 meaning trade restrictions will come into force. Reaction : \"This is a big win for all these species of sharks and rays as governments around the world will now have to act to ensure that trade is from sustainable and legal fisheries.\u201d \u2014 Andy Cornish of WWF International. Shark scientist Neil Hammerschlag at the University of Miami, Florida, tweeted: \u201cGreat news for shark and ray conservation!\u201d \n             Rosewood trees \n           Threatened by : Logging. Adopted protections : Trade restrictions were agreed on various species of trees used for timber, including those in the genus  Dalbergia , which are commercially traded as rosewood. They were added to CITES Appendix II. Reaction : \u201cOne of the most significant, though largely unreported outcomes,\" said the wildlife-trade monitoring group TRAFFIC, headquartered in Cambridge, UK. \n             Cheetahs \n           Threatened by : Capture for pet trade, mainly in Gulf States such as Saudi Arabia. Adopted protections : Delegates agreed a crackdown on illegal trade, because cheetahs ( Acinonyx jubatus ) are already listed in CITES Appendix I. Reaction : \u201cWe hope the CITES decisions adopted today will result in a step change in clamping down on the illegal cheetah trade.\u201d \u2014 Sarah Durant, head of the Zoological Society of London\u2019s cheetah conservation team. \n             Helmeted hornbills \n           Threatened by : Poaching for its \u2018red ivory\u2019 beak. Adopted protections:  Tightening up on illegal trade, because the helmeted hornbill ( Rhinoplax vigil ) is already listed in Appendix 1. \n             African grey parrots \n           Threatened by : Capture for the pet trade. Adopted protections : Delegates agreed a new ban on trade, adding the parrot ( Psittacus erithacus ) to CITES Appendix I. \n                   It\u2019s time to get real about conservation 2016-Oct-11 \n                 \n                   Worst year ever for rhino poaching in Africa 2016-Jan-25 \n                 \n                   China must act decisively to eradicate the ivory trade 2015-Nov-11 \n                 \n                   Will China\u2019s new ivory controls make a difference? 2015-Jun-03 \n                 Reprints and Permissions"},
{"file_id": "538150a", "url": "https://www.nature.com/articles/538150a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "As the first T-cell therapies for tumours near US approval, researchers race to engineer less-toxic alternatives. A groundbreaking treatment that arms immune cells called T\u00a0cells to battle cancer is barrelling towards regulators, fuelled by unprecedented clinical success and investor exuberance. But progress of the therapy, called CAR-T, has been marred by its toxicity; several deaths have been reported in clinical trials. Even as the first company readies its application to the US Food and Drug Administration (FDA)\u00a0\u2014\u00a0expected by the end of the year\u00a0\u2014\u00a0researchers are hard at work to make the supercharged T\u00a0cells safer. Doing so is crucial to expanding the use of the therapy to more people, says Anthony Walker, a managing partner at Alacrita, a consulting firm in London. \u201cRight now it is heroic medicine,\u201d he says \u2014 a gruelling treatment deployed only in people for whom all else has failed. \u201cPatients are taken sometimes to within an inch of their lives.\u201d Most CAR-T procedures begin by harvesting a patient\u2019s white blood cells and sifting out the T\u00a0cells. Those T\u00a0cells are engineered to recognize cancer cells, and then infused into the patient, ready to do battle. The approach has shown remarkable success against leukaemias and lymphomas: in one study, all traces of leukaemia disappeared in 90% of the patients who received the treatment ( S.\u00a0L.\u00a0Maude  et\u00a0al. N. Engl. J. Med.    371,  1507\u20131517; 2014 ). Results such as those have fuelled an investor frenzy. \u201cIt set the field on fire,\u201d says Walker. Swiss pharmaceutical giant Novartis invested in the technique in 2012. In 2014, CAR-T firm Kite Pharma of Santa Monica, California, raised US$128\u00a0million when it went public. A few months later, one of its competitors, Juno Therapeutics of Seattle, Washington, yielded $264\u00a0million in its initial public offering. Now Kite is racing to be the first to bring a CAR-T therapy to the market. On 18\u00a0October, the company will update investors on its plans to manufacture and sell the complex therapy, which it hopes to launch in 2017. But the treatment\u2019s toxicity has discouraged some investors. On 26\u00a0September, Kite released interim clinical-trial results \u2014 widely seen as successful \u2014 in people with aggressive non-Hodgkin\u2019s lymphoma (see  go.nature.com/2djdqen ). Yet about one-third of the patients developed serious neurological side effects, and 18% developed a deadly condition called cytokine release syndrome, which can cause organ failure. Two of the 62\u00a0patients died as a result of the treatment. That toxicity is unlikely to dissuade the FDA, given the dramatic effects of the treatment, says analyst Michael Yee of the investment bank RBC Capital Markets in San Francisco, California. \u201cIt has transformed what was essentially a death sentence into a potential for long-lasting remission,\u201d he says. But the toxicity does leave room for improvement. One approach that researchers are studying to boost safety is to improve standardization of each patient\u2019s dose of T\u00a0cells. CAR-T therapies typically begin with a mixture of various kinds of T\u00a0cell, some with very different functions. \u201cNot all T\u00a0cells are created equal,\u201d says Stanley Riddell, an immunologist at the Fred Hutchinson Cancer Research Center in Seattle. To create a better-defined T-cell cocktail, Riddell\u2019s lab first sorts out different types of T\u00a0cell and blends them together again in specific proportions. So far, he says, trials in 140\u00a0patients suggest that the approach provides better control of dosage \u2014 and toxicity (see, for example,  C. J. Turtle  et al. J. Clin. Invest.    126,  2123\u20132138; 2016 ). Other groups have developed a \u2018suicide switch\u2019 to shut off the CAR-T cells in the body. If toxicity is spiralling out of control, doctors can administer a drug that activates the switch \u2014 a modified version of a protein called caspase-9 \u2014 and triggers the CAR-T cells to self-destruct. That approach has not been popular with clinical researchers, who often opt to treat toxic reactions with other drugs rather than risk shutting down the treatment altogether, notes Michel Sadelain, an immunologist at Memorial Sloan Kettering Cancer Center in New York City. \u201cWhat you\u2019re doing is destroying your extremely expensive medication after you\u2019ve administered it,\u201d says Walker. But cancer researcher Malcolm Brenner of Baylor College of Medicine in Houston, Texas, says that the switch is not all or nothing: adding just a little of the activation drug can dampen toxic effects without killing all of the engineered T\u00a0cells. Michael Brown, a clinician and cancer researcher at the Royal Adelaide Hospital in Australia, is using the suicide-switch approach in his CAR-T clinical trial against melanoma. So far, he says, his patients haven\u2019t needed it. But having the switch in place helped him to feel more secure about the trial, in which T\u00a0cells target a protein that is more abundant in melanoma but is also expressed at low levels in normal brain tissue. Many researchers hope to reproduce CAR-T\u2019s success against leukaemia in solid tumours such as melanoma. And, like Brown, they are struggling to find proteins on cancer cells that could serve as targets for T\u00a0cells but that are absent from normal tissues. One way could be to focus on multiple proteins expressed by cancer cells, says Sadelain. The therapy will then attack only cells that express all of those proteins, to provide a more precise way to mark tumour cells for destruction. For now, all eyes are on Kite to see whether it can get its therapy approved by regulators and into hospitals. Even if the company succeeds, Walker is betting that the treatment will be the first in a long line of CAR-T therapies. \u201cWe\u2019re at such an early stage in this field,\u201d he says. \u201cIf you wind the clock forward 10\u201315\u00a0years, I think it will be unrecognizable.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                   \n                     Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                   \n                     Immune cells boost cancer survival from months to years 2014-Dec-10 \n                   \n                     Immune system offers clues to cancer treatment 2014-Nov-26 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Nature Outlook: Precision medicine \n                   \n                     Nature Outlook: Cancer immunotherapy \n                   \n                     US National Cancer Institute: CAR-T Therapy \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20778", "url": "https://www.nature.com/articles/nature.2016.20778", "year": 2016, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Two former workers say that they were treated unfairly on the basis of age and disability. Two former researchers at the  troubled Arecibo Observatory  in Puerto Rico have filed a lawsuit claiming that illegal discrimination and retaliation led to their dismissal. James Richardson and Elizabeth Sternke are suing the Universities Space Research Association (USRA), which oversees radio astronomy and planetary science at Arecibo, and the observatory\u2019s deputy director, Joan Schmelz \u2014  a prominent advocate for women in astronomy . Richardson and Sternke, a married couple in their mid-50s, allege that Schmelz discriminated against them because of their age and because Richardson is legally blind. Soon after Sternke revealed in November 2015 that she planned to file a complaint with the US Equal Opportunity Commission (EEOC), which investigates workplace bias, USRA announced that her contract job with Arecibo\u2019s education programme would end early. Richardson filed his own EEOC complaint, and in April 2016, USRA terminated his employment as a staff scientist. The EEOC ultimately found evidence of discrimination and that Sternke and Richardson were terminated in retaliation for their complaints, according to documents provided by the researchers' lawyer. In their lawsuit, filed on 4 October in the US District Court in Puerto Rico, Richardson and Sternke are seeking more than US$20 million in back pay and damages. Schmelz says that she cannot comment on the lawsuit, and declined to answer  Nature 's questions. But USRA, her co-defendant and employer, \u201cfirmly denies these allegations and plans to vigorously defend this matter\u201d, it said in a statement to  Nature . The legal challenge comes as the 53-year-old observatory battles to survive. Its single-dish radio telescope, one of the world\u2019s biggest, is still in high demand. But the US National Science Foundation (NSF), which provides roughly two-thirds of the observatory\u2019s $12 million funding, is  facing a budget crunch . The agency is now conducting  an environmental review  of major changes to the site, a possible prelude to mothballing or even demolishing the facility. The NSF\u2019s decision on Arecibo\u2019s fate is expected in 2017. Some Arecibo supporters worry that the lawsuit could nudge the observatory closer to the edge. \u201cWith all those budget difficulties they\u2019re having now, getting bad press is not going to be good for them,\u201d says Alan Harris of the planetary-science consulting firm MoreData! in La Ca\u00f1ada, California. \n               Leadership changes \n             USRA hired Richardson in 2014 as a scientist with Arecibo\u2019s planetary radar group, which observes potentially dangerous asteroids and other Solar-System bodies. He did not follow the typical academic path: according to Richardson\u2019s website, he worked as a nuclear engineer \u2014 including a stint on a US Navy submarine \u2014 before being blinded in a chemical accident and re-training as a planetary scientist. In 2014, Sternke, a sociologist who was Richardson\u2019s fianc\u00e9e at the time, joined him at Arecibo and later began working at the observatory on a short-term contract in 2015. According to EEOC determinations issued in June, Sternke and Richardson\u2019s work initially drew no complaints from management. After Richardson\u2019s boss, the head of planetary radar, announced his resignation in early 2015, Richardson sought the job. Several months later, Schmelz took up her post at Arecibo. From the start, the lawsuit says, Schmelz \u201cignored and/or chose to avoid all contact\u201d with Richardson, assigned duties to younger colleagues rather than to him, and \u201cmarginalized and ostracized\u201d Richardson and Sternke. The EEOC report also says that USRA altered the description of the job Richardson wanted \u201cto make it more suitable for another internal candidate to qualify\u201d. USRA subsequently promoted an Arecibo staffer in his 30s. Sternke submitted her resignation in November, the EEOC says. She later told USRA that she planned to file a complaint with the EEOC, the agency\u2019s report says, and was terminated on 4 December, eight days before her scheduled last day. The lawsuit alleges that in December of 2015, officials from the USRA human-resources department accused Richardson of \u201cangry behavior, bullying, and prejudices\u201d. He was terminated in April 2016 after USRA determined that he failed to meet the terms of its 'Performance Improvement Plan'. (Richardson disagrees with that assessment.) In its report on Richardson\u2019s case, the EEOC said Schmelz \u201cmade direct discriminatory age based comments\u201d, writing in her own performance evaluation that she had recruited \u201ca set of effective young leaders\u201d. The EEOC also found that Richardson was \u201cdisciplined and terminated from his employment\u201d on the basis of his age and disability, and in retaliation for his association with Sternke and for filing an EEOC charge. In a separate report, the agency found that USRA terminated Sternke\u2019s employment \u201cdue to her age (over 50) and in retaliation for complaining about illegal discrimination\u201d. The EEOC suggested that USRA pay Richardson $400,000 in damages, plus back pay, and give Sternke $200,000. But settlement talks with the EEOC failed, and in late July the agency notified Richardson and Sternke that they had 90 days to file suit. \n               Sadness and surprise \n             Richardson\u2019s former colleagues say that he is not a bully. \u201cI never heard him raise his voice, let alone get angry,\u201d says Phillip Nicholson, an astronomer at Cornell University in Ithaca, New York, where Richardson did research. His postdoctoral supervisor at Cornell, astronomer Joseph Veverka, describes Richardson as courteous and kind, if demanding. \u201cIf anyone asked Jim to do something which he did not consider completely scientifically proper, he would strongly object.\u201d Meanwhile, former Arecibo director Robert Kerr says that his USRA colleagues \u2014 including Schmelz \u2014 displayed \u201cthe utmost professionalism\u201d. \u201cJoan was no different from the rest,\u201d he adds. Meg Urry , an astrophysicist at Yale University in New Haven, Connecticut, notes that Schmelz is a tireless advocate for the right of female astronomers  to work without harassment . \u201cShe's devoted a lot of time to justice,\u201d says Urry, the past president of the American Astronomical Society. In one notable case, Schmelz helped to bring harassment complaints against astronomer Geoff Marcy; after the University of California, Berkeley,  found that Marcy violated its policies  on harassment, he retired in late 2015. The district court in Puerto Rico has not yet scheduled a hearing on Richardson and Sternke\u2019s lawsuit. In the meantime, Nicholson is struggling to make sense of the situation, given what he knows of the parties on both sides. \u201cNothing seems to ring true to the character of the people,\u201d he says. \n                     365 days: Nature\u2019s 10 2015-Dec-17 \n                   \n                     Radio interference 2015-Nov-10 \n                   \n                     Arecibo Observatory director quits after funding row 2015-Nov-09 \n                   \n                     US struggles to offload telescopes 2014-Jan-28 \n                   \n                     Change rattles the world's biggest dish 2011-May-24 \n                   \n                     Arecibo Observatory \n                   \n                     Universities Space Research Association \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20804", "url": "https://www.nature.com/articles/nature.2016.20804", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "More-advanced implants will be needed to restore full sensation throughout the body. For the first time, a paralysed man has gained a limited sense of touch, thanks to an electric implant that stimulates his brain and allows him to feel pressure-like sensations in the fingers of a robotic arm. The advance\u00a0raises the possibility of restoring limited sensation to various\u00a0areas of the body, as well as giving people with spinal-cord injuries better control over prosthetic limbs. But restoring human-like feeling, such as sensations of heat or pain, will prove more challenging, the researchers say. Nathan Copeland\u00a0had not been able to feel or move his legs and lower arms since a car accident\u00a0snapped his neck and injured his spinal cord when he was 18. Now, some 12\u00a0years later, he can feel when a robotic arm has its fingers touched, because sensors on the fingers are linked to an implant in his brain. \u201cHe says the sensations feel like they\u2019re coming from his own hand,\u201d says Robert Gaunt, a biomedical engineer at the University of Pittsburgh who led the study. \u201cI can feel just about every finger\u2014it\u2019s a really weird sensation,\u201d Copeland said, about a month after surgery, in a press release. \u201cSometimes it feels electrical and sometimes its pressure, but for the most part, I can tell most of the fingers with definite precision. It feels like my fingers are getting touched or pushed.\u201d Dustin Tyler, a biomedical engineer at Case Western Reserve University in Cleveland, Ohio, says the results as \u201ca significant and critical advance\u201d and a step towards restoring sensation in people with paralysis. The project's funders, the Defense Advanced Research Projects Agency, had revealed the advance in September 2015, but full details of the work were published on 13 October in  Science Translational Medicine 1 . \n             Augmented limbs \n           The work builds on previous achievements, whereby prosthetic arms fitted with touch sensors and wired into nerves in the stumps left by amputation allowed participants  to perceive pressure and texture .\u00a0But achieving the feat in people with spinal-cord injuries is more challenging because the connections between their limbs and\u00a0brain have been damaged or severed. Electrically stimulating the brain region that received sensory information from the rest of the body, the somatosensory cortex, can produce touch-like sensations, according to experiments in people undergoing brain surgery for other reasons. But these were relatively crude efforts. \u201cPeople have described feeling a buzz or a vibrating sensation, but it isn\u2019t a natural thing and it usually crosses multiple fingers,\u201d says Elizabeth Tyler-Kabara, a neurological surgeon at the University of Pittsburgh in Pennsylvania and a co-author of the current study. \u00a0 Copeland, by contrast, had two microelectrode arrays (each about 4 millimetres across) implanted into his somatosensory cortex, and two other electrodes positioned in the portion of the motor cortex that controls hand and arm movement. Wires from all of these electrodes passed out of his head, and could be connected to a computer and a robotic arm. When the team stimulated the sensory brain areas four weeks after implanting the device, Copeland experienced touch-like sensations when the electrodes were activated by the computer. And when sensors on the fingers of the robotic arm linked to electrodes in Copeland\u2019s brain were touched, he could tell which fingers were being stimulated \u2014 and sometimes, which regions of those fingers. The paper describes the first 6 months of the experience, but Copeland has now had the implant for 17 months and the responses have remained stable. This is encouraging, says Tyler-Kabara, because it suggests that the connections do not alter with time and that the electrical stimulation is not damaging the brain. There are limitations. Although Copeland reported feeling basic pressure-like touch, he did not experience sensations of movement, temperature or pain; nor can he feel the fingertips or thumb of the robotic arm. Moving the chips\u00a0or adding more of them might render more of the hand sensitive. Howeer, feelings such as movement are perceived by less accessible brain regions than are sensations of pressure \u2014 and the brain regions corresponding to some other body parts such as the feet are also less accessible than those for the hands. \n             Deep implants \n           These challenges could potentially be overcome by developing refined implants with more electrodes, or using flexible materials that can be implanted deeper into the brain. Researchers are also looking into wireless connections between implants and prostheses. With current technology, every extra chip needs more wires connected to the brain, which increases the risk of infection. Even with these advances, it is still unlikely that full sensation could be imbued to a robotic arm, says Andrew Jackson, a neuroscientist at Newcastle University, UK. \u201cThe kind of dextrous manipulation that able-bodied people take for granted relies upon a very complex signal from many receptors in your hand, so I think these techniques are likely to be of limited use in terms of improving control.\u201d\u00a0 Still, reinstating even a basic sense of touch to those with paralysed or missing limbs could transform their lives, Jackson adds. \u201cIf someone hasn\u2019t felt their arm for many years, it could make an awful lot of difference in terms of how they feel about their connection to the outside world.\u201d \n                   Welcome to the Cyborg Olympics 2016-Aug-03 \n                 \n                   The Pentagon\u2019s gamble on brain implants, bionic limbs and combat exoskeletons 2015-Jun-10 \n                 \n                   US regulators move on thought-controlled prosthetics 2014-Nov-26 \n                 \n                   Artificial arms get closer to the real thing 2014-Oct-08 \n                 \n                   Neuroprosthetics: Once more, with feeling 2013-May-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20808", "url": "https://www.nature.com/articles/nature.2016.20808", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Researchers at odds in head-to-head press briefing. Plans by the UK government to shake up how the country\u2019s research is funded are causing dissent among leading British scientists. At a press briefing held on 13 October at London\u2019s Science Media Centre, some of the country\u2019s most eminent researchers clashed over the  draft laws , which would bring together several funding bodies \u2014 including the seven research councils \u2014 into one central funder called United Kingdom Research and Innovation (UKRI). \u201cThis is a controversial and unnecessary and probably, in the long term, damaging change,\u201d said Martin Rees, an astronomer at the University of Cambridge and a former president of the Royal Society in London. \u201cThe upheaval involved in setting up UKRI will do more harm than good.\u201d Sitting next to Rees was an equally prominent figure arguing in favour of the change: Paul Nurse, who leads London\u2019s Francis Crick Institute and is also a former president of the Royal Society.\u00a0 Nurse led a  review of the existing system  that formed the basis for the government\u2019s proposals, which were introduced to Parliament on 19 May as the Higher Education and Research Bill. He argues that the bill could strengthen the voice of science in government and address the \u201cpitifully low\u201d levels of science funding compared with in other developed nations. \u201cThe present system has not been strong enough in its interactions with government,\u201d he said. \u201cProperly set up, UKRI can deliver that.\u201d \u201cI completely agree we need a much stronger voice for science,\u201d said Rees. But with a new government and problems  caused by the United Kingdom\u2019s vote to leave the European Union , \u201cthe last thing we need is a major overhaul\u201d. \n             Removal of autonomy \n           A major talking point of the reform bill \u2014 and the trigger for the press briefing \u2014 is the concern that it may open the door to more government interference in science funding and higher education. The bill would remove some of the legal instruments that have given the research councils formal autonomy over what they fund, and gives ministers the right to create and dissolve areas of research funding. It would also overhauls university governance, creating a new governmental body to regulate universities and allowing ministers to suggest courses for universities to teach. In an  editorial published on 4 October ,  Nature  argued that the moves \u201cwill upend globally accepted norms that protect independence and self-determination in science and higher education\u201d. Nurse, however, said at the press conference that the  Nature  editorial was \u201calarmist\u201d and \u201clazy thinking\u201d. And another eminent UK scientist \u2014 John Krebs, a zoologist at the University of Oxford, UK, and president of the British Science Association \u2014 warned against adopting the bill in an  article . \u201cIt is by no means obvious that it will improve an already excellent system of universities and research. It could do substantial harm,\u201d he wrote. Changes to the autonomy of universities would be \u201cin effect a nationalization of our university system\u201d, Stephen Curry, a structural biologist at Imperial College London, told journalists at the press conference. The bill, he said, is \u201cbad law\u201d and must be amended. Researchers expect the bill to pass swiftly through the House of Commons. But many scientists hope that it will be scrutinized more carefully and amended in the House of Lords. Ottoline Leyser, a plant biologist who is the director of the University of Cambridge\u2019s Sainsbury Laboratory, said that there is \u201cwidespread agreement\u201d in academia that the bill is a \u201ccurate\u2019s egg\u201d \u2014 a mix of good and bad parts. But the good bits are worth keeping, she said. \n                   Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                 \n                   Powerful new agency recommended to oversee UK science funding 2015-Nov-19 \n                 \n                   Europe\u2019s superlab: Sir Paul\u2019s cathedral 2015-Jun-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20802", "url": "https://www.nature.com/articles/nature.2016.20802", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Uncertain government funding drives effort to beef up private support for research. Poring over a list of the top 50 US philanthropists in 2014, physicist Marc Kastner noticed that 16 were based in California, compared with just 6 in New York, Connecticut and New Jersey combined. \u201cThat made it pretty clear where I should be,\u201d says Kastner, who established the offices of the Science Philanthropy Alliance in Palo Alto, California, when he was named the organization\u2019s first president in February 2015. The alliance is made up of philanthropic organizations that encourage funding in basic research and advise other philanthropists \u2014 especially new ones \u2014 on how to go about it. That bet paid off last month, when Facebook founder Mark Zuckerberg and physician and educator Priscilla Chan announced that their  Chan Zuckerberg Initiative  would spend at least US$3-billion on medical research over the next decade. In remarks describing the initiative's plan to eliminate, manage or prevent all major disease by 2100, Zuckerberg urged fellow philanthropists to seek advice from Kastner. \u201cThis is a milestone for the alliance, in the sense that its goal is to try to increase the funding for basic research across many fields, not just in biology,\u201d says Robert Tjian, former president of the Howard Hughes Medical Institute (HHMI) in Chevy Chase, Maryland. The HHMI was one of 6 founders of the alliance, which now counts 15 members. They include heavy hitters such as the Palo Alto-based Gordon and Betty Moore Foundation, the Kavli Foundation in Oxnard, California, and the London-based Wellcome Trust. Smaller up-and-coming members include the Eric and Wendy Schmidt Fund for Strategic Innovation in Palo Alto and the Heising-Simons Foundation, based in Los Altos, California. \n               Basic support \n             The alliance formed in 2013 after a  budget crunch hammered US government funding  for research. The group focuses on boosting private giving to basic research, as  pressure intensifies on agencies  such as the US National Institutes of Health to fund more applied and translational research. Kastner says he was drawn to his current job after watching young physicists struggling to start their careers at the Massachusetts Institute of Technology in Cambridge, where he worked for more than 40 years. \u201cThere was a need to support basic research that wasn\u2019t being met, and I thought I could help by having philanthropists do some of that,\u201d he says. The physicist is poised to make a major impact on the shape of US philanthropy as its centre of gravity shifts west, away from New York, where philanthropic families such as the Rockefellers and the Carnegies based their foundations in the early twentieth century. West coast philanthropy is anchored by established players such as the Bill and Melinda Gates Foundation in Seattle, Washington. But new ones are joining at a rapid clip, such as the Parker Foundation in San Francisco, California, founded by Napster's Sean Parker. He has spent upwards of $280 million on cancer, allergy and malaria research. \n               A guiding hand \n             Chan and Zuckerberg\u2019s announcement showcases how the Science Philanthropy Alliance works. Initially, the pair considered funding translational research. But after conversations with the alliance, among other advisers, over many months, they decided to concentrate on fundamental research, especially the building of scientific tools and technologies. The alliance provided the couple with connections to scientists, as well as advice on defining basic research and how to structure and run a scientific advisory board. \u201cPhilanthropists don\u2019t want us to tell them what kind of research to support, but they want to make sure they\u2019re doing it in the best way possible, and that\u2019s what we want, too,\u201d says Kastner. The alliance also convenes private meetings at which members discuss questions such as how to measure the impact of philanthropic spending, and whether science funding is best spent on people, places or projects, says Harvey Fineberg, president of the Gordon and Betty Moore Foundation. Crucially, the alliance does all of its work on a confidential basis. So Kastner won\u2019t say what\u2019s coming next. But he promises that it will be significant: \u201cWe\u2019re talking to people who have the potential of making very big contributions to basic science.\u201d \n                     Facebook couple commits $3 billion to cure disease 2016-Sep-21 \n                   \n                     Japan finds a key to unlock philanthropy 2012-Feb-08 \n                   \n                     Finding philanthropy: Like it? Pay for it 2012-Jan-18 \n                   \n                     UK cancer charity slashes research budget 2011-Dec-08 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20809", "url": "https://www.nature.com/articles/nature.2016.20809", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "The new estimate could help astronomers better understand how galaxies form and grow. The observable Universe contains about 2 trillion galaxies \u2014 more than ten times as many as previously estimated, according to the first significant revision of the count in two decades 1 . Since the mid-1990s, the working estimate for the number of galaxies in the Universe has been around 120 billion. That number was based mainly on a 1996 study called Hubble Deep Field 2 , in which researchers pointed the Hubble Space Telescope at a small region of space for a total of ten days, so that the long exposure would reveal extremely faint objects. This view encompassed galaxies up to 3.7 billion parsecs (12 billion light years) away, which appear to us as they existed less than 2 billion years after the Big Bang. Astrophysicists then counted the galaxies within that narrow field of view and extrapolated the number to the full sky \u2014 under the assumption that it would look similar in all directions \u2014 to get the figure of 120 billion. However, there weren\u2019t enough galaxies in the Hubble Deep Field image to account for the density of matter distributed throughout the Universe. Researchers knew that the missing matter had to be in the form of galaxies too faint to see, as gas and dark matter. \u201cWe always knew there were going to be more galaxies than that,\u201d says astrophysicist Christopher Conselice of the University of Nottingham, UK, a co-author of the latest estimate. \u201cBut we didn\u2019t know how many existed because we couldn\u2019t image them.\u201d More  recent deep-field studies  conducted using Hubble \u2014 including after NASA upgraded the observatory in 2009 \u2014 and other telescopes enabled Conselice and his collaborators to count visible galaxies out to distances of 4 billion parsecs (13 billion light years). The researchers were able to plot the number of galaxies of a given mass that corresponded to various distances away from Earth. They then extrapolated their estimates to account for galaxies too small and faint for telescopes to pick up, and calculated that the observable Universe should contain 2 trillion galaxies. The paper 1  has been accepted for publication in  The Astrophysical Journal . \n             Moments in time \n           The team\u2019s count was not too surprising, says astronomer Steven Finkelstein of the University of Texas at Austin, but it is still helpful to have a number. \u201cI don't know of anyone who has done this before,\u201d he says. Conselice says that theorists had expected the number to be even higher; he and his collaborators now plan to look into the discrepancy. At present, researchers can directly observe only about 10% of the 2 trillion galaxies. But that will change in two years, when Hubble\u2019s successor, the James Webb Space Telescope, is deployed, Conselice says. That telescope should also be able to peer much further back in time, to see how galaxies started to form, he adds. The study might lead to an improved understanding of galaxies by refining simulations of galaxy formation and enabling more detailed assessments of how they grow. But for now, the results are consistent with the general theory of how galaxies form, in which most start very small, and then undergo a furious period of mergers and acquisitions, says Debra Elmegreen, an astronomer at Vassar College in Poughkeepsie, New York. Because it takes so long for light from galaxies in the far reaches of the Universe to reach Earth, the picture we see today is a snapshot in time, and many of the galaxies included in the new estimate no longer exist. They have probably merged into larger galaxies \u2014 so the current number of galaxies that actually exist now is expected to be much lower than 2 trillion. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Astronomy: Hubble's legacy 2015-Apr-15 \n                 \n                   How the Hubble Telescope cheated death 2015-Apr-15 \n                 \n                   Hubble telescope reveals deepest view of the Universe yet 2014-Jan-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20784", "url": "https://www.nature.com/articles/nature.2016.20784", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "DeepMind\u2019s latest technique uses external memory to solve tasks that require logic and reasoning \u2014 a step toward more human-like AI. Artificial-intelligence (AI) systems known as neural networks can  recognize images ,  translate languages  and even  master the ancient game of Go . But their limited ability to represent complex relationships between data or variables has prevented them from conquering tasks that require logic and reasoning. In a paper published in  Nature  on 12 October 1 , the Google-owned company DeepMind in London reveals that it has taken a step towards overcoming this hurdle by creating a neural network with an external memory. The combination allows the neural network not only to learn, but to use memory to store and recall facts to make inferences like a conventional algorithm. This in turn enables it to tackle problems such as navigating the London Underground without any prior knowledge and solving logic puzzles. Though solving these problems would not be impressive for an algorithm programmed to do so, the hybrid system manages to accomplish this without any predefined rules. Although the approach is not entirely new \u2014 DeepMind itself reported attempting a similar feat in a preprint in 2014 2  \u2014 \u201cthe progress made in this paper is remarkable\u201d, says Yoshua Bengio, a computer scientist at the University of Montreal in Canada. \n             Memory magic \n           A neural network learns by strengthening connections between virtual neuron-like units. Without a memory, such a network might need to see\u00a0a specific London Undeground map thousands of times to learn the best way to navigate the tube. DeepMind's new system \u2014 which they call a 'differentiable neural computer' \u2014 can make sense of a map it has never seen before. It first trains its neural network on randomly generated map-like structures (which could represent stations connected by lines, or other relationships), in the process learning how to store descriptions of these relationships in its external memory as well as answer questions about them. Confronted with a new map, the DeepMind system can write these new relationships \u2014 connections between Underground stations, in one example from the paper \u2014 to memory, and recall it to plan a route. DeepMind\u2019s AI system used the same technique to tackle puzzles that require reasoning. After training on 20 different types of question-and-answer problems, it learnt to make accurate deductions. For example, the system deduced correctly that a ball is in a playground, having been informed that \u201cJohn picked up the football\u201d and \u201cJohn is in the playground\u201d. It got such problems right more than 96% of the time. The system performed better than \u2018recurrent neural networks\u2019, which also have a memory, but one that is in the fabric of the network itself, and so is less flexible than an external memory. Although the DeepMind technique has proven itself on only artificial problems, it could be applied to real-world tasks that involve making inferences from huge amounts of data. This could solve questions whose answers are not explicitly stated in the data set, says Alex Graves, a computer scientist at DeepMind and a co-author on the paper. For example, to determine whether two people lived in the same country at the same time, the system might collate facts from their respective Wikipedia pages. Although the puzzles tackled by DeepMind\u2019s AI are simple, Bengio sees the paper as a signal that neural networks are advancing beyond mere pattern recognition to human-like tasks such as reasoning. \u201cThis extension is very important if we want to approach human-level AI.\u201d \n                   Can we open the black box of AI? 2016-Oct-05 \n                 \n                   Artificial intelligence called in to tackle LHC data deluge 2015-Dec-01 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 \n                   Nature Special: The Go Files \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20810", "url": "https://www.nature.com/articles/nature.2016.20810", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Use of heat-trapping hydrofluorocarbons to be cut sharply under ozone treaty. Negotiators from 197 countries have reached a historic agreement to reduce emissions of chemical refrigerants that contribute to global warming. The deal, finalized on 15 October  at a United Nations meeting in Kigali, Rwanda , could reduce projected emissions by as much as 88% over the course of the twenty-first century.\u00a0 \u201cIt\u2019s a great deal for the climate,\u201d says Guus Velders, an atmospheric scientist at the National Institute for Public Health and the Environment in Bilthoven, the Netherlands.\u00a0 The pact represents a major expansion of the 1987 Montreal Protocol, which was intended to halt the destruction of Earth\u2019s protective ozone layer. That treaty  successfully curbed the use of ozone-depleting chemicals  used as refrigerants and in other industrial processes, but many of their replacements \u2014 known as hydrofluorocarbons (HFCs) \u2014  are potent greenhouse gases . Governments will now use the Montreal agreement to promote a new generation of chemicals that are safe for the climate as well as for the ozone layer. HFCs account for a small but growing slice of the world\u2019s greenhouse-gas emissions. Scientists project that HFCs could contribute up to 0.5 \u00b0C of warming by the end of the century if left unchecked 1 , 2 . Velders\u2019 calculations suggest that contribution could be slashed to just 0.06 \u00b0C, provided countries stick to the schedules laid out in the Kigali agreement. The pact comes amid a flurry of international activity to address climate change. On 6 October, the UN\u2019s International Civil Aviation Organization struck a deal intended to slow the growth in  emissions from international aviation . A day earlier, the European Union pushed the world across a critical threshold by  joining the 2015 Paris climate agreement , ensuring that the pact would come into force this year. \n             Eyes on the prize \n           But advocates say that the HFC agreement is a singular accomplishment. The aviation\u00a0agreement attracted criticism for being too weak, and the world hasn\u2019t even begun to test the effectiveness of the Paris agreement, which is a collection of voluntary pledges. The machinery of the Montreal Protocol, however, has proved enormously effective in promoting and diffusing environmentally friendly technologies across the world. \u201cWe are extraordinarily confident that this treaty will deliver,\u201d says Durwood Zaelke, president of the Institute for Governance and Sustainable Development, an advocacy group based in Washington DC. One difference is that the chemical industry has been able to develop viable alternatives to the chemicals in question. Developed countries are the first to adopt these alternatives. They then help to pay for developing countries to make the conversion. Much of the debate in Kigali centred on how much time developing countries should be given to make the transition.\u00a0 Although the United States and other developed countries pushed for fast implementation, the final deal relaxed the timetables for countries such as India and other developing countries. That leaves some work to do, but the Montreal Protocol has a history of setting initial targets and then tightening the requirements over time as technologies improve and costs fall, Zaelke says.\u00a0 The debate began in earnest in 2009 but moved slowly, partly because of resistance among many developing countries and partly because of political turf issues. Until now, HFCs have fallen under the sole jurisdiction of the United Nations climate treaty. The delay has frustrated many scientists and environmentalists who felt that the Montreal Protocol was ideally suited to deal with the chemicals that it spawned. \u201cIt\u2019s a PhD thesis as to why and how it took seven years to get here,\u201d says David Fahey, an atmospheric scientist with the US National Oceanic and Atmospheric Administration in Boulder, Colorado, and co-chair of a scientific assessment panel under the Montreal Protocol. \n                   World leaders discuss ban of climate-busting refrigerants 2016-Oct-10 \n                 \n                   Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                 \n                   Deal emerges to curb greenhouse-gas emissions from aviation 2016-Sep-27 \n                 \n                   A breath of fresh air 2015-Nov-11 \n                 \n                   Ozone-hole treaty slowed global warming 2013-Nov-10 \n                 \n                   Climate burden of refrigerants rockets 2009-Jun-22 \n                 \n                   Cutting out the chemicals 2009-Jan-28 \n                 \n                   UN Ozone Secretariat \n                 \n                   WMO/UNEP ozone assessments \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20807", "url": "https://www.nature.com/articles/nature.2016.20807", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Team of leading biologist Olivier Voinnet chalks up eighth retraction. Following a high-profile retraction, Swiss and French research institutions have confirmed that they are jointly conducting a new inquiry into work from the troubled group of leading plant biologist Olivier Voinnet. Voinnet himself is not at the centre of the latest inquiry, however. Voinnet is renowned for his research on how RNA interference allows plants, invertebrates and mammals to combat viruses. But last year, the French National Centre for Scientific Research (CNRS) and the Swiss Federal Institute of Technology in Zurich (ETH Zurich)  found, in separate reports, that images had been manipulated in some of his group\u2019s papers . The CNRS, where Voinnet is a senior, tenured scientist, suspended him for two years, but he has been on secondment to ETH Zurich since 2010, so the suspension will take effect only if he returns to work in France. Since mid-2015, seven papers authored by Voinnet and his colleagues have been retracted, and many more corrected. Now, the researchers have notched up an eighth retraction,  issued by  Science  on 13 October. The paper in question is one of several that are the subject of a new joint inquiry by the CNRS and ETH Zurich, says Vanessa Bleich, a spokesperson for ETH Zurich. The two organizations had  announced  the bare bones of that inquiry on 8 September, but stated at the time only that it was prompted by \u201cserious doubt\u201d that had emerged \u201cover the past few weeks\u201d about figures in \u201cseveral molecular biology publications\u201d; CNRS will take the lead in the inquiry, the statement added. Bleich says Voinnet is not at the centre of the inquiry, although he is a co-author of some of the papers under investigation. (A Swiss newspaper,  Neue Z\u00fcrcher Zeitung , had also reported Voinnet's connection to the inquiry in September). \n             Figure irregularities \n           The latest retraction notice relates to a 2010 paper that had already received two corrections and an erratum. It says that Voinnet had \"recently informed\u201d  Science  that the erratum \u201cdoes not address all figure irregularities in the paper and that these irregularities are, in fact, extensive and inappropriate image duplications and manipulations that cannot be considered the result of mistakes\u201d. Voinnet told  Nature 's news team that he would like to discuss the situation but was not allowed to comment on the retraction until the inquiry was complete. He said that he drew the issue to  Science 's attention after an anonymous poster pointed in July on the PubPeer website to further problems with the group's paper. The notice adds that all the paper's authors agreed that it should be retracted, except for one co-author, Patrice Dunoyer, who had not responded to  Science\u2019 s communications by the time the journal\u2019s retraction went to press. But the journal appended an editor's note, saying that he got in touch afterwards to approve the retraction. (Before either the retraction or editor's note appeared,  Nature \u2019s news team had asked Dunoyer why he hadn\u2019t responded: he said he had been on sick leave.) Dunoyer, who works on RNA biology at the CNRS\u2019s Institute of Molecular and Cellular Biology, says that he is also unable to comment while the joint inquiry is ongoing. The same  Science  paper had already been investigated by ETH Zurich during its earlier inquiry. But in last year\u2019s report, the institution recommended that the paper only be corrected, not retracted \u2014 on the grounds that the raw data and documentation of the experiments substantiated its scientific conclusions. Bleich declined to comment on why the earlier inquiry didn\u2019t flag up the latest issues. Little more is known about the terms of the new inquiry. In their September statement, the CNRS and ETH Zurich noted that the names of the experts on the inquiry commission were being withheld at this stage, \u201cto guarantee that the inquiry is conducted serenely\u201d. Once completed, the results of the inquiry will be made public, as will any disciplinary measures, they added. \n                   Leading plant biologist found to have committed misconduct 2015-Jul-10 \n                 \n                   The image detective who roots out manuscript flaws 2015-Jun-12 \n                 \n                   Research ethics: 3 ways to blow the whistle 2013-Nov-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20758", "url": "https://www.nature.com/articles/nature.2016.20758", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Agency looks to time-allocation model in an era of shifting commercial and international interests. NASA is looking at a new way of studying Mars. Starting in the 2020s, scientists who participate in the agency\u2019s Mars missions might no longer design and build their own highly specialized payloads to explore the red planet. Instead, planetary scientists could find themselves operating much as astronomers who use large telescopes do now: applying for time to use a spacecraft built with a generic suite of scientific instruments. The proposed change is spurred by NASA\u2019s waning influence at Mars. The agency\u2019s long-running string of spacecraft is winding to a close, and international and commercial interests are on the rise. By the middle of the next decade,  European , Chinese, Emirati and SpaceX missions are as likely to be at Mars as NASA is. Jim Watzin, head of NASA\u2019s Mars exploration programme in Washington DC, suggested the new approach to the red planet on 6 October at a virtual meeting of Mars scientists. \u201cThe era that we all know and love and embrace is really coming to an end,\u201d he said. \u201cIt\u2019s important to recognize that the future is not going to be the same as the past.\u201d Throughout the 2000s, NASA sent a sustained barrage of spacecraft to Mars, unique in the sheer number of robots directed at one planetary target. But many have expired, and the ones still operating are growing old. NASA\u2019s three functional orbiters \u2014 Mars Odyssey, Mars Reconnaissance Orbiter, and  MAVEN  \u2014 launched in 2001, 2005, and 2013 respectively. The Opportunity rover is in its thirteenth year, and the  Curiosity rover  is in its fifth. Perhaps more significantly, NASA has only one more spacecraft scheduled in its Mars programme, a rover due to launch in 2020 that is  tasked with gathering samples  for an as-yet-unscheduled return to Earth. (The  InSight geophysics probe , slated for a 2018 launch, was not developed under the auspices of NASA\u2019s Mars programme.) \n               All eyes on Mars \n             NASA wants to start planning for an orbiting mission sometime after 2020. In June, the agency asked five companies for information about what sorts of Mars orbiters they might be able to build, and how quickly and cheaply that could be done. Five international partners have also said they would like to be involved, Watzin said. Many non-NASA missions to Mars are already on the books. In 2020, the European Space Agency and China each plan to launch Mars rovers, while the United Arab Emirates will send an orbiter. SpaceX of Hawthorne, California, hopes to start sending its Red Dragon landers to Mars beginning in 2018. This broadening context prompted Watzin to propose the new way of operating Mars missions. \u201cI\u2019m not trying to fix something that\u2019s broken,\u201d he said. \u201cI\u2019m trying to open the door to a larger level of collaboration and participation than we have today, looking to the fact that we\u2019re going to have a larger pool of stakeholders involved in our missions.\u201d Under the new, facility-based approach, scientists would propose investigations using one or more instruments on a future spacecraft \u2014 likely an orbiter. NASA would award observing time to specific proposals, much as telescope allocation committees parcel out time on their mountaintops. This would be different from the current approach, in which individual teams of scientists propose, build and operate instruments. Watzin's proposal is a trial balloon, not an official change to NASA policy. \u201cThe idea right now needs to be fleshed out,\u201d says Jeffrey Johnson, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, and head of the  group  that organized the meeting. \u201cIt's a little early yet to figure out how the community is going to respond.\u201d But some researchers are already pushing back. Alfred McEwen, a planetary scientist at the University of Arizona in Tucson, notes that the Mars Reconnaissance Orbiter\u2019s  HiRISE camera  has taken thousands of images of Mars based on public requests. \u201cWe\u2019ve managed to do all the things [Watzin] described already without a new paradigm,\u201d says McEwen, the camera's principal investigator. \u201cWe have distributed operations, we have multiple customers, we have a foreign contributed instrument. So my immediate reaction to this idea was not very positive.\u201d Patrick McGovern, a planetary scientist at the Lunar and Planetary Institute in Houston, adds that most instrument principal investigators support a network of collaborators, including early-career researchers. \u201cWhat I'm worried about is, are the savings coming at the expense of supporting a team?\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Mars contamination fear could divert Curiosity rover 2016-Sep-07 \n                   \n                     NASA reschedules troubled Mars InSight mission to 2018 2016-Mar-09 \n                   \n                     NASA plans Mars sample-return rover 2014-May-13 \n                   \n                     NASA's chief scientist on Mars, moons and money 2013-Dec-13 \n                   \n                     NASA's Mars exploration site \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20700", "url": "https://www.nature.com/articles/nature.2016.20700", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Journal backed by world\u2019s largest private research funders will still depend on grants to cover expenses. The open-access journal  eLife  is dropping one of its most distinctive features: free publishing. From 2017, it will charge a fee of $2,500 for all accepted papers. Most open-access journals already charge for publishing, because they have few other ways to bring in cash. But  eLife , which launched in 2012, has until now had its expenses covered by grants from three of the world\u2019s largest private research funders: the Howard Hughes Medical Institute in Chevy Chase, Maryland; the Wellcome Trust in London; and the Max Planck Society in Berlin. These backers want to create an elite online journal that can compete for authors\u2019 best papers against leading subscription publications (such as  Nature ,  Science  and  Cell ), yet still be open access. The three funders set up the non-profit  eLife  organization, and have  committed to provide it with \u00a343 million  ($56 million) over 10 years. The journal now needs another revenue stream to put its publishing business on a more sustainable footing as the number of papers that it receives increases, says its executive director Mark Patterson, in Cambridge, UK. But  eLife  will still rely heavily on its grants, he says. By charging some fees,  eLife  will be able to scale up its publishing operations and free up grant money to develop open-source tools for the research community. \u201cPublishing science is a core activity, but it\u2019s not all that we do,\u201d he says. The journal's decision to start charging might mean that it loses some prospective authors, notes Kent Anderson, the former publisher of  Science  and now chief executive of the analytics firm RedLink in Westborough, Massachusetts. But Nick Golding, an epidemiologist at the University of Melbourne in Australia, says the new charge won't put him off submitting manuscripts to  eLife , which has published five of his articles since 2014. \"Of all the journals I've published with,  eLife  has impressed me the most. It's often difficult to find open access fees, but  eLife  is one journal I'd be very happy to pay for,\" he says. \n             Pick a fee, any fee \n           Open-access journals charge a wide variety of fees \u2014 a range that has sparked  fierce debate over how much scientists should or could pay to publish a scientific paper . Highly selective open-access journals that reject most of their submitted papers tend to have higher operating expenses, and  eLife , which last year accepted 15.4% of submissions, falls into that category. The decision to ask for $2,500 puts  eLife  in the range typically charged by other open-access journals, Patterson says, such as those published by the Public Library of Science. And it is lower than those charged by competitors such as  Science Advances  ($4,600) and  Nature Communications  ($5,200). Unusually for scientific publishers,  eLife  is transparent about its publishing costs and has posted  detailed accounts  of how it arrived at its fee. The charge does not cover all of  eLife \u2019s expenses; rather, it will cover 'marginal costs' \u2014 those that increase with each new paper the journal receives. These include salaries for scientific editors and staff who handle papers, payments for the third-party systems that process articles, and fee waivers for authors who lack sufficient funding to pay.\u00a0 The journal will still depend on its backers to pay what it terms fixed costs, such as for technology platforms, infrastructure, marketing and other staff. The total publishing cost per article in 2017,  eLife  estimates, will be around \u00a33,085. That estimate deliberately excludes a large chunk of the organization's expenses \u2014 around 22% last year \u2014 that go to what  eLife  calls \u201ctechnology and innovation\u201d activities, including the development of an open-source scientific publishing web platform, website redesigns and a partnership to develop open-source publishing tools. Some publishers think that  eLife  should include these expenses in its estimates of per-paper costs, on the grounds that they are an integral part of publishing, says Anderson. But Patterson replies that publishers take different approaches as to how to account for such costs in author charges. Anderson says that now that  eLife  has entered the crowded market of fee-charging open-access journals, he is not convinced that its offering will set it apart from competitors. \u201cWe have pricing- and value-based horse races now in the open-access market, and  eLife  is taking a lane. I don't see anything to suggest it will lap the field.\u201d \n                   Wellcome Trust launches open-access publishing venture 2016-Jul-06 \n                 \n                   Open-access journal eLife gets \u00a325-million boost 2016-Jun-01 \n                 \n                   Dutch lead European push to flip journals to open access 2016-Jan-06 \n                 \n                   UK funder explains clamp-down on open access 2014-Apr-09 \n                 \n                   Open access: The true cost of science publishing 2013-Mar-27 \n                 \n                   eLife \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20708", "url": "https://www.nature.com/articles/nature.2016.20708", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Women publish and review less than men in American Geophysical Union journals, but have a higher acceptance rate. Denver, Colorado In one of the most detailed breakdowns yet of  gender bias  in scholarly publishing, the American Geophysical Union (AGU) in Washington DC has found that its female members submit fewer papers, and are asked to be peer reviewers less frequently, than men. The effect holds across all age ranges, from  scientists in their twenties  to those in their seventies. Yet manuscripts sent to AGU journals by women were accepted 60% of the time \u2014 4 percentage points higher than the rate for men. \u201cWomen don\u2019t submit as often, but when they do they have a higher acceptance rate,\u201d says Jory Lerback, a hydrogeologist at the University of Utah in Salt Lake City. She led the data analysis while working for the AGU, and reported the findings on 28 September at a meeting of the Geological Society of America (GSA) in Denver, Colorado. Many studies have quantified  gender differences in research output, but the AGU work is rare in that the society\u2019s database contains information not only on gender, but also on age. Lerback\u2019s analysis can thus break the differences down according to where a scientist is in her career. The AGU began the study at the request of Marcia McNutt, the former editor-in-chief of  Science  who is now president of the US National Academy of Sciences in Washington DC. \u201cI was dubious at first, until we started doing it and saw what we had,\u201d says Brooks Hanson, the AGU\u2019s director of publications and Lerback's co-author. The society had started asking its members their gender and age in 2013, so it had a hugely useful database on its hands. \n             Double bind \n           Lerback and Hanson examined information from 97,431 people, cross-referencing their e-mail addresses with the editorial databases of the 19 AGU journals that existed at the time. About 29% of the society\u2019s members are women. Between 2012 and 2015, women who published in AGU journals as first authors had submitted about 1.8 papers each, compared with 2.1 papers for men in the corresponding situation. And women served as peer-reviewers just 18% of the time. The gender differences persisted across age groups, with the greatest discrepancy for the youngest scientists, in their twenties. When asked for the names of possible peer reviewers, female first authors suggested female reviewers 20% of the time, whereas male first authors suggested women 15% of the time. Meanwhile, female journal editors suggested female reviewers 21% of the time, and for male editors the figure was 17%. \u201cThis behaviour contributes to that gap between who\u2019s publishing and who\u2019s reviewing,\u201d Lerback says. Yet women also declined invitations to serve as peer reviewers at higher rates than men, completing an average of 3.65 reviews each, compared with 4.34 for men. Scientists who miss out on the chance to participate in peer review are also missing opportunities to develop their reputation and professional skills, says Hanson. \u201cReviewing is a way to impress people,\u201d he notes. \n             Mind the gap \n           But Hanson is not a fan of introducing  double-blind peer review , in which both authors and reviewers are unaware of each other\u2019s identities. Instead, he says, the AGU has been pushing to diversify the gender and geographical mix of its editorial boards, and to ensure that editorial selection committees are gender balanced. He says that training and awareness are the best ways to combat implicit bias. The GSA, which publishes four journals, says that it doesn\u2019t have the AGU\u2019s level of demographic detail but works in other ways to alleviate gender bias. \u201cRight now, our efforts have been to sustain a higher percentage of female editors and associate editors,\u201d says Jeanette Hammann, the society\u2019s director of publications. Dan Lovegrove, a geology publisher for Amsterdam-based publishing group Elsevier, reported at the meeting that although 30% of contributions to Elsevier\u2019s Earth and planetary science journals come from women, only 13% of its journal editors are female. He says that the company has launched a pilot project to encourage gender equality in recruitment for its editorial boards. \n                   Researchers debate whether female computer coders face bias 2016-Feb-15 \n                 \n                   Science and sexism: In the eye of the Twitterstorm 2015-Nov-11 \n                 \n                   Sexist review causes Twitter storm 2015-May-01 \n                 \n                   Nature journals offer double-blind review 2015-Feb-18 \n                 \n                   Journals weigh up double-blind peer review 2014-Jul-15 \n                 \n                   Bibliometrics: Global gender disparities in science 2013-Dec-11 \n                 \n                   Inequality quantified: Mind the gender gap 2013-Mar-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20712", "url": "https://www.nature.com/articles/nature.2016.20712", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Manufacturers and users will rank reagents to improve the reliability of research. Biomedical experts plan to create a scoring system that will help researchers choose reliable antibodies for their experiments. The only problems: figuring out how such a ranking would work \u2014 and getting manufacturers to adopt the standard. \u00a0 The idea comes from a  workshop  hosted this week in Asilomar, California, by the Washington-based Global Biological Standards Institute (GBSI), one of several groups concerned that poorly characterized antibodies are a  major culprit behind the irreproducibility of biology experiments . Antibodies are large, Y-shaped proteins that are supposed to bind to specified biomolecules, helping researchers to track and identify them. But reagents that detect the wrong target \u2014 or that don\u2019t detect the right one \u2014 have led to  false findings, wasted resources and acrimonious controversies . The concept of ranking antibodies is appealing, but doing so for even a fraction of those on the market would be an enormous task, says Roberto Polakiewicz, chief scientific officer of Cell Signaling Technology, an antibody manufacturer in Danvers, Massachusetts. \u201cIt\u2019s still not clear how feasible that would be or how it would be implemented.\u201d The aim is to start by proposing definitions of how an antibody\u2019s performance could be validated, says GBSI head Leonard Freedman. The reagents will need to have separate ranking systems for different kinds of experiments. For example, an antibody that accurately detects a protein in cells that have been broken open can be ineffective if used to detect the same protein in intact tissue. Researchers would still need to validate even high-scoring antibodies for their own experiments, Freedman says. But a scoring system would give scientists confidence that an antibody will work as expected for its intended use. \n             Market demand \n           Where researchers would look up the scores and the data behind them is still unclear, as is how such data would be vetted. But detailing plans for the scoring system is more important than figuring out how to put it in place, says Joshua LaBaer, a proteomics researcher at Arizona State University in Tempe and a member of the workshop steering committee. \u201cJust creating and defining a standard will create a bar that will improve the field,\u201d he says. If a few top vendors adopt a common scoring system, the practice will catch on, predicts Carl Ascoli, chief science officer at Rockland Immunochemicals, an antibody manufacturer in Limerick, Pennsylvania. \u201cOthers will follow suit because the market will demand it.\u201d Scientific funders would also look to these standards, he says. Anita Bandrowski, an information scientist at the University of California, San Diego, hopes that manufacturers will agree not just to score antibodies but also to provide lists of antibodies that were discontinued because of poor performance. These could be compiled into a database and used to alert authors, reviewers and editors about the need to be more sceptical of experimental results involving those antibodies. Bandrowski is one of a group of researchers who, just before the meeting, published a paper 1  proposing five broad strategies for validating antibodies. The workshop organizers aim to draw on these for proposals for each of the major kinds of experiments that rely on antibodies in about six months. The ensuing debate about how scores are calculated, and what details must be disclosed by antibody vendors, will be fierce, Ascoli says. \u201cThere\u2019s going to be a firestorm.\u201d \n                   Biomedical researchers lax about validating antibodies for experiments 2016-Jun-30 \n                 \n                   'Young blood' anti-ageing mechanism called into question 2015-May-19 \n                 \n                   Reproducibility crisis: Blame it on the antibodies 2015-May-19 \n                 \n                   Reproducibility: Standardize antibodies used in research 2015-Feb-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20714", "url": "https://www.nature.com/articles/nature.2016.20714", "year": 2016, "authors": [{"name": "Jane J. Lee"}], "parsed_as_year": "2006_or_before", "body": "September\u2019s sharpest science shots, selected by  Nature\u2019 s photo team. \n             Splash of light \n           People in Tanzania surround a puddle of water reflecting a solar eclipse on 1 September. The event was an  annular, or 'ring of fire', eclipse , when the Moon blocks the entire Sun except for a bright ring around the edges. \n             Water colours \n           A  plankton bloom  paints the Barents Sea, northeast of Russia, with swirls of blue and green. The European Space Agency\u2019s Sentinel-2A satellite took the natural-colour image, released on 9 September. \n             Swarm of lights \n           A swarm of 100 quadcopter  drones  took to the skies over Linz, Austria, on 10 September in a performance that combined music, movement and lights. \n             Sucking up \n           Armed with brushes, a vacuum cleaner and a crane, workers at the American Museum of Natural History in New York City scrubbed down a life-sized model of a blue  whale  ( Balaenoptera musculus ) on 7 September. The 29-metre-long whale accumulates dust as it keeps vigil over the museum\u2019s ocean-life exhibits, so employees give it an annual cleaning to keep it looking its best. \n             Homecoming \n           The  Soyuz TMA-20M  spacecraft drifts down to Earth on 7 September, carrying three of the six members of the 48th expedition to the International Space Station. The returning trio spent 172 days in space. \n             Size matters \n           Peter Glazebrook shows off the 8-kilogram root vegetable that won the heaviest-carrot competition at the Harrogate Autumn Flower Show, UK, earlier this month. It\u2019s unclear whether there\u2019s an enormous bunny out there to match. \n             Big mouth \n           This deep-sea lizardfish ( Bathysaurus  sp.) lurks on the bottom of Veatch Canyon off the US east coast. These fish are one of many species  now protected  in the area, which was designated as the first US marine national monument in the Atlantic Ocean by President Barack Obama on 15 September. \n             A winning set \n           The Insight Astronomy Photographer of the Year competition announced its winners on 16\u00a0September. Yu Jun\u2019s composite image of beads of light ringing the Moon during a solar eclipse in March took top honours. Winners in other categories included an eerie photo of the Moon and Venus hovering over a misty morning landscape and a full Moon apparently perched on top of a mountain in Madrid. \n                   Floods, fires, Zika and a hidden portrait 2016-Aug-26 \n                 \n                   Cruising sharks, fiery dragons and invisible dust 2016-Jul-29 \n                 \n                   Spacemen returning, high-tech turtles and an Antarctic rescue 2016-Jun-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20705", "url": "https://www.nature.com/articles/nature.2016.20705", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Craft sends back wealth of images in 19-kilometre descent. The European Space Agency's comet-orbiting Rosetta spacecraft was successful to the last. It crash-landed on the comet 67P/Churyumov\u2013Gerasimenko within a minute of its scheduled impact time at 11:19 UTC on 30 September, ending its 12-year long, \u20ac1.3-billion (US$1.45-billion) mission with a bump \u2014 and a final tranche of data. The orbiter's final resting place has been named Sais, after the site in Egypt where the mission's namesake, the Rosetta stone, was originally displayed. \u201cWe can finally say Rosetta has come home to Sais,\u201d said mission manager Patrick Martin, speaking from the control room at the European Space Operations Centre (ESOC) in Darmstadt, Germany. \u201cFarewell Rosetta, you\u2019ve done the job. That was space science at its best.\u201d Flight engineers at ESOC watched quietly for Rosetta's communications signal to flatline \u2014 the sign that the craft had landed. At the critical moment, onlookers looked stunned before breaking out into applause to celebrate the culmination of the mission. The  daring finale  was designed to get scientists the closest possible images and measurements of dust, gas and plasma from a comet. Rosetta sent back a continuous stream of data as it drifted down at a sedate walking pace from a height of 19 kilometres onto comet 67P's surface; ESA broadcasted the images throughout the descent. Holger Sierks, principal investigator for Rosetta's OSIRIS instrument (Optical, Spectroscopic, and Infrared Remote Imaging System), showed off the final pictures. A gravel field strewn with pebbles and boulder-like shapes is visible in the crude unprocessed images. \u201cThis will keep us busy,\u201d he said. The craft transmitted its closest shot (pictured) just 10 seconds before impact, around 20 metres away from the comet. \u201cThat image was extraordinary,\u201d says Stephen Lowry, a cometary scientist at the University of Kent, UK, and a member of the OSIRIS camera team. Rosetta\u2019s ultraviolet spectrograph, which studies the characteristic fingerprints in reflected light that reveal the comet\u2019s make-up, took its last data just minutes before the crash. Alan Stern, a planetary scientist at the Southwest Research Institute in Boulder, Colorado, and principal investigator of the NASA instrument, called the data\u2019s 3-metre resolution \u201cunprecedented for ultraviolet studies of comets\u201d. In the coming days, ESOC will use housekeeping data to put together a reconstruction of Rosetta\u2019s last journey. Estimates suggest that the landing was as close as 40 metres to the target site, with instruments sending back data well within a minute of the crash, says Martin. \u201cThe plan worked well until the end, really flawlessly,\u201d he says. Most of Rosetta\u2019s operations and science staff will now move onto other projects, but Martin will remain on the mission for three years, largely to archive data. So far, scientists have analysed only around 5% of the data that Rosetta has gathered since it  began orbiting 67P two years ago , said Andr\u00e9 Bieler, a planetary scientist at the University of Bern in Switzerland and a member of Rosetta\u2019s ROSINA (Rosetta Orbiter Spectrometer for Ion and Neutral Analysis) team, at a meeting at ESOC on the eve of the crash. \u201cWe have collected data we haven\u2019t had time to look at, but they\u2019re there, and they\u2019re ready to be assembled,\u201d he said. \n               Voyage of discovery \n             Rosetta has already made striking findings, including the discovery of water from comet 67P with a  different isotopic composition to that on Earth , as well  as molecular oxygen and nitrogen , which points to the comet being as old as the Solar System itself. Scientists also determined how 67P got its  strange rubber-duck shape , deducing that the head and body were formed separately. But many questions remain. A big challenge will be to figure out how the pebbles visible in Rosetta\u2019s final shots were created, says Lowry. They may have been shaped by dust, which is tossed into the air by sublimating ice and then falls back to the surface. Another tantalising possibility is that the pebbles are the building blocks from which 67P was originally built. If so, they might be able to tell scientists about the origins of the Solar System. The Rosetta mission was the first to orbit (rather than just visit) a comet; the first to  land a probe on a comet  and, in its final moments, the first to conclude with a  controlled comet crash-landing . (In 2001, NASA's NEAR Shoemaker mission also crash-landed \u2014 but that was on an asteroid, a body much larger and closer to Earth than 67P.) \u201cRosetta has entered the history books once again,\u201d said Johann-Dietrich W\u00f6rner, ESA\u2019s director-general. The ability to observe a cometary body changing over time, and from such close quarters, is likely to mean \u201ca true revolution\u201d in cometary science, says Geraint Jones, a planetary scientist at University College London. \u201cIt\u2019s just a wealth of data. The level of detail is incredible,\u201d he says. \n                     Comet crash: a guide to Rosetta\u2019s big finale 2016-Sep-27 \n                   \n                     Photos reveal location of lost comet lander Philae 2016-Sep-05 \n                   \n                     Historic Rosetta mission to end with crash into comet 2015-Nov-04 \n                   \n                     Philae's comet discoveries create series of conundrums 2015-Jul-30 \n                   \n                     Science pours in from Rosetta comet mission 2015-Jan-22 \n                   \n                     Rosetta probe makes history by landing on comet 2014-Nov-12 \n                   \n                     Landing on a comet: A guide to Rosetta\u2019s perilous mission 2014-Nov-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20710", "url": "https://www.nature.com/articles/nature.2016.20710", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Design flaw may have doomed machine at Princeton Plasma Physics Lab. A tough year just got tougher for US fusion researchers. The country\u2019s flagship\u00a0experimental fusion reactor has broken down, less than a year after completing a 4-year, US$94-million upgrade. Now officials at the Princeton Plasma Physics Laboratory (PPPL) in New Jersey are investigating whether problems encountered during fabrication of a key component caused the reactor to fail. Lab officials say that the machine could be offline for up to a year. Making matters worse, one of the other two fusion reactors funded by the US Department of Energy (DOE) is scheduled to shut down on 30 September. That leaves US scientists with just one major facility to conduct fusion experiments, at the defence contractor General Atomics in San Diego, California. \u201cIt\u2019s definitely a challenge for everybody,\u201d says Earl Marmar, who oversees the Alcator C-Mod reactor at the Massachusetts Institute of Technology in Cambridge that is shutting down after more than two decades. \u201cWe won\u2019t be completely without access to experimental facilities, but it\u2019s definitely not as good as it could have been for the coming year.\u201d The upgraded Princeton reactor, called the National Spherical Torus Experiment Upgrade (NSTX-U), is twice as powerful as its predecessor. Like  other 'tokamak' reactors , including the  international ITER project  under construction in France, the spherical machine uses magnetic fields to confine a hydrogen plasma. That plasma is then heated until the atoms fuse and release energy. In theory,  fusion could power the world indefinitely  \u2014 and cleanly. The Princeton machine\u2019s breakdown came to light on 27 September, after PPPL director Stewart Prager resigned. Laboratory officials say that the upgraded reactor started operating at low power in December 2015 and produced 10 weeks of high-quality data. Scientists shut it down in July after discovering that one of the coils that creates the electromagnetic trap was malfunctioning. Prager says he was thinking about stepping down as director before the reactor coil broke. He elected to depart now, after eight years, so that new leadership can carry the investigation forward and repair the machine. \u201cIt\u2019s sort of a normal passing of the baton,\u201d he says. \n               Hunting for clues \n             PPPL officials initially declined to speculate about the cause of the coil malfunction, saying that an investigation is under way. But the lab later confirmed to  Nature  that questions about the strength of the copper in the faulty coil arose, and were investigated, when the part was being fabricated. That fact that these concerns arose during the tokamak upgrade suggests that a more careful analysis could have prevented the reactor failure, says Stephen Dean, president of Fusion Power Associates, an advocacy group in Gaithersburg, Maryland.. \u201cMistakes like this do sometimes get made, but with all of the experience the fusion programme has, it should not have happened this way.\u201d NSTX-U programme director Jonathan Menard says that the finished coil met the laboratory\u2019s specifications. He adds that it is not clear whether the part\u2019s design or the manufacturing process caused problems. Another coil in the reactor, of a similar design and fabricated from the same grade of copper, has functioned well. The laboratory is planning to replace it nonetheless. A former researcher at the Princeton laboratory, who declined to be named because he is not authorized to speak about the issue, says that the copper in the faulty coil might have been stronger than it needed to be. That would have made it harder to bend the metal into the desired shape. Even tiny faults in fabrication can cause problems when energy is coursing through the reactor, heating up the coils. Menard says that after the coil malfunctioned, X-ray analyses found structural anomalies that may have resulted from internal melting when the reactor was operating. PPPL scientists plan to cut the coil open for further investigations. \u201cWe are going to have to wait for those results to make a more definitive statement,\u201d he says. \n               Uncertain future \n             Officials aren\u2019t sure how much it will cost to repair the reactor, but say that it could take up to a year to bring it back online. Because the fusion reactor was already scheduled to halt operations in late 2016 for six months of maintenance, the net loss of research time may wind up being about six months. The breakdown\u2019s impacts could extend well beyond the Princeton lab. Marmar had planned to shift people to the Princeton facility once MIT\u2019s Alcator reactor shut down. Now, MIT researchers will help Princeton to restart its reactor \u2014 and try to conduct their previously planned research by collaborating with teams at General Atomics' reactor and facilities in other countries. The DOE decided several years ago  to close the MIT reactor , but to maintain facilities in Princeton and San Diego. The US Congress reversed that decision once, in 2014, but the US government's 2016 budget assumes that the MIT reactor will shut down. The DOE says that the US fusion-research programme remains on a solid footing, with extensive international partnerships, and will be back at full strength once the Princeton machine returns to service. Others are concerned about how researchers will cope with only one major US reactor in operation. Dean thinks that the agency ought to keep Alcator C-Mod running for another year, until the Princeton reactor is fixed. \u201cIt\u2019s not a good situation for our scientists to only have one machine running,\u201d he says. Marmar is ready to restart the MIT reactor if the DOE changes its mind. \u201cThe C-Mod facility is planned to be put into a safe shutdown state,\u201d he says, \u201cbut if desired, could be brought back into service on short notice to support the US and international fusion community.\u201d \n                     US science agencies face budget limbo 2016-Sep-06 \n                   \n                     US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                   \n                     US plans for future of fusion research 2014-Sep-22 \n                   \n                     US fusion in budget vice 2012-Jul-24 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20715", "url": "https://www.nature.com/articles/nature.2016.20715", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Women and men applying for geoscience postdocs receive very different letters of support from their mentors. Gender bias in scientific fields is no secret , and it is  pervasive . It even creeps into the all-important recommendation letter, in which mentors typically bolster the credentials of their prot\u00e9g\u00e9s. Globally, female applicants are about 10% less likely than their male counterparts to receive 'excellent' letters for postdoctoral positions in the  Earth sciences , according to a study published in  Nature Geoscience  on 3 October 1 . The finding holds regardless of the gender of their recommenders or what part of the world the applicant works in. \u201cThese results uncover a real problem in the geosciences, just like other disciplines,\u201d says Kuheli Dutt, a social scientist at Columbia University in New York City and lead author of the paper. Women start off at a disadvantage, she adds, because they're perceived as less competent than their male counterparts. For example, in the US, women in science, technology, engineering and mathematics earn 41% of doctoral degrees, yet in 2012\u201313 they accounted for only 24% of postdoctoral positions at US federally funded research centres and labs, according to the  National Science Foundation . In the geosciences,  less than 10%  of full professors are women, indicating that the postdoctoral stage \u2014 the usual gateway into faculty jobs \u2014 is the point at which many women leave the field. Several factors contribute to this, says Dutt, but biases in how women are perceived at the postdoctoral level are important, and recommendation letters play a key part in getting those positions. \n             Faint praise \n           Dutt and her colleagues analysed the tone and length of 1,224 recommendation letters submitted by researchers in 54 countries for geoscience postdoctoral fellowships from 2007 to 2012. The team redacted applicant and institution names from the letters, then read and classified them as 'excellent', 'good', or 'doubtful'. The majority of the letters were rated as good. The letters used phrases such as 'highly intelligent' and 'very productive', while the rarer excellent letters included the phrases \u201cscientific leader\u201d, \u201cbrilliant scientist\u201d, \u201ctrailblazer\u201d or \u201cone of the best students I\u2019ve ever had\u201d. The writers of recommendation letters produced 'excellent' letters for 24% of male applicants, but gave the same level of recommendation to only 15% of female applicants. Furthermore, Dutt and her co-authors found that male and female recommenders were equally likely to write stronger letters for male applicants. This suggests implicit biases and stereotypes probably account for this result, Dutt says. Studies in fields including chemistry 2 , medicine 3  and psychology 4  have found similar biases in recommendation letters. Recommenders used more superlative and standout adjectives like \u201cremarkable\u201d and \u201coutstanding\u201d for men, but gave women 'grindstone' descriptors such as \u201chard-working\u201d. \n             Follow the leader \n           People on hiring committees need training to minimize implicit gender biases when evaluating recommendation letters, says Virginia Valian, a psychologist at Hunter College of the City University of New York. \u201cDescribing someone as a \u2018team player\u2019, for example, won\u2019t be interpreted the same way for a man and a woman.\u201d For men, she says, that's taken as a leadership quality, while the phrase can make a woman seem like a follower. Valian is concerned that the study didn't account for differences in qualifications between some male and female applicants. However, other studies that do account for those differences find similar, albeit smaller, gender differences, she says. Gender stereotypes  become ingrained when people are young, because they see more men in science and think of science as a male profession, says Toni Schmader, a psychologist at the University of British Columbia in Vancouver, Canada. But there are three steps that people writing and evaluating recommendations should take to prevent such biases from influencing their behaviour, she says. \u201dYou have to be aware that you have the biases in the first place, you have to be motivated to set them aside and you have to have the time and effort to do so.\u201d \n                   Gender bias found in Earth-science society journals 2016-Sep-29 \n                 \n                   Women in physics face big hurdles \u2014 still 2016-Aug-01 \n                 \n                   Science and gender: Scientists must work harder on equality 2015-Dec-21 \n                 \n                   Postdocs at Federally Funded R&D Centers \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20721", "url": "https://www.nature.com/articles/nature.2016.20721", "year": 2016, "authors": [{"name": "Richard Van Noorden"}, {"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Japanese biologist Yoshinori Ohsumi recognized for work on autophagy. Molecular biologist Yoshinori Ohsumi has won the  2016 Nobel Prize in Physiology or Medicine  for his work in the field of autophagy: the processes by which the cell digests and recycles its own components. The 71-year-old Ohsumi, who is currently a professor at the Tokyo Institute of Technology in Yokohama, was recognized for his experiments in the 1990s, when he used baker's yeast ( Saccharomyces cerevisiae ) to identify genes that control how cells destroy their own contents. The same kinds of mechanism operate in human cells \u2014 and are sometimes involved in genetic disease. \"He's a very humble yeast geneticist who basically transformed the field,\" says Sharon Tooze, a cell biologist at the Francis Crick Institute in London. \"He was interested in this weird pathway that turns out to be a vitally important pathway in medicine.\" The word 'autophagy' \u2014 from the Greek for 'self-eating' \u2014 was coined in 1963 by the Belgian biochemist Christian de Duve, who saw how cells broke down their parts inside a waste-processing sac that he called a lysosome. Biologists now understand that this process is fundamentally important to living cells. \"Without autophagy our cells won't survive,\" says Juleen Zierath, a physiologist at the Karolinska Institute in Stockholm who was on the selection committee for the medicine Nobel. When cells are starved, they can consume their own proteins for fuel. The same degradation process can be used to eliminate damaged proteins and organelles \u2014 effectively, to renew cells and clear out debris \u2014 or to ward off invading bacteria and viruses. \n               Sleepy backwater \n             Ohsumi began studying yeast as a postdoc, turning to yeast DNA replication as a side project when his main research stalled, says Tooze. When Ohsumi first started studying autophagy in 1988, \u201cit was kind of a sleepy backwater of a research topic,\u201d says biochemist Michael Hall of the University of Basel in Switzerland. \u201cIt was basically considered the garbage-disposal system of the cell \u2014 just bulk, non-specific degradation of junk.\u201d In an  interview given to the Tokyo Institute of Technology's website  in December 2012, Ohsumi said that all his research findings began with a love of the microscope. \"You can answer the most basic and important questions about the nature of life through yeasts,\" he added.\u00a0 Ohsumi would go on to develop the first yeast genetics screen to identify genes involved in the autophagy pathway. But it was a few years before biologists recognized the importance of the process in physiology and disease. Interest in the field skyrocketed when, in 1999, Beth Levine (now at the University of Texas Southwestern Medical Center in Dallas) and her colleagues reported that a mammalian autophagy gene could suppress tumour growth. That finding launched widespread efforts to learn more about the role of autophagy in cancer. Disruptions in autophagy have also been linked to Parkinson's disease, type 2 diabetes and other disorders \u2014 and research is ongoing to develop drugs that can affect the process. Researchers\u2019 understanding of the complex role of autophagy in cancer has become more detailed: the process seems to inhibit tumours in the early stages of their growth, but can also fuel cancer once it has spread, says Hall.\u00a0 \n               Single winner \n             Ohsumi, who will collect 8 million Swedish kronor (US$940,000) for the Nobel prize, also won the \u00a550-million (US$626,000) Kyoto Prize in basic sciences in 2012 for his autophagy work. Others have made key contributions to the field, and were considered to be contenders for a share of a Nobel. Biochemist Michael Thumm of the University Medical Center G\u00f6ttingen in Germany, for example, also discovered autophagy genes, as did cell biologist Daniel Klionsky of the University of Michigan in Ann Arbor. \u201cIf they\u2019re going to give it to just one, Ohsumi\u2019s the one,\u201d says Hall. \u201cBut it also would have been good to include other people.\u201d In Japan, the prize had been widely anticipated for the past few years, with journalists showing up regularly to ask Ohsumi for interviews, says Hitoshi Nakatogawa, a biologist at the Tokyo Institute of Technology who has worked with Ohsumi for a decade. When colleagues heard \u2014\u00a0around two hours before the official announcement\u00a0\u2014\u00a0of Ohsumi\u2019s win, they gathered together to celebrate in the victor\u2019s lab. \u201cWe talked about how great it was that he won it alone,\u201d he says. \u201cOhsumi never overlooks anything even in the most banal kind of experiment,\u201d Nakatogawa adds. \u201cHe doesn't care about whether it will lead to something useful, whether a breakthrough can be expected, whether it will lead to more funding. He just follows his curiosity.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Anti-parasite drugs sweep Nobel prize in medicine 2015 2015-Oct-05 \n                   \n                     Common nutrient keeps flies sharp into old age 2013-Sep-01 \n                   \n                     Nobel prize press release \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20750", "url": "https://www.nature.com/articles/nature.2016.20750", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Analysis suggests people will never live much beyond 115 but some scientists say that it's too soon to assume a fixed shelf-life. Jeanne Calment outlived her daughter and grandson by decades, finally succumbing to natural causes at the ripe old age of 122. Calment, who was French and died almost two decades ago, is thought to be world's longest living person. But if subsequent advances in medicine have lulled you into thinking that you might exceed this record, think again. An analysis of global demographic data published in  Nature 1  suggests that humans have a fixed shelf life, and that the odds of someone beating Calment\u2019s record are low \u2014 although some scientists question this interpretation. They say that the data used in the analysis are not unequivocal, and that the paper doesn\u2019t account for future advances in medicine. Human life expectancy has steadily increased since the nineteenth century. Reports of supercentenarians \u2014 people such as Calment who live to older than 110 \u2014 together with observations of model animals whose lifespans can be extended through genetic or dietary modifications, have prompted some to suggest that there is no upper limit on human lifespan. Others say that the steady increase in life expectancy and maximum human lifespan seen during the last century will eventually stop. To investigate, Jan Vijg, a geneticist at Albert Einstein College of Medicine in New York City and his colleagues turned to the  Human Mortality Database , which spans 38 countries and is jointly run by US and German demographers. They reasoned that if there\u2019s no upper limit on lifespan, then the biggest increase in survival should be experienced by ever-older age groups as the years pass and medicine improves. Instead, they found that the age with the greatest improvement in survival got steadily higher since the early twentieth century, but then started to plateau at about 99 in 1980. (The age has since increased by a very small amount). \n             Maximum age of death \n           The researchers went on to look at the  International Database on Longevity , which focuses on the oldest people and is run by an international team. They found that the maximum reported age of death \u2014 the age of the oldest person to die in a given year \u2014 in France, Japan, the United States and the United Kingdom (the countries with the largest numbers of supercentenarians) increased rapidly between the 1970s and early 1990s but plateaued in the mid-1990s at 114.9 years. The researchers observed the same trend when they considered the second, third, fourth and fifth oldest person who died in a given year \u2014 and a similar peak age of 115 years old when they tracked the maximum annual age of death using another database run by the international  Gerontology Research Group , which validates supercentenarian claims. Vijg\u2019s team concludes that there is a natural limit to human lifespan of about 115 years old. There will still be occasional outliers like Calment, but he calculates that the probability of a person exceeding 125 in any given year is less than 1 in 10,000. The limit is surprising, says Vijg, given that the world\u2019s population is increasing \u2014 supplying an ever-increasing pool of people who could live longer \u2014 and that nutrition and general health have improved. \u201cIf anything you would have expected more Jeanne Calments in recent years, but there aren\u2019t.\" But not everyone agrees with his team's interpretation. The age experiencing the greatest increase in survival may have plateaued in many countries, says  James Vaupel , founding director of the Max Planck Institute for Demographic Research in Rostock, Germany. But it has not yet plateaued in some that are particularly relevant to this research, namely Japan, which has the world\u2019s highest life expectancy \u2014 83.7 years for those born in 2015, nor in France or Italy, which have large populations and high life expectancies. Vijg\u2019s paper includes \u201cone-sided conclusions\u201d, says Vaupel. But Vijg argues that the increase in the survival age in even these three countries has significantly slowed down in recent years and so seems to be trending towards no increase. \n             Medicine not included \n           Researchers also cite future developments in medicine that could further increase maximum lifespan, which the paper does not address. \u201cOf course there are limits to human lifespan if you\u00a0don\u2019t interfere,\u201d says Richard Faragher, a biogerontologist at the University of Brighton, UK. In worms, mice and flies, for instance, researchers have radically extended lifespan by suppressing genes involved in growth-factor signalling, or by restricting food. Human cells have been rejuvenated by delivering RNA encoding a protein that extends telomeres, protective caps on the ends of chromosomes that are  associated with ageing and disease . If it wasn\u2019t possible to extend the maximum lifespan in humans, says Faragher, \u201cthis would make\u00a0us\u00a0different from every other experimental species we\u2019ve tried\u201d. Vijg argues that findings in model organisms aren\u2019t necessarily applicable to humans because these animals are bred to have certain traits. And at least one lifespan-extending strategy,  caloric restriction , is much  less effective  when used in wild mice or monkeys, he says. \u201cI\u2019m not saying drugs or tissue engineering couldn\u2019t be very beneficial to increase our average lifespan, but will they really enable us to break through this ceiling of 115? I find that highly unlikely,\u201d Vijg says. \u201cLifespan is controlled by too many genes. You could maybe plug one of those holes, but there are still another 10,000 other holes springing up.\u201d Biomedical gerontologist Aubrey de Grey, chief science officer of the SENS Research Foundation Mountain View, California, which develops and promotes rejeuvenation biotechnologies, is more hopeful. \u201cUnlike a dam, the pressure on the so-far-unplugged leaks actually diminishes as one plugs more and more of them,\u201d he says. \u201cThe result in this paper is absolutely correct, but it says nothing about the potential of future medicine, only the performance of today\u2019s and yesterday\u2019s medicine.\u201d Read the related News & Views article: \u2018 Measuring our narrow strip of life \u2019; and the related Editorial: ' The limits to human lifespan must be respected '. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Ageing research: Blood to blood 2015-Jan-21 \n                 \n                   Monkeys that cut calories live longer 2014-Apr-01 \n                 \n                   Calorie restriction falters in the long run 2012-Aug-29 \n                 \n                   Telomerase reverses ageing process 2010-Nov-28 \n                 \n                   Biodemography of human ageing 2010-Mar-24 \n                 \n                   The Human Mortality Database \n                 \n                   International Database on Longevity \n                 \n                   Gerontology Research Group \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20722", "url": "https://www.nature.com/articles/nature.2016.20722", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}, {"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "British-born theorists recognized for work on topological phases. David Thouless, Duncan Haldane and Michael Kosterlitz have won the  2016 Nobel Prize in Physics  for their theoretical explanations of strange states of matter in two-dimensional materials, known as topological phases. The trio\u2019s work in the 1970s and 1980s laid the foundations for predicting and explaining bizarre behaviours that experimentalists discovered at the surfaces of materials, and inside extremely thin layers. These include superconductivity \u2014 the ability to conduct electricity without resistance \u2014 and magnetism in very thin materials. At the time, these mathematical theories were quite abstract, said Haldane in an interview with the Nobel Commitee just after winning the prize. He said that he was \u201cvery surprised and very gratified\u201d to receive the award. But physicists are now exploring similar states of matter for potential use in a new generation of electronics, and in quantum computers. And the theories pioneered by the Nobel winners have been extended to develop exciting materials such as  topological insulators  \u2014 which don't conduct electricity in their bulk but do on their surface. \n               Physics through topology \n             The three winners all explained the behaviour of exotic matter through the mathematical concept of topology, which describes properties that remain unchanged if an object is deformed but not torn. \"In different ways, they showed how the concept of topology could give rise to new forms of matter that hadn\u2019t previously been understood,\u201d says Nigel Cooper, a theoretical physicist at the University of Cambridge, UK. Just as a knot tied in an unbroken circle of string cannot be removed without cutting the string, topological properties tend to be robust. For example, vortices in a fluid are easy to move around but harder to destroy. \u201cBecause of topology, they\u2019re protected. They cannot be simply removed,\u201d explains Immanuel Bloch, an experimental physicist who has studied topological phenomena at the Ludwig Maximilian University in Munich, Germany. Thouless and Kosterlitz, working at the University of Birmingham, UK, used topology to explain certain kinds of phase transition. Atoms in different phases of matter \u2014 such as a solid, liquid or gas \u2014 have characteristic kinds of order. In the 1970s, researchers believed that order in a 2D material was impossible, because thermal fluctuations would destroy any ordering, even at temperatures close to absolute zero. But Thouless and Kosterlitz showed that topological phase transitions \u2014 in which a material switches between states with different topologies \u2014 were possible in thin layers of materials. Using this model they demonstrated that, in theory, superconductivity could occur at low temperatures, but that it would disappear at higher temperatures. They also explained the mechanism that would make the effect vanish. Their theory, known as the Kosterlitz\u2013Thouless (KT) transition, turned out to apply to many different kinds of 2D material, and became a useful tool throughout physics. (Vadim Berezinskii, a Ukrainian physicist who presented similar ideas and whose name is usually associated with the transition along with Kosterlitz and Thouless, might have been in line for the prize, but he died in 1980.) \n               Quantum effects \n             In 1982, Thouless also explained a phenomenon known as the quantum Hall effect \u2014 it had been discovered in 1980 by German physicist Klaus von Klitzing, who would go on to win the 1985 physics Nobel prize for his finding. In this odd effect, when electrons are confined to thin films, chilled to near absolute zero and subjected to a strong magnetic field, they flow in an unusually orderly way with conductivity that increases in steps with an increasing magnetic field. Thouless showed that the quantum Hall effect was, again, a topological phenomenon. Changes to the system\u2019s properties could not occur smoothly \u2014 which would be mathematically similar to \u2018deforming\u2019 the topological system \u2014 but had to occur in sudden steps. The quantum Hall effect was a huge surprise, says Roderich Moessner, a theoretical condensed-matter physicist at the\u00a0Max Planck Institute for the Physics of Complex Systems in Dresden, Germany. \"Thouless realized that topology was a central ingredient.\" Haldane, meanwhile, was busy applying the concept of topology to chains of magnetic atoms. These atoms have a quantum property known as spin, and in 1982, he predicted that certain chains of the atoms could show topological properties that result in half spins at either end. Because this quantum property depends on the collective action of the whole chain, rather than on any individual particle, similar phenomena are now being explored as robust ways to encode information in a quantum computer. The British-born theorists now all work in the United States: Thouless at the University of Washington, Seattle; Kosterlitz at Brown University in Providence, Rhode Island; and Haldane at Princeton University in New Jersey. They will split the prize money of 8 million Swedish kronor (US$940,000), half going to Thouless and the other half split between Kosterlitz and Haldane. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Morphing neutrinos win physics Nobel 2015-Oct-06 \n                   \n                     Twisted magnetic fields tie information in a knot 2013-Aug-08 \n                   \n                     Topological insulators: Star material 2010-Jul-14 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20735", "url": "https://www.nature.com/articles/nature.2016.20735", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Agreement is likely to enter into force before next round of UN climate negotiations in Marrakesh. The  Paris climate pact  is set to enter into force as soon as next month, after the European Parliament  voted on 4 October  for the European Union to ratify the agreement. The 2015 accord, which seeks to hold warming \"well below\" 2 \u00b0C above pre-industrial temperatures, must be ratified or otherwise formally joined by 55 countries accounting for 55% of global emissions to take effect. More than 60 countries, including China and the United States, have already joined the accord, and ratification by the EU, the world\u2019s third-largest greenhouse-gas emitter, would push the pact past its other legal threshold. The EU has previously agreed to cut its emissions by 40% by 2030, relative to 1990 levels. But each of the nation\u2019s member states must ratify the Paris agreement separately, and observers feared that lack of consent among the bloc\u2019s member states over their respective share to the EU-wide reduction target might delay the Paris pact until at least 2017. They had also worried that the United Kingdom\u2019s decision to leave the EU might cause further delay. \n             Faster track \n           In a surprise move, EU heads of states agreed last week that the bloc, which has long been pushing for international agreement on climate action, should move on a faster track. \u201cIt would have been very embarrassing for the EU, of all countries, to further delay the start of the Paris agreement,\u201d says Oliver Geden, head of the EU Research Division at the German Institute for International and Security Affairs in Berlin. As a result of Parliament\u2019s vote, the EU is expected before the end of this week to formally submit its ratification documents to the United Nations in New York City. Given that not every EU member state is taking similarly rapid action to ratify the Paris pact, it is not clear whether the bloc\u2019s entire share of global emissions can yet be counted as part of the accord. But seven member states that have already completed their ratification procedures \u2014 France, Hungary, Austria, Germany, Slovakia, Portugal and Malta \u2014 will submit their formal documents to the United Nations along with the EU, says European Commission spokesperson Anna-Kaisa Itkonen. That will be sufficient to push the Paris accord into force. The deal will take effect on the 30th day after the United Nations receives formal ratifications that meet the 55% threshold \u2014 now likely to occur before the launch on 7 November of the next United Nations climate meeting in Marrakesh, Morocco. \u201cDespite its internal conflicts, the EU has shown that it is still capable of action,\u201d says Geden. \u201cThat\u2019s a diplomatic success and really quite a surprise.\u201d \n                   Brazil ratification pushes Paris climate deal one step closer 2016-Sep-14 \n                 \n                   Paris climate deal: what comes next 2016-Apr-22 \n                 \n                   Climate scientists focus on 1.5 degrees after Paris deal 2016-Apr-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20713", "url": "https://www.nature.com/articles/nature.2016.20713", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": " Panel will focus on the implications of gene editing in human reproduction and livestock. From designer babies to engineered mosquitoes, advances in genome-editing technologies such as CRISPR\u2013Cas9 have raised the possibility of  tremendous scientific advances  \u2014 and  serious ethical concerns . In a preliminary 130-page report released on 30 September, the influential Nuffield Council on Bioethics in London announced that two applications of the technology demanded further attention: genome editing in human embryos and in livestock. The two areas were selected on the basis of months of analysis and input from scholars and the public, said Hugh Whittall, director of the Nuffield Council, at a briefing on 29 September. It will probably be years before genome editing is used in human reproduction, but it was clear from that input that ethical concerns about edited human embryos were at the forefront of many minds, says Karen Yeung, Nuffield working-group member and a legal scholar at King\u2019s College London. \u201cHuman reproductive applications are perhaps the most talked about or controversial area.\u201d \n               Designer-baby fears \n             Although gene editing was already racing through research laboratories, the revelation in 2015 that researchers had  used CRISPR\u2013Cas9 in human embryos  shone a public spotlight on its potential applications in human reproduction. That first study used non-viable embryos for research purposes only 1 , but it launched a public debate about whether and how such technologies should be deployed in humans. It also sparked a spate of soul-searching at national academies and agencies around the world. The US National Academies of Sciences, Engineering and Medicine  are putting together a report  \u2014 due out in early 2017 \u2014 on human applications of genome editing. Other academy committees will evaluate how to adjust regulations on genetically modified livestock, among several biotechnology products, to account for gene editing and other techniques. They will also consider how to approach  \u2018gene drives\u2019  \u2014 a method that harnesses gene editing to promote the rapid spread of genes through wild populations. In parallel, an independent group of European ethicists has called for the formation of a European steering committee to discuss standards to ensure that  CRISPR methods  are safe and reliable before being used for medical purposes. The team has started discussions with the European Commission about this, says Fran\u00e7ois Hirsch, assistant director for ethics and regulation at the Institute for Health Technologies in Paris, who co-authored a white paper calling for the committee. The Nuffield Council aims to finish its report on ethical questions in human reproduction in early 2017. The working group will focus on the implications of using gene editing to address genetic diseases, says Yeung. Although she thinks that such applications are years away, they are important enough to warrant an early focus. Tinkering with embryos destined for implantation is against the law in the United Kingdom, Yeung notes. If the group finds strong moral arguments in favour of genome editing to prevent disease, it could take a long time to change that law. The working group would also have to wrestle with where to draw the line between ethically acceptable and unacceptable uses, Yeung says. That discussion is particularly important, says Alta Charo, who studies law and ethics at the University of Wisconsin\u2013Madison. Although scientists and ethicists tend to focus on dealing with serious genetic disorders, the public conversation often wanders into murkier territory, such as augmentation of intelligence. \u201cThe laypress tends to do all of these covers about designer babies,\u201d she says. \u201cThey tend to focus on the things that are the least likely to be genetically determined, but capture our imaginations the most.\u201d \n               CRISPR cows \n             Use of  the technology in livestock  such as cattle or swine comes with unique issues of its own. These include concerns about animal welfare, and questions as to whether and how meat produced from such animals should be labelled. Labelling is a particularly vexing issue, given that genome-editing techniques might leave no molecular trace. The resulting animals can be indistinguishable from natural counterparts that happen to carry the same mutation. \u201cLabelling and classification depend on traceability,\u201d says John Dupr\u00e9, a philosopher of science at the University of Exeter, UK, who will serve on the Nuffield working party on livestock. \u201cGenome editing makes analytical verification of this difficult or impossible.\u201d But some edited livestock \u2014 including cattle that lack horns and pigs that are resistant to disease \u2014 are already under development. And the working group felt there had been comparatively little public discussion of the matter, says Peter Mills, assistant director of the Nuffield Council. \u201cIn the livestock, the technology there is pretty much ready to go,\u201d he says. \u201cThat was something from our point of view that needs to be brought to public attention.\u201d \n                     Should you edit your children\u2019s genes? 2016-Feb-23 \n                   \n                     Gene-editing summit supports some research in human embryos 2015-Dec-03 \n                   \n                     UK scientists apply for licence to edit genes in human embryos 2015-Sep-18 \n                   \n                     Ethics of embryo editing divides scientists 2015-Mar-18 \n                   \n                     Nuffield Council on Bioethics: Gene editing \n                   Reprints and Permissions"},
{"file_id": "538016a", "url": "https://www.nature.com/articles/538016a", "year": 2016, "authors": [{"name": "Shaoni  Bhattacharya"}], "parsed_as_year": "2006_or_before", "body": "Ancient genes will soon be available to researchers again, but the move poses its own challenges. A major seed bank in Aleppo, Syria, holds genes that might help researchers breed crops to survive climate change. But the conflict tearing the country apart has rendered the bank largely inaccessible for the past four years. Now an effort to duplicate its seed collection at more-accessible locations is ramping up. On 29 September, the International Center for Agricultural Research in the Dry Areas (ICARDA), which runs the bank in Aleppo, officially launched a sister bank in Terbol, Lebanon, which now hosts 30,000 duplicates. Together with a new bank in Rabat, Morocco, it will make thousands of seeds available to researchers. \u201cThe situation in Syria did not allow us to continue our core activities,\u201d says Ahmed Amri, head of genetic resources at ICARDA\u2019s research station in Rabat. \u201cI\u2019m happy that we [ICARDA] have established ourselves back to normal.\u201d Seed banks function as bank accounts for plant genes. Collectors deposit seeds, which can later be \u2018withdrawn\u2019 to replenish crops lost in conflict or disaster, to breed new traits into crops \u2014 such as pest or heat resistance \u2014 and to research the evolution of plants over the ages. ICARDA\u2019s collection, previously held entirely at the bank in Aleppo, is especially valuable because it aims to collect seeds from the world\u2019s dry regions. That includes the Fertile Crescent, which spans parts of North Africa, the Middle East, the Caucasus and west Asia, and is thought of as the birthplace of modern agriculture. The collection contains many wild relatives of modern crops such as wheat, barley, lentils and grass pea. The centre provides researchers and breeders with an average of about 20,000 samples each year, says Amri, with most material going to the United States, to institutions in the nation\u2019s breadbasket such as Kansas State University and North Dakota State University. Many wild varieties from arid regions have traits that may help crops to meet the challenges posed by climate change, including resistance to drought, heat and pests, and adaptations to salinity. ICARDA\u2019s gene bank harbours wheat seeds that are the product of thousands of years of adaptation and natural selection, says Maricelis Acevedo, associate director for science for the Delivering Genetic Gains in Wheat project at Cornell University in Ithaca, New York. \u201cOnly a small amount of wheat genetic diversity has been utilized and explored.\u201d Although  most staff left ICARDA\u2019s Aleppo site in 2012 , the vault there is intact, according to the last inspection three months ago. But seeds can no longer be moved in or out easily. Almost all of the seeds in ICARDA\u2019s bank have previously been duplicated and sent to banks elsewhere, mainly to the super-secure Svalbard Global Seed Vault in Norway \u2014 a.k.a. the \u2018doomsday vault\u2019 \u2014 which was set up to provide back-up copies of seeds held in banks worldwide. But this trove is not easily available to scientists. By contrast, ICARDA\u2019s collection is mainly meant to be \u2018active\u2019: in other words, available to farmers, researchers and breeders. In 2015, ICARDA made its first withdrawal of seeds from the Svalbard bank and is now using them to build up stocks in Terbol and Rabat. It will return the stocks to Svalbard and withdraw several more batches to reconstruct the entire Aleppo collection. Duplicating the collection in more-accessible gene banks is vital, says Mogens Hovm\u00f8ller, a plant pathologist at the University of Aarhus in Denmark, who also leads the  Global Rust Reference Center . That project was co-founded by ICARDA and is part of an  effort to minimize the world\u2019s vulnerability  to devastating wheat-rust diseases. The choice of Terbol as a location is a \u201cbrilliant move\u201d, says Michiel van Slagaren, who worked for ICARDA from 1988 to 1994 and is now at the Kew Royal Botanic Gardens site in Wakehurst, UK. Terbol lies in Lebanon\u2019s Bekaa valley, which provides a gradient of conditions from semi-desert to high-rainfall areas and so is ideal for testing how seeds grow in different ecosystems, he says. But the move may also bring risks. The gene bank looks out on the Anti-Lebanon mountain range that forms much of Lebanon\u2019s border with Syria and is not far from the conflict. The Bekaa valley also hosts refugees fleeing the civil war. Van Slageren ponders the potential for the conflict to spill into Lebanon. \u201cYou do have to wonder how their minds have been put at ease,\u201d he says. He notes that when ICARDA was set up in 1977, its head\u00adquarters were in Lebanon, but moved to Syria because of the Lebanese Civil War. The latest move has also posed staff challenges. Many long-serving members were already close to retirement when ICARDA left Syria, says Amri, and so did not move to Terbol. And funding remains an issue, although ICARDA received significant financial help with the move from various agencies, including the  CGIAR Consortium , a global partnership aimed at alleviating poverty and hunger. The current capacities of the banks in Terbol and Rabat \u2014 100,000 and 35,000, respectively \u2014 do not add up to enough to duplicate all 141,000\u00a0seeds, representing some 700 species, that Aleppo holds, let alone take on new seeds (see \u2018Caught in conflict\u2019). Amri is confident. Among other things, previous unrest in Lebanon did not disrupt ICARDA\u2019s Terbol station. \u201cIt\u2019s gone through 20 years of fighting, and we never had any problems,\u201d he says. Still, the Moroccan talks wistfully of his years working in Syria. \u201cWe enjoyed our lives in Aleppo. It was one of the nicest places to live \u2014 wonderful people and a good environment for research at ICARDA.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     The struggle to save the Middle East\u2019s cultural treasures 2016-Jan-08 \n                   \n                     Climate change implicated in current Syrian conflict 2015-Mar-02 \n                   \n                     Conflict in Syria forces international research centre to move staff 2012-Sep-16 \n                   \n                     Seeds in threatened soil 2005-Jun-01 \n                   \n                     Blog post: Safekeeping Syria\u2019s plant genetic heritage \n                   \n                     International Center for Agricultural Research in the Dry Areas (ICARDA) \n                   \n                     CGIAR \n                   \n                     Svalbard Global Seed Vault \n                   \n                     Millennium Seed Bank, Kew \n                   \n                     Global Rust Reference Center \n                   \n                     Delivering Genetic Gain in Wheat programme at Cornell University \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20734", "url": "https://www.nature.com/articles/nature.2016.20734", "year": 2016, "authors": [{"name": "Richard Van Noorden"}, {"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Jean-Pierre Sauvage, Fraser Stoddart and Bernard Feringa share 2016 award. Three chemists who created tiny molecular machines have won the  2016 Nobel Prize in Chemistry  for their intricate designs. Jean-Pierre Sauvage, at the University of Strasbourg in France; Fraser Stoddart, a Scottish-born chemist at Northwestern University in Evanston, Illinois; and Bernard Feringa, at the University of Groningen in the Netherlands, share the award for their work in the 1980s and 1990s, when they pioneered efforts to miniaturize motors. \u201cI\u2019m a bit shocked because it was such a great surprise. And I\u2019m so honoured,\u201d said Feringa in an interview with the Nobel Committee just after winning the prize. The three have made  molecular knots, shuttles, rotors, chains, pumps, axles, switches, memory devices and even a nanocar  \u2014 all at the scale of molecules (see 'Nano machines'). The nanoscale machines are yet to find application, but researchers hope that their uses could range from delivering drugs to computer memory. \u201cIt\u2019s early days, of course,\u201d Feringa told the Nobel Committee. \u201cBut once you are able to control movement, you have a motor, you can think of all kinds of functions.\u201d He suggested that the machines could be used as tiny robots in the body to deliver drugs or detect cancerous cells; or as smart materials that could adapt or change depending on external signals. \"I applaud the fact that \u2014 for once in chemistry \u2014 Stockholm [where the Nobels are announced] has recognized a piece of chemistry that is fundamental in its making and being,\" Stoddart said at a press conference at Northwestern University, held later in the day. Only a handful of laboratories are currently actively engaged in making nanomachines, says Dean Astumian, who studies the theory of molecular motors at the University of Maine in Orono. But he thinks the field will get a boost from the award. \u201cThe recognition that is afforded by a Nobel Prize is going to attract the best young people,\u201d he says. Astumian thinks the work will provide applications within 25 years. \u201cThere\u2019s no device that you can buy that\u2019s made out of molecular machines. But they\u2019re coming.\u201d \n               Molecular architects \n             In 1983, Sauvage\u2019s group was the first to create molecular interlocking chains and rings \u2014 called catenanes \u2014 which were the first steps to creating the connected parts needed for molecular motors. By creating interlocking rings, Stoddart noted at his press conference, Sauvage's group effectively invented a new way to bind molecules together \u2014 a mechanical bond, rather than a chemical one. \"New bonds are few and far between. They are really the blue moons,\" Stoddart said. Stoddart himself, in 1991, created the first molecular shuttle: a ring-shaped molecule threaded onto an \u2018axle\u2019, called a rotaxane. The ring could shunt back and forth between two sites on the axle, which was capped at each end by stoppers, and Stoddart and other chemists figured out how to control that process, using changes in acidity, light or temperature. Since then, Stoddart\u2019s team has used similar rotaxanes to make a molecular \u2018lift\u2019, which can raise itself (by less than a nanometre) above a surface, and an artificial \u2018muscle\u2019, in which rotaxanes bend a thin sheet. The researchers have also used millions of rotaxanes to make a  high-density memory device  \u2014 in which the shuttles flick from an \u2018on\u2019 state to an \u2018off\u2019 state. And in 1999, Feringa was the first to develop a synthetic molecular motor \u2014 a single molecule with paddle units connected by a carbon\u2013carbon double bond. The paddles rotated, and kept on spinning, when the bond was broken with light. Feringa showed that the motors could have macroscale effects, such as rotating a glass rod sitting on top of them. Perhaps most famously, Feringa has also created a four-wheel-drive  \u2018nanocar\u2019  out of the motors. \n               Wider impacts \n             The Nobel winners' work \u2014 and other chemists' nanomachines \u2014 have also had an impact on researchers\u2019 understanding of nature, Astumian says. In particular, the artificial systems have helped to demonstrate that all chemically-powered molecular machines, whether synthetic or biological, work according to the same principles: by selectively harvesting the random jiggles of Brownian motion, rather than pushing against them. Asked by reporters at the Nobel press conference whether his machines would find a use, Feringa likened the creators of minuscule machines to the Wright Brothers, who made their maiden flight in a powered aircraft more than 100 years ago. \u201cPeople were saying, why do we need a flying machine? Now we have a Boeing 747 and an Airbus. That\u2019s a little bit how I feel. The opportunities are great.\u201d During his own press conference, Stoddart also took political swipes, both at recent UK anti-immigration rhetoric and at US Presidential candidate Donald Trump. He said that his old country, the United Kingdom, was \u201cin a real mess because it thinks it can raise borders to people coming in\". And referring to Trump's comment in his first debate with Hillary Clinton that not paying federal taxes would be \"smart\", Stoddart said that one-third of his Nobel earnings would go to taxes, because, he said, \"I am not smart\". \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Physics of 2D exotic matter wins Nobel 2016-Oct-04 \n                   \n                     Medicine Nobel for research on how cells 'eat themselves' 2016-Oct-03 \n                   \n                     The tiniest Lego: a tale of nanoscale motors, rotors, switches and pumps 2015-Sep-02 \n                   \n                     Chemistry Nobel webpage \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20754", "url": "https://www.nature.com/articles/nature.2016.20754", "year": 2016, "authors": [{"name": "Linda Nordling"}], "parsed_as_year": "2006_or_before", "body": "Network would be Africa's largest demographics project if it can sustain long-term funding. South Africa's government has announced that it will expand the country\u2019s existing demographic studies to create a project that will be the largest of its kind in Africa \u2014 tracking the health, income, and educational attainment of around 1% of South Africa\u2019s population. The Department of Science and Technology estimates that it will put 264 million rand (US$19 million) into the demographic project over the next five years,\u00a0which will eventually cover at least half a million people. It has secured the funding for its first three years; the rest will need to be allocated in future government budgets. If the study can be sustained in the long term, researchers hope that the data will help them to track efforts to curb major health problems such as HIV and tuberculosis, and to monitor emerging lifestyle-related threats such as cancer and diabetes. The department intends for the survey to run for decades, following people from the cradle to the grave and monitoring inter-generational trends. Long-term demographic studies have played an important part in charting disease patterns. One survey that began in 1948 in Framingham, Massachusetts, led to the discovery of cardiovascular disease risk factors such as smoking and diabetes, and has allowed scientists to study inter-generational disease patterns. But in Africa, as in many other parts of the developing world, such long-term projects have been neglected in favour of focusing on health emergencies such as HIV or Ebola, says Glenda Gray, president of the South African Medical Research Council. \u201cYou never get your head above water to plan for the future,\u201d she says. She thinks that the new project will change that. South Africa has had three demographic surveillance projects running since the mid-to-late 1990s, based in Mpumalanga and Limpopo in the northeast, and KwaZulu-Natal on the east coast. These have been able to track trends such as a growth in life expectancy as the country  rolled out antiretroviral drugs to fight the HIV epidemic . But the long-term sustainability of such studies \u2014 which have been funded by non-governmental donors \u2014 is a perennial concern, says Kobus Herbst, deputy director of the African Health Research Institute, based in Durban, which runs the study in KwaZulu-Natal. So the government\u2019s investment is particularly welcome, he says. \n               From rural to urban \n             All the existing surveillance projects are in rural areas, providing only a narrow view of national population trends, says Gray. \u201cThe rural sites have been critical for understanding things like how antiretroviral rollout plays out in districts,\u201d she says. But they don\u2019t catch emerging patterns of disease linked with modern city life, driven by factors such as pollution, work-related stress and dietary changes. Of the four new surveillance nodes in the planned network, three will be based in South Africa\u2019s biggest cities: Cape Town, Johannesburg and Durban. The existing surveys already cover around 250,000 people, but each collects different types of data, so their measurements cannot be compared or integrated together. During the first three years, the surveys will be linked up, and the Limpopo one will be expanded. By the end of the three-year period, a total of 300,000 people should be included in the project, says Herbst. The target of 500,000 people will be reached, hopefully, in five years' time, he says. The government funding will cover the full health and socio-demographic surveys, as well as fund linkages to national health records and the collection of dried blood spots from adult participants once a year for HIV testing, Herbst says. To do more \u2014 such as sequence DNA \u2014 funding will be sought from external donors. Linda Fried, an epidemiologist who is dean of Columbia University\u2019s Mailman School of Public Health in New York City, thinks that the surveys will not only allow South Africa to develop its science base but also attract international investment. The programme was launched on 4 October by South African science minister Naledi Pandor, at a conference to plan out South Africa\u2019s  first road map for national research infrastructures . In addition to the demographic project, the road map launched this week includes plans for a nuclear-medicine research facility dedicated to drug development and clinical research, a solar-research facility to demonstrate photovoltaic technologies, and a new hub to coordinate efforts to protect the country\u2019s natural-history collections. \u201cWe build big scientific infrastructure to attract international researchers to our country,\u201d Pandor said. \n                     South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                   \n                     South Africa ushers in a new era for HIV 2016-Jul-13 \n                   \n                     Massive UK baby study cancelled 2015-Oct-27 \n                   \n                     Epidemiology: Study of a lifetime 2011-Mar-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20617", "url": "https://www.nature.com/articles/nature.2016.20617", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "A torrent of low-quality meta-analyses and systematic reviews in biomedicine might be hiding valuable research and misleading scientists. A gold standard of scientific analysis is fast becoming tarnished, according to a report by a leading meta-researcher. Systematic reviews and meta-analyses distil scientific articles on similar questions into what is meant to be an authoritative take on a particular topic \u2014 often how well a particular treatment works across medical settings \u2014 and they are key tools in evidence-based medicine. But valuable reports are getting diluted by \u201ca massive production of unnecessary, misleading and conflicted systematic reviews and meta-analyses\u201d, according to John Ioannidis at Stanford University in California, who has published a report in  The Milbank Quarterly 1  looking at trends in the publication of these articles. He decided to try to quantify the problem after noticing \u201can epidemic\u201d of poor and obviously flawed articles, he says. \u201cWhen the most influential literature is wrong, the harm that is done is worse than when unimportant studies are wrong.\u201d Ioannidis counted the number of articles that had been tagged as \u2018systematic reviews\u2019 and \u2018meta-analyses\u2019 in PubMed, a database of biomedical and life sciences publications. From 1991 to 2014, the numbers of these articles published annually increased by more than 2,600%, to 28,959 for systematic reviews and 9,135 for meta-analyses. Over the same time period, the total number of articles appearing in PubMed each year increased by 153%. The most prolific source of meta-analyses \u2014 63% of the total in 2014 \u2014 were genetic association studies from authors in China, many of which did not account for the high likelihood of finding false positives, Ioannidis concluded.\u00a0 One reason that systematic reviews are increasing is that more people around the world are doing research and are eager to get publications, says Christopher Schmid, a biostatistician at Brown University School of Public Health in Providence, Rhode Island. Schmid, who handles meta-analyses at the  American Journal of Kidney Diseases , says that around ten years ago he began noticing that many more submissions were coming from Asia. \u201cAt first they were not good quality, but they have really improved a lot.\u201d Still, he says, access to data is likely to expand faster than education about what it takes to do a good systematic review. \n             Questionable motives? \n           Ioannidis also thinks that much of the overall increase stems from articles intended mainly to increase citations and publications \u2014 or to serve as marketing tools for industry groups. One topic \u2014 the use of drugs called statins to prevent a common heart arrhythmia after heart surgery \u2014 had been covered by 21 meta-analyses in seven years; another 185 had been written about antidepressants in a similar period, and about one-third of these had co-authors employed by a drug manufacturer. The prestige of such publications in biomedicine contributes to the problem, says Ioannidis. They generally run in respectable journals, he says, and are also cited more than any other type of study design. Another study published this year 2  examined characteristics of a random sample of 300 systematic reviews and found that problems were common; few sought out unpublished data or incorporated sources of bias into the analysis. Many failed to report how they identified or selected the articles to include. Hopefully, such analyses will bring attention to a serious problem, says Kay Dickersin, director of the Center for Clinical Trials and Evidence Synthesis at Johns Hopkins University in Baltimore, Maryland. There are good reasons for these types of articles to increase, she says. People appreciate that such studies are important in making community health decisions, and more instruction is available to teach scientists to do them well. But demand is still greater than the amount of expertise out there, says Dickersin, who is part of an effort to install trained experts as journal editors. \u201cWe just have to acknowledge that specialty journals can\u2019t find enough methodologists to vet reviews,\u201d she says. \u201cIt is terrible and scary, since systematic reviews and meta-analyses are considered the highest level of evidence.\u201d Read a previous Trend Watch: ' Brazil ratification pushes Paris climate deal one step closer ' \n                   How many replication studies are enough? 2016-Feb-26 \n                 \n                   US behavioural research studies skew positive 2013-Aug-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20756", "url": "https://www.nature.com/articles/nature.2016.20756", "year": 2016, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Humans might not be the only ones that understand when others harbour mistaken beliefs. The delight of slapstick comedy lies in watching the mistakes of unwitting players, and new research shows that apes just might get the joke, too. A study published on 6 October in  Science  suggests that, like humans, chimpanzees and  other apes  can infer the beliefs of others \u00ad\u2014 even when those beliefs contradict reality \u2014 and anticipate their errors 1 . The findings, which counter many previous studies, could fuel the debate over  whether humans are unique  in their ability to recognize the desires, beliefs and internal thoughts of others \u2014 a concept known as theory of mind. In previous studies, chimpanzees ( Pan troglodytes ) have seemed to grasp some aspects of the goals, knowledge and perceptions of others 2 . But chimps, monkeys and other primates have consistently failed to demonstrate an understanding of others\u2019 false beliefs \u2014 a key component of theory of mind 2 , 3 . Children younger than age four had also historically failed many of these tests 4 , supporting the idea that understanding false beliefs requires sophisticated thinking that develops later in childhood. But in 2007, a study of infants challenged this concept 4 . Researchers found that babies as young as 25 months, looked first at where an actor would search (incorrectly) for an object after it had been moved without the actor\u2019s knowledge. Inspired by these results, a team of comparative psychologists borrowed the method to revisit the question in chimpanzees, bonobos ( Pan paniscus ) and orangutans ( Pongo abelii ). The study's results were definitely a surprise, says Christopher Krupenye, now at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, who co-led the work with Fumihiro Kano at Kyoto University\u2019s Kumamoto Sanctuary in Kumamoto, Japan. This was especially intriguing because apes had done so poorly in previous experiments designed to examine this question. \u201cTo some extent, I saw this as a last-ditch effort,\" he says. \n             Putting on a show \n           To tailor their task for apes, the researchers went for entertainment value to ensure that the animals paid attention to various scenarios. In two separate experiments, the team created and starred in a series of short films depicting combative interactions between a human and a person dressed in a \u2018King Kong\u2019 suit. Each series began by introducing the story\u2019s premise: a human searching for either a stone or King Kong. In one series, the human whacked a stick against one of two haystacks where they had watched King Kong hide; in the other, the person would lift one of two boxes under which they had seen  King Kong tuck a stolen stone . These scenes showed the apes that the person would pursue the object in its last known location. \u201cFor humans, these scenes look silly, almost like Charlie Chaplin scenes. But for apes, it\u2019s a novel social conflict,\u201d says Krupenye. The slightly bizarre quality of the scenarios was intentional to keep the animals from drawing on knowledge of familiar situations. In the films, the object (King Kong or the stone) was eventually moved from its initial location (haystack or box) to the other \u2014 sometimes while the human observed, and other times while the human was absent. Then, the object was removed from the scene altogether while the human was away, in part to prevent the apes from expressing their own beliefs about the object\u2019s location. The videos ended with the person returning to the arena, approaching both empty locations and preparing to search without giving any indication of where they would look. \n             The eyes have it \n           At the deciding moment, about 20\u201330 apes responded by looking at one of the two locations. Of those animals, about two-thirds to three-quarters, depending on the experiment, looked first to where the human would have thought their target was hiding. This predictive ability suggests that apes understand the incorrect beliefs of others, says Kano. \u201cIt\u2019s a pretty shocking result,\u201d says cognitive psychologist Laurie Santos at Yale University in New Haven, Connecticut \u2014 citing many primate studies, including her own 3 , which suggest that the animals lack this skill. The effect reported in this study is small, she notes. But \u201cif these results hold up, they\u2019ll be a game changer for the way that people think about primate social cognition\u201d, Santos adds. Valerie Kuhlmeier, a developmental psychologist at Queen\u2019s University in Kingston, Canada, commends the group for executing a difficult and carefully crafted experiment. But she offers a competing explanation for the results, one in which the apes used knowledge of abstract rules \u2014 specifically, that people tend to look for objects in the place they last saw them. Genuine false-belief understanding still seems to be uniquely human, contends Kuhlmeier. Although the authors acknowledge that the apes could have followed learnt rules, Krupenye says, \u201cthey're still able to accurately predict others\u2019 actions in more sophisticated contexts than we have thought before\u201d. He plans to strengthen their case by demonstrating other forms of false-belief understanding in apes. \u201cThis is a first study that will hopefully energize interest in the topic,\u201d says Krupenye. \n                   Dogs can tell when praise is sincere 2016-Aug-30 \n                 \n                   Monkeys seem to recognize their reflections 2015-Jan-09 \n                 \n                   Rats free each other from cages 2011-Dec-08 \n                 \n                   Elephants not fooled by mirrors 2006-Oct-30 \n                 \n                   Gorillas branch out into tool use 2005-Sep-30 \n                 \n                   Salamanders can do maths 2003-May-03 \n                 \n                   Christopher Krupenye \n                 \n                   Fumihiro Kano \n                 \n                   Laurie Santos \n                 \n                   Valerie Kuhlmeier \n                 Reprints and Permissions"},
{"file_id": "537457a", "url": "https://www.nature.com/articles/537457a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "After decades of rocky relations, they are working together to trace indigenous communities\u2019 ancestry. In 1938, anthropologists Norman Tindale and Joseph Birdsell set off on an 18-month, 29,000-kilometre expedition to survey Australia\u2019s indigenous groups. They took photographs, physical measurements and hair samples from thousands of Aboriginal Australians at a time when few protections existed for research subjects, and well before the country\u2019s government granted full citizenship to Aboriginals in 1967. Western museums are filled with Aboriginal Australian artefacts, as well as hair, skulls and other tissues collected on similar expeditions. And decades of such treatment by researchers engendered strong mistrust among Aboriginal communities. However, a new generation of geneticists is attempting to repair relations. These scientists are eager to fill gaps in their knowledge of human prehistory, while also involving communities in genomics research. Three papers published this week in  Nature 1 , 2 , 3  use genome data from Aboriginal Australians. One reports sequences from 83\u00a0individuals and is the largest survey of Aboriginal genetic diversity yet published. With the other two papers, it helps to chart human migrations out of Africa and into Australasia, addressing a major question about how  Homo sapiens  moved around the world. Fraught relations between Aboriginal communities and geneticists continued well into the twentieth century with the Human Genetic Diversity Project, a 1990s survey of indigenous groups worldwide. Worries that scientists would create patented cell lines using blood gathered from Aboriginal groups prevented any sample collection. Two decades later, publication of  the first Aboriginal Australian genome 4  was nearly shelved because researchers did not get approval from any Aboriginal group before sequencing some hair collected in the 1920s. After a team member threatened to withdraw from the project, lead author Eske Willerslev, an evolutionary geneticist at the Natural History Museum of Denmark in Copenhagen, went to Western Australia to  seek the blessing of an Aboriginal group  in the region where the hair had been collected. \u201cI do regret that I didn\u2019t approach them before we had started undertaking the study,\u201d says Willerslev. But he is glad that he obtained their backing before publication in 2011. \n               Rules of engagement \n             In the study published this week 1 , Willerslev and his team sequenced Aboriginal Australian genomes to trace the arrival of humans in Australia some 50,000 years ago and track their spread across the continent. Willerslev says his meeting with Goldfields Land and Sea Council \u2014 the group consulted for the 2011 genome study \u2014 paved the way for outreach to other communities. \u201cIncreasingly, there is an awareness that there are rules and terms of engagement in terms of doing research with Aboriginal people and communities,\u201d says Alex Brown, a public health researcher at the University of South Australia in Adelaide and an Aboriginal Australian. He and Willerslev are now studying type 2 diabetes in Aboriginal people, who have much higher rates of the disease than other Australians. Other geneticists are also trying to build bridges with indigenous groups. The Aboriginal Heritage Project, which aims to sequence DNA from the 5,000 hair samples that Tindale, Birdsell and others collected, is seeking approval from living descendants before doing any sequencing. And their engagement does not end there. \u201cWe\u2019re asking them what they want to find out, rather than the other way around, which is how most research is done on Aboriginal groups,\u201d says project leader Alan Cooper at the University of Adelaide. Of the 150 families approached so far, only one has declined to participate.  It\u2019s really important that people have a sense of ownership.  The National Centre for Indigenous Genomics (NCIG), which maintains a database of 7,000\u00a0blood samples gathered from nearly 50 communities since the 1960s, is also giving Aboriginal groups a say in research. Blood samples will not be included in its database without permission from individuals or their surviving relatives, and a committee of indigenous Australians will weigh all requests from researchers to access the data. Participants can see how their data are used through an Internet portal and can withdraw their DNA from any project if they wish. \u201cThere\u2019s been damage done in the past, and it\u2019s really important that people have a sense of ownership,\u201d says NCIG director Simon Easteal at the Australian National University in Canberra. He also hopes the database can help individuals pinpoint their heritage, especially members of the \u2018stolen generations\u2019 who were forcibly removed from their families as children and raised among white Australians. There are still rocky moments. Willerslev says some people turn his team away, but he hopes that relations overall are improving. Meanwhile, some scientists in Australia, including Cooper and Easteal, worry about overseas researchers, whom they think may not be attuned to Australian cultural complexities. But Brown has no qualms about international researchers if they obey ethical guidelines and act with the interests of Aboriginal communities in mind. \u201cIt is much easier to work with people who have proven and meaningful relationships with indigenous communities,\u201d he says. \u201cMy push on them will be: sure, you\u2019ll get your pound of flesh out of this, but if you\u2019re not leaving something behind, then we simply can\u2019t do it.\u201d News & Views:  A map of human wanderlust \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               Reprints and Permissions"},
{"file_id": "nature.2016.20649", "url": "https://www.nature.com/articles/nature.2016.20649", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Chan Zuckerberg Initiative aims to have major impact by 2100. They are not the first billionaires to try to disrupt science. But Facebook co-founder Mark Zuckerberg and his wife, physician and educator Priscilla Chan, have enlisted a \u2018dream team\u2019 of scientific leaders to oversee a US$3-billion effort to boost basic research. \u201cWe see this work as being led and done by scientists,\u201d Chan told  Nature  before the couple unveiled the Chan Zuckerberg Initiative's plans on 21 September. She and her husband created the initiative in December to invest proceeds from their Facebook shares to aid causes such as education, health research and Internet connectivity. Zuckerberg and Chan have set themselves an audacious goal: eliminating, curing or preventing disease by the end of the century. They intend to get there by coaxing teams with diverse expertise to collaborate on developing new tools and technologies \u2014 something that scientists say is sorely needed. The $3-billion commitment announced today will cover the project's first ten years.\u201cBuilding tools requires bringing scientists and engineers together in large numbers for large periods of time, and that\u2019s not something most science funding is set up to do,\u201d Zuckerberg told  Nature . \u201cThat emerged to us as a big opening where we could help grow this movement among other scientific funders.\u201d \n               Filling the gaps \n             The initiative's approach stands in stark contrast to some other Silicon Valley-led efforts to revamp science. Take Google's parent company, Alphabet, which has closely guarded its biomedical-research enterprises \u2014 including its life sciences company Verily, and its anti-aging research company Calico, whose creation prompted  TIME  magazine to ask, \u201cCan Google solve death?\u201d. Chan and Zuckerberg \u201chave set out a goal that makes you gulp, and then they\u2019ve said, what are the missing pieces we need to get there?\u201d says Eric Lander, president of the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, and one of dozens of scientists whom the couple have quietly consulted over the past year. \u201cI am sure it will provoke people to think, can we actually do that?\u201d The pair\u2019s plans involve a who\u2019s who of researchers.  Neurobiologist Cornelia (Cori) Bargmann , an architect of the US National Institutes of Health's (NIH) contributions to the US government  BRAIN Initiative , will become president of science for the Chan Zuckerberg Initiative. The couple have also consulted a host of other biology notables, including Francis Collins, the director of the NIH, and Arthur Levinson, chief executive of Google\u2019s Calico and former chief executive of Genentech. Princeton University president emeritus Shirley Tilghman and Nobel laureate Harold Varmus are on the project\u2019s scientific advisory board.Bargmann says that the organization intends to set up \u201cchallenge networks\u201d of interdisciplinary researchers from different institutions. The scientists will commit to work on problems such as neurodegeneration, which could require contributions from basic biologists, clinicians and engineers. The initiative has also created the San Francisco-based Chan Zuckerberg Biohub, a US$600-million, 10-year partnership with Stanford University in California, the University of California, San Francisco (UCSF), and the University of California, Berkeley. UCSF biochemist Joseph DeRisi and Stanford bioengineer Stephen Quake are leading the effort. The biohub will first focus on creating a human-cell atlas that will use technologies such as single-cell genetic sequencing and gene editing to examine cells in minute detail, and developing new ways to detect, respond to, treat and prevent infectious disease.  \n               Knowledge sharing \n             Bargmann hopes to draw on the project\u2019s Silicon Valley roots to address issues such as the dearth of scalable tools that can be widely used across fields. \u201cIn my lab, everyone now writes code; that\u2019s a bit like everyone making their own soap,\u201d Bargmann says. \u201cWe should be finding ways of doing this that are general and powerful, that allow us to interact and share our knowledge.\u201d Silicon Valley companies have drawn heavily on some areas of scientific expertise \u2014 luring away talent in fields such as  machine learning . Google\u2019s Verily has also  recruited top-flight biomedical researchers  to work on ideas such as the Baseline Study, a longitudinal health project that has been running in a pilot phase since 2014. But the company has not published any data from that project, and scientists at Verily have said little publicly about their work there.DeRisi says that, by contrast, the biohub will disseminate data as broadly and as rapidly as possible. The initiative also hopes to avoid some of the administrative hurdles that hamper scientists\u2019 productivity. Applications for individual investigator awards, for instance, will be simplified compared with NIH applications, and some individual investigator awards will be reserved for non-tenured scientists, so that the researchers aren\u2019t competing with their more senior colleagues. The biohub will also create some lab-leader positions for researchers who don't want to teach or write grants.Lander predicts that such moves will be especially welcomed by young scientists, who, he says, are clamouring to work more collaboratively. \u201cYounger scientists are tremendously excited to figure out how to work together, but there haven\u2019t been that many vehicles to support these kinds of approaches.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Why biomedical superstars are signing on with Google 2015-Oct-21 \n                   \n                     Neuroscience: As the worm turns 2013-Feb-20 \n                   Reprints and Permissions"},
{"file_id": "537460a", "url": "https://www.nature.com/articles/537460a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Accusations of impropriety feature in escalating dispute. Geneticist George Church has pioneered methods for sequencing and altering genomes. He has been called a founding father of synthetic biology, and is probably the world\u2019s leading authority on efforts to resurrect the extinct woolly mammoth. Now, a battle over who owns the patent rights to a  revolutionary gene-editing technique  could hinge, in part, on whether Church\u2019s scientific skill could be considered \u2018ordinary\u2019. Such are the arcane and often bizarre issues the US Patent and Trademark Office (USPTO) must consider in the  fight over CRISPR\u2013Cas9 gene editing . But the proceedings, which could drag out for years, have taken an ugly turn from scientific minutiae to accusations of impropriety. \u201cThere seem to be a number of allegations of bad actors and bad faith,\u201d says Jacob Sherkow, a legal scholar at New York Law School in New York City. \u201cIt\u2019s aggressive.\u201d CRISPR patent applicants in Europe are also awaiting key rulings \u2014 some expected at the end of September \u2014 that could decide their fate (see \u2018An international conflict\u2019). \n               boxed-text \n             For some, the rancour is no surprise. \u201cWhen there is a lot of money at stake, people fight over it,\u201d says Robin Feldman, a legal scholar at the University of California Hastings College of the Law in San Francisco. \u201cAnd in a battle over the keys to the kingdom, everything matters.\u201d \n               Eyes on the prize \n             In nature, bacteria and archaea use CRISPR\u2013Cas9 to fend off viruses. But in 2012, a team led by molecular biologist Jennifer Doudna of the University of California, Berkeley, and microbiologist Emmanuelle Charpentier, then of Ume\u00e5 University in Sweden, reported that they had reprogrammed CRISPR\u2013Cas9 to cut isolated DNA at sites of their choosing 1 . Then, in early 2013, several groups \u2014 including one led by synthetic biologist Feng Zhang of the Broad Institute of MIT and Harvard in Cambridge, Massachusetts \u2014 reported that CRISPR\u2013Cas9 also worked in living eukaryotic cells,  including human cells  (see, for instance, ref.  2 ). Thanks to its ease and versatility, CRISPR\u2013Cas9 has been embraced by laboratories around the world to  rewrite genomes and rewire cells . Its potential applications in  medicine, agriculture and research  are myriad. There are more than 860\u00a0CRISPR patent families worldwide, according to the consulting firm IPStudies near Lausanne, Switzerland. A new one is added, on average, each day. Much of the focus is on the teams centred at Berkeley and the Broad Institute, whose \u2018foundational\u2019 patents cover a wide swathe of CRISPR\u2013Cas9 applications. Although Berkeley\u2019s team filed for a patent first, the Broad opted for an expedited review process, and its patents were granted earlier. The Berkeley team then  asked the USPTO to declare a \u2018patent interference\u2019 , launching a complicated process to establish who first came up with the invention. Since January, the two sides have been making their case in filings to USPTO patent judges. The Broad asserts that Berkeley\u2019s initial patent filing described using CRISPR\u2013Cas9 in prokaryotes such as bacteria, but did not sufficiently describe the procedure in eukaryotes such as mice and human cells. That distinction is important: CRISPR\u2019s most lucrative applications are likely to be in medicine, and several biotechnology companies have already licensed patents from either Berkeley or the Broad. Berkeley argues that the application of CRISPR\u2013Cas9 to eukaryotic cells was obvious and that \u201cpersons of ordinary skill\u201d, such as a postdoc with relevant expertise, could have made the leap. Berkeley points to the swift success of several teams \u2014 led by Doudna; Zhang; Church (at Harvard Medical School in Boston, Massachusetts); and genome engineer Jin-Soo Kim at the Institute for Basic Science in Seoul \u2014 that applied CRISPR to human cells. The Broad countered that these scientists are all leaders in their field and could hardly be considered \u2018ordinary\u2019. \n               Risky business \n             Surprising accusations have been interwoven with the scientific arguments. Berkeley has submitted an e-mail from Shuailiang Lin, who was a visiting student in Zhang\u2019s lab in 2011\u201312. Lin claims that the lab took inspiration from Doudna and Charpentier\u2019s paper 1 , rather than working out the system independently. The Broad countered that Lin made this assertion while asking Doudna for a job. Berkeley asked to subpoena Lin (who has since been employed at the University of California, San Francisco), but USPTO judges denied that request on 14\u00a0September. A more complete response from the Broad could come when the two sides file replies to previous motions in late\u00a0September. In the meantime, the Broad petitioned the USPTO judges to ignore testimony from two of Berkeley\u2019s scientific witnesses. The law firm that collected their depositions had previously worked for the Broad, and therefore may have been privy to confidential information, the Broad argued. USPTO judges disagreed. \u201cBroad\u2019s request amounts to merely a fishing expedition,\u201d they wrote on 24\u00a0August. One of the most aggressive and risky moves was Berkeley\u2019s decision to subpoena Church, Sherkow says. Berkeley has submitted e-mails from Church congratulating Doudna and Charpentier on their 2012 paper, acknowledging that it inspired his team to try the system in eukaryotic cells. But Church, who has laboured for years to move a different gene-editing system from bacteria to human cells, told  Nature  in August that such a shift is \u201canything but obvious\u201d. The USPTO denied the subpoena on 14\u00a0September. Church says that he has not spoken to Berkeley\u2019s lawyers, but was surprised by the judges\u2019 ruling. \u201cI imagined my observations would be considered quite relevant,\u201d he says. Overall, the rancour is unusual for two academic institutions, says Mark Summerfield, a patent lawyer at Watermark in Melbourne, Australia. At first, Summerfield rooted for the two sides to settle, as academics usually do. But then he saw the list of companies that had licensed the patents, and were footing many of the legal bills. \u201cWhat is really behind this is not the academic institutions, it is the commercial interests,\u201d he says. \u201cThat\u2019s when I realized that they\u2019re not going to come to an agreement. They\u2019re going to fight it out until the bitter end.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @heidiledford \n               \n                     Chinese scientists to pioneer first human CRISPR trial 2016-Jul-21 \n                   \n                     The unsung heroes of CRISPR 2016-Jul-20 \n                   \n                     First CRISPR clinical trial gets green light from US panel 2016-Jun-22 \n                   \n                     The quiet revolutionary: How the co-discovery of CRISPR explosively changed Emmanuelle Charpentier\u2019s life 2016-Apr-27 \n                   \n                     Nature  special: CRISPR \n                   \n                     USPTO CRISPR interference files \n                   Reprints and Permissions"},
{"file_id": "537593a", "url": "https://www.nature.com/articles/537593a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Construction of the Five-hundred-meter Aperture Spherical Radio Telescope (FAST) is complete, but debugging has only just begun. Set in a remote natural depression in the mountainous region of Guizhou, China, the world\u2019s largest single-dish telescope\u00a0is\u00a0on the brink of sparking a new era in radio astronomy. But scientists also worry\u00a0about the daringly complex structure of the Five-hundred-meter Aperture Spherical Radio Telescope (FAST). \u201cIt will be the instrument of choice for any\u00a0exotic object in its range,\u201d says Matthew Bailes, an astrophysicist at the Swinburne University of Technology in Hawthorn, Australia. But \u201cits design is so radical, we\u2019re\u00a0all\u00a0wondering if it will work.\u201d On 25 September, FAST\u2019s construction was declared officially complete. Some 200 scientists from around the world attended an inauguration ceremony and got their first look at FAST\u2019s preliminary data, which will be used to debug the telescope. That process could take three years or more, says Peng Bo, an astronomer at the National Astronomical Observatories in Beijing and the project\u2019s deputy manager. Then teams from around the world will be able to bid for time to use the telescope, FAST chief scientist Nan Rendong told  Nature.  Many observatories are open to international teams, but astronomers were unsure whether FAST would be. \u201cThis is critical to achieving the best possible science,\u201d says astronomer Jason Hessels at the Netherlands Institute for Radio Astronomy in Amsterdam. FAST has twice the effective collecting area of the Arecibo Observatory in Puerto Rico and will scan twice as much sky (see \u2018Galactic giant\u2019). Size matters because many celestial objects are tough to detect. Spinning stars called pulsars and the cosmic clouds of hydrogen that\u00a0hold clues to the origin of the Universe emit faint signals, whereas  mysterious \u2018fast\u00a0radio bursts\u2019  are transient. A larger -telescope increases the number of signals available, aiding the discovery and characterization of such objects. Pulsars, which send out periodic bursts of radio waves as they spin, are expected to give FAST its first taste of success. Peng thinks the telescope will more than double the current pulsar count of 2,600. FAST might even uncover the first pulsar with a period of under a millisecond, suggests Shri Kulkarni, an astronomer at the California Institute of Technology in Pasadena. Because pulsars are predicted to break up at around this speed, this \u201cwould blow away a number of models of physics of dense matter\u201d, he says. FAST should also detect more \u2018millisecond pulsars\u2019, whose regular periods of 1\u201310 milliseconds mean that they rival atomic clocks as timekeepers, says Kulkarni, who helped discover the first millisecond pulsar using Arecibo. FAST should eventually be able to track them for long enough to  reveal distortions  in their periods caused by gravitational waves, the ripples in space-time whose direct detection was  announced in February . Nan, who is an astronomer at the National Astronomical Observatories in Beijing, says FAST will also be able to detect molecules from outer space that are suggestive of life, and plans to enlist the telescope in the search for extra-terrestrial intelligence (SETI). The giant telescope is also likely to discover something completely unexpected, say astronomers. \n               Behind the curve \n             But FAST\u2019s construction was not easy, and its reliability is not a given. Like Arecibo\u2019s, FAST\u2019s dish curves like a sphere. Such a surface is the simplest and cheapest to build, and means that the dish receives signals from a broad swathe of sky. But unlike steeper \u2018parabolic\u2019 dishes, it does not concentrate the signals at one point, and so there is a loss of focus, causing FAST\u2019s designers to opt for a radical solution. Arecibo has mirrors attached to its dish to correct for the loss of focus, but a similar set-up for FAST would have meant 10,000 tonnes of metal hanging over the dish. Instead, FAST\u2019s surface is made up of some 4,500 panels, some of which can be tilted, raised and lowered by 2,225 actuators to temporarily make it parabolic. But this makes FAST extremely complicated. The 100-metre-wide parabolic  Green Bank Telescope  in West Virginia has about 2,000 moving panels to help it maintain its shape, but these usually shift by only a few centimetres, says astronomer D. J. Pisano at West Virginia University in Morgantown, who has studied hydrogen clouds for 10 years using Green Bank. \u201cFor FAST they will be moving the panels over distances of metres,\u201d he says. \u201cThis is definitely a challenge.\u201d Even Nan is worried that it could be some time before the telescope is ready to do science. \u201cIt\u2019s terrible, terrible, thinking about reliability,\u201d he says. The team has found more than 150 problematic actuators in the months running up to the first testing phase, leading to arguments with the contractors who supplied them. \u201cAnd it\u2019s not just the actuators,\u201d Nan says. \u201cEverything is difficult, everything is risky.\u201d Peng is more sanguine and says of Nan: \u201cI\u2019m too optimistic; he\u2019s too sceptical.\u201d \n               Saga of adventure \n             Nan, who like Peng has been involved in FAST since its inception in the early 1990s, relates its history like a saga. There was the exhausting lecture circuit to drum up support. There was the lobbying for permission to use ultra\u2011high-resolution GPS to find the best site. And there were the old-school construction methods, which were necessary because the surrounding mountains are too steep for heavy machinery. But Nan\u2019s despondency belies his excitement. He wrote a poem for a promotional video, and he speaks of the telescope as an almost sacred endeavour. The rock formation on which it sits is \u201cunique on Earth, I promise you\u201d, he says. And he describes FAST\u2019s potential to find clues to alien life as \u201cthe possible detection of civilization\u201d. \u201cWe\u2019ll see a lot of beautiful things,\u201d he says. \u201cIt\u2019s an adventure.\u201d \n                     Why ultra-powerful radio bursts are the most perplexing mystery in astronomy 2016-Jun-28 \n                   \n                     Fresh confusion over origins of enigmatic radio-wave blasts 2016-Mar-02 \n                   \n                     Arecibo Observatory director quits after funding row 2015-Nov-09 \n                   \n                     US struggles to offload telescopes 2014-Jan-28 \n                   \n                     Pulsar watchers race for gravity waves 2010-Jan-13 \n                   \n                     National Astronomical Observatories, Chinese Academy of Sciences \n                   \n                     Arecibo observatory \n                   \n                     Green Bank Telescope \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20664", "url": "https://www.nature.com/articles/nature.2016.20664", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The latest crop of prize predictions illuminates the century-long struggle to assign credit to individual researchers. If the predictions are to be believed, this could be a rip-roaring Nobel Prize season. Each year, Nobel soothsayers offer preseason prophecies about who will win the awards, which are announced in early October. This year\u2019s crop of predictions is wading into controversial territory. Several have homed in on  CRISPR\u2013Cas9 gene editing  \u2014 a relatively quick and easy method for altering genomes \u2014 as a possible winner. In physics, predictions are coalescing around a team at the Laser Interferometer Gravitational-Wave Observatory (LIGO) that, earlier this year, ended a century-long quest to  detect the gravitational waves  predicted by  Albert Einstein . But bestowing prizes for these discoveries would require the Nobel committees to make difficult \u2014 and unusually speedy \u2014 judgements about who deserves credit. The LIGO collaboration, for example, is more than 1,000 researchers strong. And  battles over who invented CRISPR\u2013Cas9 gene editing  are raging at the US Patent and Trademark Office (USPTO) and elsewhere around the world \u2014 raising questions about whether a Nobel could affect deliberations over patents, or whether the Nobel Committee will wait for the patent dispute to conclude. Regardless of which team the committee chooses, it is safe to say that initial positive press for the winners will be followed by a dose of ice water, as slighted researchers and their colleagues cry foul, says Arturo Casadevall, a microbiologist at the Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland.  \u201cOn the first week of October, the world focuses on science and that\u2019s good,\u201d he says. \u201cBut after that, every single year, there\u2019s a controversy.\u201d \n             Playing favourites \n           Forecasters have been issuing predictions since the first Nobel Prizes were handed out over a century ago, says Nils Hansson, a historian at the Heinrich Heine University of D\u00fcsseldorf, Germany, who has picked through archives of Nobel nominations and deliberations. (That information becomes public after 50 years.) From the start, participants expressed concern about the rule that no more than three scholars could share a prize. Hansson says that In 1901, a German surgeon asked to nominate candidates for the first prize in physiology or medicine protested that science is done in teams, and so it is difficult to pick one person who has made the most important contribution. The annual Nobel predictions by analytics firm Thomson Reuters highlight the challenge. Last year, Thomson Reuters\u2019s data crunchers predicted that the Nobel Prize for Chemistry would go to Jennifer Doudna of the University of California in Berkeley and  Emmanuelle Charpentier , now at the Max Planck Institute for Infection Biology in Berlin, for inventing the CRISPR\u2013Cas9 technique. This year, however, the firm predicted a different CRISPR\u2013Cas9 pairing: Feng Zhang of the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, and George Church of Harvard Medical School across the river in Boston. This time, Thomson Reuters predicted that the award would be for the development of CRISPR\u2013Cas9 gene editing specifically in mouse and human cells. In so doing, Thomson Reuters has crystallized arguments in  an ongoing battle between the Broad and Berkeley  over who owns patent rights to the technology. If one of these teams nabs a Nobel Prize, the winners\u2019 legal team would probably submit the award as evidence in the patent fight before the USPTO \u2014 but the patent judges are likely to disregard it, says Jacob Sherkow, an intellectual-property scholar at New York Law School in New York City. \u201cFuture developments \u2014 like who the scientific community later thinks is the \u2018true\u2019 inventor \u2014 aren\u2019t that important.\u201d \n             Carving up credit \n           Likewise, the Nobel Committee is unlikely to concern itself with the patent brawl \u2014 at least if history is any guide. Hansson says that the committee has consistently tuned out external factors, even in the 1930s when Adolf Hitler forbade German scholars from accepting the award. Instead, the committee busies itself with establishing priority for the discovery, wrestling with the problem of pinpointing one, two or three scholars in a large community. Doing so can take decades. In first half of the 20th century, many researchers were nominated 20 or more times before receiving an award, Hansson says. Pathologist Peyton Rous, for example, won the 1966 Nobel Prize in Physiology or Medicine for discovering tumour-causing viruses in chickens \u2014 half a century after he made the discovery. \u201cAnd even with all of that deliberation, each year will bring the usual disputes over the scholars who were left out,\u201d Hansson says. Last year\u2019s chemistry award to  DNA-repair researchers , for example, generated a stir for omitting several key scientists in the field, including Philip Hanawalt of Stanford University in California. But perhaps the most visible Nobel omission was in 2003, when the Nobel Prize in Physiology or Medicine was awarded for the development of magnetic resonance imaging. Physician Raymond Damadian \u2014 who, Sherkow notes, held a valuable patent on the technique \u2014 did not make the cut. He responded by  taking out full-page advertisements  in newspapers, including  The New York Times  and  The   Washington Post,  proclaiming this slight as \u201cthe shameful wrong that must be righted\u201d. Casadevall has argued that the Nobel Committee could avoid such negativity by awarding fields rather than individuals. The LIGO prediction illustrates his point, he says. \u201cWould it be the people who built the interferometers? Should it be the theoreticians?\u201d he asks. \u201cThis is a human accomplishment that involves enormous numbers of people. Picking three at the most is always going to be unfair and unrepresentative.\u201d For now, Nobel-aspiring scientists would do well to head off potential disputes ahead of time, Nobel prizewinner Richard Roberts of New England Biolabs in Ipswich, Massachusetts, advised last year in a tongue-in-cheek guide to winning the award 1 . \u201cCollaborate with other scientists,\u201d he wrote, \u201cbut never with more than two other people.\u201d \n                   Titanic clash over CRISPR patents turns ugly 2016-Sep-21 \n                 \n                   Einstein's gravitational waves found at last 2016-Feb-11 \n                 \n                   DNA repair sleuths win chemistry Nobel 2015-Oct-07 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   The Nobel Prize \n                 \n                   Thomson Reuters 2016 Nobel Prize predictions \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20679", "url": "https://www.nature.com/articles/nature.2016.20679", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Research reveals an overlooked role for rivers in northern ecosystems. Denver, Colorado In the race to account for how carbon moves through Arctic ecosystems, especially as they warm, scientists may be overlooking one major component: river flood plains. A preliminary study of ten Arctic rivers suggests that they cycle roughly three to seven times more carbon through their flood plains than eventually exits the river into the ocean, says Joel Rowland, a geomorphologist at the Los Alamos National Laboratory in New Mexico. The fate of that flood-plain carbon isn\u2019t known. It may be respired into the atmosphere, or be redeposited on riverbanks farther downstream. Either way, it represents an important chunk of the Arctic carbon budget that researchers do not yet understand, Rowland says. \u201cThere\u2019s a lot of action going on that\u2019s been ignored.\u201d He reported the findings on 25 September at a meeting of the Geological Society of America in Denver, Colorado. Arctic rivers are responsible for  some 10% of the world\u2019s freshwater discharge , and their enormous size and meandering paths mean that many of them have large flood plains. Yet few studies have tackled what river flood plains mean for global carbon cycling, says Katherine Lininger, a geomorphologist at Colorado State University in Fort Collins. Instead, researchers typically view rivers as pipes, funnelling the carbon that enters them upstream all the way to the ocean, practically untouched. Recent estimates suggest that  Arctic rivers carry nearly 6 million metric tonnes of carbon  into the ocean each year 1 . Offshore, that can form an important carbon sink 2 . \n             Shifting soils \n           To see what the carbon might be doing along the way, Rowland and his colleagues analysed aerial images of rivers, including the Lena in Siberia and the Yukon in Alaska. They used software to map changes in the river channels over time, and calculated how that corresponded to erosion on the flood plain \u2014 including how much carbon was released as the river shifted course. It is one of the first attempts to measure how much carbon moves around on river flood plains, Rowland says. Shifting carbon from one point to another can affect its ultimate fate. Imagine that part of the riverbank crumbles away, and the carbon in that soil is washed downstream and then builds up on a fresh bank. Microbes will interact with the newly remobilized carbon differently than if it had remained upstream in the older soil. Lininger has been measuring carbon directly in the flood plain of the Yukon River, floating downstream and taking samples of soil along the way. At the meeting, she reported preliminary estimates that the flood plain contains more carbon than Arctic-soil databases estimate. The work reinforces how much needs to be done to understand carbon in river flood plains, she says. Rowland wants to expand his work to look at rivers globally. Those in warmer latitudes, such as the Amazon, may have entirely different patterns of carbon distribution in their flood plains, he says. \u201cIf you\u2019re not just worried about the carbon coming out the end, but also where it came from,\u201d he says, \u201cthen you need to understand its life history.\u201d \n                   Permafrost science heats up in the United States 2011-Dec-19 \n                 \n                   Observing the scars of the Arctic thaw 2009-Jun-30 \n                 \n                   Arctic water flow speeding up 2006-Apr-06 \n                 \n                   Nature 's Arctic special \n                 \n                   Arctic Great Rivers Observatory \n                 \n                   Northern Circumpolar Soil Carbon Database \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20673", "url": "https://www.nature.com/articles/nature.2016.20673", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Suggests greenhouse gases may warm planet more than previously thought. A global temperature record published on 26 September in  Nature 1  extends 2 million years into the past \u2014 the longest continuous log yet published \u2014 and has sparked debate about how Earth's climate will change in the future. The study harnesses data from dozens of ocean-sediment cores, as well as climate models, to provide estimates of global average surface temperatures. Prior reconstructions have gone back further \u2014 in some cases back to 3 million years \u2014 but were less comprehensive or focused only on particular time periods. The longest comprehensive temperature record available before this study went back 22,000 years. \u201cIt\u2019s a useful starting place,\u201d says lead author Carolyn Snyder, director of the Climate Protection Partnerships Division of the US Environmental Protection Agency in Washington DC. \u201cPeople can take this and improve upon it as more records become available in the future.\u201d Using a subset of the reconstructed temperature data, Snyder, who began the study while at Stanford University in Palo Alto, California, analysed the relationship between past temperatures and carbon dioxide (CO 2 ) levels estimated from Antarctic ice cores covering the past 800,000 years. Based on that analysis, she found that future long-term warming induced by greenhouse gases could be more severe than many previous estimates. Even if the amount of atmospheric CO 2  were to stabilize at current levels, the study suggests that average temperatures may increase by roughly 5 \u00b0C\u00a0over the next few millennia as a result of the effects of the greenhouse gas on glaciers, ecosystems and other factors. A doubling of the pre-industrial levels of atmospheric CO 2  of roughly 280 parts per million, which could occur within decades unless people curb greenhouse-gas emissions, could eventually boost global average temperatures by around 9 \u00b0C. This is on the high end of existing estimates. \n             Proceed with caution \n           And this is where the study has encountered scepticism. \u201cThe key part of this paper is the temperature reconstruction, which is really valuable,\u201d says Eelco Rohling, a palaeoclimatologist\u00a0at the Australian National University in Canberra. But he adds that the question of how the planet will respond to atmospheric CO 2  over the long term requires more detailed analysis.\u00a0 In particular, the study fails to account for subtle changes in Earth\u2019s orbit that affected global temperatures and helped to drive the expansion and retreat of glaciers throughout the time period covered by the analysis,\u00a0says Gavin Schmidt, director of NASA\u2019s Goddard Institute for Space Studies in New York City. He says the effects of such orbital variations must be considered when comparing the glacial era to the present. Schmidt's research into Earth's long-term\u00a0sensitivity to CO 2  has focused on a warmer era before the glacial ages, about 3 million years ago. That work suggests that the millennial-scale warming that would be expected from rising greenhouse gases is around 4.5 \u00b0C for a doubling of pre-industrial atmospheric CO 2  levels 2 . The new analysis has little bearing on the short-term climate sensitivity, which is what humanity might expect to see over the next century or two. The Intergovernmental Panel on Climate Change estimates that short-term climate sensitivity is around 3 \u00b0C of warming for a doubling of atmospheric CO 2 3 .\u00a0 \n             Bare necessities \n           Snyder isn't convinced that the orbital effects are that important in this case. She says her study provides a single measure of the relationship between historic temperatures and CO 2  levels. If that relationship were to hold up, it would suggest that the Earth is in store for even more warming in the future. But she stresses that conclusions about future climate change should be viewed with caution. \u201cThis is not an exact prediction or a forecast,\u201d she says. \u201cThe experiment we as humans are doing is very different than what we saw in the past.\u201d Although Snyder\u2019s temperature record will probably be improved as new data are incorporated in the future, the study fills a crucial gap in the archives of climate science, says Jeremy Shakun, a geologist at Boston College in Chestnut Hill, Massachusetts, who developed the previous temperature record out to 22,000 years. \u201cThis is something that just needed to be done,\u201d Shakun says. As for the debate about long-term climate sensitivity, he says scientists can debate the details, but it\u2019s clear that heat will continue to build up in the Earth system for a very long time. \n                   Paris climate deal: what comes next 2016-Apr-22 \n                 \n                   Climate scientists focus on 1.5 degrees after Paris deal 2016-Apr-15 \n                 \n                   Climate scientists discuss future of their field 2015-Jul-07 \n                 \n                   Climate change: The case of the missing heat 2014-Jan-15 \n                 \n                   The real holes in climate science 2010-Jan-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20662", "url": "https://www.nature.com/articles/nature.2016.20662", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Eight scientists are among the 23 winners. Victoria Orphan, a geobiologist and explorer of marine life on the sea floor, is one of eight scientists to win a \u2018genius grant\u2019 this year from the philanthropic MacArthur Foundation in Chicago, Illinois. The awards, announced on 22 September, consist of US$625,000 grants paid out over 5 years. Creative and inspiring individuals in any field are eligible for the award, and there are no restrictions on how winners spend the money. Orphan, at the California Institute of Technology in Pasadena, investigates how microbes survive in extreme environments such as deep-sea vents, which could mimic conditions capable of supporting life on other planets. Earth\u2019s deep-sea microbes consume the methane that seeps out of sea-floor vents, and thereby reduce the amount of this potent greenhouse gas in the oceans. Other science-related winners of this year\u2019s awards are listed below. Manu Prakash , a physical biologist and inventor at Stanford University in California, works to democratize and promote science and medicine in developing countries. Prakash, 36, who emigrated\u00a0from Rampur, India, promotes what he calls \u2018frugal science\u2019, designing high-tech yet inexpensive science tools such as the  Foldscope , a microscope made almost entirely from paper. Rebecca Richards-Kortum , a bioengineer at Rice University in Houston, Texas, develops  simple and inexpensive diagnostic\u00a0technologies  for use in the developing world \u2014 such as a microendoscope for treating cervical cancer. She also trains others to develop such tools. Dianne Newman , a microbiologist at the California Institute of Technology, studies how bacteria and other microbes  evolved billions of years ago , when Earth\u2019s atmosphere held little or no oxygen. Her research could help researchers to develop treatments that kill harmful bacteria in the lungs of  people with cystic fibrosis . Daryl Baldwin , a linguist at the Miami University of Ohio in Oxford, works to preserve the culture and language of the Miami (Myaamia) nation. The Native American group once made their home in the midwestern United States, but fell into decline after the US government forcibly removed them to other parts of the country in the nineteenth century. Baldwin strives to revive their Algonquian language, and is constructing an online dictionary. Subhash Khot , a theoretical computer scientist at New York University, seeks to  understand the limits of computation . He is known for his contribution to the \u2018unique-games conjecture\u2019, in which he suggested that some problems are so complex that even approximate solutions cannot be found. Bill Thies , a computer scientist at Microsoft Research India in Bangalore, designs communication and digital technologies to improve the health, social and economic well-being of low-income communities in rural India. He has developed a mobile tool for collecting data on childhood malnutrition and a biometric system for delivering tuberculosis medication. Jin-Quan Yu , a synthetic chemist at Scripps Research Institute in La Jolla, California, researches the use of metal-based  catalysts  to help break chemical bonds between carbon and hydrogen atoms to make new organic molecules. Yu\u2019s work could one day help drugmakers to develop new compounds and medications more quickly. \n                   Nanowires, stem-cell transplants and wastewater treatment win 2015 MacArthur \u2018genius grants\u2019 2015-Sep-29 \n                 \n                   Blog post: MacArthur Foundation awards 2013 'genius grants' \n                 \n                   Blog post: Prime numbers, black carbon and nanomaterials win 2014 MacArthur 'genius grants' \n                 \n                   MacArthur Foundation \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20659", "url": "https://www.nature.com/articles/nature.2016.20659", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Numerous failed attempts to replicate the 'blocking effect' cast doubt on its scope. Physiologist Ivan Pavlov conditioned dogs to associate food with the sound of a buzzer, which left them salivating. Decades later, researchers discovered such training appears to block efforts to teach the animals to link other stimuli to the same reward. Dogs trained to expect food when a buzzer sounds can then be conditioned to salivate when they are exposed to the noise and a flash of light simultaneously. But light alone will not cue them to drool. This \u2018blocking effect\u2019 is well-known in psychology, but new research suggests that the concept might not be so simple. Psychologists in Belgium failed to replicate the effect in 15 independent experiments, they report this month in the  Journal of Experimental Psychology 1 . \u201cFor a long time, you tend to think, \u2018It\u2019s me\u2019 \u2014 I\u2019m doing something wrong, or messing up the experiment,\u2019\u201d says lead author Tom Beckers, a psychologist at the Catholic University of Leuven (KU Leuven) in Belgium. But after his student, co-author Elisa Maes, also could not replicate the blocking effect, and the team failed again in experiments in other labs, Beckers realized that \u201cit can\u2019t just be us\u201d. The scientists do not claim that the blocking effect is not real, or that previous observations of it are wrong. Instead, Beckers thinks that psychologists do not yet know enough about the precise conditions under which it applies. \n             Old science, new tricks? \n           The blocking effect underpins the idea that surprising or unexpected experiences drive learning. A dog being trained to associate a sound with the arrival of food will at first find that noise novel \u2014 reinforcing the notion that sound equals kibble. Once that link is made, any attempt to link another stimulus to the delivery of food will seem redundant, and fail. Studies of the brain\u2019s dopamine system seem to confirm this idea: the levels of dopamine \u2014 a chemical that signals pleasure \u2014 surge higher after an unexpected reward than an expected one. But the latest study suggests that the process of learning might be more complicated than scientists had realized. The research is part of a broader push in the social sciences to test the reliability of published results \u2014 an effort that has led some researchers to suggest there is a \u2018 replication crisis \u2019 afoot, because many results that seem solid cannot be reproduced. Last year, for example, a team led by Brian Nosek, a social psychologist who directs the Center for Open Science in Charlottesville, Virginia, sought to replicate the published findings of 98 psychology papers;  61% of their attempts failed  to do so. Nosek says that if the latest findings on the blocking effect are confirmed by further research, that could help scientists to better understand how learning happens. In their experiments, Beckers and his colleagues tested different types of sensory stimuli, ways of delivering food pellets and species of rats and mice. The team also used different researchers to conduct each experiment. In every case, they failed to observe a  statistically significant  blocking effect. \u201cIt\u2019s remarkable that a team of researchers is able to publish so many null results,\u201d says Eric-Jan Wagenmakers, a psychologist at the University of Amsterdam. \u201cThis would have been impossible 10 years ago.\u201c \n             Questions remain \n           Nevertheless, the analysis has limitations. Many of the replication experiments have small samples, with only eight animals. Some also used mice, which don\u2019t react as predictably as rats. Aspects of the experimental design could explain why the team did not observe the blocking effect, says David Shanks, a psychologist at University College London. One way to investigate further, he says, would be to ' pre-register ' a multi-lab project to examine the blocking effect. Pre-registration would require the study's organizers to record their methods, and the outcomes they plan to measure, before they start experiments \u2014 and pledge to publish their results, no matter what they find. This would allow different groups of scientists, including strong proponents of the blocking effect, to run standardized experiments on the phenomenon. \u201cIt\u2019s nice that there\u2019s a replication debate that isn\u2019t about people hurling insults at each other,\u201d says Shanks. \u201cThere\u2019s actually some intellectual substance to it.\u201d \n                   1,500 scientists lift the lid on reproducibility 2016-May-25 \n                 \n                   Psychology\u2019s reproducibility problem is exaggerated \u2013 say psychologists 2016-Mar-03 \n                 \n                   Over half of psychology studies fail reproducibility test 2015-Aug-27 \n                 \n                   Tom Beckers, KU Leuven, Belgium \n                 \n                   Reproducibility Project: Psychology \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20685", "url": "https://www.nature.com/articles/nature.2016.20685", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Watery jets could be tapping into a buried ocean with the potential to support life. The elusive plumes of suspected water vapour shooting out from Jupiter\u2019s moon Europa,  first reported in 2013 1 , have shown themselves again. Astronomers using the Hubble Space Telescope have spotted the jets erupting three more times. Scientists speculate that the plumes could be tapping into an ocean buried beneath kilometres of ice. That would make them a direct conduit to a realm that could support life. Researchers have suggested that future spacecraft would be able to study that ocean by looking at the material splattered across Europa's surface by the plumes. Saturn's moon Enceladus  has similar watery jets . Despite numerous attempts 2 , however, plumes on Europa had not been confirmed until now. \u201cPreviously there\u2019s been just one piece of evidence that these things exist,\u201d says team leader William Sparks, an astronomer at the Space Telescope Science Institute in Baltimore, Maryland. \u201cIf they\u2019re real, they have to be intermittent.\u201d Factors as varied as the time of day or the tidal pull of Jupiter could cause the plumes to appear and disappear. Sparks and his colleagues watched Europa pass across the face of Jupiter 10 times while looking for signs of ultraviolet emissions from the moon\u2019s atmosphere. Of those 10 passages, three \u2014 in January, March and April 2014 \u2014 showed hints of plumes. Most of them are clustered around Europa\u2019s southern hemisphere, the scientists report  in a paper to appear on 29 September in the  Astrophysical Journal . \n             Plume watch \n           Lorenz Roth, who led the team that made the 2013 report, which also used data collected by Hubble, says the newly reported jets do not seem to be in the same location as the previous sighting. \u201cUnless something appears very close to the south pole, it can hardly be the same plume,\u201d says Roth, at the Royal Institute of Technology in Stockholm. He also notes that, in order for Sparks's team to observe these plumes against Jupiter's face, the material in them would have to be extremely dense. That means there is a lot of water in these jets, which begs the question, why has no one seen these before the 2013 report, he says. Sparks and his colleagues have observed two additional passes of Europa across the face of Jupiter since their 2014 observations, but have not finished analysing that data to see if they also captured plumes. \u201cWe are working at the limits of Hubble\u2019s unique capabilities,\u201d he says. Future missions that might spy the plumes up close are  the European Space Agency\u2019s JUICE mission , slated for launch in 2022, and  a possible NASA spacecraft  to Europa to launch in roughly the same time frame. \n                   Icy Enceladus hides a watery ocean 2014-Apr-03 \n                 \n                   Hubble spots water spurting from Europa 2013-Dec-12 \n                 \n                   Europe plans mission to Jupiter 2012-May-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20696", "url": "https://www.nature.com/articles/nature.2016.20696", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Internet giant's latest service employs neural networks to cut error rate by 60%, the company says. Google's online translation service, Google Translate, will soon be using a new algorithm that is entirely based on  deep learning , the company  announced  on 27 September. The algorithm, which is also described in a paper posted to the preprint server arXiv 1 , is the first widely-available computer system for translating languages that relies on the increasingly popular AI technique. Compared to the firm's existing service, the algorithm reduces errors by around 60%, Google computer scientists say. A Chinese-to-English service that uses the algorithm is now being used on the Google Translate mobile and web-based apps, and Google says that it will roll out other languages over the next few months. The advance is yet another example of the success of deep learning, which has helped crack major AI problems in recent years by combining artificial neural networks \u2014 layers of computational units that mimic the way neurons connect in the brain \u2014 with enormous data sets. Most notably, the technique has beaten other machine approaches to  image recognition  and  game-playing . Google has now applied the same approach to language translation, to create what it calls a Neural Machine Translation system (NMTS). \u201cFrom the input to the output, it\u2019s entirely done by one neural network,\u201d says Quoc Le, a computer scientist at Google in Mountain View, California, who helped to develop the NMTS. The NMTS borrows from others\u2019 advances in machine learning and adds a few methodological novelties, says Yoshua Bengio, a computer scientist at the University of Montreal in Canada who has read the arXiv paper. \u201cOn a first look, it appears that they have pulled most of the known tricks,\u201d he says. The team\u2019s main achievement is to show that \u201dwith solid engineering and a well-designed architecture, neural-machine translation can far outpace classical methods for machine translation\u201d, he says, with \u201cpretty amazing results\u201d. The algorithm \"really improves the state-of-the-art in many ways\u201d, says J\u00fcrgen Schmidhuber, a computer scientist at the University of Lugano (also known as the USI) in Manno, Switzerland. \n             Machine translation \n           Until now, Google Translate\u2019s use of artificial neural networks has been limited, says Charina Choi, a company spokesperson. For the most part, its algorithms analysed text word by word, learning to associate corresponding words in different languages by scouring millions of existing translations, such as in documents from the United Nations or the European Parliament. The NMTS also learns by analysing existing translations; as it does so, it tweaks connections between artificial neurons in a way that will improve its performance. But it analyses sentences by first breaking up each word into \u2018word segments\u2019, an idea that came from team member Mike Schuster, also at Google in Mountain View, who had employed it in speech-recognition software. \u201cSomehow, in some representation inside the neural network, the segments can combine to represent meaning,\u201d says Le. This could be similar to the way that neural networks perform visual tasks such as face recognition: they start from the individual pixels in an image and work up through increasingly complex features such as edges, geometric patterns and so on. The same neural network that analysed the text then produces a translation. To improve speed, the company runs the system on computer chips that it designed specifically for machine learning. AlphaGo, the program that  beat a top human player at the game of Go  earlier this year, used similar hardware. \n             Performance verdict \n           To evaluate the translation system\u2019s performance, the Google researchers took sentences from Wikipedia and from news articles and put NMTS-made translations (between a handful of different language pairs) side by side with corresponding ones made by the company\u2019s old system and by human translators. The team then had human evaluators score the quality of the translations in a blind test. Chinese-to-English translation, which is notoriously difficult, showed marked improvements, but still lagged compared to the algorithm's translations among Indo-European languages. For some other language pairs, the accuracy of the NMTS approached that of human translators, although the authors caution that the significance of the test was limited by its sample of well-crafted, simple sentences. Schmidhuber thinks that machines will only be able to truly match or beat humans at translation once they are able to combine different sensory inputs. \u201cToday, they only see sentences such as \u2018the cat fell from the tree\u2019,\u201d Schmidhuber says. \u201cIn the future, they will also see videos of cats falling from trees, and they will control robots that can see, hear, move and manipulate objects, and feel pain through pain sensors, and relate their experiences to texts.\u201d \n                   Artificial intelligence called in to tackle LHC data deluge 2015-Dec-01 \n                 \n                   Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 \n                   Nature Special: The Go Files \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20680", "url": "https://www.nature.com/articles/nature.2016.20680", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Airlines would be required to offset most of their greenhouse-gas emissions after 2020 under the latest plan. Governments will begin final negotiations this week on a plan to curb carbon emissions from international aircraft flights beginning in 2020. The proposal, which will be debated at a meeting of the United Nations\u2019 International Civil Aviation Organization (ICAO) in Montreal, Canada, would direct most airlines to invest in carbon \u201coffsets\u201d that reduce emissions in other carbon-producing industries. At least 58\u00a0countries, which account for more than 80% of international aviation emissions, have said they would participate in a voluntary phase that would begin in 2021 and last six years; the requirements would become mandatory in 2027. \u201cThis is a solid first step, but it\u2019s not a done deal,\u201d says Annie Petsonk, international counsel for the Environmental Defense Fund, an advocacy group based in New York City. Aviation accounts for 2% of global carbon emissions, with more than half of that contributed by international flights. Initial estimates suggest that the proposed agreement would cover as much as 70% of the projected growth in emissions from 2021 to 2035, depending on how many countries ultimately join the voluntary phase. This would result in roughly 2 billion tonnes of carbon dioxide offsets over 15 years, which would be valued at roughly US$10 billion at today\u2019s carbon prices, according to the International Council on Clean Transportation (ICCT), a research-based advocacy organization based in Washington DC. In total, the offsets would be equivalent to roughly five years of carbon emissions from the United Kingdom. \n             A global first \n           Although disputes over details could arise during the talks, which run from 27 September to 7 October, most observers say the general outline of the draft agreement is unlikely to change substantially. The proposal almost certainly falls short of the ICAO\u2019s stated goal of carbon-neutral growth in international aviation beyond 2020. The agency adopted that target when it launched deliberations three years ago, but questions of fairness led to exemptions for many developing countries, where the aviation industry is just beginning to take off. Whereas environmentalists are pushing to make the agreement more stringent, industry officials say full coverage is too much to ask. \u201cRather than complaining that this isn\u2019t 100% perfect from anybody\u2019s point of view, I think we should be marvelling at what is going to be achieved,\u201d says Nancy Young, vice-president for environmental affairs at Airlines For America, a trade group based in Washington DC. Young notes that this would be the first global agreement to curb emissions from a specific industry. The agreement would build on  a CO 2  emissions standard for new aircraft  that the ICAO advanced in February. That standard could cut fuel consumption at cruising speed by an estimated 4% compared with 2015 levels, and is due to come into full effect in 2028. But environmentalists blasted the standard as wholly inadequate. An analysis by the ICCT suggested that market forces could  drive substantially more gains in fuel efficiency  than are required by the CO 2  standard. ICAO estimates that more-efficient aircraft and operations could offset nearly half of the growth in international-aviation emissions, which could rise by 300\u2013400% over the next 25 years. Advanced biofuels, which are just beginning to be deployed, could also contribute an as-yet-unknown share of emissions reductions. The offset mechanism under discussion this week was initially conceived as a way of closing the remaining gap and ensuring carbon-neutral growth. But emissions will continue to rise unless more countries participate, says Daniel Rutherford, the ICCT\u2019s chief representative in the ICAO process. Fortunately, some countries that could be excluded under the mandatory phase are opting in anyway, Rutherford says. \u201cIt\u2019s good news, but we still have a ways to go.\u201d \n                   UN agency proposes greenhouse-gas standard for aircraft 2016-Feb-09 \n                 \n                   Paris climate deal hinges on better carbon accountancy 2016-Jan-26 \n                 \n                   Talks in the city of light generate more heat 2015-Dec-21 \n                 \n                   Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                 Reprints and Permissions"},
{"file_id": "537291a", "url": "https://www.nature.com/articles/537291a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Long-term tracking of people who beat the virus reveal its remarkable longevity in the human body. Ebola survivors are teaching scientists some surprising lessons. Long-term studies have revealed that the virus lasts longer in survivors\u2019 bodies than previously suspected. The findings, presented on 12\u00a0September at an Ebola-virus conference in Antwerp, Belgium, underscore the need for extended tracking of people who have beaten Ebola and other rare infections. Researchers have long known that the virus can persist in people who have recovered from the infection. But the size of the  West African outbreak , coupled with improved monitoring technologies, is changing how scientists view life after Ebola \u2014 and  how to prevent future outbreaks . \u201cNow that you have tens of thousands of survivors and systemic approaches to follow them, you can detect things that happen more rarely and attribute them to Ebola,\u201d says physician and epidemiologist Daniel Bausch of the World Health Organization in Geneva, Switzerland. Researchers will soon publish the first confirmed report of a person without obvious Ebola symptoms infecting another person. A seemingly healthy mother in Guinea passed the virus to her nine-month-old daughter in breast milk, and the child died from Ebola-virus infection in August 2015, according to a European Union-funded team led by Sophie Duraffour from the Bernhard Nocht Institute for Tropical Medicine in Hamburg, Germany. A study due to be presented at the Antwerp meeting also suggests that some people who became infected during the recent outbreak escaped detection. Miles Carroll, an epi \u00ad demiologist at Public Health England in Porton Down, and his colleagues tracked 80\u00a0people who had contact with Ebola patients in Guinea but did not themselves become noticeably ill. Yet 15\u201320% of these contacts developed immune responses capable of neutralizing Ebola viruses, suggesting that they had contracted mild infections that went undetected. This \u2018sub-symptomatic\u2019 or \u2018asymptomatic\u2019 Ebola was known to exist, but the latest studies involve more people who have been studied more intensively than in the past. Researchers caution, however, that it is still rare for Ebola lingering in a person\u2019s body to spark new outbreaks. The phenomenon would probably have escaped notice if the recent epidemic had been smaller. Thousands of men who are infected have survived, but until recently scientists did not know that the Ebola virus could be transmitted in semen beyond three months, says Mary Choi, an epidemiologist at the US\u00a0Centers for Disease Control and Prevention. The agency and the Liberian government are running the largest-ever investigation of Ebola viruses in the semen of survivors. So far, the team\u2019s study of 466\u00a0men has detected virus fragments in semen up to 18\u00a0months after a man has recovered from his infection 1 . In February, two months after the outbreak was declared over in Guinea, Duraffour and her colleagues traced a cluster of new Ebola cases to a man who transmitted the virus to a sexual partner 17\u00a0months after recovering from his infection 2 . Yet another study, which examined 26\u00a0male Ebola survivors, found that the vast majorityeliminated the virus from their semen within 4\u00a0months of recovery 3 . The precise timing varied widely from person to person, however. Choi says that the virus probably lasts for longer than 18 months in semen. Her team will continue to monitor the virus\u2019s persistence, while counselling survivors to use condoms or abstain from sex until their semen tests negative twice. \u201cThe primary takeaway is that semen testing should be incorporated earlier on as part of services that survivors receive,\u201d Choi says. Researchers must show sensitivity in communicating such findings, says virologist Stephan G\u00fcnther of the Bernhard Nocht Institute, and take care not to make life more difficult than it already is for Ebola survivors, who  face discrimination  and  lingering health problems . \u201cWe have to be careful to stress that these are very, very rare events.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Erika_Check \n               \n                     Ebola survivor\u2019s blood holds promise of new treatment 2016-Feb-25 \n                   \n                     How Ebola-vaccine success could reshape clinical-trial policy 2015-Aug-04 \n                   \n                     Ebola teaches tough lessons about rapid research 2015-May-27 \n                   \n                     Ebola\u2019s mental-health wounds linger in Africa 2015-Mar-03 \n                   \n                     Nature  special: Ebola \n                   \n                     Ebola, 40 years after Yambuku conference \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20670", "url": "https://www.nature.com/articles/nature.2016.20670", "year": 2016, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Research struggles in a country in economic free-fall. Following years of chronic funding shortages and political neglect, the Zimbabwe Academy of Science (ZAS) is on its knees and has made a plea for support from the large Zimbabwean diaspora. The academy has historically survived on donations and membership fees, but this is no longer sustainable, said ZAS head Christopher Mutambirwa at a meeting of Zimbabwean expatriates in Johannesburg, South Africa, on 14 September. According to Mutambirwa, who is a former environmental scientist at the University of Zimbabwe in Harare, the academy has fewer than 100 fellows, and the country's economic distress means that fewer than 15 members now even pay their fees. The aim of the meeting \u2014 initiated by the Academy of Science of South Africa and which included ZAS members and Zimbabwean academics in South Africa \u2014 was to find ways to support Zimbabwean research. Among the most drastic solutions proposed were to move the ZAS's headquarters (currently in the Tropical Resources Ecology Centre at the University of Zimbabwe) to Pretoria, South Africa\u2019s capital, or to make the academy a 'virtual' entity \u2014 without a permanent office or administrative staff. The ZAS has already had to let go its sole full-time employee. \n               Economic woes \n             Zimbabwe has a strong agriculture sector, with tobacco and cotton among its main exports. Traditionally, much of the country's research has come from ties between the country's universities and the agriculture industry. The economy took a negative turn after 2000, when the government of President Robert Mugabe \u2014 who has been in power since 1987 and is now 92 \u2014 fast-tracked a programme of land expropriations and agricultural productivity plummeted. The resulting economic and political turmoil, with a long-term decline in gross domestic product and bouts of hyperinflation, has caused millions to leave the country. Many have crossed the border into neighbouring South Africa, including some scientists. \u201cWithout enough money around, it\u2019s made a number of people leave,\u201d says Christopher Chetsanga, a biochemist who heads the country\u2019s Council for Higher Education and was president of the ZAS at its founding in 2004. There are no official figures on the flight of skilled Zimbabweans, or on how many researchers remain in the country; according to  a UNESCO report , a government survey in 2012 found that about 1,300 researchers were there at that time. \n               Funding down \n             Still, Zimbabwe has consistently produced between 300 and 400 peer-reviewed papers a year, and the ZAS is one of the few institutions in the country that have consistently advocated for science. Both Chetsanga and Mutambirwa said that the ZAS had pleaded with government to recognize the academy through an act of parliament, which would then put it on the government\u2019s payroll and ringfence funding. But according to the Zimbabwean parliament\u2019s website, there is no ZAS bill on the roll, and the current economic crisis means that the government is unlikely to allocate money to an academy of science when it cannot meet its own debt-repayment deadlines with international funding agencies. The academics  Nature  spoke to cited lack of funding for research and equipment as their biggest challenge. The majority of research funding comes from the government, which is then disbursed via the country\u2019s 17 universities, the Medical Research Council of Zimbabwe and the Research Council of Zimbabwe. The latter focuses on social sciences and humanities; sustainable environment and resource management; public health; and national security. It saw its funding decline from US$556,907 in 2013 to $499,769 in 2014, the most recent year for which figures are available. \n               Brain drain \n             Because of the country\u2019s politically fractious relations with North American and European countries, international funding and collaboration have declined. The country has been subject to international sanctions since 2002, over alleged electoral fraud and human-rights violations. \u201cWe don\u2019t have many friends as a country,\u201d Dexter Tagwireyi, a toxicologist at the University of Zimbabwe and head of the Zimbabwe Young Academy of Science, said at the Johannesburg meeting. \u201cOpportunities like competitive grants, you don\u2019t even see Zimbabwe on the list.\u201d Researchers also struggle with the same endemic problems as other Zimbabweans: chronic water and electricity outages and telecommunications difficulties. At the moment, the ZAS's activities are voluntary and unpaid. A number of solutions to the dire straits that the ZAS and Zimbabwean research in general are in were proposed \u2014 such as promoting ZAS membership, collaboration and co-supervision among the diaspora, and basing the academy online or in South Africa \u2014 but some were more palatable than others. A virtual organization would not solve the issue of funding, they said. Numerous Zimbabwean academics reject the idea of a Pretoria-based ZAS. Sociologist Rudo Gaidzanwa at the University of Zimbabwe says that this move would be regressive and would \u201csend the wrong signal\u201d. \u201cOur futures are tied to the future of our country,\u201d she says. \u201cUntil our situation improves economically, we\u2019re going to haemorrhage academics.\u201d \n                     South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                   \n                     Africa\u2019s elite 2016-Mar-16 \n                   \n                     Research: Africa's fight for equality 2015-May-05 \n                   \n                     Nature News Special: Africa \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20591", "url": "https://www.nature.com/articles/nature.2016.20591", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "First results from Gaia probe also seem to solve old controversy over Pleiades cluster. The European Space Agency (ESA) has released the largest, most detailed map yet of the Milky Way. It pinpoints the 3D positions of 1.1 billion stars, almost 400 million of which were previously unknown to science. ESA\u2019s Gaia space observatory mapped out the catalogue. The results are expected to  transform what astronomers know about the Galaxy  \u2014 allowing researchers to discover new extrasolar planets, examine the distribution of dark matter and fine-tune models of how stars evolve. Hundreds of astronomers began to access the  database  as soon as it was made publicly available on 14 September, says Gaia project scientist Timo Prusti, who works at ESA\u2019s European Space Research and Technology Centre in Noordwijk, the Netherlands. \u201cMy advice to the astronomical community is: please enjoy with us,\u201d he said at a press conference in Madrid. Within 24 hours, more than 11,000 users had accessed the catalogue, ESA said, and independent teams have begun to post papers based on Gaia data on the preprint repository arXiv. Gaia has already found more stars than researchers expected, which suggests that the Milky Way is slightly bigger than previously estimated, says Gisella Clementini, a Gaia researcher at the Bologna Astronomical Observatory in Italy. But few new results were announced at the catalogue\u2019s unveiling, because Gaia\u2019s team was allowed to do only limited analyses before the data release \u2014 unusual for space observatories, whose mission scientists often have up to a year\u2019s exclusive use of their data before sharing them with the world. One notable result, however, is a measurement of the distance of the Pleiades 1 , a cluster of stars in the constellation Taurus that has been the subject of  a long-running controversy . Whereas numerous measurements put the Pleiades cluster at a distance of about 135 parsecs (440 light years) from the Sun, Gaia\u2019s predecessor, ESA\u2019s Hipparcos mission, found it to be about 15 parsecs closer. Gaia measured 134 parsecs, give or take 6 parsecs \u2014 suggesting that the Hipparcos findings were inaccurate. Anthony Brown, an astronomer at the Leiden Observatory in the Netherlands who chairs Gaia\u2019s data-processing collaboration, stresses that the results are preliminary and that they could change once Gaia collects more data. (Ultimately, Gaia should be the first mission able to measure the distances of individual stars in the cluster, rather than an average.) But there\u2019s scant possibility that Gaia\u2019s results will be corrected so much that they agree with the Hipparcos results, thinks David Soderblom, an astronomer at the Space Telescope Science Institute in Baltimore, Maryland. \u201cIt\u2019s not impossible but it sure isn\u2019t very likely at this point,\u201d he says. \u201cThat, to me, is basically the answer.\u201d Soderblom expects that the trouble with the Hipparcos measurement may have been in corrections made to account for the unusual brightness of stars in the cluster. Gaia launched in late 2013 and  started its scientific mission  in July 2014. The spacecraft cost \u20ac450 million (US$500 million), but the mission\u2019s total cost, including the expense of operations and running data centres, is close to \u20ac1 billion. The preliminary catalogue released today is based on Gaia\u2019s first 14 months of data-taking. Gaia does not take still exposures as ordinary telescope cameras do: instead, it constantly spins on its axis, making a full revolution every six hours and tracking the streaks that stars leave along its 1-gigapixel detector. By comparing scans of the sky taken six months apart, researchers are able to triangulate and measure stars\u2019 distances using the parallax effect, a technique that dates back to ancient Greece. In the first release of Gaia's catalogue, more than two million stars have been labelled both with measurements of their distances from the Sun and their motion, obtained by comparing Gaia data with those from Hipparcos. In future releases, the catalogue will grow to include the distances and velocities of more than one billion stars. With more years of observation, Gaia\u2019s measurements will become so accurate that the distances of many of the Galaxy\u2019s stars will be pinpointed to within 1%. \u201cWhat Gaia is going to do is going to be phenomenal,\u201d says Wendy Freedman, an astronomer at the University of Chicago in Illinois. \u201cIt will be the fundamental go-to place for astronomers for decades to come.\u201d\n \n                     Milky Way mapper: 6 ways the Gaia spacecraft will change astronomy 2016-Sep-09 \n                   \n                     Siren call 2016-Mar-23 \n                   \n                     Row reignites over distance of Pleiades star cluster 2014-Aug-28 \n                   \n                     Astrometry: Europe's star power 2013-Oct-02 \n                   Reprints and Permissions"},
{"file_id": "537289a", "url": "https://www.nature.com/articles/537289a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Panel rocked by investigations into surgeon \u2014 but its credibility stays intact. In an unprecedented move, the group that selects the winners of the Nobel Prize in Physiology or Medicine \u2014 the Nobel Assembly \u2014 has asked two of its members to resign following a scandal at the institute that supplies the assembly\u2019s members. But scientists around the world don\u2019t see the events at the Karolinska Institute (KI) in Stockholm as a threat to the reputation of the medical prize. They say that the assembly is sufficiently separate to the KI and has handled the affair well so far. \u201cEverything is exploding now, but the long-term credibility won\u2019t be affected,\u201d says cancer researcher Julio Celis, associate scientific director of the Danish Cancer Society Research Center in Copenhagen. The scandal involves the surgeon Paolo Macchiarini. Multiple inquiries have alleged that he committed scientific misconduct and subjected patients to unethical, experimental tracheal transplant operations, three of which occurred at the affiliated Karolinska University Hospital. Two of the patients have since died, and the third has required continuous hospital care since the transplant. In June, Swedish public prosecutors opened investigations following preliminary charges against Macchiarini of involuntary manslaughter and causing grievous bodily harm. Macchiarini has denied the allegations. On 5\u00a0September, an  independent report that revealed  institutional problems at the KI mentioned Nobel Assembly members Harriet Wallberg-Henriksson and Anders Hamsten \u2014 both former KI vice-chancellors \u2014 for their roles in hiring Macchiarini in 2010 and subsequently extending his contracts. ( Hamsten resigned as vice-chancellor  in February after acknowledging that he had misjudged Macchiarini; the KI  dismissed Macchiarini in March .) The call for Wallberg-Henriksson and Hamsten to resign came a day after the report and is a first for the 115-year-old panel, says neuroscientist Thomas Perlmann, secretary of the Nobel Committee, whose fixed-term members are elected from the more permanent assembly. \u201cThe professionalism of some of the faculty at the Karolinska Institute has been called into question, and this won\u2019t go away,\u201d says Erwin Neher of the Max Planck Institute for Biophysical Chemistry in G\u00f6ttingen, Germany, who won the medicine prize in 1991. \u201cBut I don\u2019t think this discredits the Nobel prize \u2014 they are two different things.\u201d When Alfred Nobel died in 1896, he left the bulk of his fortune \u2014 amassed from his explosives businesses \u2014 to the Nobel prizes. His will specified which institutions would select each prize, and declared the KI in charge of medicine. The first prizes were awarded in 1901. At first, the entire KI faculty selected the medicine winners, but by the 1970s it had grown too large for this to be practical \u2014 and a new law made all documents at state institutions accessible to the public, ruling out secret deliberations. So in 1977, the Nobel Assembly was created, comprising 50\u00a0KI professors; the Nobel Foundation pays for its operations. The Nobel Committee has also done a good job of separating itself from the Macchiarini affair since it began, says neuroscientist Eero Castr\u00e9n at the University of Helsinki. KI geneticist Urban Lendahl, who participated in the decision to hire Macchiarini,  resigned his position as secretary-general  of the Nobel Committee in February, notes Castr\u00e9n. (Lendahl stepped down because he anticipated that he would be involved in the investigation.) Two other assembly members \u2014 clinical immunologist Katarina Le Blanc, who co-authored a paper with Macchiarini that is under investigation by the Central Ethical Review Board, and Hans-Gustaf Ljunggren, who was dean of research at the KI from 2013 until February \u2014 have not been asked to resign because there is still \u201cuncertainty over their roles\u201d in the Macchiarini affair, says Perlmann. \u201cTo protect the brand\u201d, he adds, none of the three, nor Wallberg-Henriksson, nor Hamsten, has participated in assembly activities since February. Perlmann says that the Nobel Committee is not taking further action, but will monitor perceptions of the prize to see whether it needs to do more. \u201cIt is important that institutions deal in a fair way with those whose judgement or moral probity has been called into question,\u201d says Steven Hyman, director of the Stanley Center for Psychiatric Research at the Broad Institute in Boston, Massachusetts, who has nominated prize candidates to the Nobel Committee. \u201cThe Nobel Assembly seems to be doing this.\u201d He adds: \u201cThere is no benefit to the world, or to patients who have been harmed, by using a very serious incident to undercut a globally important institute.\u201d The assembly has survived other challenges, usually relating to complaints about its choices. In 1994, it encountered accusations \u2014 quickly discredited \u2014 that it had allowed a  drug company to buy the 1986 medicine prize  for Italian neuroscientist  Rita Levi-Montalcini . Just as the Swedish king never comments on politics, the Nobel Assembly never comments on such complaints. But during its 100th anniversary celebrations, it acknowledged some regrets \u2014 such as awarding a share of the 1923 prize for the discovery of insulin to John Macleod, whose role is now questioned, and the failure to recognize Oswald Avery, who identified DNA as the genetic material in the 1940s. \u201cThe prize has survived many things,\u201d says cell biologist M\u00e5ns Ehrenberg of Uppsala University, who has served on the committee that selects the Nobel Prize in Chemistry. \u201cThe standard of evaluation no one can criticize.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Macchiarini scandal is a valuable lesson for the Karolinska Institute 2016-Sep-06 \n                   \n                     Culture of silence and nonchalance protected disgraced trachea surgeon (updated) 2016-Sep-02 \n                   \n                     Prestigious Karolinska Institute dismisses controversial trachea surgeon 2016-Mar-23 \n                   \n                     Karolinska\u2019s vice-chancellor resigns over case of controversial surgeon 2016-Feb-15 \n                   \n                     Benefactors of mankind 2001-Oct-11 \n                   Reprints and Permissions"},
{"file_id": "537287a", "url": "https://www.nature.com/articles/537287a", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Adl\u00e8ne Hicheur\u2019s ejection from Brazil to France remains unexplained. At around lunchtime on 15\u00a0July, police removed particle physicist Adl\u00e8ne Hicheur from his home in Rio de Janeiro and escorted him to the airport. That evening, they commanded him to board a flight to Paris, accompanied by three Brazilian police officers. From there, he was transported to his parents\u2019 home in the small southeastern town of Vienne and placed under house arrest. He must report to police three times a day and cannot leave home between 8:00 p.m. and 6:00 a.m.. Two months later, the reasons for Hicheur\u2019s sudden deportation remain a mystery. In 2012, a French court  convicted him  of plotting with al-Qaeda\u2019s North African branch to carry out terror attacks on military and economic targets on French soil. Hicheur and his supporters, including scientific colleagues, maintain his innocence and say his trial was a  miscarriage of justice . Brazilian authorities had discussed his past with scientists before allowing the physicist to come to work in Brazil in 2013. Once back in France, Hicheur was placed under house arrest using state-of-emergency powers introduced following a spate of terrorism attacks; officials there say that he still constitutes a security threat. His colleagues, with the backing of several institutions, are ramping up their pleas to Brazilian authorities to explain the reasons for the deportation. They are concerned that it violated Brazilian law and breached Hicheur\u2019s human rights. Neither Hicheur nor his institution, the Federal University of Rio de Janeiro (UFRJ), has been given a justification for his deportation, UFRJ colleagues say, and Hicheur had no chance to contest its legality. \u201cHis deportation without any explanation is something that makes me feel ashamed for my country,\u201d says Ron Shellard, director of the Brazilian Center for Physics Research (CBPF) in Rio de Janeiro. \u201cIf there is no objective reason for this extreme act, the Brazilian government should revoke the act of deportation and request the French authorities to send him back to Rio.\u201d At the airport, Hicheur repeatedly requested that he be sent to Algeria (the nationality on his Brazilian work visa) or anywhere other than France, fearing that he would be confined under the state-of-emergency laws, says Ignacio Bediaga, a physicist at the CBPF. Bediaga and three UFRJ officials had rushed to the airport and remained with Hicheur until his flight took off. \u201cIn my opinion, Dr Hicheur was illegally extradited, at the request of the French government,\u201d Bediaga says. Collaborators at CERN, Europe\u2019s particle-physics laboratory near Geneva, Switzerland, and at other European laboratories, have also expressed solidarity with Hicheur. And an international  group of researchers has written  to French President Fran\u00e7ois Hollande, asking him to intervene to lift the physicist\u2019s house arrest \u2014 but has received no reply. Neither French nor Brazilian authorities had responded to  Nature \u2019s requests for comment by the time this article went to press. Hicheur says his latest problems began in January, when the Brazilian magazine  Epoca  splashed his French conviction on its front page under the headline \u201cA terrorist in Brazil\u201d. A deluge of media coverage followed. \u201cI was an invited professor at the UFRJ with a smooth, peaceful life, until the craziness reached me again,\u201d Hicheur says. After Hicheur\u2019s deportation, the justice ministry issued a  brief statement  saying little more than that the decision was based on a recommendation by the federal police, and that Hicheur\u2019s presence was an \u201cinconvenience to the national interest\u201d.  In an interview  with the newspaper  Folha de S.Paulo , justice minister Alexandre de Moraes said Hicheur had not communicated with terrorist groups, or committed any crime while in Brazil. But he said he felt it was \u201cabsurd\u201d to allow someone who had been convicted of terrorism-related offences to live and work in the country. \u201cFurthermore, he is a nuclear physicist, who, in a laboratory, has all the material at hand,\u201d he added \u2014 apparently unaware that Hicheur studies the physics of fundamental particles. But Shellard says that he discussed Hicheur\u2019s past with Brazil\u2019s foreign office when he and others invited the physicist to Rio in 2013. Because Hicheur had served his prison term in France, and had recommendations from leading scientists, officials had no problem with his coming to Brazil. Concern over the case is growing. On 1\u00a0September, researchers at the UFRJ\u2019s Laboratory of Elementary Particles petitioned Brazil\u2019s justice, science and education ministries to release Hicheur.  The petition  has now been signed by more than 300 people: mostly Brazilian physicists, but also a large contingent of researchers from European institutes. And on 5\u00a0September, a general assembly of the particle-physics section of the Brazilian Society of Physics \u2014 held at the society\u2019s annual meeting in Natal \u2014 agreed unanimously to send a letter to de Moraes, expressing concern that the society\u2019s board still hasn\u2019t received an explanation for the deportation, two months after it was first requested. Bediaga and other researchers are convinced that repressive measures in the run-up to Rio\u2019s Olympic games, combined with media coverage of Hicheur\u2019s earlier conviction, were linked to the decision to deport the physicist. Nadine Borges, a lawyer and human-rights expert at the UFRJ, says that she is taking up Hicheur\u2019s case in a personal capacity. In France, Hicheur\u2019s lawyers filed in July to have his house arrest lifted, but the request was quickly rejected by a Grenoble tribunal. Hicheur says he now will appeal to a higher court. See Editorial  page 279 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DeclanButlerNat \n               \n                     French standoff raises fears for incarcerated physicist 2012-Mar-22 \n                   \n                     The case of Dr Hicheur 2011-Oct-12 \n                   \n                     Physicist languishes in French prison 2011-Oct-07 \n                   \n                     Physicists protest colleague's terrorism detention 2010-Nov-08 \n                   \n                     Particle physicist 'falsely accused', claims brother 2009-Oct-13 \n                   \n                     Physicist working at CERN arrested 2009-Oct-09 \n                   \n                     Blog post: French physicist jailed for 5 years on dubious intent-of-terrorism charges \n                   \n                     Petition in support of Adl\u00e8ne Hicheur launched his lab colleagues \n                   \n                     Adl\u00e8ne Hicheur International Support Committee \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20588", "url": "https://www.nature.com/articles/nature.2016.20588", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Country joins top emitters United States and China in joining the agreement this month. Brazil, one of the world's leading greenhouse-gas emitters, ratified the  Paris climate pact  on 12 September, adding to growing momentum to bring the 2015 agreement into force before the end of this year. The agreement had received a significant boost earlier this month when the United States and China \u2014 by far the world's leading emitters \u2014 formally joined on 3 September. The Paris deal seeks to hold warming  \u2018well below\u2019 2\u00b0C above pre-industrial temperatures . For it to take effect, 55 countries accounting for 55% of global emissions must ratify or otherwise formally join the accord. Countries can ratify, accept or approve the deal, depending on their domestic processes. So far, 28 countries representing 41.5% of global emissions have joined up, and no one knows precisely what combination of countries might push the agreement over the threshold. At least 58 countries have committed to join by the end of the year, but many of those are island states and other small emitters, says Eliza Northrop, who is tracking the process for the World Resources Institute, an environmental think tank in Washington DC. So the question is how quickly some of the other major emitters will come through, including India, Japan, South Korea, Mexico and Canada.\u201cIt\u2019s a bit of a puzzle at this point, but I feel very confident that it will enter into force this year,\u201d says Northrop.Less clear is whether the agreement will take effect before the next round of climate negotiations in Marrakech, Morocco, in November. For that to happen, other major emitters would need to ratify the Paris pact by 7 October, because it only enters into force 30 days after the \u201855/55\u2019 threshold has been met.One of the biggest challenges comes from the European Union, where each country must go through its own legislative procedures before the negotiating bloc can sign off as a whole. But there is little doubt that the Paris agreement will take effect in record time. By comparison, the Paris deal\u2019s predecessor, the 1997  Kyoto Protocol , didn't enter into force for more than seven years after it was adopted. Read a previous Trend Watch: ' Most cities too hot to host 2088 summer Olympics ' \n                   Paris climate deal: what comes next 2016-Apr-22 \n                 \n                   Climate scientists focus on 1.5 degrees after Paris deal 2016-Apr-15 \n                 \n                   Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                 \n                   Nature  special: Paris climate talks \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20611", "url": "https://www.nature.com/articles/nature.2016.20611", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Tiangong 2 will develop expertise for a future space station and conduct science experiments. China has launched Tiangong 2, its second orbiting space lab \u2014 marking another stepping stone towards the country\u2019s goal of building a space station by the early 2020s. The module, which launched aboard a Long March rocket from the Jiuquan Satellite Launch Center in the Gobi desert at 22:04 local time on 15 September, will initially fly uncrewed in low-Earth orbit, but a planned second launch will carry two astronauts to it in November. Tiangong 2 (meaning \u2018heavenly palace\u2019) carries a number of scientific experiments, including an astrophysics detector that is the first space-science experiment built jointly by China with European countries. \u201cBy itself, Tiangong 2 is not a monumental achievement, but it is an important step in a larger effort to eventually build a Chinese space station in the early 2020s,\u201d says Brian Weeden, a space-policy expert at the Secure World Foundation in Washington DC. The 8-tonne module replaces the now-defunct Tiangong 1, a mission that  marked several milestones  in China\u2019s manned space programme, including the country\u2019s first in-orbit rendezvous with another spacecraft. Mission control lost contact with that station earlier this year, and its orbit is slowly decaying. An uncontrolled re-entry is  expected some time in 2017 . In November, a Shenzhou spacecraft will carry two astronauts to Tiangong-2 for a 30-day stay. Then in April 2017, a cargo craft will dock to refuel and bring more supplies. The module also carries a robotic arm, a prototype for a similar tool that would fly on a space station. \n             Science projects \n           Tiangong 2 reportedly carries 14 experiments. These include POLAR, an international mission dedicated to establishing whether the photons from \u03b3-ray bursts (GRBs) \u2014 thought to be a particularly energetic type of stellar explosion \u2014 are polarized. Answering this long-debated issue could shed light on how GRBs produce such high-energy photons in the first place. \u201cWe aim to measure ten \u03b3-ray bursts per year,\u201d says POLAR project manager Nicolas Produit, an astrophysicist at the University of Geneva in Switzerland, who spoke to  Nature  from a hotel near the Jiuquan launch centre. The \u20ac3-million (US$3.4 million) detector was built largely with Swiss funding, and with the collaboration of Swiss, Chinese and Polish scientists, and support from the European Space Agency (ESA). POLAR is the first space experiment developed as a full international collaboration between China and other countries, Produit says. US law bars NASA from doing joint projects with China\u2019s space agencies, but the Chinese Academy of Sciences is discussing a number of other  space collaborations with ESA . The country has also been aggressively ramping up its space science: just in the last year, it put into orbit  DAMPE, its first space probe dedicated to the search for dark matter,  as well as  QUESS, the world\u2019s first quantum-communications satellite . This is making the country an exciting place for international researchers to test ideas for space science, compared to projects run by ESA and NASA, which Produit says are slower-moving. \u201cIn China, things go fast. They have the money; they have the will,\u201c Produit says. \u201cChina is where things happen now.\u201d Still, the main goal for Tiangong 2 and a future space station is not science, Weeden points out. \u201cChina wants to build and operate a space station for the same reasons the United States and Soviet Union did in decades past: prestige.\u201d \n                   Chinese satellite is one giant step for the quantum internet 2016-Jul-27 \n                 \n                   Science stars of China 2016-Jun-20 \n                 \n                   China\u2019s quantum space pioneer: We need to explore the unknown 2016-Jan-13 \n                 \n                   China\u2019s dark-matter satellite launches era of space science 2015-Dec-17 \n                 \n                   China and Europe pore over proposals for joint space mission 2015-Mar-19 \n                 \n                   POLAR \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20590", "url": "https://www.nature.com/articles/nature.2016.20590", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Sea-ice retreat is affecting every one of the endangered species\u2019 refuges. Not a single polar-bear haven in the rapidly warming Arctic is safe from the effects of climate change, researchers have found. Polar bears ( Ursus maritimus)  rely on sea ice for roaming, breeding, and as a platform from which to hunt seals. When the ice melts in the summer, the bears spend several months on land, largely fasting, until the freeze-up allows them to resume hunting. So if they are to survive, they need pockets of ice to persist almost year-round. Some climate models suggest that most of the Arctic may be ice-free in summer by mid-century 1 . But  icy refuges  near the North Pole currently support 19 populations of polar bears, totalling some 25,000 individuals. Scientists weren\u2019t sure about the exact rate of ice retreat in these habitats, or whether some refuges might not yet be dwindling. All of the Arctic refuges are in fact on the decline, a detailed examination of satellite data now suggests. Mathematician Harry Stern and biologist Kristin Laidre at the University of Washington in Seattle used a 35-year satellite record to examine each of the 19 population areas, which range from 53,000 to 281,000 square kilometres in size. For each, they calculated the dates on which sea ice retreated in the Arctic spring and advanced in the autumn, as well as the average summer sea-ice concentration and number of ice-covered days. In all the refuges, the researchers found a trend towards sea-ice retreating earlier in spring and advancing later in autumn. The time span between the sea-ice maximum in March and the sea-ice minimum in September has lengthened by up to nine weeks since 1979 when satellite observations began, they report in  The Cryosphere 2 . \n             Under strain \n           The measurements show that polar bear habitats are all being put under strain, the researchers say. \u201cThe spring ice break-up and fall ice advance roughly bound the duration of time polar bears have to feed, find mates and breed,\u201d Laidre says. Dwindling ice conditions have been previously shown to  affect polar bears\u2019 abundance and health : for example, polar bear metabolism doesn\u2019t seem to slow much when sea ice melts and food becomes scarce, suggesting that the bears don\u2019t have a way to conserve energy to survive summer fasts 3 . Five Arctic range nations \u2014 the United States, Canada, Greenland, Norway and Russia \u2014 in 2015 adopted a ten-year circumpolar action plan on polar-bear conservation. Using common measurements of habitat change for all polar-bear refuges will guide that plan\u2019s implementation and help to coordinate national conservation efforts, says Dag Vongraven of the Norwegian Polar Research Institute in Troms\u00f8, who co-chairs the polar-bear specialist group of the International Union for Conservation of Nature. \n                   Polar bear metabolism cannot cope with ice loss 2015-Jul-16 \n                 \n                   Polar bears could survive on persisting ice 2010-Dec-15 \n                 \n                   International Union for Conservation of Nature \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20622", "url": "https://www.nature.com/articles/nature.2016.20622", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "DNA from extinct species forces rethink of elephants\u2019 family tree. The genome of a mysterious ancient fossil has shaken up the elephant family tree. Modern elephants are classified into three species: the Asian elephant ( Elephas maximus ) and two African elephants \u2014 the forest-dwellers ( Loxodonta cyclotis ) and those that live in the savannah ( Loxodonta africana ). The division of the African elephants, originally considered a single species, was confirmed  only in 2010 . Scientists had assumed from fossil evidence that an ancient predecessor called the straight-tusked elephant ( Paleoloxodon antiquus ), which lived in European forests until around 100,000 years ago, was a close relative of Asian elephants. In fact, this ancient species is most closely related to African forest elephants, a genetic analysis now reveals. Even more surprising, living forest elephants in the Congo Basin are closer kin to the extinct species than they are to today\u2019s African savannah-dwellers. And, together with newly announced genomes from ancient mammoths, the analysis also reveals that many different elephant and mammoth species interbred in the past. \u201cIt\u2019s mind blowing,\u201d says Tom Gilbert, an evolutionary geneticist at the Natural History Museum of Denmark in Copenhagen. The straight-tusked elephant is little-known even among experts, he says. \u201cAnd the first thing we hear about it is: here\u2019s the genome.\u201d Love Dal\u00e9n, a palaeogeneticist at the Swedish Museum of Natural History in Stockholm, says that the study will force a reshuffle of the elephant family tree. \u201cBasically  Loxodonta  is not valid as a genus name,\u201d he says. He thinks that taxonomists may need to come up with new names for the different species, to better represent the relationship between savannah, forest and straight-tusked elephants. The results were announced at the 7th International Symposium on Biomolecular Archaeology meeting in Oxford, UK, on 15 September. A team led by evolutionary geneticist Eleftheria Palkopoulou and population geneticist David Reich, both at Harvard Medical School in Boston, Massachusetts, together with evolutionary geneticist Michael Hofreiter at the University of Potsdam in Germany, conducted the study. It was based on the genomes of two 120,000-year-old straight-tusked elephant samples from Germany. \n             Ancient interbreeding \n           Palkopoulou and her colleagues also revealed the genomes of other animals, including four woolly mammoths ( Mammuthus primigenius ) and, for the first time, the whole-genome sequences of a Columbian mammoth ( Mammuthus columbi ) from North America and two North American mastodons ( Mammut americanum ). The researchers found evidence that many of the different elephant and mammoth species had interbred. Straight-tusked elephants mated with both Asian elephants and woolly mammoths. And African savannah and forest elephants, who are known to interbreed today \u2014 hybrids of the two species live in some parts of the Democratic Republic of Congo and elsewhere \u2014 also seem to have interbred in the distant past. Palkopoulou hopes to work out when these interbreeding episodes happened. The study represents a landmark in ancient genomics, scientists at the meeting say. The straight-tusked elephants aren\u2019t the oldest ancient genomes \u2014 that record belongs to  the genome from a horse bone, between 560,000 and 780,000 years old, found frozen in the Canadian Arctic  \u2014 but they do represent the oldest whole genomes from a warm environment. The fact that one of the straight-tusked elephant genomes was of such high quality \u2014 with each DNA letter sequenced on average 15 times \u2014 left many scientists awestruck. \"These things are the realm of palaeontology,\u201d says Gilbert. \u201cIt\u2019s a sign of where we are today.\u201d \u201cNo one had dared to think about sequencing straight-tusked elephants before,\u201d says Dal\u00e9n. \u201cIt\u2019s just insane to go that far back in time.\u201d \n                   DNA reveals that giraffes are four species \u2014 not one 2016-Sep-08 \n                 \n                   Ancient genomes suggest dual origin for modern dogs 2016-Jun-02 \n                 \n                   Linnaeus's Asian elephant was wrong species 2013-Nov-04 \n                 \n                   African elephants are two distinct species 2010-Dec-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20606", "url": "https://www.nature.com/articles/nature.2016.20606", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Long-awaited plan would exempt computer-aided harvesting from EU copyright law. The European Commission has  announced  long-awaited plans to make it easier for researchers to harvest facts and data from research papers \u2014 by freeing the computer-aided activity from the shackles of copyright law. Software can rapidly analyse millions of online articles and data sets at speeds humans can\u2019t match, an activity known as  text and data mining (TDM) . Scientists hope that this could reveal patterns in scientific knowledge and generate new hypotheses. But the field has been hampered by uncertainties about the legality of sifting through science publishers\u2019 content to crunch the data. In the European Union, this sort of activity requires the permission of a paper\u2019s copyright holder. To crawl across paywalled content, would-be miners have had to go through the  laborious process  of asking various publishers for approval. And publishers have sometimes refused to allow TDM (apparently out of fear that paywalled content might be freely redistributed), or have only permitted it with restrictions, controlled licenses or fees. A 2014  report  for the European Commission suggested that Europe\u2019s researchers were doing less computer crawling than those in the United States and Asia. As part of copyright-reform proposals  announced on 14 September , the Commission suggests exempting TDM from copyright \u2014 but only for research organizations \u201cacting in the public interest\u201d, such as universities and research centres, and only for content that they already have legal access to read. It would cover both commercial and non-commercial research. But the exception will not apply to commercial firms, which would still need to negotiate rights with publishers and other content providers. \u201cWe must remove barriers that prevent scientists from digging deeper into the existing knowledge base. This proposed copyright exception will give researchers the freedom to pursue their work without fear of legal repercussions,\u201d said Carlos Moedas, head of research at the European Commission, in a press statement. \n             Uncertainty lifted \n           If adopted, the proposals \u2014 which would need to be approved by the European Parliament and the council that represents the European Union member states \u2014 would lift many of the uncertainties over an academic\u2019s right to text mine. Even if university libraries sign a contract with publishers that runs contrary to the exemption, this would be \u201cunenforceable\u201d, the proposals say. One of the leading campaigners for the exemption \u2014 the Association of European Research Libraries in the Hague, the Netherlands \u2014 calls the proposals a \u201c hugely important step \u201d towards addressing legal confusions. However, Susan Reilly, the organization\u2019s executive director, notes that it\u2019s disappointing that start-up firms won\u2019t be able to take advantage. According to the proposed directive, publishers would have the right to take \u201creasonable measures\u201d to ensure the security and integrity of their databases, and where their content is stored. This suggests that publishers and research organizations may need to reach agreement on how text miners access and compute copyrighted content \u2013 even if academics no longer have to ask for legal permission to do it. This is an issue, says Reilly. \"No one wants to bring down servers.\" But she says that publisher's electronic platforms are sufficiently robust to handle the extra load caused by content mining, and that libraries are ready to help discuss what reasonable access measures might be. \n                   Legal confusion threatens to slow data science 2016-Aug-03 \n                 \n                   Text-mining block prompts online response 2015-Nov-20 \n                 \n                   Tensions grow as data-mining discussions fall apart 2013-Jun-04 \n                 \n                   Text-mining spat heats up 2013-Mar-20 \n                 \n                   Trouble at the text mine 2012-Mar-07 \n                 \n                   Literature mining: Speed reading 2010-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20616", "url": "https://www.nature.com/articles/nature.2016.20616", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Investigators are now required to disclose all clinical trials, whether successful or not. The disappointing results of clinical trials will no longer be able to languish unpublished, thanks to rules released on 16 September by the US Department of Health and Human Services (HHS) and the US National Institutes of Health (NIH). The long-awaited changes to the HHS clinical-trial disclosure laws requires, for the first time, that researchers report the design and results of all clinical trials and empowers the government to enforce penalties for those that do not comply. The NIH rules apply only to work done through agency grants, and include stricter reporting requirements for phase I trials. If institutions don\u2019t follow the rules, the NIH could withdraw their funding. \u201cI think a lot of major universities just miss the point that if you do an experiment on a person and get consent, you really have the obligation to make the results known,\u201d says Robert Califf, head of the US Food and Drug Administration (FDA). \u201cThis is fundamentally an ethical issue.\u201d Both sets of rules are intended to crack down on the  large number of clinical trials that are conducted but never reported . They go into effect on 18 January, and researchers will have 90 days to comply. \n             Ambiguity \n           Under a 2007 law, researchers conducting trials with human subjects had to register their study with an HHS website called ClinicalTrials.gov before they started their work. The site, which has more than 225,000 entries, is the largest such repository in the world. At the time, researchers had to include information about their methods and results, but there were  so many exceptions and loopholes  \u2014 such as trials that obtained FDA approval for their therapies could register after the fact \u2014 the law was hard to enforce. That ambiguity allowed researchers to avoid reporting all their trials, particularly those that returned negative results. A 2014 analysis found that 4 years after 400 randomly selected trials finished, 30% of them hadn't published their results 1 . Most trials that fail in the early stages are never published at all, says Christopher Gill, a health researcher at Boston University in Massachusetts. This can bias the literature and obscure important information on whether an experimental therapy is harmful. \u201cFrom the perspective of consumers and science, failures are as important as successes,\u201d Gill says.        \n             A new day \n           Under the new rule, trials must be registered on ClinicalTrials.gov within 21 days of enrolling their first patient \u2014 researchers can no longer wait for the results of their trails to report their data. \u201cThat\u2019s a huge breakthrough,\u201d says Kay Dickersin, director of the Center for Clinical Trials and Evidence Synthesis at Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland. The NIH\u2019s companion rule includes a requirement that NIH-funded researchers register phase I trials: these typically include small numbers of healthy volunteers and test a therapy\u2019s safety instead of its efficacy. They also include trials that do not involve a FDA-regulated product, such as behavioural interventions. Other changes include requirements that scientists report details on how they plan to conduct their trials, outline the statistics they will use to analyse the results and reveal any changes that they make to the protocol over the course of the study. This should help to address a problem known as \u2018 p -hacking\u2019, in which researchers analyse their data in multiple ways and report only the method that returns positive results. Researchers will also now be required to report the race and ethnicity of participants. The final HHS rules will give regulators a greater ability to enforce existing regulations, because many studies of drugs that are eventually licensed are still not reported, says bioethicist Jennifer Miller of New York University\u2019s Langone Medical Center. Her analysis of all drugs sponsored by large pharma companies, and approved by the FDA in 2012, showed that almost half had undergone phase II or III trials that were never reported 2 . \u201cYou need a clear law so you can have clear compliance,\u201d she says, and expects that the new rule will go a long way towards achieving this. \u201cI\u2019m really happy about a whole lot of things made clear now almost 10 years after [the FDAAA],\u201d Dickersin says. \u201cWe had to wait a while but this is great.\u201d \n                   Science academies blast US government\u2019s planned research-ethics reforms 2016-Jun-29 \n                 \n                   Academics fall short in reporting results of clinical trials 2016-Feb-22 \n                 \n                   Clinical-trial rules to improve access to results 2014-Nov-25 \n                 \n                   Half of US clinical trials go unpublished 2013-Dec-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20610", "url": "https://www.nature.com/articles/nature.2016.20610", "year": 2016, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "Spacecraft could help scientists track logging, natural disasters and illegal mining. \n             Update:\u00a0The rocket carrying Per\u00faSAT-1 lifted off successfully from Kourou, French Guiana, at 01:43 UTC on 16 September (22:43 local time on 15 September), launch operator Arianespace has announced. \n           Peru is poised to launch its first Earth-observation satellite on 15 September. Called Per\u00faSAT-1, it will give the small South American country one of the sharpest space-based cameras available. Researchers are eager to use the Peru probe\u2019s images to study  forest health  and  monitor natural disasters , among other things. The satellite could help officials to  discover illegal gold mines ,  roads used for logging  and other incursions into Peru's forests, says Matt Finer, a researcher at the Amazon Conservation Association in Washington DC. Per\u00faSAT-1 will collect visible light, and will deliver images in which the pixels are as small as 70 centimetres on one side \u2014 a bit larger than a standard chess board. \u201cThe resolution is definitely world-class,\u201d Finer says. \u201cIt\u2019s going to be a powerful tool for the government.\u201d Peru is a relative newcomer to space. Its National Commission for Aerospace Research and Development (CONIDA) has launched a CubeSat and a handful of other nanosatellites built by university researchers; the success of Per\u00faSAT-1 would represent a major advance. \n             Desire for data \n           Peru\u2019s decision in 2014 to spend around US$200 million on its own state-of-the-art satellite raised eyebrows, given the availability of detailed satellite images and the developing country\u2019s lack of experience operating spacecraft. NASA\u2019s  Landsat satellites  deliver images of every point on Earth at a resolution of 30 metres per pixel up to every eight days, and the first of the European Space Agency\u2019s  Sentinel-2 satellites  is beaming down images at resolutions of up to 10 metres. Private companies including Planet, DigitalGlobe and Terra Bella (owned by Google) take and sell images at a resolution of up to 40 centimetres per pixel. But some in Peru\u2019s government would prefer that the country doesn't rely solely on satellites owned by foreign governments and companies, says Brian Zutta Salazar, a remote-sensing scientist at the Peruvian Ministry of the Environment in Lima. \u201cIn Peru, there\u2019s definitely a desire to generate your own data.\u201d Per\u00faSAT-1 will follow a Sun-synchronous orbit 695 kilometres above Earth, meaning that it will pass over a given place at the same time each day. This orbit, common for Earth-observation satellites, minimizes changes in lighting that could complicate comparisons between successive images. The satellite will provide a new image of a given position as often as every three days, although clouds and other factors could sometimes lengthen that. \n             Access questions \n           In addition to monitoring forests and tracking the aftermath of natural disasters, officials expect the satellite to aid efforts to improve border security and crack down on drug trafficking. CONIDA scientists and engineers will download and work with data at a new facility in Lima. Processing images from collection to distribution is not easy, however, and Peru\u2019s government will be playing catch-up with NASA, the US Geological Survey and other groups who have been handling large volumes of satellite data for many years, notes Matthew Hansen, a remote-sensing scientist at the University of Maryland in College Park. CONIDA has also not yet said publicly who will have access to the data, how quickly and at what cost \u2014 decisions that Salazar thinks the agency is probably still working out. Still, Per\u00faSAT-1 will catapult Peru into the lead among South American countries when it comes to Earth observation. (Brazil has launched a series of lower-resolution satellites, and Chile launched one in 2011 with a resolution of up to 1.45 metres per pixel.) Salazar predicts that the Per\u00faSAT-1 data will find a ready audience in government, non-governmental organizations and academia. \u201cOnce it gets going, then a lot of people will really understand the usefulness,\u201d he says. \n                   Peru\u2019s gold rush prompts public-health emergency 2016-Jun-01 \n                 \n                   Satellites: Make Earth observations open access 2014-Sep-02 \n                 \n                   Earth observation enters next phase 2014-Apr-08 \n                 \n                   Landsat 8 to the rescue 2013-Feb-06 \n                 \n                   Peru National Commission for Aerospace Research and Development (CONIDA) \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20620", "url": "https://www.nature.com/articles/nature.2016.20620", "year": 2016, "authors": [{"name": "Nicola Nosengo"}], "parsed_as_year": "2006_or_before", "body": "Alleged theft from Italian gene bank dismissed \u2014 but ownership of samples remains under investigation. News that public prosecutors were investigating a potential heist in a gene bank in Sardinia made a media splash earlier this week. A technician at the facility had reported thousands of vials of human DNA missing. But the sensational story soon collapsed: the vials were located at a hospital in Cagliari, Sardinia\u2019s largest city, where they had been moved by scientists about three years earlier. Case closed? Not quite: the investigation continues, because the theft-that-wasn\u2019t has revived confusion about who actually owns the DNA samples and their associated data. \u00a0 The alleged crime scene was Parco Genos, a biomedical facility in the small town of Perdasdefogu in the eastern Sardinian province of Ogliastra. It stores DNA samples from almost 13,000 residents of ten surrounding towns,  collected since 2000 as part of a research project  part-funded by Italy\u2019s National Research Council (CNR). The inhabitants of this island region are exceptionally long-lived \u2014 as with Okinawa island in Japan and Ikaria in Greece, the area is a longevity hotspot. And within each town, people's DNA is not very genetically diverse, because they have lived in relative isolation for centuries. Scientists hope that by matching people's DNA with their medical history and genealogy, they can discover genes that confer protection from ageing and disease. \n             Stray samples \n           In mid-August, a technician at Parco Genos contacted the public prosecutor of the nearby town of Lanusei and told him that an automatic alert on her mobile phone had flagged a temperature anomaly in one of the facility\u2019s fridges, when no-one was supposed to be there. After checking, she told the prosecutor that three refrigerated drawers had been emptied. \u201cWe found that the drawers were indeed empty, but we could not confirm how many samples they contained before. We estimated that about 14,000 were missing,\u201d says prosecutor Biagio Mazzeo, who immediately opened an investigation. There was no sign of a break-in, and the lab has no security cameras. News of the investigation reached local papers, and was quickly picked up by national and overseas media. Researchers \u2014 and Mazzeo himself \u2014 were perplexed. At the time the investigation reached the media, Mazzeo told  Nature  that it was difficult to imagine who could have benefited from stealing the vials, which have no value without accompanying health and genealogical data about the donors. Those data are not stored at Parco Genos, notes Mario Pirastu, a researcher at the CNR\u2019s Institute of Genetic and Biomedical Research in Sassari who has led the project since the early 2000s. He says they are held at the Sassari institute and in a lab owned by the research company Shardna Life Science, in the southern town of Pula. Then came the answer: Pirastu contacted investigators on 14 September and says he realized that the samples were in fact part of a larger batch of 25,000 vials stored at the eye clinic of the San Giovanni di Dio hospital in Cagliari. They had been there for about three years, he says, and were moved by Pirastu himself, who is using them for a research project. CNR scientists have often moved samples for research purposes, he says. \"I can\u2019t imagine why the technician at Parco Genos would think of reporting the vials stolen.\u201d Representatives of Parco Genos did not return  Nature \u2019s request for comments. \n             Identity crisis \n           Although it\u2019s clear that there was no theft, the investigation continues, says Mazzeo \u2014 and Parco Genos and Shardna, as well as the refrigerators in Cagliari, will remain sealed off for \u201ca few more days\u201d. It has emerged that because of the project\u2019s complicated history, he says, it is not clear who owns the samples and the data and who can use them. Parco Genos \u2014 originally a non-profit firm owned by local municipalities \u2014 is now owned by dentist and medical-equipment entrepreneur Piergiorgio Lorrai. And Shardna, originally a joint venture between the CNR and a wealthy Sardinian entrepreneur, is now owned by a private biotech firm in London, called Tiziana Life Sciences. \u201cIt\u2019s a delicate situation,\u201d says Mazzeo. \u201cSamples were originally collected by a public institution, but now a foreign private business has acquired rights to them. Is donors\u2019 consent still valid? The Italian law is not so clear.\" He says that the Italian Data Protection Authority is looking into the situation. Lorrai was recently quoted by Italian newspapers as saying that rights to the samples should not be sold to a private business without donors\u2019 consent. (Tiziana declined  Nature\u2019 s request for comment). Pirastu\u2019s view is that \u201cthe samples belong to the citizens, while the rights to use them once belonged to Shardna, and now to Tiziana Life Sciences. But CNR has always had privileged access to the data and will continue to have, and this guarantees that research is done in the public interest.\u201d CNR researchers, Pirastu notes, have used data from the gene bank to contribute to many research papers over the years, mostly as contributors to international consortia. Pirastu now fears that the investigation could delay the reboot of the project. The collection of samples stalled years ago as a consequence of the financial troubles, and the existing samples haven\u2019t yet all been sequenced. Activities at Parco Genos have now halted almost to the point that the technician who started the investigation is its only employee. Pirastu had hoped that fresh investments from Tiziana Life Sciences would allow activities to resume soon. But Mazzeo says that Tiziana may now have to contact all the donors and have them sign new consent forms. \u201cI think that the goal of the denunciation was not really to report a theft, but to put a spotlight on a very complicated situation,\u201d he says. \u201cAnd in a way, it worked.\" \n                   Scientists hope to attract millions to 'DNA.LAND' 2015-Oct-09 \n                 \n                   Genetic privacy needs a more nuanced approach 2013-Feb-06 \n                 \n                   Genetic privacy needs a more nuanced approach 2013-Feb-06 \n                 \n                   Vatican bids for Italian institute 2011-Oct-18 \n                 Reprints and Permissions"},
{"file_id": "537462a", "url": "https://www.nature.com/articles/537462a", "year": 2016, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Two-thousand-year-old bones could yield first DNA from an ancient shipwreck victim. Antikythera, Greece Hannes Schroeder snaps on two pairs of blue latex gloves, then wipes his hands with a solution of bleach. In front of him is a large Tupperware box full of plastic bags that each contain sea water and a piece of red-stained bone. He lifts one out and inspects its contents as several archaeologists hover behind, waiting for his verdict. They\u2019re hoping he can pull off a feat never attempted before\u00a0\u2014\u00a0DNA analysis on someone who has been under the sea for 2,000 years. Through the window, sunlight sparkles on cobalt water. The researchers are on the tiny Greek island of Antikythera, a 10-minute boat ride from the wreckage of a 2,000-year-old merchant ship. Discovered by sponge divers in 1900, the wreck was the first ever investigated by archaeologists. Its most famous bounty to date has been a  surprisingly sophisticated clockwork device  that modelled the motions of the Sun, Moon and planets in the sky\u00a0\u2014\u00a0dubbed 1  the  \u2018Antikythera mechanism\u2019 . But on 31\u00a0August this year, investigators made another groundbreaking discovery: a human skeleton, buried under around half a metre of pottery sherds and sand. \u201cWe\u2019re thrilled,\u201d says Brendan Foley, an underwater archaeologist at Woods Hole Oceanographic Institution in Massachusetts, and co-director of the excavations team. \u201cWe don\u2019t know of anything else like it.\u201d Within days of the find, Foley invited Schroeder, an expert in ancient-DNA analysis from the Natural History Museum of Denmark in Copenhagen, to assess whether genetic material might be extracted from the bones. On his way to Antikythera, Schroeder was doubtful. But as he removes the bones from their bags he is pleasantly surprised. The material is a little chalky, but overall looks well preserved. \u201cIt doesn\u2019t look like bone that\u2019s 2,000 years old,\u201d he says. Then, sifting through several large pieces of skull, he finds both petrous bones\u00a0\u2014\u00a0dense nuggets behind the ear that preserve DNA better than other parts of the skeleton or the teeth. \u201cIt\u2019s amazing you guys found that,\u201d Schroeder says. \u201cIf there\u2019s any DNA, then from what we know, it\u2019ll be there.\u201d Schroeder agrees to go ahead with DNA extraction when permission is granted by the Greek authorities. It would take about a week to find out whether the sample contains any DNA, he says: then perhaps a couple of months to sequence it and analyse the results. For Schroeder, the discovery gives him the chance to push the boundaries of  ancient-DNA studies . So far, most have been conducted on samples from cold climates such as northern Europe. \u201cI\u2019ve been trying to push the application of ancient DNA into environments where people don\u2019t usually look for DNA,\u201d he says. (He was part of a team that last year published the first Mediterranean ancient genome, of a Neolithic individual from Spain 2 .) Foley and the archaeologists, meanwhile, are elated by the chance to learn more about the people on board the first-century  bc  ship, which carried luxury items from the eastern Mediterranean, probably intended for wealthy buyers in Rome. \n               Rare discovery \n             The skeleton discovery is a rare find, agrees Mark Dunkley, an underwater archaeologist from the London-based heritage organization Historic England. Unless covered by sediment or otherwise protected, the bodies of shipwreck victims are usually swept away and decay, or are eaten by fish. Complete skeletons have been recovered from younger ships, such as the sixteenth-century English warship the  Mary Rose  and the seventeenth-century  Vasa  in Sweden. Both sank in mud, close to port. But \u201cthe farther you go back, the rarer it is\u201d, says Dunkley. Only a handful of examples of human remains have been found on ancient wrecks, says archaeologist Dimitris Kourkoumelis of the Greek Ephorate of Underwater Antiquities, who collaborates with Foley. They include a skull found inside a Roman soldier\u2019s helmet near Sardinia, and a skeleton reportedly discovered inside a sunken sarcophagus near the Greek island of Syrna (although the bones disappeared before the find could be confirmed). In fact, the best-documented example is the Antikythera wreck itself: scattered bones were found by the French marine explorer Jacques Cousteau, who excavated here in 1976. Argyro Nafplioti, an osteoarchaeologist at the University of Cambridge, UK, concluded that the remains came from at least four individuals, including a young man, a woman and a teenager of unknown sex 3 . At the wreck site, only broken pots now remain on the sea floor \u2014 the sponge divers recovered all artefacts visible on the seabed in 1900\u201301. But Foley thinks that much of the ship\u2019s cargo may be buried under the sediment. His team, including expert technical divers and members of the Greek archaeological service, relocated and mapped the 50-metre-deep site before beginning their own excavations in 2014. They have found items such as wine jars, glassware, two  bronze spears from statues , gold jewellery and table jugs used by the crew (see \u2018Ancient bounty\u2019). The divers have also recovered ship components including enormous anchors and a teardrop-shaped lead weight, found in June, that may be the first known example of what ancient texts describe as a \u2018war dolphin\u2019\u00a0\u2014\u00a0a defensive weapon carried by merchant vessels to smash hostile ships. The skeleton uncovered in August consists of a partial skull with three teeth, two arm bones, several rib pieces and two femurs, all apparently from the same person. Foley\u2019s team plans further excavations to see whether more bones are still under the sand. That so many individuals have been found at Antikythera\u00a0\u2014\u00a0when most wrecks yield none \u2014 may be partly because few other wrecks have been as exhaustively investigated. But the researchers think it also reveals something about how the ship sank. This was a huge vessel for its time, perhaps more than 40 metres long, says Foley, with multiple decks and many people on board. The wreck is close to shore, at the foot of the island\u2019s steep cliffs. He concludes that a storm smashed the ship against the rocks so that it broke up and sank before people had a chance to react. \u201cWe think it was such a violent wrecking event, people got trapped below decks.\u201d \n               Mediterranean mystery \n             The individuals found at Antikythera could be from the crew, which would probably have consisted of 15\u201320 people on a ship this size. Greek and Roman merchant ships also commonly carried passengers, and sometimes slaves. One reason people get trapped inside shipwrecks is if they are chained, points out Dunkley. \u201cThe crew would be able to get off relatively fast. Those shackled would have no opportunity to escape.\u201d Intriguingly, the recently discovered bones were surrounded by corroded iron objects, so far unidentified; the iron oxide has stained the bones amber red. Schroeder says that because ancient underwater remains are so rare, DNA analysis on such samples using state-of-the-art techniques has barely been tried. (Analyses were conducted on skeletons from the  Mary Rose  and the  Vasa , but specialists no longer see those methods\u00a0\u2014\u00a0based on amplifying DNA using a method called PCR\u00a0\u2014\u00a0as reliable, because it is too difficult to distinguish ancient DNA from modern contamination.) Exceptions include analyses on  8,000-year-old wheat  from a submerged site off the English coast (although these results have been questioned because the DNA  did not show the expected age-related damage 4 ), and mitochondrial DNA from a 12,000-year-old skeleton found in a freshwater sinkhole in Mexico 5 . Finding undisturbed remains such as those at Antikythera is crucial because it offers the opportunity to extract any DNA in the best possible condition. Previously salvaged bones are not ideal for analysis because they have often been washed, treated with conservation mater\u00adials or kept in warm conditions (all of which can destroy fragile DNA), or handled in a way that contaminates them. Schroeder guesses from the skeleton\u2019s fairly robust femur and unworn teeth that the individual was a young man. As well as confirming the person\u2019s gender, DNA from the Antikythera bones could provide information about characteristics from hair and eye colour to ancestry and geographic origin. In the past few years, modern genome sequences have revealed that genetic variation in populations mirrors geography, says Schroeder. He and others are now starting to look at how ancient individuals fit on that map, to reconstruct past population movements. Would the shipwreck victim look more Greek-Italian or Near Eastern, he wonders? Over dinner, the researchers decide to nickname the bones\u2019 owner Pamphilos, after a name found neatly scratched on a wine cup from the wreck. \u201cYour mind starts spinning,\u201d says Schroeder. \u201cWho were those people who crossed the Mediterranean 2,000 years ago? Maybe one of them was the astronomer who owned the mechanism.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Ancient DNA dispute raises questions about wheat trade in prehistoric Britain 2015-Nov-03 \n                   \n                     Famed Antikythera wreck yields more treasures 2014-Oct-10 \n                   \n                     Mexican skeleton gives clue to American ancestry 2014-May-15 \n                   \n                     In search of lost time 2006-Nov-29 \n                   \n                     Blog post: Beyond the Antikythera mechanism \n                   \n                     \u2018Return to Antikythera\u2019 project \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20644", "url": "https://www.nature.com/articles/nature.2016.20644", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Research on non-invasive pregnancy tests and superconductors earns US$1-million \u2018Chinese Nobels\u2019. The first winners of a prize devoted exclusively to scientific discoveries made in China were announced on 19 September in Beijing. The Future Forum, a non-profit organization established last year in Beijing, announced that pathologist Yuk Ming Dennis Lo at the Chinese University of Hong Kong has won the life-science  Future Science Prize  for the discovery that  DNA from a fetus can be extracted from the mother\u2019s blood 1 . The discovery led to the now widely used non-invasive tests to screen a pregnant woman\u2019s blood to see if the fetus has disorders such as Down\u2019s syndrome.  Shenzhen-based BGI  alone has carried out more than 1 million screens based on the finding. Qi-Kun Xue of Tsinghua University in Beijing netted the physics prize for the experimental discovery of  high-temperature superconductivity  at the interfaces of materials 2  and the quantized anomalous Hall effect 3  \u2014 an unusual orderly motion of electrons in a conductor at low temperature. That line of work belongs in the fast-emerging field of  topological insulators . Each prize is worth US$1 million. Xue says that he will \u201cshare the money with my colleagues who made significant contribution to the two discoveries\u201d. Lo says he hasn't had time to think about what to do with the money, but that he will start by using some of it to invite family, friends and long-time collaborators to the prize ceremony in January in Beijing. \u201cEverything happened so rapidly today,\u201d says Lo. The prizes were announced at 3 p.m. local time at a press conference. \n             'Fair and independent' \n           Organizers stress that the prize, funded by Robin Li, chief executive of China\u2019s giant Internet search engine, Baidu, and several other private industry executives, is awarded on the basis of \u201cfair and independent\u201d selection. Government-sponsored awards and grants have spurred controversy with  charges of favouritism and poor stewardship  in the past. Chinese media have  billed the awards as \u201cChina\u2019s Nobel Prize\u201d . Winners of the annual prize are selected by a Chinese jury, and given only to scientists working in mainland China, Hong Kong, Macau and Taiwan. The fields can change each year. Up to five scientists can share a prize. Lo says that the high-profile prizes could bring stories of discoveries to a new generation of Chinese students. \u201cStories of scientific discoveries are a powerful tool for arousing students\u2019 interests in science,\u201d he says. He notes that the discovery of DNA by Watson and Crick motivated him when he was young. Last year,  China celebrated the first scientific Nobel Prize  awarded for work done in the country. That prize was awarded to Youyou Tu, a pharmacologist at the China Academy of Chinese Medical Sciences in Beijing, for research she had done more than four decades ago. It triggered debate over why there haven\u2019t been more Chinese laureates, and whether the current science funding system in China encourages the type of creativity needed to win such prizes. \n             China\u2019s Nobel \n           Lo recognizes that the \u2018Chinese Nobel\u2019 is like a \u201cyoung plant with just the first year of blossom\u201d compared with the real Nobel prize, which has more than a century of achievements. \u201cI am hopeful that, with time, [the Future Science prize] would acquire the status and history enjoyed by its more established counterparts,\u201d he says. Other science prizes from the Chinese region that draw comparisons with the Nobel prize, such as  Taiwan\u2019s Tang Prize  and Hong Kong\u2019s Shaw prize, can be awarded for work done anywhere in the world. \n                   Anti-parasite drugs sweep Nobel prize in medicine 2015 2015-Oct-05 \n                 \n                   Questions emerge over top Chinese science prize 2015-Feb-12 \n                 \n                   Superconductor breaks high-temperature record 2012-Feb-22 \n                 \n                   Baby's genome hidden in mother's blood 2010-Dec-08 \n                 \n                   Future Science Prize \n                 \n                   Tang Prize \n                 \n                   Shaw Prize \n                 Reprints and Permissions"},
{"file_id": "537458a", "url": "https://www.nature.com/articles/537458a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Next-generation space-weather model will map the danger facing power grids. In the fight to protect Earth from solar storms, the battle lines are drawn in space at a point 1.6\u00a0million kilometres away. There, a US National Oceanic and Atmospheric Administration (NOAA)  satellite waits for electrons and protons  to wash over it, a sign that the Sun has burped a flood of charged particles in our direction. As early as the end of this month, NOAA should have a much better idea of just how dangerous those electromagnetic storms are. The agency will begin releasing forecasts that use a more sophisticated model to predict how incoming solar storms could fry electrical power grids. It will be the clearest guide yet as to which utility operators, in what parts of the world, need to worry. \u201cThis is the first time we will get short-term forecasts of what the changes at the surface of the Earth will be,\u201d says Bob Rutledge, lead forecaster at NOAA\u2019s Space Weather Prediction Center in Boulder, Colorado. \u201cWe can tell a power-grid customer not only that it will be a bad day, but give them some heads-up on what exactly they will be facing.\u201d Powerful solar storms  can knock out radio communications and  satellite operations , but some of their most devastating effects are on electrical power grids. In 1989, a solar storm wiped out Canada\u2019s entire Hydro-Qu\u00e9bec grid for hours, leaving several million people in the dark. In 2003, storm-induced surges fried transformers in South Africa and overheated others at a nuclear power plant in Sweden. But if a power company knows that a solar storm is coming, officials can shunt power from threatened areas of the network to safer ones or take other precautions. Until now, NOAA had warned of solar activity using the planetary K-index, a scale that ranks the current  geomagnetic threat to the entire Earth . The new \u2018geospace\u2019 forecast, which draws on more than two decades of research, comes in the form of a map showing which areas are likely to be hit hardest ( G.\u00a0T\u00f3th  et al. J. Geophys. Res. Space Phys.   110,  A12226; 2005 ). Knowing that Canada, for instance, will be hit harder than northern Europe helps grid operators, says Tamas Gombosi, a space physicist at the University of Michigan in Ann Arbor who helped to develop the model. He compares it to having a hurricane forecast that says a storm will hit Florida, rather than just somewhere on the planet (see \u2018Storms from the Sun\u2019). \n               Magnetosphere model \n             Space-weather forecasting is as rudimentary as conventional weather forecasting was three or four decades ago, says Catherine Burnett, space-weather programme manager at the UK Met Office in Exeter. Researchers have developed different models to describe various portions of the Sun\u2013Earth system, but linking them into a coherent framework has been difficult. The Michigan approach combines 15\u00a0models that collectively describe the solar atmosphere through interplanetary space and into Earth\u2019s magnetic realm. The NOAA forecast incorporates three of those: one model describing Earth\u2019s entire magneto\u00adsphere, another focusing on the inner magneto\u00adsphere and one for electrical activity in the upper atmosphere. The inner magnetosphere chunk is crucial to the model\u2019s overall success, says developer G\u00e1bor T\u00f3th at the University of Michigan. It describes how energetic particles flow and interact as they approach Earth\u2019s poles, and how the particles affect magnetism at the planet\u2019s surface. Alerts can provide roughly 20\u00a0minutes to one hour of warning. NOAA\u2019s improved forecasts are part of a push by US agencies to implement a national space-weather strategy issued last year by the White House. Regulators will also soon require power-grid operators to produce hazard assessments that include the threat of solar storms. \u201cWithout those two pieces, we wouldn\u2019t have remotely the interest we have now,\u201d says Antti Pulkkinen, a space-weather researcher at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. \u201cIt really has changed the game.\u201d NOAA plans to continue refining its forecasts as new research rolls in. The possible improvements include incorporating how the geology beneath power grids affects the intensity of a solar storm. Fluctuating magnetic fields can induce electrical currents to flow in the ground, which sets up further problems for transmission lines. \u201cAll of this is terrifically complicated,\u201d says Jeffrey Love, a geomagnetics researcher at the US Geological Survey in Golden, Colorado. In their latest paper, Love, Pulkkinen and their colleagues describe the most detailed map of these \u2018geoelectric hazards\u2019 across part of the United States ( J.\u00a0J.\u00a0Loveetal.Geophys.Res.Lett.http://doi.org/bqpm;2016 ). Of the areas surveyed so far, those at the highest risk are the upper Midwestern states of Minnesota and Wisconsin, where complex geology induces strong electrical currents. Adding in 3D models of these ground currents will improve the next generation of NOAA forecasts, Rutledge says. \u201cThis is by no means the end.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Al Gore\u2019s dream spacecraft gears up for launch 2015-Jan-14 \n                   \n                     Solar eruptions combine to cause super storms 2014-Mar-18 \n                   \n                     UK bolsters defences against crippling solar storms 2013-Dec-26 \n                   \n                     Sunny outlook for space weather forecasters 2012-Apr-27 \n                   \n                     Astrophysics: Prepare for the coming space weather storm 2012-Apr-18 \n                   \n                     Linked solar eruptions explained 2011-Aug-26 \n                   \n                     What will the next solar cycle bring? 2010-Jan-26 \n                   \n                     NOAA Space Weather Prediction Center \n                   \n                     Space Weather Modeling Framework \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20550", "url": "https://www.nature.com/articles/nature.2016.20550", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Academics complain that reaction to failed coup is hurting science. Turkey\u2019s government has sacked 2,346 university staff for suspected ties to July\u2019s attempted military coup in the country. The sackings, announced in a 1 September decree as part of a wider purge of 40,000 civil servants, are the first of an expected wave of dismissals under powers granted by state-of-emergency rules following the coup. Those fired are unable to appeal, cannot hold any government positions in the future, and will have their passports revoked. Turkey\u2019s government has blamed the G\u00fclen movement \u2014 a religious organization \u2014 for the coup attempt. But academics have protested that some of those now being fired are not G\u00fclen followers, but simply opponents of particular government policies. More than 40 of those sacked, for example, had in January  signed an  \u2018Academics for Peace\u2019 petition  that had called for an end to violence between government forces and Kurdish separatists. Hundreds of the signatories of that petition have already faced investigations and several have been suspended, according to a website set up by some of the petition\u2019s supporters. \u201cThis latest attempt to purge Academics for Peace by linking them to coup plotters is outrageous and unacceptable,\u201d  a statement on the petition\u2019s website  said. \n             More sackings expected \n           \u201cAcademics with absolutely no links with the G\u00fclenists, who had even actively opposed G\u00fclenists in the past, are being sacked alongside suspected sect members,\u201d said the Association of University Councils \u2014 an academic society that represents young researchers \u2014 in a press statement. The G\u00fclenists had been close allies to the government of Recep Tayyip Erdo\u011fan and had used the connection to place their supporters in key positions in the judiciary, education and science. But in 2013, the alliance broke down and Erdo\u011fan (who has been Turkey's president since 2014) designated the G\u00fclen movement a terrorist group. More firings of academics are anticipated. In the first days of the state of emergency that was declared after the coup attempt, the Turkish Council of Higher Education (Y\u00d6K) told universities to identify and side-line academics and administrators suspected of being G\u00fclenists. \u201cMany of those fired were already under investigation. It was completely unexpected that so many would be sacked en masse, before the investigations were concluded,\u201d says Mehmet Somel, an evolutionary biologist from the Middle East Technical University in Ankara. In July, the Y\u00d6K had also  ordered all 1,577 of the country\u2019s university deans to leave their posts ; although they may reapply for their jobs, the move seemed designed to tighten Erdo\u011fan's political control of the higher education sector. And it told all academics who were out of the country to return home. Meanwhile, the science agency T\u00dcB\u0130TAK has suspended its fellowships and postponed all major project-funding calls. The Association of University Councils says that the government's measures after the coup are \u201csystematically harming science in Turkey\u201d. \n                   Turkey purges universities after failed coup 2016-Jul-19 \n                 \n                   Turkish academics jailed for \u2018making terrorism propaganda\u2019 2016-Mar-16 \n                 \n                   Turkish scientists rocked by accusations of supporting terrorism 2016-Jan-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20503", "url": "https://www.nature.com/articles/nature.2016.20503", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Marathon used as benchmark to judge safety of possible future host cities. Most cities might be too hot to host the summer Olympic Games after 2085 because of climate change, according to an analysis in  The Lancet 1 .Using climate modelling and a measure of heat stress to the human body, researchers led by Kirk Smith, an environmental-health researcher at the University of California, Berkeley, judged whether cities would be suitable for hosting the Games.The authors used a measure known as the wet-bulb globe temperature, which takes into account how factors including temperature, humidity and wind speed affect people, especially during exercise. They used climate models under a high-emissions scenario to predict what this measurement would be for various cities in the future. The team proposed that it would be low risk to run a marathon if the wet-bulb globe temperature is less than 26 \u00b0C in the shade. Any location that had a more than 10% chance of having higher temperatures for the marathon would not be a viable host city. The study looked only at cities in the Northern Hemisphere \u2014 home to 90% of the world\u2019s population, and where summer occurs in July and August \u2014 and excluded those at an altitude of more than 1,600 metres (altitude had been a problem at the 1968 Mexico Olympics), as well as cities with populations of less than 600,000.That left 25 suitable cities in western Europe for the 2088 Games \u2014 more than half of which are in the United Kingdom \u2014 and just 8 in the rest of the Northern Hemisphere, including San Francisco in California, St Petersburg in Russia and Ulaanbaatar in Mongolia. And according to the researchers' calculations, none of the cities that bid for the 2020 summer Games \u2014 Tokyo, Madrid and Istanbul \u2014 would be fit to be a host. Read a previous Trend Watch: ' Europe leads growing market in offshore wind power ' Reprints and Permissions"},
{"file_id": "nature.2016.20530", "url": "https://www.nature.com/articles/nature.2016.20530", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Research begins at the unabashedly international Francis Crick Institute. \u201cIt is amazing, isn't it,\u201d says Paul Nurse, as he stands on a bridge overlooking the grand atrium of the new Francis Crick Institute in London. Light floods in from the building's cathedral-like entrance. \u201cI can't quite believe it's here.\" Nurse, the institute\u2019s founding director, and his ten lab members are among the first researchers to begin working at the Crick, which opened to the media on 1 September. The UK government and the Crick\u2019s other funders have gambled \u00a3700 million (US$927 million) on the institute, in the hope that it will  attract some of world\u2019s brightest young biomedical researchers to Britain  and catalyse a boom in the UK life-sciences economy. The building will eventually house 1,500 scientists and support staff, making it Europe's largest single-site biomedical institute. They will study a broad portfolio of biomedical research, from immunology to cancer genetics.  \n               Brexit looms \n             The 93,000-square-metre glass and steel temple looms over the neighbouring British Library, the largest public structure built in Britain in the twentieth century. But looming over the Crick is the  prospect of Brexit . The UK vote on 23 June to  leave the European Union  poses a range of uncertainties for UK researchers, from access to European funding to the ease of moving between EU countries. \u201cOur vision is to be a major research institute of great significance on the world stage,\u201d says Nurse. \u201cInternationalism is absolutely in our DNA.\u201d The Crick\u2019s first researchers, who began arriving in mid-August, come mostly from two institutes in London: the National Institute of Medical Research, run by the Medical Research Council, and the London Research Institute, run by the charity Cancer Research UK. The ultimate plan is for the Crick to house a growing and ever-changing roster of young group leaders, who will spend up to 12 years there. More than half of the Crick\u2019s current postdocs are from EU countries other than the United Kingdom, Nurse notes, and limits to freedom of movement for EU workers could make it harder to recruit. And if Britain does not secure access to EU research-funding programmes, that could also limit funding for the Crick's scientists. \n               Best people \n             Jernej Ule, a molecular biologist at University College London who will spend three years at the Crick, is emblematic of Nurse\u2019s international vision. Ule is a native of Slovenia and did his PhD and postdoctoral work in the United States. His lab, which studies how changes in gene expression influence motor neuron disease and other neural conditions, includes scientists from Spain, Italy, France, Germany and the United Kingdom. \u201cFor me to recruit the best people, I need to have a capacity to throw a net very broadly,\u201d he says. Ule also receives EU funding. After he arrived in the United Kingdom, he won a grant from the  European Research Council (ERC)  in 2007 to study RNA regulatory networks in neurons, then a nascent area of research. \u201cHaving the chance to apply for\u00a0European\u00a0funding at this top level is crucial to give us this\u00a0independence\u00a0of\u00a0thinking in\u00a0very new directions,\" he says. \u201cWithout the ERC I wouldn't be where I am right now.\u201d He and several other scientists who have begun working at the Crick say that the institute\u2019s mission is even more essential in the wake of the Brexit vote. \u201cIt\u2019s almost like we have the Crick in spite of Brexit,\u201d says Matthew Swaffer, a postdoc in Nurse\u2019s lab. \u201cI feel like it portrays the exact opposite sentiment that some people feel Brexit represents.\u201d \n               Interdisciplinary allure \n             Swaffer's colleague Tiffany Mak, a first-year PhD student, joined the Crick in part because of its mecca for\u00a0researchers from a wide variety of disciplines \u2014 and that has not diminished. \u201cThis project puts so much emphasis on bringing people from all sorts of backgrounds together. Hopefully it will act as a hub and not let politics get in the way of science and collaboration.\u201d same anxieties  over Brexit as other UK research institutions, says Kieron Flanagan, a science-policy researcher at the University of Manchester. But the institute\u2019s high profile \u2014 some have described it as \u201ctoo big to fail\u201d \u2014 could even buffer it from some Brexit\u00a0worries, such as the ability to continue to recruit top scientists from Europe, he says. \u201cThey may have fewer problems than the university in the middle of nowhere in attracting people, but there will still be that concern there.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     UK government gives Brexit science funding guarantee 2016-Aug-15 \n                   \n                     Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                   \n                     Lessons from Brexit 2016-Jul-25 \n                   \n                     Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                   \n                     Europe\u2019s superlab: Sir Paul\u2019s cathedral 2015-Jun-23 \n                   \n                     Francis Crick Institute raises alarm about train line 2015-Feb-25 \n                   \n                     All of Nature's Brexit coverage \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20533", "url": "https://www.nature.com/articles/nature.2016.20533", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Two independent reports find scientific and medical inadequacies \u2014 and an uncritical environment surrounding Paolo Macchiarini. A \"star surgeon\" who implanted the world's first artificial trachea \u2014 but has since been dismissed following allegations of scientific and clinical misconduct \u2014 worked in an environment that provided a \u201cculture of silence\u201d, a lack of respect for rules and \u201cgroup thinking\u201d. That is the conclusion of an external inquiry commissioned in February by the Karolinska University Hospital in Stockholm into the three artificial-trachea operations that the surgeon, Paolo Macchiarini, carried out at the hospital between 2011 and 2013. The report, led by Kjell Asplund, chairperson of the Swedish National Council on Medical Ethics and released on 31 August, also says that the Karolinska Institute (KI), with which Macchiarini was jointly affiliated, applied unusual pressure on the hospital to hire him and to defend him against criticism \u2014 but also that the hospital was too willing to toe the KI line. Hospital director Melvin Samsom formally apologized to the three trachea recipients and their families \u2014 two of the patients have since died, and the third has required continuous hospital care since the transplant. \u201cWhat has happened is both unacceptable and exceptional,\u201d Samsom said during a press conference on 31 August. The hospital stopped further transplants in 2013 but Macchiarini went on to carry out five more artificial-trachea transplants at other locations. In June, public prosecutors opened investigations following preliminary charges against Macchiarini of involuntary manslaughter and causing grievous bodily harm. The report on the hospital was followed on 5 September by the results of a second independent inquiry commissioned by the KI \u2014 also in February. That inquiry examined the procedures the KI used to appoint Macchiarini and extend his contracts, and how the KI handled allegations of scientific misconduct against the surgeon. \n             Nonchalant attitude \n           The KI had a \u201cnonchalant attitude towards regulations\u201d,\u00a0says the 5 September report, citing poor management and administrative procedures, including for handling scientific misconduct allegations. It also says that Macchiarini\u2019s initial appointment in 2010 \u201cwas pushed through inappropriately\u201d, with the vice-chancellor at the time interfering directly, and that negative references for Macchiarini were not passed on to the recruitment committee. \u201cIt is striking how Asplund\u2019s\u00a0independent inquiry into procedures at the university hospital drew many of the same conclusions, even though we had not compared notes,\u201d says Sten Heckscher, a former president of Sweden\u2019s Supreme Administrative Court, who led the KI inquiry. Acting vice-chancellor of the KI, Karin Dahlman-Wright, said in a statement on the KI inquiry results: \u201cMacchiarini himself must bear considerable responsibility in all this, but it is also very clear that KI has failed in its monitoring of compliance with rules and procedures.\u201d She added: \"It is now up to us to show that KI is so much more than just the Macchiarini case.\u201d Already the KI has responded by tightening up its procedures for recruitment and handling allegations of scientific misconduct, she said. On 5 September, Macchiarini said in a  statement to Swedish broadcaster SVT  that he is not guilty of research mismanagement, and has always done his best for his patients. \n             Exaggerated success \n           Allegations of misconduct against Macchiarini  emerged in 2014 , including that he had exaggerated the success of his artificial-trachea implants in several scientific papers. In August 2015, the KI\u00a0 cleared him of scientific misconduct.  But a Swedish television documentary about Macchiarini\u2019s work, aired in January,  re-opened the issue . The KI subsequently  dismissed Macchiarini , and both the KI and the university hospital commissioned independent investigations, with the KI focusing on its management of Macchiarini\u2019s academic work and the hospital on his clinical activities. Under Macchiarini's procedure, the artificial windpipes were coated with bone-marrow stem cells extracted from the patients, who were later treated with growth factors to stimulate the cells to grow and cover the synthetic structure. The 31 August report led by Asplund points to problems with how Macchiarini managed the operations. These include mislabelling the procedures as medical care rather than clinical research, which resulted in failure to submit the procedure to an ethical review board and failure to obtain a permit from the Swedish Medical Products Agency to use the growth-promoting drugs, which have not yet been approved for the clinic.  The patients were not appropriately informed before consenting to the operation, whose exact procedures had never been carried out in a whole animal, the report says. Moreover, Macchiarini was not always available to deal with complications in his patients when they arose. \n             No risk assessment \n           The Asplund report also examines the institutes themselves. It finds that the hospital management did no risk assessment before the experimental procedure and did not ensure systematic follow-up. And it says that the highly competitive environment of the university hospital may have contributed to the course of events. The initial view of Macchiarini as having star status created a culture of acceptance, the report suggests, with colleagues preferring to keep criticisms to themselves rather than risk their own positions. Colleagues who dared to speak up were discredited instead of listened to. The report finds that Macchiarini\u2019s recruitment to the hospital was mostly driven by the KI\u2019s enthusiasm for his apparently innovative translational research. The hospital, the report states, called in references, some of which indicated certain shortcomings in Macchiarini\u2019s medical judgement, at a late stage in the recruitment process. The report's authors infer that the hospital did not act on these warning signs because of pressure from the KI. The KI also tried to pressure the hospital to extend its own contract with Macchiarini beyond November 2013, the report says, but in this case, the hospital held out. The affair has damaged trust in clinical research in Sweden, says the report, but the hospital is already taking steps to improve things. For example, it has prepared internal guidelines for experimental clinical methods and for how to deal with whistle-blowers. Acting KI vice-chancellor Karin Dahlman-Wright said in a statement on 31 August that \u201cit would be extremely regrettable if the Karolinska Institutet had exerted any kind of pressure\u201d in hiring Macchiarini. \n             Further criticism \n           Further criticism of the KI comes from the 5 September report. As well as noting a lack of regard for rules at the KI, it points out that the KI extended Macchiarini\u2019s contracts in 2013 and 2015 \u2014 even after the hospital had terminated its contract with the surgeon. And in 2015, the KI\u2019s audit office investigated whether Macchiarini\u2019s activities outside Stockholm posed any potential financial conflicts of interest. \u201cWe find it strange that the audit of his extra-occupational activities did not address the matter of ethics or thepotential damage to KI\u2019s reputation,\u201d says the report. It also says that the KI serially mishandled allegations of scientific misconduct. For example, when the institute cleared Macchiarini in 2015, this ran counter to an independent report a few months earlier, which found that he  had committed misconduct . The KI also holds some responsibility for the controversial transplants carried out at the Karolinska University Hospital, says the 5 September report. Staff were sometimes involved in discussions preceding and following surgery, and the KI claimed the success of the transplants in its evaluations of how it used its own research funding. KI cancer immunologist Hans Wigzell, who was vice-chancellor of the institute from 1995 until 2003, says the affair has left many KI professors nervous that their institute\u2019s damaged reputation will have knock-on effects for funding \u2014 and that a temptation to tighten procedures will lead to a damaging bureaucracy. \u201cThe systems at the KI are fine,\u201d he says. \u201cThe problems arose because decision-makers failed to follow the system\u2019s rules, and then they bunkered down.\u201d Macchiarini and his lawyer declined to comment to  Nature  on either of the reports. \n                   Prestigious Karolinska Institute dismisses controversial trachea surgeon 2016-Mar-23 \n                 \n                   Karolinska Institute to cut ties with controversial surgeon 2016-Feb-05 \n                 \n                   Artificial-windpipe pioneer under scrutiny again 2016-Feb-01 \n                 \n                   Artificial-windpipe pioneer cleared of misconduct 2015-Aug-28 \n                 \n                   Karolinska Institute \n                 \n                   Inquiry report summary (PDF) \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20526", "url": "https://www.nature.com/articles/nature.2016.20526", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Images from Dawn spacecraft reveal signs of complex geology that created the dome-shaped Ahuna Mons. A massive ice volcano towers over the surface of the dwarf planet Ceres, researchers report today in  Science 1 . Dubbed Ahuna Mons, the volcano stands 4 kilometres tall, roughly half the height of Mount Everest. Although scientists have spotted potential cryovolcanoes elsewhere in the Solar System \u2014 most notably on Pluto 2  \u2014 the study\u2019s authors say that their evidence is the strongest yet. \u201cThis huge mountain was a surprise,\u201d says lead author Ottaviano Ruesch, a planetary scientist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. \u201dWe were expecting to see just fluid plains of lava.\u201d\u00a0 Ruesch and his colleagues based their analysis on images and other observations collected by NASA\u2019s Dawn spacecraft, which began orbiting Ceres in March 2015. Those data demonstrate that the dwarf planet is more than just a cratered ball of rock and ice: it seems to be geologically active, with processes other than crater-forming impacts shaping its surface. The Dawn images, which have a resolution of 35 metres per pixel, reveal steep slopes covered in debris, and crags and pits on the summit of the mound-like Ahuna Mons. The cryovolcano appears to be only a few hundred million years old, making it a relatively recent addition to 4.5-billion-year-old Ceres. \n             Slushy start \n           Ceres\u2019s cryovolcano could be a frozen analogue to some volcanoes on Earth \u2014 its shape is consistent with that of a spreading volcanic dome such as Mount St Helens in Washington. Such volcanoes do not typically spew lava into the sky; instead, it oozes slowly to the surface, where it forms a dome. The researchers think that Ahuna Mons was formed by the same mechanism, but with slushy ice rather than molten rock. Surface temperatures on the dwarf planet hover at \u2212113\u00a0\u00baC. Such conditions would normally create ice that is hard as rock, but the authors think that the ice volcano contains chloride and other salts. These could lower the temperature at which ice freezes and produce a briny, viscous cryomagma. (Salts may also be present on Ceres' surface, which could explain the mysterious bright spots seen in images from Dawn.) The unusual domed shape of Ahuna Mons suggests that material such as cryomagma came up from below, says Norbert Sch\u00f6rghofer, an astronomer at the University of Hawaii at Manoa. If that is so, a still-unknown heat source within the Ceres must be helping to drive the volcanic activity.\u00a0 \u201cAhuna Mons was not something we expected,\u201d says Debra Buczkowski, a planetary geologist at Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, who is lead author of a  Science  paper on Ceres\u2019s topography 3 , also published today. Buczkowki\u2019s team describes craters criss-crossed with fractures that could be produced by cryomagma rising from within the dwarf planet \u2014 another possible indication of cryovolcanism. But not everyone is convinced that Ceres boasts an ice volcano. Jeffrey Moore, a planetary scientist at NASA Ames Research Center in Moffett Field, California, notes that the smooth area around Ahuna Mons\u2019s dome could be a relic of the impact that created an adjacent crater. That event could have melted nearby surface rock. \u201cThe mound remains the most enigmatic feature on Ceres,\u201d Moore says. With Dawn still in orbit around Ceres, researchers will continue to study the complex geology that underlies Ahuna Mons. \u201cIt\u2019s not active yet,\u201d Ruesch says. \u201cBut we want to make sure. Nature is always so unexpected.\u201d \n                   Mysterious bright spots on Ceres are probably salt 2015-Dec-09 \n                 \n                   Intriguing geology of Ceres revealed in new pictures 2015-Jun-22 \n                 \n                   Spacecraft nears dwarf planet Ceres 2015-Mar-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20532", "url": "https://www.nature.com/articles/nature.2016.20532", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Chemist who died on 24 August did pioneering work with green fluorescent protein. He helped scientists to see things they could never have imagined. Roger Tsien,\u00a0 who died last week aged 64 ,\u00a0 shared the 2008 Nobel Prize for Chemistry \u00a0for his work with the green fluorescent protein (GFP), which has become an indispensable tool in life sciences research. Tsien, a chemist who worked mainly at the University of California, San Diego, probed the protein\u2019s structure and used the insights to boost GFP\u2019s glow and build a whole palette of fluorescent proteins, which researchers have used to trace individual proteins and cells. Here  Nature  celebrates Tsien\u2019s work \u2014 and some of the objects that might never have been seen without his insights.\u00a0 \n             Roger Tsien \n           \n             The source \n           \n             Peering inside \n           \n             The Brainbow \n           \n             Vital structure \n           \n             Glowing pigs \n           \n             Green monkeys \n           \n             Painted scene \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "nature.2016.20486", "url": "https://www.nature.com/articles/nature.2016.20486", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Retrieval of a space-rock sample would be proof of concept for mining metals and water. On 8 September, a NASA spacecraft is set to launch on a seven-year mission to retrieve rocks and dust from a near-Earth asteroid called Bennu. Those samples could help scientists to better understand  the origins of the Solar System\u2019s planets  \u2014 and, perhaps, of life itself. Called OSIRIS-REx, the mission comes as a handful of companies pursue controversial plans to mine asteroids, in search of rare minerals or even fuel for extended space missions. If the NASA effort succeeds, it will serve as a proof of concept for more ambitious attempts to exploit asteroids for scientific or commercial gain. \u201cWe\u2019re cheering for them for a successful launch and mission,\u201d says Chris Lewicki, president and chief executive of Planetary Resources in Redmond, Washington, a company that is developing technology to mine asteroids. Extracting resources from space rocks, he says, will \u201cunleash  the economic potential  of exploring the Solar System\u201d. OSIRIS-REx\u2019s target, Bennu, formed about 4.5 billion years ago at the same time as Earth and the other planets in the Solar System. It is just 500 metres wide and travels at more than 100,000 kilometres per hour. NASA scientists chose Bennu because its nearly circular path brings it within 300,000 kilometres of Earth every six years, making it relatively accessible. And unlike many smaller space rocks, it does not rotate so quickly that it flings off debris that could harm a spacecraft. But grabbing a sample will not be easy. After OSIRIS-REx enters orbit around Bennu, it will descend close to the surface and deploy a 3.35-metre-long arm equipped with a suction-cup-like device. When the arm makes contact, it will release a jet of nitrogen gas to loosen surface rocks and dust, and push at least 60 grams of material into a storage chamber. A NASA engineer developed the idea using an air compressor and a plastic cup, says Rich Kuhns, the mission\u2019s programme manager. \n             Cosmic bounty \n           If all goes well, OSIRIS-REx will return to Earth in 2023 with the largest haul of space rocks since  NASA\u2019s Apollo programme  ended in the 1970s. (Japan\u2019s Hayabusa-2 spacecraft is on its way to sample the asteroid Ryugu, but mission scientists plan to collect less than a gram of material.) NASA scientists will analyse the OSIRIS-REx sample to determine Bennu\u2019s chemical composition. They hope to find water ice and organic molecules such as amino acids \u2014 both precursors to life. \u201cOSIRIS-REx is really a trailblazer,\u201d says Dante Lauretta, the mission\u2019s principal investigator and a planetary scientist at the University of Arizona in Tucson. \u201cAny team that\u2019s planning on intimately interacting with an asteroid, whether they\u2019re mining it or for future exploration, they\u2019re going to take advantage of all the pioneering techniques we\u2019re developing.\u201d Lauretta should know: he is a science adviser to Planetary Resources, which has identified several near-Earth asteroids that could be rich in water or precious metals. Another company, Deep Space Industries in Mountain View, California, said on 9 August that it is planning a commercial asteroid-mining mission called Prospector-1. Such companies might eventually extract scarce, valuable platinum-group metals and bring them back to Earth to produce electronic devices and  catalytic converters . Asteroids' minerals could also be turned into fuel for deep-space missions, and their metals could be used to print 3D structures in space. Water from asteroids could be used in shields to protect spacecraft from cosmic rays and solar radiation. Ultimately, the commercial goals of private firms are likely to diverge from the scientific ones of space agencies. \u201cOur agenda is really very different,\u201d says John Lewis, chief scientist for Deep Space Industries. \u201cOur purpose is to find economically attractive resources on asteroids and to devise means to extract them, process them and market them.\u201d \n             Spacesuits and lawsuits? \n           Yet commercial asteroid missions could face legal challenges that do not affect scientific exploration.  A 1967 United Nations treaty  declares outer space, \u201cincluding the moon and other celestial bodies\u201d, to be off-limits to sovereign claims. In practical terms, that means that \u201cno country can own property on the Moon\u201d or on asteroids, says lawyer Michael Listner, founder of Space Law and Policy Solutions, a think-tank in East Rochester, New Hampshire. Others disagree. Last autumn, the United States \u2014 a signatory to the UN treaty \u2014 enacted a law that permits commercial exploration and recovery of space resources by US citizens. \u201cThe US is saying to companies, \u2018We\u2019re going to give you permission to go harvest these resources,\u2019\u201d Listner says. Luxembourg is considering new regulations to permit asteroid mining, and has partnered with companies such as Deep Space Industries and Planetary Resources; other countries could soon follow. There is no international legal framework to address differing interpretations of the UN treaty nor territorial disputes in space, should any develop. Despite this uncertainty, space agencies and space-mining companies continue to develop plans for the next generation of asteroid exploration. Deep Space Industries' Prospector-1 mission could launch as soon as 2019, while NASA plans to  send a robotic spacecraft to an asteroid in the 2020s  to retrieve a boulder and drag it into orbit around the Moon. \n                   Japanese asteroid probe delayed 2014-Nov-28 \n                 \n                   Space miners seek riches in nearby asteroids 2012-Apr-24 \n                 \n                   Space capsule probed for asteroid dust 2010-Jun-29 \n                 \n                   OSIRIS-REx mission page \n                 \n                   Deep Space Industries \n                 \n                   Planetary Resources \n                 Reprints and Permissions"},
{"file_id": "537149a", "url": "https://www.nature.com/articles/537149a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Likelihood of stopgap spending measure grows. Another year, another round of budget roulette for US science agencies. When Congress returns from its summer break on 6 September, it will have just three weeks to pass a new government funding bill before the 2017 budget year begins on 1 October. Policy analysts predict that lawmakers will pass a stopgap funding measure that will keep agencies\u2019 budgets flat until the presidential election in November \u2014 and perhaps into next year. That would leave the US National Institutes of Health (NIH), the National Science Foundation and other science agencies in a familiar, if uncomfortable, position: unable to start new programmes or to end old ones without permission from Congress, and unsure about their total funding for the year. More uncertainty will come early next year, when the next US president takes office and replaces most agency directors. \u201cIt will be a transition year, and will be difficult enough\u201d, even without the budget limbo, says Matt Hourihan, director of the research and develop\u00adment budget and policy programme at the American Association for the Advancement of Science in Washington DC. One major question for agencies is how a budget deal between the House of Representatives and the Senate would reconcile the two bodies\u2019 very different 2017 spending plans. The House has proposed increasing the NIH\u2019s budget by US$1.3\u00a0billion over the 2016 level; the Senate has suggested a $2-billion boost. The House spending bill for NASA includes an extra $200\u00a0million for the agency\u2019s planetary-science programme compared with the current level, whereas the Senate has proposed cutting the programme\u2019s budget by about $300 million. Then there is the  beleaguered inter\u00adnational nuclear-fusion project ITER , which is funded by a consortium that includes the Department of Energy (DOE). The Senate has proposed cutting all US support for ITER in 2017 and redistributing the money saved to other energy programmes. But the House\u2019s plan would have the United States continue to contribute roughly $115\u00a0million per year to ITER, with flat funding for most other DOE programmes. The House and Senate do agree on some things, however. Neither included money for the White House\u2019s proposed $680-million  Cancer Moonshot Initiative . Ben Krinsky, legislative-affairs officer at the Federation of American Societies for Experimental Biology in Washington DC, says that Congress might be more willing to provide funding once it sees the NIH\u2019s final road map for the project, which the agency is due to release later this month. Meanwhile, the Senate is expected to vote this week on legislation that would create a $1.1-billion emergency fund for response to the Zika virus and research towards a vaccine. The US Department of Health and Human Services says that its budget for fighting the virus has almost run out\u00a0\u2014\u00a0even though in August it took back $81\u00a0million from the budgets of the NIH and other agencies to pay for  Zika response efforts . But perhaps the most immediate question for Congress and the science agencies is how long a temporary spending measure would last. The timing will be influenced by the 8\u00a0November general election, in which the White House, all 435 House seats and one-third of the Senate are up for grabs. December is often mentioned as a probable end date, but that would require Congress to return for a \u2018lame duck\u2019 session after the election. And some conservative law\u00admakers have proposed that any temporary funding plan should be extended until after the next president takes office. This would be a problem for the science agencies, says Jason Callahan, space-policy adviser at the Planetary Society in Alexandria, Virginia. \u201cEvery\u00adthing will increase in cost if there\u2019s uncertainty in the budget,\u201d he says. \u201cIt\u2019s bad policy to run the federal government on continuing resolutions, but it\u2019s an election year.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                   \n                     Obama makes risky bid to increase science spending 2016-Feb-10 \n                   \n                     US budget deal could ease uncertainty over science spending 2015-Oct-28 \n                   \n                     Nature  special: 2016 US election \n                   Reprints and Permissions"},
{"file_id": "537148a", "url": "https://www.nature.com/articles/537148a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Controversial US guidelines attempt to rein in rogue stem-cell clinics. Thomas Albini met his first patient blinded by a stem-cell \u2018treatment\u2019 last year. The elderly woman, who had macular degeneration, thought she was paying to participate in a clinical trial that would save her sight by injecting stem cells into both eyes. Instead, it left her legally blind. By the time Albini, an ophthalmologist at the University of Miami in Florida, had treated two more women who had been blinded by the same procedure, he knew that there was a systemic problem. Two of the women had been lured by a posting in a clinical-trial registry\u00a0\u2014 even though there was no real trial to speak of\u00a0\u2014 and none of the injections had been administered by a physician. The clinic offering the injections claimed that its procedure did not require approval from the US Food and Drug Administration (FDA), in part because it used the patient\u2019s own cells. Altogether, Albini found the cases shocking. \u201cAny sort of review would have been helpful.\u201d The debate over whether the FDA should review such treatments is growing more intense as purported stem-cell clinics proliferate across the United States. Current FDA regulations are poorly enforced and leave room for various interpretations. On 8\u00a0September, Albini will present his experiences at an FDA workshop. The following week, dozens of researchers, companies and patient advocates will flock to Bethesda, Maryland, for an FDA public hearing. Many of them will tout the virtues of unproven stem-cell therapies and insist that people should have the right to such treatments. The FDA has expanded the one-day hearing to two\u00a0\u2014 and moved it to a larger auditorium\u00a0\u2014 in response to overwhelming public interest. The discussion will focus on FDA proposals that aim to better define which cell therapies deserve strict regulation. If adopted, these controversial guidelines could encompass a large chunk of the cell-therapy clinics that claim to fall largely outside the agency\u2019s purview. A burgeoning industry has sprung up in the absence of definitive oversight. A recent study of stem-cell clinics that advertise online uncovered 570\u00a0such centres operating in the United States ( L.\u00a0Turner and P.\u00a0Knoepfler  Cell Stem Cell   19,  154\u2013157; 2016 ). Under FDA regulations, these clinics must prepare and store their therapies safely, and their facilities are subject to sporadic inspections. But many clinics also operate under the assumption that they do not need the agency\u2019s approval to carry out their procedures and do not have to conduct the clinical trials that the FDA normally demands to prove that a therapy works. Agency regulations state that clinics do not need regulatory approval if therapies involve \u201cminimal manipulation\u201d of cells that do not fundamentally alter their properties, and if those cells fulfil a \u201chomologous\u201d function similar to their original role in the body. But the precise definitions of \u201cminimal manipulation\u201d and \u201chomologous use\u201d are controversial. A series of four FDA draft guidelines released in 2014 and 2015 addressed that ambiguity by providing concrete examples of what would trigger greater FDA oversight. After soliciting public comment, the FDA will decide whether to amend and finalize the proposals. Not everyone is happy with the results up to now. Arnold Caplan, who studies regenerative medicine at Case Western Reserve University in Cleveland, Ohio, worries that the FDA will start seeking approvals for treatments that are now considered standard, including the use of abdominal fat in breast reconstruction following a mastectomy. Others are concerned that tighter guidelines will make it harder to bring discoveries to market. \u201cIt will potentially slow down translation in many instances,\u201d says Keith March, a cardio\u00adlogist at Indiana University in Indianapolis, who will also present at the public hearing. \u201cWe need to be cognizant of that.\u201d \n               Too late? \n             Some researchers are glad that the FDA is tackling the issue, however. Stem-cell researcher Jeanne Loring at the Scripps Research Institute in La Jolla, California, and her lab are talking to the FDA about starting clinical tests of a stem-cell treatment for Parkinson\u2019s disease. \u201cThey\u2019re making sure we know what we\u2019re doing,\u201d she says. But even if the FDA finalizes the proposals, it is unclear what effect the rules will have, says bioethicist Leigh Turner at the University of Minnesota in Minneapolis. The stem-cell clinics are too entrenched to be chased away by FDA guidance, he says. \u201cThe real question is if the FDA is going to send inspectors and issue warning letters.\u201d For Albini, the proposed FDA guidance is not a perfect solution, but it is at least a step in the right direction. He may never know for sure why the treatments blinded his patients. And he acknowledges that clearer guidelines\u00a0\u2014 and stricter enforcement\u00a0\u2014 will not prevent every such tragedy in the future. Neither will they keep some clinics from recruiting patients under the guise of conducting clinical trials. But every step counts. \u201cThe more regulatory hurdles you put in the way of somebody who wants to use the term \u2018research\u2019 as marketing, the better off we\u2019d be,\u201d Albini says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     FDA should stand firm on stem-cell treatments 2016-Jul-05 \n                   \n                     How iPS cells changed the world 2016-Jun-15 \n                   \n                     Policy: Global standards for stem-cell research 2016-May-12 \n                   \n                     China announces stem-cell rules 2015-Aug-26 \n                   \n                     Stem cells in Texas: Cowboy culture 2013-Feb-13 \n                   \n                     Nature  special: Reprogramming \n                   \n                     FDA public hearing \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20536", "url": "https://www.nature.com/articles/nature.2016.20536", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Pinpointing lander\u2019s cold resting place on comet 67P/Churyumov\u2013Gerasimenko will be a boon to researchers. The last resting place of the European Space Agency\u2019s (ESA\u2019s) comet lander Philae has been confirmed, less than a month before the end of the mission that saw it travel billions of kilometres from Earth. Photographs taken by Philae\u2019s mother ship Rosetta on 2 September clearly show the lander, including two of its three legs. The pictures, released on 5 September, confirm that Philae lies on its side in the shadow of a cliff, lodged in a crack, with one of its legs in the air. Pinpointing Philae\u2019s whereabouts and orientation should now help scientists to  interpret the data that the lander beamed back to Earth during its short life , in particular, in refining data from CONSERT, a radio instrument designed to study the comet\u2019s interior. \u201cThis wonderful news means that we now have the missing \u2018ground-truth\u2019 information needed to put Philae\u2019s three days of science into proper context, now that we know where that ground actually is,\u201d Matt Taylor, ESA\u2019s Rosetta project scientist, wrote on the agency\u2019s blog. \n             In the shade \n           Philae\u2019s resting place had a huge impact on its mission. The lander\u2019s tilted position meant that the comet\u2019s surface partially blocked Philae\u2019s antenna, making communication difficult, and the shady spot meant that the craft could not charge its solar panels, so Philae went into hibernation after just three days on the comet\u2019s surface. After that, the lander made  only sporadic but fruitless contact  with Rosetta, and in July,  ESA switched off Rosetta\u2019s radio communications  with the lander for good. The latest images \u2014 which have a resolution of 5 centimetres per pixel \u2014 come from a sweep of 67P/Churyumov\u2013Gerasimenko made by Rosetta from its closest-ever distance from the surface, just 2.7 kilometres. They\u00a0 confirm a suspected sighting of Philae \u00a0that was made in 2015 by combining images with data from Philae\u2019s radio instrument. Rosetta will now pass closer and closer to the surface as it prepares for a final manoeuvre that will send it\u00a0 crashing into the comet  on 30 September. \n                   Philae comet lander goes quiet for good 2016-Jul-26 \n                 \n                   Historic Rosetta mission to end with crash into comet 2015-Nov-04 \n                 \n                   Philae's comet discoveries create series of conundrums 2015-Jul-30 \n                 \n                   Philae comet lander wakes up and phones home 2015-Jun-14 \n                 \n                   Rosetta orbiter spies possible lander site 2015-Jun-12 \n                 \n                   ESA's Rosetta blog \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20531", "url": "https://www.nature.com/articles/nature.2016.20531", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "The top job in UK research is up for grabs, so who might apply? Do you have a high scientific standing? A wide appreciation of different research disciplines? Fancy earning \u00a3300,000 ($400,000)? If so, the UK government has a job for you. The  advertisement  for chief executive of the UK Research and Innovation (UKRI) \u2014 arguably the biggest job in UK science \u2014 went online on 30 August, prompting speculation about who might fill the role. Current favourites are UK university chiefs whose experience leading big interdisciplinary organizations prepares them to helm a body that will join together  the UK\u2019s nine existing research funding bodies . The salary \u2014 well beyond that of most working scientists and roughly twice what heads of existing UK research councils earn \u2014 \u201cdemonstrates the ambition that\u2019s there to recruit a really serious, heavy-weight person\u201d, says James Wilsdon, who studies research policy at the University of Sheffield. The wage should be high enough to lure university heads, says John Womersley, chief executive of the UK Science and Technology Facilities Council in Swindon. Including pensions and benefits, heads of UK universities, known as vice-chancellors, earned an average of around \u00a3270,000 in 2014\u201315, according to a survey by  Times Higher Education . \u201cSo that\u2019s the talent pool they want to fish in,\u201d says Womersley. \n             Power pull \n           The advertisement comes in advance of the legislation that will form the UKRI, the Higher Education and Research Bill, which has not yet passed through Parliament. The body will unite several disparate organizations: the seven research councils; the research funding activities of the Higher Education Funding Council for England (to be named Research England); and innovation funder Innovate UK. Expected to start in 2018, the UKRI head will oversee an annual budget exceeding \u00a36 billion. The bill\u2019s wording leaves much open to interpretation, and the UKRI\u2019s first chief executive will have a huge amount of power to shape the research system, says Wilsdon. Policy specialists are already narrowing their list of possible candidates. Experience running a large, research-heavy university could be desirable, as will being a fellow of the Royal Society (the UK's national science academy), says Wilsdon. \u201cThat would keep the academies happy and demonstrate that he or she is \u2018one of us\u2019,\u201d he says. \u201cSo already you start to think, who does that leave?\u201d \n             Possible candidates \n           People who tick those boxes, according to policy experts, include Nancy Rothwell, vice-chancellor of the University of Manchester, and Keith Burnett, vice-chancellor of the University of Sheffield. Rothwell has advised the UK prime minister on science policy, as co-chair of the Council for Science and Technology. Another possible candidate with government experience is Adrian Smith, vice-chancellor of the University of London and former director general of knowledge and innovation in the Department for Business, Innovation and Skills. Other names touted include John Bell, former president of the Academy of Medical Sciences, and Leszek Borysiewicz, vice-chancellor of the University of Cambridge, UK, and former head of the UK Medical Research Council (MRC). According to Wilsdon, appointing a biomedical scientist might seem particularly attractive: among the current research funders, he says the MRC was the most resistant to the new body. Candidates need not come from the United Kingdom, says Womersley. \u201cUniversities have started recruiting vice-chancellors from overseas, and this may be similar \u2014 someone who has run a large research system in another country might actually be a good candidate,\u201d he says. Whoever takes on the job should prepare themselves for a headache, adds Wilsdon. The chief executive will have to figure out how to run the new organization, including how to maintain the status of the existing research councils. \u201cIt\u2019s far from clear that anyone, even ticking all these boxes, would come in and easily navigate through this stuff,\u201d he says. Applications close on 26 September. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "537145a", "url": "https://www.nature.com/articles/537145a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA must avoid spreading Earth microbes to suspected water in hillside streaks. Four years into its travels across Mars, NASA\u2019s Curiosity rover faces an un\u00adexpected challenge: wending its way safely among dozens of  dark streaks that could indicate water  seeping from the red planet\u2019s hillsides. Although scientists might love to investigate the streaks at close range,  strict international rules  prohibit Curiosity from touching any part of Mars that could host liquid water, to prevent contamination. But as the rover begins climbing the mountain Aeolis Mons next month, it will probably pass within a few kilometres of a dark streak that grew and shifted between February and July 2012 in ways suggestive of flowing water. NASA officials are trying to determine whether Earth microbes aboard Curiosity could contaminate the potential Martian seeps from a distance. If the risk is too high, NASA could shift the rover\u2019s course\u00a0\u2014 but that would present a daunting geographical challenge. There is only one obvious path to the ancient geological formations that Curiosity scientists have been yearning to sample for years (see \u2018All wet?\u2019). \u201cWe\u2019re very excited to get up to these layers and find the 3-billion-year-old water,\u201d says Ashwin Vasavada, Curiosity\u2019s project scientist at NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California. \u201cNot the ten-day-old water.\u201d The streaks \u2014 dubbed recurring slope lineae (RSLs) because they appear, fade away and re\u00adappear seasonally on steep slopes \u2014 were first reported 1  on Mars five years ago in a handful of places. The total count is now up to 452\u00a0possible RSLs. More than half of those are in the enormous equatorial canyon of Valles Marineris, but they also appear at other latitudes and longitudes. \u201cWe\u2019re just finding them all over the place,\u201d says David Stillman, a planetary scientist at the Southwest Research Institute in Boulder, Colorado, who leads the cataloguing. \n               Dark marks \n             RSLs typically measure a few metres across and hundreds of metres long. One leading idea is that they form when the chilly Martian surface warms just enough to  thaw an ice dam in the soil , allowing  water to begin seeping  downhill. When temperatures drop, the water freezes and the hillside lightens again until next season. But the picture is complicated by factors such as potential salt in the water; brines may seep at lower temperatures than fresher water 2 . Other possible explanations for the streaks include water condensing from the atmosphere, or the flow of bone-dry debris. \u201cThey have a lot of behaviours that resemble liquid water,\u201d says Colin Dundas, a planetary geologist at the US Geological Survey in Flagstaff, Arizona. \u201cBut Mars is a strange place, and it\u2019s worth considering the possibility there are dry processes that could surprise us.\u201d A study published last month used orbital infrared data to suggest that typical RSLs contain no more than 3% water 3 . And other streaky-slope Martian features, known as gullies, were initially thought to be caused by liquid water but are now thought to be formed mostly by carbon dioxide frost. Dundas and his colleagues have counted 58\u00a0possible RSLs near Curiosity\u2019s landing site in Gale Crater 4 . Many of them appeared after a planet-wide dust storm in 2007\u00a0\u2014 possibly because the dust acted as a greenhouse and temporarily warmed the surface, Stillman says. Since January, mission scientists have used the ChemCam instrument aboard the rover \u2014 which includes a small telescope \u2014 to photograph nearby streaks whenever possible. So far, the rover has taken pictures of 8 of the 58 locations and seen no changes. The features are lines on slopes, but they have not yet recurred. \u201cWe\u2019ve got two of the three letters in the acronym,\u201d says Ryan Anderson, a geologist at the US Geological Survey who leads the imaging campaign. Curiosity is currently about 5\u00a0kilometres away from the potential RSLs; on its current projected path, it would never get any closer than about 2\u00a0kilometres, Vasavada says. The rover could not physically drive up and touch the streaks if it wanted to, because it cannot navigate the slopes of 25 degrees or greater on which they appear. But the rover\u2019s sheer unexpected proximity to potential RSLs has NASA re-evaluating its planetary-protection protocols. Curiosity was only partly sterilized before going to Mars, and experts at JPL and NASA headquarters in Washington DC are calculating how long the remaining microbes could survive in Mars\u2019s harsh atmosphere\u00a0\u2014 as well as what weather conditions could transport them several kilometres away and possibly contaminate a water seep. \u201cThat hasn\u2019t been well quantified for any mission,\u201d says Vasavada. The work is an early test for the NASA Mars rover slated to launch in 2020, which will look for life and collect and stash samples for possible return to Earth. RSLs exist at several of the rover\u2019s eight possible landing sites. For now, Curiosity is finishing exploring the Murray formation. This area is made of sediments from the bottom of ancient lakes\u00a0\u2014 the sort of potentially life-supporting environment the rover was sent to find. Curiosity\u2019s second extended mission begins on 1\u00a0October. Barring disaster, the rover\u2019s lifespan will be set by its nuclear-power source, which will continue to dwindle in coming years through radioactive decay. Curiosity still has kilometres to scale on Aeolis Mons as it moves towards its final destination, a sulfate-rich group of rocks. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @alexwitze \n               \n                     Why hunting for life in Martian water will be a tricky task 2015-Sep-28 \n                   \n                     Water seems to flow freely on Mars 2013-Dec-10 \n                   \n                     Mystery of slick Martian slopes gets less slippery 2012-Mar-20 \n                   \n                     Dark streaks guide search for life on Mars 2011-Aug-04 \n                   \n                     Mars Curiosity rover \n                   \n                     HiRISE images of RSLs \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20535", "url": "https://www.nature.com/articles/nature.2016.20535", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "From immunotherapies to diagnostics, an expert panel outlines research goals for broad initiative. Advisers to the US Cancer Moonshot Initiative have produced a wide-ranging laundry list of research targets for the project \u2014 even as its funding remains uncertain. The ten recommendations released on 7 September include the launch of a national clinical-trial network specifically targeted at therapies that harness the immune system, and the creation of a 3D cancer atlas to catalogue a tumour's mutations and its interactions with neighbouring normal cells. The advisory panel \u2014 whose members include leading cancer researchers, physicians and patient advocates \u2014 also called for new cancer technologies, including advanced imaging techniques and drug-delivery devices; a focus on proteins that drive many paediatric cancers; and studies of how tumours become resistant to cancer treatments. The National Cancer Institute (NCI) has not yet determined how much funding will go to each of the initiatives, or how the projects will be structured. The White House  launched the moonshot in January  to  double the pace of cancer research  over the next five years. But the programme is  stuck in funding limbo  as Congress hashes out next year\u2019s budget. The US National Institutes of Health requested US$680 million for the moonshot for the 2017 fiscal year, which starts on 1 October. Despite vocal support from members of both political parties, lawmakers have said that they need more detail on the programme before they can fully fund it. If that does not happen before Congress sets the government\u2019s 2017 budget, full funding might have to wait until the 2018 fiscal year, says Matt Hourihan, director of the research and develop\u00adment budget and policy programme at the American Association for the Advancement of Science in Washington DC. \n               Waiting game \n             The recommendations from the moonshot\u2019s advisory panel provide the information that lawmakers want, says Jon Retzlaff, managing director of science policy and government affairs for the American Association for Cancer Research in Washington DC. Retzlaff plans to start lobbying Congress with the recommendations in hand. \u201cThe concepts and the grant proposals that will be generated because of these proposals, I think, will inspire Congress to say, \u2018Yes, this is a worthy project,\u2019\u201d he says. For now, uncertainty hangs heavy over moonshot discussions. At a meeting on 7 September, NCI deputy director Dinah Singer said that the agency aims to launch some parts of the moonshot programme in fiscal year 2017 and might seek funding from the private sector. But some NCI advisers are concerned that without substantial new funding, implementing the advisory panel's recommendations could hamper the NCI's current projects.  The initiative already received $195 million in 2016, and lawmakers have expressed interest in committing at least that much again in the next year, says Hourihan. NCI director Douglas Lowy said he is hoping for a substantial funding boost. \u201cIf we didn't get one, it\u2019s not that we wouldn\u2019t be able to start anything,\u201d he said. \u201cIt\u2019s just that the size, scope and speed would be dramatically different.\u201d In spite of the uncertainty, the report generated excitement among some cancer researchers. A call to expand the use of proven cancer-prevention and early-detection strategies, for example, was a pleasant surprise, says cancer geneticist Bert Vogelstein of Johns Hopkins University in Baltimore, Maryland. Although many experts think that the approach could slash cancer deaths, it has not typically been high on the funding list, says Vogelstein. \u201cI was very impressed,\u201d he says. \u201cThey picked out some underexplored opportunities.\u201d \n               Mixed reactions \n             But the recommendations also faced criticism at the 7 September meeting. Several attendees argued that the report needs to contain a stronger emphasis on disparities in cancer deaths that have been linked to race and economic status. \u201cDisparities should be sitting at the top of this whole thing,\u201d said Mack Roach, a radiation oncologist at the University of California, San Francisco. \u201cPeople are dying who shouldn\u2019t be dying.\u201d That issue was left largely to the Moonshot Task Force, a separate advisory panel that is focused on improving access to cancer care and removing barriers to cancer research, said the task force\u2019s leader, Greg Simon, who is chief executive of Poliwogg, a health-care investment company in New York City. The task force plans to release its report later this year. The latest recommendations could not cover the full gamut of cancer research, advisory-panel members stressed during the meeting. \u201cWe really need to show we can produce something,\u201d said cancer researcher Elizabeth Jaffee of Johns Hopkins. \u201cWe went after the shovel-ready or low-hanging fruit as the priority right now.\u201d Even so, the breadth of the recommendations was impressive, and could serve to draw new researchers to the field, says Stephen Elledge, a geneticist at Harvard Medical School in Boston, Massachusetts. \u201cThey did a pretty good job,\u201d he says. \u201cI was glad they didn\u2019t just say, \u2018Oh we just need to sequence more tumours.\u2019\u201d \n                     Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                   \n                     Scientists worry as cancer moonshots multiply 2016-Apr-27 \n                   \n                     Biden time 2016-Apr-27 \n                   \n                     Back to Earth 2016-Feb-17 \n                   \n                     Obama proposes cancer \u201cmoonshot\u201d in State of the Union address 2016-Jan-13 \n                   \n                     Nature collection: Cancer genomics -- from bench to bedside \n                   \n                     Cancer Moonshot Initiative \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20552", "url": "https://www.nature.com/articles/nature.2016.20552", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Sequences of nearly 200 beer-making strains reveal evolution in action. Geneticists have traced the history of beer\u2019s most important ingredient: yeast. By sequencing the genomes of nearly 200 modern strains of brewer\u2019s yeast, the research reveals how, over hundreds of years, humans transformed the wild fungus  Saccharomyces cerevisiae  into a variety of strains tuned for particular tipples. Yeast gives beer its booze and bubbles by fermenting sugar into alcohol and carbon dioxide, but it also makes hundreds of chemicals that impart flavours such as bananas and cloves to a drink. Brewing yeasts differ in their production of these metabolites and in other traits such as their tolerance to alcohol. To understand the basis for these differences, a team led by geneticist Kevin Verstrepen at the University of Leuven and the Flanders Institute of Biotechnology in Belgium, sequenced the genomes of 157  S. cerevisiae  strains used to make ale and other fermented products, including wine, sak\u00e9 and bread\u00a0. Their work is detailed in an 8 September  Cell  paper 1 . An evolutionary tree of the yeast strains revealed distinct families of yeast used for making wine, bread and sak\u00e9, and two distantly related groups of ale yeast, including strains from Belgium, Germany, Britain and the United States. \u201cThis is a genomic encyclopaedia of ale yeasts that will serve researchers for years to come,\u201d says Chris Hittinger, an evolutionary geneticist at the University of Wisconsin\u2013Madison. Verstrepen\u2019s team, meanwhile, is  using genomics to churn out new strains of beer yeast . \n             Ancient intoxicant \n           Beer is one of civilization\u2019s oldest intoxicants. A 5,000-year-old Sumerian tablet depicts an ancient keg party, while similarly aged pots from western Iran and northern China hold residues of beer ingredients, including barley and fermentation by-products. Given that history, Verstrepen expected the ancestors of modern brewing yeasts to date back thousands of years. Instead, his team estimates that humans domesticated beer yeasts starting in the late sixteenth and early seventeenth century. This, he says, coincides with a period in Europe when beer-making moved from homes to pubs and monasteries. He suspects that early professional brewers took yeast with them when they moved around Europe and even to the New World: US beer strains, for instance, are closely related to British strains. Brewers did not isolate the first yeast strains until much later, in the late nineteenth century \u2014 but they may have inadvertently shaped the genomes of yeast by brewing each new batch of beer on top of the dregs of the last one, Verstrepen proposes. Through this practice, brewers might have slowly selected yeast strains that perform well and produce desirable flavours. An independent team led by Jos\u00e9 Paulo Sampaio, an evolutionary geneticist at the New University of Lisbon, came to many of the same conclusions as Verstrepen\u2019s team about how humans shaped beer yeast, after sequencing 28 beer yeast strains. That study will appear next month in  Current Biology . Hittinger says that he\u2019s not sure about the finding that beer yeast was domesticated in the 1600s. Those dates are based on a DNA mutation rate for yeast that is 50 times faster than those estimated by other studies; a slower mutation rate would mean that beer domestication occurred much earlier than the study suggests. But Verstrepen stands by the calculation \u2014 yeast mutates rapidly when living in alcohol, he notes. \n             Genetically modified beer \n           Although all the industrial yeasts bore signs of human influence, the beer yeast genomes were the most dramatically altered. Beer-making strains carry variations and duplications\u00a0in genes involved in consuming maltose and maltotriose, the main sugars in beer. Most of the beer yeasts had variations that limit production of 4-vinyl guaiacol (4-VG), which imbues clove and smoke flavours that many beer drinkers loathe. One exception was yeast used in German wheat beers called Hefeweizens, which typically smell of cloves. The genomes of these strains contain stretches of DNA \u2014 including the genes that make 4-VG \u2014 that seem to originate from wine yeast. Verstrepen thinks that these strains emerged when an ale strain hybridized with a wine-making yeast, regaining the capacity to make the clove-smelling chemical. The newly available genomes may also shake up beer-making. Verstrepen\u2019s lab is breeding different yeast strains and selecting hybrids with a desired set of gene variants. For the  Cell  paper, they made a hybrid strain with high alcohol tolerance that does not produce 4-VG. His lab has brewed with genetically modified yeast to make a beer with very high levels of a banana-tasting chemical, but he only distributes yeast created through conventional breeding to breweries. Loren Miraglia, a home brewer in San Diego, California, who provided some of the sequenced strains in the  Cell  paper, has thought of modifying beer yeasts with the gene-editing tools he uses in his job at a genomics institute. However, he doubts that consumers are ready for CRISPR beer. Hittinger imagines beer bottles carrying information about traits such as 4-VG production, which is determined by variations in genes called  PAD1  and  FDC1 . \u201cIt\u2019s one of the major flavours that causes me not to like certain beers,\u201d he says. \u201cI would check the  PAD1  and  FDC1  status of a beer before I ordered it.\u201d \n                   Tapping genetics for better beer 2016-Jul-26 \n                 \n                   Biohackers gear up for genome editing 2015-Aug-26 \n                 \n                   Why fruitflies know their beer 2013-Dec-09 \n                 \n                   Beer gets fresh approach 2008-Jun-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20567", "url": "https://www.nature.com/articles/nature.2016.20567", "year": 2016, "authors": [{"name": "Chris Woolston"}], "parsed_as_year": "2006_or_before", "body": "Finding could alter conservation strategies for long-necked animals. One of the most iconic animals in Africa has a secret. A genetic analysis suggests that the giraffe is not one species, but 4 separate ones \u2014 a finding that could alter how conservationists protect these animals. Researchers previously split giraffes into several subspecies on the basis of their coat patterns and where they lived. Closer inspection of  their genes , however, reveals that giraffes should actually be divided into four distinct lineages that don\u2019t interbreed in the wild, researchers report on 8 September in  Current Biology 1 . Previous genetic studies 2  have suggested that there were discrete giraffe populations that rarely intermingled, but this is the first to detect species-level differences, says Axel Janke, a geneticist at Goethe University in Frankfurt, Germany, and the study\u2019s senior author. \u201cIt was an amazing finding,\u201d he says. He notes that giraffes are highly mobile, wide-ranging animals that would have many chances to interbreed in the wild if they were so inclined: \u201cThe million-dollar question is what kept them apart in the past.\u201d Janke speculates that rivers or other physical barriers kept populations separate long enough for new species to arise. \n               Ruminating on ruminants \n             The study tracked the distribution of 7 specific genetic sequences \u2014 chosen to enable researchers to measure genetic diversity \u2014 in nuclear DNA from skin biopsies of 190 giraffes. They also looked at the animals\u2019 mitochondrial DNA. The sequences fell into four distinct patterns that strongly suggested separate species. Janke says that each of the four species is about as different from each other as the brown bear ( Ursus arctos ) is from the polar bear ( Ursus maritimus ). The researchers suggest replacing the current species name,  Giraffa camelopardalis , with four new ones: the southern giraffe ( G. giraffa ), found mainly in South Africa, Namibia and Botswana; the Masai giraffe ( G. tippelskirchi ) of Tanzania, Kenya and Zambia; the reticulated giraffe ( G. reticulata ) found mainly in Kenya, Somalia and southern Ethiopia; and the northern giraffe ( G. camelopardalis ), found in scattered groups in the central and eastern parts of the continent. The one remaining subspecies is the Nubian giraffe ( G. camelopardalis camelopardalis ) of Ethiopia and South Sudan. It is a distinct subspecies of the northern giraffe. \u201cThis study is pretty persuasive,\u201d says George Amato, a conservation biologist at the American Museum of Natural History in New York City, who has conducted extensive research on the genetics of African wildlife. \u201cI applaud the science and what it adds to our understanding of African biogeography.\u201d Janke says that the findings have obvious implications for conservation: all of the giraffe species must be protected, with special attention paid to the northern and reticulated giraffe. Each of those species has fewer than 10,000 individuals. According to the Giraffe Conservation Foundation, the overall number of giraffes has dropped from more than 140,000 in the late 1990s to fewer than 80,000 today, largely because of habitat loss and hunting. \n               Finding clarity \n             But applying the new findings to conservation efforts may be difficult. \u201cSo far, we haven\u2019t really been able to fully appreciate the power of genomics in conservation,\u201d says Aaron Shafer, a geneticist at Trent University in Peterborough, Canada. Genetics can uncover new species, but it's not always obvious how that knowledge should guide decisions about animal protection. Amato notes strong parallels between giraffes and African elephants, which were classified as a single species until a 2010 study 3   provided genetic evidence that there were actually two : forest elephants ( Loxodonta cyclotis ) and savannah elephants ( Loxodonta africana ). That finding  increased calls for extra protection  of the forest elephant, the rarer of the two. However, assessments of African elephants by the International Union for Conservation of Nature treat the animals as one species,  due to concerns  that splitting them into two species would place forest and savannah elephant hybrids into a kind of conservation limbo. Evidence showing that many populations of American bison ( Bison bison ) carry small amounts of domestic-cattle DNA 4  prompted concerns over whether it was worth saving the contaminated herds, since they weren't completely wild. Amato and other biologists have argued that the animals still deserve protection. \u201cThey are ecologically functional bison,\u201d Amato says. It remains to be seen whether the latest study will have any impact on giraffe conservation, he says. The most immediate effects may be felt in zoos that trade the mammals for breeding purposes: now that researchers have identified separate species, it should be easier for zookeepers to make appropriate matches. The discovery of separate giraffe species could have come sooner, but the animals have been largely neglected by science. \u201cGiraffes were fairly ubiquitous in their habitat, and they weren\u2019t much of a target for poachers,\u201d Amato says. \u201cThey are an iconic animal, but they were taken for granted.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Threat to African forest elephants 2016-Aug-31 \n                   \n                     Giraffe genome sequence reveals clues to its unique morphology and physiology 2016-May-17 \n                   \n                     African elephants are two distinct species 2010-Dec-21 \n                   \n                     Giraffe Conservation Foundation \n                   \n                     How a genetics lab can save wildlife \n                   \n                     Conservation genetics to the rescue \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20569", "url": "https://www.nature.com/articles/nature.2016.20569", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "European mission will shed light on hidden asteroids, the Universe\u2019s expansion and exoplanets. Astronomers the world over are about to get their first taste of a tool that will transform their working lives. Gaia, a  space telescope  launched by the European Space Agency (ESA) in late 2013, will release its first map of the Milky Way on 14 September. The catalogue will show the 3D positions of 2,057,050 stars and other objects, and how those positions have changed over the past two decades. Eventually, the map will contain one billion objects or more and will be 1,000 times more extensive and at least 10 times more precise than anything that came before. The release next week will also include 19 papers by Gaia astronomers who have already seen the data. But independent teams are getting ready for their first glimpse. Lennart Lindegren, an astronomer at the Lund Observatory in Sweden and a major driving force in the Gaia project since it was first proposed in 1993, expects astronomers to produce 100 or so papers just in the weeks following the draft catalogue release. Some groups have planned \u2018Gaia hacking\u2019 and \u2018Gaia sprint\u2019 events, at which researchers will collectively work out how best to exploit the sudden manna. \u201cGaia is going to revolutionize what we know about stars and the Galaxy,\u201d says David Hogg, an astronomer at New York University who is leading some of these efforts. So what are some of the revelations that Gaia could make? \n               Milky Way archaeology \n             Gaia\u2019s 3D view of the Milky Way in motion will reveal how stars move under its combined gravitational pull. This will add to knowledge of the Galaxy\u2019s structure, including parts that are not directly visible from Earth, such as the \u2018bar\u2019 \u2014 two arms that stick straight out of the Galactic Centre and join it to the spiral arms. Researchers will be able to identify \u2018outlier\u2019 groups of stars which stream together at high speeds, and which are thought to be remnants of mergers with smaller galaxies, says Michael Perryman, an astronomer at University College Dublin and a former senior scientist for Gaia at ESA. Combined with existing information about factors including stars\u2019 colour, temperature and chemical composition, this detailed map will enable researchers to reconstruct the Galaxy\u2019s archaeology: how it got to its present state over the past 13 billion years. \u201cOver its lifetime, Gaia is going to radically impact our understanding of the structure of the Milky Way and its evolutionary history,\u201d says Monica Valluri, an astronomer at the University of Michigan in Ann Arbor. \n               Where is the Milky Way's dark matter? \n             The details of star trajectories inside the Galaxy will reveal the distribution not only of visible matter, but also of dark matter, which constitutes the bulk of most galaxies\u2019 mass. And that in turn could help to reveal what dark matter is. Gaia might also put some exotic theories to the test. Standard dark-matter theory predicts that the gravitational field of the Galaxy is spherically symmetrical near the Galactic Centre but then becomes elongated \u201clike an American football\u201d farther out, Valluri explains. But an alternative theory called MOND (modified Newtonian dynamics) implies that the field is shaped more like a pancake. By looking at the velocities of stars, which depend on the gravitational field, Gaia will be able to test which theory is right. The probe\u2019s data might even reveal evidence for the idea that dark matter killed the dinosaurs. If dark matter is concentrated in a relatively thin \u2018dark disk\u2019 near the Galactic plane,  says the audacious theory , it could trigger asteroid impacts that cause mass extinctions when the Solar System periodically crosses the disk. \n               Disputed stellar distances \n             Precise measurements of how far individual stars lie from the Sun will enable astrophysicists to fine-tune their models of how stars evolve. That is because current theories rely heavily on estimates of distance to understand how a star\u2019s intrinsic brightness changes during its lifetime. One of the first groups of stars that researchers will want to check is the Pleiades, a cluster in the constellation Taurus. Most observations, including one 1  made with the Hubble Space Telescope, put the cluster about 135 parsecs (440 light years) away. But results based on data from Hipparcos, an ESA space mission that preceded Gaia, suggest  2  that it is only 120 parsecs away. Some have said that  the discrepancy  casts doubt on the accuracy of Hipparcos. Gaia uses a similar, but much more evolved, method to Hipparcos, so astronomers will be watching its observations closely. \u201cI believe that the Hipparcos result will very likely be proved wrong by Gaia,\u201d says David Soderblom of the Space Telescope Science Institute in Baltimore, Maryland, who is an author on the Hubble study. \n               Thousands of new worlds \n             Astronomers have discovered thousands of planets orbiting other stars, in most cases by detecting tiny dips in a star\u2019s brightness when an orbiting planet passes in front of, or \u2018transits\u2019, it. Gaia will detect planets using another method: measuring slight wobbles in the star\u2019s position caused by a planet\u2019s gravitational pull. \u201cIt seems like a good bet that the mission will reveal thousands of new worlds,\u201d says Gregory Laughlin, an astronomer at Yale University in New Haven, Connecticut. Gaia\u2019s technique is best suited to detecting large planets in relatively wide orbits, says Alessandro Sozzetti, a Gaia researcher at the Astrophysical Observatory of Turin in Italy. And unlike the transit method, it directly measures a planet\u2019s mass. If it works, it will be a striking comeback for a technique that has seen many  false starts . But finding planets in this way will require several years of observation, with a sneak preview expected by 2018, Sozzetti says. \n               How fast the Universe is expanding \n             Although Gaia is primarily an explorer of the Milky Way, its influence will reach across the entire observable Universe. Gaia\u2019s direct distance measurements work only for objects in the Galaxy or its immediate vicinity; to estimate the distances to faraway galaxies, astronomers typically wait for stellar explosions called Type Ia supernovae. The apparent brightness of such a supernova reveals how far away the corresponding galaxy is. Such signposts, or \u2018standard candles\u2019, have been the main tool for estimating the rate of expansion of the Universe. The measurements have led astronomers to propose that a mysterious \u2018dark energy\u2019 has been accelerating that expansion. But to  use supernovae as signposts , astronomers must compare them with other types of standard candle in our Galaxy. In its first release, Gaia will measure the distances of thousands of such stars to high accuracy. Eventually, the probe\u2019s measurements will enable cosmologists to improve their maps of the entire Universe and perhaps to resolve some  conflicting estimates of its rate of expansion . \n               Invisible asteroid threats \n             As it constantly scans the sky, Gaia will also track and discover things much closer to home. It is ultimately expected to observe some 350,000 asteroids inside the Solar System, and to discover hundreds of new ones, says Gaia astronomer Paolo Tanga of the C\u00f4te d\u2019Azur Observatory in Nice, France. These will include near-Earth objects (NEOs), those whose orbits bring them within about 200 million kilometres of Earth. When it spots an NEO, Gaia can alert observatories, which can then use ground-based telescopes to establish whether the object is a threat. From its vantage point in space, Gaia will scan nearly the entire sky and so might reveal objects that, during certain times, are too close to the Sun to be observed from Earth, says Anthony Brown, an astronomer at the Leiden Observatory in the Netherlands who chairs Gaia\u2019s data-processing collaboration. \u201cWe can observe in areas you cannot normally reach from the ground at the same time.\u201d By tracking the way certain asteroids orbit the Sun over several years, Gaia will also be able to perform sensitive tests of Albert Einstein's description of gravity, his  general theory of relativity . \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Measurement of Universe's expansion rate creates cosmological puzzle 2016-Apr-11 \n                   \n                     Siren call 2016-Mar-23 \n                   \n                     Row reignites over distance of Pleiades star cluster 2014-Aug-28 \n                   \n                     Did dark matter kill the dinosaurs? 2014-Mar-07 \n                   \n                     Astrometry: Europe's star power 2013-Oct-02 \n                   \n                     Exoplanet claim bites the dust 2009-Dec-08 \n                   \n                     Gaia \n                   \n                     Gaia Archive \n                   \n                     Gaia Data Release 1 \n                   \n                     Gaia Sprints \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20577", "url": "https://www.nature.com/articles/nature.2016.20577", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Canada\u2019s Chalk River reactor, which makes large amounts of technetium-99m, will end production next month. Next month, Canada\u2019s Chalk River nuclear-research reactor will halt production of a medical isotope that is widely used in diagnostic scans. Any  unplanned outages  at the world\u2019s remaining production sites could lead to severe shortages of the radioactive tracer technetium-99m until new facilities come online in 2017 and 2018, the US National Academies of Sciences, Engineering and Medicine warns in a  report  released on 12 September. Chalk River produces about 20% of the world\u2019s supply of technetium; the rest comes from six other reactors in Europe, Australia and South Africa. Most of these reactors bombard highly enriched uranium (HEU) targets to produce molybdenum-99, which decays into technetium. Stockpiling the radioisotopes is impossible because of their short half-lives \u2014 66 hours for molybdenum-99, and 6 hours for technetium-99m. As a result, supply disruptions can quickly translate into shortages at hospitals, as happened  when two reactors shut down for repairs and maintenance in 2009 . \u201cWhat we have is a period of vulnerability that could last into 2018,\u201d says Kevin Crowley, senior director of the academies\u2019 Nuclear and Radiation Studies Board. In the event of shortages, he says, doctors would be forced to delay medical procedures that rely on the isotopes or use alternative technologies. One of the most common medical uses for technetium-99m is single-photon-emission computed tomography (SPECT), which can be used to monitor blood flow in the heart and brain and scan bones for tumours. Nonetheless, industry and governments have done a good job of coordinating international production and shipping of technetium since 2009, says Sally Schwarz, a nuclear pharmacist and co-director of the cyclotron facility at the Washington University School of Medicine in St Louis, Missouri. Schwarz is optimistic that any supply disruptions will be minimal. The medical community has learnt to economize its use of technetium, she notes, and physicians can use alternative diagnostic technologies in the event of isotope shortages. \n             Industry adjustments \n           In the meantime, facilities in Australia, South Africa and Europe are planning expansions next year that could make up most of the shortfall from the Chalk River closure. The European sites are also preparing to convert their reactors to use low-enriched uranium (LEU), which  is thought to be less valuable to terrorists . Australia, which already uses LEU targets, is building a new facility to process molybdenum-99. Delays in any of these projects would increase the risk of shortages. The Chalk River facility will stay open through March 2018, however, and could restart production before then on an emergency basis if an isotope shortage develops. The academies\u2019 study says that US and Canadian governments must work to ensure that there is a viable plan to fire up its isotope production if needed. By 2018, the United States could see the launch of domestic technetium production using new technologies for producing and processing molybdenum-99 \u2014 resulting in a possible glut that could pose new challenges for suppliers. \u201cFor the new domestic suppliers, the question is whether can they capture enough of the market to have a viable business plan,\u201d Crowley says. The academies\u2019 report also raises concerns about efforts to eliminate the use of highly enriched uranium and secure the nuclear waste that is created during medical-isotope production. The United States currently provides the bulk of the world\u2019s HEU targets but plans to halt shipments of highly enriched uranium by 2020. However, Russia has indicated that it may begin production of molybdenum-99 in the future, and has not yet committed to using LEU targets.  \n                   Radioisotopes: The medical testing crisis 2013-Dec-11 \n                 \n                   Souped-up cyclotrons offer isotope remedy 2012-Feb-21 \n                 \n                   Medical isotope supplies dwindle 2010-Feb-12 \n                 \n                   Medical isotope shortage reaches crisis level 2009-Jul-15 \n                 \n                   Researchers urge action on medical-isotope shortage 2009-Jun-24 \n                 \n                   Canadian accelerator produces a city\u2019s-worth of medical isotopes overnight \n                 \n                   National Academies' report \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20551", "url": "https://www.nature.com/articles/nature.2016.20551", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Geologic strain of tides during full and new moons could increase magnitude of tremors. Big earthquakes, such as the ones that devastated Chile in 2010 and Japan in 2011, are more likely to occur during full and new moons \u2014 the two times each month when tidal stresses are highest. Earth\u2019s tides, which are caused by a gravitational tug-of-war involving the Moon and the Sun, put extra strain on geological faults. Seismologists have tried for decades to understand whether that stress could trigger quakes. They generally agree that the ocean\u2019s twice-daily high tides can affect tiny, slow-motion tremors in certain places, including California\u2019s San Andreas fault 1  and the Cascadia region 2  of the North American west coast. But a new study, published on 12 September in  Nature Geoscience 3 , looks at much larger patterns involving the twice-monthly tides that occur during full and new moons. It finds that the fraction of high magnitude earthquakes goes up globally as tidal stresses rise. Satoshi Ide, a seismologist at the University of Tokyo, and his colleagues investigated three separate earthquake records covering Japan, California and the entire globe. For the 15 days leading up to each quake, the scientists assigned a number representing the relative tidal stress on that day, with 15 representing the highest. They found that large quakes such as those that hit Chile and Tohoku-Oki occurred near the time of maximum tidal strain \u2014 or during new and full moons when the Sun, Moon and Earth align. For more than 10,000 earthquakes of around magnitude 5.5, the researchers found, an earthquake that began during a time of high tidal stress was more likely to grow to magnitude 8 or above. \n             Breaking point \n           \u201cThis is a very innovative way to address this long-debated issue,\u201d says Honn Kao, a seismologist at the Geological Survey of Canada and Natural Resources Canada in Sidney. \u201cIt gives us some sense into the possible relationship between tidal stress and the occurrence of big earthquakes.\u201d Perhaps the miniscule added strain of tides, he says, could be the final factor that nudges a geological fault into rupturing. The current study will not be the final word on the matter, adds Kao. There are just too many factors that contribute to triggering an earthquake \u2014 such as how stress transfers within the ground to cause a geological fault to move \u2014 to untangle exactly what role tides might have. But \u201cthe results are plausible\u201d, says John Vidale, a seismologist at the University of Washington in Seattle who helped to debunk some of the more tenuous tide\u2013earthquake claims 4 . \u201cThey\u2019ve done a very careful job.\u201d The discovery does not affect how societies should prepare for possible earthquakes, says Ide. Even if slightly enhanced by the tides, the probability of a quake happening on any particular day in an earthquake-prone region remains very low. \u201cIt\u2019s too small to take some actions,\u201d he says. Ide is now looking at an additional list of earthquakes that occur where plates with oceanic crust plunge beneath continental crust, to see if the pattern holds up there as well. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Chinese data hint at trigger for fatal quake 2014-Sep-10 \n                 \n                   Hurricane may have triggered earthquake aftershocks 2013-Apr-19 \n                 \n                   Floods linked to San Andreas quakes 2010-Jan-06 \n                 \n                   Typhoons trigger gentler tremors 2009-Jun-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20506", "url": "https://www.nature.com/articles/nature.2016.20506", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Rocks in Greenland contain structures that could have been laid down by living organisms 3.7 billion years ago. Geologists say that they have unearthed some of the oldest known evidence for life on Earth. The discovery, yet to be confirmed, suggests that life arose quickly on the young planet. In this week's  Nature , Australian and British researchers report finding layered structures called stromatolites in 3.7-billion-year-old rocks from Greenland 1 . Stromatolites, which look a bit like geological cauliflowers, form when microbes trap sediment and build up layer after dome-shaped layer. But the discovery involves some of the most physically tortured rocks on Earth, which have been squeezed and heated over billions of years as crustal plates shifted. The pressure and heat recrystallizes the rocks, erasing much of the fine-scale detail that researchers normally use to identify fossilized stromatolites \u2014 so the work is already triggering heated debate. \u201cI\u2019ve got 14 queries and problems that need addressing before I\u2019ll believe it,\u201d says Roger Buick, a geobiologist at the University of Washington in Seattle. The rocks hail from Isua, Greenland, where researchers have laboured to tease out potential signs of life dating back billions of years. Previous work on the rocks\u2019 chemistry, such as a 1999 paper analysing carbon isotopes 2 , suggested that they contain \u2018biomarker\u2019 traces of early organisms. But various claims over the years have remained contentious. \n             Unearthing evidence \n           Now, melting snow has revealed new clues. A team led by Allen Nutman, a geologist at the University of Wollongong in Australia, visited a rock outcrop that had been buried under a perennial snow patch until warmer temperatures melted it away. They sawed out a chunk of 3.7-billion-year-old rock and took it back to Australia to study. In it they found the purported stromatolites, along with other clues to ancient life. \u201cIt\u2019s a combination of different types of evidence that makes the story so compelling,\u201d says team member Martin Van Kranendonk, a geologist at the University of New South Wales in Kensington, Australia. The structures are tiny bumps, just 1\u20134 centimetres tall, whose shape and internal layering strongly resemble ancient and modern stromatolites, Van Kranendonk and his colleagues say. The texture of the surrounding rocks suggests that they were laid down at the bottom of a shallow sea, much as stromatolites are today in places such as the Bahamas and western Australia. And the rocks contain carbonate minerals such as dolomite, which are also common in younger stromatolites. The Greenland structures are about 220 million years older than the oldest widely accepted evidence for life,  a set of stromatolites from the Pilbara region of western Australia 3 . \u201cThe evidence is a whole lot thinner than the rocks in Australia,\u201d says Abigail Allwood, an astrobiologist at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. \u201cHaving said that, it\u2019s incredible that anything can be found in these rocks that are barely a ghost of what they were before. That\u2019s why it\u2019s worthy of attention.\u201d \n             Doubts crystallize \n           Part of the problem with studying ancient stromatolites  is that layered structures can form through processes that have nothing to do with life. Minerals precipitating out on the seafloor can leave layers, like rings on a bathtub, that look like stromatolites but aren't 4 . \u201cAt most, these structures should be classified as pseudostromatolites,\u201d says Kathleen Grey, a consulting palaeontologist in Perth, Australia, who has worked on ancient stromatolites. \u201cSadly, I don\u2019t feel the evidence is convincing for such an important claim.\u201d Tanja Bosak, a geobiologist at the Massachusetts Institute of Technology in Cambridge, adds that she would like to see whether the proposed stromatolites have small amounts of organic matter in or near them. Comparing different types of carbon in the rock could help to reveal whether the structures are biological or not. At a minimum, Allwood notes, the Greenland rocks should help astrobiologists as they prepare for the first ever samples to be returned from Mars, from  a NASA mission slated to launch in 2020 . The newly reported stromatolites may serve as a test case for scientists to argue about what constitutes convincing evidence of past life. \u201cIf we found something like this on Mars would we stick a flag in it and call it life?\u201d she asks. \u201cI don\u2019t think we would.\u201d See the related News & Views article: ' Evidence of life in Earth\u2019s oldest rocks ' \n                   New candidates for oldest fossils 2011-Aug-21 \n                 \n                   High window on the past 2009-Sep-17 \n                 \n                   Shining a light on ancient stromatolites 2008-Jan-25 \n                 \n                   Complex ecosystems arrived early 2006-Jun-07 \n                 \n                   Australian Centre for Astrobiology \n                 \n                   The discovery of the Earth's oldest rocks \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20574", "url": "https://www.nature.com/articles/nature.2016.20574", "year": 2016, "authors": [{"name": "Carrie Arnold"}], "parsed_as_year": "2006_or_before", "body": "A virus that influences the development of the placenta in mammals could also help to explain male animals\u2019 physiques. Viruses are notorious for their ability to cause disease, but they also shape human biology in less obvious ways. Retroviruses, which insert their genetic material into  our genomes  to copy themselves, have left behind genes that help to steer our immune systems and mold the development of embryos and the placenta. Now researchers report in  PLOS Genetics  that syncytin, a viral protein that enables  placenta formation , also helps to increase muscle mass in male mice 1 . These results could partially explain a lingering mystery in biology: why the males of many mammalian species tend to be more muscular than females. \u201cAs soon as I read it, my mind started racing with the potential implications,\u201d says evolutionary virologist Aris Katzourakis of the University of Oxford, UK. \n             Viral legacy \n           About 8% of the 3 billion pairs of As, Ts, Gs and Cs that make up our DNA are viral detritus. Many of those viral hand-me-downs have degraded into useless junk \u2014 but not all, as a series of discoveries over the past 15 years has revealed. In 2000, scientists discovered that syncytin, a protein that enables the formation of the placenta, actually originated as a viral protein that humans subsequently \u2018borrowed\u2019 2 . That original viral protein enables the retrovirus to fuse with host cells, depositing its entire genome into the safe harbour of the cytoplasm. Syncytin has changed little from this ancestral protein form; it directs certain placental cells to fuse with cells in the mother\u2019s uterus, forming the outer layer of the placenta. Subsequent research showed that different groups of mammals have different types of syncytin protein, indicating that mammals have repeatedly borrowed retroviral proteins and repurposed them in placenta development. \u201cIt\u2019s a little mind-boggling to think that cellular fusion is directed by a virus we acquired 30 million years ago,\u201d says Lars-Inge Larsson, a pathologist at the University of Copenhagen. \n             Growth factor \n           The latest study, led by virologist Thierry Heidmann of France\u2019s National Centre for Scientific Research (CNRS) in Villejuif and the Universit\u00e9 Paris-Sud in Orsay, investigated what happens if syncytin is deleted from the mouse genome. Removal of both copies was lethal, but deletion of syncytin B while leaving syncytin A in mice resulted in male offspring that appeared small and sickly. These animals weighed 18% less than littermates with both syncytin copies. The researchers initially thought that the loss of syncytin created a malformed placenta that hampered the growth of the mice before birth. Subsequent discoveries by other labs that syncytin was active in immune cells 3  and immature muscle cells called myoblasts 4 , as well as the placenta, caused Heidmann to rethink his hypothesis. Mature muscle cells, he knew, form via the fusion of numerous immature myoblasts. Given that cellular fusion has a role in both processes, Heidmann and colleagues hypothesized that syncytin might be activated in both of these, too. Further analysis of their previous data revealed that the decrease in body weight in the male syncytin B knockout mice was due to their reduced muscle mass. Cellular studies showed that the muscles in the male knockout mice had a greater than 20% reduction of the number of muscle fibers and in the number of nuclei per fiber. \u201cWe were very, very surprised to see that the differences were in males but not females,\u201d Heidmann says. \n             Bulking up \n           Subsequent experiments by Heidmann's team followed mouse myoblasts as they matured into muscle cells and showed that both syncytin genes are active during this process, and that blocking the proteins reduced cellular fusion by more than 40%. Studies of cell cultures from sheep, dogs and humans showed similar reductions in myoblast fusion when the researchers blocked syncytin activity. \u201cThis is the first strong line of evidence that retroviral envelope proteins play an important role beyond the placenta,\u201d says Cedric Feschotte, an evolutionary biologist at the University of Utah in Salt Lake City. Heidmann stresses that syncytins are not the only important proteins in muscle fusion, and that his group still doesn\u2019t know why the proteins drive muscle growth in males but not females. And given that the syncytins in mice are derived from radically different viruses than those found in humans, Feschotte cautions against assuming that they are equally important in human muscle development. Nonetheless, he says, it is clear that these viral proteins scattered throughout our genome are much more important than anyone could have guessed. \u201cWhat we\u2019re seeing is probably just the tip of the iceberg,\u201d says Fechotte. \n                   Puppy bred to have muscular dystrophy saved by surprise mutation 2015-Nov-12 \n                 \n                   Gene-editing record smashed in pigs 2015-Oct-06 \n                 \n                   Super-muscly pigs created by small genetic tweak 2015-Jun-30 \n                 \n                   NIH invests US$41.5 million in placenta research 2015-Feb-27 \n                 \n                   Face-to-face with the earliest ancestor of all placental mammals 2013-Feb-07 \n                 \n                   Placenta to the rescue 2011-Aug-01 \n                 \n                   Ancient chimp virus brought 'back to life' 2010-Oct-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20487", "url": "https://www.nature.com/articles/nature.2016.20487", "year": 2016, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Ditching conventional electronics and power sources, the pliable robot operates without rigid parts. A squishy octopus-shaped machine less than 2 centimetres tall is making waves in the field of soft robotics. The \u2018octobot\u2019 described today in  Nature 1  is the first self-contained robot made exclusively of soft, flexible parts. Interest in soft robots has taken off  in recent years, as engineers  look beyond rigid Terminator-type machines  to designs that can squeeze into tight spaces, mould to their surroundings, or handle delicate objects safely. But engineering soft versions of key parts has challenged researchers. \u201cThe brains, the electronics, the batteries \u2014 those components were all hard,\u201d says roboticist Daniela Rus at the Massachusetts Institute of Technology in Cambridge. \u201cThis work is new and really exciting.\u201d The octobot is made of silicone rubber. Its \u2018brain\u2019 is a flexible microfluidic circuit that directs the flow of liquid fuel through channels using pressure-activated valves and switches. \u201cIt\u2019s an analogy of what would be an electrical circuit normally,\u201d says engineer Robert Wood at Harvard University in Cambridge, Massachusetts, one of the study\u2019s leaders. \u201cInstead of passing electrons around, we're passing liquids and gases.\u201d Valves and switches in the robot\u2019s brain are positioned to extend the arms in two alternating groups. The process starts when researchers inject fuel into two reservoirs, each dedicated to one group of four arms. These reservoirs expand like balloons and push fuel through the microfluidic circuit. As fuel travels through the circuit, changes in pressure close off some control points and open others, restricting flow to only one half of the system at a time. As that side consumes fuel, its internal pressure decreases, allowing fuel to enter the other side \u2014 which then pinches off the first side, and so on. \n             Building a better bot \n           The robot's brain talks to its limbs through 3D-printed channels embedded in the body. To create the body, researchers poured silicone polymers into an octopus-shaped mould. Then, using a 3D printer, they injected special inks that maintained their form and position in the surrounding polymer. The scientists heated the octobot to cure its structure, which also caused the ink to evaporate \u2014 leaving behind a hollow network that infiltrates the octobot's limbs and links to its brain. Many soft robots are tethered to compressed air tanks that provide power, but this can  restrict their range of motion . Wood and his colleagues take a different approach, using a chemical reaction to power the octobot. Their fuel is a 50% hydrogen peroxide solution. When this is exposed to platinum infused into two segments of the robot's internal network, it rapidly decomposes into a greater volume of water and oxygen. The resulting burst of pressurized gas in each segment inflates and extends one set of arms, eventually exiting through exhaust vents. \u201cThe combination of the microfluidics with the chemical reaction is really interesting,\u201d says Cecilia Laschi, a roboticist at the Sant'Anna School of Advanced Studies in Pisa, Italy. \u201cIt's a completely new and different way to see soft robots.\u201d The octobot currently runs for up to 8 minutes on 1 millilitre of fuel. It is not designed to perform any particular task, and doesn\u2019t mimic the motions of a real octopus. Instead, it demonstrates the technology, says Wood. In the future, more sophisticated microfluidic circuits might improve endurance, and allow more complex movements when paired with the appropriate limb designs, the authors suggest. \u201cNow what needs to be worked out is how to reprogram the robots to perform different actions, to respond to the environment, and not just perform a pre-programmed sequence,\u201d says materials engineer Robert Shepherd at Cornell University in Ithaca, New York. Shepherd is especially keen to see whether souped-up microfluidic circuits can be combined with flexible sensors to make smarter soft robots that are better able to adapt to changing conditions.  See the related News & Views:  'Generation soft' \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   A world where everyone has a robot: why 2040 could blow your mind 2016-Feb-24 \n                 \n                   Meet the soft, cuddly robots of the future 2016-Feb-03 \n                 \n                   'Instinctive' robot recovers from injury fast 2015-May-27 \n                 \n                   Origami robot folds itself in 4 minutes 2014-Aug-07 \n                 \n                   Explosive power makes silicone robot jump 2013-Feb-08 \n                 \n                   Artificial skins detect the gentlest touch 2010-Sep-12 \n                 \n                   Rise of the soft robots \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20489", "url": "https://www.nature.com/articles/nature.2016.20489", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Unlike 2009 tragedy, no seismic activity was recorded prior to the latest quake. \n             At 3.36 a.m. today, I was awoken by an urgent, terrifying shaking of my bed. \n           \n             This, it later emerged, was the first shock wave of the 6.2-magnitude earthquake in central Italy that has killed dozens of people \u2014 and destroyed historic villages and small towns as lovely as the one where I am now staying on holiday. It was a sinister d\u00e9j\u00e0 vu \u2014 in 2009 I was awoken in Rome by an even more powerful quake \u2014 the one that destroyed L'Aquila. The clock stood at 3.33 a.m. \n           Nature 's senior European correspondent Alison Abbott, who was in nearby Tuscania when the earthquake struck this morning, sent over these impressions. The earthquake, the death toll of which has now risen to 250 according to Italy's civil protection agency, is the strongest in Italy since the devastating magnitude-6.3 earthquake in 2009 near the town of L'Aquila. That event killed about 300 people and destroyed tens of thousands of homes \u2014 and, controversially, caused a group of scientists to be put on trial for manslaughter. The shocks in the small hours of this morning have again caused death, destruction and panic, leaving the centre of Amatrice, a town in the Apennine Mountains in central Italy, in ruins. Central Italy\u2019s geologically and tectonically complex make-up creates a notorious quake risk. The Adria micro-plate dives beneath the Apennine Mountain range from east to west, creating seismic strain. The mighty Eurasian and African plates, which build the Alps in northern Italy, also collide here. This creates further strain, with the Eurasian plate moving northeast at a rate of 24 millimetres per year. \n             Expected rupture \n           The latest quake is the outcome of a normal faulting event, and is a result of the east\u2013west movement of the Adria plate under the Apennines occurring faster than the collision of the Eurasian and African plates,  according to a preliminary analysis by the US Geological Survey . Seismologists had expected a rupture to occur near the location of today\u2019s quake at any time. Fitting into a seismic sequence, this morning's shocks occurred in a geographical gap between a series of earthquakes in 1997 some 50 kilometres farther northwest, and the L'Aquila quake in 2009 some 45 kilometres to the southeast. Alessandro Amato, a geologist at Italy's National Institute of Geophysics and Volcanology in Rome, awoke to the shocks from dreaming that someone had knocked wildly at his door. Having done some computer modelling since, he says that there is a risk of severe aftershocks in the next hours or weeks. \u201cThe quake may have activated adjacent faults as happened in 1997,\u201d he says. \u201cWe expect a number of aftershocks of decreasing magnitude. But we can't say when and exactly where they will occur.\u201d \n             Legal aftermath \n           Unlike in 2009, there was no seismic activity recorded before today\u2019s quake. Controversy over the significance of alleged precursor tremors to the 2009 quake had  legal ramifications . Six scientists and one government official who had publicly dismissed a warning by a local amateur researcher who claimed to have evidence of an imminent large quake\u00a0were accused of misinforming the public. Following an unprecedented trial of the scientists that drew international attention, they were given six-year jail sentences for manslaughter in 2012, but the scientists were cleared on appeal in 2014.\u00a0 Today's quake, which shares some similarities with the 2009 event, is a continuation of the region's expected tectonic activity. But, says Amato, \u201cpredicting earthquakes reliably is but a distant dream\u201d. No damages were reported at the National Institute of Nuclear Physics\u2019s (INFN\u2019s) laboratories in the area in Frascati near Rome and underground at the Gran Sasso Massif near L\u2019Aquila, says Antonella Varaschin, a spokesperson at the INFN headquarters in Rome. Further details on the quake are still emerging, and the death toll may continue to rise. The atmosphere in Tuscania is pensive. Abbott says: \u201cTaking a coffee this morning in Tuscania, which was itself extensively damaged by a deadly quake in 1971, the talk was sad, calm, of 'fate'.\u201d Additional reporting by Davide Castelvecchi. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Italian seismologists cleared of manslaughter 2014-Nov-10 \n                 \n                   Italian seismologists fight to overturn convictions 2014-Oct-20 \n                 \n                   Research from rubble 2009-May-20 \n                 \n                   USGS earthquake report \n                 \n                   National Institute of Geophysics and Volcanology \n                 Reprints and Permissions"},
{"file_id": "536386b", "url": "https://www.nature.com/articles/536386b", "year": 2016, "authors": [{"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "US agencies have adopted stronger policies but have not always followed them. As Barack Obama prepares to leave office,  Nature  examines the scientific highs and lows of his presidency. Read the other stories in this series about his policies on  biomedicine ,  space  and  climate change . Many researchers who watched Barack Obama\u2019s inauguration in 2009 were thrilled by his pledge to \u201c restore science to its rightful place \u201d. But scientists and legal scholars say that, in many ways, Obama has failed to live up to that lofty promise. In general, government researchers have enjoyed more freedom \u2014\u00a0and endured less political meddling\u00a0\u2014\u00a0than they did under the previous president, George W. Bush. Bush\u2019s administration was accused of muzzling or  ignoring scientists  on subjects ranging from  stem cells  to  climate change . In March 2009, Obama instructed agencies to develop policies to  reduce political interference and increase transparency  about the research used in policy decisions. And when the Union of Concerned Scientists (UCS) surveyed federal researchers in 2015, most said that their agency adhered to its scientific-integrity policy. But critics say that Obama\u2019s White House has not shied away from exerting political influence over science. In 2011, the Environmental Protection Agency (EPA) sent a proposal to the White House that would strengthen controls on ozone pollution, based on guidance from its scientific advisers. But Obama directed the agency to withdraw the plan, citing the cost of the stricter limits at a time when the economy was still recovering from a recession. And that same year, Health and Human Services secretary Kathleen Sebelius  overruled the Food and Drug Administration\u2019s finding  that the emergency contraceptive \u2018Plan B One-Step\u2019 was safe to dispense over the counter for all women and girls. In both cases, science eventually won out: the EPA approved stronger ozone standards in 2015, and the FDA approved unrestricted sales of Plan B in 2013 after judges ruled against the agency. Nevertheless, these examples show how political considerations have sometimes trumped scientific ones during Obama\u2019s tenure, says Lisa Heinzerling, a law professor at Georgetown University in Washington DC. \u201cThere are structures in place that threaten scientific integrity and encourage the injection of politics into matters that are supposed to be scientific or technical,\u201d says Heinzerling, who worked at the EPA for two years under Obama. Science advocates are concerned about how political influence shapes science behind closed doors at the White House. The president\u2019s Office of Management and Budget, which reviews proposals for new rules and regulations, can make substantial changes or kill a policy without explaining why. \u201cIn some cases, the White House is messing around, and it\u2019s not doing it transparently,\u201d says Wendy Wagner, a law professor at the University of Texas at Austin. The recent UCS survey revealed room for improvement at several agencies. Nearly half the scientists at the Centers for Disease Control and Prevention said that their agency gave too much weight to political interests; that proportion rose to 73% at the Fish and Wildlife Service. And less than 60% of scientists at the four agencies surveyed said they could openly express concerns about the work of their employer without fear of retaliation. \u201cWe have a lot of new policies and pro-cedures in place that are tremendously beneficial,\u201d says Gretchen Goldman, a UCS analyst who led the study. \u201cBut what we\u2019re finding is that there\u2019s more work to be done.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                   \n                     Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                   \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     US science: The Obama experiment 2012-Sep-26 \n                   \n                     Integrity policy unveiled at last 2010-Dec-20 \n                   \n                     Union of Concerned Scientists survey on transparency and research integrity at federal agencies \n                   \n                     White House list of agencies\u2019 scientifc-integrity policies \n                   Reprints and Permissions"},
{"file_id": "536387a", "url": "https://www.nature.com/articles/536387a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "President sidesteps Congress to curb US greenhouse-gas emissions. As Barack Obama prepares to leave office,  Nature  examines the scientific highs and lows of his presidency. Read the other stories in this series about his policies on  biomedicine ,  space  and  research integrity . Global warming was one of Barack Obama\u2019s top priorities \u2014 and one of the most difficult to address, given strong opposition from Republicans in Congress. Yet he managed to help broker a global climate accord and push through regulations to curb greenhouse-gas emissions from cars, trucks and power plants. \u201cObama has established a terrific climate legacy,\u201d says David Doniger, who directs the climate and clean-air programme at the Natural Resources Defense Council, an advocacy group in New York. The president\u2019s earliest actions capitalized on the global financial crisis. In February 2009, Obama signed  economic-stimulus legislation  that included nearly $37\u00a0billion for clean-energy research and development (R&D) at the Department of Energy. Four months later, with failing car companies seeking a federal bailout, the Obama administration proposed higher fuel-efficiency requirements and the first greenhouse-gas standards for passenger vehicles. Theregulations, which took effect in 2012, will nearly double the average fuel efficiency of vehicles by 2025, to around 23\u00a0kilometres per litre. And after his campaign for a comprehensive climate bill failed in 2010, an emboldened Obama  used existing laws to issue regulations  that curbed greenhouse-gas emissions, bolstered energy-efficiency standards and  expanded energy R&D programmes . But the president\u2019s big push on climate came in advance of the United Nations climate summit in Paris in 2015. He committed the United States to reduce emissions by at least 26% below 2005 levels by 2025, and negotiated directly with countries such as China to build support for a global climate agreement. The final version,  adopted on 12\u00a0December , aims to hold average global temperatures to 1.5\u20132\u2009\u00b0C above pre-industrial levels. \u201cParis is a major achievement for the world,\u201d says Robert Socolow, a climate scientist at Princeton University in New Jersey. \u201cI don\u2019t think it would have happened without Obama.\u201d Yet Obama\u2019s domestic achievements could be undone by legal challenges. In February, the US Supreme Court temporarily  blocked a federal regulation  to reduce emissions from existing power plants. The fate of that rule\u2014 the cornerstone of Obama\u2019s plan to reduce emissions \u2014 could depend on the election in November. The Supreme Court is down one member and the next president will choose a replacement, who could decide whether the climate rule stands. Some environmental experts say that Obama should have pushed harder for a comprehensive climate bill, rather than settling for piecemeal regulations. \u201cAll of these things are actually small bites at the apple that won\u2019t achieve meaningful emissions reductions over time,\u201d says Catrina Rorke, director of energy policy at the R\u00a0Street Institute, a conservative think tank in Washington\u00a0DC. Others criticize Obama for encouraging a vast expansion of domestic oil and gas development, even as he sought to wean the country off coal and curb its greenhouse-gas emissions. \u201cThe administration is still trying to have it both ways,\u201d says Stephen Kretzmann, executive director of Oil Change International, an advocacy group in Washington\u00a0DC. Obama  rejected the Keystone XL pipeline , which would have carried oil from the Canadian tar sands to US refineries, and has said that some fossil fuels should be kept \u201cin the ground\u201d. But his administration continues to push an \u2018all-of-the-above\u2019 energy strategy that leads to higher production of domestic fossil fuels, Kretzmann says. Nonetheless, Obama has helped to change the conversation about global warming at home and abroad, says Doniger. \u201cThe next president needs to do more,\u201d he says, \u201cbut did the Obama administration move the ball forward? They sure did.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Obama\u2019s science legacy: uneven progress on scientific integrity 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                   \n                     Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                   \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     US Supreme Court puts Obama climate regulations on hold 2016-Feb-10 \n                   \n                     Nations approve historic global climate accord 2015-Dec-12 \n                   \n                     Keystone XL decision puts spotlight on US climate politics 2015-Nov-06 \n                   \n                     Obama acts alone on climate 2015-Jan-27 \n                   \n                     US science: The Obama experiment 2012-Sep-26 \n                   \n                     EPA Clean Power Plan \n                   \n                     Paris Climate Agreement \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20471", "url": "https://www.nature.com/articles/nature.2016.20471", "year": 2016, "authors": [{"name": "Jane Qiu"}], "parsed_as_year": "2006_or_before", "body": "Climate change could be to blame for Tibetan tragedy. One of the world's largest documented ice avalanches is flummoxing researchers. But they suspect that glacier fluctuations caused by a changing climate may be to blame. About 100 million cubic metres of ice and rocks gushed down a narrow valley in Rutog county in the west of the Tibet Autonomous Region on 17 July, killing nine herders and hundreds of sheep and yaks. The debris covered nearly 10 square kilometres at a thickness of up to 30 metres, says Zong Jibiao, a glaciologist at the Chinese Academy of Sciences\u2019 Institute of Tibetan Plateau Research (ITPR) in Beijing, who completed a field investigation of the site last week. The only other known incident comparable in scale is the 2002 ice avalanche from the Kolka Glacier 1 , 2  in the Caucasus Mountains in Russia, says Andreas K\u00e4\u00e4b, a glaciologist at the University of Oslo in Norway. That catastrophic event killed 140 people. Preliminary analyses show that the Rutog avalanche was unusual because it started from a flat point at 5,200\u20136,200 metres above sea level rather than in steep terrain. The ice crashed down nearly one kilometre along the narrow gully and ran into the Aru Co lake, 6 kilometres away. \u201cThe site of collapse is baffling \u2026 the Rutog avalanche initiated at quite a flat spot. It doesn\u2019t make sense,\u201d says Tian Lide, a glaciologist also at the ITPR, who runs a research station in Rutog. Zong adds: \u201cIt went with such a force that the gully was widened out by the process.\" \n             Glacier surge \n           This force is likely to have been caused by lubrication of the ice from rain or glacial melt, and researchers think that increasing precipitation in recent years may be partly to blame. Temperatures in Tibet  have soared by 0.4 \u00b0C per decade since 1960 \u2014 twice the global average. Warming can generate meltwater that carves out a glacier from within, making it vulnerable to collapse, says Tian. K\u00e4\u00e4b thinks that both the Kolka and Rutog avalanches could have been triggered by a rare glacier surge, in which a glacier periodically advances 10\u2013100 times faster than its normal speed. The phenomenon affects about 1% of glaciers globally. Western Tibet has many surge-type glaciers, and some researchers suspect that climate change at high elevations could affect the frequency of surges 3 . Regardless of what triggered the Rutog avalanche, \u201cclimate change is causing more glacial hazards through mechanisms we don\u2019t fully understand\u201d, says Tian. \u201cThere is an urgent need for more monitoring and research efforts, especially in populated areas in high mountains.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Killer landslides: The lasting legacy of Nepal\u2019s quake 2016-Apr-25 \n                 \n                   Nepal earthquake caused fewer landslides than feared 2015-Dec-16 \n                 \n                   Human error is behind many avalanche deaths 2015-Aug-31 \n                 \n                   Landslide risks rise up agenda 2014-Jul-15 \n                 \n                   Avalanche hotspot revealed 2014-May-07 \n                 \n                   http://english.itpcas.cas.cn \n                 \n                   Third Pole Environment \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20445", "url": "https://www.nature.com/articles/nature.2016.20445", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Planet orbiting Proxima Centauri is likely to be the focus of future interstellar voyages. Proxima Centauri, the star closest to the Sun, has an Earth-sized planet orbiting it at the right distance for liquid water to exist. The discovery, reported today in  Nature 1 , fulfils a longstanding dream of science-fiction writers \u2014 a potentially habitable world that is close enough for humans to send their first interstellar spacecraft. \u201cThe search for life starts now,\u201d says Guillem Anglada-Escud\u00e9, an astronomer at Queen Mary University of London and leader of the team that made the discovery. Humanity\u2019s first chance to explore this nearby world may come from the recently announced Breakthrough Starshot initiative,  which plans to build fleets of tiny laser-propelled interstellar probes  in the coming decades. Travelling at 20% of the speed of light, they would take about 20 years to cover the 1.3 parsecs from Earth to Proxima Centauri. How a science-fiction story about our nearest neighbour became a reality Proxima\u2019s planet is at least 1.3 times the mass of Earth. The planet orbits its red-dwarf star \u2014 much smaller and dimmer than the Sun \u2014 every 11.2 days. \u201cIf you tried to pick the type of planet you\u2019d most want around the type of star you\u2019d most want, it would be this,\u201d says David Kipping, an astronomer at Columbia University in New York City. \u201cIt\u2019s thrilling.\u201d Earlier studies had hinted at the existence of a planet around Proxima. Starting in 2000, a spectrograph at the European Southern Observatory (ESO) in Chile looked for  shifts in starlight caused by the gravitational tug of an orbiting planet . The resulting measurements suggested that something was happening to the star every 11.2 days. But astronomers could not rule out whether the signal was caused by an orbiting planet or another type of activity, such as stellar flares. \n               Star and planet align \n             In January 2016, Anglada-Escud\u00e9 and his colleagues launched a campaign to nail down the suspected Proxima planet. ESO granted their request to observe using a second planet-hunting instrument, on a different telescope, for 20 minutes almost every night between 19 January and 31 March. \u201cAs soon as we had 10 nights it was obvious,\u201d Anglada-Escud\u00e9 says. The team dubbed the work the \u2018pale red dot\u2019 campaign, after the famous 'pale blue dot' photograph taken of Earth by the Voyager 1 spacecraft in 1990. Because Proxima is a red-dwarf star, the planet would appear reddish or orangeish, perhaps bathed in light similar to the warm evening tints of Earth. Although the planet orbits at a distance that would permit liquid water, other factors might render it unlivable. It might be tidally locked \u2014 meaning that the same hemisphere always faces the star, which scorches one side of the planet while the other remains cool. The active star might occasionally zap the planet with destructive X-ray flares. And it's unclear whether the planet has a protective, life-friendly atmosphere. Proxima itself belongs to the triple-star system Alpha Centauri. In 2012, a  Nature  paper reported that  an Earth-mass planet orbited another member of that stellar trio , Alpha Centauri B 2 . That result has now mostly been dismissed 3 , 4 , but exoplanet specialists say the Proxima claim is more likely to hold up. \u201cPeople call me Mr Sceptical, and I think this result is more robust,\u201d says Artie Hatzes, an astronomer at the Thuringian State Observatory in Tautenburg, Germany. \n               False alarm \n             This time, the combination of new observations and older measurements dating back to 2000 increases confidence in the finding, Anglada-Escud\u00e9\u2019s team argues. \u201cIt\u2019s stayed there robustly in phase and amplitude over a very long time,\u201d says team member Michael Endl, an astronomer at the University of Texas at Austin. \u201cThat\u2019s a telltale sign of a planet.\u201d The data even contain hints that a second planet may exist, orbiting Proxima somewhere between every 100 and 400 days. The researchers now hope to learn whether the Proxima planet's pass across the face of its star can be seen from Earth. The chances are low, but such a \u2018transit\u2019 could reveal details of the planet, such as whether it has an atmosphere. A team led by Kipping has been independently looking for transits around Proxima, and is frantically crunching its data in search of any signal. The discovery of the Proxima planet comes at a time of growing scientific interest in small planets around dwarf stars, says Steinn Sigurdsson, an astrophysicist at Pennsylvania State University in University Park.  NASA\u2019s Kepler space telescope  has shown that rocky planets are common around such stars, which themselves are the most common type of star in the Galaxy. \u201cThis is a total vindication of that strategy,\u201d he says. One day, the Proxima planet might be seen as the birth of a new stage in planetary research. \u201cIt gives us the target and focus to build the next generation of telescopes and one day maybe even get to visit,\u201d says Kipping. \u201cIt's exactly what we need to take exoplanetary science to the next level.\u201d See News & Views:  Earth-like planet around Sun\u2019s neighbour \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Billionaire backs plan to send pint-sized starships beyond the Solar System 2016-Apr-13 \n                   \n                     The truth about exoplanets 2016-Feb-17 \n                   \n                     Rebooted Kepler spacecraft hauls in the planets 2016-Jan-07 \n                   \n                     The exoplanet files 2015-Nov-18 \n                   \n                     Climate scientists join search for alien Earths 2015-Apr-17 \n                   \n                     The exoplanet next door 2012-Oct-16 \n                   \n                     Pale Red Dot \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20491", "url": "https://www.nature.com/articles/nature.2016.20491", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Evolution of mathematics traced using unusually comprehensive genealogy database. Most of the world\u2019s mathematicians fall into just 24 scientific 'families', one of which dates back to the fifteenth century. The insight comes from an analysis of the  Mathematics Genealogy Project (MGP) , which aims to connect all mathematicians, living and dead, into family trees on the basis of teacher\u2013pupil lineages, in particular who an individual's doctoral adviser was. The analysis also uses the MGP \u2014 the most complete such project \u2014 to trace trends in the history of science, including the emergence of the United States as a scientific power in the 1920s and when different mathematical subfields rose to dominance 1 . \u201cYou can see how mathematics has evolved in time,\u201d says Floriana Gargiulo, who studies networks dynamics at the University of Namur, Belgium and who led the analysis. The MGP is hosted by North Dakota State University in Fargo and co-sponsored by the American Mathematical Society. Since the early 1990s, its organizers have mined information from university departments and from individuals who make submissions regarding themselves or people they know about. As of 25 August, the MGP contained 201,618 entries. As well as doctoral advisers (PhD advisers in recent times) and pupils of academic mathematicians, the organizers record details such as the university that awarded the doctorate. \n               Distinct families \n             Previously, researchers had used the MGP to reconstruct their own PhD-family trees, or to see how many \u2018descendants\u2019 a researcher has (readers can  do their own search here ).\u00a0Gargiulo's team wanted to make a comprehensive analysis of the entire database and divide it into distinct families, rather than just looking at how many descendants any one person has. After downloading the database, Gargiulo and her colleagues wrote machine-learning algorithms that cross-checked and complemented the MGP data with information from Wikipedia and from scientists' profiles in the Scopus bibliographic database. This revealed 84 distinct family trees with two-thirds of the world\u2019s mathematicians concentrated in just 24 of them. The high degree of clustering arises in part because the algorithms assigned each mathematician just one academic parent: when an individual had more than one adviser, they were assigned the one with the bigger network. But the phenomenon chimes with anecdotal reports from those who research their own mathematical ancestry, says MGP director Mitchel Keller, a mathematician at Washington and Lee University in Lexington, Virginia. \u201cMost of them run into Euler, or Gauss or some other big name,\u201d he says. Although the MGP is still somewhat US centric, the goal is for it to become as international as possible, Keller says. Peculiarly, the progenitor of the largest family tree is not a mathematician but a physician: Sigismondo Polcastro, who taught medicine at the University of Padua in Italy in the early fifteenth century. He has 56,387 descendants according to the analysis. The second-largest tree is one started by a Russian called Ivan Dolbnya in the late nineteenth century. \n               Tracking history \n             The authors also tracked mathematical activity by country, which seemed to pinpoint major historical events. Around the time of the dissolution of the Austro-Hungarian Empire in the First World War, there is a decline in mathematics PhDs awarded in the region, notes Gargiulo. Between 1920 and 1940, the United States took over from Germany as the country producing the largest number of mathematics PhDs each year. And the ascendancy of the Soviet Union is marked by a peak of PhDs in the 1960s, followed by a relative fall after the break-up of the union in 1991. Gargiulo\u2019s team also looked at the dominance of mathematical subfields relative to each other. The researchers found that dominance shifted from mathematical physics to pure maths during the first half of the twentieth century, and later to statistics and other applied disciplines, such as computer science. Idiosyncrasies in the field of mathematics could explain why it has the most comprehensive genealogy database of any discipline. \u201cMathematicians are a bit of a world apart,\u201d says Roberta Sinatra, a network and data scientist at Central European University in Budapest who led a 2015 study that mapped the evolution of the subdisciplines of physics by mining data from papers on the Web of Science 2 . Mathematicians tend to publish less than other researchers, and they establish their academic reputation not so much on how much they publish or on their number of citations, but on who they have collaborated with, including their mentors, she says. \u201cI think it\u2019s not a coincidence that they have this genealogy project.\" At least one discipline is trying to catch up. Historian of astronomy Joseph Tenn of Sonoma State University in California plans by 2017 to launch the  AstroGen project  to record the PhD advisers and students of astronomers. \u201cI started it,\" he says, \"because so many of my colleagues in astronomy admired and enjoyed perusing the Mathematics Genealogy Project.\" Davide Castelvecchi's  genealogy goes back to Leonhard Euler, via Joseph-Louis Lagrange; to Friedrich Leibniz, the father of the co-inventor of calculus; and to thirteenth-century Persian astronomer Shams ad-Din Al-Bukhari. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Text-mining block prompts online response 2015-Nov-20 \n                   \n                     Crowd-sourcing: Strength in numbers 2014-Feb-26 \n                   \n                     Scientific families: Dynasty 2013-Jan-16 \n                   \n                     The Mathematics Genealogy Project \n                   \n                     A Labor of Love: The Mathematics Genealogy Project \n                   \n                     The Astronomy Genealogy Project \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20492", "url": "https://www.nature.com/articles/nature.2016.20492", "year": 2016, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Over 1,200 sign open letter to President Jacob Zuma warning universities are at a tipping point. More than 1,200 South African academics are warning that the country's university system is at a tipping point as a result of chronic underfunding. The researchers from 18 South African universities have signed an open letter to the president Jacob Zuma, higher education and training minister Blade Nzimande and finance minister Pravin Gordhan. The letter, sent on 11 August and also published in the national weekly newspaper the  Mail & Guardian  on 15 August , calls on the government to address the \u201cfunding crisis\u201d in higher education. \u201cThe core functions of universities are being put under threat,\u201d the letter says. \u201cWe have reached a limit. We simply cannot weather any further cuts without jeopardizing the academic project.\u201d It comes amid a  backdrop of student protests  at rising tuition fees, strained university resources and a government inquiry into free undergraduate education \u2014 which critics say South Africa cannot afford. The country is in austerity, with an economic growth forecast of 0% for the year. Student protests against a proposed 6.3% fee hike have already led to the closure of campuses at the University of KwaZulu-Natal and Mangosuthu University of Technology earlier this month. \n             Student protests \n           \u201cWe're at a tipping point. If the current trajectory continues and the state does not intervene, then we're going to see a period of austerity which will undermine our public universities,\" warns Noor Nieftagodien, a historian at the University of Witwatersrand in Johannesburg. He coordinated the open letter with colleague Kelly Gillespie at the School of Social Sciences in response to budget cuts at the school, with the hope of engaging the wider academic community. \u201cAcademics have tended to respond to these issues from their institutional base. We wanted to get as many academics as possible, irrespective of institution, geography and discipline,\u201d he says. South Africa's university system is funded by government subsidies, student fees, research contracts and investments. The latest figures show that it cost about 60.6 billion rands (US$4.3 billion) in 2014. But the government's portion of this has been steadily declining for more than a decade \u2014 whereas student numbers have almost tripled from 360,250 to 983,698 over the past 22 years. In 2000, government grants covered about 49% of university income, falling to about 40% by 2009. To make up the shortfall, universities have increased student fees each year for more than a decade. This resulted in the #FeesMustFall student protests last year after universities tried to raise fees by 10\u201312%. \n             Research impact \n           The government agreed a zero fee increase in 2016. But Ed Rybicki, a virologist at the University of Cape Town who signed the letter, says budgets are getting tighter, in part thanks to this. Saleem Badat, a programme director at philanthropic organization the Mellon Foundation in New York and former head of Higher Education South Africa says he has \"grave concerns\" about another fee freeze in 2017. \u201cI fear it may lead to the slow demise of South African universities,\u201d he says. Compounding the issue, at some universities, the management agreed to student demands to in-source all workers, costing hundreds of millions of rands annually. The University of Cape Town put out a call for voluntary early retirement and severance in May this year to help cut costs. All this may have an impact on research. \u201cAnything that potentially could jeopardize the sustainability of the university system has a direct implication in terms of our ability to generate new knowledge and increase research,\u201d says Molapo Qhobela, head of the National Research Foundation in Pretoria, which funds the majority of the country's research. Khaye Nkwanyana, spokesman for the Department of Higher Education and Training in Pretoria, says he would \u201csee if any officials had the appetite to respond\u201d to media questions about the open letter. The department had not responded by the time of writing. \n                   South Africa\u2019s political turmoil endangers research 2016-Jul-13 \n                 \n                   Giant SKA telescope rattles South African community 2016-Jun-22 \n                 \n                   South Africa's research spending slows down 2013-May-17 \n                 \n                   http://www.natureindex.com/news-blog/south-african-research-hits-hard-economic-times?utm_source=NI_facebook&utm_medium=social&utm_campaign=news \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20505", "url": "https://www.nature.com/articles/nature.2016.20505", "year": 2016, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Omid Kokabee, who became seriously ill while serving time on controversial treason charges, will now be allowed to leave the country. Omid Kokabee, a physicist convicted of espionage in Iran, has been granted freedom on parole, his lawyer announced on 29 August. It could be the end of a five-year-long struggle for the Iranian scientist, who has said all along that he was punished for refusing to help a covert nuclear-weapons programme. Kokabee, who is now 34 years old, was working on his PhD thesis in Spain and in the United States when he was jailed in Tehran in early 2011 while attempting to fly back to the United States after visiting his native country. He was later  convicted for \u201cillegal earnings\u201d and \"communication with a hostile government \", accusations which are tantamount to spying. Kokabee maintained his innocence and later stated that he had been  persecuted for refusing to cooperate  with a nuclear military programme in Iran. He had expertise with a type of laser that can be used for isotope separation, a step in the production of enriched uranium for nuclear weapons. Last April, Kokabee was moved to hospital to have a kidney removed due to cancer. He was then  granted a temporary medical leave  and released after his friends posted a bail for him of 5 billion Iranian rials (US$165,000). But that status had to be renewed every two weeks. Having already served more than one-third of his sentence, he was eligible for parole according to Iranian law. The head of the judiciary has now allowed it, after turning down several previous requests from Kokabee's lawyer. If the judiciary decided to revoke the parole for some reason, he could be brought back to prison to serve the remaining three years of his sentence. However, sources in Iran who are familiar with his case told  Nature  that Kokabee will be allowed to leave the country while he is on parole. During his time in prison, Kokabee received the support of several scientific and human-rights organizations, including awards  from the American Physical Society  and the  American Association for the Advancement of Science , and a letter signed by more than 30 Nobel laureates. In a separate case,  Shahram Amiri , another Iranian physicist allegedly related to the country's nuclear programme and accused of espionage, was executed earlier this month in Iran. \n                   Jailed Iranian physicist released on bail 2016-May-25 \n                 \n                   Iranian says he was jailed for refusing to engage in military research 2013-Apr-26 \n                 \n                   Iranian physicist sentenced to prison 2012-May-15 \n                 \n                   2014 Andrei Sakharov Prize of the American Physical Society \n                 \n                   2014 AAAS Scientific Freedom and Responsibility Award \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20493", "url": "https://www.nature.com/articles/nature.2016.20493", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "August\u2019s sharpest science shots, selected by  Nature\u2019s  photo team. \n             Zika in Cuba \n           Clouds of pesticide, such as this one, regularly waft through Cuba\u2019s neighbourhoods. It is one of the measures that has kept the Zika virus at bay, although the disease has now arrived even in Cuba. Desmond Boylan, who accompanied  Nature  reporter Sara Reardon on  a recent trip to the island , took this shot earlier in 2016. \n             Burning problem \n           Drought in California is becoming an annual occurrence, which means that devastating wildfires are too. In this 17 August photo, embers from a blaze are seen near Keenbrook. \n             Water damage \n           While California longs for rain, people in other parts of the United States are cursing devastating floods. Thousands fled rising water levels in Louisiana this month, shown here at Denham Springs in the state. Several people have been killed and a state of emergency has been declared. \n             Ultimate disco \n           Ali Ert\u00fcrk at the Ludwig Maximilians University of Munich in Germany and his colleagues  have created a technique called ultimate DISCO  which removes pigments and lipids from the tissues of dead animals. Their method also shrinks bodies by up to 65%, making it possible to image whole animals using a technique called light-sheet microscopy. \n             Borderlands \n           Davide Gaglio captured this sunrise at Kgalagadi Park, which lies on the border between South Africa, Botswana and Namibia. It won the overall prize in  the BMC Ecology Image Competition 2016 . \n             DNA labyrinth \n           This labyrinth is made of closely packed DNA molecules,  created on a biochip  by a team who have developed a method to make one-dimensional fibres 20 nanometres wide and 70 micrometres long. \n             Hidden Degas \n           Researchers probing the circa 1880s  Portrait of a Woman  by Edgar Degas with X-rays  have revealed another woman\u2019s portrait  under the oil paint. \n             Microbial menagerie \n           Environmental microbiologist Marilyn Roossinck presents the story of 101 viruses in her recently published book, and shows portraits of them in electron-microscopy images that  Nature \u2019s reviewer found  \u201chave more than a passing resemblance to the paintings of Jackson Pollock and Wassily Kandinsky\u201d. \n             Blooming corpse \n           This time-lapse video shows the New York Botanical Gardens\u2019  Amorphophallus titanum  coming into bloom and then collapsing. Although it looks pretty, this huge blossom is called the corpse flower for a reason \u2013 it stinks to high heaven. \n                   Cruising sharks, fiery dragons and invisible dust 2016-Jul-29 \n                 \n                   Spacemen returning, high-tech turtles and an Antarctic rescue 2016-Jun-24 \n                 Reprints and Permissions"},
{"file_id": "537019a", "url": "https://www.nature.com/articles/537019a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Digital scans will help researchers test whether she fell out of a tree. The world\u2019s most famous fossil is now open source. 3D scans of Lucy \u2014\u00a0a 3.18-million-year-old hominin found in Ethiopia \u2014\u00a0were released on 29\u00a0August, allowing anyone to examine her arm, shoulder and knee bones and even make their own 3D-printed copies. The scans accompany a  Nature  paper that argues that Lucy, a human relative belonging to the species  Australopithecus afarensis , died after falling from a tree ( J.Kappelmanetal.Naturehttp://dx.doi.org/10.1038/nature19332;2016 ). The team behind the paper also made the scans available to the public and is eager for other researchers to test the hypothesis by printing out the bones. \u201cIt\u2019s one thing for me to describe it in detail in paper, but it\u2019s another thing to hold these things, to be able to print them out, look at them and put them together,\u201d says team leader John Kappelman, a palaeoanthropologist at the University of Texas at Austin. His team received approval from the National Museum of Ethiopia and the country\u2019s government to make the models of Lucy public. \u201cMy sense from the Ethiopians is that Lucy is not only their national treasure, but they see her as a treasure for humankind,\u201d says Kappelman, who hopes that the country will soon release digital scans of the rest of Lucy and that other countries may follow suit with other hominin fossils. \u201cComing from Ethiopia, it really is a positive step, because other countries that are hesitant may be willing to do the same thing,\u201d says Louise Leakey, a palaeontologist at Stony Brook University in New York. But Kappelman and others say that such a move could threaten cash-strapped museums \u2014 many of them in Africa \u2014\u00a0that rely on income generated from casts of their fossil collections to help them survive. Lucy\u2019s digital debut was eight years in the making. Her 40%-complete remains spent 10 days in Kappelman\u2019s lab in August 2008 during a US tour. His team worked day and night to scan every one of several hundred bone fragments using a computed-tomography (CT) imager. Close examination revealed unusual fractures: the end of her right humerus that connected to her shoulder had a series of clean breaks and compressions similar to those that orthopaedic surgeons often see in people who attempt to break a fall with an outstretched arm. Damage to Lucy\u2019s pelvis, left shoulder and knee and right ankle was also consistent with a fall from a great height. Kappelman\u2019s team estimates that Lucy fell from a tree taller than 10 metres and died from her injuries, reaching a speed of up to 60 kilometres per hour at impact. \n               Arboreal origins \n             It\u2019s unclear how suited Lucy was to arboreal life. She walked upright, but she may have held onto adaptations that helped her ancestors cope with trees \u2014 although that idea is hotly debated. Kappelman\u2019s team proposes that Lucy would have slept in trees to avoid predators, yet was not as adroit there as her more-ape-like ancestors. \u201cHere\u2019s the most famous fossil on the planet, the centre of the debate over arborealism in human evolution, and we think it\u2019s most likely she died from a fall out of tree,\u201d he says. But Marc Meyer, a palaeoanthropologist at Chaffey College in Rancho Cucamonga, California, who recently examined Lucy in Addis Ababa, is sceptical. Chimpanzees tend to break their spines when they fall from trees, says Meyer, and \u201cLucy\u2019s spine does not come close to the amount of damage we would expect to see in a fatal fall\u201d. Lucy\u2019s discoverers noticed her broken bones when they found her, but proposed that this had occurred after she died. Donald Johanson, the palaeoanthropologist at Arizona State University in Tempe  who found Lucy in 1974 , still stands by that interpretation. Broken bones such as Lucy\u2019s are common in other nearby remains, he notes. Kappelman is keen for others to test their theory. Digital models of portions of Lucy\u2019s left knee and right shoulder and arm are available at eLucy.org. But although printed bones and virtual models can be helpful, Meyer says there is no substitute for seeing a fossil in person. He found stark differences between  Ardipithecus ramidus , a 4.4-million-year-old hominin also found in Ethiopia, and a physical cast that he studied, including several deformities not captured in the cast. \n               Digital downloads \n             Digital models of hominin fossils are rare, but a few are available. About 100 of the 1,500 remains ascribed to  Homo naledi ,  uncovered in 2013 in a South African cave system , can be downloaded at MorphoSource.org, as can models of the 2-million-year-old  Australopithecus sediba  found by the same team in 2008. AfricanFossils.org , which distributes digital models of hominin fossils for education and is headed by Leakey, contains numerous important specimens from Kenya. But the website\u2019s models, although sufficient for 3D printing in many cases, are purposefully low in resolution, so as not to cut into income generated from making physical replicas. Kappelman would like to see such revenue streams maintained, for instance by making lower-quality models free while charging researchers for good digital reproductions. \u201cWhat has to be done is to put together a good business model that allows these museums to be able to have some sort of revenue stream off of these data,\u201d he says. Leakey, however, thinks that charging researchers will further limit access. She also points out that digital models can easily be pirated. \u201cThe days of keeping this content squirrelled away are gone,\u201d she says. \u201cOnce you make a 3D model available, to control it is impossible.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @ewencallaway \n               \n                     Crowdsourcing digs up an early human species 2015-Sep-10 \n                   \n                     New species of early human discovered near fossil of \u2018Lucy\u2019 2015-May-27 \n                   \n                     Lucy discoverer on the ancestor people relate to 2014-Nov-21 \n                   \n                     3D images remodel history 2014-Jun-17 \n                   \n                     Palaeontology: Free digital scans of human fossils 2013-May-08 \n                   \n                     Ancient human ancestor had feet like an ape 2012-Mar-28 \n                   \n                     Oldest hominid skeleton revealed 2009-Oct-01 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20494", "url": "https://www.nature.com/articles/nature.2016.20494", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "From birds to coastlines, drones take data collection to a whole new level. Drones are increasingly making their way into remote locations, violent storms and hazardous habitats for scientific purposes. The technology is so popular that the US Federal Aviation Administration (FAA) is stepping in with new rules governing  how drones are operated  for research uses, among others. The rules, which take effect on 29 August, include limitations such as daylight-only operations, weight specifications and line-of-sight restrictions. It's not necessarily bad news for scientists, though. \u201cThe FAA makes things much simpler for us,\u201d says Peter Traykovski, an engineer at the Woods Hole Oceanographic Institution in Massachusetts. \u201dYou don't need to be a certified pilot \u2014 just take an exam of aeronautical knowledge.\u201d The rules shouldn't stifle the creative ways in which researchers employ drones. So in that spirit of imagination,  Nature  takes a look at some of the more unusual ways in which scientists employ these mechanical minions. \n             Under the sea \n           Dave Clague at the Monterey Bay Aquarium Research Institute in Moss Landing, California, uses a torpedo-shaped unmanned underwater vehicle (pictured) to  map the sea floor  and study underwater volcanoes. Outfitted with sonar and navigation equipment, the drone is programmed to travel 50 metres above the ocean floor. Clague uses the data it gathers to make high-resolution maps of mid-ocean ridges and other features off the Pacific coast of the United States and Mexico. It's an underwater version of taking aerial photographs of volcanoes on land, says Clague. The technology allows scientists to cover large areas of the sea floor that are not easily mapped by other means.\u00a0 \n             Feel the burn \n           To maintain their health, certain forests, shrublands and grasslands need periodic \u2018controlled burns\u2019. These contained fires, which officials set using equipment such as drip torches, also remove dry foliage that could serve as  fuel for wildfires . Dirac Twidwell, an ecologist at the University of Nebraska\u2013Lincoln, uses a drone (pictured) that drops fireballs to ignite controlled burns from the air. The drones give his team access to large areas with rough terrain that would be impractical or too expensive to reach on foot. \n             For the birds \n           Ornithologist Andy Wilson at Gettysburg College in Pennsylvania hangs a microphone from his aerial drone to eavesdrop on songbirds. Dangling eight metres below a quadcopter (pictured), the microphone picks up audio cues that Wilson uses to count birds of different species. \u201cFor the song sparrow, red-winged blackbird and yellow warbler, we got a similar rate of detections from our recordings as from the ground,\u201d he says. \u201dThat's awesome.\u201d The set-up also gives Wilson low-cost access to the interiors of swamps, forests and steep areas. \n             Arctic coasts \n           This jet-powered kayak drone, or \u2018JetYak\u2019, can  go where other research ships can\u2019t . Traykovski and Hanumant Singh at the Woods Hole Oceanographic Institution in Massachusetts developed a drone to monitor areas too shallow for most vessels, conducting coastal surveys and assessing how coastlines respond to storms. The researchers also send the JetYak into areas too hazardous for crewed boats, including the edge of calving glaciers along West Greenland (pictured). \n             Super drone \n           The gigantic Global Hawk (pictured) \u2014 complete with a 40-metre wingspan \u2014 flies into storms brewing over the Atlantic Ocean to collect data that help forecasters assess incoming weather. The US National Oceanic and Atmospheric Administration (NOAA) and NASA operate the drone. \u201cPeople need timely, reliable and actionable information,\u201d says Robbie Hood, director of NOAA\u2019s Unmanned Aircraft Systems Program. She describes a recent example, when \u201creal-time data delivered from the NASA Global Hawk to the National Hurricane Center were credited for alerting the hurricane forecasters to the storm\u2019s intensification.\u201d \n                   What goes up 2014-Aug-19 \n                 \n                   US drone research hits regulatory turbulence 2014-Aug-15 \n                 \n                   Autonomous drones flock like birds 2014-Feb-26 \n                 \n                   Summary of the new FAA rules. \n                 Reprints and Permissions"},
{"file_id": "537016a", "url": "https://www.nature.com/articles/537016a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Materials research is at the heart of efforts to keep the world\u2019s reactors running well past 2050. Sophisticated inspections are helping to pick up defects in ageing nuclear power plants before they cause trouble. In March, ultrasonic tests identified signs of wear and tear in some of the stainless-steel bolts in the reactor core of the Indian Point power plant just north of New York City. Researchers at the Electric Power Research Institute (EPRI) in Palo Alto, California, are now analysing more than a dozen of the 5-centimetre-long bolts \u2014 which secure plates that help direct water through the radioactive core \u2014 to determine why they failed the inspection. The analysis comes as the US Nuclear Regulatory Commission (NRC) considers whether to extend the life of Indian Point\u2019s two 40-year-old reactors for 20 more years. Opponents of the plant, including the state of New York, cite the defective bolts, a transformer fire last year and environmental and safety concerns as evidence that the facility should close. The plant\u2019s damaged bolts are just one example of the maintenance issues facing ageing nuclear reactors around the world. The International Atomic Energy Agency and the NRC are developing management guidelines for these facilities, but the problem may be most acute for the United States, whose fleet of 99\u00a0reactors is the oldest and largest. The NRC has renewed the licences of 81 US reactors still in operation for another 20 years. And it presented safety guidelines in December for utilities considering renewing their licences for another 20 years. But concerns remain about the effects of time on facilities that could be in operation for 80 years (see \u2018Going, going, gone\u2019). Former NRC chair Allison Macfarlane says that the industry has been struggling economically in the face of cheap natural gas, and that many nuclear power companies are investing the bare minimum when it comes to maintenance and upgrades. She would rather see a transition to newer \u2014 and safer \u2014 reactor designs than attempts to push old ones to their limits. \n               Extending lifetimes \n             Kurt Edsinger, director of materials at the EPRI, and his team will run a battery of tests on some of the Indian Point bolts to examine fractures and assess the strength of the material. They will also analyse the effects of roughly four decades of neutron bombardment on the crystalline structure of the steel in the bolts. The study is part of a larger effort by the EPRI and the US Department of Energy to inform the industry and regulators around the world about the risks regarding ageing materials and components as nuclear power plants come up for further licence renewals. \u201cSo far, there have been no generic show-stoppers identified that would preclude a second licence renewal,\u201d says Kathryn McCarthy, technical director of the energy department\u2019s Light Water Reactor Sustainability Program. With few new reactors coming on line around the world, the longevity of existing facilities could have huge implications for the global climate. Nuclear plants currently provide 20% of the United States\u2019 electricity \u2014 and more than half of its low-carbon power. At the global level, only hydropower provides more low-carbon power, at roughly 16% of total electricity produced, compared with nearly 11% for nuclear. \u201cIf you maintain them and replace parts, there is no reason why nuclear plants can\u2019t run a very long time, which is great news from a climate perspective,\u201d says Michael Shellenberger, president of the Environmental Progress advocacy group in Berkeley, California. Others are less sanguine. Important questions remain regarding the durability of parts that inspectors cannot see, such as underground power cables, as well as about how materials age, says Macfarlane. Of particular concern are the concrete containment structures and steel pressure vessels at the heart of reactors, as well as the kilometres of wires that snake through the plants. Researchers are now analysing the long-term effects of intense heat and neutron bombardment on a plant\u2019s crucial materials down to the atomic level. In some cases, scientists conduct accelerated-ageing experiments, in which materials are intensely irradiated to simulate 80 years of activity inside a reactor. That information can then be plugged into models that project degradation. \n               Early warning \n             The NRC\u2019s licence-renewal process focuses on crucial infrastructure that might not be part of regular maintenance programmes. The goal is to create an inspection system that detects defects before they become a problem, says Allen Hiser, a senior technical adviser in the NRC division that handles licence renewals. NRC officials say this is what happened at Indian Point; similar bolt defects were discovered in 1988 at a nuclear reactor in France, and the agency established inspection requirements to detect such issues in the future. But that is not the whole story, says Dave Lochbaum, head of the nuclear-safety project at the Union of Concerned Scientists advocacy group in Cambridge, Massachusetts. The ultrasonic inspection that identified the damaged bolts at Indian Point \u2014 a technique that is now mandatory \u2014 came about only after the state of New York challenged the adequacy of visual inspections nearly a decade ago, he says. Macfarlane remains sceptical. If the licences for current US plants are renewed for a second time, the facilities will live to be 80 years old, with nearly 100-year-old designs, she says. \u201cWe would be much better off with some of the newer reactors.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     A safe place for nuclear energy? 2016-Aug-09 \n                   \n                     US advised to stick with troubled fusion reactor ITER 2016-May-26 \n                   \n                     The nuclear option 2016-May-04 \n                   \n                     Nuclear summit a test for Obama's legacy 2016-Mar-30 \n                   \n                     DOE R&D for ageing reactors \n                   \n                     EPRI R&D for ageing reactors \n                   Reprints and Permissions"},
{"file_id": "537015a", "url": "https://www.nature.com/articles/537015a", "year": 2016, "authors": [{"name": "Alison Abbott"}, {"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "In a region known to be seismically active, destruction on this scale was still a surprise. A devastating 6.2-magnitude earthquake in central Italy on 24 August that killed more than 290 people was the country\u2019s largest since a magnitude-6.3 earthquake in 2009 that hit the town of L\u2019Aquila, about 40\u00a0kilometres away. That event killed 308 people, destroyed tens of thousands of homes and  a university . Controversially, it also caused six scientists to be put on trial for manslaughter. Central Italy\u2019s complex geological and tectonic make-up creates a notorious quake risk. The Adria micro-plate dives beneath the Apennine mountain range from east to west, creating seismic strain. The mighty Eurasian and African plates also collide here, with the Eurasian plate moving northeast at 24\u00a0millimetres per year. The  latest quake  also injured hundreds and laid waste to historic villages in the Apennine mountains, including Amatrice (see \u2018Epicentre of a quake\u2019). It was a result of increased horizontal stress perpendicular to the mountain chain. Seismologists had expected a rupture to occur near the location at any time. Still, Giulio Selvaggi, a research director at the National Institute of Geophysics and Volcanology in Rome, and one of those  initially convicted of manslaughter \u00a0\u2014 all six were  cleared on appeal \u00a0\u2014 says he was shocked by the death and destruction wreaked by last week\u2019s quake. The mountainous region around Amatrice is sparsely populated, but the final death toll may exceed that of more populated and urbanized L\u2019Aquila. Selvaggi seconds a public outcry over the failure of authorities to prioritize making old buildings more earthquake-resistant and notes that his team supplies earthquake maps to them. \u201cWe scientists have made a beautiful, detailed seismic hazard map, showing clearly the areas in greatest need of preventive measures,\u201d he says. \u201cBut public authorities don\u2019t take enough action.\u201d The court case over the L\u2019Aquila earthquake came about because a local amateur researcher claimed to have evidence of an imminent, large quake. Six scientists and one government official who had publicly dismissed the amateur\u2019s methods were accused of misinforming the public. Following an  unprecedented trial , all seven were given six-year jail sentences for manslaughter, but the scientists were cleared on appeal in 2014. Computer scientist Paola Inverardi, who is rector of the university in L\u2019Aquila, says the rebuilding of the university is nearly complete, and that research activities had resumed by 2012. Science in the region has also benefited from supporting initiatives following the quake, she says. One of these is the Gran Sasso Science Institute, an international graduate school founded in 2012 to inject young intellectual life into L\u2019Aquila. It has been so successful that in June it was awarded university status. Unlike the earthquake in L\u2019Aquila, which was preceded by frequent, mostly low-magnitude, tremors in the surrounding area, no seismic activity was recorded before the latest earthquake. \u201cIt came out of the blue, without the preceding tremors we experienced in \u2018our\u2019 earthquake,\u201d says Inverardi. L\u2019Aquila itself experienced virtually no damage, but, she says, \u201cpsychologically we were all pushed back\u201d. \n                 Tweet \n                 Follow @NatureNews \n               \n                     'Terrifying shaking': Deadly Italian quake strikes 40 kilometres from L\u2019Aquila 2016-Aug-24 \n                   \n                     Italian seismologists cleared of manslaughter 2014-Nov-10 \n                   \n                     Italian seismologists fight to overturn convictions 2014-Oct-20 \n                   \n                     Research from rubble 2009-May-20 \n                   \n                     USGS earthquake report \n                   \n                     National Institute of Geophysics and Volcanology \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20514", "url": "https://www.nature.com/articles/nature.2016.20514", "year": 2016, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Study suggests that man\u2019s best friend probably understands more than we thought when we talk to them. Attention, dog owners! Your pets probably know when you\u2019re praising them \u2014 and not just by the tone of your voice. New data suggest that dogs\u2019 brains not only  respond  to the tone of human speech, but can also distinguish between positive and neutral words. The findings will be published in the 2 September issue of  Science 1 . The study \u201cprovides the first evidence from inside a dog\u2019s brain that there\u2019s processing that depends on the meaning of a word and not just the tone of voice in which it is said\u201d, says Clive Wynne, a behavioural scientist who studies dogs at Arizona State University in Tempe. In the study, Attila Andics, a neuroscientist at E\u00f6tv\u00f6s Lor\u00e1nd University in Budapest, and his colleagues scanned the brains of 13 family dogs of 4 different breeds while the canines listened to a series of praising or neutral words. Different areas of the animals\u2019 brains lit up depending on the tone and meaning of the words. Over several months, the team had trained the dogs to lie in a functional magnetic resonance imaging (fMRI) scanner and remain completely still for two 7-minute brain-scanning sessions. The dogs were not restrained and could leave the scanner whenever they chose. Once the dogs were inside the scanner, the researchers played recordings of Hungarian words spoken in both a neutral and a positive tone. They included praising words meaning \u201cthat\u2019s it\u201d, \u201cclever\u201d and \u201cwell done\u201d, and neutral words meaning \u201cas if\u201d, \u201csuch\u201d and \u201cyet\u201d. \n             Good boy! \n           The left hemisphere of the dogs\u2019 brains responded more strongly to the meanings of words,  much like human brains do 2 . Praising words, regardless of intonation, were associated with a greater response in the left hemisphere than in the right. Neutral words produced no such difference. Parts of the right hemisphere, meanwhile, picked up on the emotional information conveyed by the intonation, regardless of a word\u2019s meaning. The researchers found that words delivered in a praising tone were associated with stronger coordination of activity between certain auditory regions and areas involved in reward processing. Praising words delivered in a positive tone elicited especially strong responses in the brain\u2019s primary reward regions. All other combinations of word meaning and intonation provoked roughly equal, smaller responses in the dogs\u2019 brains. \u201cDogs seem to care both what we say and how we say it,\u201d says Andics. \u201cThey not only separately process word meaning and intonation, but are also able to combine these two types of information as we see in reward processing.\u201d He cautions that dogs probably don\u2019t fully understand language as humans do. Still, the study results suggest that dogs can derive some semblance of meaning from different words. \n             Wait \u2026 \n           But Terrence Deacon, an evolutionary anthropologist at the University of California, Berkeley, notes that although the hemispheric differences in the study were convincing, the results in the reward centres were less so. \u201cIt\u2019s such a small area and overlaps with so many different areas that I\u2019m a little suspicious that it\u2019s probably not a strong finding,\u201d he says. Others urge even greater caution in interpreting the results. Gregory Berns, who studies brain activity in dogs and people at Emory University in Atlanta, Georgia, faults the relatively small number of animals and the reporting of only averaged data. Berns argues that the authors failed to test whether individual dogs had inherent biases to greater activity in one hemisphere over the other, independent of language. Variability in even a single dog could have skewed the averaged results, he says. But David Reby, a psychologist at the University of Sussex, UK, calls the work \u201can elegant study\u201d, noting that it corroborates his own behavioural findings in dogs 3 . The question that Reby wonders about, though, is whether the division of language-processing work between the two hemispheres arose in dogs from selective breeding for animals that efficiently processed human speech, or whether it is an inherent trait. In the future, studying brain activation in wolves \u2014  which can be tamed but not domesticated  \u2014 could help to answer this question, he says. \n                   Dog DNA probed for clues to human psychiatric ills 2016-Jan-26 \n                 \n                   'Here boy' makes dogs wag to the right 2007-Mar-21 \n                 \n                   People track scents in same way as dogs 2006-Dec-17 \n                 \n                   Old dog learns new tricks 2004-Jun-11 \n                 \n                   Stone Age man kept a dog 2002-Nov-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20508", "url": "https://www.nature.com/articles/nature.2016.20508", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Two regions of the marsupials\u2019 DNA could confer resistance to the disease. A  contagious facial cancer  that is almost always fatal has cut a wide swathe through the population of Tasmanian devils since 1996. The disease has reduced the devil population by 80%, and researchers have predicted that the cancer will drive the animals to extinction within decades. But a study published on 30 August in  Nature Communications 1  offers hope. Researchers have found that Tasmanian devils have developed some genetic resistance to the disease in just four to six generations. Evolving resistance within so few generations is rare for vertebrates, says Beata Ujvari, an evolutionary ecologist at Deakin University in Melbourne, Australia, who was not invovled in the study. Australia\u2019s rabbit population quickly developed resistance to myxomatosis, a fatal viral infection. But it took 50\u201380 generations to do so. The devil facial-tumour disease jumps from one Tasmanian devil to another when they bite each other during social interactions. And even though the cancer has wiped out up to 95% of some devil populations, small groups of the carnivorous marsupial have managed to hang on. \n             Resistance isn\u2019t futile \n           The researchers wanted to find out how the devils persisted in the face of such a devastating disease. So Andrew Storfer, an evolutionary geneticist at Washington State University in Pullman, and his colleagues sequenced about one-sixth of the devil\u2019s genome using 294 individuals from 3 wild populations. They used samples collected before and after those groups first encountered the facial cancer. The team found versions of five genes spread across two regions of the genome that seemed to be increasing in frequency throughout the devil populations. Storfer says that two of the genes,  CD146  and  THY1 , are particularly interesting because they help the immune system to recognize foreign cells. Usually, cancerous cells originate in the host, but devil facial-tumour disease is highly unusual. All instances of it come from the cells of the first known affected Tasmanian devil. So Storfer thinks that  CD146  and  THY1  would be the most likely candidates involved in resistance to this disease because the genes might allow the animal\u2019s body to recognize the tumour cells as \u2018foreign\u2019. Storfer says that his team was able to rule out the possibility that these genetic changes were random, because the same genes were proliferating in three geographically distinct populations.\u00a0 \n             Some hope \n           The research offers several avenues of hope for Tasmanian-devil conservation. \u201cIt\u2019s one of the key cornerstones in saving them; identifying these regions which might provide resistance,\u201d says Ujvari. If researchers can screen captive devils for the beneficial genes, they can breed these animals in carefully managed populations in Tasmania and mainland Australia, says Storfer. His group also hopes to find devils on Tasmania\u2019s far west coast \u2014 the only part of the country that hasn\u2019t been hit by the facial cancer \u2014 that  carry the resistance genes . \u201cIt has a lot of potential for future vaccination studies,\u201d says Hannah Siddle, a molecular immunologist who is developing vaccines for the disease at the University of Southampton, UK. For instance,  vaccinations  or immunotherapy that target these genes might help the devils\u2019 immune systems to fight off the cancer. First, though, Storfer\u2019s lab needs to confirm that the genes do convey resistance to the cancer. A bulletproof way to do that would be to purposely infect Tasmanian devils that carry the beneficial versions of those genes. But that would be \u201ccompletely unethical and illegal\u201d, says Storfer, because Tasmanian devils are  an endangered species . So instead, the researchers plan to tinker with tumour-cell lines in the lab to see whether the genes that the team has identified disrupt the cancerous cells. The dwindling Tasmanian-devil population numbers, and the animals\u2019 high degree of inbreeding, make these mammals particularly vulnerable to disease. But, despite that, the current research gives Ujvari hope. \u201cPersonally,\u201d she says, \u201cI think they will make it.\u201d \n                   Vaccine hope for Tasmanian devil tumour disease 2013-Mar-11 \n                 \n                   Field narrows in hunt for devil tumour genes 2012-Feb-16 \n                 \n                   Hopes of a tumour test for Tasmanian devils 2009-Dec-31 \n                 \n                   Genome scan may save Tasmanian devils from cancer 2009-Mar-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20509", "url": "https://www.nature.com/articles/nature.2016.20509", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Larger studies are under way to test whether the promising early data holds up. A drug called aducanumab might remove  the toxic proteins  thought to trigger Alzheimer\u2019s disease from the brain, suggests findings from a small clinical trial. The results, reported on 31 August in  Nature 1 , showed that aducanumab broke up amyloid-\u03b2 proteins in patients with early-stage Alzheimer\u2019s disease. The trial mainly tested the safety of the drug in people, and so the final word on whether aducanumab works to ameliorate the  memory  and cognitive losses associated with Alzheimer\u2019s will have to wait until the completion of two larger phase III trials. They are now in progress, and planned to run until at least 2020. The latest study involved 165 people split into different groups, some of which received the drug and one which received a placebo. In the group receiving infusions of aducanumab, 103 patients given the drug once a month for up to 54 weeks experienced a reduction in the amount of tangled amyloid-\u03b2 in their brains. These results echoed the findings of a pretrial mouse study \u2014 reported in the same paper 1  \u2014 in which the drug seemed to clear amyloid-\u03b2 plaques from the animals\u2019 brains. \u201cThis drug had a more profound effect in reversing amyloid-plaque burden than we have seen to date,\u201d says psychiatrist Eric Reiman, executive director of the Banner Alzheimer\u2019s Institute in Phoenix, Arizona, who is testing other approaches for Alzheimer\u2019s prevention and treatment. \u201cThat is a very striking and encouraging finding and a major advance.\u201d Reiman wrote a  commentary  accompanying the article. \u201cThis is the best news we\u2019ve had in my 25 years of doing Alzheimer\u2019s research, and it brings hope to patients and families affected by the disease,\u201d says neurologist Stephen Salloway of Butler Hospital in Providence, Rhode Island, who was on the team that ran the trial. \n             Proceed with caution \n           Patients in the groups that got the drug were given one of four different doses of aducanumab. Individuals who received the highest doses also saw the highest reductions in plaques. And a group of 91 patients treated for 54 weeks saw slower cognitive declines than did those who received placebo infusions. Scientists have  debated for years  whether the build-up of amyloid-\u03b2 causes the memory loss and other symptoms of Alzheimer\u2019s. This trial is a point in favour of the \u201camyloid hypothesis\u201d, which suggests that elimination of the protein itself might alleviate the disease\u2019s symptoms. Still, Reiman cautions, the trial is too small to prove that the drug actually works. Numerous other Alzheimer\u2019s drugs have looked promising in early-stage trials, yet ended in failure, and even in the  deaths of patients . Aducanumab led to abnormalities on brain-imaging scans in less than one-third of the patients. But researchers closely monitor such anomalies in Alzheimer\u2019s trials, because some participants in previous Alzheimer\u2019s antibody trials have died as a result of brain inflammation. All of the reported imaging abnormalities eventually disappeared in about 4 to 12 weeks, and no patients were hospitalized. Some people with imaging anomalies continued to take the drug despite these side effects. Patients who received higher doses of the drug, or who had genetic risk factors for Alzheimer\u2019s, were more likely to develop the brain anomalies. Biogen \u2014 the company that makes aducanumab \u2014 has adjusted the drug\u2019s dosage and the monitoring schedule for people with genetic risk for Alzheimer\u2019s in its phase 3 trials. Reiman says that the drugmakers will need to determine whether there is a dosage that hits a \u201csweet spot\u201d at which it is strong enough to work without causing potentially lethal brain inflammation. \n             Looking forward \n           Aducanumab is a bright spot in the field of Alzheimer\u2019s therapeutics after years of failed antibody and other types of drug trials. The antibody drug solanezumab failed to slow cognitive decline in two large 2013 clinical trials, but is currently being tested in multiple other trials. One includes individuals with mild Alzheimer\u2019s disease, and could report results as early as the end of this year. Other therapeutic strategies undergoing clinical trials include targeting enzymes called \u03b2-secretase 1, involved in processing amyloid proteins; targeting antibodies to attack a form of amyloid protein \u2014 the \u201cpyroglutamate\u201d form \u2014 found in plaques; and targeting a protein called tau that also seems to be implicated in the disease. \u201cThe fact that we now have an antibody that  gets into the brain sufficiently  enough to engage its target and remove plaques is an important development, and we look forward to seeing results from this and other phase 3 trials,\u201d Reiman says. See the related News & Views article: ' Attack on amyloid-\u00df protein ' \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Memories retrieved in mutant \u2018Alzheimer\u2019s\u2019 mice 2016-Mar-16 \n                 \n                   Alzheimer\u2019s research takes a leaf from the prion notebook 2015-May-29 \n                 \n                   Alzheimer's drug sneaks through blood\u2013brain barrier 2014-Nov-05 \n                 \n                   Battle of the mind 2003-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20515", "url": "https://www.nature.com/articles/nature.2016.20515", "year": 2016, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "Samples of the cell line do not match its 50-year-old source \u2015 but how the mix-up occurred is a mystery. Biomedical scientists are often urged to check that their cell lines are not contaminated or mislabelled. But as a new study shows, any effort to  authenticate a cell line  is only as good as the reference standard against which the cells are compared. A cell line that is widely used to study brain cancer does not match the cells used to create the line nearly 50 years ago, or the tumour purported to be its source, researchers report on 31 August in  Science Translational Medicine 1 . In fact, no one is quite sure of the true provenance of the cell line distributed by most cell repositories. \u201cIt is a good cautionary tale to say, \u2018Question your assumptions and do as many appropriate controls as you can to make sure you really have what you think you have,\u2019\u201d says Jon Lorsch, director of the US National Institute of General Medical Sciences in Bethesda, Maryland. And because few cell lines are ever verified against their primary-source material, \u201cthis paper is probably just the tip of the iceberg\u201d, says Christopher Korch, a geneticist at the University of Colorado Denver. Many groups are trying to tackle the problem of misidentified cell lines to improve the reproducibility of research findings. This year, the US National Institutes of Health started requiring grant applicants to describe how they will authenticate their cell lines. And  journals such as  Nature  have recently begun to  ask authors to check their cells  against a database of 475 lines (and counting) that are known to be mixed up. But no organizations have called for the kind of archival sleuthing that produced the new study. \u201cIt\u2019s hard enough to get people to do the standard authentication,\u201d says Leonard Freedman, president of the Global Biological Standards Institute, a non-profit organization in Washington DC that has found that  most life scientists never authenticate their cells 2 . \u201cThis is much more elaborate.\u201d \n               Mistaken identity \n             The cell line in question, U87, was established in 1966 at Uppsala University in Sweden, using tissue from a 44-year-old woman with an aggressive brain cancer known as glioblastoma. U87 has since become a workhorse of brain-cancer research, subject to countless investigations that have yielded around 2,000 scientific papers. The enthusiasm for U87 initially puzzled Bengt Westermark, a tumour biologist at Uppsala. \u201cI couldn\u2019t understand why people would work with such boring cells,\u201d he says. As a graduate student in the 1970s, Westermark studied eight different brain-cancer cell lines. U87 was \u201chopeless to work with\u201d, he says, because it grew so much more slowly than the others. Years later, Westermark got his hands on the version of U87 that is distributed by the American Type Culture Collection (ATCC), a cell repository in Manassas, Virginia, that houses the world\u2019s largest collection of biological materials. He could see from the cells\u2019 growth properties that this U87 was clearly different from the cells that had given him so much grief in graduate school. Westermark decided to do a formal comparison. Fortunately, Uppsala still had the preserved tumour tissue that spawned the original cell line. This enabled Westermark\u2019s team to verify the identity of the archival U87 sample in their freezer. The researchers then used DNA-fingerprinting techniques to show that the ATCC\u2019s U87 was different \u2014 and that it didn\u2019t match any other cell lines created at Uppsala, either. \n               Cultural shift \n             According to Mindy Goldsborough, ATCC\u2019s chief science and technology officer, the repository acquired its U87 line in 1982 from the Memorial Sloan KetteringCancer Center in New York City, which itself had received the cell line from Uppsala in 1973. And by the time it arrived at the ATCC, U87 had a Y chromosome \u2014 despite the fact that it was supposed to have come from a female patient. This suggests that the mix-up probably happened at Sloan Kettering or during one of the hand-offs. In light of the new revelations, the ATCC now plans to update the background details in its listing for U87, which it describes as male. But the origin of the U87 line remains a mystery. A comparison of gene-expression profiles conducted by Westermark's team suggests that the ATCC cell line probably came from a brain tumour. \u201cIt\u2019s bad news that it\u2019s not what it should be,\u201d Westermark says, \u201cbut it\u2019s good news that it\u2019s probably a glioblastoma.\u201d This means that studies of U87 still reflect brain-cancer biology and don\u2019t need to be tossed out, he adds. Still, many cancer researchers think that it is time to move beyond U87 and other \u201cclassical\u201d cell lines \u2014 regardless of where they came from \u2014 because the culture conditions historically used to grow the cells change their biological nature. Westermark and others now favour newer cell lines that have been propagated on the types of growth medium that ensure genetic and epigenetic stability. Through its Human Glioma Cell Culture biobank, Uppsala provides these sorts of cells to other researchers for a small processing fee. \u201cThere is an increasing understanding that what we\u2019ve historically used is so poorly representative of the human disease,\u201d says Howard Fine, a neuro-oncologist at the Weill Cornell Brain Tumor Center in New York City. \u201cSo, any time someone can shoot down the [U87] cell line, I\u2019m happy.\u201d \n                     Biomedical researchers lax in checking for imposter cell lines 2015-Oct-12 \n                   \n                     Biotech firm announces fast test to unmask imposter cell lines 2015-Apr-15 \n                   \n                     Announcement: Time to tackle cells\u2019 mistaken identity 2015-Apr-15 \n                   \n                     Biologists tackle cells' identity crisis 2010-Jun-02 \n                   \n                     Database of cross-contaminated or misidentified cell lines \n                   \n                     Uppsala University\u2019s Human Glioma Cell Culture resource \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20507", "url": "https://www.nature.com/articles/nature.2016.20507", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Fossils find suggests that cat-sized reptile lived alongside birds and larger pterosaurs. When dinosaurs roamed Earth,  pterosaurs ruled the skies . The largest of these ancient reptiles had wingspans of 10 metres or more. But fossil fragments unearthed in western Canada suggest that these giant flying reptiles co-existed with a more diminutive form \u2014 closer to the size of an albatross. The finding is preliminary, but if it holds, it could upend scientists\u2019 view of pterosaurs\u2019 evolution, and their eventual extinction 66 million years ago. The fossils \u2014 an upper arm bone and vertebrae discovered on Hornby Island in British Columbia \u2014 came from a nearly full grown pterosaur that had a wingspan of just 1.5 metres and was about as tall as a housecat, scientists report on 31 August in  Royal Society Open Science 1 . They suggest the existence of a species about 77 million years ago, during the late Cretaceous period, that was much smaller than the giant pterosaurs thought to dominate then. \u201cIt\u2019s quite different from other animals we\u2019ve studied. There hasn\u2019t really been evidence before of small pterosaurs at this time period,\u201d says Elizabeth Martin-Silverstone, the study\u2019s lead author and a palaeobiologist at the University of Southampton, UK. \n             At arm\u2019s length \n           She and her colleagues examined a thin slice of the arm bone \u2014 a humerus \u2014 and analysed it on a microscopic level, looking at how the bone had maintained and reworked itself to get an idea of the animal\u2019s growth stage. They also found that the vertebrae were beginning to fuse together. Together, these demonstrated that it was nearly a full-grown adult when it died. Pterosaurs\u2019 bones were hollow, with thin walls, so relatively few have survived as fossils. And small pterosaurs are particularly tough to identify, which means that the fossils that have been found give a limited picture of the original diversity of the animals. But in recent years, scientists have discovered specimens that suggest pterosaurs grew larger as they evolved. The biggest yet known was the size of a small plane \u2014 and lived during the late Cretaceous period; the smallest thought to be living then had wingspans of roughly 2.5 metres. The latest study relies on only a few bones, so it does not provide definitive proof that small pterosaur species existed alongside the larger ones, says Alexander Kellner, a palaeontologist at the National Museum of Brazil in Rio de Janeiro.\u00a0 \u201cI praise the authors for their efforts, but the specimen is not very complete,\u201d he says. \u201cIf they had a skull, jaw or neck bones, that would help. The classification? I don\u2019t know. It could be anything.\u201d \n             Identity crisis \n           Study co-author Mark Witton, a palaeontologist at the University of Portsmouth, UK, acknowledges the work\u2019s limitations. \u201cWe\u2019ve only got one data point, so don\u2019t rewrite the textbooks yet,\u201d he says. But he and his colleagues say that they carefully ruled out alternative explanations for the small size of the fossilized bones. The fused backbone means that the bones did not come from a bird. And it could not be a nyctosaur, a previously known small marine pterosaur, because the arm bone lacked that creature\u2019s distinctive hatchet-shaped crest, where the flight muscles attach, says Martin-Silverstone. The Cretaceous ended 66 million years ago with  a mass extinction  that saw pterosaurs  vanish alongside the dinosaurs . In general, the extinction wiped out bigger species, while smaller animals like many birds managed to muddle through and survive. If the latest finding is confirmed, it will turn out that birds were not the only small-winged vertebrates living then, although the tiny pterosaur\u2019s unfortunate fate would imply that being little was no guarantee of survival. \u201cThey have plenty of new material to determine that this is a new species of pterosaur,\u201d says Michael Habib, a palaeontologist at the University of Southern California in Los Angeles. \u201cIf there\u2019s one, there were probably others. Then we\u2019d need to rethink what we previously thought about survivability of these little ones.\u201d \n                   Bat-winged dinosaur discovery poses flight puzzle 2015-Apr-29 \n                 \n                   Palaeontology: The truth about T. rex 2013-Oct-23 \n                 \n                   Perfect pterosaur found in fossil egg 2004-Jun-10 \n                 Reprints and Permissions"},
{"file_id": "536258a", "url": "https://www.nature.com/articles/536258a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Result could be closest thing yet to an observation of the bizarre phenomenon. Black holes are not actually black. Instead, these gravitational sinks are thought to emit radiation that causes them to shrink and eventually disappear. This phenomenon, one of the weirdest things about black holes, was predicted by Stephen Hawking more than 40\u00a0years ago, creating problems for theoretical physics that still convulse the field. Now, after seven years of  often solitary study , Jeff Steinhauer, an experimental physicist at the Technion-Israel Institute of Technology in Haifa, has created an artificial black hole that seems to emit such \u2018Hawking radiation\u2019 on its own, from quantum fluctuations that emerge from its experimental set-up. It is nearly impossible to observe Hawking radiation in a real black hole, and previous artificial-black-hole experiments did not trace their radiation to spontaneous fluctuations. So the result, published on 15\u00a0August 1 , could be the closest thing yet to an observation of Hawking radiation. Steinhauer says that black-hole analogues might help to solve some of the dilemmas that the phenomenon poses for other theories, including one called the black-hole information paradox, and perhaps point the way to  uniting quantum mechanics with a theory of gravity . Other physicists are impressed, but they caution that the results are not clear-cut. And some doubt whether laboratory analogues can reveal much about real black holes. \u201cThis experiment, if all statements hold, is really amazing,\u201d says Silke Weinfurtner, a theoretical and experimental physicist at the University of Nottingham, UK. \u201cIt doesn\u2019t prove that Hawking radiation exists around astrophysical black holes.\u201d It was in the mid-1970s that Hawking, a theoretical physicist at the University of Cambridge, UK, discovered that the event horizon of a black hole \u2014 the surface from which nothing, including light, can escape \u2014 should have peculiar consequences for physics. His starting point was that the randomness of quantum theory ruled out the existence of true nothingness. Even the emptiest region of space teems with fluctuations in energy fields, causing photon pairs to appear continuously, only to immediately destroy each other. But, just as Pinocchio turned from a puppet into a boy, these \u2018virtual\u2019 photons could become real particles if the event horizon separated them before they could annihilate each other. One photon would fall inside the event horizon and the other would escape into outer space. This, Hawking showed, causes black holes both to radiate \u2014 albeit extremely feebly \u2014 and to ultimately shrink and vanish, because the particle that falls inside always has a \u2018negative energy\u2019 that depletes the black hole. Most controversially, Hawking also suggested that a black hole\u2019s disappearance destroys all information about objects that have fallen into it, contradicting the accepted wisdom that the total amount of information in the Universe stays constant. In the early 1980s, physicist Bill Unruh of the University of British Columbia in Vancouver, Canada, proposed a way to test some of Hawking\u2019s predictions 2 . He imagined a medium that experienced accelerated motion, such as water approaching a waterfall. Like a swimmer reaching a point where he cannot swim fast enough away to escape the waterfall, sound waves that are past the point in the medium that surpasses the speed of sound would become unable to move against the flow. Unruh predicted that this point is equivalent to an event horizon\u00a0\u2014\u00a0and that it should display a sonic form of Hawking radiation. Steinhauer implemented Unruh\u2019s idea in a cloud of rubidium atoms that he cooled to a fraction of a degree above absolute zero. Contained in a cigar-shaped trap a few millimetres long, the atoms entered a quantum state called a  Bose\u2013Einstein condensate  (BEC), in which the speed of sound was just half a millimetre per second. Steinhauer created an event horizon by accelerating the atoms until some were travelling at more than 1\u2009mm\u2009s \u22121  \u2014 a supersonic speed for the condensate (see \u2018Building a black hole\u2019). At its ultracold temperature, the BEC undergoes only weak quantum fluctuations that are similar to those in the vacuum of space. And these should produce packets of sound called phonons, just as the vacuum produces photons, Steinhauer says. The partners should separate from each other, with one partner on the supersonic side of the horizon and the other forming Hawking radiation. On one side of his acoustical event horizon, where the atoms move at supersonic speeds, phonons became trapped. And when Steinhauer took pictures of the BEC, he found correlations between the densities of atoms that were an equal distance from the event horizon but on opposite sides. This demonstrates that pairs of phonons were entangled \u2014 a sign that they originated spontaneously from the same quantum fluctuation, he says, and that the BEC was producing Hawking radiation. By contrast, radiation that he observed in an  earlier version of the set-up  had to be triggered rather than arising from the BEC itself 3 , whereas a previous experiment in water waves led by Unruh and Weinfurtner did not attempt to show quantum effects 4 . Just as real black holes are not black, Steinhauer\u2019s acoustical black holes are not completely quiet. Their sound, if it were audible, might resemble static noise. \u201cFor sure, this is a pioneering paper,\u201d says Ulf Leonhardt, a physicist at the Weizmann Institute of Science in Rehovot, Israel, who leads a different attempt to demonstrate the effect,  using laser waves in an optical fibre . But he says that the evidence of entanglement seems incomplete, because Steinhauer demonstrated correlations only for phonons of relatively high energies, with lower-energy phonon pairs seemingly not correlated. He also says he\u2019s not confident that the medium is a true BEC, which, he says, means that there could be other types of fluctuation that could mimic Hawking radiation. Also unclear is what analogues can say about the mysteries surrounding true black holes. \u201cI don\u2019t believe it will illuminate the so-called information paradox,\u201d says Leonard Susskind, a theoretical physicist at Stanford University in California. In contrast to the case of astrophysical black holes, there is no information loss in Steinhauer\u2019s sonic black hole because the BEC does not evaporate. Still, if Steinhauer\u2019s results were confirmed, it would be \u201ca triumph for Hawking, perhaps in the same sense that the expected detection of the Higgs boson was a triumph for Higgs and company\u201d, says Susskind. Few doubted that the particle existed, but its  discovery in 2012  still earned Peter Higgs and another theorist, Fran\u00e7ois Englert, who predicted it,  a Nobel prize . \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @dcastelvecchi \n               \n                     One-man band: the solo physicist who models black holes in sound 2016-Aug-15 \n                   \n                     Hawking\u2019s latest black-hole paper splits physicists 2016-Jan-27 \n                   \n                     The quantum source of space-time 2015-Nov-16 \n                   \n                     Hawking radiation mimicked in the lab 2014-Oct-12 \n                   \n                     Astrophysics: Fire in the hole! 2013-Apr-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20472", "url": "https://www.nature.com/articles/nature.2016.20472", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "No reason is given for the surprise move. Russian President Vladimir Putin has appointed a church historian as the country\u2019s new science and education minister. On 19 August, the president announced that Olga Vasilyeva would succeed the current science minister, Dmitry Livanov, who will become presidential envoy on trade and economic relations with Ukraine,  according to the Russian news agency Interfax . During his 4-year term as minister, Livanov oversaw a  radical overhaul of the Russian Academy of Sciences , Russia\u2019s main basic research organization. The formerly separate academies of sciences, medical sciences and agricultural science were merged and put under the governance of a federal agency.  Livanov told Nature  last year that the academy\u2019s future role will mainly be to provide expert advice to the government and society. But many members of the academy, which runs hundreds of research institutes across Russia, are  unhappy with the changes  and with the way that Livanov handled the painful reform. Vladimir Ivanov, a vice-president of the academy, told the  Rossiyskaya Gazeta  news portal that he welcomed the move because Livanov had failed to involve scientists and academic officials in the overhaul of the academy. \n             Unexpected proposal \n           In making the decision, Putin followed a proposal made by prime minister Dmitry Medvedev, according to Interfax. Putin gave no reason for Livanov\u2019s replacement. The minister was unpopular in public for his education policies \u2014 many parents are upset, for example, that they must now pay fees for their children's school textbooks, according to  Rossiyskaya Gazeta . But whether a lack of public popularity was the reason for Livanov\u2019s dismissal is unclear. Putin and Medvedev did value Livanov\u2019s work, and they say that they consider his experience to be important in other spheres, according to the Russian news agency TASS. Some scientists fear that Vasilyeva\u2019s appointment might mark a rise of Christian orthodoxy and religious attitudes in the realms of school education, higher learning and public life. But Vasilyeva, formerly in charge of religious public education in the presidential administration,  told Interfax  that religion will not interfere with her future work as education and science minister. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Russian secret service to vet research papers 2015-Oct-20 \n                 \n                   Russia turns screw on science foundation 2015-May-28 \n                 \n                   Russian science minister explains radical restructure 2015-Jan-26 \n                 \n                   Putin\u2019s Russia divides and enrages scientists 2014-Dec-16 \n                 \n                   Ministry of Education and Science of the Russian Federation \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20405", "url": "https://www.nature.com/articles/nature.2016.20405", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Excitement rises over chance of new physics from  particle-du-jour. Why the Universe is filled with matter, rather than antimatter, is one of physics\u2019 greatest mysteries. An experiment in Japan has now glimpsed a possible explanation: subatomic particles called neutrinos might behave differently in their matter and antimatter forms. The disparity, announced at the International Conference on High Energy Physics (ICHEP) in Chicago, Illinois, on 6 August, may turn out not to be real: more data will need to be gathered to be sure. \u201cYou would probably bet that this difference exists in neutrinos, but it would be premature to state that we can see it,\u201d says Andr\u00e9 de Gouv\u00eaa, a theoretical physicist at Northwestern University in Evanston, Illinois. Even so, the announcement is likely to increase excitement over studies of neutrinos, the abundant but elusive particles that seem increasingly key to solving all kinds of puzzles in physics. In the 1990s, neutrinos were found 1 , 2   to defy the predictions of physics' standard model  \u2014 a successful, but incomplete, description of nature \u2014 by virtue of possessing mass, rather than being entirely massless. Since then, neutrino experiments have  sprouted up around the world , and researchers are realizing that they should look to these particles for new explanations in physics, says Keith Matera, a physicist on a US-based neutrino experiment called NOvA at the Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois. \u201cThey are the crack in the standard model,\u201d he says. \n               An odd abundance \n             The excess of matter over antimatter in our Universe is extraordinary, because if the mirror-image particles were produced in equal quantities after the Big Bang, they would have annihilated each other on contact, leaving nothing but radiation. Physicists have observed differences in the behaviour of some matter particles and antimatter particles, such as kaons and B mesons \u2014 but not enough to explain the dominance of matter in the Universe. One answer might be that super-heavy particles decayed in the early Universe in an asymmetric fashion and produced more matter than antimatter. Some physicists think that a heavyweight relative of the neutrino could be the culprit. Under this theory, if neutrinos and antineutrinos behave differently today, then a similar imbalance in their ancient counterparts could explain the overabundance of matter. To test this, researchers on the Tokai to Kamioka (T2K) experiment in Japan looked for differences in the way that matter and antimatter neutrinos oscillate between three types, or \u2018flavours\u2019, as they travel (see 'Changing flavours'). They shot beams of neutrinos of one flavour \u2014 muon neutrinos \u2014 from the Japan Proton Accelerator Research Complex in the seaside village of Tokaimura to the Super-Kamiokande detector, an underground steel tank more than 295 kilometres away and filled with 50,000 tons of water. The team counted how many electron neutrinos appeared \u2014 a sign that the muon neutrinos had morphed into a different flavour along the journey. They then repeated the experiment with a beam of muon antineutrinos. The two beams behaved slightly differently, said Konosuke Iwamoto, a physicist at the University of Rochester, New York, during his presentation at ICHEP. \n               Weird oscillations \n             The team expected that if there were no difference between matter and antimatter, their detector would have, after almost 6 years of experiments, seen 24 electron neutrinos and \u2014 because antimatter is harder to produce and detect \u2014 7 electron antineutrinos. Instead, they saw 32 neutrinos and 4 antineutrinos arrive in their detector. \u201cWithout getting into complicated mathematics, this suggests that matter and antimatter do not oscillate in the same way,\u201d says Chang Kee Jung, a physicist at Stony Brook University in New York and a member of the T2K experiment. Preliminary findings from the T2K and NOvA experiments had hinted at the same idea. But the observations so far could be a chance fluctuation; there is a 1 in 20 chance (or in statistical terms, about 2 sigma) of seeing these results if neutrinos and antineutrinos behave identically, points out Jung. It will take much more data to confirm the signal. By the end of its current run in 2021, the T2K experiment should have five times more data than it has today. But the team will need 13 times more data to push statistical confidence in the finding to 3 sigma, a statistical threshold beyond which most physicists would accept the data as reasonable \u2014 but not completely convincing \u2014 evidence of the asymmetry. \n               Two are better than one \n             The T2K team has proposed extending its experiment to 2025 in order to gather the necessary data. But it is trying to speed up data-gathering by combining results with those from NOvA, which sends a neutrino beam 810 kilometres from Fermilab to a mine in northern Minnesota. NOvA has been shooting neutrino beams; it will switch to antineutrino beams in 2017. The two groups have agreed to produce a joint analysis and could together reach 3 sigma by around 2020, says Jung. Reaching the statistical certainty needed to announce a formal discovery \u2014 5 sigma \u2014 could require a  new generation of neutrino experiments  already being planned around the world. Researchers from the NOvA experiment presented another exciting but preliminary finding at the ICHEP, also deduced from the study of the rate at which muon neutrinos switch to electron neutrinos: a hint at a resolution for which of neutrinos\u2019 three different mass states is the heaviest.They found their results slightly favour a normal mass order, rather than an inverted one. Knowing which it is would help scientists to decide between rival theories about how the four forces of nature unite as a single force at high energies, such as during the Big Bang. Physicists are racking up discoveries about neutrinos on an almost annual basis, says de Gouv\u00eaa: \u201cFor the timescales of particle physics, this is changing really, really quickly.\u201d  \n               boxed-text \n             \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Hopes for revolutionary new LHC particle dashed 2016-Aug-05 \n                   \n                     Neutrino study made key priority for US nuclear physics 2015-Oct-20 \n                   \n                     Morphing neutrinos win physics Nobel 2015-Oct-06 \n                   \n                     Age of the neutrino: Plans to decipher mysterious particle take shape 2015-Aug-12 \n                   \n                     Neutrinos found to switch to elusive \u2018tau\u2019 flavour 2015-Jun-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20416", "url": "https://www.nature.com/articles/nature.2016.20416", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Health officials launch emergency immunization campaign. In a major setback to the global campaign to eradicate polio, Nigeria has seen its first cases of wild poliovirus in more than two years, the World Health Organization (WHO) in Geneva, Switzerland,  announced on 11 August . The country will now start emergency-vaccination campaigns to hold back the virus's spread. Nigeria was on the brink of wiping out polio; its last recorded case had been in July 2014. That was a remarkable achievement, given that in 2012, it recorded 122 cases \u2014 more than all other countries combined.  Improvements to vaccination efforts had prompted the turnaround , and seemed to have set the stage for Africa to be declared polio free in 2017. The earliest that could now happen is 2019: a region must be free of polio for three years for the WHO to officially declare that it has eradicated the virus. \u201cThis is truly disappointing because Nigeria had made extreme progress with their control of polio virus,\u201d says\u00a0Michel Zaffran,\u00a0director of polio eradication at the WHO. Nigeria's government found two children that had been paralysed in July by polio, the WHO said. Wild polio virus was detected in one of them, living in the Gwoza district of Nigeria's northeastern-most state, Borno. A closely-related virus was also found in a healthy child living about 100 kilometres away in the Jere district; they had been in contact with the other paralysis case. \n             Lurking cases \n           The lineage of poliovirus responsible for the outbreak was last detected in 2011 in Borno. Together with other northeastern states, the region has been the target of violent attacks by the Islamic militant group Boko Haram \u2014 a situation that has hampered polio-vaccination teams, as well as those looking for signs of the virus, from accessing the area. \u201cClearly cases were missed, because this thing has been circulating for four years,\u201d says Oliver Rosenbauer, spokesperson for the WHO\u2019s Global Polio Eradication Initiative. Polio causes paralysis in around 1 in every 200 infections, and Rosenbauer says that there is probably a reservoir of individuals spreading the virus, and that more polio cases are \u201clikely\u201d. \u201cIt was to be expected that there would be problems with the quality of surveillance, but we didn\u2019t think there was wild polio virus circulating in this area of the country,\u201d says Zaffran. Next week, health officials in Nigeria will begin the first of six emergency vaccination campaigns. The first will target children in Borno state; the rest, not yet scheduled, will attempt to reach children across northeastern Nigeria and in neighbouring Chad, Cameroon and Niger. Improving surveillance for poliovirus cases \u2014 for instance, in healthy individuals and in the environment \u2014 is another priority, Rosenbauer says. David Heymann, chairperson of Public Health England and a former head of the WHO's polio-eradication effort, sees the latest cases as a positive sign that surveillance is in place to detect polio in even the hardest-to-reach parts of Nigeria. More polio cases could still turn up, Heymann says, but he still expects Nigeria and the rest of the world to wipe out polio eventually. \u201cIt shows that the end game is very difficult,\u201d he says. \u201cThere will be some setbacks all along the way.\u201d Afghanistan and Pakistan are the only other countries besides Nigeria that have never interrupted the spread of polio, but they have made gains in battling the virus. Pakistan has recorded 13 polio cases this year and Afghanistan has seen 6, compared to a combined 74 cases in 2014. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Smart shots bring Nigeria to brink of polio eradication 2015-Jul-15 \n                 \n                   Public health: Polio's moving target 2013-Apr-17 \n                 \n                   A last push to eradicate polio 2011-Feb-01 \n                 \n                   Polio focus shifts to Nigeria 2003-Oct-24 \n                 \n                   Global Polio Eradication Initiative \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20407", "url": "https://www.nature.com/articles/nature.2016.20407", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Technique that adds noise to genetic data would enable much faster access to large data sets. Large genomic databases are indispensable for scientists looking for genetic variations associated with diseases. But they come with  privacy risks  for people who contribute their DNA. A 2013 study 1  showed that hackers could use publicly available information on the Internet to identify people from their anonymized genomic data. To address those concerns, a system developed by Bonnie Berger and Sean Simmons, computer scientists at the Massachusetts Institute of Technology (MIT) in Cambridge, uses an approach called differential privacy. It masks the donor's identity by adding a small amount of noise, or random variation, to the results it returns on a user\u2019s query. The researchers published their results in the latest issue of\u00a0 Cell Systems 2 .\u00a0 The system calculates the statistic that researchers want \u2014 such as the chance that one genetic variation is associated with a particular disease, or the top five genetic variations associated with an illness. Then it adds random variation to the result, essentially returning slightly incorrect information. For example, in a query for the top five genetic variations associated with a disease, the system might yield the top four genetic variations and the sixth or seventh variation. The user would not know which of the results to their query is more correct than another, but they could still use the information. It would just be much harder for someone to work out the patient information behind the data. \u201cWhen you induce a little noise in the system, in many ways it\u2019s not that different from noise in the data to begin with,\u201d says Bradley Malin, a computer scientist at Vanderbilt University in Nashville, Tennessee. \u201cIt is reliable to a certain degree.\u201d The US Census Bureau and US Department of Labor have been adding noise to their data in this way for decades, he says. \n             Faster access \n           The privacy of individuals in a data set employing this technique remains intact as long as the database is big enough \u2014 containing information from a few thousand individuals or more \u2014 and if researchers stay within their 'privacy budget', which limits the number of questions they can ask. Users would not be able to ask about hundreds or thousands of locations in a genome. A database protected by this technique could be instantly searchable. Currently, getting permission to access databases administered by agencies including the US National Institutes of Health can take months.\u00a0 Simmons and Berger say that even with the noise, the system's answers will be close enough to be useful for asking a few targeted questions. \u201cIt's meant to be used to get access to data sets that you might not have access to otherwise,\u201d says Simmons. For example, if researchers analysing a small data set found a genetic variation associated with a disease, this system could allow them to verify that association using a much larger data set that they otherwise couldn\u2019t access. It could also let researchers preview a data set to determine its usefulness before going through a time-consuming application process for full access. \n             That queasy feeling \n           \u201cI think it's a really excellent mathematical work,\u201d says  Yaniv Erlich , a computational biologist at Columbia University in New York City. \u201cIt\u2019s nice on paper. But from a practical perspective I'm not sure that it can be used.\u201d One of his concerns is the system\u2019s question limitation. What researchers want these days is to examine the top 10 or top 100 genetic variations associated with a disease, Erlich says, not just 5. Also, \u201cpeople don\u2019t like to put noise in their data\u201d because a lot of hard work goes into generating the information, Erlich says. The noise issue could also have troubling implications for clinical decisions based on such information. Malin adds that there is a very small probability that the system would introduce a large amount of noise in answer to a query. \u201cThat\u2019s what makes people a little queasy.\u201d  But Simmons is trying to improve the system, attempting to add less noise while achieving the same privacy. And Berger is working with the Broad Institute of MIT and Harvard in Cambridge to determine ways of decreasing privacy risks, possibly by using differential privacy techniques. This would be useful if the institute decided to release aggregate genomic data from its databases more widely. \u201cIn the end that\u2019s what we really care about,\u201d Simmons says, \u201cmaking this data as widely accessible as possible.\u201d Reprints and Permissions"},
{"file_id": "nature.2016.20344", "url": "https://www.nature.com/articles/nature.2016.20344", "year": 2016, "authors": [{"name": "Rachel Berkowitz"}], "parsed_as_year": "2006_or_before", "body": "Forecasters hope to predict strikes months or even years in advance. Most people avoid spending time in  lightning -prone locales. But this month, scientists are heading to an area of Venezuela that sees more lightning strikes than anywhere else in the world, to test a system designed to forecast strike frequency up to three months in advance. They are going to the right place: the region around Lake Maracaibo in northern Venezuela, which normally surpasses 200 strikes per square kilometre each year 1 . The researchers \u2014 led by \u00c1ngel Mu\u00f1oz, a climate scientist at Princeton University in New Jersey \u2014 will monitor  atmospheric conditions and lightning strikes  there for the next 3 years, collecting data for 72-hour periods every 3 months. Mu\u00f1oz and his team will compare these data with projections from a lightning model that they have developed 2 , in the hope of producing a system that can accurately predict lightning frequency in this part of Venezuela months in advance. Such projections could help to improve the safety of rural, fishing and farming communities, the oil and gas industry and power grids. \u201cCan we say something about lightning activity three months in advance?\u201d asks Mu\u00f1oz. \u201cWe\u2019re showing that it\u2019s not only possible, but that forecasts in this part of the world are actually very skilful.\u201d But expanding that model to other regions might be difficult, says Andrew Dowdy, a climate scientist at the Australian Bureau of Meteorology in Melbourne. His research has shown 3  that the weather cycle known as the El Ni\u00f1o\u2013Southern Oscillation helps to create lightning patterns that differ by season and by region. Furthermore, a lack of long-term lightning observations in many parts of the world makes it difficult to separate the influence of climate change from variations in weather caused by local effects such as the expansion of urban heat islands. One study 4  projects that the frequency of lightning strikes in North America will increase by 12% for every degree Celsius of warming. \n             In a flash \n           Mu\u00f1oz\u2019s team developed its model using almost two decades of satellite lightning maps, plus data on winds, sea surface temperature and atmospheric pressure and moisture in the Lake Maracaibo Basin. The researchers will collect more such data this summer, using \u2018microweather\u2019 stations secured at fixed intervals along the tethers of weather balloons at altitudes of up to 1.4 kilometres. The stations transmit their observations to the ground every ten minutes by Wi-Fi, as ground-based detectors measure lightning activity. The researchers will also install a ground-based lightning sensor in Venezuela that will feed into a global monitoring network run by Robert Holzworth, an atmospheric and space physicist at the University of Washington in Seattle. Holzworth, who plans to install a further ten stations of his own at sites around the world in the next few months, says that the data they collect could help to reveal whether strike locations are changing as regional temperatures shift. Meanwhile, NASA is poised to launch two new space-based lightning sensors \u2014 continuing a record of satellite measurements that began in 1997. These sensors will be able to detect lightning in clouds, complementing ground-based measurements of strike locations. NASA\u2019s Geostationary Operational Environmental Satellite R-series weather satellite, scheduled to launch in November, will carry the world\u2019s first geostationary lightning mapper. The detector will provide 24/7 measurements of lightning over much of the Americas. That same month, the agency will send a spare lightning sensor to be installed on the International Space Station. \n                   Images expose thunder in exquisite detail 2015-May-05 \n                 \n                   Cosmic rays reveal the secrets of thunderstorms 2015-Apr-23 \n                 \n                   Parasitic vines may serve as lightning rods 2014-Jun-02 \n                 \n                   Lightning linked to solar wind 2014-May-16 \n                 \n                   Lightning network tested out in Guinea 2013-Oct-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20437", "url": "https://www.nature.com/articles/nature.2016.20437", "year": 2016, "authors": [{"name": "Ron Cowen"}], "parsed_as_year": "2006_or_before", "body": "Working alone, Jeff Steinhauer has created a sonic analogue of Hawking radiation. Jeff Steinhauer is no longer with the band. Years ago, the physicist played drums with a rock \u2018n\u2019 roll group at his department at the Technion\u2013Israel Institute of Technology in Haifa. But lately, he has been busy on a solo project: to trap noise, not create it. Working on his own since 2013, Steinhauer has been perfecting artificial, lab-made systems that suck in sound, rather as cosmic black holes trap light. The research involves the creation of atomic vibrations \u2014 sound waves \u2014 in accelerated, ultracold atoms. The sound waves cannot outrun the movement of the medium in which they were created: an analogue for the way in which the monstrous gravity of a black hole traps light radiation. In a paper published on 15 August 1 , Steinhauer \u2014 the sole author \u2014 reports that these imitation black holes  nevertheless emit sound waves  because of quantum-mechanical effects, in line with physicist Stephen Hawking\u2019s prediction 2 , 42 years ago, that cosmic black holes emit light. Hawking radiation has never been observed. But Steinhauer\u2019s sonic analogue, if confirmed, might provide a way to explore the effect. For physicists, one of the most striking aspects of the report is that Steinhauer published the finding alone. Most other groups that work on similar systems have at least a few postdocs and graduate students, says William Unruh, a physicist at the University of British Columbia in Vancouver, Canada, who in 1981 first predicted the creation of a sound-wave analogue of black holes 3 . \u201cIt\u2019s unusual to have just one person working on it,\u201d he says.\u00a0 \n             To his own tune \n           But that\u2019s no surprise to several people who are colleagues of Steinhauer or who have worked in his department. They describe him as intense, private and relentless: a virtual one-man band in the laboratory. \u201cHe\u2019s pretty persistent and some might even say stubborn,\u201d says Unruh. \u201cHe\u2019s the biggest perfectionist I\u2019ve ever seen,\u201d says Shahar Rinott, who earned a master\u2019s degree with Steinhauer at Technion and was one of six of Steinhauer\u2019s co-authors \u2014 all master\u2019s students who later left the lab \u2014 in a 2010 paper that reported the first sonic analogue of a black hole 4 . Even a minor equipment malfunction that did not interfere with an experiment would lead Steinhauer to halt work until he understood what went wrong, Rinott says. (Ultimately, Rinott says that he chose to leave Steinhauer\u2019s lab because, when it came time for his PhD, he wanted a doctorate adviser who allowed him more independence). Steinhauer says that he did not set out to work alone \u2014 and points out that, in the past few months, he has hired a postdoc. \u201cI probably have a reputation that it\u2019s difficult to work in my lab,\u201d he says \u2014 adding that the masters\u2019-degree students with whom he worked usually found it hard to learn the information needed for the experiments. But a one-man-lab has its advantages, he says: \u201cI\u2019m able to work on that one important project all day every day.\u201d Steinhauer, who turns 50 this week, has always been persistent, independent and a risk-taker. In his office at the Technion, he still keeps a racing bicycle that he assembled as a teenager, growing up in Los Angeles, California. The bicycle was built from parts that he bought using an insurance payout, after a near-fatal car accident mangled his old bike and broke his front teeth. After completing his PhD at the University of California, Los Angeles, in 1995, Steinhauer decided that he wanted to try to live in Israel, in part because of his Jewish roots. He hopped on a plane to Tel Aviv with no job to go to and a place to stay for a few days. \u201cMy mother thought I would come back after a few months,\u201d he says. But bar a year\u2019s postdoc position overseas in 2002, he has been there ever since. In the basement of the Technion\u2019s physics building, Steinhauer still keeps his drum set. His favourite tune? \u2018Black Hole Sun\u2019, by US rock band Soundgarden. \n                   Artificial black hole creates its own version of Hawking radiation 2016-Aug-15 \n                 \n                   Hawking\u2019s latest black-hole paper splits physicists 2016-Jan-27 \n                 \n                   Hawking radiation mimicked in the lab 2014-Oct-12 \n                 \n                   Astrophysics: Fire in the hole! 2013-Apr-03 \n                 Reprints and Permissions"},
{"file_id": "536260a", "url": "https://www.nature.com/articles/536260a", "year": 2016, "authors": [{"name": "Brian Owens"}], "parsed_as_year": "2006_or_before", "body": "Ecologists fear plan to seal off the United States from Mexico would put wildlife at risk. With Republican presidential candidate Donald Trump talking about walling off the United States from Mexico, ecologists fear for the future of the delicate and surprisingly diverse ecosystems that span Mexico\u2019s border with the southwestern United States. \u201cThe southwestern US and northwestern Mexico share their weather, rivers and wildlife,\u201d says Sergio Avila-Villegas, a conservation scientist from the Arizona-Sonora Desert Museum in Tucson. \u201cThe infrastructure on the border cuts through all that and divides a shared landscape in two.\u201d Trump\u2019s policies tend to be short on detail, but he has talked about sealing off the entire 3,200-kilometre border with a wall that would be 10\u201320 metres high. \u201cWe will build a wall,\u201d Trump says in a video on his campaign website. \u201cIt will be a great wall. It will do what it is supposed to do: keep illegal immigrants out.\u201d Constructing a wall \u201cwould be a huge loss\u201d, says Clinton Epps, a wildlife biologist at Oregon State University in Corvallis. \u201cWe know how important the natural movement of wildlife is for the persistence of many species.\u201d Far from being a barren wasteland, the US\u2013Mexico borderlands have some of the highest diversity of mammals, birds and plants in the continental United States and northern Mexico \u2014 including many threatened species. A wall could divide species that make a home in both nations. Bighorn sheep, for example, live in small groups and rely on cross-border connections to survive, says Epps. Other species, such as jaguars, ocelots and bears, are concentrated in Mexico but have smaller, genetically linked US populations. \u201cBlack bears were extirpated in West Texas, and it was a big deal when they re-established in the 1990s,\u201d Epps says. Breaking their links with Mexican bears could put the animals at risk again. And birds that rarely fly, such as roadrunners, or those that swoop low to the ground, such as pygmy owls, could also have trouble surmounting the wall. Such a physical barrier would worsen the habitat disruption caused by noise, bright lights and traffic near the border. And a wall would cut across rivers and streams that cross the border, severing a vital link. \u201cWhen water crosses the border, it unites ecosystems,\u201d says Avila-Villegas. \u201cIf we block the water, it affects nature on a much more fundamental level.\u201d Trump is not the first US politician to hit upon the idea of sealing the southern border. In 2006, President George W. Bush authorized the construction of a 1,126-kilometre border wall, of which nearly 1,100 kilometres were completed. The existing barriers are a mixture of 6-metre-high steel walls, \u2018bollard fences\u2019 made of steel pipes set upright in the ground about 5 centimetres apart, and lower vehicle barriers that Avila-Villegas says resemble the tank traps set on the beaches of Normandy during the Second World War. Few studies have explored these barriers\u2019 effects on animal populations, and there are not even any reliable baseline data on conditions before the barriers were built. Avila-Villegas has seen photos taken by border patrols of mountain lions running alongside the barriers or trying to climb over them, so he knows that the walls are causing the animals stress. But he has no real way of measuring it. A 2014 study found that the fencing in Arizona seemed to harm native wildlife, but had little impact on human movement ( J.\u00a0W.\u00a0McCallum  et\u00a0al. PLoS ONE   9,  e93679; 2014 ). In 2009, Epps published a paper setting out some of the potential threats to animal populations posed by Bush\u2019s wall, but he lacked the money to follow up with field studies ( A.\u00a0D.\u00a0Flesch  et\u00a0al. Conserv. Biol.   24,  171\u2013181; 2009 ). Now he is not sure such research would be possible, even with sufficient funds. \u201cThe border is not a friendly place any more,\u201d Epps says. \u201cI would be hesitant to send a grad student there.\u201d Avila-Villegas has first-hand experience of the difficulties that researchers face there. Ten years ago, he tried to collect some baseline data before Bush\u2019s barriers were built, but gave up for his own safety. \u201cIt\u2019s easy to ask why the research hasn\u2019t been done, but that ignores the fact that the border is a war zone,\u201d he says. \u201cI had to stop my field work because of law enforcement and the \u00adMinutemen\u201d \u2014 groups of armed private citizens who have taken it upon themselves to \u2018defend\u2019 the border against illegal crossings. And it has not got any easier. \u201cEvery time I \u2014 a Hispanic male with dark skin and long hair \u2014 am in the field, I get patrols, helicopters and ATVs [all-terrain vehicles] coming to check on what I\u2019m doing,\u201d Avila-Villegas says. He spends much of his time trying to promote conservation issues that affect Mexico and the United States by forging links between researchers and \u00adpolicymakers in both countries. But his dedication to an open border has also prompted him to take a more personal stand. After a dozen years in the United States, Avila-Villegas has finally applied for citizenship \u2014 so that, come November, he can vote against Trump and his wall. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     United States border fence threatens wildlife 2011-Aug-02 \n                   \n                     Wildlife caught in crossfire of US immigration battle 2006-Jul-26 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20434", "url": "https://www.nature.com/articles/nature.2016.20434", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Researchers will not lose out on existing EU grants. British scientists say they're relieved by a government promise to guarantee them funding for existing EU research projects, even after the country leaves the European Union. But the reassurance only partly allays concerns about Brexit's effect on UK science. The United Kingdom receives billions of euros for research from the European Union, mostly from its \u20ac74.8-billion (US$83.6-billion) Horizon 2020 (H2020) programme. June\u2019s  referendum vote for the nation to leave the EU  left British scientists worried that funding for existing multi-year projects could be yanked away. And the uncertainty led to reports of  EU collaborators deciding to drop UK scientists from future grant applications  \u2014 even though the United Kingdom is still a full member of the EU. But on 13 August,  the government announced  that it will step in to pay UK contributions to EU H2020 projects after Brexit, provided that the projects were bid for before the day that the UK leaves the EU (a date which has not yet been fixed). \u201cBy underwriting Horizon 2020 funding in this way today, we are again demonstrating the importance we place on maintaining the world leading research that takes place in the UK,\u201d  said UK science minister, Jo Johnson .  \n             Project disparities \n           Other types of EU project were given lesser guarantees. UK recipients of EU \u2018structural funds\u2019 (some of which are spent on research infrastructure) are to be assured funding only if they bid for them before an annual address on the nation's finances known as the 'Autumn Statement' \u2014 an event that typically takes place in November or December. Still, the promise ensures that, for example, the UK\u2019s University of Manchester can expect to receive \u00a35 million (US$6.4 million) from EU funds for a planned Graphene Engineering Innovation Centre. \u201cSince the referendum vote, the research community has been struggling with the uncertainty. This provides huge reassurance,\u201d says Sarah Main, director of the Campaign for Science and Engineering (CaSE) in London. The move will also reassure European collaborators, she says. \"This is encouraging news that provides much-needed stability for British universities during the transition period as the UK exits the EU, and provides an important signal to European researchers that they can continue to collaborate with their UK colleagues as they have before,\u201d said Alistair Jarvis, deputy chief executive of the higher-education umbrella group Universities UK in London. \n             The bare essentials \n           But the campaign group Scientists for EU issued a statement calling the announcement \u201cdecidedly underwhelming\u201d and \u201ca confirmation of the bare essentials, but nothing more\u201d. After Brexit, UK scientists may lose the ability to apply for H2020 funding, depending on the terms of the split. And the government has not committed to shoring up those potential lost funds with domestic grants, Scientists for EU pointed out. \u201cThis guarantee alleviates some of the uncertainties about existing and imminent H2020 grants, but does nothing to dispel fears about mobility between the UK and the rest of the EU following Brexit, which is integral to many H2020 schemes, nor does it address longer-term funding issues,\u201d says Paul Crowther, who heads the physics and astronomy department at the University of Sheffield, UK. Main says that she is still encouraged by the government\u2019s continued support for science. She cites another example of political positive intentions: a  letter from UK Prime Minister  Theresa May in July to the director of London\u2019s Francis Crick Institute, Paul Nurse, saying that the government was committed to ensuring a positive outcome for UK science. \u201cTo be honest, I\u2019m feeling positive,\u201d she says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                 \n                   Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                 \n                   Lessons from Brexit 2016-Jul-25 \n                 \n                   All  Nature 's Brexit coverage \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20446", "url": "https://www.nature.com/articles/nature.2016.20446", "year": 2016, "authors": [{"name": "Miquel Sureda Anfres"}], "parsed_as_year": "2006_or_before", "body": "Evidence against neonicotinoid chemicals mounts ahead of EU review. A dip in the populations of wild bees across the English countryside over nine years coincided with the use of chemicals called neonicotinoids on the crops in which the bees forage, ecologists say. The UK government-funded study, published on 16 August in  Nature Communications 1 , is the first to link the controversial insecticides to the decline of many bee species in real-world conditions. Previous work has studied the effects of the insecticides on bees in the laboratory, or on a few wild-bee species in a small number of fields over a few weeks 2 .\u00a0 \u201cOur results show that neonicotinoids are harmful to wild bees \u2014 we are very confident about that,\u201d says Nick Isaac, an ecologist at the Centre for Ecology & Hydrology (CEH) in Wallingford, UK, who worked on the study. The report feeds into a  raging debate  about whether to ban or restrict the widely used chemicals to help bee populations to recover. Many bee species are in decline around the world, although climate change, habitat loss, parasites and other insecticides besides neonicotinoids have all been linked to the problem, says Ben Woodcock, another ecologist at the CEH. The European Union has imposed a temporary ban on the use of three neonicotinoids \u2014 clothianidin, imidacloprid and thiamethoxam \u2014 in most cases. But some chemical manufacturers and farmers say that alternative insecticide treatments aren't as effective, and the United Kingdom  lifted the ban last year , arguing that \u201cemergency rules\u201d allowed use of the insecticides where crops were at greatest risk of pest damage. The European Food Safety Authority in Parma, Italy, is due to review the effects of the chemicals on bees by January 2017 \u2014 a report that could lead the EU to extend its ban. \n             Bees in trouble \n           In the United Kingdom, farmers were licensed to treat oilseed rape ( Brassica napus ) seeds with neonicotinoids starting in 2002; by 2011, four-fifths of such seeds were treated with these chemicals. Isaac and his colleagues looked at local records of the populations of some 62 wild-bee species from 1994\u20132011. After 2002, they observed an average decline of 13% in the bees' geographical spread. But the bee species that collected pollen and nectar in oilseed-rape fields were more badly affected than others. Based on their data, the researchers estimate that the neonicotinoids were responsible, on average, for a 7% decline in the bees' distribution \u2014 about half of the total drop. But in the case of the bees that forage in oilseed rape, the insecticides would have caused a 10% fall. The result is yet more evidence that neonicotinoids are involved in bee decline, says Christopher Connolly, who studies human and bee neuroscience at the University of Dundee, UK. \u201cThe evidence against neonicotinoids now exists in key bee brain cells involved in learning and memory, in whole bees, entire colonies, and now, at the level of whole populations of wild bees,\u201d he says. \n             Business battle \n           The study cannot show a causal relationship between neonicotinoid use and the decline of wild bees, says Utz Klages, a spokesperson for Bayer Crop Science in Monheim, Germany, one of the world\u2019s main neonicotinoid producers. The company has long argued that the evidence that the insecticides can harm bees is limited. But Richard Pywell, an ecologist at the CEH who was also involved in the study, says he thinks that the correlations between insecticide use and bee decline make a clear case. Pywell says that he cannot comment on whether the EU should continue its neonicotinoid ban. \u201cOur job isn\u2019t to decide about policies. It is to provide independent evidence to the EU and UK policymakers,\u201d he says.\u00a0 The problem for policymakers is how to control crop pests while encouraging a healthy diversity of pollinators such as bees, Woodcock says. \u201cYou can\u2019t just say, \u2018As long as we save the bees, everything else can go to hell\u2019,\u201d he says. \u201cWe also need to consider the effects of whatever pesticide is used instead of neonicotinoids when those are banned.\u201d \n                   Fears for bees as UK lifts insecticide ban 2015-Jul-23 \n                 \n                   Bee studies stir up pesticide debate 2015-Apr-22 \n                 \n                   Reports spark row over bee-bothering insecticides 2013-Jan-16 \n                 Reprints and Permissions"},
{"file_id": "536257a", "url": "https://www.nature.com/articles/536257a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "It is one of the last Caribbean countries to get hit. As soon as the rain stops, mosquitoes flood the guard house of an upscale tourist resort near Cuba\u2019s Bay of Pigs. Without hesitation, one of the guards reaches under his desk to pull out a device that looks like a very large hair dryer. \u201cMosquito gun,\u201d he says. He walks around, spraying a thick, white cloud of fumigant that engulfs the booth. Slowly, the mosquitoes disappear. It\u2019s not uncommon to see clouds of pesticide wafting through Cuba\u2019s houses and neighbour\u00adhoods. It is largely because of such intensive measures by ordinary citizens that the country has been among the last in the Caribbean to succumb to local transmission of Zika. As of 11\u00a0August, Cuba has recorded three people who were infected by local mosquitoes rather than contracting the illness abroad, compared with 8,766\u00a0confirmed cases in nearby Puerto Rico (see \u2018Zika in the Caribbean\u2019). Although scientists and public-health officials are disappointed that Zika has finally arrived in Cuba, they are not surprised. \u201cIt\u2019s not easy to avoid an introduction, because a lot of people are coming to Cuba from a lot of places,\u201d says Maria Guzm\u00e1n, head of virology at the Pedro Kour\u00ed Tropical Medicine Institute in Havana. The country has recorded about 30\u00a0confirmed imported cases. Zika is especially insidious because most people who have it show either no symptoms or only common ones such as fevers, which could be attributed to other illnesses. Yet, with the exception of one locally acquired case in March, Cuba mostly managed to keep Zika out until this month. \n               On the ball \n             That success was the result of its excellent health-care system and an extensive surveillance programme for vector-borne diseases that the government set up 35\u00a0years ago, says Ileana Morales, director of science and technology at Cuba\u2019s public-health ministry. In 1981, Cuba saw the first outbreak of haemorrhagic dengue fever in the Americas, with more than 344,000 infections. \u201cWe turned that epidemiological event into an opportunity,\u201d says Morales. The country sent medical workers to affected areas and began intensively spraying pesticides to eradicate the  Aedes aegypti  mosquito that carries the disease. It also created a national reporting system, as well as a framework for cooperation between government agencies and public-education campaigns to encourage spraying and self-monitoring for mosquito bites, even among children. One of the most effective measures was a heavy fine for people found to have mosquitoes breeding on their property, says Duane Gubler, an infectious-disease researcher at Duke\u2013NUS Medical School in Singapore. With all these measures in place, Cuba eliminated the dengue outbreak in four months. Now, when another outbreak threatens, \u201cit\u2019s no problem for us to reinforce our system\u201d and intensify such efforts, says Morales. In February, before any Zika cases had been detected in Cuba, the government dispatched 9,000\u00a0soldiers to spray homes and other buildings, while workers killed mosquito larvae in habitats such as waterways. Airport officials screened visitors arriving from Zika-infected countries and medical workers went from door to door looking for people with symptoms. The health-care system already conducts extensive prenatal examinations, so it is primed to detect Zika-caused birth defects such as microcephaly. Cristian Morales, head of the Cuba office of the Pan American Health Organization (PAHO), says that it is probably unrealistic for other countries to simply copy Cuba\u2019s mosquito-control programmes. The country\u2019s health-care network is one of the best in the developing world, and the decades-long stability of its government has ensured policy continuity and enforcement of measures such as fines. He adds that the most important aspects of a response, for any country, include collaboration between government sectors and increased surveillance. \n               Everyone\u2019s challenge \n             \u201cCuba probably does a better job of controlling mosquitoes than any other country in the Americas, but it hasn\u2019t been totally effective,\u201d says Gubler. This is partly due to dips in funding. A resurgence of dengue in 1997 was probably exacerbated by the fall of the Soviet Union, Cuba\u2019s major trading partner, which decimated the economy and weakened health funding. Another disadvantage stems from the 56-year-old US trade embargo, which prevents Cuba from acquiring drugs and medical supplies that include components made in the United States. It must instead buy them from other countries, such as China, often at higher cost. Yet success has come despite these issues. According to PAHO, health workers have intensified efforts to spray pesticides and eradicate standing water \u2014 where mosquitoes can breed \u2014 within 150 metres of the homes of each of the two most recent people to get Zika, in the southeastern province of Holguin. Workers are also searching houses for infected people and collecting mosquitoes for study. Guzm\u00e1n adds that Cuban researchers have begun to plan work on a Zika vaccine. She says that international cooperation will be important in helping Cuba and others to address Zika. \u201cIt\u2019s a problem of everybody. It\u2019s a new challenge for the world.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     US reviews plan to infect mosquitoes with bacteria to stop disease 2016-May-24 \n                   \n                     First Zika-linked birth defects detected in Colombia 2016-Mar-04 \n                   \n                     Dengue virus: Break-bone fever 2002-Apr-18 \n                   \n                     PAHO Epidemiological Update (Americas) \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20453", "url": "https://www.nature.com/articles/nature.2016.20453", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Labs are vying to build ever-bigger colliders against a backdrop of uncertainty about how particle physicists will make the next big discoveries. It was a triumph for particle physics \u2014 and many were keen for a piece of the action. The  discovery of the Higgs boson in 2012  using the world\u2019s largest particle accelerator, the Large Hadron Collider (LHC), prompted a pitch from Japanese scientists to host its successor. The machine would build on the LHC\u2019s success by measuring the properties of the Higgs boson and other known, or soon-to-be-discovered, particles in exquisite detail. But the next steps for particle physics now seem less certain, as discussions at the International Conference on High Energy Physics (ICHEP) in Chicago on 8 August suggest. Much hinges on whether the LHC unearths phenomena that fall outside the standard model of particle physics \u2014  something that it has not yet done  but on which  physicists are still counting  \u2014 and whether China\u2019s plans to build an LHC successor move forward. When Japanese scientists  proposed hosting the International Linear Collider (ILC) , a group of international scientists had already drafted its design. The ILC would collide electrons and positrons along a 31-kilometre-long track, in contrast to the 27-kilometre-long LHC, which collides protons in a circular track that is based at Europe\u2019s particle-physics laboratory, CERN (See 'World of colliders'). Because protons are composite particles made of quarks, collisions create a mess of debris. The ILC's particles, by contrast, are fundamental and so provide the cleaner collisions more suited to precision measurements, which could reveal deviations from expected behaviour that point to physics beyond the standard model. \n               Higgs study \n             For physicists, the opportunity to carry out detailed study of the Higgs boson and the heaviest, \u2018top\u2019 quark, the second most recently discovered particle, is reason enough to build the facility. Japan\u2019s Ministry of Education, Culture, Sports, Science and Technology (MEXT) was expected to make a call on whether to host the project \u2014 which could begin experiments around 2030 \u2014 in 2016. But the Japanese panel advising MEXT indicated last year that opportunities to study the Higgs boson and the top quark would not on their own justify building the ILC, and that it would wait until the end of the LHC's first maximum-energy run \u2013 scheduled for 2018 \u2013 before making a decision. That means the panel is not yet convinced by the argument that the ILC should be built irrespective of what the LHC finds, says Masanori Yamauchi, director-general of Japan\u2019s High Energy Accelerator Research Organization (KEK) in Tsukuba who sat on an ICHEP panel at a session on future facilities. \u201cThat\u2019s the statement hidden under their statement,\u201d he says. If the LHC discovers new phenomena, these would be further fodder for ILC study \u2014 and would strengthen the case for building the high precision machine. US physicists have long backed building a linear collider. And a joint MEXT and US Department of Energy group is discussing ways to reduce the ILC\u2019s costs, says Yamauchi, which are now estimated at US$10 billion. A reduction of around 15% is feasible \u2014 but Japan will need funding commitments from other countries before it formally agrees to host, he added.  \n               Chinese competitor \n             Snapping at Japan\u2019s heels is a Chinese team. In the months after the Higgs discovery, a team of physicists led by  Wang Yifang , director of the Institute of High Energy Physics in Beijing, floated a  plan to host a collider  in the 2030s, also partially funded by the international community and focused on precision measurements of the Higgs and other particles. Circular rather than linear, this 50\u2013100-kilometre-long electron\u2013positron smasher would not reach the energies of the ILC. But it would require the creation of a tunnel that could allow a proton\u2013proton collider \u2014 similar to the LHC, but much bigger \u2014 to be built at a hugely reduced cost. Wang and his team this year secured around 35 million yuan (US$5 million) in funding from China\u2019s Ministry of Science and Technology to continue research and development for the project, Wang told the ICHEP session. Last month, China\u2019s National Development and Reform Commission turned down a further request from the team for 800 million yuan, but other funding routes remain open, Wang said, and the team now plans to focus on raising international interest in the project. By affirming worldwide interest in Higgs physics, the Chinese proposal bolsters Japan\u2019s case for building the ILC, says Yamauchi. But if it goes ahead, it could drain international funding from the ILC and put its future on shakier ground. \u201cIt may have a negative impact,\u201d he says. \n               Super-LHC \n             In the future, the option to use China's electron\u2013positron collider as the basis for a giant proton\u2013proton collider could interfere with CERN\u2019s own plans for a 100-kilometre-circumference circular machine that would smash protons together at more than 7 times the energy of the LHC. Until the mid-2030s, CERN will be busy with an upgrade that will raise the intensity \u2014 but not the energy \u2014 of the LHC\u2019s proton beam. And by that time, China might have a suitable tunnel that could make it harder to get backing for this \u2018super-LHC\u2019. At ICHEP,  Fabiola Gianotti , CERN\u2019s director-general, floated an interim idea: souping up the energy of the LHC beyond its current design by installing a new generation of superconducting magnets by around 2035. This would provide a relatively modest boost in energy \u2014 from 14 teraelectronvolts (TeV) to 28 TeV \u2014 that would have a strong science case if the LHC finds new physics at 14 TeV, said Gianotti. Its $5-billion price tag could be paid for out of CERN\u2019s regular budget. For decades, successive facilities have found particles predicted by the standard model, and neither the LHC nor any of its proposed successors is guaranteed to find new physics. Questions asked at the ICHEP session revealed some soul-searching among attendees, including a plea to reassure young high-energy physicists about the future of the field and contemplation of whether money would be better spent on other approaches rather than ever-bigger accelerators. Indeed, the US is betting on neutrinos, fundamental particles that  could reveal physics beyond the standard model , not colliders. The Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois, hopes to become the world capital of neutrino physics by hosting the $1-billion Long-Baseline Neutrino Facility, which will beam neutrinos to a range of detectors starting in 2026. Funding will require approval from US Congress in 2017. But at the ICHEP session, Fermilab director Nigel Lockyer was confident: \u201cWe are beyond the point of no return. It is happening.\u201d\u00a0 \n                     Hopes for revolutionary new LHC particle dashed 2016-Aug-05 \n                   \n                     LHC 2.0: A new view of the Universe 2015-Mar-11 \n                   \n                     China plans super collider 2014-Jul-22 \n                   \n                     Japan in pole position to host particle smasher 2012-Dec-14 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20436", "url": "https://www.nature.com/articles/nature.2016.20436", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Recent decisions seem to drive spike in patent rejections. Rejections for US patents related to personalized medicine have spiked after recent Supreme Court decisions tightened the rules for such claims, an analysis of more than 39,000 patent applications reveals. The data, presented on 11 August at the  Intellectual Property Scholars Conference  in Stanford, California, address patent applications in eight categories that commonly include personalized-medicine patents. They show that following  a key Supreme Court decision in 2012 , the US Patent and Trademark Office (USPTO) was nearly four times more likely to deem subjects of such applications unpatentable \u2014 and applicants were less than half as likely to overcome those rejections. \u201cThe change in office actions was absolutely striking,\u201d says Nicholson Price, who studies intellectual property at the University of Michigan Law School in Ann Arbor. \u201cThe data are very clear that the patent office has changed its behaviour.\u201d Over the past decade, the Supreme Court has used  a series of patent cases  to clarify what the USPTO should consider patentable. Natural phenomena and abstract ideas, for example, are not patentable, according to section 101 of the US patent code, and the court has attempted to distinguish between these categories and true inventions. Two of those Supreme Court cases touched directly on the biomedical industry. In 2012, the  Mayo Collaborative Services v. Prometheus Laboratories, Inc.  decision  struck down two patents on medical diagnostics , and in the 2013  Association for Molecular Pathology v. Myriad Genetics  ruling, the court  threw out patents on gene sequences  used to assess cancer risk. In the wake of those decisions, many lawyers predicted that patents on inventions that are important to personalized medicine \u2014 particularly, diagnostic tests that could match individuals to a particular therapy \u2014 would be hard to come by, potentially driving away investors. \n               Numbers game \n             Legal scholar Bernard Chao of the University of Denver in Colorado decided to find out just how big the impact has been. Chao sifted through around 85,000 records of USPTO actions taken on more than 39,000 patent applications, and sorted out those that had been rejected for not meeting the requirements of section 101. He found that last year, 22.5% of those office actions were rejections because of section 101, compared with only 5.5% in 2011, the year before the  Mayo  decision. Applicants were also less likely to overcome those rejections in the wake of the  Mayo  decision: before  Mayo , 70.7% of the section 101 rejections were successfully overcome. After  Mayo , that percentage dropped to 29.7%. But Chao notes that there are caveats to his analysis: the categories he examined omit some personalized-medicine patents and contain other kinds of patents as well. In the future, he hopes to take a closer look at individual patent applications, and to learn more about whether certain applications are more likely to get through than others. Those analyses will be key to finding out how patent applicants are adapting to the new requirements, says Price. \u201cPatent attorneys are clever,\u201d he says, and may have learned how to construct their patents to avoid conflict with the recent decisions. Others have documented a clear effect of the Supreme Court\u2019s patent decisions on software patent applications. But some have cheered that change, Chao adds. Software patents are controversial, and some scholars have argued that such patents cause more harm to the industry than help it. Personalized-medicine patents, however, tend to get more support: \u201cPersonalized medicine is probably the poster child of what we think should be incentivized by patents.\u201d Ultimately, it will be difficult to unravel what impact the patent decline is having on the personalized-medicine industry, cautions Arti Rai, a legal scholar at Duke University in Durham, North Carolina. The sector is facing challenges from several sides: the US Food and Drug Administration has proposed tougher regulations, and insurance companies have been reluctant to pay for new diagnostic tests. \u201cDiagnostics start-ups are not in a good space right now, that\u2019s clear,\u201d Rai says. \u201cBut how much of that is due to  Mayo  is less clear.\u201d \n                     Myriad Genetics embroiled in breast-cancer data fight \u2014 again 2016-May-20 \n                   \n                     Biotech reels over patent ruling 2014-Jul-08 \n                   \n                     Cancer-gene data sharing boosted 2014-Jun-10 \n                   \n                     Software patents await legal fate 2014-Mar-25 \n                   \n                     Myriad ruling causes confusion 2013-Jun-18 \n                   \n                     US Supreme Court upends diagnostics patents 2012-Mar-21 \n                   \n                     US Supreme Court:  Mayo v. Prometheus  decision \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20451", "url": "https://www.nature.com/articles/nature.2016.20451", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "The altered  Escherichia coli  represent the most extensive reengineering yet of an organism\u2019s genetic code. Synthetic biologists report the most far-reaching rewiring yet of a bacterial genome. The feat, described today in  Science , involved repurposing 3.8% of the base pairs of the bacterium  Escherichia coli 1 . The scientists replaced 7 of its 64 genetic codons \u2014 sequences that code for amino acids \u2014 with others that produce the same components. They were able to reduce the number of codons by synthesizing the DNA in 55 fragments, each of which was 50,000 base pairs long. They have yet to reassemble those pieces into a functioning  E. coli . Despite that, the team, led by researchers at Harvard Medical School in Boston, Massachusetts, say that it is a major step in the push to engineer organisms with new properties, such as resistance to infection by viruses. The synthetic biologists, including George Church at Harvard, reported their results on 18 August in  Science 1 . They say the work also serves as a prototype for the Human Genome Project\u2014Write, in which scientists aim to  synthesize a human genome . \n             Big changes \n           \u201cThis is a demonstration that that kind of radical reengineering is feasible,\u201d Church says. \u201cGoing down from 64 to 57 codons is a dramatic departure from what exists in nature,\u201d says Farren Isaacs, a synthetic biologist at Yale University in New Haven, Connecticut, who worked with Church on previous recoding studies but was not involved in this project. \u201cIt\u2018s an important step forward for demonstrating the malleability of the genetic code and how entirely new types of biological functions and properties can be extracted from organisms through genomes that have been recoded.\u201d Church\u2019s lab and others have previously shown 2  that it is possible to  recode single amino acids  in  E. coli  so that the bacterium can incorporate amino acids not found in nature. Such reprogrammed organisms are highly resistant to viral infection, because they no longer contain the genetic machinery common to all natural organisms that viruses exploit to survive. They can also be made  entirely dependent  on synthetic amino acids in their diets, to allay the fear that recoded bacteria could escape from a lab and wreak havoc in the wild. \n             We have the technology \n           The recoding used in the latest study is a painstaking process, and it probably would not have been possible just a few years ago. The speed of engineering and synthesizing DNA has increased massively over the past decade, enabling much more ambitious genetic-engineering projects. \u201cThis project is at an unprecedented scale; it\u2019s the largest completely synthesized genome that has ever been produced, and by far the most functional changes\u201d that have been introduced into a genome, says Marc Lajoie, a synthetic biologist who worked on the project in Church's lab and is now at the University of Washington in Seattle. Scientists led by genomic entrepreneur Craig Venter of the J. Craig Venter Institute in La Jolla, California, announced in March that they had created a  synthetic genome  based on a bacterial genome with all unnecessary genes removed. But that organism\u2019s genome was an order of magnitude smaller than  E. coli \u2019s. Church and his team are now attempting to stitch the DNA segments of their recoded  E. coli  into one continuous genome. They will then test whether that reconstituted organism is capable of life. Church says it is unclear how long this will take; members of his lab estimate that it could be anywhere from four months to four years. \u201cIt will be a big effort, but it looks like it's going to happen,\u201d says Isaacs. \n                   Plan to synthesize human genome triggers mixed response 2016-Jun-02 \n                 \n                   \u2018Minimal\u2019 cell raises stakes in race to harness synthetic life 2016-Mar-24 \n                 \n                   GM microbes created that can\u2019t escape the lab 2015-Jan-21 \n                 \n                   Genomes edited to free up codons 2011-Jul-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20449", "url": "https://www.nature.com/articles/nature.2016.20449", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Easy gene alterations in weird creatures make CRISPR a killer app for evolutionary developmental biology. Most summers since 1893, young developmental and evolutionary biologists have flocked to Woods Hole, Massachusetts, to master the tricks of their trade. At the world-famous Marine Biological Laboratory there, students in its annual embryology course dissect sea urchins and comb jellies, and graft cells together from different animals. But for the last three years, the keen apprentices have been learning something new: gene editing. The precise, efficient CRISPR\u2013Cas9 gene-editing technique has already  taken life-sciences labs by storm . Now it is sweeping through evo-devo, the field that seeks to explain the developmental changes underlying evolutionary adaptations. Rather than simply infer what caused historic transitions, such as how fish developed limbs, scientists can check their hypotheses directly with CRISPR. The idea is simple: cut out the fish genes thought to be involved in making fins, and see whether the fish start to form something resembling feet. That is exactly what researchers report today in  Nature , using CRISPR to help explain how fish developed feet and started walking 1 . Others have wielded the technique to determine how butterflies evolved exquisite colour vision, and how crustaceans acquired claws. \u201cCRISPR is a revolution all across biology, but for evo-devo it\u2019s transformative,\u201d says Arnaud Martin, an evolutionary developmental biologist at George Washington University in Washington DC. \u201cWe can do things we were not able to do before.\u201d \n             How fins became feet \n           Neil Shubin, a palaeontologist and developmental biologist at the University of Chicago in Illinois, has used gene-editing to examine how the tips of fish fins, or rays, were replaced by feet and digits in four-legged land vertebrates, or tetrapods. While researchers know that ancient fish developed limbs \u2013 Shubin led the team that in 2004 discovered  a 375-million-year-old fossil that seemed to catch that transition in the act  \u2013 they also thought that the foot was an evolutionary novelty without an equivalent in fish, because rays and feet are made of different kinds of bone. But Shubin says gene-editing has changed his mind. His team used CRISPR to engineer zebrafish lacking various combinations of the several  hox13  genes they possess \u2013 genes that researchers already thought played an important role in laying down fin rays. None of the mutants grew fully fledged feet, Shubin notes, but some possessed \u201cfingery fins\u201d made of the same kind of bone that builds fingers and toes in tetrapods. \u201cAs a palaeontologist I studied and trained thinking these are two different kinds of bones that are completely unrelated developmentally or evolutionarily,\u201d says Shubin. \u201cThese results challenge that assumption.\u201d The zebrafish is a popular model organism, whose genome is regularly manipulated in the lab. But CRISPR vastly sped up the experiments performed by Shubin's team. One next step will be to knock out  hox13  genes in fish species that more closely resemble the ancient fish that gained limbs, say Aditya Saxena and Kimberly Cooper, evolutionary developmental biologists at the University of California, San Diego. Those experiments are now conceivable thanks to CRISPR, they note in a  commentary  that accompanies Shubin's article[2]. \n             Editing crabs and butterflies \n           There is little reason to think the technique will not work on other, more esoteric species, too. \u201cCRISPR seems to be universally working in any organism,\u201d says Martin, who has successfully applied the technique to a marine crustacean called  Parhyale hawaiensis,  which is gaining popularity in evo-devo. In a January  Current Biology  paper, he and colleague Nipam Patel, at the University of California, Berkeley, found that inactivating different Hox genes in the species messes with the development of specialized appendages such as antennae and claws 3 . If scientists can successfully rear an animal in the lab so they can gain access to its eggs, they should be able to use CRISPR, Martin says. Such flexibility is important for evo-devo researchers, says Claude Desplan, a developmental neurobiologist at New York University, whose team applied CRISPR to yellow swallowtail butterflies in a  Nature  paper published last month, to test a theory about how photoreceptors in their eyes detect a broader spectrum of colours than insects such as fruit flies 4 . On-going experiments in his lab have applied gene-editing to wasps and ants. So far, evo-devo researchers have focused on using CRISPR to eliminate a gene\u2019s activity or to introduce genes, such as the one encoding green fluorescent protein, that make it possible to better track an animal\u2019s development 5 . But Martin expects researchers will soon begin using the tool to precisely alter DNA sequences in animals to test ideas about specific genetic changes. Those could include changes to regulatory DNA sequences that influence where and when a gene is active, which may have contributed to adaptations such as tetrapod limbs. Researchers could also make an educated guess at the DNA sequences of ancient transitional creatures and insert those into living animals using CRISPR, says Bhart-Anjan Bhullar, a palaeontologist at Yale University in New Haven, Connecticut. Last year, his team used chemicals to modify development pathways in chickens that they thought helped to  mould the snouts of theropod dinosaurs into modern birds\u2019 beaks . He hopes to now be able to do such experiments with CRISPR. Bhullar, who attended last month\u2019s embryology course at Woods Hole, says he\u2019s impressed by the success of gene-editing trials by students there, where scientists had the chance to use CRISPR editing on zebrafish, the crustacean  P. hawaiensis , frogs, slipper snails and sea squirts. With CRISPR, \u201cstuff just works\u201d, Bhullar says. \u201cThis is rapidly going to become the standard in evolutionary developmental biology.\u201d Read the related News & Views article, \" Fin to limb within our grasp \". \n                   Welcome to the CRISPR zoo 2016-Mar-09 \n                 \n                   CRISPR: gene editing is just the beginning 2016-Mar-07 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   'Dino-chickens' reveal how the beak was born 2015-May-12 \n                 \n                   How fish can learn to walk 2014-Aug-27 \n                 \n                   The fish that crawled out of the water 2006-Apr-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20458", "url": "https://www.nature.com/articles/nature.2016.20458", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Imaging technique reveals dopamine surges as mice learn to associate a sound with pleasure. Neuroscientists have invented a way to watch the ebb and flow of the brain's chemical messengers in real time. They were able to see the surge of neurotransmitters as mice were conditioned \u2014 similarly to Pavlov's famous dogs \u2014 to salivate in response to a sound. The study, presented at the American Chemical Society\u2019s meeting in Philadelphia, Pennyslvania, on 22 August, uses a technique that could help to disentangle the complex language of neurotransmitters. Ultimately, it could lead to a better understanding of brain circuitry. The brain\u2019s electrical surges are easy to track. But detecting the chemicals that drive this activity \u2014 the neurotransmitters that travel between brain cells and lead them to fire \u2014 is much harder. \u201cThere\u2019s a hidden signalling network in the brain, and we need tools to uncover it,\u201d says Michael Strano, a chemical engineer at the Massachusetts Institute of Technology in Cambridge. In many parts of the brain, neurotransmitters can exist at undetectably low levels. Typically, researchers monitor them by sucking fluid out from between neurons and analysing the contents in the lab. But that technique cannot measure activity in real time. Another option is to insert a metal probe into the space between neurons to measure how neurotransmitters react chemically when they touch metal. But the probe is unable to distinguish between structurally similar molecules, such as dopamine, which is involved in pleasure and reward, and noradrenaline which is involved in alertness. \n             Fluorescence fix \n           Enter neuroscientist Paul Slesinger of the Icahn School of Medicine at Mount Sinai in New York City and neurophysicist David Kleinfeld of the University of California, San Diego. In May, they reported a method for making genetically modified human cells that produce artificial receptors for neurotransmitters. These receptors are also linked to fluorescent molecules so that when a particular neurotransmitter binds to its receptor, the cell lights up 1 . The researchers injected these cells, known as CNiFERs (cell-based neurotransmitter fluorescent engineered reporters) into the brains of 13 mice. Then, they cut a window into each mouse\u2019s skull to expose its brain and put a transparent cover over the hole so that they could watch the cells light up in real time through a microscope. Over the course of five days, the researchers trained the mice by playing a sound before giving them a sugar treat. The mice soon learned to salivate in anticipation as soon as they heard the sound. Each day, the researchers recorded light from the animals\u2019 brains, enabling them to determine the exact moment at which neurotransmitters were released. For the first time, they could see a surge of dopamine \u2014 the pleasure molecule that drives salivation \u2014 after the sound that occurred more rapidly as the association became stronger. Noradrenaline, a molecule involved in alertness, is also thought to surge in this type of learning, but researchers have never been able to distinguish it from dopamine in real time. But by engineering CNiFERs specific to each neurotransmitter, Slesinger and Kleinfeld showed, also for the first time, that the noradrenaline spike occured at variable times following the tone and did not change with training. This suggests that the neurotransmitter could be responding to some other factor or behavioural reaction. The ability to use separate CNiFERs for the two neurotransmitters might eventually reveal whether noradrenalin has a role in learning and addiction, and whether drugs that target it are likely to change behaviour. \n             Mapping methods \n           Strano says that the technique is an improvement on current methods because it quantifies neurotransmitters directly instead of calculating them through their effects. \u201cIt\u2019s one of the purest tests you can do,\u201d he says. But he worries that genetically modified cells might not act the same way as natural cells. His lab is working on a set of nanotubes that cross the blood\u2013brain barrier and emit light when they encounter a neurotransmitter in the brain 2 . But Lin Tian, a neuroscientist at the University of California, Davis, thinks that the technique is of limited use. The CNiFERs show whether the total amount of a molecule such as dopamine is increasing or decreasing, but they do not reveal which neuron is sending or receiving the signal \u2014 making it hard to map tangled brain circuits. Instead, Tian and her colleagues are modifying bacterial proteins so that they bind neurotransmitters and emit light. This technique is precise enough to detect the signalling molecule glutamate in a single gap between two neurons, thus revealing the exact cells involved 3 . Tian says that CNiFERs might be more useful for amino-acid-based neuropeptides, such as orexin, which is involved in sleep and drug-seeking behaviours. These larger molecules are more difficult to detect with chemical techniques. Slesinger says that he and his collaborators are working on CNiFERs for this and other neuropeptides. \u00a0 All of the researchers are trying to expand the repertoire of neurotransmitters that can be detected. Kleinfeld says that CNiFERS are unlikely to be used in humans any time soon because implanting cells into the brain could be dangerous. But they might be used to detect whether drugs are working in mice, and they are sensitive enough to reveal, perhaps, more subtle ways in which the brain malfunctions. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Implant aims to track brain signals in real time 2013-Nov-12 \n                 \n                   Cell signalling: It's all about the structure 2011-Aug-24 \n                 \n                   Cell signalling caught in the act 2011-Jul-19 \n                 \n                   252nd American Chemical Society National Meeting & Exposition \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20448", "url": "https://www.nature.com/articles/nature.2016.20448", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Nineteen species delisted from Endangered Species Act in past seven years. More species protected by the US Endangered Species Act (ESA) have recovered during President Barack Obama\u2019s administration than under all other presidents combined, the US Department of Interior announced on 11 August. And 2016 marks a record high for species recovery, with six so far officially \u2018delisted\u2019 from ESA\u2019s roster. The ESA, passed in 1973 to assist the recovery and protection of imperilled species and ecosystems, is widely seen as a  landmark piece of environmental legislation . During Obama\u2019s presidency, 19 species have now recovered and been delisted; this compares to seven such removals under George W. Bush, six during Bill Clinton\u2019s administration and five under Ronald Reagan. That may simply be a result of the 43-year-old ESA legislation finally starting to pay dividends, says Noah Greenwald, director of endangered species at the Center for Biological Diversity, a non-profit conservation group headquartered in Tucson, Arizona. \u201cIt also reflects the fact that the Obama administration has been putting more resources into processing delistings for recovered species, in an effort to counter attacks from Republicans in Congress who say the law has a poor success rate,\u201d he adds. The latest delistings are of three subspecies of fox native to California\u2019s Channel Islands ( Urocyon littoralis  ssp.). The Department of Interior says that the foxes, listed in 2004, represent the \u201cfastest successful recovery\u201d of any ESA mammal, crediting efforts including a captive-breeding programme and a vaccination campaign against a canine virus. But the ESA process does not move as quickly as it should when it comes to listing species for protection in the first place, according to research by Greenwald and his colleagues. In a report 1  published last month, they calculate that it takes a species on average 12 years to be listed after first consideration \u2014 much more than the two years that the law says it should. Read a previous Trend Watch: ' US grants for zebrafish studies on the rise ' \n                   Biodiversity: The ravages of guns, nets and bulldozers 2016-Aug-10 \n                 \n                   Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                 \n                   Conservation: The Endangered Species Act at 40 2013-Dec-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20347", "url": "https://www.nature.com/articles/nature.2016.20347", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "July\u2019s sharpest science shots, selected by  Nature \u2019s photo team. \n             Dusky shark \n           A blacktip reef shark ( Carcharias melanopterus ) cruises at dusk in this picture by James Lea. The image was shot at D\u2019Arros Island in the Seychelles, where  researchers have been tracking sharks  to test the effectiveness of local marine protected areas. \n             Environmental Photographer of the Year \n           \n             Juno in July \n           NASA\u2019s Juno probe became the\u00a0 first spacecraft to visit Jupiter \u00a0in more than two decades earlier this month. This shot is a composite of some of the images\u00a0 it took on 10 July \u00a0as it orbited the gas giant. \n             Dragon down \n           SpaceX\u2019s Falcon 9 rocket not only blasts off, it also blasts down as it lands for re-use. Photographer  John Kraus \u2019s image shows both burns from the 18 July launch and landing. \n             Mountain parrot \n           Described by the International Union for Conservation of Nature as an  \u201cinquisitive alpine parrot \u201d, the kea ( Nestor notabilis ) is at risk: just a few thousand are thought to be left in New Zealand. This image was captured by the BBC as part of its series  New Zealand: Earth\u2019s Mythical Island , which began this month. \n             Hatchet job \n           Because we at\u00a0 Nature\u00a0 never get tired of seeing what\u00a0 \u2018Fish Guy\u2019 \u00a0and University of Washington biomechanist Adam Summers can do with a fish skeleton. This is a freshwater hatchetfish ( Thoracocorax stellatu ), dyed to reveal its internal structure. \n             Human sensor \n           The \u2018 human sensor\u2019  costume designed by artist Kasia Molga reacts to local air pollution by changing colour. This month it went out and about to reflect local air quality in Manchester, UK, supported by the  Invisible Dust science\u2013art project . \n             Solar triumph \n           The fuel-free plane  Solar Impulse 2  finally completed its round-the-world trip this month, more than a year after it set off. It is shown here landing in Abu Dhabi at the end of its circumnavigation \u2014 the first by a solar-powered plane. \n                   Spacemen returning, high-tech turtles and an Antarctic rescue 2016-Jun-24 \n                 Reprints and Permissions"},
{"file_id": "536018a", "url": "https://www.nature.com/articles/536018a", "year": 2016, "authors": [{"name": "Daniel Cressey"}, {"name": "Ramin Skibba"}, {"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "A graphical guide to the impact of the Olympics on science. Whether it\u2019s drug scandals, pollution problems or sheer curiosity at the incredible capabilities of the athletes, the Olympic Games have long fascinated researchers as well as the general public. In recent decades, research has increased on the selection of Olympic sites, environmental issues and the Games\u2019 ability to encourage people to participate in sport, says sports-medicine specialist Lars Engebretsen, who heads science and research for the International Olympic Committee. The Olympics don\u2019t typically inspire researchers to start new fields\u00a0\u2014\u00a0instead, they tend to feed into ongoing studies, says Vanessa Heggie, a historian of science and sports medicine at the University of Birmingham, UK. As the 2016 summer Games kick off in Rio de Janeiro,  Nature  uses bibliometrics to provide insight into the who, where, what, how and why of Olympic science. \n               \u2022 Surge in science \u2022 Papers per games \u2022 The disciplines compete \u2022 Greece takes gold \u2022 Citations in the city \n             \n               Surge in science \n             The proportion of research papers that are about the Games has risen rapidly. Over the past few decades, the Olympics has also expanded the number of events, drawn more participants and become vastly more expensive. \n               Papers per games \n             Beijing 2008 inspired the most papers, followed by London 2012. Beijing had imposed special restrictions on air pollutants, providing a rare opportunity for researchers to do relatively controlled experiments, says David Rich, an environmental epidemiologist at the University of Rochester in New York. The London 2012 Olympics inspired topics ranging from urban development and sprawl to security and surveillance. \n               The disciplines compete \n             The social sciences have generated the most Olympics papers\u00a0\u2014\u00a0with medicine and engineering winning silver and bronze, respectively. The Olympics are an \u201curban change-maker\u201d, says sociologist Jacqueline Kennelly at Carleton University in Ottawa, Canada. They have led to expensive infrastructure projects and placed huge demands on public transport. And those that have contended with world wars, protests, boycotts and terrorist attacks have generated substantial literature. Social scientists have also used the Games to study diverse topics such as the relationships between athletes and coaches ( R. A. Philippe and R. Seller  Psychol. Sport Exer.   7,  159\u2013171; 2006 ) and how much the medal count influences national pride ( I. van Hilvoorde  et al. Int. Rev. Sociol. Sport   45,  87\u2013102; 2010 ). \n               Greece takes gold \n             The countries that have published the most Olympics research are the usual science powerhouses. But divide the number of Olympics papers by the total number of papers published by that country\u00a0\u2014\u00a0and different nations take the lead, with Greece at the front of the pack. The Olympic Games date back to the eighth century\u00a0bc, and Greek scientists are naturally proud of their heritage, says Minas Samatas, a political sociologist at the University of Crete in Rethymno, who studied the 2004 Olympics in Athens. Norway boasts the second highest fraction of Olympics papers, and has won the most medals in the winter Games. Most of its 61 papers are about the winter Games or winter sports, especially skiing. \n               Citations in the city \n             The paper that has generated the most citations focuses on the Atlanta 1996 Games, and is followed closely by one about Beijing 2008. Both articles explore how policies\u00a0such as increased provision of public transportation\u00a0can improve air quality. The fifth most highly cited paper analysed levels of enthusiasm about the 2000 Olympics among different resident groups in the host city, Sydney. It is the most highly cited Olympics paper in the social sciences. \n               Methodology \n             Using the Scopus database,  Nature  searched for articles that have \u201cOlympics\u201d or \u201cOlympic Games\u201d in the title or \u201cOlympic Games\u201d in the abstract. \n                 Tweet \n                 Follow @NatureNews \n               \n                     China by the numbers 2016-Jun-22 \n                   \n                     The top 100 papers 2014-Oct-29 \n                   \n                     Science at the Olympics: Team science 2012-Jul-18 \n                   \n                     The Olympic Games \n                   Reprints and Permissions"},
{"file_id": "536016a", "url": "https://www.nature.com/articles/536016a", "year": 2016, "authors": [{"name": "Simon Oxenham"}], "parsed_as_year": "2006_or_before", "body": "Researcher who spent months chasing permission to republish online data sets urges others to read up on the law. Knowledge from millions of biological studies encoded into one network \u2014 that is Daniel Himmelstein\u2019s alluring description of  Hetionet , a free online resource that melds data from 28 public sources on links between drugs, genes and diseases. But for a product built on public information, obtaining legal permissions has been surprisingly tough. When Himmelstein, a data scientist at\u00a0the University of Pennsylvania in Philadelphia, contacted researchers for permission to reproduce their work openly, several said they were surprised that he had to ask. \u201cIt never really crossed my\u00a0mind that licensing is an issue here,\u201d says\u00a0J\u00f6rg Menche, a bioinformatician at the Research Center for Molecular Medicine of the Austrian Academy of Sciences in Vienna. Menche rapidly gave consent \u2014 but not everyone was so helpful. One research group never replied to Himmelstein, and three replied without clearing up the legal confusion. Ultimately, Himmelstein published the final version of Hetionet in July \u2014 minus one data set whose licence forbids redistribution, but including the three that he still lacks clear permission to republish.  The tangle  shows that many researchers don\u2019t understand that simply posting a data set publicly doesn\u2019t mean others can legally republish it, says Himmelstein. The confusion has the power to slow down science, he says, because researchers will be discouraged from combining data sets into more useful resources. It will also become increasingly problematic as scientists publish\u00a0more information online. \u201cScience is becoming more and more dependent on reusing data,\u201d Himmelstein says. \n               Data-set laws \n             Because a piece of data \u2014 a fact \u2014 cannot be copyrighted, many scientists think that a publicly posted data set that does not place explicit terms and conditions on access can simply be republished without legal problems. But that\u2019s not necessarily correct, says Estelle Derclaye, a specialist in intellectual-property law at the University of Nottingham, UK. The European Union assigns specific database rights, independent of copyright, that aim to protect the investment made in compiling a database. Legally speaking, these rights prevent researchers such as Himmelstein from republishing data sets created by scientists in EU states without their consent. Other countries have different layers of legal protection. But even in jurisdictions such as the United States, where no separate rights exist to govern databases, there is still room for confusion. Although facts don\u2019t qualify for\u00a0copyright, the way they are compiled \u00adarguably might \u2014 if the act of making that compilation requires sufficiently creative expression. \u201cThe default legal position on how\u00a0data may be used in any given context is hard to untangle,\u201d according to a  guide on licensing data  issued by the Digital Curation Centre in Edinburgh, UK. Advocates of data-sharing accordingly recommend that researchers who are creating public databases add clear licences explaining how they intend their data to be reused and redistributed, and whether they waive any database rights. \n               Lack of confidence \n             In Himmelstein\u2019s case, some of the data sets that he wanted to use had clear licences \u00ad\u2014 and some of these prevented unrestricted redistribution, but others did not. The most frustrating part of his project, he says, was the feeling that good data were going to waste because their creators could not clarify whether he could republish them. Andrew Charlesworth, an intellectual-\u00adproperty expert at the University of \u00adBristol, UK, says that this may be because few re\u00ad\u00adsearchers were confident enough of the law to give Himmelstein clear guidance. \u201cWhat you tend to find is that if nobody has a remit to answer those kinds of questions, they are not\u00a0in a hurry to take it on,\u201d he says. Even without clear permissions, Himmelstein is unlikely to face legal penalties for publishing Hetionet, says Jonathan Band, an intellectual-property lawyer with the law firm Policy Bandwidth in Washington DC \u2014 unless, that is, he mistakenly breached terms and conditions placed on the data sets. Academics who put their data sets publicly online usually intend their work to be available for others to republish freely; and no one has ever got into trouble for doing Himmelstein\u2019s kind of project, Band adds. But Himmelstein is not convinced that he is legally in the clear \u2014 and feels that such \u00aduncertainty may deter other scientists from reproducing academic data. If a researcher launches a commercial product that is based on public data sets, he adds, the stakes of not having clear licensing are likely to rise. \u201cI think these are largely untested waters, and most \u00adacademics aren\u2019t in the position to risk \u00adsetting off a legal battle that will help clarify these issues,\u201d he says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Digital badges motivate scientists to share data 2016-May-12 \n                   \n                     Legal tussle delays launch of huge toxicity database 2016-Feb-11 \n                   \n                     Trouble at the text mine 2012-Mar-07 \n                   \n                     Hetionet \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20349", "url": "https://www.nature.com/articles/nature.2016.20349", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Persistent biases continue to affect the numbers of female physicists. There are more women in the sciences than ever before. They hold leading faculty and administrative positions while their representation in fields such as biology, sociology and psychology has increased. Yet the  physical sciences are woefully behind  when it comes to the number of women at all levels. \u201cPhysics and engineering both have big gender divides,\u201d says Eric Brewe, a physics education researcher at Florida International University in Miami. This persistent problem prompted a  special issue  of the journal  Physical Review Physics Education Research , with 17 papers and an editorial on gender issues in physics, published on 1 August. Brewe was one of two guest editors for the issue. Recent scandals involving  sexual harassment in astrophysics  departments at US universities and allegations of gender segregation in an undergraduate physics class in Ohio have underscored the  issues that women continue to face in the physical sciences . The special issue addresses the reasons why relatively few women enter the field of physics, as well as the factors that deter them from completing their degrees. They include a lack of role models, entrenched stereotypes and an undervaluing of their abilities. Many authors also highlighted the fact that women are \u2014 usually inadvertently \u2014  made to feel like they don\u2019t fit in 1 . Women comprise between 49% and 58% of undergraduates and graduates in the social and life sciences at US universities. By contrast, only about 20% of US undergraduate and graduate students in physics are women, according to the US National Science Foundation. That gap has persisted over the past decade. \n             A glaring deficit \n           \u201cWomen in physics don\u2019t have a lot of role models,\u201d says Paula Stephan, an economist at Georgia State University in Atlanta. About 8% of US universities with PhD-granting departments don\u2019t have any women on their physics faculty. At the rest, only an average of 11% of the professors are women, according to the American Institute of Physics (AIP). But departments with more women faculty members benefit both male and female students, Stephan says. More diverse departments tend to be more productive, as measured by the number of publications, she says. They also tend to have better policies that address work\u2013life balance, according to the American Association of University Women. Stereotypes pose another obstacle, says Sarah Eddy, a biologist at the University of Texas at Austin, who co-authored a paper in the special issue 2 . Most of the scientists that people see on television or in films are men \u2014 although the  Ghostbusters  reboot is a notable exception. This contributes to the stereotypical association between science and maleness. Eddy has found that male students underestimate their female peers\u2019 knowledge 3 . When  women feel like they\u2019re being judged  because of their gender, it affects their performance, their feeling of belonging and their interest in science. \u201cWe\u2019ve got these unconscious biases from cultural influences since we were kids,\u201d she says. \n             Systemic changes \n           It\u2019s not just their peers, however. Female undergraduates underrate their own abilities in mathematics, eroding their self-confidence and increasing their anxiety while studying physics, says Linda Sax, an education researcher at the University of California, Los Angeles.Women also tend to want their studies to meet communal or \u201csocial activist\u201d goals of working with people and making the world a better place, according to a paper that Sax co-authored 4 . However, undergraduates often view physics as an abstract field that has little direct application to the real world. Women at universities report stronger social activist goals than men do, but physics consistently attracts students who place less value on such goals. \u201cWe need to make the work more relevant to students\u2019 lives,\u201d Sax says. These hurdles remain in graduate school, contributing to more women leaving physics at the PhD level. Other factors that discourage female doctoral students include their relationships with their advisers and the \u2018two-body problem\u2019 \u2014 the struggle for couples in academia to find positions in the same place 5 . The later often results in people limiting their careers or leaving physics, says Rachel Ivie, head of the Statistical Research Center at AIP in College Park, Maryland, a study co-author in the special issue. And women are more affected by this than men, she says. Addressing these problems means significant changes at the university level, argues Ram\u00f3n Barthelemy, AAAS Science Policy Fellow in Washington DC, who co-authored several studies in the special issue. Those changes could include an explicit  code of conduct at conferences ,  striving for more diverse faculty  and updating mentoring and teaching styles. There is reason for hope, however. \u201cMore and more people are paying attention and getting passionate about these issues,\u201d says Eddy. \n                   Speak up about subtle sexism in science 2016-Apr-26 \n                 \n                   Science and gender: Scientists must work harder on equality 2015-Dec-21 \n                 \n                   Universities highlight gender-equality policies after sexism row 2015-Jul-10 \n                 \n                   Hidden hurdle for women in science 2015-Jan-15 \n                 \n                   Inequality quantified: Mind the gender gap 2013-Mar-06 \n                 \n                   National Science Foundation data \n                 \n                   American Institute of Physics data \n                 \n                   American Association of University Women report: \u201cWhy So Few? Women in Science, Technology, Engineering and Mathematics\u201d \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20377", "url": "https://www.nature.com/articles/nature.2016.20377", "year": 2016, "authors": [{"name": "Myles Gough"}], "parsed_as_year": "2006_or_before", "body": "But researchers say damage is already done after job losses at CSIRO. Australia's government has ordered its national science agency to re-prioritize basic climate research \u2014 six months after the organization unveiled  controversial plans to slash jobs  in the sector. But the intervention may have come too late to salvage damage already caused, researchers say. The Commonwealth Scientific and Industrial Research Organisation (CSIRO) will \u2014 on government instructions \u2014 create 15 new climate-science jobs and receive an extra Aus$37 million (US$28 million) over the next 10 years, both for salaries and extra support in the sector, science minister Greg Hunt announced on 4 August. \u201cIt's a new government and we're laying out a direction that climate science matters,\u201d he told the Australian Broadcasting Corporation. Hunt, a former environment minister who was put in charge of the industry, innovation and science ministry after July\u2019s federal election, said that Prime Minister Malcolm Turnbull supported the move. A spokesperson for Hunt\u2019s ministry said that he was in the process of preparing a \u201cnew statement of expectations\u201d for CSIRO, and that the net effect of the government\u2019s intervention would be to bring the agency\u2019s total number of climate scientists to 115, down from around 135 earlier in the year. \n             Partial U-turn \n           \u201cIn the context that this is a U-turn from previous cuts, this is good news,\u201d says Wenju Cai, a climate modeller at CSIRO. But he points out that the government did not intervene when CSIRO\u2019s chief executive, Larry Marshall, first announced plans to cut hundreds of climate-science jobs in February. At the time, the government distanced itself from CSIRO's cuts, calling them an agency-level decision.Climate job losses so far number around 35, after strong opposition from both researchers and the public. \u201cIf the directive came earlier we would not have had to endure those very painful cuts,\u201d Cai says. \"A lot of damage has been done, a lot of people have been lost,\u201d says William Steffen, a climate scientist at the Australian National University in Canberra. \u201cWe need a thorough, authoritative and accurate assessment of where we stand now, including Mr Hunt's intervention today, compared to where we were before Larry Marshall got into the act and started sacking CSIRO scientists. Until we get the numbers on that, we can't say what the long-term impact of this announcement really is,\u201d he says. A spokesperson for CSIRO says the agency isn\u2019t commenting at this stage. CSIRO's staff association says that Hunt\u2019s intervention does not go far enough to repair damage done by the agency's cuts, and that the cuts are not over. \u201cCSIRO management is continuing to proceed with plans to slash 296 jobs across the organization, including more than 60 experienced climate and marine scientists,\u201d says a statement posted on its website. \u201cYou don\u2019t need to be a scientist to realise that employing 15 climate researchers when you\u2019re in the process of sacking more than 50 doesn\u2019t add up. It\u2019s not going to restore CSIRO\u2019s research capacity or repair Australia\u2019s global reputation,\u201d said Sam Popovski, secretary for the staff association. He suggested that Hunt direct CSIRO to halt all current job cuts. In April, CSIRO had announced that it would sack fewer staff and would  launch a new climate-science centre in Hobart , Tasmania, which would employ 40 full-time researchers \u2014 a move that one scientist characterized as \u201ctrying to put a sticking plaster over a gaping wound\u201d. So far, that centre has neither opened nor had a director appointed, Popovski told  Nature . \n                   Australian climate job cuts leave hole in Southern Hemisphere research 2016-May-18 \n                 \n                   Australia softens blow of climate job cuts 2016-Apr-26 \n                 \n                   Job cuts in Australia target climate scientists 2016-Feb-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20350", "url": "https://www.nature.com/articles/nature.2016.20350", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Huge survey tests people's attitudes towards potential future biomedical technologies. Most people in the United States are more worried than enthusiastic about the prospect of scientific advances such as gene editing and brain-chip implants, a survey of thousands suggests. The Pew Research Center in Washington DC  asked 4,726 US people  about the potential uses of three biomedical technologies that it classified as \u2018potential human enhancement\u2019: gene editing to reduce disease risk in babies; brain implants to enhance concentration and brain processes, and transfusions of synthetic blood to improve strength and stamina. (None of these procedures are a reality, but the underlying technologies are being researched.)  Those who took the survey were overwhelmingly wary about all of the ideas. In each case, more than 60% said that they would be worried about the technologies, and fewer than half expressed enthusiasm about them \u2014 with the prospect of brain implants prompting the most concern and least excitement. More than 70% thought that the procedures would become available before they were well understood or officially deemed safe. Around one-third thought the technologies were morally unacceptable, and about 70% were concerned that such enhancements would widen social divides \u2014 for instance, because initially only wealthy people would be able to afford them. Respondents were not generally familiar with these ideas for enhancement: only 38% had heard about the topic of brain implants, and just 22% had heard of the concept of synthetic blood. Gene editing was more familiar: 57% had heard or read about it. Among those who had read at least a little about gene editing, more than half said that it was something they would want for their baby \u2014 but among those who hadn\u2019t, 37% felt that way. Read a previous Trend Watch: ' Global rate of new HIV infections hasn't fallen in a decade ' \n                   First paralysed person to be 'reanimated' offers neuroscience insights 2016-Apr-13 \n                 \n                   Injectable brain implant spies on individual neurons 2015-Jun-08 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 Reprints and Permissions"},
{"file_id": "536015a", "url": "https://www.nature.com/articles/536015a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "They hope for an active role in the UK department for exiting the EU. British science\u2019s largest lobbying campaign in years is under way. After the  shock of the United Kingdom\u2019s vote to leave the European Union , anxious researchers are doing all they can to ensure that their interests are represented in Brexit negotiations. One big unanswered question is what role science will have in the new \u2018Brexit ministry\u2019\u00a0\u2014\u00a0the Department for Exiting the European Union (DEEU)\u00a0\u2014\u00a0that has been expressly formed to take the country out of the EU. Worried at the prospect of losing access to EU funding and collaborations, scientific societies have fired off numerous letters asking the government to keep their country in the EU\u2019s research system, and warning of  damage already caused by Brexit . An advocacy group, Scientists for EU, says it has gathered (in confidence) 25 cases of foreign scientists withdrawing job applications or being refused a UK post as a result of Brexit, 7 cases of someone in UK science leaving the country, and 33 of disruption to funding for the EU\u2019s Horizon 2020 research-grants programme. The government has indicated that it is listening to scientists\u00a0\u2014\u00a0but seems reluctant to say so too loudly. On 18\u00a0July, Prime Minister Theresa May sent a letter to Paul Nurse, the director of London\u2019s Francis Crick Institute, telling him that the government was committed to \u201censuring a positive outcome for UK science\u201d as the country exited the EU. But the letter\u00a0\u2014 effectively May\u2019s first statement on science \u2014 did not become public knowledge until science minister Jo Johnson referred to it in passing in a 25\u00a0July speech at the EuroScience Open Forum in Manchester, prompting journalists to press for a copy. Venkatraman Ramakrishnan, the president of London\u2019s Royal Society, said he welcomed the comments and was looking forward to working with May and her colleagues \u201cto turn these words into action\u201d. What action May will take remains unclear: prospects for science are inextricably entangled with the wider Brexit issues of freedom of movement and UK access to the EU\u2019s single market. David Davis, a Member of Parliament who had campaigned on the \u2018leave\u2019 side of the referendum, leads the DEEU. He has announced plans to conduct a \u201chuge consultation\u201d ahead of the start of formal EU exit negotiations, which May has postponed until at least 2017. \n               Science in the Brexit ministry \n             Davis\u2019s team is talking to \u201cthe research institutes\u201d, he told Sky News on 17\u00a0July\u00a0\u2014\u00a0but his department could not confirm which bodies this referred to. UK national aca\u00addemies have written jointly to Davis and \u201clook forward to working with him to ensure that science\u2019s voice is heard in Brexit negotiations\u201d, the Royal Society told  Nature . Some hope that the Brexit ministry will contain specific advocates for research. \u201cThere should be some sort of champion for science within the department,\u201d says John Beddington, a population biologist at the Oxford Martin School, and a former UK chief scientific adviser. An obvious choice is science minister Johnson, Beddington says, although the DEEU could also dedicate a group of civil servants to the job. Johnson could be a \u201cvery strong, very early voice\u201d in DEEU deliberations, Sharon Witherspoon, policy chief at the UK Academy of Social Sciences, told a House of Lords inquiry on 19\u00a0July. She added that research needed \u201curgent attention, and cannot wait to be an afterthought\u201d. Giving more-formal responsibilities to Johnson, whose role in May\u2019s government is split between the education and business departments, might be a stretch. \u201cIf anyone can do it, Jo can. But I\u2019m not confident that the best voice for the science community would be to add another job on for Jo,\u201d says Nick Hillman, director of the Oxford-based Higher Education Policy Institute. A different potential conduit for scientific input could be the DEEU\u2019s departmental board, an advisory body that, in other departments, often includes senior business figures. And another idea is for Davis\u2019s department to appoint a chief scientific adviser (CSA), as most other UK ministries already have. But Beddington says that although the DEEU and the newly created Department for International Trade should each have a CSA, their role should not be to advocate for science, but to feed advice into the negotiations on issues such as environmental regulations, product standards and health and safety. \u201cWhether to appoint a CSA is the kind of thought process they should be going through,\u201d says Hillman. \u201cIt doesn\u2019t mean they are there yet, though.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Lessons from Brexit 2016-Jul-25 \n                   \n                     Brexit watch: UK researchers scramble to save science 2016-Jul-22 \n                   \n                     Science\u2019s status shifts in new Brexit government 2016-Jul-14 \n                   \n                     Brexit and science: Seven days later 2016-Jul-01 \n                   \n                     Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                   \n                     Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                   \n                     Nature  special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20382", "url": "https://www.nature.com/articles/nature.2016.20382", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "IceCube observatory reports null result in search for particle. An observatory buried deep in Antarctic ice has reported the results of its search for an hypothesized particle called the \u2018sterile neutrino\u2019: a total blank. The null result, reported on 8 August in  Physical Review Letters 1 , doesn\u2019t spell the end of a decades-long search to find the subatomic particle, which \u2014 if found \u2014 would  upend the standard picture of particle physics . But it is the strongest evidence so far that the sterile neutrino doesn\u2019t exist at the mass range that physicists had hoped, based on anomalies from several experiments over the past three decades.\u00a0 Neutrinos are everywhere: every second, trillions of the subatomic particles fly through our bodies. But they interact so rarely with matter that to detect them requires  large underground experiments equipped to spot neutrino\u2013matter collisions . These experiments have spotted three types: the electron neutrino, muon neutrino and tau neutrino; the three can change type as they travel. In the mid-1990s, a detector at the Los Alamos National Laboratory in New Mexico saw an anomaly that hinted there might be a fourth kind of neutrino, which would interact even more rarely with matter than would ordinary neutrinos. It was dubbed the \u2018sterile\u2019 neutrino, and the Los Alamos experiment suggested it weighed around one-billionth the mass of a hydrogen atom \u2014 around 1 electronvolt (1 eV). Other experiments found similar anomalies. More-recent studies that counted neutrinos streaming from nuclear reactors, including last February at Daya Bay in China 2 , have seen strange features in their data that could, in theory, point to a sterile neutrino. \n             Answers in the ice \n           The sterile neutrino can\u2019t be detected directly.\u00a0\u201cThe only way to see it is because it messes up the observation of the three other neutrinos,\u201d says Francis Halzen, a physicist at the University of Wisconsin\u2013Madison. Halzen is the principal investigator at IceCube, an array of more than 5,000 basketball-sized sensors embedded in ice to depths of more than two kilometres. The telescope hunts for neutrinos by detecting the faint flash of light caused whenever such a particle hits an atomic nucleus in the ice. To search for sterile neutrinos, Halzen\u2019s team looked for the arrival of muon neutrinos that started life on the other side of Earth (see 'Neutrino observatory'). These were originally produced by the collision of cosmic rays with air molecules in the atmosphere, and passed through the planet to reach the detector. The IceCube team hoped to find a dearth of muon neutrinos at particular energies. That would have suggested that some muon neutrinos had temporarily mutated into sterile neutrinos during their voyage.  But, after analysing the results of a year's worth of data, the researchers found no feature suggesting the existence of sterile neutrinos around 1 eV. This is line with  results from the European Space Agency's Planck observatory , which concluded from cosmological evidence that there should only be three families of neutrinos in that mass range. \u201cI hope that with our result and with the Planck result we are slowly walking our way back from this story,\u201d says Halzen. The IceCube team are still taking data in their sterile neutrino hunt, but don't expect their results to change, he adds. Olga Mena Requejo, a theoretical particle physicist at the University of Valencia in Spain, agrees that the findings rule out the sterile-neutrino explanation for the Los Alamos experiment anomaly \u2014 at least within the simplest theoretical models. But she and other physicists say that some models could still leave the door open for the particle's existence. In particular, the Daya Bay experiment counted electron neutrinos, not muon neutrinos: sterile neutrinos could in principle mutate into muon neutrinos much more rarely than into other types, points out Jiajie Ling, a physicist at Sun Yat-Sen University in Guangzhou who coordinated Daya Bay's sterile-neutrino analysis. \n             The search goes on \n           Separately, X-ray astronomers have seen an unexplained glow in certain galaxies that, according to one theory, could also be explained if a much heavier sterile neutrino existed, with a mass of around 7,000 eV. Earlier this year, the short-lived  Hitomi space observatory  found no evidence of the 7 KeV sterile neutrinos 3 , but that result was inconclusive, says Kevork Abazajian, a theoretical astrophysicist at the University of California in Irvine. So the search at heavier masses goes on: the IceCube results say nothing about the existence of these more massive sterile neutrinos. A trio of detectors now under construction at Fermilab should be able to either conclusively rule out the Los Alamos anomaly, or find an explanation for it \u2014 which may or may not involve sterile neutrinos. \u201cHunting for the sterile neutrinos is like hitting a bat in a dark room,\u201d says Kam-Biu Luk, one of the principal investigators at the Daya Bay experiment. \u201cWe have no idea where they hide.\u201d \n                   Physics: Invest in neutrino astronomy 2016-May-25 \n                 \n                   European probe shoots down dark-matter claims 2014-Dec-02 \n                 \n                   Hunt for the sterile neutrino heats up 2010-Mar-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20380", "url": "https://www.nature.com/articles/nature.2016.20380", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Researchers dropped from EU grant proposal because UK inclusion would \u2018compromise\u2019 project. UK researchers are  suffering because of the country\u2019s vote to leave the European Union  \u2014 and a British physicist has now gone public with one such tale of woe. Paul Crowther, who heads the physics and astronomy department at the University of Sheffield, has shared e-mails from late July that explain why researchers in his department were suddenly dropped from an EU collaboration. The European coordinator for the consortium felt that Brexit put UK-based researchers in a \u201cvery awkward position\u201d and that their participation would \u201ccompromise the project\u201d. Crowther says that he wants the e-mails to be read because researchers need to circulate such stories widely, given that many reports of the effects of Brexit have been based on hearsay and rumour. He has stripped the e-mails of identifying details and made them public with the approval of all involved, sharing them with both  Nature \u2019s news team and the London-based Institute of Physics, which is collecting stories of Brexit\u2019s effects on science to send to the UK government. On 21 July, the coordinator for the EU consortium e-mailed Crowther\u2019s colleague to say that his UK team would be dropped from the project. (Neither individual wants to be named.) \n             \u201cI regret to inform you that in the end we decided to not include your group in the consortium. The main reason of this decision concerns the Brexit and all the incertitude it brings. It may seem a decision very drastic (at least this is my feeling), but this is the outcome of the discussions I had with [redacted] and [redacted] (my group leader here in [redacted]). We finally decided to \u2018remove\u2019 the problem at the base. \n           \n             Anyway, I really hope that this is not a \u2018goodbye\u2019 but a \u2018see you soon\u2019. As soon as the rules will be clear (hopefully asap) we will have again occasions to work together, eventually on this subject of [redacted] ... Of course I know very well the value of your work and more generally of the research group you work in. It is my interest to work with people like you. I hope in the future, to come back with better news.\u201d \n           The consortium is an Innovative Training Network (ITN), a type of multinational project to assist research into a particular field, with costs that often run into hundreds of thousands of euros. The networks are paid for under the Marie Sk\u0142odowska-Curie actions, a \u20ac6.2-billion (US$6.9-billion) slice of the European Commission\u2019s \u20ac74.8-billion Horizon 2020 funding programme. Crowther, who saw the e-mail because he was organizing his department\u2019s response to a House of Commons inquiry into the effects of Brexit on science, asked for more information about the exclusion. The ITN coordinator told him that before the Brexit vote, the UK team had been part of a preliminary agreement. \n             \u201cThe Brexit vote put the UK-based researches in a very awkward position. I have been thinking a lot and talking with many people, either related or not to the ITN. Unfortunately, the general consensus was that it is preferable to exclude the UK members. The main argument is a sort of \u2018precaution principle\u2019: provided the confusion, incertitude and lack of information about the rules for the EU projects (will they change? if yes, how?) the easiest solution was removing the problem at its root, which meant excluding the UK members from the ITN network. \n           \n             It is a drastic solution and it may seem extreme. Nevertheless, as a (virtual) coordinator it is my duty to maximise the chances of obtaining the grant. Any possible weakness of the consortium must be avoided and, despite the excellent scientific contribution from the Sheffield group, I feel that their participation after the Brexit vote, would compromise the project.\u201d \n           In a  blogpost  on the Institute of Physics website, Crowther contrasts this attitude with the words of Carlos Moedas, the EU research commissioner, who told an audience at the EuroScience Open Forum in Manchester, UK, last week that Horizon 2020 projects would continue to be evaluated on the basis of merit, not nationality.\u201cI urge the European scientific community to continue to choose their project partners on the basis of excellence,\u201d Moedas said. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                 \n                   Resilient British science will withstand Brexit 2016-Jul-27 \n                 \n                   Brexit watch: UK researchers scramble to save science 2016-Jul-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20376", "url": "https://www.nature.com/articles/nature.2016.20376", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "But the hunt continues for elementary particles beyond the standard model of physics. Chicago, Illinois It would have been bigger than finding the Higgs boson and marked the beginning of a new era in particle physics. But new data have squashed the hope that the hints of a new particle detected by the Large Hadron Collider (LHC) would solidify with time. Instead, the intriguing data \u2018bump\u2019 \u2014  first reported in December  \u2014 turns out to be nothing more than a statistical fluctuation. Representatives from ATLAS and CMS \u2014 two independent experiments at the LHC \u2014 presented the news at the International Conference on High Energy Physics (ICHEP) in Chicago, Illinois, on 5 August. Analyses incorporating almost five times the amount of data used in December show that the signal has faded to almost nothing.\u00a0 \u201cThere is no significant excess seen in the 2016 data,\u201d says Bruno Lenzi, a CERN physicist and part of the ATLAS collaboration, presenting to a standing-room only session at ICHEP. Presenting directly after Lenzi, Chiara Ilaria Rovelli, a physicist at the National Institute of Nuclear Physics in Rome, piled on the bad news. Additional data from CMS also failed to produce a significant signal. \u201cThe modest excess presented in 2015, is unfortunately not confirmed by 2016 data,\u201d she said. While the announcement was a disappointment to researchers, it wasn\u2019t completely unexpected. The ATLAS collaboration\u2019s most recent update in June put the significance of the signal \u2014 a measure of how likely random fluctuations in the data would produce such a bump without a particle \u2014 at 2.1 sigma. That was well below the 5 sigma threshold for determining whether a signal is a discovery or just noise. But because both ATLAS and CMS experiments independently saw the signal \u2014 which consisted of slightly more pairs of photons with a combined energy of 750 gigaelectronvolts (GeV) than expected \u2014 physicists hoped that the bump was real. It sparked a rash of  more than 500 theory papers , which tried to explain the potential new particle. \u201cSeeing a glimpse of something, even the half a glimpse that makes you hold your breath a moment and think what if \u2014 it\u2019s too valuable to be left unexplored,\u201d says Tara Shears, a particle physicist at the University of Liverpool, UK. \n               History of a bump \n             Cautious excitement about the bump was driven by its potential payout, says Don Lincoln, a physicist at the Fermi National Accelerator Laboratory near Batavia, Illinois. Physicists know that their highly successful description of forces and matter \u2014 called the standard model \u2014 is incomplete since it fails to account for mysteries including dark matter and how to reconcile quantum mechanics with gravity. A new particle would have been the first signpost directing physicists towards a new theory, says Lincoln. \u201cMost scientists suspected the excess would go away, but the consequences of it being real led many to spend some sleepless nights hoping that it was.\u201d The two-photon signal was appealing in part because the analysis behind it was relatively simple and robust. It was also easy to come up with  models to explain the bump  that didn\u2019t conflict with other experimental results, says Christoffer Petersson, a theoretical physicist at Chalmers University of Technology in Gothenburg, Sweden. The fact that one possible explanation included the particle being a heavier cousin to the Higgs boson, and potentially just one of a whole new family of particles, also made it appealing, says Guido Tonelli, a physicist at the University of Pisa in Italy and former head of CMS. Even though  all those models  are now wrong, Petersson doesn\u2019t view the work as a waste of time. \u201cIt was a fun exercise to try to fit different ideas to this experimental result and I did learn a couple of things in the process,\u201d he says. Statistical fluctuations and discoveries look identical at first, says Lincoln. Such coincidences are always possible when performing thousands of searches and across a wide range of particle masses, and similar hints have appeared and disappeared many times in the past, he says. \u201cYou should expect to see this cycle many times in the future.\u201d \n               Whither the LHC \n             But this false alarm does not affect the LHC\u2019s chances of finding something else, says Petersson. \u201cThis is not really a more significant blow than the blow from any other LHC search that comes up empty-handed,\u201d he says. So for the experiments and researchers at the LHC, it\u2019s business as usual going forward. Still, 40 years after the standard model was developed, some physicists are concerned that nothing beyond it has been found, by the LHC or at any previous particle accelerator. And since June 2015, the LHC has been operating at 13 teraelectronvolts (TeV) \u2014 near its 14 TeV maximum. Guy Wilkinson, spokesperson for the LHCb experiment, said it was surprising that nothing unexpected had emerged in the LHC data, adding that he was \"slightly breaking with orthodoxy\" in saying so. This underscores a growing unease in the community that as time goes on without new findings, the most appealing versions of a popular theory known as supersymmetry become less likely to be true. But Petersson\u00a0notes\u00a0that the chances the machine will find something beyond the standard model are enhanced this year and next. If new particles are rare, or if they decay in ways that are difficult to observe, they could take a long time to emerge, he explains. Attaining high energies is not the only way to find new particles, says Shears. With enough data, particles that are too heavy to be produced directly could reveal themselves through their subtle influence on other well-known particles, she says. Physicists at CERN\u2019s LHCb experiment have  already found hints of such deviations  between their data and standard model predictions. But they will need more information to confirm them. The LHC has only racked up a sixth of the total data physicists hope to collect by the end of 2018. So Tonelli remains optimistic that discoveries are coming. \u201cWe know already that sooner or later one of these anomalies will survive all controls and suddenly, crack, everything will change,\u201d he says. \u201cThe beauty of our work is that this could happen at any time.\u201d \n                     Hints of new LHC particle get slightly stronger 2016-Mar-17 \n                   \n                     Hint of new boson at LHC sparks flood of papers 2015-Dec-24 \n                   \n                     LHC sees hint of boson heavier than Higgs 2015-Dec-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20379", "url": "https://www.nature.com/articles/nature.2016.20379", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Researchers in the United States will soon be able to resume creating chimaera-based projects. Since September 2015, researchers  have been banned  from receiving funding from the US National Institutes of Health (NIH) for adding human stem cells to animal embryos, creating blends called chimaeras. But a  proposal by the NIH released on 4 August would lift the funding moratorium , except for certain situations. It would also set up a panel to review the ethics and oversight of grant applications. The new rules shorten the developmental window during which human cells can be introduced into non-human primate embryos, disallowing it before the stage of development in which the central nervous system begins to form. This is intended to limit the number of human cells that would make up the chimaera\u2019s brain. They also prohibit breeding animals that contain human cells, so as to prevent a human-like embryo from growing in a non-human womb or the birth of an animal that is more humanized than its parents. Any grant applications that fall into a grey area would undergo a panel review. \u201cIt would be an extra set of eyes to make sure we\u2019re not triggering any animal-welfare issues,\u201d says Carrie Wolinetz, associate director for science\u00a0policy at the NIH in Washington DC. The panel will pay particular attention to applications involving primates, mammals at very early stages of development or those in which human cells could affect an animal's brain. Past a certain point of development, rodent embryos with human cells that could affect brain development are exempt from panel review, says Wolinetz. This is because NIH\u2019s scientific advisers think that the rodent brain is substantially different from ours and would not become human-like. Chimaeras are a  growing area of research . Currently, researchers use them to study early embryonic development and to create animal models of human diseases. But one major goal is to engineer animals to grow human organs. The organs could later be harvested from the adult animal and used for transplantation into a patient. Unlike in the United States, it is illegal to perform such research without approval in the United Kingdom, even with private funding. Laws introduced in the United Kingdom in January mandate extra reviews of proposals involving certain types of chimaeras, including ones that would have a human appearance or features such as faces or hands. \n               Mixed reviews \n             Reactions from researchers have been mixed. Steven Goldman, a neuroscientist at the University of Rochester in New York, says that the 2015 moratorium was overkill and is relieved that it will now be lifted. The new guidelines, he says, are \u201cmore intelligent from the standpoint of where the science is\u201d. But Ali Brivanlou, a developmental biologist at the Rockefeller University in New York City says that the NIH proposal focuses on the wrong aspects of the issue. Rather than restricting the timing of modification, he says, there should be more focus on limiting the percentage of the animal that ends up being human. \u201cOn a positive note, it\u2019s amazing that this is going on,\u201d he says, because there are many related questions and ethical issues that should be debated publicly. Fran\u00e7oise Baylis, a bioethicist at Dalhousie University in Halifax, Canada, thinks that the new rules leave many questions unanswered. Currently, there are only two types of research subject, human and non-human, and there are clear distinctions on how to treat them. With chimaeras, researchers risk creating a third category for which there are no research guidelines, she says. \u201cWe just tend to say we\u2019ll treat them like non-human animals, as if nothing happened,\u201d Baylis says. The NIH rules and other countries\u2019 laws focus on cognition as the important factor for limiting chimaera research. But that is not necessarily the best way to determine how humanized animals should be categorized because it can be subjective, Baylis says. For instance, people who are cognitively impaired are still treated as human subjects in research, whereas very intelligent primates are not. These are the kinds of questions that the oversight panel will discuss when reviewing specific grant applications, says Wolinetz. The panel will give recommendations to the scientific grant reviewers, which could include suggestions such as not allowing certain types of chimaeras to be brought to term, or monitoring an adult chimaera\u2019s behaviour before continuing the experiment. \u201cThere are no hard and fast lines,\u201d she says. \u201cThere\u2019s going to be some on-the-job learning.\u201d The NIH\u2019s rule is now  open for public comment  for 30 days, after which the agency will issue a final rule and lift the moratorium. Wolinetz hopes that this will be ready in time for the grant cycle that begins in January 2017. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Human embryos grown in lab for longer than ever before 2016-May-04 \n                   \n                     Scientists stumble across unknown stem-cell type 2015-May-06 \n                   \n                     Regulations proposed for animal\u2013human chimaeras 2011-Jul-21 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20378", "url": "https://www.nature.com/articles/nature.2016.20378", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Economically costly disease is mainly passed through infected pastures. Badgers and cows are scattered across the English countryside, yet the two species rarely meet face-to-face, a large study has revealed 1 . The finding is not merely incidental. It sheds light on how badgers transmit bovine tuberculosis (TB) to cows: a question which UK researchers have spent  more than a decade studying . Since 2013, the UK's government has sanctioned the killing of  hundreds of badgers  ( Meles meles ) in controversial culls to try to dampen the spread of bovine TB. The disease, caused by the bacterium  Mycobacterium bovis , cost the country an estimated \u00a3100 million ($131 million) in 2014 alone through compensation and control measures. But the latest government-funded study \u2014 which involved fitting GPS collars and radio collars to track the whereabouts of hundreds of cows and scores of badgers \u2014 suggests that bovine TB is probably not passed by direct contact between species, but rather indirectly through contaminated pasture, says Rosie Woodroffe, a badger specialist at the Zoological Society of London who led the work. Despite recording thousands of nights of data, the team didn't observe a single contact between badgers and cows. \u201cThis helps to explain why TB is so hard to control,\u201d she says. \n             Soil attraction \n           The findings suggest that badgers like to hang around earthworm-rich cattle pasture, but not the cattle themselves. Badger faeces and sputum \u2014 and cow pats from infected cattle \u2014 might be the carriers of  M. bovis  in farms, Woodroffe says. And in most cases, pasture and slurry from herds in which bovine TB has been detected is not treated as infectious, she adds. The work backs up an earlier, smaller-scale study in Northern Ireland, which also suggested that badgers don\u2019t often meet cows 2 . \u201cTo have corroboration from a different location involving large numbers of animals is very reassuring,\u201d says Declan O\u2019Mahony, a mammal ecologist at the Belfast-based Agri-Food & Biosciences Institute who led the smaller study, funded by a department in Northern Ireland's devolved government. Researchers now have to work out how best to reduce the indirect, environmental transmission of bovine TB, says Andrew Conlan, who studies disease dynamics at the University of Cambridge, UK. The implications for the government\u2019s hotly disputed policy of killing badgers to control disease spread are less clear. The work \u201ccertainly doesn\u2019t increase the case for badger culling\u201d, says Woodroffe, who is one of a number of scientists who have long questioned the scientific basis of the culls. But John Krebs, a zoologist at the University of Oxford, UK, who opposes badger culling, says that the results are a \u201cfurther nail in the coffin of the policy of culling badgers to control bovine TB in cattle\u201d. Krebs, who is also a member of the UK's House of Lords, led a nine-year trial into the efficacy of badger killing 3 , which suggested that culling around 70% of badgers in large areas would lead to a reduction in bovine TB of up to 16%. He thinks these benefits do not justify major culls. \u201cThe much bigger issue is cattle-to-cattle transmission within and between herds,\u201d he says. However, another round of badger culling is widely expected for 2016: a public consultation on the topic closed in March. So far, the cull has been trialled in three regions of England, but nine regions are now being considered for badger-hunting licences. \n                   UK official defends badger cull 2013-Jun-06 \n                 \n                   Badger battle erupts in England 2012-Oct-16 \n                 \n                   Badger away 2012-Oct-16 \n                 Reprints and Permissions"},
{"file_id": "536136b", "url": "https://www.nature.com/articles/536136b", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The popular technique has limitations that have sparked searches for alternatives. The CRISPR\u2013Cas9 tool enables scientists to alter genomes practically at will. Hailed as dramatically easier, cheaper and more versatile than previous technologies, it has blazed through labs around the world, finding new applications in medicine and basic research. But for all the devotion, CRISPR\u2013Cas9 has its limitations. It is excellent at going to a particular location on the genome and cutting there, says bioengineer Prashant Mali at the University of California, San Diego. \u201cBut sometimes your application of interest demands a bit more.\u201d The zeal with which researchers jumped on a  possible new gene-editing system called NgAgo  earlier this year reveals an undercurrent of frustration with CRISPR\u2013Cas9 \u2014 and a drive to find alternatives. \u201cIt\u2019s a reminder of how fragile every new technology is,\u201d says George Church, a geneticist at Harvard Medical School in Boston, Massachusetts.  NgAgo is just one of a growing library of gene-editing tools. Some are variations on the CRISPR theme; others offer new ways to edit genomes. \n               A mini-me \n             CRISPR\u2013Cas9 may one day be used to rewrite the genes responsible for genetic diseases. But the components of the system \u2014 an enzyme called Cas9 and a strand of RNA to direct the enzyme to the desired sequence \u2014 are too large to stuff into the genome of the virus most commonly used in gene therapy to shuttle foreign genetic material into human cells. A solution comes in the form of a  mini-Cas9 , which was plucked from the bacterium  Staphylococcus aureus 1 . It\u2019s small enough to squeeze into the virus used in one of the gene therapies currently on the market. Last December, two groups used the mini-me Cas9 in mice to correct the gene responsible for Duchenne muscular dystrophy 2 , 3 . \n               Expanded reach \n             Cas9 will not cut everywhere it\u2019s directed to \u2014 a certain DNA sequence must be nearby for that to happen. This demand is easily met in many genomes, but can be a painful limitation for some experiments. Researchers are looking to microbes to supply enzymes that have different sequence requirements so that they can expand the number of sequences they can modify. One such enzyme,  called Cpf1 , may become an attractive alternative. Smaller than Cas9, it has different sequence requirements and is highly specific 4 , 5 . Another enzyme, called C2c2, targets RNA rather than DNA \u2014 a feature that holds potential for studying RNA and combating viruses with RNA genomes 6 . \n               True editors \n             Many labs use CRISPR\u2013Cas9 only to delete sections in a gene, thereby abolishing its function. \u201cPeople want to declare victory like that\u2019s editing,\u201d says Church. \u201cBut burning a page of the book is not editing the book.\u201d Those who want to swap one sequence with another face a more difficult task. When Cas9 cuts DNA, the cell often makes mistakes as it stitches together the broken ends. This creates the deletions that many researchers desire. But researchers who want to rewrite a DNA sequence rely on a different repair pathway that can insert a new sequence \u2014 a process that occurs at a much lower frequency than the error-prone stitching. \u201cEveryone says the future is editing many genes at a time, and I think: \u2018We can\u2019t even do one now with reasonable efficiency\u2019,\u201d says plant scientist Daniel Voytas of the University of Minnesota in Saint Paul. But developments in the past few months have given Voytas hope. In April, researchers announced that they had disabled Cas9 and tethered to it an enzyme that converts one DNA letter to another. The disabled Cas9 still targeted the sequence dictated by its guide RNA, but could not cut: instead the attached enzyme switched the DNA letters,  ultimately yielding a T where once there was a C 7 . A paper published in  Science  last week reports similar results 8 . Voytas and others are hopeful that tethering other enzymes to the disabled Cas9 will allow different sequence changes. \n               Pursuing Argonautes \n             In May, a paper in  Nature Biotechnology 9  unveiled an entirely new gene-editing system. Researchers claimed that they could use a protein called NgAgo to slice DNA at a predetermined site without needing a guide RNA or a specific neighbouring genome sequence. Instead, the protein \u2014 which is made by a bacterium \u2014 is programmed using a short DNA sequence that corresponds to the target area. The finding kicked off a wave of excitement and speculation that CRISPR\u2013Cas9 would be unseated, but laboratories have so far failed to reproduce the results. Even so, there is still hope that proteins from the family that NgAgo belongs to \u2014 known as Ago or Argonautes \u2014 made by other bacteria could provide a way forward, says genome engineer Jin-Soo Kim at the Institute for Basic Science in Seoul. \n               Programming enzymes \n             Other gene-editing systems are also in the pipeline, although some have lingered there for years. For an extensive project that aimed to edit genes in bacteria, Church\u2019s lab did not reach for CRISPR at all. Instead, the team relied heavily on a system called lambda Red, which can be programmed to alter DNA sequences without the need for a guide RNA. But despite 13 years of study in Church\u2019s lab, lambda Red works only in bacteria. Church and Feng Zhang, a bioengineer at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, say that their labs are also working on developing enzymes called integrases and recombinases for use as gene editors. \u201cBy exploring the diversity of enzymes, we can make the genome-editing toolbox even more powerful,\u201d says Zhang. \u201cWe have to continue to explore the unknown.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Replications, ridicule and a recluse: the controversy over NgAgo gene-editing intensifies 2016-Aug-08 \n                   \n                     Chinese scientists to pioneer first human CRISPR trial 2016-Jul-21 \n                   \n                     The unsung heroes of CRISPR 2016-Jul-20 \n                   \n                     First CRISPR clinical trial gets green light from US panel 2016-Jun-22 \n                   \n                     The quiet revolutionary: How the co-discovery of CRISPR explosively changed Emmanuelle Charpentier\u2019s life 2016-Apr-27 \n                   \n                     Nature  special: CRISPR \n                   Reprints and Permissions"},
{"file_id": "536134a", "url": "https://www.nature.com/articles/536134a", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Perlan mission will surf stratospheric waves and conduct atmospheric research. A glider that aims to soar higher than any other piloted aircraft will begin its first campaign this month in the skies above Argentina. For its pilots and engineers, the  Perlan Project  holds the excitement of breaking the world altitude record for gliding \u2014 and perhaps one day reaching close to the vacuum of space. But for Elizabeth Austin, the project\u2019s chief scientist, there\u2019s another thrill: the glider will carry scientific instruments for climate, aerospace and stratospheric research that cannot be done using other means. \u201cThe possibilities are just so incredible,\u201d says Austin, an atmospheric physicist and the founder of forecasting service WeatherExtreme in Incline Village, Nevada. The carbon-fibre glider, built with a pressurized cabin, is intended to achieve sustained flight at around 27,000\u00a0metres, where the density of air is about 2% of that at sea level. In the series of flights that the craft will begin in mid-August, it will fly to only 15,000\u201318,000\u00a0metres \u2014 in part because of weather conditions \u2014 but this could still break the glider altitude record of 15,445\u00a0metres, set by an earlier Perlan model. The glider will carry instruments to measure levels of aerosols and greenhouse gases, including ozone, methane and water vapour, and will gather information on the exchange of gases and energy between the two lower layers of Earth\u2019s atmosphere: the troposphere and the stratosphere. Those data, to be collected this year and next, could improve climate models, which account poorly for these atmospheric interactions and contain \u201chorrific\u201d uncertainties about the levels and behaviour of water vapour at stratospheric altitudes, Austin says. Scientific balloons  have already flown at much higher altitudes, but they must follow the wind, Austin adds, whereas a pilot can steer and circle a glider. \u201cWe can spend hours flying where we want. A glider is an incredible scientific platform as there\u2019s no other way to get this sort of data.\u201d \u201cIt\u2019s an extremely exciting project,\u201d says Jie Gong, an expert in atmospheric dynamics at NASA\u2019s sciences and exploration directorate in Greenbelt, Maryland. On the basis of its intended flight route, the Perlan glider might be able to provide the first direct observations of polar stratospheric clouds, a unique type of ice cloud that forms in the polar stratosphere and helps to deplete ozone, Gong adds. \n               Surfing over mountains \n             The glider is named after those same clouds, which have an iridescent mother-of-pearl appearance (Perlan means \u2018pearl\u2019 in Icelandic). They are typically generated at high altitudes by stratospheric mountain waves\u00a0\u2014 when strong winds that blow over the tops of high mountains are driven up towards space. In 1992, a retired NASA test pilot, Einar Enevoldson, founded the Perlan Project with the aim of creating a glider that could surf these waves up to the stratosphere. And in 2006, he and the US adventurer Steve Fossett proved the concept with their record-breaking flight on Perlan\u00a01, a modified conventional glider. But Fossett\u2019s death the following year in a light-aircraft accident set the project back until July 2014, when European aerospace group Airbus became a major sponsor and contributed its research expertise. The Perlan\u00a02 craft made its maiden flight last year in Oregon, and in March surfed its first mountain waves above the Sierra Nevada range in California. Its next flights will be over El\u00a0Calafate on the eastern and southern fringes of the Andes range in Argentina. There, during the South Pole\u2019s winter, a fast-moving, high-altitude jet stream called the polar-night jet extends from the troposphere into the upper atmospheric layers \u2014 helping the Andes mountain waves (and the glider) to reach the stratosphere (see \u2018Science on a glider\u2019). Besides its atmospheric chemistry, Perlan\u00a02 will carry instruments to study turbulence in stratospheric mountain waves, and to explore the microphysics of interactions between mountain waves and polar meteorology, which ultimately affect weather variability. Information on how mountain waves break in the stratosphere is \u201cextremely limited\u201d, says Gong, and requires detailed, fine-scale data on temperature, humidity and wind, which the glider is uniquely placed to measure. Airbus says that many of the weather phenomena Perlan\u00a02 will encounter will provide useful information for it and other aircraft makers that are contemplating operating aeroplanes at higher altitudes. Once Perlan is fully tested, says Austin, she hopes to get funding to use the glider as a long-term scientific platform that would examine how hourly, seasonal or even decadal changes in the stratosphere affect weather and climate. A drone that could carry more instruments is a future possibility \u2014 but for now, a piloted craft is preferable and simpler, says Ed Warnock, the project\u2019s chief executive. Machines cannot yet match the best human pilots when it comes to climbing waves in such demanding flight conditions, he says. Perlan\u2019s backers hope that it can surpass 27,000\u00a0metres in 2017 \u2014 and, ultimately, they intend another version of the glider to fly higher than 30,000\u00a0metres, where the air density is almost identical to that on Mars\u2019s surface. That might provide insight into how winged aircraft could fly on the red planet. For now, engineers and scientists alike are just hoping to see the glider soar into the stratosphere above the Andes and take data. \u201cEverything in the aircraft is experimental. It\u2019s a very difficult mission to do right, and to do it safely is not easy,\u201d Austin says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Antarctic ozone hole is on the mend 2016-Jun-30 \n                   \n                     NASA launches next-generation scientific balloon 2014-Dec-29 \n                   \n                     Mini satellites prove their scientific power 2014-Apr-16 \n                   \n                     Drones in science: Fly, and bring me data 2013-Jun-12 \n                   \n                     Perlan Project \n                   \n                     Airbus Perlan site \n                   Reprints and Permissions"},
{"file_id": "536136a", "url": "https://www.nature.com/articles/536136a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "As failures to replicate results using the CRISPR alternative stack up, a quiet scientist stands by his claims.  Shijiazhuang, China A controversy is escalating over whether a gene-editing technique proposed as an alternative to the popular CRISPR\u2013Cas9 system actually works. Three months ago, Han Chunyu, a biologist at Hebei University of Science and Technology in Shijiazhuang, reported that the enzyme NgAgo can be used to edit mammalian genes. Now, an increasing number of scientists are complaining that they cannot replicate Han\u2019s results \u2014 although one researcher has told  Nature  that he can.  Nature Biotechnology , which published the research, is investigating the matter. Han says he receives dozens of harassing calls and texts each day, mocking him and telling him that his career is over \u2014 but he is convinced that the technique is sound. On 8 August, he  submitted a protocol to the online genetic-information repository Addgene . He hopes that this will help efforts to reproduce his work, but other scientists say it does not clear things up.\u00a0 The stakes are high. Over the past few years, the CRISPR\u2013Cas9 system has transformed biology. But it has also made scientists hungry for other methods to expand the gene-editing toolkit:  NgAgo is one of several that have emerged . \u201cA lot of us are really cheerleading and hoping that it works,\u201d says geneticist George Church of Harvard Medical School in Boston, Massachusetts. CRISPR\u2013Cas9 uses small genetic sequences to guide an enzyme to cut DNA in a particular location. Inspired, Han looked through the literature for other guidable protein \u2018scissors\u2019, and came across a family of proteins called Argonaute, or Ago, that fitted the bill. Others had flagged the proteins as potential gene editors. In the paper, Han\u2019s team reports using a wide variety of genetic sequences to guide one of these proteins, NgAgo, to edit eight different genes in human cells and to insert genes at specific points on chromosomes ( F. Gao  et\u00a0al .  Nature Biotechnol.   34,  768\u2013773; 2016 ). Crucially, NgAgo very specifically cut only the target genes, says Han, unlike CRISPR\u2013Cas9, which sometimes edits the wrong genes. And whereas CRISPR\u2013Cas9 requires a certain genetic sequence to be near the cutting site to initiate its activity, NgAgo does not, which could broaden its potential applications, adds Han. The initial reaction to the work in China was laudatory, including a visit to the lab by China Central Television. It was overwhelming, says Han, who is a reclusive figure. His hobbies include collecting teas and playing an ancient stringed instrument called the guqin. He doesn\u2019t like to travel and has never left China: a trip to visit a collaborator in Hangzhou in March was the first time the 42 year old had boarded a plane. Before his paper came out, \u201cI was completely unknown\u201d, says Han, who spoke to  Nature  at his laboratory and a nearby restaurant. Doubts about the research first surfaced at the beginning of July, when Fang Shimin, a former biochemist who has  become famous for exposing fraudulent scientists , wrote on his website New Threads ( xys.org ) that he had heard reports of failed reproduction efforts, and alleged that Han\u2019s paper was irreproducible. Criticism grew on various Chinese sites. On 29 July, the controversy went inter\u00adnational when Gaetan Burgio, a geneticist at the Australian National University in Canberra, posted thorough details of  his failed attempts to replicate the experiment  on his blog. Normally, his posts get a few dozen hits, but this one spiked to more than 5,000. On the same day, geneticist Llu\u00eds Montoliu, at the Spanish National Centre for Biotechnology in Madrid, e-mailed his colleagues at the International Society for Transgenic Technologies to recommend \u201cabandoning any project involving the use of NgAgo\u201d to \u201cavoid wasting time, money, animals and people\u201d. The e-mail was leaked and posted on Fang\u2019s website. Since then, an online survey by Pooran Dewari, a molecular biologist at the MRC Centre for Regenerative Medicine in Edinburgh, UK, has found  only 9 researchers who say that NgAgo works  \u2014 and 97 who say that it doesn\u2019t. Two researchers who initially reported success with NgAgo in an online chat group now say that they were mistaken. Debojyoti Chakraborty, a molecular biologist at the CSIR-Institute of Genomics and Integrative Biology in New Delhi, says that he repeated a specific section of Han\u2019s paper that described using NgAgo to knock out a gene for a fluorescent protein that had been introduced into a cell. The glow was reduced, so Chakraborty assumed that NgAgo had disabled the gene. But after sequencing the DNA, he found no evidence of gene editing. He now says that the reduction in fluorescence must have had some other cause. Jan Winter, a PhD student in genomics at the German Cancer Research Center in Heidelberg, says that he had a similar experience. \u201cI will retry the experiment in the upcoming weeks, but so far I think it won\u2019t work,\u201d he says. Han says that he has only got the system to work on cells cultured in his laboratory, and it failed in cells that he purchased. He later found the purchased cells to be contaminated with bacteria called  Mycoplasma , and says that others might be having the same problem. He adds that some graduate students might be working too fast and not being careful with reagents. Winter disagrees: \u201cI do not think it is a problem of the scientists doing something wrong.\u201d One researcher in China, who works independently from Han\u2019s research group and who doesn\u2019t want his name to be entangled in the public controversy, told  Nature  that he had tested NgAgo in a few kinds of cell and found that it was able to induce genetic mutations at the desired sites \u2014 a finding that he verified by sequencing. He adds that the process was less efficient than CRISPR\u2013Cas9, and requires tweaking to improve the efficiency. \u201cBut, in short, it worked,\u201d he says. Two more Chinese scientists, who also asked not to be named, say they have initial results showing that NgAgo works but still need to confirm with sequencing. \u201cIt might, might work,\u201d says Burgio, \u201cbut if so, it\u2019s so challenging that it\u2019s not worth pursuing. It won\u2019t surpass CRISPR, not by a long shot.\u201d Burgio says there is little that is new in the  revised protocol on Addgene . There is a warning to maintain levels of magnesium in cells, \u201cbut that doesn't make any sense to me\u201d, he says. It also warns against  Mycoplasma  contamination. But Montoliu, who might now give NgAgo one more chance in September, doubts that this could account for all the reported problems. The failure of NgAgo \u201cwould be disappointing, but then there is work for us left to do to see whether other Argonaute systems can get it to work somehow,\u201d says microbiologist John van der Oost of Wageningen University in the Netherlands, a co-author of the 2014 analysis of Argonaute proteins that laid the groundwork for their use in gene editing ( D.\u00a0C.\u00a0Swarts  et al .  Nature    507,  258\u2013261; 2014 ). This week,  Nature Biotechnology  sent a statement to  Nature \u2019s news team, saying that \u201cseveral researchers\u201d have contacted the journal to report that they cannot reproduce the results, and that \u201cthe journal is following established process to investigate the issues\u201d. A spokesperson declined to comment on the nature or duration of the investigation. ( Nature Biotechnology  is published by  Nature \u2019s publisher, Springer Nature;  Nature \u2019s news and comment team is editorially independent of the publisher\u2019s research editorial teams.) Hebei University of Science and Technology says that it will ask Han to repeat the experiment so that it can be verified by an independent party within a month, according to  Chinese state media . Additional reporting by Heidi Ledford \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Beyond CRISPR: A guide to the many other ways to edit a genome 2016-Aug-08 \n                   \n                     Chinese scientists to pioneer first human CRISPR trial 2016-Jul-21 \n                   \n                     CRISPR, the disruptor 2015-Jun-03 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   \n                     Nature  special: CRISPR \n                   \n                     Nature  special: Science in China \n                   \n                     Outlook: Gene editing \n                   \n                     Chunyu Han lab page on Addgene \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20391", "url": "https://www.nature.com/articles/nature.2016.20391", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Analysis from US National Institutes of Health charts shift in model-organism trends. Zebrafish are the rising stars of model-organism research, an analysis of grants from the US National Institutes of Health (NIH) shows. A team at the NIH Office of Portfolio Analysis  assessed trends  in the agency\u2019s funding of model-organism research between 2008 and 2015, through its R01 awards, the largest NIH grant programme for individual investigators. Using a text-mining algorithm and manual searches, they studied grant data for four animal models: fruit flies ( Drosophila melanogaster ), nematode worms ( Caenorhabditis elegans ), zebrafish ( Danio rerio ) and  Xenopus laevis  frogs. Together these organisms were mentioned in more than 9,500 successful grant applications. The analysis revealed that grants for zebrafish studies accounted for 0.8% of all R01 awards in 2008, but for 1.27% in 2015 \u2014 a rise of almost 60%. And the proportion of  C. elegans  studies rose from 0.87% to 0.98%, a more modest overall increase of about 36%. By contrast, awards for research with  Xenopus  frogs dropped by some 30%, from 0.83% to 0.57%.  The shifts are broadly representative of the numbers of applications received, the team says, indicating a shift in model-organism trends. In an  extension of the analysis , the team found that nearly 50% of funded R01 grants in the same period were for mouse studies \u2014 a proportion that has increased yearly since 2008. Read a previous Trend Watch: ' Brain implants and gene-editing enhancements worry US public ' \n                   Parasitic infection may have spoiled zebrafish experiments 2016-Jul-29 \n                 \n                   Funding for model-organism databases in trouble 2016-Jun-21 \n                 \n                   Preclinical research: Make mouse studies work 2014-Mar-26 \n                 \n                   Zebrafish genome helps in hunt for treatments 2013-Apr-17 \n                 \n                   NIH Office of Portfolio Analysis \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20406", "url": "https://www.nature.com/articles/nature.2016.20406", "year": 2016, "authors": [{"name": "Miquel Sureda Anfres"}], "parsed_as_year": "2006_or_before", "body": "Greenland shark found to be at least 272 years old. A large, almost-blind shark that lives in the freezing waters of the North Atlantic and Arctic oceans is officially the world\u2019s longest-living vertebrate, scientists say. The Greenland shark ( Somniosus microcephalus ) has a lifespan of at least 272 years, and might live as long as 500 years 1 . That is older than the  211-year lifespan of the bowhead whale  ( Balaena mysticetus ), the previous record-holder in the scientific literature 2 . It also beats the popular \u2014 but unconfirmed \u2014 tale of a famous female Koi carp called Hanako, who supposedly lived to 226 years old. Marine scientists already knew that the Greenland shark was long-lived, says Peter Bushnell, a marine physiologist at Indiana University South Bend and a co-author of the study, published in  Science . The fish are enormous but grow slowly, suggesting a long lifespan. Adult Greenland sharks have been measured at more than 6 metres long \u2014 and researchers think that they could grow even longer. One 1963 study estimated that the species grows at less than 1 centimetre per year 3 . Getting a definitive measure of the shark\u2019s age, however, has proved tricky. Conventionally, researchers count layers of calcified tissue that grow on a fish\u2019s fin scales or other bony structures \u2014 rather like counting tree rings. But Greenland sharks have small, spineless fins, and their vertebrae are too soft for countable layers to be deposited, says marine biologist Julius Nielsen at the University of Copenhagen, who also worked on the study. \n             The eyes have it \n           Instead, the team decided to measure levels of radioactive carbon-14 in fibres in the centre of the shark\u2019s eye lens. Such measurements reflect levels of radiocarbon in the ocean when the lens was first formed. Measurements of 28 female Greenland sharks, made during surveys in 2010\u201313, suggested that the largest of them (at 5.02 metres long) must have been between 272 and 512 years old at the time. The shark's longevity probably arises because it expends very little energy, owing to its cold body temperature and enormous size, Bushnell says. Not all cold, large species live to such an exceptional age, so it would be intriguing to know whether the shark has any particular quirks or molecular tricks that contribute to its long lifespan, says Mario Baumgart, a biologist at the Leibniz Institute on Aging in Jena, Germany. Nielsen agrees \u2014 but says that he\u2019s not working directly on that question. He prefers to explore other mysteries, such as how the sharks catch their prey, and where they mate. The study also shows that Greenland shark females don\u2019t reach sexual maturity until around 150 years old \u2014 suggesting that a century of heavy fishing could wipe out the entire species, says Bushnell. Although the sharks aren't themselves being overfished, a greater threat comes from the way climate change is affecting fishing practices in their environment, says Aaron MacNeil, a marine biologist at the Australian Institute of Marine Science near Townsville, Queensland. \u201cGreenland sharks have been fished by Inuits for centuries and still there\u2019s a lot of them right now,\u201d he says. \u201cIn my view, the real danger is that the Arctic is quickly changing due to global warming, leading to increases in commercial fishing and bycatch that Greenland sharks may not be able to cope with.\u201d \n                   Bright light accelerates ageing in mice 2016-Jul-14 \n                 \n                   Short-lived fish may hold clues to human ageing 2015-Dec-03 \n                 \n                   Why sharks have no bones 2014-Jan-08 \n                 Reprints and Permissions"},
{"file_id": "536138a", "url": "https://www.nature.com/articles/536138a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Life came to ice-free Canadian corridor too late to sustain migrations of Clovis and pre-Clovis people. Archaeologists need a new theory for the colonization of the Americas. Plant and animal DNA buried under two Canadian lakes squashes the idea that the first Americans travelled through an ice-free corridor that extended from Alaska to Montana. The analysis, published online in  Nature  on 10\u00a0August and led by palaeo\u00adgeneticist Eske Willerslev of the University of Copenhagen, suggests that the passageway became habitable 12,600\u00a0years ago 1 . That\u2019s nearly 1,000\u00a0years after the formation of the Clovis culture \u2014 once thought to be the first Americans \u2014 and even longer after other, pre-Clovis cultures  settled the continents  (see 'American trail').  Some 14,000 years ago, as North America was emerging from the last Ice Age, twin glaciers that blanketed central Canada receded, creating the ice-free corridor before the appearance of Clovis people across what is now the central United States. \u201cThat coincidence seemed too powerful to ignore,\u201d says archaeologist and co-author David Meltzer of Southern Methodist University in Dallas, Texas. \u201cPeople who have been cooling their heels in Alaska for thousands of years see this new land open up and they come blasting down this corridor into the new world.\u201d \n               Persistent idea \n             The ice-free-corridor theory began to crack in the 1990s, when researchers made a case that  humans lived at Monte Verde in Chile more than 14,000 years ago . The discovery of  other possible pre-Clovis sites  in North America  further shook the theory that Clovis people were the first Americans . But the idea that their ancestors at least trekked through the corridor persisted, says Meltzer, even though there was little consensus on when the passage opened or when it became habitable. \u201cIt\u2019s 1,500 kilometres. You can\u2019t pack a lunch and do it in a day.\u201d To build a picture of the habitat as it crept out of the Ice Age, Willerslev\u2019s team analysed DNA in cores taken from beneath two lakes in what was the last stretch of the corridor to melt. The first plant life \u2014 thin grasses and sedges \u2014 dates back just 12,600 years. The region later became lusher, with sagebrush, buttercups and even roses, followed by willow and poplar trees. This habitat attracted bison first, and later mammoths, elk, voles and the occasional bald eagle. Around 11,500 years ago, the corridor began to resemble the pine and spruce boreal forests of today\u2019s landscape. The region\u2019s bounty must eventually have tempted hunter-gatherers. But the dates rule out its use as a corridor by Clovis people and earlier Americans to colonize the Americas, says Willerslev. Instead, both probably skirted the Pacific coast, perhaps by boat. Loren Davis, an archaeologist at Oregon State University in Corvallis, agrees: \u201cNow that the ice-free corridor has been shown to be dead in the water \u2014 no pun intended \u2014 we can start to look at something like a coastal migration route.\u201d Other recent research has hinted that Clovis people and other early humans could not have moved through the ice-free corridor. In June, a team led by Beth Shapiro, an evolutionary palaeobiologist at the University of California, Santa Cruz, sequenced ancient DNA from bison that lived to the north and south of the passageway and found that these populations were cut off from each other during the last Ice Age until at least 13,000\u201313,400 years ago, when they started mixing again 2 . Shapiro, too, now favours the theory of a coastal migration route for humans. \n               Pacific pit stops \n             Discovering sites along these routes won\u2019t be easy, because most are now likely to be underwater.  But this summer, Davis and his colleagues began surveying areas of the Pacific Ocean , such as former bays and estuaries that might have served as pit stops for the first Americans. In 2017, the team will start to collect marine sediments to look for signs of habitation, such as stone artefacts or ancient human DNA. Willerslev hopes to be part of the searches, and thinks that recreating these once-coastal habitats through DNA sequencing could prove to be a valuable tool. The fact that early humans advanced to the Americas despite continent-sized glaciers standing in the way has also prompted him to rethink the conventional wisdom that early humans, like other animals, migrated solely in search of food. \u201cJust like people today are trying to reach the top of Mount Everest or the South Pole, I'm sure these hunter-gatherers were also explorers and curious about what would be on the other side of these glacier caps,\u201d he says. \u201cWhen you first reach California, why would you go further? Why not just stay in the Bay Area?\u201d See related News & Views article:  \u2018Muddy messages about American migration\u2019 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               Reprints and Permissions"},
{"file_id": "nature.2016.20408", "url": "https://www.nature.com/articles/nature.2016.20408", "year": 2016, "authors": [{"name": "Pakinam Amer"}, {"name": "Mohammed Yahia"}], "parsed_as_year": "2006_or_before", "body": "Cash-strapped Zewail City of Science and Technology is the legacy of Arab chemist Ahmed Zewail. Questions are swirling over the future of Egypt\u2019s first science city, after the death of the Nobel laureate who made the project his legacy. The  Zewail City of Science and Technology , a campus outside Cairo comprising a non-profit university and several research institutes, is named for the man who spearheaded it: Egyptian-born US chemist Ahmed Zewail, the  first Arab to win a science Nobel . But Zewail\u2019s death at the age of 70 last week raises fresh doubts about the research hub's already precarious finances. The institute had relied heavily on Zewail\u2019s star name and contacts to attract the support of scientific luminaries and millions of dollars in donations and government loans. It is now running out of money, has not yet raised enough cash to support a planned move to a new campus and will probably have to rely on more state support, say researchers working there. \u201cFundraising has always been a challenge, and I think it is likely to be affected by the loss of Dr Zewail in the short term,\u201d says Sherif El-Khamisy, a molecular biologist at the University of Sheffield, UK, who is also director of Zewail City\u2019s Center for Genomics. \u201cBut the logistical support envisaged from the state is expected to override the initial fear or uncertainty.\u201d \n               Egyptian flagship \n             Uncertainty has plagued Zewail City since its inception. While working at the California Institute of Technology in Pasadena, Zewail proposed in 1999 to found the university and technology hub near Cairo as a flagship science project, essential for Egypt\u2019s research development. But it was not until 2011 that the institute launched \u2014 a delay that Zewail has ascribed to political instability and bureaucracy. The young university was quickly  plunged into controversy , after Egypt's first not-for-profit private research institution, Nile University \u2014 also outside Cairo \u2014 argued that it owned some of the buildings gifted to the science city. Nile University ultimately  won the legal dispute  \u2014 although it has allowed researchers from Zewail City to stay on in its buildings until a new campus is complete. Zewail City began accepting students in 2013; it currently has more 500 students and 150 academic professors and researchers. The first class of students will graduate next year, many of whom have received scholarships to cover their tuition fees. The project\u2019s new campus is expected to be finished in 2019, at a cost of at least US$450 million; a first phase should be complete by July 2017, when many faculty and students are to move there. But Zewail City hasn\u2019t raised enough money to finish even its first phase, says Sherif Fouad, a spokesperson for the institute. To pay for scholarships and campus construction, it has almost used up the 700 million Egyptian pounds (around US$80 million) raised from donors; its other funding comes in the form of a 1-billion-Egyptian-pound loan from the ministry of defence, which ultimately must be paid back. A shaky economy and the widely expected devaluation of Egypt\u2019s currency is not helping matters.  \n               President\u2019s backing \n             El-Khamisy and others affiliated with the institute say they are hopeful that it will survive \u2014 not least because it has the verbal backing of Egypt\u2019s president, Abdel Fattah el-Sisi. In a speech on 6 August after Zewail\u2019s death, el-Sisi asked Egyptians to continue to donate to the city, but vowed that Egypt\u2019s armed forces \u2014 whose engineers are building the new campus \u2014 would finish construction even if no more money comes through. \u00a0 \u201cThe president\u2019s speech was very reassuring for us all that Zewail City remains a priority for the government and is considered one of Egypt\u2019s national projects,\u201d says Fouad. It is likely that Egypt\u2019s government will ultimately need to step in with support, says Salah Obayya, a physicist who is currently acting chairman of Zewail City until a replacement for Zewail is elected. How the state deals with that intervention could affect whether the institute can maintain the support of scientists whom Zewail sought to attract, says Ibrahim el-Sherbiny, joint director of the institute\u2019s Center for Materials Science. \u201cIf they feel the reassurance on the ground, they will remain and attract others because they loved Dr Zewail, and I am sure they would love to support him after his death,\u201d he says. Zewail City enjoys an unusual autonomy: unlike other Egyptian state-sponsored institutions, it has been granted a decree that allows the campus to outline its own structure and governance, guaranteeing its independence from the education ministry. Obayya says that he does not expect such autonomy to be affected by closer government intervention. At a meeting on 8 August, Zewail City\u2019s board of directors vowed that their pioneer\u2019s \u201cnational mission\u201d would carry on. British-Egyptian cardiac surgeon Magdi Yacoub of Imperial College London is widely tipped to take Zewail\u2019s place at the head of the project, says Fouad. \u201cIf Sir Magdi Yacoub is chosen to run the city, it will give the project the needed stability to soldier on,\u201d says Sherif Sedky, a physicist and former academic president of Zewail City, who is now provost of the American University in Cairo. This article is jointly published with  \n                     Nature Middle East \n                   . \n                     Court grants students access to disputed campus 2012-Nov-20 \n                   \n                     Universities clash by the Nile 2012-May-01 \n                   \n                     Nature Middle East \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20454", "url": "https://www.nature.com/articles/nature.2016.20454", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Offshore capacity on the rise despite high costs of installation. The United Kingdom has  approved plans  for the world\u2019s largest offshore wind farm: up to 300 turbines with a capacity of up to 1.8 gigawatts in the North Sea. The country already leads the way in offshore wind power, accounting for 40% of the world\u2019s 12 gigawatts of installed capacity. Germany follows with 27%. Offshore wind power still represents just 3% of the world\u2019s installed wind capacity, according to the Global Wind Energy Council. But the market is expanding. In 2015, offshore wind accounted for 24% of wind-power installations in the European Union, up from 13% the year before. And since 2011, overall capacity installed off the coasts of 11 European countries has tripled. The main challenges for offshore development are the high capital and maintenance costs,  according to  Windpower Monthly . Offshore wind power costs around twice as much to generate as onshore (which itself can now often be cheaper than conventional power). But thanks to advanced turbine technology and decreasing installation costs, offshore generation costs have started to drop from their 2014 peak and are projected to fall from US$200 per megawatt hour in 2015, to $139 per megawatt hour in 2030, according to estimates by the US National Renewable Energy Laboratory. Read a previous Trend Watch: ' US endangered-species recovery surges to record high ' \n                   Germany\u2019s renewable revolution awaits energy forecast 2016-Jul-13 \n                 \n                   Renewable energy: Wind power tests the waters 2014-Sep-24 \n                 \n                   Renewable energy: Back the renewables boom 2014-Mar-19 \n                 \n                   Global Wind Energy Council \n                 Reprints and Permissions"},
{"file_id": "536386a", "url": "https://www.nature.com/articles/536386a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "A crewed trip to Mars is still decades away. As Barack Obama prepares to leave office,  Nature  examines the scientific highs and lows of his presidency. Read the other stories in this series about his policies on  biomedicine ,  research integrity  and  climate change . Barack Obama tried to shake up the US space programme, including NASA\u2019s long-standing plan to send people to Mars. But nearly eight years \u2014 and a series of U-turns \u2014 later, he has little to show for his effort. \u201cWhere NASA is today is really not all that different from where it was during the last presidential transition,\u201d says Marcia Smith, a space-policy analyst in Arlington, Virginia, who runs SpacePolicyOnline.com. A crewed Mars mission remains two decades away. Its schedule is constrained by the funding available to develop the necessary hardware \u2014 a  new heavy-lift rocket and crew capsule  to sustain astronauts in deep space. That is almost exactly the situation NASA was in eight years ago, bar one detail: Obama ditched the Moon as a first stop for astronauts on their way to Mars. That decision, in February 2010, stunned NASA, Congress and space-policy experts. Obama cancelled the Constellation programme, which his predecessor George W. Bush created to send US astronauts  back to the Moon  in preparation for an eventual Mars trip. Two months later Obama announced a different course: astronauts would  visit a yet-to-be-chosen asteroid  before heading off to the red planet. The White House did not consult Congress on the switch, angering powerful members who represent space-industry employees in states such as Florida, Texas and California. \u201cThe hostility created by the way the Obama administration rolled that out still lingers in Congress,\u201d says Smith. The decision also alienated traditional US space partners such as Europe and Japan, says Scott Pace, director of the Space Policy Institute at George Washington University in Washington DC. \u201cLittle to no weight was given to the international implications of the decision to abandon efforts to lead an international return of humans to the lunar surface,\u201d he says. NASA was forced to modify its Mars plan in 2013, when it became clear that it did not have the technology to support astronauts in deep space. The White House introduced a controversial stopgap measure: instead of a crewed mission to visit an asteroid, a robot would drag an asteroid near the Moon where astronauts could then visit it. Asteroid scientists have  roundly denounced the plan , but it is moving forward despite slipping schedules and ballooning costs. The hardware for crewed deep-space journeys is also at risk of schedule and budget delays, the Government Accountability Office said last month. The heavy-lift rocket is scheduled for its first test flight in November 2018, while the crew capsule\u2019s is set for August 2021. Obama extended US participation in the International Space Station for four more years, to 2024 \u2014 a move generally acclaimed by scientists. And he oversaw the  shutdown of the space-shuttle programme , a process begun by Bush. After the last shuttle,  Atlantis , flew in July 2011, the United States turned to Russia to buy rides to orbit for its astronauts. NASA is relying on commercial companies to fly equipment and \u2014 eventually \u2014 astronauts to the space station. The first commercial cargo flights began in 2012, and the first astronauts are scheduled to fly aboard commercial spaceships no earlier than 2017. Many critics see NASA\u2019s human-spaceflight programme as adrift. Eileen Collins, a former space-shuttle commander, told the Republican National Convention in July that the agency needs \u201cvisionary leadership again\u201d. Scientists grumble about the relative lack of flagship missions in development. One of the biggest, a proposed mission to Jupiter\u2019s moon Europa, has been pushed through not by the White House or NASA, but by a Republican congressman from Texas who is enamoured with the idea of life on icy worlds. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Obama\u2019s science legacy: uneven progress on scientific integrity 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: betting big on biomedical science 2016-Aug-22 \n                   \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     NASA's deep-space crew capsule faces first big test 2014-Dec-03 \n                   \n                     NASA's plan to visit an asteroid faces rocky start 2014-Nov-10 \n                   \n                     Duelling visions stall NASA 2012-Dec-12 \n                   \n                     US science: The Obama experiment 2012-Sep-26 \n                   \n                     Obama\u2019s National Space Policy (PDF) \n                   \n                     Asteroid Redirect Mission \n                   \n                     NASA Journey to Mars overview \n                   \n                     Government Accountability Office report on NASA\u2019s Space Launch System \n                   \n                     Government Accountability Office report on NASA's Orion vehicle \n                   Reprints and Permissions"},
{"file_id": "536385a", "url": "https://www.nature.com/articles/536385a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Ambitious bids to map the brain and cure cancer have not boosted overall research funding. As Barack Obama prepares to leave office,  Nature  examines the scientific highs and lows of his presidency. Read the other stories in this series about his policies on  space ,  research integrity  and  climate change . When president-elect Barack Obama chose physicist John Holdren as his top science adviser in December 2008, some biomedical researchers worried that the pick signalled a White House bias towards physical science. Obama quickly put those fears to rest. Within weeks of his inauguration, he had  overturned restrictions on research using embryonic stem cells . He has gone on to launch major initiatives to map the brain, develop personalized medical treatments and cure cancer. But faced with a penny-pinching Congress, Obama\u2019s strong support for biomedical science has not translated into significant funding gains for the US National Institutes of Health (NIH). The agency has seen the purchasing power of flat research budgets  eroded by inflation  (see \u2018Budget battles\u2019). \u201cThe life sciences were a significant priority for the Obama administration,\u201d says Gregory Petsko, a biochemist at Weill Cornell Medical College in New York City. \u201cBut with Congress being the way that it is, there was a limit to what Obama could do as far as increasing support of biomedical research.\u201d It is the big initiatives that will probably form Obama\u2019s lasting biomedical legacy, says Benjamin Corb, head of public affairs at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. In 2013, Obama announced the Brain Research Through Advancing Innovative Neurotechnologies (BRAIN) initiative to  map the human brain . In 2015, he unveiled the Precision Medicine Initiative, which includes an ambitious study of health records and  genomic information from one million people in the United States . And in January, he introduced the Cancer Moonshot, a US$1-billion proposal to  double the pace of cancer research  in five years. NIH director Francis Collins, who led the Human Genome Project in the 1990s, likens Obama to a player who scores three goals in the same game: \u201cI said to him, basically, \u2018Mr President, you have achieved a hat-trick.\u2019\u201d But such programmes may come at a cost to basic research funding, even as they draw attention to areas of science that may be overlooked or underfunded. \u201cThese big initiatives tend to cast a really large shadow,\u201d says Corb. \u201cThey can overshadow some of those basic research needs.\u201d And it\u2019s not clear whether Obama\u2019s major initiatives will survive under the next president. Democratic presidential candidate Hillary Clinton has said that she would continue the Cancer Moonshot initiative. She also supports Alzheimer\u2019s disease research, which bodes well for the BRAIN initiative if she is elected, Corb says. Republican candidate Donald Trump has  no clear policy on biomedical research . But the next president won\u2019t be making that decision alone. Patient advocates drive major changes in biomedical research priorities and funding over time, and will probably ensure that Obama\u2019s big-science initiatives continue, says Mary Woolley, president of the science-advocacy organization Research!America in Arlington, Virginia. \u201cDetermined advocates are not going to take \u2018no\u2019 for an answer,\u201d she says. \u201cThey\u2019ll be the ones that bridge administrations.\u201d \n                 Additional reporting by Sara Reardon. \n               \n                 Tweet \n                 Follow @NatureNews \n               \n                     Obama\u2019s science legacy: uneven progress on scientific integrity 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: climate (policy) hots up 2016-Aug-23 \n                   \n                     Obama\u2019s science legacy: a space race stalls 2016-Aug-22 \n                   \n                     Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                   \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     Scientists worry as cancer moonshots multiply 2016-Apr-27 \n                   \n                     Giant study poses DNA data-sharing dilemma 2015-Sep-01 \n                   \n                     Ambitious plans for BRAIN project unveiled 2014-Jun-06 \n                   \n                     US science: The Obama experiment 2012-Sep-26 \n                   \n                     Obama overturns stem-cell ban 2009-Mar-09 \n                   \n                     BRAIN Initiative \n                   \n                     Precision Medicine Initiative \n                   \n                     Cancer Moonshot \n                   \n                     AAAS: Historic Trends in US R&D Funding \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20409", "url": "https://www.nature.com/articles/nature.2016.20409", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "World\u2019s largest scientific society plans to introduce ChemRxiv for a traditionally reluctant discipline. Chemists could soon be getting their own dedicated preprint server: the ChemRxiv. The American Chemical Society (ACS), the world\u2019s largest scientific society,  announced on 10 August  that it wants to establish the site to help chemists to share early results and data with colleagues online, ahead of formal publication. The repository would follow on the heels of the popular preprint server  arXiv , which  turns 25 this year  and is used widely by physicists, computer scientists and mathematicians, and the  bioRxiv , for biologists, which was  launched 3 years ago . The name is catching on in other disciplines, too: 2016 has seen the launch of the  SocArXiv  for social sciences and the  engrXiv  for engineering, and a PsyArXiv, for psychology, is  rumoured to be on the way . Some chemists have welcomed the announcement. \u201cI\u2019m very, very excited,\u201d says Al\u00e1n Aspuru-Guzik, a quantum chemist at Harvard University in Cambridge, Massachusetts, and an advocate for preprint culture who already posts his work to the chemical-physics section of arXiv.\u00a0\u201cI think it really hinders the field of chemistry, not having an arXiv culture.\u201d The ACS says that it is inviting other interested parties to participate in shaping its service, ahead of its future launch at an as-yet unspecified date. This could include other publishers and philanthropists, who might be willing to pay some of the venture\u2019s costs. \u201cWe\u2019ve been really impressed over the past couple of years by the number of developments in the preprint server field, most noticeably, the launch and rapid growth of bioRxiv and growing popularity of arXiv on the physics side,\u201d says Kevin Davies, vice-president of the ACS Publications Division. \u201cThere is a growing need and desire for someone to launch a preprint server for the chemistry field,\u201d he says. \n             Journal block \n           Chemists have historically been reluctant to share early versions of their manuscripts publicly before peer review. One factor is that some major journals in the discipline frown on publishing work that has already been posted online. The  Journal of the American Chemical Society  ( JACS ), the ACS\u2019s best-known journal, states, for example, that only \u201coriginal work that has not been previously published\u201d will be considered, and that when submitting, authors must inform the editor if they have posted results on a preprint server. And the influential journal  Angewandte Chemie , published by Wiley-VCH, explicitly bars authors from having published any of the \u201cessential findings\u201d of their paper in a preprint. Davies says that around three-quarters of the ACS\u2019s 50 journals have positive attitudes towards preprints. He says that policies are set by the individual chief editors and editorial boards of the society\u2019s journals. \u201cThere will not be a top-down shift imposed by ACS,\u201d he says. The initiative would be even more valuable if ACS could collaborate with other major chemistry publishers, so as to ensure that all chemistry journals move to accepting papers that have been uploaded to preprint servers, says Lee Cronin, who studies complex chemical systems at the University of Glasgow, UK. It remains to be seen how quickly a preprint server will catch on in chemistry. But Aspuru-Guzik thinks that once chemists go to ACS meetings and see other chemists posting links to the ChemRxiv, things could quickly change: \u201cIt\u2019s kind of like catching Pok\u00e9mon \u2013 you see someone catching Pok\u00e9mon, and the next thing  you\u2019re catching Pok\u00e9mon yourself ,\u201d he says. \n                   ArXiv preprint server plans multimillion-dollar overhaul 2016-Jun-29 \n                 \n                   Biologists urged to hug a preprint 2016-Feb-16 \n                 \n                   ArXiv rejections lead to spat over screening process 2016-Jan-29 \n                 \n                   Open journals that piggyback on arXiv gather momentum 2016-Jan-04 \n                 \n                   ACS announcement \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20287", "url": "https://www.nature.com/articles/nature.2016.20287", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Three-year pilot devotes \u20ac3 million to verifying other studies. The Netherlands has launched what researchers say is the world\u2019s first national fund dedicated to replication studies: a pot of \u20ac3 million (US$3.3 million) over the next 3 years for Dutch scientists to test whether they can reproduce important research results in social and medical sciences. The pilot programme was  announced on 19 July  by the Netherlands Organisation for Scientific Research (NWO), the country\u2019s largest research-funding agency. It marks a tiny fraction of the agency\u2019s \u20ac700-million annual budget, but is an important step, says Brian Nosek, executive director of the Center for Open Science in Charlottesville, Virginia. \u201cIf my calculations are correct, this is an increase of infinity per cent of federal funding dedicated to replication studies,\u201d he says. Nosek has led  an effort to replicate work from 100 psychology publications , which relied on what he estimates was $4 million in donations of time and resources from participating researchers. Even limited funds for replication can make innovative research more efficient, because it helps researchers flag up blind alleys, he says. \u201cConfirming a result helps justify further investment in that line of inquiry. Failing to confirm a result identifies challenges that should be investigated further before going all in.\u201d \u201cThis clearly signals that NWO feels there is imbalance in how much scientists perform replication research, and how much scientists perform novel research,\u201d says Daniel Lakens, a cognitive psychologist at Eindhoven University of Technology in the Netherlands. \n             Impact check \n           The NWO pilot will focus on repeating \u201ccornerstone\u201d research \u2014 studies that have had a large impact on science, government policy or public debate. Jos Engelen, chair of the NWO\u2019s governing board, says that the agency expects to be able to fund 8\u201310 projects each year. A study that collects new data can be funded with up to \u20ac150,000; one that re-analyses existing data can receive up to \u20ac75,000. Scientists are not allowed to use the money to replicate their own work, and the official call for proposals should come in September. The NWO programme is making a good investment by encouraging replication, says Sam Schwarzkopf, a cognitive neuroscientist at University College London. But he argues that replication should simply be built into general research \u2014 for instance, by requiring that researchers funded for innovative work must also perform direct replications of previous work.\u00a0 Daniel Gilbert, a psychologist at Harvard University in Cambridge, Massachusetts, who has previously  criticized Nosek's work , says the benefits of dedicating funds for replication studies remain to be seen. \"If the Dutch government wants to spend its money on research whose sole qualification is its unoriginality, then that\u2019s their prerogative. Will we learn something valuable from such research? Probably. Will it be more valuable than what we would have learned if the same amount of money had been spent exploring important new ideas? That\u2019s a difficult question to answer. But it is the critical question, and it is the question no one asks,\" he says. The NWO hopes to use insights from its pilot programme to incorporate replication into research more broadly, but exactly how that will work is uncertain, says Engelen. \u201cIt is too early to have expectations about this type of funding becoming a regular fixture,\u201d he says. \n                   1,500 scientists lift the lid on reproducibility 2016-May-25 \n                 \n                   How many replication studies are enough? 2016-Feb-26 \n                 \n                   Metascience could rescue the \u2018replication crisis\u2019 2014-Nov-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20307", "url": "https://www.nature.com/articles/nature.2016.20307", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Uncertainty reigns as the UK struggles with how to sever its relationship with the EU. Scientists usually look down on anecdotal evidence \u2014 but for the past month,  alarmed UK researchers  have been grabbing at every anecdote they can find. The reason: an urgent need to emphasize to politicians that UK science is already being damaged by Brexit, the country\u2019s decision to leave the European Union. Because of  uncertainty about the future , research leaders say, UK institutions that rely on EU funding are already seeing their staff dropped or demoted from planned collaborative EU grant applications, and top talent could already be leaving Britain. \u201cIt\u2019s a bit soon to tell whether this is really significant. The stories we are getting are in the tens, not in the hundreds or thousands,\u201d Philip Nelson, chief executive of the UK Engineering and Physical Sciences Research Council (EPSRC), told a House of Lords inquiry into the effects of Brexit on science on 19 July. \u201cThe extent to which this is a kneejerk reaction to the referendum is really hard to tell.\u201d Individual anecdotes of Brexit\u2019s concrete impacts are emerging. Tom Dowling, a British geologist who returned to the United Kingdom in March after gaining his PhD at Lund University in Sweden, told  Nature  that he has just scrapped his application for a European research grant. He and his supervisor at Cambridge University felt that potential post-Brexit bias against British scientists meant that it \u201cwasn\u2019t worth continuing\u201d. Dowling adds that he is now considering leaving the country and taking European citizenship.  And Chris Husbands, vice-chancellor of Sheffield Hallam University, told a House of Commons inquiry that his institution\u2019s academics had been asked to withdraw from three collaborative projects funded by the EU\u2019s Horizon 2020 programme, \u201cdue to the perceived risk of having a UK partner on the project\u201d. Other consortia have asked that the university no longer be a coordinator in collaborations, he said. The UK science minister Jo Johnson, has set up a specific e-mail address (research@bis.gsi.gov.uk) to receive more such examples. Still, five UK universities told  Nature  that they haven\u2019t yet heard firm examples of negative fallout from Brexit. And spokespeople for two organizations that are collating dossiers for Johnson\u2019s inbox \u2014 Universities UK, which represents British higher-education institutions, and the Institute of Physics \u2014 both told  Nature  on 20 July that despite concerns, they haven\u2019t yet seen evidence that Brexit is having a widespread impact. Research leaders say that waiting a few months for stronger evidence \u2014 such as quantitative proof of a drop in UK\u2013EU collaborations, or an exodus of non-British EU academics (who make up 15% of UK university staff) \u2014 could be too late. \u201cIf we do not raise these real concerns now, by the time we have hard data, the damage may have already been done,\u201d says a spokesperson for the Royal Society.\u00a0 \n             Guarantee wanted \n           Demands are growing for politicians to do something to reassure scientists. On 19 July, seven national academies, including the Royal Society, urged the government to make a \u201cbold public commitment\u201d that the United Kingdom wants to retain and build on its research base, \u201cto assuage any loss of confidence in UK research\u201d. They say it is \u201cvital\u201d that non-British EU academics be given assurances that they will be able to continue to live and work in the country, and that Britain reassures its EU partners of its commitment to current and future research.  The head of the Royal Society, Nobel laureate Venkatraman Ramakrishnan, has called for the government to underwrite grants given to British scientists in multinational EU projects, to prevent EU collaborators worrying about any future loss of funding. And some researchers hope that the government could guarantee to protect UK research from any financial losses from Brexit, by redirecting some of the money that would have been paid to the EU. When science minister Johnson was asked whether he could promise security for science funding at a 19 July debate on higher-education legislation, he avoided answering the question. But it is politically very unlikely that government ministers can make solid assurances right now, says Sarah Main, director of the London-based Campaign for Science and Engineering. Because Brexit negotiations haven\u2019t started \u2014 and because constraints on freedom of movement were a crucial factor in favour of the Brexit vote \u2014 no one can guarantee that the United Kingdom will be able to easily hire EU scientists, access EU research funding or play a full part in projects with EU partners in years to come. Main says that, for now, she\u2019d just like to hear from  the new UK government  that science is of core importance to its plans for economic growth. \u201cWe\u2019ve moved from a political environment where that sort of thing was said quite regularly, to a point where we don\u2019t really know,\u201d she says. \n             Science on the agenda \n           Whatever happens, UK scientists want to make sure that their interests are heard when it comes to the Brexit negotiations with the EU. An  online petition  that calls for any Brexit deal to preserve UK access to EU collaborative research and development programmes has attracted more than 15,000 signatures in the ten days since it was launched. \u201cWe want to make sure that science doesn\u2019t get forgotten,\u201d says the petition\u2019s co-founder David Robinson, a metrology specialist who runs Psi-tran, a research consultancy in Surrey, UK. And more than 1,600 scientists \u2014 most of them early-career researchers at UK universities \u2014 wrote in a letter to  The Times  on 22 July that the government should protect scientists by acting to maintain access to EU funding and ensure the free movement of researchers. \"If these are lost during EU renegotiations, we insist that the government puts equivalent UK-backed schemes in place,\" the authors say. For now, it\u2019s important for scientists to remember that the United Kingdom remains a full member of the EU, emphasizes Gill Wells, who heads a team dealing with queries about European funding at the University of Oxford. She says that there is some panicking. But she has sought and received assurances from the European Commission that there will be no bias against UK applicants for European Research Council grants. And she cautions against making too much noise about the impacts of Brexit on job recruitment. \u201cThe more awareness [there is] that people don\u2019t come, the more people won\u2019t come.\u201d But for non-British scientists pondering UK job applications, the uncertainty must be having an effect, says Philippe Froguel, a French geneticist at Imperial College London. \u201cIt is not a good time to go to the UK to do science,\u201d he says. \u201cNobody in our field knows anything about the future, but everyone imagines the worst: fewer PhD students and academic recruits from Europe, and no access to EU funding, which means a loss of UK leadership in many fields of medical research. Many non-UK nationals like me are thinking of either taking a UK passport or leaving. A big mess indeed.\u201d Additional reporting by Petra Szilagyi and Quirin Schiermeier \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Science\u2019s status shifts in new Brexit government 2016-Jul-14 \n                 \n                   Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                 \n                   Nature  special: Brexit and science \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20309", "url": "https://www.nature.com/articles/nature.2016.20309", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Puzzling distribution of cases suggests Zika is not the only factor in reported microcephaly surge. Government researchers in Brazil are set to explore the country's peculiar distribution of Zika-linked microcephaly \u2014 babies born with abnormally small heads. Zika virus has spread throughout Brazil, but extremely high rates of microcephaly have been reported only in the country's northeast. Although evidence suggests that Zika can cause microcephaly, the clustering pattern hints that other environmental, socio-economic or biological factors could be at play. \u201cWe suspect that something more than Zika virus is causing the high intensity and severity of cases,\u201d says Fatima Marinho, director of information and health analysis at Brazil\u2019s ministry of health. If that turns out to be true, it could change researchers' assessment of the risk that Zika poses to pregnant women and their children. The idea has long been on Brazilian researchers' radar. \"This is being discussed in almost every scientific meeting,\" says Lavinia Sch\u00fcler-Faccini, a researcher at the Federal University of Rio Grande do Sul. But the enquiry marks the first time that scientists at the health ministry have taken up the hypothesis. The ministry has asked Oliver Brady, an epidemiologist at the London School of Hygiene & Tropical Medicine, and Simon Hay, director of geospatial science at the Institute for Health Metrics and Evaluation in Seattle, Washington, to collaborate with researchers in Brazil. \u201cThe aim is to understand why we are only observing elevated rates in the northeast,\u201d says Brady, who flew into Brasilia this month to begin work. \"I think they may be on to something,\" says Linda Birnbaum, director of the US National Institute of Environmental Health Sciences (NIEHS). Zika was  discovered in 1947  and hadn\u2019t been implicated in birth defects until now; and current strains of the virus don\u2019t show any significant mutations that might have increased its virulence. \"So why now?\" she asks. \n               Surprising clusters \n             The northeast was where the first reported surge in microcephaly cases in Brazil began a year ago. Health officials had expected that they would later see the same high rates in other parts of the country. \"We were expecting an explosion of birth defects,\" says Marinho. But as of 20 July, almost 90% of the 1,709 confirmed cases of congenital microcephaly or birth defects of the central nervous system reported in Brazil since last November were in a relatively small area: in the coastal hinterland of the country's northeastern tip. The affected area is about the size of the United Kingdom, whereas Brazil is almost as large as the United States. What's particularly surprising, says Marinho, is that just three cases have been confirmed in Brazil\u2019s second-most populous state, Minas Gerais, which borders the most-affected part of the northeast region. Poor data on the scale and timing of Zika outbreaks across Brazil make it difficult to tell whether large increases in microcephaly elsewhere might simply have been delayed \u2014 but ministry scientists now think that the northeast represents a marked outlier, she says. \n               Other factors at play? \n             There are many hypotheses about what might be going on. Marinho says that her team's data, submitted for publication, hint that socio-economic factors might be involved. For example, the majority of women who have had babies with microcephaly have been young, single, black, poor and tend to live in small cities or on the outskirts of big ones, she says. Another idea is that co-infections of Zika and other viruses, such as dengue and chikungunya, might be interacting to cause the high intensity of birth defects in the area. A third possibility was put forward in a paper published last month 1 , in which researchers from Brazilian labs noted a correlation between low vaccination rates for yellow fever and the microcephaly clusters. Because yellow fever and Zika are in the same virus family \u2014 they are both flaviviruses \u2014 the scientists speculated that the vaccine might provide some protection against Zika. \"It is a plausible hypothesis,\" says Duane Gubler, who studies mosquito-borne diseases at Duke\u2013NUS Medical School in Singapore. Marinho, however, is sceptical \u2014 arguing that there are many areas with low yellow fever vaccination rates that haven't had many confirmed microcephaly cases. The Brazilian doctor who was the first to report a firm link between Zika and microcephaly \u2014 Adriana Melo at IPESQ, a research institute in Campina Grande \u2014 is also among those who have suggested that other factors could be involved. In a preprint posted on the bioRxiv server on 15 July 2 , Melo and her colleagues at the Federal University of Rio de Janeiro reported that they had found bovine viral diarrhoea virus (BVDV) proteins in the brains of three fetuses with microcephaly from Para\u00edba state. The brains tested positive for Zika RNA, but the researchers found no Zika proteins. BVDV causes serious birth defects in cattle but is not known to infect people. Melo and her team suggest that Zika infection might reduce physiological barriers, making it easier for BVDV to cause infections. But they haven't ruled out the possibility, raised by other researchers, that their findings might be due to contamination (BVDV is a common contaminant of fetal bovine serum and other bovine-derived lab reagents). \n               Patchy data \n             The Brazilian health ministry\u2019s study will test for BVDV among other ideas, says Brady. Researchers will reanalyse raw data on microcephaly cases, and will model connections with possible cofactors such as socio-economic status, water contamination and mosquito-borne diseases. Most of this information will come from health-ministry databases, but the team will also study experimental data, such as how people's immune response may change after past infection with other viruses such as dengue. But researchers say that the information they have may not be enough to pin down whether factors in addition to Zika are involved. Much of the microcephaly raw data comes from routine hospital reports, which are often incomplete. And lab tests to confirm Zika infection are rarely carried out. Ultimately, researchers and public-health officials might have to wait for higher-quality data from research programmes such as the Zika in Infants and Pregnancy Study, which launched last month in Puerto Rico and aims to monitor as many as 10,000 pregnant women. The US National Institutes of Health (including Birnbaum\u2019s NIEHS) and the Oswaldo Cruz Foundation in Brazil are doing the work, which will also include testing whether nutritional, socio-economic and environmental factors have a role. The study will expand to Brazil, Colombia and other Zika-affected areas. Until more is known about Zika and the causes of increased microcephaly rates in Brazil\u2019s northeast, public-health actions and advice must err on the side of precaution, says Ian Lipkin, a virologist and outbreak specialist at Columbia University in New York City. \n                     Zika raises profile of more common birth-defect virus 2016-Jul-05 \n                   \n                     Zika must remain a high priority 2016-May-18 \n                   \n                     Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                   \n                     Zika virus: Brazil's surge in small-headed babies questioned by report 2016-Jan-28 \n                   Reprints and Permissions"},
{"file_id": "535334a", "url": "https://www.nature.com/articles/535334a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Court decision escalates tensions in ecologically sensitive region, but may also push nations to cooperate. An international tribunal has ruled against China\u2019s territorial claims in the South China Sea\u00a0\u2014\u00a0and ecologists are worried. They warn that the decision, which China has vowed to ignore, could escalate tensions between China and its neighbours, leading to increased competition for fish and a subsequent collapse in stocks. \u201cNow catastrophe looks much closer than before,\u201d says John McManus, a marine ecologist at the University of Miami in Florida. \u201cThe Hague decision stirred the pot.\u201d But McManus and others also note that the ruling, by the Permanent Court of Arbitration in The Hague, may nudge China to cooperate more with regional rivals on scientific and environmental issues. The Philippines brought the case in 2013 following China\u2019s occupation of a reef, called Scarborough Shoal, that both countries claim. On 12 July, the court upheld Philippine allegations that China had unlawfully restricted access to its fisherman there. And it rebuked China for its broader territorial claims within the \u2018nine-dash line\u2019 that envelops most of the South China Sea (see \u2018Disputed waters\u2019). China argues that certain geological fixtures in the sea are islands that belong to its sovereign land and that the waters that surround them are within its \u2018 exclusive economic zone \u2019. The court found that the fixtures are merely rocks or \u201clow-tide elevations\u201d. The tribunal also said that China had violated the United Nations Convention on the Law of the Sea by constructing artificial islands that damaged coral reefs, and by failing to stop its fishers from snatching protected species. The judgement is legally binding, but China, which views the South China Sea as increasingly important strategically, looks likely to ignore it. \u201cChina neither accepts nor recognizes it,\u201d says a statement from the foreign affairs ministry. The region contains more than 1\u00a0billion tonnes of oil reserves and is an important nexus connecting the Pacific and Indian oceans. \u201cNo one will force China from those islands if they don\u2019t want to go,\u201d says Tim Johnston, Asia program director for the Brussels-based International Crisis Group. Days after the ruling, China cordoned off a swathe of the area for military exercises. Military escalation could follow. For instance, the tribunal found that Mischief Reef is within the Philippines\u2019 exclusive economic zone but China has built a military base there, and, since the ruling, landed an aircraft there. Ecologists will be watching out for an escalation in fishing, in particular at the Scarborough Shoal. Fish densities and catch rates in the South China Sea have plummeted in past decades. McManus\u2019s research suggests that the reef sits at the centre of a crucial region from which many coastal fishing stocks are replenished. He fears that the ruling\u00a0\u2014\u00a0which found that China and the Philippines share fishing rights there \u2014 will lead both to increase their fishing activity. \u201cOne will try to get there before the other one,\u201d says McManus. \u201cWhen we have a present fisheries crisis and a looming fisheries catastrophe, you shouldn\u2019t go to one of the most important places for fisheries and destroy it.\u201d Such a rush could affect hundreds of species, he says, and permanently reduce the numbers of some, including sea turtles, sharks and giant clams. Another problem for conservationists is the destruction of coral reefs. McManus estimates that 162\u00a0square kilometres of reef has been destroyed, almost all of it by the Chinese in the past few decades. His calculations, which  he presented at the South China Sea Conference  on 12 July, suggest that Chinese cutter boats that hunt endangered giant clams account for 104\u00a0km 2  of the damage, with 55\u00a0km 2  a result of island building by dredging sediment from the ocean floor and dumping it on the reefs. A statement by China\u2019s ministry of foreign affairs says that island building is carried out \u201cbased on thorough studies and scientific proof\u201d and that \u201cthe impact on the ecological system of coral reefs is limited\u201d. But scientists have long said that the island building has to stop. Kwang-Tsao Shao, a marine-biodiversity expert at Taiwan\u2019s Academia Sinica in Taipei, says that at meetings that include his mainland peers, there is consensus from ecologists on both sides of the strait that the region should be set aside as a marine protected area. Scientists in the region do already collaborate: Zhifei Liu at Tongji University in Shanghai, China, leads a  UNESCO research project  which brings together scientists from China, the Philippines and other countries to study how sediment is deposited and transported in the South China Sea. Liu says that this and other China-funded projects will be unaffected by the ruling, although he worries that Philippine collaborators might now drop out. But scientific interest and environmental objectives in the area could strengthen diplomacy, by giving adversaries a reason to sit down and iron out priorities of mutual interest. The tribunal ruling may be what is needed to spark such dialogue, says Johnston. China\u00a0\u2014\u00a0although bullish in its responses so far and unlikely to give up its claims \u2014 will want to at least look as though it is acting fairly and for the common good. \u201cWe are hoping this may tip the balance and persuade China that constructive negotiation is the way forward,\u201d he says. Since the 1990s, McManus has advocated for a jointly run marine \u2018peace park\u2019 in the region. \u201cIt\u2019s the only way to avert a fisheries collapse. It will have a good effect on efforts to avert military action,\u201d he says. The tribunal decision makes him slightly more optimistic. He now gives the park a 1 in 10 chance of happening rather than 1 in 100. \u201cIf China can just sit there thinking \u2018this is all ours\u2019, we won\u2019t get anywhere,\u201d he says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Sea drilling project launches 2014-Jan-21 \n                   \n                     Uncharted territory 2011-Oct-19 \n                   \n                     Angry words over East Asian seas 2011-Oct-19 \n                   \n                     Coordinated plan to protect South China Sea 1996-Aug-29 \n                   \n                     Nature  special: Science in China \n                   \n                     Statement of the Tribunal \n                   \n                     Asia Maritime Transparency Initiative \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20305", "url": "https://www.nature.com/articles/nature.2016.20305", "year": 2016, "authors": [{"name": "Nisha Gaind"}], "parsed_as_year": "2006_or_before", "body": "Number has plateaued at around 2.5 million each year. Deaths from HIV/AIDS have declined steadily around the world over the past decade \u2014 but the rate of new infections has stayed much the same, an analysis in  The Lancet HIV 1  shows.The number of new HIV infections peaked at 3.3 million in 1997, and dropped by an average of 2.7% each year to around 2.5 million in 2005. But the infection rate has stagnated since then. In 74 countries, including several in the Middle East, the rate has increased.  A global scale-up in the use of antiretroviral therapy has been one of the crucial contributors to the decline in death rate, says the analysis, led by global-health researcher Haidong Wang at the University of Washington in Seattle. Worldwide, 41% of people with HIV/AIDS now receive antiretroviral drugs. Substantially reducing the number of new infections has proved more challenging, however. Efforts to prevent HIV transmission from mother to child have been a success, but HIV-related aid to developing countries has levelled off since 2010 \u2014 and does not look set to rise. Also to blame might be an increase in unprotected sex in places that now have a reduced perception of HIV risk, the report says.The analysis is part of the Global Burden of Disease Study 2015, a systematic effort to map the distribution of an array of diseases, led by the Institute for Health Metrics and Evaluation in Seattle, Washington. Read a previous Trend watch:  Farmed fish drive sea change in global consumption . \n                   Older men and young women drive South African HIV epidemic 2016-Jul-18 \n                 \n                   South Africa ushers in a new era for HIV 2016-Jul-13 \n                 \n                   Gene-editing method tackles HIV in first clinical test 2014-Mar-05 \n                 \n                   Vital statistics 2013-Feb-19 \n                 \n                   A burden weighed 2012-Dec-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20338", "url": "https://www.nature.com/articles/nature.2016.20338", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "European Space Agency switches off radio communications with popular space probe. Philae, the space probe that  made history by landing on a comet  in November 2014, has been silent since July 2015 \u2014 and is now silent for good. The European Space Agency (ESA) turned off its only means of talking to the lander at 11:00 Central European Summer Time on 27 July, as the probe\u2019s mothership, Rosetta, powered down in preparation for its own demise.  The lander\u2019s Twitter account,  @Philae2014 , has amassed nearly 448,000 followers \u2014 and on 26 July, it sent out a farewell message. \u201cIt\u2019s time for me to say goodbye. Tomorrow, the unit on @ESA_Rosetta for communication with me will be switched off forever...\u201d The lander had a bright but unlucky career. After landing with remarkable precision on the rubber-duck-shaped comet 67P/Churyumov-Gerasimenko, it failed to grip the comet\u2019s surface, and bounced twice before coming to rest in a shady spot where it was unable to charge its solar panels. Philae was able to perform only  64 hours of experiments  before its batteries died and the probe went into hibernation. The lander then briefly spluttered  back to life in June and July 2015 , as 67P neared its closest point to the Sun and gained more solar power, but it was unable to send back any scientific data about the comet. Despite its short lifetime, Philae was able to paint a rich picture of its final resting place. It found that 67P has  no magnetic field , but  some intriguing polymers . It also found the comet to have a surprising combination of a  strong, hard crust, covered by a softer layer of dust and ice . \"Considering how many different circumstances Philae had to be designed for, the lander functioned very well. No, we didn\u2019t get everything we hoped for, but I can\u2019t even list all the obstacles Philae overcame successfully,\" says Valentina Lommatsch, a member of the lander team at the German Aerospace Centre (DLR). In February this year, ESA scientists said that they suspected that the chances of hearing again from Philae were \u201c close to zero \u201d, but Rosetta kept listening, just in case. Now some 520 million kilometres from the Sun, Rosetta is quickly losing solar power. To boost power for remaining science operations ahead of Rosetta\u2019s  final manoeuvre and crash landing  on 30 September, ESA turned off non-essential components, including its interface for communicating with Philae. Switching off the communications device was not particularly emotional, says Stephan Ulamec, Philae lander manager at the DLR, as the lander team had for months never expected a signal from Philae. The end of Rosetta, on the other hand \u2013 which is still active and sending data \u2013 will be more emotional, he says. The level of public interest in the mission has been surprising, adds Ulamec. \u201cIt showed how much the general public is fascinated by space missions and solar system exploration. I hope this also became clear to politicians, making future, bold space missions possible.\u201d On Twitter, users poured out their goodbyes to the lander. And  @Philae2014  sent out a final plea for postcards from home. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Historic Rosetta mission to end with crash into comet 2015-Nov-04 \n                 \n                   Revived Philae poised to do comet science 2015-Jun-16 \n                 \n                   Philae comet lander wakes up and phones home 2015-Jun-14 \n                 \n                   Five factors that will decide if Philae wakes 2015-May-07 \n                 \n                   Rosetta's comet has no magnetic field 2015-Apr-14 \n                 \n                   Philae\u2019s 64 hours of comet science yield rich data 2014-Nov-18 \n                 \n                   Rosetta blog \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20302", "url": "https://www.nature.com/articles/nature.2016.20302", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Gene-editing technique to treat lung cancer is due to be tested in people in August. Chinese scientists are on the verge of being first in the world to inject people with cells modified using the CRISPR\u2013Cas9 gene-editing technique. A team led by Lu You, an oncologist at Sichuan University\u2019s West China Hospital in Chengdu, plans to start testing such cells in people with lung cancer next month. The clinical trial received ethical approval from the hospital's review board on 6 July. \u201cIt\u2019s an exciting step forward,\u201d says Carl June, a clinical researcher in immunotherapy at the University of Pennsylvania in Philadelphia. There have been a number of human clinical trials using an alternative gene-editing technique, including one led by June,  that have helped patients combat HIV . June is also a scientific adviser on a  planned US trial that would also use CRISPR\u2013Cas9-modified cells  for the treatment of cancer. Last month, an advisory panel of the US National Institutes of Health (NIH) approved that project. But the trial also requires a green light from the US Food and Drug Administration (FDA) and a university review board. The US researchers have said they could start their clinical trial by the end of this year. \n               Ineffective chemo \n             The Chinese trial will enrol patients who have metastatic non-small cell lung cancer and for whom  chemotherapy, radiation therapy and other treatments have failed . \u201cTreatment options are very limited,\u201d says Lu. \u201cThis technique is of great promise in bringing benefits to patients, especially the cancer patients whom we treat every day.\u201d Lu\u2019s team will extract immune cells called T cells from the blood of the enrolled patients, and then use  CRISPR\u2013Cas9 technology  \u2014 which pairs a molecular guide able to identify specific genetic sequences on a chromosome with an enzyme that can snip the chromosome at that spot \u2014 to knock out a gene in the cells. The gene encodes a protein called PD-1 that normally acts as a check on the cell\u2019s capacity to launch an immune response, to prevent it from attacking healthy cells. The gene-edited cells will then be multiplied in the lab and re-introduced into the patient\u2019s bloodstream. The engineered cells will circulate and, the team hopes, home in on the cancer, says Lu. The planned US trial similarly intends to knock out the gene for PD-1, and it will also knock out a second gene and insert a third before the cells are re-introduced into the patient. Last year, the FDA  approved  for use against lung cancer  two antibody-based therapies that block PD-1 . But it is difficult to predict for any given patient to what extent these antibodies will block PD-1 and activate the immune response. By contrast, knocking out the gene blocks PD-1 with greater certainty, while multiplying the cells increases the chance of a response. \u201cIt will be much more powerful than the antibodies,\" says Timothy Chan, who does clinical research in immunotherapy at Memorial Sloan Kettering Cancer Center in New York City. \n               Validated cells \n             It is well known that  CRISPR can result in gene edits at the wrong place  in the genome, with potentially harmful effects. Chengdu MedGenCell, a biotechnology company and a collaborator on the trial, will validate the cells to ensure that the correct genes are knocked out before the cells are re-introduced into the patients, says oncologist Lei Deng of West China Hospital, who is a member of Lu\u2019s team. Because the technique targets T cells, which are involved in various kinds of immune responses, in a non-specific way, Chan worries that the approach might induce an excessive autoimmune response in which the cells would start attacking the gut, or adrenaline glands or other normal tissue. \u201cAll the T cells \u2014 everything will be active. That will be a concern,\u201d says Chan.  He suggests, instead, that the team take T cells from the site of the tumour, because they would already be specialized for attacking cancer. But Deng says that the lung-cancer tumours targeted by their trial are not easily accessible. He also says that the team is reassured by the FDA-approved antibody therapies, which did not show a high rate of autoimmune response. The phase I trial is designed foremost to test whether the approach is safe. It will examine the effects of three different dosage regimens on ten people, and, Deng says, the team plans to proceed slowly, increasing the dosage gradually and starting with just one patient, who will be monitored closely for side effects. But the researchers will also closely watch markers in the blood that would indicate that the treatment is working. \n               Fast reputation \n             Lu says that the review process, which took half a year, required that the team invest a lot of time and human resources, including close communication with the hospital\u2019s internal review board (IRB). \u201cThere was a lot of back and forth,\u201d he says. The NIH\u2019s approval of the other CRISPR trial \u201cstrengthened ours and our IRB\u2019s confidence in this study\u201d, he adds. China has had a reputation for moving fast \u2014 sometimes too fast \u2014 with CRISPR, says Tetsuya Ishii, a bioethicist at Hokkaido University in Sapporo, Japan. According to Lu, his team was able to move fast because they are experienced with clinical trials of cancer treatments. June is not surprised that a Chinese group would jump out in front on a trial such as this: \u201cChina places a high priority on biomedical research,\u201d he says. Ishii notes that if the clinical trial begins as planned, it would be the latest in a series of firsts for China in the field of CRISPR gene editing, including the  first CRISPR-edited human embryos , and the first  CRISPR-edited monkeys . \u201cWhen it comes to gene editing, China goes first,\u201d says Ishii. \u201cI hope we are the first,\" says Lu. \"And more importantly, I hope we can get positive data from the trial.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     First CRISPR clinical trial gets green light from US panel 2016-Jun-22 \n                   \n                     Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                   Reprints and Permissions"},
{"file_id": "535473a", "url": "https://www.nature.com/articles/535473a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Presidential candidates begin to make clear their stark differences on climate change, energy production and stem-cell research. Science is slowly coming into focus in the US presidential campaign. Although neither Republican Donald Trump nor Democrat Hillary Clinton has emphasized core research issues, the candidates \u2014 and their parties \u2014 are beginning to flesh out their positions on climate change, education, biomedical research and  other topics  that involve the scientific community. Trump\u2019s pick of Indiana Governor Mike Pence as his running mate on 15\u00a0July signalled a sharp turn towards the Republican party\u2019s conservative base. Pence, a self-described Christian conservative, has questioned the existence of climate change, waffled on evolution and criticized President Barack Obama for  supporting embryonic-stem-cell research . His new role aligns with the hard-line policy platform adopted at the Republican convention, where Trump officially became the party\u2019s nominee on 19\u00a0July. If Trump wins, Pence\u2019s rise could embolden conservative Republicans to seek new limits on federal funding for embryonic-stem-cell research. But predicting how Trump would govern is a dangerous parlour game, says Michael Werner, executive director of the Alliance for Regenerative Medicine, an advocacy group in Washington DC: \u201cWe really don\u2019t know what a Trump\u2013Pence administration would do.\u201d It\u2019s a common refrain. Deciphering Trump\u2019s views on core science issues has been difficult given the free-wheeling style of his populist campaign. He has often seemed to focus more on taunting the political establishment than on staking out policy positions. By contrast, the Clinton campaign has consulted dozens of scientists on topics that include health, education and the environment. \u201cTrump doesn\u2019t have a prominent policy shop and a prominent set of policy advisers,\u201d says Douglas Holtz-Eakin, who counselled Republican senator John McCain (Arizona) on economic policy during his failed 2008 presidential bid. \u201cClinton has a vast bureaucracy and a ten-point plan for going out to lunch, so they couldn\u2019t be more different.\u201d The two candidates \u2014 whose campaign staff declined multiple interview requests \u2014 also seem to think very differently about the role of science. Although Clinton has described science and innovation as a foundation for the future, science funding seems to be an afterthought for Trump, says John Karsten, coordinator of the Center for Technology Innovation at the Brookings Institution, a think tank in Washington DC. Instead, the Republican has focused on issues such as national security, immigration and crumbling infrastructure. Climate change is one of the few science topics that has grabbed the campaign spotlight \u2014 in part because of Republican anger over Obama\u2019s regulations to limit greenhouse-gas emissions from  power plants , vehicles and  oil and gas development . Clinton\u2019s climate and energy proposals would largely maintain the current course; by contrast, in a major policy speech on 26\u00a0May, Trump promised to roll back Obama\u2019s \u201ctotalitarian\u201d regulations and withdraw the United States from the Paris climate agreement. Trump, who has long denied mainstream climate science, also said that his administration will focus on \u201creal environmental challenges, not phony ones\u201d. \n               Split tickets \n             This yawning philosophical divide is apparent in the party platforms that the Republicans and Democrats developed ahead of their nominating conventions this month. Environmentalists have criticized the Republican platform for labelling coal a \u201cclean\u201d energy source, even though it produces more carbon dioxide emissions per unit of energy than any other fossil fuel. Democrats, meanwhile, are poised to adopt a platform this week at their national convention that calls for using \u201cevery tool available to reduce emissions now\u201d. \u201cClimate is going to be talked about in this campaign, because the candidates have distinctly different positions,\u201d says Michael Oppenheimer, a climate scientist at Princeton University in New Jersey who is advising the Clinton team. Although his workload was light during primary season, Oppenheimer anticipates questions from the campaign about how global warming might affect certain regions, or the extent to which an extreme weather event might be related to global warming. Some experts say that the Democratic party\u2019s adoption of science as a campaign issue \u2014 which  Obama kick-started in 2008  \u2014 risks further polarizing thorny policy debates around scientific issues such as global warming. \u201cThe Democrats found that science was a good thing for them, just like historically strong support for the military was good for the Republicans,\u201d says Daniel Sarewitz, co-director of Arizona State University\u2019s Consortium for Science, Policy and Outcomes in Washington DC (and a regular contributor to  Nature ). \u201cIf the Democrats are the party of science, and you are a Republican, what does that make you think?\u201d But Holtz-Eakin says that the Trump campaign\u2019s apparent decision to forgo science advice is a reflection of Trump himself, not of Republican priorities. In 2008, he notes, the McCain campaign consulted scientists to formulate its positions on issues such as global warming \u2014 just as Clinton has done. With just over three months until the election, there is still a chance that Trump will assemble his own coterie of science advisers, says Andrew Rosenberg, who heads the Center for Science and Democracy at the Union of Concerned Scientists in Cambridge, Massachusetts. Doing so not only informs policy positions, it builds relationships that are useful after the election, when the winning candidate begins to assemble a government. \u201cThese things widen the network,\u201d Rosenberg says. \u201cI know it\u2019s happening with the Clinton campaign, and at some point I would expect it would happen with the Trump campaign.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Obama\u2019s top scientist talks shrinking budgets, Donald Trump, and his biggest regret 2016-Jul-06 \n                   \n                     Paris climate deal: what comes next 2016-Apr-22 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     The elephant in the room we can\u2019t ignore 2016-Mar-16 \n                   \n                     Policy: The art of science advice to government 2014-Mar-12 \n                   \n                     Trump campaign site \n                   \n                     Clinton campaign site \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20322", "url": "https://www.nature.com/articles/nature.2016.20322", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Britain\u2019s leave vote confuses EU emissions pledges. The European Union's climate-change agenda could lose momentum as a result of the bloc's split with the United Kingdom, policy experts say. Wrangling over the terms of Brexit seems likely to delay the EU\u2019s ratification of the Paris climate agreement, which aims to stabilize greenhouse-gas emissions, says Oliver Geden, head of the EU Research Division at the German Institute for International and Security Affairs in Berlin. \u201cBrexit might be an excuse for some EU countries to withhold their signature,\u201d he says. And because the United Kingdom has long been a proponent of strong climate policies within the EU bloc, the departure could strengthen the position of European countries that are reluctant to take forceful climate action. \u201cThe UK not being part of the negotiating mix means there is likely to be less pressure for ambitious targets and ensuring that the EU delivers on its Paris agreement commitments,\u201d says Martin Nesbit, a policy expert at the Institute for European Environmental Policy in London. \n             Emissions cuts \n           Before the Paris talks, the EU had pledged to cut its greenhouse-gas emissions by at least 40% by 2030, relative to 1990 levels. As part of that pledge, industries participating in the EU\u2019s emissions trading system were to reduce emissions by 43%, and other sectors \u2014 such as transport, agriculture and construction \u2014 were to achieve a 30% cut (both relative to 2005 levels). The latter target is most exposed to Brexit. Last week, the European Commission proposed the amount by which each of its 28 member states \u2014 including the United Kingdom \u2014 should cut 2005 emissions domestically by 2030, depending on individual states\u2019 economic strength and potential to reduce emissions. The proposals, which member states and the European parliament are yet to approve, range from 0% for Bulgaria to 40% for Luxembourg and Sweden. The United Kingdom has been given a 37% reduction target; once it quits the EU, its extra 7% will have to be divided between the remaining countries to keep the bloc on track. Equivalent to some 29 million tonnes of carbon dioxide, or less than one percentage point for each country\u2019s target, according to an analysis by the London-based climate watchdog group Carbon Brief, that is not a large amount. But the political wrangling over how to fairly share out the post-Brexit burden between EU member states will inevitably delay the bloc\u2019s ratification of Paris, says Geden. Eastern European countries, including Poland, the Czech Republic, Hungary and Slovakia, whose energy systems rely heavily on coal, will be reluctant to take on any extra emission cuts, he adds. A delay is unlikely to jeopardize the progress of the landmark Paris agreement, however. It will come into effect when 55 countries, accounting for at least 55% of the world\u2019s greenhouse-gas emissions, have ratified it. (So far, 20 countries \u2014 none of them large economies or EU members \u2014 have done so.) And it is unlikely to derail the growing momentum behind global action on climate. But it makes it more likely that the centre of gravity of global climate efforts will shift to China and the United States, which both aim to ratify the Paris deal before the end of the year. And until the EU ratifies the Paris agreement, it will have little say on its policy details, says Geden. \u201cFor the EU as a whole, which has long claimed leadership in international climate policies, delayed ratification of that treaty it has so vehemently advocated would be quite a disaster,\" he says. \u201cMuch depends on the outcome of forthcoming negotiations,\u201d adds Sebastian Oberth\u00fcr, a climate-policy researcher at the Free University of Brussels. \u201cBut Brexit will certainly not make things any easier.\u201d \n             Uncertain policies \n           Brexit uncertainty also looms over other key EU legislation related to climate and energy \u2014 in part, because the level of UK participation in the lawmaking process is unclear. In the second half of 2016, member states aim to finalize the long-planned reform of the EU emissions trading system and to adopt a new directive on renewable energy. The bloc\u2019s upcoming agenda also includes debating how to overcome barriers to the bloc's \"energy union\", the EU-wide single market for electricity, in which the United Kingdom may wish to remain to maintain its energy security. As long as the nation has not formally declared its exit, EU policymaking will continue under the premise that any legislation is applicable to it. But experts reckon that the United Kingdom\u2019s political influence in Brussels, on environmental policies and beyond, will rapidly fade. That means that it may become easier for the EU to adopt environmental policies unloved in Britain, says Nesbit \u2014 such as emission taxes and stricter fishing quotas. The UK government said last week that it will not take up its scheduled presidency of the EU in the second half of 2017, focusing instead on its preparations for Brexit. The United Kingdom, says Nesbit, will have \u201czero to negative\u201d influence on the outcome of EU policy negotiations in the next couple of years. \n                   Science\u2019s status shifts in new Brexit government 2016-Jul-14 \n                 \n                   Germany\u2019s renewable revolution awaits energy forecast 2016-Jul-13 \n                 \n                   Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                 \n                   Polish scientists protest over plan to log in Bia\u0142owie\u017ca Forest 2016-Feb-24 \n                 \n                   Policy: Climate advisers must maintain integrity 2015-May-06 \n                 \n                   Economics: Support low-carbon investment 2015-Mar-04 \n                 \n                   Nature Special: Brexit and Science \n                 \n                   EU 2030 energy strategy \n                 \n                   EU environmemt website \n                 \n                   Institute for European Environmental Policy \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20333", "url": "https://www.nature.com/articles/nature.2016.20333", "year": 2016, "authors": [{"name": "Ken Croswell"}], "parsed_as_year": "2006_or_before", "body": "An almost invisible galaxy weighs as much as our own. It took 33.5 hours on one of the world\u2019s largest telescopes, but for the first time astronomers have measured the motion of stars inside a newly recognized breed of dimly lit\u00a0galaxy.\u00a0The stars\u2019 rapid\u00a0speed\u00a0reveals that the galaxy weighs as much as the far more brilliant  Milky Way 1 . \u201cIt\u2019s an important measurement,\u201d says Avi Loeb, chair of the astronomy department at Harvard University in Cambridge, Massachusetts, who was not involved in the study. \u201cIt\u2019s a very challenging measurement, and they should be saluted for getting it.\u201d \u2018Ultradiffuse\u2019 galaxies came to attention only last year, after Pieter van Dokkum of Yale University in New Haven, Connecticut, and Roberto Abraham of the University of Toronto in Canada built an array of sensitive telephoto lenses named Dragonfly. The astronomers and their colleagues observed the Coma galaxy cluster 101 megaparsecs (330 million light years) away and detected 47 faint smudges 2 . \u201cThey can\u2019t be real,\u201d van Dokkum recalls thinking when he first saw the galaxies on his laptop computer. But their distribution in space matched that of the cluster\u2019s other galaxies, indicating that they were true members. Since then, hundreds more of these galaxies have turned up in the Coma cluster and elsewhere. Ultradiffuse galaxies are large like the Milky Way \u2014 which is much bigger than most \u2014 but they glow as dimly as mere dwarf galaxies. It\u2019s as though a city as big as London emitted as little light as Kalamazoo, Michigan. \n             Speedy ghosts \n           To study these celestial phantoms further, van Dokkum\u2019s team observed one of the largest and brightest of them, a galaxy named Dragonfly 44 in the Coma cluster. The galaxy emits 1% of the light emitted by the Milky Way. Using the 10-metre Keck II telescope atop Mauna Kea in Hawaii, the observers measured the width of a spectral line to deduce the galaxy\u2019s mass. The more massive a galaxy is, the faster its stars move relative to one another. These motions broaden the spectral line through Doppler shifts, or the change in the wavelength of light given off by an object depending on its motion relative to an observer. By combining six nights of data, the astronomers found that the stars\u2019 typical movements relative to one another clocked in at 47 kilometres per second. This number indicates a massive galaxy, roughly the same weight as the Milky Way. If the distribution of the galaxy\u2019s mass continues beyond its visible boundaries in the same way that it does in our own, Dragonfly 44 is about a trillion times more massive than the Sun. Furthermore, the galaxy possesses about 90 globular star clusters, 10 times more than a typical low-mass galaxy as dim as this one. This again argues that Dragonfly 44 is massive. Galaxies this massive are usually the most efficient at converting their gas into stars. Yet Dragonfly 44 is a mere blip in terms of brilliance, what the researchers call a \u2018failed galaxy\u2019. \u201cIt\u2019s sort of a dark version of the Milky Way,\u201d van Dokkum says. \u201cFor every 100 stars the galaxy should have formed, it only formed one.\u201d Ideas abound as to why ultradiffuse galaxies such as Dragonfly 44 failed to live up to their potential. Perhaps a quasar at the galaxy\u2019s centre blasted gas away, or maybe hot gas in the Coma cluster stripped away the galaxy\u2019s gas. Loeb and Nicola Amorisco, also at Harvard, recently suggested that ultradiffuse galaxies might be low-mass galaxies that are born spinning fast, spreading their gas so thinly that they spawn few stars 3 . Loeb says that rapid rotation can also explain a massive ultradiffuse galaxy. However, the new observations indicate that Dragonfly 44 spins slowly. Still, Loeb suspects that it was born whirling rapidly and lost its spin after encountering other galaxies. But van Dokkum says that the origin of these odd galaxies is a mystery: \u201cThe true answer is we really don\u2019t know.\u201d \n                   Dead X-ray satellite reveals galaxy cluster surprise 2016-Jul-06 \n                 \n                   Missing galaxy mass found 2014-Feb-18 \n                 \n                   Galaxy formation: The new Milky Way 2012-Oct-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20339", "url": "https://www.nature.com/articles/nature.2016.20339", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Bacteria from the human body produce an antibiotic that seems to kill resistant bacteria. A new antibiotic was right under our noses \u2014 or rather, in them. Produced by a bacterium living in the human nose, the molecule kills the potentially deadly  methicillin-resistant  Staphylococcus    aureus  (MRSA) in mice and rats. Staphylococcus    aureus  resides in the noses of 1 in 3 people without causing a problem. MRSA \u2014 an  S. aureus  strain resistant to many antibiotics \u2014 is found in 2 in 100. In a small percentage of cases, the bacterium escapes to the bloodstream, causing infection. MRSA kills 11,000 people annually in the United States alone. The potential new soldier in the fight against MRSA is a molecule called lugdunin produced by the bacterium  Staphylococcus lugdunensis , report Andreas Peschel and colleagues at the University of T\u00fcbingen, Germany, on 27 July in  Nature . In a sampling of 187 hospital patients, people whose noses naturally contained  S. lugdunensis  were six times less likely to have  S. aureus  than people whose noses lacked  S. lugdunensis , Peschel's team found. This suggests that  S. lugdunensis  is able to combat the growth of the problematic bacterium. That means the antibiotic produced by the bacterium could be developed as a preventive \u2014 a nasal spray, for example \u2014 to keep  S. aureus  out of people\u2019s noses in the first place. About 9% of people naturally carry  S. lugdunensis . \n             A new hope \n           The vast majority of antibiotics are small molecules that attack bacterial enzymes, the proteins that orchestrate chemical reactions inside the cell. The researchers found that lugdunin is unusual in that it\u2019s much larger, with a mode of action involving the cellular membrane that isn\u2019t fully understood. That novel  modus operandi  could be the reason why bacterial strains of  S. aureus  were unable to evolve resistance to the antibiotic in a 30-day test tube trial. \u201cWe never found spontaneous mutants,\u201d says Peschel. John Powers, an infectious disease clinician at George Washington University in Washington DC, is hopeful that lugdunin might eventually become a useful antiobitic for human use. But he would like to see how the antibiotic works in humans, as the test tube trials Peschel's team conducted cannot predict whether  antibiotic resistance  will develop in people. The human microbiome has so far yielded only a few antibiotics, such as lactocillin, which comes from a vaginal bacterium.  Soil bacteria  are the typical source for new antibiotics. When Peschel and his team stumbled upon lugdunin, they weren\u2019t looking for a new antibiotic. They were studying  S. aureus  in its natural environment, the human nose. \u201cIf you want to keep the bacteria in check, you need to understand their lifestyle,\u201d he says. \u201cAnd to understand that, we also looked at its competitors.\u201d They screened 90 bacteria from the human nose, and found that only  S. lugdunensis  killed MRSA. When Peschel\u2019s team infected the skin of mice with  S. aureus , lugdunin ointment killed the infection both on the surface and in deeper layers of the skin.  S. lugdunensis  also reduced the amount of  S. aureus  when squirted into the noses of cotton rats ( Sigmodon hispidus ). In addition to MRSA, lugdunin killed  S. aureus  resistant to the antibiotic glycopeptide and vancomycin-resistant  Enterococcus spp . It's the first time researchers have been able to definitively connect the production of an antibiotic in a bacterium with the suppresssion of a competitor in a microbiome community, says Kim Lewis, a microbiologist at Northeastern University in Boston, Massachusetts. Lewis has co-authored a  commentary  accompanying this study. \u201cIt\u00a0was a bit surprising,\u201d he says. \u201cWe do not usually think of antibiotics as an\u00a0important tool that bacteria can use in competition in the\u00a0microbiome.\u201d Peschel says they are currently talking to companies interested in developing lugdunin as a drug for human use. \n               See also  \n               News & Views in Nature by K. Lewis and P. Strandwitz \n             \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Dramatic rise seen in antibiotic use 2015-Sep-17 \n                 \n                   Antibiotic alternatives rev up bacterial arms race 2015-May-27 \n                 \n                   Promising antibiotic discovered in microbial \u2018dark matter\u2019 2015-Jan-07 \n                 \n                   Vaccine development: Man vs MRSA 2012-Feb-01 \n                 Reprints and Permissions"},
{"file_id": "535477a", "url": "https://www.nature.com/articles/535477a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "European Research Council embarks on an unusual evaluation that could inspire others. Last month, neuroscientist Ileana Hanganu-Opatz began a risky project with a risqu\u00e9 name: Psychocell. With a grant of \u20ac2\u00a0million (US$2.2 million), she is studying whether a single type of neuron causes a miswiring in the developing brain that has been linked to psychiatric disease. But it may turn out that no \u2018psychocell\u2019 exists, or that her mouse models are unsuitable. Supporting such blue-skies research is the mission of  her funder, the prestigious European Research Council  (ERC), which launched in 2007  to raise the quality of European science . \u201cNo one but the ERC would have funded such a high-risk project,\u201d says Hanganu-Opatz, from the University of Hamburg, Germany. Now, the council, which sits within the European Union\u2019s Framework funding programmes and has a \u20ac1.7-billion budget this year, has embarked on an unusual exercise: to retrospectively evaluate the success of the projects it funds. By contrast, most funding agencies assume that the evaluation to select which projects they fund is sufficient. \u201cVirtually no basic research funding agency tries retrospectively to analyse its own performance and impacts,\u201d says Erik Arnold, chair of Technopolis, a European research and innovation consultancy headquartered in Brighton, UK. \u201cIt would be nice if the ERC effort would inspire others to do so.\u201d On 26 July, at the European Science Open Forum in Manchester, UK, ERC president Jean-Pierre Bourguignon announced the results of a pilot investigation of 199 completed projects, almost three-quarters of which were deemed to have resulted in a scientific breakthrough or major advance (see \u2018To science and beyond\u2019). \u201cWe push both scientists and grant-application reviewers to take a certain risk, so it is important to know that they are actually taking risks\u00a0\u2014\u00a0and that we are selecting the right projects,\u201d says Bourguignon. The ERC now plans to evaluate a selection of completed projects each year and to keep refining its methodology. Bourguignon hopes that this will help the council during discussions with politicians. \u201cWe want evidence-based arguments to show that bottom-up, curiosity driven research is valuable to society,\u201d he says. The council will have to lobby to keep its generous funding in the next Framework programme, due to begin in 2021. The pilot evaluation rated projects that were among the first to be funded by the council, mostly in 2007 and 2008. It assigned eight projects each to 25 three-person expert groups. The ERC gave the experts a bibliometric analysis of the publications from each project, but asked them to use their professional judgement to form an overall view of each one. They found that 43 had led to a scientific breakthrough, 99 had generated a major advance \u2014 and only 7 had had no appreciable scientific output. That indicates an appropriate level of risk and ambition, says Bourguignon. The evaluators also judged that almost 10% of projects had already had a large impact on the economy, policymaking or other aspects of society, and that around one-quarter were likely to do so in the future. \u201cIt\u2019s a delight to see a qualitative approach,\u201d says science-policy specialist Ben Martin at the University of Sussex in Brighton. \u201cBibliometrics are misleading in isolation\u00a0\u2014\u00a0but too often used this way.\u201d Bourguignon says that many of the evaluators, who remain anonymous, struggled with the unfamiliar task of subjectively declaring research a \u201cscientific advance\u201d. The study has limitations. Two experts in each group had served on ERC grant-awarding panels. None of the projects that they judged was included in the analysis, but the process could seem unobjective, says Arnold. Martin says the terms used to categorize the projects may be interpreted differently across disciplines. \u201cAs a social scientist, I can tell you that we don\u2019t describe our work in terms of \u2018breakthroughs\u2019.\u201d Bourguignon agrees that the small study was not optimally designed. But the ERC has since solicited independent comments on the methodology, and an ongoing evaluation of a further 250 projects has been fine-tuned to let evaluators across disciplines report consistently. In the pilot review, evaluators also stressed the ERC\u2019s impact on an individual\u2019s career, something that Hanganu-Opatz experienced at first hand. Her university gave her tenure on 18 July, and three other universities made her offers. \u201cThe visibility you get when you win an ERC grant is embarrassing,\u201d she says. See  Editorial . \n                     Agencies must show that basic research is worth the investment 2016-Jul-26 \n                   \n                     Brussels concedes to European Research Council reform 2009-Oct-22 \n                   \n                     Born to be in Brussels 2005-Jul-27 \n                   \n                     ERC homepage \n                   Reprints and Permissions"},
{"file_id": "535474a", "url": "https://www.nature.com/articles/535474a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Astrobiologists debate which chemical signatures would hint at life on other worlds. In the search for life beyond Earth, false alarms abound. Researchers have generally considered, and rejected, claims ranging from a 1970s report of life on Mars to the 1990s \u2018discovery\u2019 of fossilized space microbes in a meteorite. Now, inspired by the detection of  thousands of planets beyond the Solar System , NASA has started a fresh effort to learn how to recognize extraterrestrial life. The goal is to understand  what gases alien life might produce  \u2014 and how Earth-bound astronomers might detect such \u2018biosignatures\u2019 in  light passing through the atmospheres of planets  trillions of kilometres away (see \u2018Searching for alien life\u2019). The agency will convene a workshop this week in Seattle, Washington, with the ultimate goal of advising a NASA exoplanet group on how to avoid embarrassing errors in the future. \u201cWe have to come together and determine what good evidence of life on another planet could be,\u201d says Shawn Domagal-Goldman, one of the workshop\u2019s organizers and an astronomer at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. The exercise comes at a crucial time, as astronomers grapple with how to interpret exoplanet data from the  next generation of telescopes . Some scientists are working to understand how nature could produce archetypal biosignature gases, such as oxygen, in the absence of living organisms. Others are trying to think as expansively as possible about the types of biochemistry that could sustain life. \u201cWe could fool ourselves into thinking a lifeless planet has life \u2014 or we could be missing life because we don\u2019t really understand the context of what could be produced on another planet,\u201d says Sarah Rugheimer, an astronomer at the University of St Andrews, UK. Detecting a biosignature gas is just the first step to understanding what could be happening on an exoplanet. Each world has its own  combination of physical and chemical factors  that may or may not lead to life, says Victoria Meadows, an astronomer at the University of Washington in Seattle. \u201cPlanets are hard, and we shouldn\u2019t think they are all going to be the same or reveal their secrets very easily,\u201d she says. A planet\u2019s environment is key. Some Earth-sized planets  orbit M dwarf stars  \u2014 the most common type of star in the Galaxy \u2014 at the right distance to harbour liquid water. But Meadows\u2019 collaborators have shown 1  that photo-chemical reactions can send water into the planet\u2019s atmosphere and then break off its hydrogen, which escapes into space. What\u2019s left is a thick blanket of oxygen that might seem as if it came from living organisms, but results from a run-away greenhouse effect. There are ways to tell. The runaway greenhouse would create an atmosphere thousands of times denser than Earth\u2019s, in which O 2  molecules collide to produce O 4 . So spotting O 4  in a planet\u2019s atmosphere could be a clue that the oxygen does not, in fact, come from life, Meadows\u2019 team reported this year 2 . Another method is to draw up a list of alternative biosignature gases \u2014 things not as obvious as oxygen that might be made by organisms under certain conditions. These include dimethyl sulfide 3 , which is produced by Earthly phytoplankton, or even ammonia 4 . On a cold alien planet, organisms might make the gas using the same chemical process as industrial manufacturers. At the Massachusetts Institute of Technology in Cambridge, astronomer Sara Seager has begun to examine 14,000 compounds that are stable enough to exist in a planetary atmosphere. She and her colleagues are winnowing down their initial list of molecules using criteria such as whether there are geophysical ways to send the compound into the atmosphere 5 . \u201cWe\u2019re doing a triage process,\u201d says Seager. \u201cWe don\u2019t want to miss anything.\u201d The Seattle meeting aims to compile a working list of biosignature gases and their chemical properties. The information will feed into how astronomers analyse data from NASA\u2019s James Webb Space Telescope, slated for launch in 2018. The telescope will be able to look at only a handful of habitable planets, but it will provide the first detailed glimpse of what gases surround which world, says Nikole Lewis, an astronomer at the Space Telescope Science Institute in Baltimore, Maryland. No single gas is likely to be a slam-dunk indicator of alien life. But Domagal-Goldman hopes that the workshop will produce a framework for understanding where scientists could trip themselves up. \u201cWe don\u2019t want to have a great press release,\u201d he says, \u201cand then a week later have egg on everybody\u2019s faces.\u201d \n                     The truth about exoplanets 2016-Feb-17 \n                   \n                     Climate scientists join search for alien Earths 2015-Apr-17 \n                   \n                     Hubble successor will struggle to hunt alien life 2015-Feb-09 \n                   \n                     Seeing ourselves in the Moon's mirror 2012-Feb-29 \n                   \n                     NASA workshop \n                   \n                     Exoplanet chemical database \n                   Reprints and Permissions"},
{"file_id": "535478a", "url": "https://www.nature.com/articles/535478a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Craft that launched in August is first in a wave of planned quantum space experiments. \n               Update: China launched the world\u2019s first quantum satellite on 16 August. The Quantum Experiments at Space Scale (QUESS) satellite, which lifted off from the Jiuquan Satellite Launch Center in northern China at 1:40\u2009a.m. local time, successfully entered orbit at an altitude of 500 kilometres. \n             China is poised to launch the world\u2019s first satellite designed to do quantum experiments. A fleet of quantum-enabled craft is likely to follow. First up could be more Chinese satellites, which will together create a super-secure communications network, potentially linking people anywhere in the world. But groups from Canada, Japan, Italy and Singapore also have plans for quantum space experiments. \u201cDefinitely, I think there will be a race,\u201d says  Chaoyang Lu , a physicist at the University of Science and Technology of China in Hefei, who works with the team behind the Chinese satellite. The 600-kilogram craft, the latest in a  string of Chinese space-science\u00a0satellites , will launch from Jiuquan Satellite Launch Center in August. The Chinese Academy of Sciences and the Austrian Academy of Sciences are collaborators on the US$100-million mission. Quantum communications are secure because any tinkering with them is detectable. Two parties can communicate secretly \u2014\u00a0by sharing a encryption key encoded in the polarization of a string of photons, say \u2014\u00a0safe in the knowledge that any eavesdropping would leave its mark. So far, scientists have managed to  demonstrate quantum communication up to about 300 kilometres . Photons travelling through optical fibres and the air get scattered or absorbed, and amplifying a signal while preserving a photon\u2019s fragile quantum state is extremely difficult. The Chinese researchers hope that transmitting photons through space, where they travel more smoothly, will allow them to communicate over greater distances. At the heart of their satellite is a crystal that produces pairs of entangled photons, whose properties remain entwined however far apart they are separated. The craft\u2019s first task will be to fire the partners in these pairs to ground -stations in Beijing and Vienna, and use them to generate a secret key. During the two-year mission, the team also plans to perform a statistical measurement known as a Bell test to prove that entanglement can exist between particles separated by a distance of 1,200 kilometres. Although quantum theory predicts that entanglement persists at any distance,  a Bell test would prove it . The team will also attempt to \u2018teleport\u2019 quantum states, using an entangled pair of photons alongside information transmitted by more conventional means to reconstruct the quantum state of a photon in a new location. \u201cIf the first satellite goes well, China will definitely launch more,\u201d says Lu. About 20 satellites would be required to enable secure communications throughout the world, he adds. The teams from outside China are taking a different tack. A collaboration between the National University of Singapore (NUS) and the University of Strathclyde, UK, is using cheap  5-kilogram satellites known as cubesats  to do quantum experiments. Last year, the team launched a cubesat that created and measured pairs of \u2018correlated\u2019 photons in orbit; next year, it hopes to launch a device that produces fully entangled pairs. Costing just $100,000 each, cubesats make space-based quantum communications accessible, says NUS physicist Alexander Ling, who is leading the project. A Canadian team proposes to generate pairs of entangled photons on the ground, and then fire some of them to a microsatellite that weighs less than 30 kilograms. This would be cheaper than generating the photons in space, says Brendon Higgins, a physicist at the University of Waterloo, who is part of the Canadian Quantum Encryption and Science Satellite (QEYSSat) team. But delivering the photons to the moving satellite would be a challenge. The team plans to test the system using a photon receiver on an aeroplane first. An even simpler approach to quantum space science, pioneered by a team at the University of Padua in Italy led by Paolo Villoresi, involves adding reflectors and other simple equipment to regular satellites. Last year, the team showed that photons bounced back to Earth off an existing satellite maintained their quantum states and were received with low enough error rates for quantum cryptography ( G. Vallone  et\u00a0al.   Phys. Rev. Lett.   115,  040502; 2015 ). In principle, the researchers say, the method could be used to generate secret keys, albeit at a slower rate than in more-complex set-ups. Researchers have also proposed a quantum experiment aboard the International Space Station (ISS) that would simultaneously entangle the states of two separate properties of a photon \u2014 a technique known as hyperentanglement \u2014 to make teleportation more reliable and efficient. As well as making communications much more secure, these satellite systems would mark a major step towards a \u2018quantum internet\u2019 made up of quantum computers around the world, or a quantum computing cloud, says Paul Kwiat, a physicist at the University of Illinois at Urbana\u2013Champaign who is working with NASA on the ISS project. The quantum internet is likely to involve a combination of satellite- and ground-based links, says Anton Zeilinger, a physicist at the Austrian Academy of Sciences in Vienna, who argued unsuccessfully for a European quantum satellite before joining forces with the Chinese team. And some challenges remain. Physicists will, for instance, need to find ways for satellites to communicate with each other directly; to perfect the art of entangling photons that come from different sources; and to boost the rate of data transmission using single photons from megabits to gigabits per second. If the Chinese team is successful, other groups should find it easier to get funding for quantum satellites, says Zeilinger. The United States has a relatively low profile when it comes to this particular space race, but Zeilinger suggests that it could be doing more work on the topic that is classified. Eventually, quantum teleportation in space could even allow researchers to combine photons from satellites to make a distributed telescope with an effective aperture the size of Earth \u2014 and enormous resolution. \u201cYou could not just see planets,\u201d says Kwiat, \u201cbut in principle read licence plates on Jupiter\u2019s moons.\u201d \n                     China\u2019s quantum space pioneer: We need to explore the unknown 2016-Jan-13 \n                   \n                     China\u2019s dark-matter satellite launches era of space science 2015-Dec-17 \n                   \n                     Quantum \u2018spookiness\u2019 passes toughest test yet 2015-Aug-27 \n                   \n                     Quantum communications leap out of the lab 2014-Apr-23 \n                   \n                     Data teleportation: The quantum space race 2012-Dec-05 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20334", "url": "https://www.nature.com/articles/nature.2016.20334", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "A volatile arrangement of tectonic plates millions of years ago gave us the Pacific. The Pacific Ocean was born from a geological spasm starting 190 million years ago, when Earth\u2019s crust ripped apart and fresh lava welled up from below. Now, new work offers up the details on this seafloor birth, and it\u2019s a lot more complex than researchers had thought. The study is a rare step forward in understanding the origin of the Pacific, one of geology\u2019s most enduring mysteries. \u201cThis is one big piece of the puzzle that we\u2019ve now put into place,\u201d says Lydian Boschman, a geologist at Utrecht University in the Netherlands. She and her colleague Douwe van Hinsbergen report the discovery on 27 July in  Science Advances 1 . Oceans are born at unstable seams in Earth\u2019s crust, where plates pull apart, allowing molten rock to fill the gap and solidify. The fresh crust pushes older crust away from the seam and towards the edge of a continent. Eventually, the ocean crust crashes into continental crust and, through the process of plate tectonics, gets sucked down and recycled deep within the planet. Because of this continuing cycle of creation and destruction, no seafloor dates back more than about 200 million years. To see how oceans behaved further back in time, geologists have to try to reconstruct the three-dimensional geometry of long-vanished crustal plates. \n             Mind the gap \n           Boschman and van Hinsbergen studied the oldest part of the Pacific plate, which lies just east of the Mariana Trench. Previous work suggested that the Pacific was born in what\u2019s known as a geological triple junction, with fresh seafloor spreading outward from each of three intersecting ridges. But that plate geometry is geologically stable; in the south Atlantic Ocean, a similar triple junction has endured for more than 100 million years without forming a new plate. \u201cThere\u2019s no reason to,\u201d says Boschman. Instead, she says, the Pacific must have been born at an unstable type of triple junction. The three intersecting seams would have had to have been transform faults, in which the two sides of a fault slide past one another. California\u2019s San Andreas fault moves in this fashion. Three transform faults coming together would have resulted in a triangular gap opening in the centre. \u201cA triple junction with ridges is not going to make a new plate,\u201d says Boschman. But \u201ca triple junction with transform faults does\u201d. The configuration was probably an accident, she adds. The work shows how basic thinking about plate tectonics can still yield surprises, says Bernhard Steinberger, a geophysicist at the GFZ German Research Centre for Geosciences in Potsdam, Germany. \u201cThis is one of those rare cases where a discovery could be made simply by an elegant thought,\u201d he says. Boschman would like to push even further back in time, to unravel the history of the ocean that preceded the Pacific and surrounded the supercontinent Pangaea. She is currently doing fieldwork in Costa Rica, looking for evidence of ancient seafloor rocks scraped up on the side of the continent as the ocean crust was dragged under and destroyed. \n                   Earth science: How plate tectonics clicked 2013-Sep-04 \n                 \n                   How the West was built 2013-Apr-03 \n                 \n                   Supercontinent Amasia to take North Pole position 2012-Feb-08 \n                 \n                   Speedy continental collision explained 2007-Oct-17 \n                 \n                   Lydian Boschman \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20342", "url": "https://www.nature.com/articles/nature.2016.20342", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Conference on Shinichi Mochizuki\u2019s work inspires cautious optimism. Nearly four years after Shinichi Mochizuki unveiled an imposing set of papers that  could revolutionize the theory of numbers , other mathematicians have yet to understand his work or agree on its validity \u2014 although they have made modest progress. Some four dozen mathematicians converged last week for a rare opportunity to hear Mochizuki present his own work at a conference on his home turf, Kyoto University's Research Institute for Mathematical Sciences (RIMS). Mochizuki is \u201cless isolated than he was before the process got started\u201d, says Kiran Kedlaya, a number theorist at the University of California, San Diego. Although at first Mochizuki's papers, which stretch over more than 500 pages 1 , 2 , 3 , 4 , seemed like an impenetrable jungle of formulae, experts have slowly discerned a strategy in the proof that the papers describe, and have been able to zero in on particular passages that seem crucial, he says. And Jeffrey Lagarias, a number theorist at the University of Michigan in Ann Arbor, says that he got far enough to see that Mochizuki\u2019s work is worth the effort. \"It has some revolutionary new ideas,\u201d he says. Still, Kedlaya says that the more he delves into the proof, the longer he thinks it will take to reach a consensus on whether it is correct. He used to think that the issue would be resolved perhaps by 2017. \u201cNow I'm thinking at least three years from now.\u201d Others are even less optimistic. \u201cThe constructions are generally clear, and many of the arguments could be followed to some extent, but the overarching strategy remains totally elusive for me,\u201d says mathematician Vesselin Dimitrov of Yale University in New Haven, Connecticut. \u201cAdd to this the heavy, unprecedentedly indigestible notation: these papers are unlike anything that has ever appeared in the mathematical literature.\u201d \n               The  \n               abc \n                proof \n             Mochizuki\u2019s theorem aims to prove the important  abc  conjecture, which dates back to 1985 and relates to prime numbers \u2014 whole numbers that cannot be evenly divided by any smaller number except by 1.  The conjecture  comes in a number of different forms, but explains how the primes that divide two numbers,  a  and  b , are related to those that divide their sum,  c . If Mochizuki\u2019s proof is correct, it would have repercussions across the entire field, says Dimitrov. \u201cWhen you work in number theory, you cannot ignore the  abc  conjecture,\u201d he says. \u201cThis is why all number theorists eagerly wanted to know about Mochizuki's approach.\u201d For example, Dimitrov showed in January 5  how, assuming the correctness of Mochizuki\u2019s proof, one might be able to derive many other important results, including a completely independent proof of the celebrated  Fermat\u2019s last theorem . But the purported proof, which Mochizuki  first posted on his webpage in August 2012 , builds on more than a decade of previous work in which Mochizuki worked in virtual isolation and developed a novel and extremely abstract branch of mathematics. \n               Mochizuki in the room \n             The Kyoto workshop followed on the heels of one held last December in Oxford, UK.  Mochizuki did not attend that first meeting , although he answered the audience\u2019s questions over a Skype video link. This time, having him in the room \u2014 and hearing him present some of the materials himself \u2014 was helpful, says Taylor Dupuy, a mathematician at the Hebrew University of Jerusalem who participated in both workshops. There are now around ten mathematicians who are putting substantial effort into digesting the material \u2014 up from just three before the Oxford workshop, says Ivan Fesenko, a mathematician at the University of Nottingham, UK, who co-organized both workshops. The group includes younger researchers, such as Dupuy. In keeping with his reputation for being a very private person, Mochizuki \u2014 who is said to never eat meals in the presence of colleagues \u2014 did not take part in the customary mingling and social activities at the Kyoto meeting, according to several sources. And although he was unfailingly forthcoming in answering questions, it was unclear what he thought of the proceedings. \u201cMochizuki does not give a lot away,\u201d Kedlaya says. \u201cHe\u2019s an excellent poker player.\u201d Fellow mathematicians have criticized Mochizuki for his refusal to travel. After he posted his papers, he turned down multiple offers to spend time abroad and lecture on his ideas. Although he spent much of his youth in the United States, he is now said to rarely leave the Kyoto area. (Mochizuki does not respond to requests for interviews, and the workshop\u2019s website contained the notice: \u201cActivities aimed at interviewing or media coverage of any sort within the facilities of RIMS, Kyoto University, will not be accepted.\u201d) \u201cHe is very level-headed,\u201d says another workshop participant, who did not want to be named. \u201cThe only thing that frustrates him is people making rash judgemental comments without understanding any details.\u201d Still, Dupuy says, \u201cI think he does take a lot of the criticism about him really personally. I\u2019m sure he\u2019s sick of this whole thing, too.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Fermat's last theorem earns Andrew Wiles the Abel Prize 2016-Mar-15 \n                   \n                     Biggest mystery in mathematics in limbo after cryptic meeting 2015-Dec-16 \n                   \n                     The biggest mystery in mathematics: Shinichi Mochizuki and the impenetrable proof 2015-Oct-07 \n                   \n                     Proof claimed for deep connection between primes 2012-Sep-10 \n                   \n                     Oxford Workshop \n                   \n                     RIMS Workshop \n                   \n                     Shinichi Mochizuki \n                   \n                     Kiran Kedlaya \n                   \n                     Dimitrov Vesselin \n                   \n                     Taylor Dupuy \n                   \n                     Ivan Fesenko \n                   \n                     Jeffrey Lagarias \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20230", "url": "https://www.nature.com/articles/nature.2016.20230", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Changes in cloud patterns match predictions from climate simulations of a warming world. Clouds are moving up, up and away. An analysis of satellite data has found that, since the early 1980s, clouds have shifted towards Earth\u2019s poles and cloud tops have extended higher into the atmosphere. The changes match what climate models predict and are a rare step forward among  much scientific uncertainty about how clouds will behave in a warming world \u201cIt\u2019s really the first credible evidence that we have of climate change and clouds in the observed record,\u201d says Joel Norris, an atmospheric scientist at the Scripps Institution of Oceanography in La Jolla, California. Norris and his colleagues describe the work on 11 July in  Nature 1 . Clouds are both hard to observe and difficult to simulate in climate models, says Katherine Marvel, a climate researcher at NASA\u2019s Goddard Institute for Space Studies in New York City. This is because researchers have to cobble together data on cloud patterns from existing satellite observations. These are designed to collect information on short-term weather trends, not the long-term behaviour needed for climate models. \n             A workaround \n           Norris\u2019s team tried to get around this issue by purging satellite data of misleading readings, such as those produced by sensors that have degraded over time. The scientists used two  long-term databases of cloud cover , along with measures of water content over the oceans and of Earth\u2019s reflectivity \u2014 or how much sunlight the planet's surface throws back into space.\u00a0 By 2009, the team found that there were fewer clouds over the mid-latitudes than there had been in 1983. That finding meshes with climate predictions that  dry zones will expand out of the subtropics  and push storms towards the poles. The team also found that cloud tops rose higher in the atmosphere by the end of the 2000s, again as predicted for a warming atmosphere. Norris and his colleagues \u201chave done a great job using the satellite record in an appropriate way\u201d, says Ryan Eastman, an atmospheric scientist at the University of Washington in Seattle. In 2013, he and a colleague used ground-based observations of clouds to describe some of the same trends. Their study also noted that clouds were declining in middle latitudes as storms shifted poleward 2 . The new work meshes well with the earlier findings, Eastman says. The fact that observations match the model predictions is worrying, says Veerabhadran Ramanathan, an atmospheric scientist at the Scripps Institution of Oceanography who was not on the team. If models really are starting to get clouds correct, it suggests that the planet may warm on the higher end of estimates over the coming century, he says. Still, the story remains complicated. The cloud shifts match what scientists would expect from increasing greenhouse-gas emissions, but also what happens in the aftermath of large volcanic eruptions that spew particles into the atmosphere. Researchers need to dig a little more to tease out the relative roles of greenhouse gases and volcanoes, Marvel says. Norris aims to do that next. \u201cThe data aren\u2019t hopeless,\u201d he says. \u201cThere\u2019s more here than we thought.\u201d \n                   Cloud-seeding surprise could improve climate predictions 2016-May-25 \n                 \n                   The mystery of the expanding tropics 2016-Feb-02 \n                 \n                   Antarctic clouds studied for first time in five decades 2016-Jan-05 \n                 \n                   Climatologists to physicists: your planet needs you 2015-Apr-07 \n                 \n                   Climate forecasting: Build high-resolution global climate models 2014-Nov-19 \n                 \n                   Climate forecasting: A break in the clouds 2012-May-09 \n                 \n                   International Satellite Cloud Climatology Project \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20242", "url": "https://www.nature.com/articles/nature.2016.20242", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "The effort will use next-generation cell-culture methods and fresh patient samples.\u00a0 An international collaboration of cancer-research heavy-weights aims to grow 1,000 new cell lines for scientists to study \u2014 and that could be just the beginning. The Human Cancer Models Initiative announced its pilot project on 11 July, and intends to complete the initial 1,000 models within 3 years. Members of the initiative include the US National Cancer Institute (NCI) in Bethesda, Maryland; Cancer Research UK in London; the Wellcome Trust Sanger Institute in Hinxton, UK; and Hubrecht Organoid Technology of Utrecht in the Netherlands. The initial goal of 1,000 cell lines would roughly double the world\u2019s collection of accessible cancer cell models, says Louis Staudt, head of the NCI\u2019s Center for Cancer Genomics. But if all goes well during the pilot, the project will generate thousands more. Staudt estimates that researchers need about 10,000 models to fully capture the diversity of relatively common genetic subtypes of cancer. \u201cWhether we actually will push into that depends a lot upon how easy and valuable the cell lines are from the pilot,\u201d he says. \n             Reflections of reality \n           The initiative\u2019s models will offer several improvements over most available cell lines. Each line will be matched with clinical data about the donor patient, and how they responded to treatment. The project will also use cutting-edge techniques to generate its models, which will include  3D cultures called organoids , and cells that have been reprogrammed to grow indefinitely in culture. The hope is that these features will better reflect human cancers, enabling the cells to be used to model disease, screen for new drugs and determine which treatments are suited for which cancers. Umber Cheema, a tissue engineer at University College London, says that the initiative is an exciting opportunity to unite protocols and expertise from different research groups. \u201cIt\u2019s been a little bit disjointed, in terms of different people in different countries working on their specific models,\u201d she says. \u201cWe have so much we can share with each other.\u201d The pilot project will give members of the initiative a chance to work out the kinks in their protocols, searching for ways to make their pipelines cheaper and more efficient, says Mathew Garnett, a cancer researcher at the Sanger Institute. A key stumbling block can be establishing a network of clinics able to collect samples \u2014 and consent forms \u2014 and rush them to research labs to generate the models.  At the NCI, the Human Cancer Models Initiative will be paired with another effort to create a large collection of  human cancer cells that have been grown in mice . Cell lines generated from that project will be fed into the cancer-models initiative, says Staudt. The NCI is also interested in exploring other methods of deriving cell models \u2014 a hot field in cancer research. Staudt notes that groups are working to find optimal conditions for difficult-to-grow cancer cells, such as lymphoma. Others are trying to refine current models so that they better reflect a tumour\u2019s natural environment. Cheema\u2019s group, for example, grows cells in 3D cultures that reproduce some aspects of a tumour's environment, and even contain a rudimentary vascular system. Her team hopes to refine the technique so that it can be used to determine whether an individual\u2019s cancer cells is likely to be metastatic, or to respond to a given therapy. \u201cThere are people out there with their own special sauce,\u201d says Staudt. \u201cWe are open to all of these opportunities.\u201d \n                   US cancer institute to overhaul tumour cell lines 2016-Feb-17 \n                 \n                   Obama proposes cancer \u201cmoonshot\u201d in State of the Union address 2016-Jan-13 \n                 \n                   Nature special: Cancer Genomics \n                 \n                   US National Cancer Institute: Precision Medicine Initiative \n                 Reprints and Permissions"},
{"file_id": "535209a", "url": "https://www.nature.com/articles/535209a", "year": 2016, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Allen Brain Observatory releases unprecedented survey of activity in the mouse visual cortex. Inspired by the large-scale sky surveys with which astronomers explore the cosmos, neuroscientists in Seattle, Washington, have spent four years systematically surveying the neural activity of the mouse visual cortex. The Allen Brain Observatory\u2019s first data release, on 13 July, provides a publicly accessible data set of unprecedented size and scope, designed to help scientists to model and understand the human brain. The project is part of an ambitious ten-year brain-research plan announced in 2012 by the Allen Institute for Brain Science. Designed to catalogue neurons and their electrical characteristics in minute detail, the initiative aims to enable new insights into how perception and cognition arise. To compile the brain observatory\u2019s first data set, researchers used a specialized microscope to record calcium waves that occur when neurons fire, sampling activity in 25\u00a0mice over 360\u00a0experimental sessions, while the animals viewed a battery of visual stimuli such as moving patterns of lines, images of natural scenes and short movies. The data set so far includes 18,000\u00a0cells in 4 areas of the visual cortex, making it one of the largest and most comprehensive of its kind. The set also includes information about each neuron\u2019s location and its expression of certain genetic markers. At 30\u00a0terabytes, the raw data are too large to share easily, but users can download a more manageable processed data set, or explore it online. \u201cIt\u2019s amazing,\u201d says Anne Churchland, a neuro\u00adscientist at Cold Spring Harbor Laboratory in New York. \u201cThere\u2019s no other effort I know of where people have looked at so many brain areas with so many stimuli \u2014 and importantly, where the data are freely available as well.\u201d Other labs have  collected similar data , but on a  much smaller scale , with fewer animals or fewer neurons. This information has been difficult to merge and compare, as a result of differences in the species, techniques or brain regions examined. And most data remain in the hands of individual labs. To create the unusually extensive Allen data set, more than 100\u00a0researchers developed and used standardized equipment and protocols for every stage of the experiment. This allowed them to repeatedly and systematically sample the same populations of neurons across many animals and sessions. Now, Allen Institute researchers plan to monitor activity while the mice carry out behavioural tasks. The scientists also want to use more recording techniques, and to extend their sampling across the entire mouse visual cortex and beyond. Christof Koch, president of the Allen Institute, hopes that over the next 3\u20134\u00a0years, the project will evolve into a true observatory, with researchers able to request certain experiments \u2014 the results of which will be made publicly available. The project\u2019s neural-activity map could help to fill out a picture of what cell types live in the brain and how they work together. Ultimately, the Allen Institute wants its own researchers and others to be able to use the massive data set to help to uncover the fundamental computational principles that underlie cognition. This lofty goal is shared by the US government\u2019s Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative, which was  launched in 2013  with the Allen Institute among its private partners. But whereas the BRAIN Initiative has largely supported individuals and small groups of investigators with conventional grants, the Allen Institute has concentrated personnel and money on a small number of large projects. It aims to create public research tools that would be unfeasible for individual labs to produce. Armed with a sweeping survey of neural activity, Koch says, theoreticians will be able to design more accurate models of brain function, and find better ways to test the validity of existing models. But he is also realistic about the challenges ahead. \u201cWe\u2019re under no illusions that now we have all this data that the solution will jump out at us,\u201d says Koch. The Allen Brain Observatory\u2019s impact will depend in part on whether the neuroscience field embraces this experiment in communal research. Early reactions suggest that researchers are eager to participate. Churchland says that the in-depth information about how different visual areas respond to stimuli could help to guide and fine-tune her experiments. The data could also help labs that lack access to highly specialized imaging equipment, she adds. Theoreticians, too, are looking forward to delving into the data. \u201cThis is basically a bonanza,\u201d says computational neuroscientist Steven Zucker at Yale University in New Haven, Connecticut. \u201cIt\u2019s as if somebody opened the door into the world\u2019s biggest neuroscience lab for theoreticians around the world and said, \u2018Come on in and play with our data.\u2019\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Crumb of mouse brain reconstructed in full detail 2015-Jul-30 \n                   \n                     Injectable brain implant spies on individual neurons 2015-Jun-08 \n                   \n                     Neuron encyclopaedia fires up to reveal brain secrets 2015-Mar-31 \n                   \n                     Ambitious plans for BRAIN project unveiled 2014-Jun-06 \n                   \n                     Neurotechnology: BRAIN storm 2013-Nov-06 \n                   \n                     Whole human brain mapped in 3D 2013-Jun-20 \n                   \n                     Allen Brain Observatory \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20255", "url": "https://www.nature.com/articles/nature.2016.20255", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Thomson Reuters divests intellectual-property and science division in US$3.55-billion deal. The vast science-citation database \u2018Web of Science\u2019 will be sold by its long-time owner, Thomson Reuters, as part of a US$3.55-billion divestment of the firm\u2019s intellectual-property and science division. The deal, according to an  announcement on 11 July , will transfer the division to private equity funds affiliated with Onex Corporation, based in Toronto, and Baring Private Equity Asia, headquartered in Hong Kong. But industry observers expect that the new owners will later break up the division and resell its parts for a profit. Thomson Reuters, a multinational news and information company, had long been expected to part with the division,  which employs  some 3,200 people , to focus on its core businesses of financial, trade and regulatory information. \u201cPrivate-equity groups only buy something when they have an idea of how they will resell it later,\u201d says Joseph Esposito, who heads Processed Media, an academic and professional publishing consultancy in New York City, and who is a former chief executive of the  Encyclopaedia Britannica . Esposito speculates that the equity funds have calculated that the expansion of science and innovation in Asia makes the businesses ripe for growth, and so for reselling \u2014 in particular, Thomson Reuters\u2019s patent databases, such as the Derwent World Patents Index. \u201cWe should not be surprised to find that some pieces of the new acquisition get spun off,\u201d he says. Any future owner of the division\u2019s science-metrics products, which include the subscription-based platforms Web of Science and Journal Citation Reports, is unlikely to change them much or to innovate, as these services are already mature and profitable stand-alone products, predicts Esposito: \u201cThey are cash cows.\u201d The sale, which is subject to approval by regulatory authorities, has also sparked speculation over who might eventually end up buying the products from their private-equity owners. David Worlock, an independent UK-based publishing consultant,  speculates  that  Nature \u2019s parent company, Springer Nature, might be one potential suitor. The company says that it has no comment to make. Yvonne Nobis , head of science-information services at the the Betty & Gordon Moore Library at the University of Cambridge, UK, suggests a more radical option. \u201cShould the academic community buy @webofscience ? We need metrics to be publisher neutral,\u201d she  tweeted . \n                   Nature owner merges with publishing giant 2015-Jan-15 \n                 \n                   Metrics: A profusion of measures 2010-Jun-16 \n                 \n                   Beat it, impact factor! Publishing elite turns against controversial metric \n                 \n                   Thomson Reuters press release \n                 Reprints and Permissions"},
{"file_id": "535208a", "url": "https://www.nature.com/articles/535208a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The US government is considering a plan to allow wireless firms to share radio frequencies used in weather forecasts. As Hurricane Patricia barrelled down on\u00a0Mexico last October, forecasters at the US National Oceanic and Atmospheric Administration (NOAA) grabbed as\u00a0many \u00adsatellite images as they could to track\u00a0its progress. But at least one crucial shot\u00a0failed to download. A 22\u00a0October image\u00a0from the\u00a0\u00adGeostationary Operational Environ\u00admental Satellite (GOES) system showed a black\u00a0swathe\u00a0\u2014 no data \u2014 across most of the Pacific Ocean. \u201cYou couldn\u2019t even see the hurricane,\u201d says Al Wissman, chief of data management and continuity operations for NOAA\u2019s satellite and information service in Silver Spring, Maryland. \u201cThat\u2019s how devastated the imagery was.\u201d The culprit was radio interference from mobile-phone companies. And the problem may soon get worse. The US Federal Communications Commission (FCC) is considering whether to allow a satellite-communications company to share a crucial, additional set of frequencies that NOAA uses for time-critical weather transmissions. If the application is granted, Ligado \u00adNetworks of Reston, Virginia, will begin transmitting at frequencies between 1,675 and 1,680 megahertz. That overlaps with the \u00adcommunications range of NOAA\u2019s next generation of GOES satellites, starting with the game-changing GOES-R probe that is set to launch in November. The satellite will transmit in three times the number of channels as do current satellites, providing images with four times the current resolution, and it will scan for weather events five times faster. Last month, emergency managers, pilots, private weather forecasters and other groups flooded the FCC with letters arguing against\u00a0the change. Researchers will discuss the \u00adproposal at a meeting of the American \u00adMeteorological Society (AMS) in Tuscaloosa, Alabama, on 21 July. Wireless broadband has been a boon for meteorologists, who can now send crucial tornado, hurricane and other alerts directly to people\u2019s smartphones. \u201cBut it can\u2019t come at the risk of interrupting important weather communications that are used in order to be able to deliver the most accurate and reliable forecast,\u201d says Jonathan Porter, vice-president of innovation and development at the private forecasting company AccuWeather in State College, Pennsylvania. Porter also chairs an AMS committee on spectrum allocation. In general, the US government sets aside swathes of radio frequencies for purposes that protect safety and national security, such\u00a0as weather forecasting. But in 2010, President Barack Obama told the various agencies that\u00a0regulate spectrum-sharing to free up 500\u2009MHz for wireless broadband use by 2020. In \u00adNovember 2012, a company that later evolved into Ligado filed a request to share the 1,675\u20131,680-MHz band. Commercial mobile-phone companies are already transmitting at slightly lower frequencies, the 1,670\u20131,675-MHz band \u2014 a situation that has caused problems with NOAA data. In a representative sample of GOES imagery taken between May and September 2015, the\u00a0agency found that 3.6% of the data \u00adduring that stream had been subject to interference. And in May of this year, NOAA clocked 30 events in which satellite transmissions had dropped out, either streaking or nearly obliterating the images. \u201cWe consider that to be unacceptable,\u201d Wissman says. In response, NOAA has begun to shift the transmission frequencies for the radiosonde balloons it launches to obtain vertical profiles of the atmosphere. It also redesigned an aspect of its GOES-R transmissions to be centred on 1,686.6\u2009MHz, in the hope that this would be high enough to escape the interference. But that change affects only how GOES-R relays its own imagery to Earth. GOES-R has a second job as a sort of internet in the sky, relaying data from 27,000 ground stations including stream gauges, tsunami buoys and seismic stations (see \u2018Weather watchers\u2019). If Ligado\u2019s application is granted, that \u2018rebroadcast\u2019 service is likely to be interrupted \u2014 affecting forecasts of phenomena such as the spread of smoke during wildfires or the disruption of plane flights by volcanic ash. \u201cIt\u2019s just an untenable situation to have in a critical situation,\u201d says William Mahoney, an atmospheric scientist at the National Center for Atmospheric Research in Boulder, Colorado, and head of the AMS commission on the weather, water and climate enterprise. One of GOES-R\u2019s big advantages is that it\u00a0will send updated data as often as every 30 seconds. That\u2019s much more frequent than the 10\u201330-minute refresh time of the current GOES series, so any disruption to the real-time data flow will be much worse, Porter says. Ligado has proposed ways to address the concerns, such as establishing blackout zones around NOAA\u2019s receiving stations or creating a cloud-based computing network to handle data distribution for non-NOAA users. But many of those who have commented publicly are sceptical about such plans. The World Meteorological Organization pointed out that cloud computing is vulnerable when\u00a0weather data are most needed: during severe storms. The FCC is accepting replies to the original set of public comments until 21 July. After that, it will grind slowly towards a decision. In Tuscaloosa next week, meteorologists will sit down for a public discussion with representatives from Ligado about the best way forward. Porter, who will chair the panel, hopes that the government will proceed slowly \u2014 perhaps by delaying the bandwidth-sharing or at least phasing it in slowly and documenting any interference. \u201cThis is not just, \u2018Oh, a few weather forecasts\u2019,\u201d says Renee Leduc Clarke, a consultant with Narayan Strategy in Washington DC who has been working with clients on the \u00adspectrum-sharing issue. \u201cThis is equal to lives\u00a0and property inside our economy \u2014 the\u00a0same economy we\u2019re trying to boost with wireless broadband.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Earth observation enters next phase 2014-Apr-08 \n                   \n                     Climate researchers warn of data crisis 2011-Oct-28 \n                   \n                     Earth Monitoring: The planetary panopticon 2007-Dec-05 \n                   \n                     Federal Communications Commission call for public comments (PDF) \n                   \n                     American Meteorological Society ad hoc committee on radio frequency allocations \n                   \n                     GOES-R \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20257", "url": "https://www.nature.com/articles/nature.2016.20257", "year": 2016, "authors": [{"name": "Barbara Casassus"}], "parsed_as_year": "2006_or_before", "body": "Critics say Philippe Mauguin lacks research experience. Paris Philippe Mauguin, an agronomic engineer and chief of staff to France\u2019s agriculture minister, is poised to become president and chief executive of the French  National Institute for Agricultural Research  (INRA). Two committees in France\u2019s parliament approved Mauguin's nomination on 13 July, enraging scientists who say that he lacks research experience. French President Fran\u00e7ois Hollande said on 4 July that he intended to nominate Mauguin, prompting an online petition and a flurry of protests by INRA staff and associated researchers. But their efforts to thwart the appointment failed. The cabinet is expected to rubber-stamp the decision on 20 July. Mauguin will replace current INRA president and chief executive Fran\u00e7ois Houllier, who had applied to stay on for a second 4-year term. The new agency head should take up his post on 26 July.                  Major French research agencies have always been headed by leading scientists, says Bernard Meunier, president of the French Academy of Sciences, speaking in a personal capacity. Mauguin is a civil servant, and \u201cdoes not have researchers\u2019 confidence\u201d, he adds. In Mauguin\u2019s first public comments since the row began, he denounced the \u201csmear campaign\u201d but said that there would be no witch-hunt of his opponents at INRA. Mauguin denied claims that his nomination was politically motivated or that he had had access to his rival\u2019s application. His first priority would be to quell the anger sparked by his nomination, he added. But INRA researchers worry that the controversy has tarnished the agency\u2019s image internationally. In his presentation to the parliamentary committees before their vote on his nomination, Mauguin echoed the agency\u2019s current strategy, says one INRA researcher, who declined to be identified for fear of retaliation. \u201cWe learned nothing new, and are more convinced than ever that M. Mauguin does not have a programme of his own,\u201d the researcher adds.\u00a0 \n             Up in arms \n           The controversy has already taken a toll. After six years as president of INRA\u2019s Scientific Advisory Board and a member of the board of directors, Fr\u00e9d\u00e9ric Dardel quit on 6 July in protest over Mauguin's nomination. He said in his letter of resignation that the decision \u201cwas heart-breaking\u201d, and that the agency should be run \u201cby a recognized scientific personality\u201d with a PhD. Opposition parliamentary members from both houses, as well as the researcher-led campaign group Sciences en Marche (Science in Motion) called for a suspension of Mauguin\u2019s nomination. In a letter to the Senate, Sciences en Marche mentioned concerns that the agriculture ministry has little interest in basic research, and would have undue influence at INRA, even though the  higher education and research ministry  provides most of the institute\u2019s funding. The letter also expressed worries that Mauguin would focus on research themes popular with the electorate in the run-up to next year\u2019s presidential election, and that he could be dismissed from his post if the ruling socialist party loses. An  online petition  against the nomination, started on 4 July by several INRA scientists, has nearly 3,000 signatures, including most of the institute\u2019s researchers. It was accompanied by a letter to Hollande, the government and parliament on Sunday, alleging that the nomination procedure showed \u201copen contempt\u201d for the agency\u2019s staff. \n             Not the first \n           Mauguin would not be the first non-scientist to head a publish research agency in France. In 2005, Jean-Yves Perrot, political adviser to former finance minister Herv\u00e9 Gaymard, took over as chief executive of the national marine research agency IFREMER. But that was before a 2013 law that requires the government to publicly advertise top science-agency jobs, and calls for ad hoc juries to interview candidates. Those juries then give the French president a non-binding opinion on the best choice. Although those opinions would normally be for the president\u2019s eyes only, the two parliamentary economic-affairs committees got a look at the jury\u2019s recommendation for the head of INRA on 12 July. The 2013 law aimed to stop the traditional practice of making political appointments, but \u201cwe can see this is not the case\u201d, says Muriel Vayssier-Taussat, an INRA research director. \u201cThe fight continues,\u201d says Patrick Hetzel, an opposition member of the National Assembly and one of Mauguin\u2019s most vociferous opponents. \u201cWe are going to see what legal action we will take.\u201d \n                   France\u2019s research minister lays out his priorities 2016-May-06 \n                 \n                   French scientists welcome new research minister 2015-Jun-17 \n                 \n                   France puts \u20ac260 million into research infrastucture 2011-Mar-08 \n                 Reprints and Permissions"},
{"file_id": "535212a", "url": "https://www.nature.com/articles/535212a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Poster-child for renewables strives to make wind and solar power more grid-friendly. The rows of towering wind turbines and legions of glistening solar panels spread across Germany\u2019s landscape are striking emblems of the country\u2019s shift to non-nuclear, low-carbon power. But although Germany is the world\u2019s  poster child for renewable energy , its grids cannot yet cope with the erratic nature of wind and solar power. In June, German meteorologists, engineers and utility firms began to test whether big data and machine learning can make these power sources more grid-friendly. \u201cTo operate the grid more efficiently and keep fossil reserves at a minimum, operators need to have a better idea of how much wind and solar power to expect at any given time,\u201d says Malte Siefert, a physicist at the Fraunhofer Institute for Wind Energy and Energy System Technology in Kassel, Germany, and a leader on the project, called  EWeLiNE . At about 45,000 megawatts, Germany\u2019s wind-power capacity is the third largest in the world, behind China\u2019s and the United States\u2019. And Germany is outperformed only by China in solar capacity. But the pace of the country\u2019s switch to renewables and its ambitions are unrivalled. Renewables now provide about one-third of domestic electricity and the government has promised that by 2050, at least 80% of the country\u2019s electricity will come from renewables. The trouble is that on calm and cloudy days, grid operators still need to call on conventional power stations to meet expected demand. And on unusually sunny and windy days \u2014 such as on 8 May, when for about 4\u00a0hours wind and solar power generated more than 90% of the electricity that Germany consumed \u2014 they must swiftly order coal and gas-fired power stations to reduce their output lest an influx of power \u2018congests\u2019 the grid and increases the risk of failures. Such requests, called re-dispatches, cost German customers more than \u20ac500 million (US$553 million) a year because grid operators must compensate utility firms for adjustments to their inputs. They can also lead to needless carbon dioxide emissions if grid operators generate extra power that ends up being wasted. \u201cIt is quite a concern that renewable energy here is expanding so fast without a proper database for accurate power forecast,\u201d says Renate Hagedorn, a meteorologist with the German weather service in Offenbach. \n               Eye of the storm \n             Standard weather models predict the strength and arrival times of storms and weather fronts in a given region. But they cannot, for example, predict wind strength at the hub of a turbine, which determines the amount of power the turbine will produce. The \u20ac7-million EWeLiNE project, a collaboration that includes three major grid operators \u2014 50Hertz, Amprion and TenneT \u2014 and that is funded by the federal ministry for economic affairs and energy, set out in 2012 to provide load forecasts that are specific to the needs of grid operators. Most wind turbines are equipped with devices that measure the wind speeds at their hubs, and some solar panels contain sensors for sunlight intensity. EWeLiNE combines these data with other atmospheric observations \u2014 from ground-based weather stations, radar and satellites \u2014 and sophisticated computer models predict power generation over the next 48 hours or so. The team checks these power forecasts against what actually materializes, and machine learning then improves the predictive models. The EWeLiNE researchers began testing their system using solar-panel and wind-turbine data from across Germany last month. Eventually, the idea is for grid operators to use the power forecast to guide these requests. But very few wind and solar facilities are set up to transmit the data in real time, so the results cannot yet be used to adjust how much power is produced. In two years, EWeLiNE plans to have real-time transmission capabilities for most of the wind and solar facilities in Germany. There are signs that the approach will work. The National Center for Atmospheric Research (NCAR) in Boulder, Colorado, started on a similar system in 2009, and it is is now operational in eight US states. At Xcel Energy, the utility firm with the highest total wind capacity in the United States, the number of forecasting errors has dropped since 2009, saving customers some US$60 million and reducing annual CO 2  emissions from fossil-reserve power generation by more than a quarter of a million tonnes per year, says Drake Bartlett, a renewable-energy analyst with the firm who is based in Denver, Colorado. \u201cGermany has some very good modellers who are already doing a nice job without the real-time data that we have,\u201d says Sue Haupt, who oversees weather-system research at NCAR. \u201cOnce they get access to that data I am sure it\u2019ll be used to great effect.\u201d EWeLiNE cannnot simply use the NCAR system because weather models and the algorithms that convert weather predictions into power forecasts differ between the United States and Germany. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Energy hit 2016-Jun-08 \n                   \n                     Embrace the change 2016-Jun-07 \n                   \n                     Obama acts alone on climate 2015-Jan-27 \n                   \n                     Renewable energy: Back the renewables boom 2014-Mar-19 \n                   \n                     Renewable power: Germany\u2019s energy gamble 2013-Apr-10 \n                   \n                     Energy alternatives: Electricity without carbon 2008-Aug-13 \n                   \n                     Fraunhofer IWES \n                   \n                     EWeLINE \n                   \n                     NCAR \n                   Reprints and Permissions"},
{"file_id": "535207a", "url": "https://www.nature.com/articles/535207a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Economic instability and campus violence have thrown labs into crisis. South Africa\u2019s universities have long been viewed as among the strongest in sub-Saharan Africa. But ongoing financial and political turmoil are endangering research at the nation\u2019s centres of higher learning. It is an extension of the overall crisis that currently faces South Africa. The country\u2019s economy is in tatters, with its currency falling in value, and a corruption scandal has weakened President Jacob Zuma and his ruling political party. The upheaval is an unwelcome backdrop to the  upcoming 21st International AIDS conference in Durban  on 18\u201322 July. Funding cuts have threatened agencies such as the South African Medical Research Council (MRC), and have harmed researchers\u2019 abilities to run their labs and recruit young scientists. They have also delayed planned projects at South African universities. The MRC is fighting a 7% budget cut for 2017\u201318, says council president Glenda Gray, and probably more cuts the year after. \u201cThis would be devastating,\u201d she says. \u201cBy cutting off science funding, you cut off your ability to be globally competitive.\u201d But the true effects have not yet been felt, says vaccine researcher Shabir Madhi, executive director of South Africa\u2019s National Institute for Communicable Diseases in Johannesburg. He worries that young scientists\u2019 careers will sputter as a result of funding shortfalls, because junior researchers depend on government and university money to launch their programmes. Long-established scientists draw much of their research funding from outside South Africa and are less affected by the cuts. Attempts by universities to compensate for slashes to funding have been challenged, sometimes violently. A proposed 10.5% fee hike at the University of the Witwatersrand in Johannesburg last October sparked a student protest movement, known on social media as the \u201c#FeesMustFall\u201d campaign. The protests spread to other universities, which had also proposed fee increases of 10\u201312%.The movement successfully squashed the hikes, and protestors are now pressing for free tuition at all South African universities. Without fee increases, however, universities are facing immediate budget shortfalls, which have forced them to make widespread cuts. Astronomer David Block at the University of the Witwatersrand says that he and his colleagues were told at a faculty meeting last month to save money by cutting their use of water, heat and electricity. Earlier this year, he attempted to recruit a promising postdoctoral researcher, but failed because his department lacked money for new hires. \u201cIt really has reached a crisis \u2014 we\u2019re under tremendous strain.\u201d \n               Up in smoke \n             Projects such as a programme to train vaccinology researchers at various institutions, including the University of the Witwatersrand, have had to find outside funding \u2014 a temporary stopgap. Researchers are also worried about access to infrastructure, ever since protests ahead of municipal elections on 3 August led to campus vandalism. Unrest in January shut down University of Pretoria campuses for weeks, and in February, the Potchefstroom campus of North-West University was closed after students torched administration buildings, including a science centre. In May, arsonists burned down a historic auditorium at the University of Johannesburg. Researchers and university administrators worry that political violence is becoming a new normal. During some of the worst mayhem, in May, Alta Schutte, director of the hypertension unit of North-West University said, \u201cWhen I go home every day, I am a bit concerned that when I come back, my office, my lab, my hypertension clinic or my biobank will not be there.\u201d The protest movement is a response to the nation\u2019s persistent inequality. \u201cAn upper-middle-income country like South Africa should widen access to education,\u201d says cardiologist Bongani Mayosi at the University of Cape Town. But the violence and intimidation have gone too far, he says. Danie Visser, deputy vice-chancellor for research and internationalization at the University of Cape Town, agrees. \u201cWe are probably at a critical juncture: if the country is able meaningfully to address the issues that brought about the student protests in the first place, our universities \u2014 and therefore also our research \u2014 will survive and flourish.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Erika_Check \n               \n                     South Africa ushers in a new era for HIV 2016-Jul-13 \n                   \n                     Science in turmoil: After the Arab Spring 2015-Apr-29 \n                   \n                     State cuts fuel California protests 2011-Dec-06 \n                   \n                     Research cuts hit the DNA business 2011-Nov-01 \n                   \n                     The Guardian : South Africa\u2019s student protests have lessons for all universities \n                   \n                     BBC: Why are South African students so angry? \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20256", "url": "https://www.nature.com/articles/nature.2016.20256", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "The world that we hear shapes the music that we like. Some people like to listen to the Beatles, while others prefer Gregorian chants. When it comes to music, scientists find that nurture can trump nature. Musical preferences  seem to be mainly shaped by a person\u2019s cultural upbringing and experiences rather than biological factors, according to a study published on 13 July in  Nature 1 . \u201cOur results show that there is a profound cultural difference\u201d in the way people respond to consonant and dissonant sounds, says Josh McDermott, a cognitive scientist at the Massachusetts Institute of Technology in Cambridge and lead author of the paper. This suggests that other cultures hear the world differently, he adds. The study is one of the first to put an age-old argument to the test. Some scientists believe that  the way people respond to music  has a biological basis, because pitches that people often like have particular interval ratios. They argue that this would trump any cultural shaping of musical preferences, effectively making them a universal phenomenon. Ethnomusicologists and music composers, by contrast, think that such preferences are more a product of one\u2019s culture. If a person\u2019s upbringing shapes their preferences, then they are not a universal phenomenon. \n             Tuned experiments \n           The trick to working out where musical preferences come from was to find and test people who hadn\u2019t had much contact with Western music. McDermott and his team travelled by aeroplane, car and canoe to reach the remote villages of the Tsimane\u2019 people (pronounced \u2018chee-MAH-ney\u2019), an indigenous society in Bolivia\u2019s Amazon basin at the foot of the Andes. Not only are the Tsimane\u2019 largely isolated from Western culture, but their music is also unusual in that they play or sing only one line at a time, rather than harmonies. In their experiments, McDermott and his colleagues investigated aesthetic responses to music by playing combinations of notes to three groups of people: the Tsimane\u2019 and two other groups of Bolivians that had experienced increasing levels of exposure to Western music. The researchers recorded whether each group perceived the notes as pleasant or unpleasant to hear. They tested consonant chords, which are common in Western and many other musical cultures, as well as dissonant ones. (In \u2018do re mi fa so la ti do\u2019, for instance, the \u2018dos\u2019 are exactly an octave apart and are an example of consonant notes.) The Tsimane\u2019 are just as good at making acoustic distinctions as the groups with more experience of other types of music, the scientists find. Most people prefer consonant tones, but the Tsimane\u2019 have no preference between them. \u201cThis pretty convincingly rules out that the preferences are things we\u2019re born with,\u201d McDermott argues. \u201cCulture plays a role. We like the music we grew up with,\u201d agrees Dale Purves, a neurobiologist at Duke University in Durham, North Carolina. \u201cNature versus nurture is always a fool's errand.\u201d It's almost always a combination, he adds. Robert Zatorre, a neuroscientist at McGill University in Montreal, Canada, also expresses scepticism that cultural influences are dominant in musical preferences. For example, macaque monkeys lack a musical culture, but nonetheless have neurons in the auditory part of their brains that respond in a different way to different tone intervals. Zatorre has written a  News & Views article  that accompanies the paper. But he adds that cultural experiences are still important in shaping how a person perceives sounds. All humans are born with similar brains and nervous systems, but these are flexible. The  development of speech parallels that of music  in a person's upbringing. Infants start out having the ability to discriminate between the sounds used in any language, but this fades over time as they specialize in their native tongue. Japanese people lose the ability to distinguish between \u2018r\u2019 and \u2018l\u2019 sounds, for instance. \u201cYour brain basically gets tuned to the environment around it,\u201d Zatorre says. See also Editorial  p.199 \n                   Why dissonant music strikes the wrong chord in the brain 2012-Nov-12 \n                 \n                   Music is in our genes 2007-Dec-10 \n                 \n                   Brain cells tune in to music 2005-Aug-24 \n                 \n                   Purves's lab \n                 \n                   Zatorre's lab \n                 \n                   McDermott's lab  \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20241", "url": "https://www.nature.com/articles/nature.2016.20241", "year": 2016, "authors": [{"name": "Peter Andrey Smith"}], "parsed_as_year": "2006_or_before", "body": "Movement of genes across and between microorganism species could influence humans\u2019 susceptibility to disease. To understand how microorganisms and their genes traverse the globe, Ilana Brito maxed out her own credit card, bought dewars of liquid nitrogen to preserve her samples, and flew to Fiji. Brito, who is now a microbiologist at Cornell University in Ithaca, New York, and her colleagues sampled microbes from the hands, saliva and faeces of people in five villages to map the spread of microbial genes across the villagers' social networks. The long-awaited results of this project are published this week in  Nature 1 . The study suggests that day-to-day interactions between people can affect the transfer of genes in  the human microbiome  \u2014 between and across species of microorganisms  that thrive in the body . This ongoing exchange of genes could help to reveal how an individual\u2019s microbiome  influences his chance of disease , and why some populations seem to be more susceptible to certain disorders. Brito and her colleagues compared the microbiomes of 172 Fijians with those of 81 North Americans, surveying thousands of mobile genes for evidence of transfer across populations. Bacteria readily swap genetic information with their neighbours, even across species \u2014 a process that can make an organism more or less virulent, or confer resistance to a particular antibiotic. The scientists also sequenced individual cells to see the entire set of genes within, and to identify which elements on a given gene are mobile. And the team analysed genetic material from the cheek swabs, saliva and faecal samples collected from each village in Fiji. The result is a massive trove of genetic data \u2014 the first sequencing effort of this scale to document a developing-world microbiome. \n             Island hopping \n           Focusing on a relatively isolated island population had several advantages. \u201cThese people tend to stick around in the same villages \u2014 everything is local,\u201d Brito says of the Fijians. These small, relatively contained populations helped to simplify the social networks that researchers sought to map. The Fijian villages also had a greater diversity of microbes compared to Western cultures that have largely eliminated bacterial pathogens through hygiene, antibiotics and sanitation infrastructure, Brito says. Previous studies have shown that an individual\u2019s microbiome is more or less stable, and that any shifts in its composition \u2014 caused by factors such as diet or drug use \u2014 can affect a person\u2019s susceptibility to disease. But scientists know little about how microbial genes spread across geographic regions or human populations, and what selective pressures hasten their spread globally. Brito\u2019s study illuminates one likely selective pressure: diet. Her team found that Fijians are more likely than North Americans to harbour microorganisms that contain plant-based genes to help digest starch \u2014 in what seems to be a consequence of differing dinners. And although genes for dietary enzymes and the overall composition of the human microbiome remained similar at the population level, the study pinpointed differences in these mobile gene pools between neighbouring villages. This suggests that highly localized cultural and environmental changes play a part in shaping microbial communities. Understanding how mobile gene elements travel could also help scientists to better understand the spread of genes that confer antibiotic resistance to drugs such as colistin, an antibiotic of last resort, for instance. \n             A broader view \n           Brito\u2019s project is unique in the scope with which it examines the microbial genes of individuals and villages, says Jack Gilbert, a microbiologist at the University of Chicago in Illinois. Because mobile genes differ from village to village, Gilbert says, it\u2019s possible that routine social interactions \u2014 such as sharing a meal \u2014 alter the microbiome function, even if they don\u2019t necessarily change the types of bacteria colonizing a person. These differences, he says, could help scientists to understand why certain populations are more susceptible to certain diseases \u2014 such as the high prevalence of asthma and food allergies among the Hutterites, a North American religious community similar to the Amish. The study is also a testament to Brito\u2019s perseverance. The US National Institutes of Health initially rejected her Fiji proposal as too ambitious, although the agency later contributed funding to have the samples sequenced. Determined to proceed, she paid for a trip to Fiji with a staff of four; at one point, she enlisted her mother to label sample tubes. For now, Brito continues to analyse the data she collected in Fiji \u2014 but she is also considering a return trip, to further explore the unseen world of the microbiome. \n                   White House goes big on microbiome research 2016-May-13 \n                 \n                   Scientists bust myth that our bodies have more bacteria than human cells 2016-Jan-08 \n                 \n                   Scientists debate mega-microbiome initiatives 2015-Oct-30 \n                 \n                   The tantalizing links between gut microbes and the brain 2015-Oct-14 \n                 \n                   Microbiomes raise privacy concerns 2015-May-11 \n                 \n                   Microbiome therapy gains market traction 2014-May-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20258", "url": "https://www.nature.com/articles/nature.2016.20258", "year": 2016, "authors": [{"name": "Petra Szil\u00e1gyi"}], "parsed_as_year": "2006_or_before", "body": "Peeled strips of single-layer carbon could be useful in electronic circuitry. Graphene, a single-atom-thick sheet of carbon, is stronger than steel and as stiff as diamond. Yet, this tough, thin material can also be induced to peel itself to pieces. Puncturing a hole in graphene with a diamond tip and repeatedly moving that tip back and forth \u2014 rather like rucking up a carpet \u2014 causes narrow strips of carbon to curl spontaneously upwards, tearing out of the graphene layer and even folding back on themselves, scientists from Trinity College Dublin report in an article in  Nature 1  on 13 July. The discovery is \u201centirely surprising\u201d, says James Tour, a specialist in nanotechnology at Rice University in Houston, Texas. Tour says that since the technique is in its infancy and the researchers haven't yet demonstrated they can control it, it's hard to see exactly how it could be used. But the discoverers of the effect, physicists Graham Cross and James Annett, think that it should be possible to control the size of the ribbons and the way that they peel and fold, potentially making them useful in electronic circuitry. Annett \u2014 a graduate student at the time of the discovery \u2014 happened on the finding by chance, when he was dragging a diamond tip over the surface of graphene to test the carbon sheet\u2019s anti-friction properties. Sometimes, he noticed, the tip would puncture the graphene sheet and it would continue to tear apart in long ribbons of varying size \u2014 up to tens of micrometres long. \u201cWhen James showed me his results, I knew immediately that we had discovered something important,\u201d says Cross. \n             Mechanism magic \n           The process is possible, Cross says, because a single, flat layer of graphene is less energetically stable than multiple layers. Given the freedom to move, a graphene ribbon would rather roll up and fold back on itself than stay flush with the surface. But to reach that more stable state, a ribbon must tear other strong carbon\u2013carbon bonds inside graphene as it peels away \u2014 an energetic barrier to movement. Oscillating the diamond tip helps to overcome that barrier. The process works at room temperature; but at higher temperatures, the ribbons grow more rapidly and are longer. There are many ways to carve shapes out of graphene \u2014 such as using chemicals, lasers or oxygen plasma to etch away unwanted parts of a graphene sheet. Last year, a group led by physicist Paul McEuen at Cornell University in Ithaca, NY,  created complex cuts and folds in graphene , a process which they likened to kirigami, the Japanese art of paper cutting. But Cross and Annett\u2019s method works under milder conditions and could be used to make many ribbons quickly, the researchers think, because each shape does not have to be laboriously carved.  Cross thinks that if he can control the way the ribbons form and stack, he might be able to use them as transistors (electrical switches), capacitors (devices that store electrical charge) or connections between electrically conductive graphene sheets. In unpublished experiments, he says, he has already controlled the way the ribbons stack atop each other. Boris Yakobson, a materials scientist at Rice University, says that he is \u201cthrilled\u201d by the finding. If the researchers can use multiple diamond tips in different shapes and further control the process, \u201cone can envision forming a predesigned ribbon network ready to serve as electrodes in a specific circuitry of a future device,\u201d he says. \n                   UK graphene inquiry reveals commercial struggles 2016-May-03 \n                 \n                   Graphene kirigami 2015-Jul-29 \n                 \n                   Graphene booms in factories but lacks a killer app 2015-Jun-17 \n                 \n                   The super materials that could trump graphene 2015-Jun-17 \n                 \n                   Chemistry: The trials of new carbon 2011-Jan-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20263", "url": "https://www.nature.com/articles/nature.2016.20263", "year": 2016, "authors": [{"name": "Rebecca Boyle"}], "parsed_as_year": "2006_or_before", "body": "Exposure to artificial light weakens rodents\u2019 muscles and bones, but risks to people are less clear. Eliane Lucassen works the night shift at Leiden University Medical Center in the Netherlands, beginning her day at 6 p.m. Yet her own research has shown that this schedule might cause her health problems. \u201cIt\u2019s funny,\u201d the medical resident says. \u201cHere I am, spreading around that it\u2019s actually unhealthy. But it needs to be done.\u201d Lucassen and Johanna Meijer, a neuroscientist at Leiden, report today in  Current Biology 1  that a constant barrage of bright light prematurely ages mice,  playing havoc with their circadian clocks  and causing a cascade of health problems. Mice exposed to constant light experienced bone-density loss, skeletal-muscle weakness and inflammation; restoring their health was as simple as turning the lights off. The findings are preliminary, but they suggest that people living in  cities flooded with artificial light  may face  similar health risks . \u201cWe came to know that smoking was bad, or that sugar is bad, but light was never an issue,\u201d says Meijer. \u201cLight and darkness matter.\u201d \n             Disrupted patterns \n           Many previous studies have hinted at a connection between artificial light exposure and health problems in animals and people 2 . Epidemiological analyses have found that shift workers have an increased risk of breast cancer 3 , metabolic syndrome 4  and osteoporosis 5 , 6 . People exposed to bright light at night are more likely to have cardiovascular disease and often don\u2019t get enough sleep. Yet drawing a direct link between light exposure and poor health has been difficult. Meijer\u2019s group explored this relationship in mice by implanting electrodes in the part of the animals\u2019 brains that controls their body clocks, to measure the activity of neurons there. The scientists then housed the mice in brightly lit cages for 24 weeks. The animals had bedding to make nests, could move freely and were able to close their eyes when they slept. But sleeping mice couldn't avoid the light entirely, and still got about one-seventh of the light exposure that they did while awake. Overall, the animals were exposed to more light than they would get in a typical light\u2013dark cycle. In response, the mice\u2019s neuronal activity patterns shifted, leaving cells in the brain\u2019s pacemaker region pulsing irregularly. This loss of synchronization mirrors what happens in ageing brains. The mice also adopted a 25.5-hour day, lost bone density and had weaker muscles, as measured by how strongly they could grip with their forelimbs. After the researchers restored darkness, the mice's neurons returned to their normal rhythms and the animals reverted to a 24-hour day. \n             Bright lights, big impact \n           The analysis takes an innovative approach to studying circadian biology in mice, says Richard Stevens, an epidemiologist at the University of Connecticut School of Medicine in Farmington who studies the effect of light on cancer. But he says that the findings may not apply to people. The bright lights foisted on the mice were more dramatic than the light\u2013dark cycles that people would experience in real life, even in extreme situations. \u201cThe next experiment ought to be something like 12 hours of light, 6 hours of dim light and 6 hours of dark. That would be the kind of exposure that humans would have,\u201d Stevens says. And disruption of the biological clock alone might not cause the health effects reported in the study, says Steven Lockley, a neuroscientist at Harvard Medical School in Boston, Massachusetts. Poor sleep and light itself can each affect health, so an altered circadian clock may not be to blame. But Meijer says the study should be a warning to people who work in intensive-care facilities or long-term care facilities, and to shift workers \u2014 such as her former student, Lucassen. An atlas of artificial light pollution released in June showed that two-thirds of the world\u2019s population is  exposed to light at night 7 . Also last month, the American Medical Association\u2019s Council on Science and Public Health  called for a reduction in bright artificial light , citing evidence that it may increase a person\u2019s risk of developing cancer, diabetes and cardiovascular disease. Meijer now plans to examine how light affects the immune system, and she wants to repeat her neuron-monitoring study with grass rats, which are active during the day (unlike standard lab mice). She remains fascinated by the circadian system. \u201cThere is no other region of the brain we know so much about,\u201d Meijer says. \u201cIt has been a beautiful model for neuroscience research. But only in the last five to seven years have we realized it is also essential for health.\u201d \n                   A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                 \n                   Flies reared in the dark for 60 years give up their genetic secrets 2016-Feb-09 \n                 \n                   Biological clocks defy circadian rhythms 2013-Sep-26 \n                 \n                   City life turns blackbirds into early birds 2013-Jun-05 \n                 \n                   A biological clock to wind them all 2012-May-16 \n                 \n                   In search of dark nights 2010-Jul-07 \n                 \n                   Circadian rhythms: Of owls, larks and alarm clocks 2009-Mar-11 \n                 \n                   Johanna Meijer \n                 \n                   Richard Stevens \n                 \n                   Steven Lockley \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20265", "url": "https://www.nature.com/articles/nature.2016.20265", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "'Black and Bloom' project explores how microorganisms help to determine the pace of Arctic melting. Researchers are fanning out across the Greenland ice sheet this month to explore a crucial, but overlooked, influence on its future: red, green and brown-coloured algal blooms. These darken the snow and ice, causing it to absorb more sunlight and melt faster. The \u00a33-million (US$4-million)  Black and Bloom project  aims to measure how algae are changing how much sunlight Greenland\u2019s ice sheet bounces back into space. \u201cWe want to get a handle on just how much of the darkness is due to microbes and how much to other physical factors\u201d, such as soot or mineral dust, says Martyn Tranter, a biogeochemist at the University of Bristol, UK, and the project\u2019s principal investigator. Team scientists arrived near Kangerlussuaq, Greenland, this week for 6 weeks of observations. The work will continue for two more summers, exploring different parts of the ice sheet. Ultimately, the scientists hope to develop the first deep understanding of how biological processes affect Greenland\u2019s reflectivity. From these results, climate modellers should be able to improve their estimates of how the ice sheet \u2014 which contains  enough water to raise sea levels by seven metres  \u2014 is likely to melt in the coming decades. The past several years, as well as the current one, have seen temperature and melting records  set across Greenland . Black and Bloom will provide \u201ca one-of-a-kind dataset\u201d to help researchers better understand Greenland's future, says Marco Tedesco, a geophysicist at the Lamont-Doherty Earth Observatory in Palisades, New York. Tranter adds that the work could also affect predictions of water supplies in other areas, such as the Himalayas, where algal blooms dot water-producing glaciers. \n               Summer party \n             For decades, most studies on Greenland microbiology focused on cryoconite holes, small pits on the surface of the ice sheet that are filled with dark organic matter and ice-adapted algae. But enormous blooms of photosynthetic algae also cover the snow-strewn ice sheet every summer 1 . Some, such as  Chlamydomonas nivalis , spread first as greenish blooms as they begin to photosynthesize, and then turn a reddish colour as they produce carotenoid pigments to protect themselves from the sun\u2019s ultraviolet rays. \u201cThey\u2019re extremely lazy algae \u2014 they sleep for nine months and then wake up and have a party,\u201d says team member Liane Benning, a biogeochemist at the University of Leeds, UK, and the GeoForschungsZentrum research centre in Potsdam, Germany. The algae creates vast, colourful fields of what is popularly known as 'watermelon snow'. Last month in  Nature Communications , Benning and her team reported  sampling watermelon snow at glaciers across the Arctic 2 . They found 6 types of algae living at 40 red-snow sites in Norway, Sweden, Greenland and Iceland. By comparing the optical properties of red snow to clean snow, they estimated that algal blooms could reduce reflectivity by 13% over the melting season. \u201cWherever we look, the impact is quite dramatic,\u201d Benning says. After the snow cover melts for the season, other species of alga take over. These ice-adapted algae are typically brownish-grey, less visibly dramatic than the red and green blooms but just as important for darkening the ice sheet. Only in the past few years have scientists begun to realize that some of the dark particles on the ice sheet are in fact these ice algae and not soot, Benning says. \n               A rotten discovery \n             Tranter says he got the idea for Black and Bloom about four years ago, when he was working on the margins of the Greenland ice sheet and forgot his glacier goggles. He put his shaded cycling glasses on instead, and suddenly colour popped out at him. \u201cEverywhere the ice surface was melting I could see a mauve colour,\u201d he says. \u201cI said guys, there\u2019s tons of algae growing in this rotten ice.\u201d Black and Bloom is the first effort to systematically explore algae\u2019s role in darkening ice sheets 3 . This initial field season focuses on southwest Greenland, at a  'dark snow' site  where collaborators Jason Box and Marek Stibal of the Geological Survey of Denmark and Greenland have been quantifying the soot and mineral dust that settles onto Greenland. Now the microbiologists have arrived with equipment to sample the various algal and bacterial species that pockmark the ice. The heart of Black and Bloom is a study region half a kilometre long on each side. Here, the researchers will collect samples of black carbon and microoganisms while measuring incoming sunlight and reflectivity. They will also venture out on transects, both on foot and using unmanned aerial vehicles, to get a broader perspective on the algal blooms. With longer melting seasons over the past few years, the algae have more time to bloom and darken the sheet, Tranter says. Next year, the team plans to go out earlier in the season, to be there in May when the snow begins to melt and the algae wake from their winter nap. \n                     Cold truths at the top of the world 2016-Apr-19 \n                   \n                     NASA launches mission to Greenland 2015-Jul-28 \n                   \n                     Rediscovered photos reveal Greenland's glacier history 2012-May-28 \n                   \n                     Collapse of the ice titans 2010-Sep-09 \n                   \n                     Atmospheric science: Climate's smoky spectre 2009-Jul-01 \n                   \n                     Climate change: Losing Greenland 2008-Apr-16 \n                   \n                     Black and Bloom project \n                   \n                     Greenland ice sheet surface mass budget \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20264", "url": "https://www.nature.com/articles/nature.2016.20264", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Reshuffled UK administration signals change for research and science policy. Three weeks after  UK voters chose to leave the European Union , the country has a new prime minister, Theresa May \u2014 and a revamped administration that is poised to change science\u2019s place in government. For researchers, May\u2019s most important decision so far may be her appointment on 14 July of  Greg Clark , a former science minister, to lead a newly formed department that will also have ultimate responsibility for research, and the  confirmation on 15 July  that Jo Johnson will remain in his  post as universities and science minister . Science-policy experts have welcomed the appointment of Clark, whose official title is Secretary of State for Business, Energy and Industrial Strategy (BEIS). \u201cPeople will be happy that he has played that role in the past and understands the importance of science and of the research system,\u201d says Kieron Flanagan, a science-policy researcher at the Alliance Manchester Business School. The new department replaces the Department for Business, Innovation and Skills (BIS), which had overseen the United Kingdom\u2019s annual \u00a34.7-billion (US$6.3 billion) research budget, and also the Department for Energy and Climate Change (DECC). Some worry that the elimination of DECC will weaken the United Kingdom\u2019s responsibilities on climate change and decarbonization. \u201cDECC\u2019s disappearance raises urgent questions,\u201d said Angus MacNeil, a politician who leads the cross-parliamentary Energy and Climate Change Committee. Bob Ward, a climate-change policy expert at the London School of Economics and Political Science, warns against jumping to the conclusion that May will be timid on climate action. \"From what we know of her statements on climate change, she understands the importance of it,\u201d he says. \"I don't think the fact that there is no climate change in the title necessarily means a reduction in commitment.\" A more consequential change will come if some of the civil servants who are experts on climate change are lost in the transition. DECC\u2019s staff understood not only climate science but also its effects on regional weather and the need for UK infrastructure to adapt, says Corinne Le Qu\u00e9r\u00e9, director of the Tyndall Centre for Climate Change Research at the University of East Anglia in Norwich. May\u2019s own recent rival for the prime minister position, Andrea Leadsom, is the new environment secretary, and May has moved responsibilities for higher education from BIS to the education department, which is now under Justine Greening. Johnson\u2019s brief will now be split between the education department and BEIS. Nick Hillman, director of the Higher Education Policy Institute in Oxford, points out that universities and schools are very different, but that the reorganization could work if Johnson has \u201cconsiderable autonomy\u201d within the education department. Johnson\u2019s reappointment signals that May plans to push on with reforms of  higher education  and of  research funding  that her predecessor,  David Cameron , began, say observers. \n               Stability, for now \n             An overall atmosphere of chaos has reigned since the referendum. Policy experts say that May\u2019s ascendance has brought the country a measure of stability. \u201cIt\u2019s the first piece of sanity in a long time for UK politics,\u201d says Paul Nightingale, deputy director of the Science Policy Research Unit at the University of Sussex, UK. May appointed Philip Hammond as Chancellor of the Exchequer, a job that includes overseeing the state\u2019s budget, including its allocations to research. \u201cHe is seen as being a person who doesn't make headline decisions, so we might have some hope of status quo at the very least with regard to research funding,\" says Jenny Rohn, who chairs the UK lobby group Science is Vital. \u201cWe just heard that there will be no emergency budget, so scientists will have time to make their case before the autumn statement.\" But the country still faces the  uncertainty of the Brexit  \u2014 and the results of negotiations to leave the EU. May, who became the United Kingdom\u2019s second female prime minister on 13 July, had opposed leaving the EU, like Cameron. (As Flanagan puts it, May had been perceived as \u201cthe nearest thing to Cameron that isn\u2019t Cameron\u201d). But May has made it clear that under her watch, the United Kingdom will leave the EU, and she has sought to differentiate herself from Cameron\u2019s outgoing government. She has sacked some of its key members, and filled some posts with pro-Brexit politicians: putting Boris Johnson, the controversial pro-Leave former mayor of London, in charge of the Foreign Office, for example. She has also created a post for leading the negotiations that will determine the United Kingdom\u2019s new relations with the EU. Scientists are still in the dark about how May herself views science. She ran virtually no formal campaign for prime minister and has given little indication of what her policy priorities on research would be. In a speech in Birmingham on 11 July, she called for \u201ca better research and development policy that helps firms to make the right investment decisions\u201d and \u201can energy policy that emphasizes the reliability of supply and lower costs for users\u201d, but did not go into further detail. \n               Pragmatic operator \n             In her former role as home secretary, May\u2019s push to reduce immigration and  tighten up visa requirements  sometimes put her at odds with university administrators. She also helped to push through a bill that enacted a blanket prohibition on so-called designer drugs. But she has shown pragmatism and a willingness to change her mind when presented with compelling evidence, says Nightingale. \u201cShe has been an example of good practice in gathering evidence, and also of explaining her decisions when they have not gone with the scientific advice,\" says Sarah Main, director of the London-based Campaign for Science and Engineering. May\u2019s past decisions do not necessarily give a good indication of how she will act as prime minister, Flanagan says. As a home secretary who was positioning herself to be the next prime minister, May had to seem tough to Conservative voters on issues such as immigration and security, he says. Central to scientists\u2019 concerns are that their needs will be taken account of when the Brexit terms are agreed. In particular, they want reassurance that they will still be able to  access EU science funding and to easily hire people from throughout the bloc . \u201cWe need to make sure people understand that, perhaps unintentionally, the UK research community does have a lot to lose,\u201d says Main. The UK research community is anxious for the government to make a commitment to shielding them from the possible impacts of Brexit. \u201cThe challenge would be for the new government and the new prime minister to set out clearly what is their ambition for science and research to play a part in the UK future,\u201d Main says. \u201cWe would like to see that clearly stated.\u201d \n                 Additional reporting by Richard Van Noorden and Elizabeth Gibney. \n               \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Brexit watch: Scientists grapple with the fallout 2016-Jul-08 \n                   \n                     Brexit and science: Seven days later 2016-Jul-01 \n                   \n                     Nature Special: Brexit and science \n                   Reprints and Permissions"},
{"file_id": "535333a", "url": "https://www.nature.com/articles/535333a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "European Investment Bank provides surprise loan to halt startling brain drain. A massive loan from the European Union\u2019s investment bank gives Greek researchers their first ray of hope since the debt crisis hit six years ago: a government-backed plan to create a Greek research agency. Dubbed the Hellenic Foundation for Research and Innovation (HFRI), it will issue regular calls for basic research proposals, fill requests for research equipment and award fellowships for young scientists. Its funder, the European Investment Bank (EIB) in Luxembourg, generally finances projects that contribute to growth and employment, including many green-energy and water-security programmes. So the decision to support Greek research came as a surprise to some. \u201cAt first we hadn\u2019t believed that the EIB would pay for blue-skies research,\u201d says  Greek research minister Costas Fotakis , a former laser physicist. The EIB says that the HFRI is crucial to halting Greece\u2019s startling brain drain: graduates and postgraduates have left Greece in droves since the crisis began. On 15\u00a0July, the bank approved the \u20ac180-million (US$200-million) loan, which the Greek government will top up with \u20ac60\u00a0million. The total will support the HFRI during its first two-and-a-half years. The EIB rarely loans more than 50% of the cost of a project, but the 28\u00a0EU member states voted unanimously to make an exception, says EIB spokesman Richard Willis. \u201cGiven the key issues around fundamental research in Greece, 75% was seen as justified,\u201d he says. \u201cIt is about competitiveness, forward-thinking and the future.\u201d The EIB does not make the detailed conditions of its loans public, but Willis says that the terms for the HFRI are very attractive and that Greece has a full 15\u00a0years to repay the money. If the HFRI is successful, the bank will consider additional loans in the future, he adds. A parliamentary bill to establish the agency is currently being discussed. It proposes that the HFRI operate along the lines of the US National Science Foundation and the DFG, Germany\u2019s main funding agency \u2014 and without direct political influence. \u201cFor the first time we\u2019ll have some regularity in research funding in Greece,\u201d says Nektarios Tavernarakis, director of the FORTH Institute of Molecular Biology and Biotechnology (IMBB) in Heraklion, Crete. \u201cIt will definitely help make Greece a more attractive place to do research.\u201d Tavernarakis, who in April won his second grant from the prestigious European Research Council, knows from bitter experience how hard it is to persuade ambitious young scientists to join even a high-performing research institute like his own.  When the debt crisis hit a peak last July, triggering bank closures , the resulting controls on the flow of capital out of the country frightened off candidates who had previously been prepared to work at the IMBB, he says. \u201cAnd that was quite understandable.\u201d Fotakis says that the HFRI is a key part of government strategy to increase the country\u2019s potential. He blames the Greek brain drain on the  austerity measures  imposed by the European Commission, the European Central Bank and the International Monetary Fund in exchange for keeping the country from bankruptcy. \u201cThey have lowered wages and pensions, and made all aspects of research difficult,\u201d he says. Because parliament is unlikely to pass the HFRI bill before September, Fotakis plans to launch calls for some PhD and postdoctoral grants immediately. Even before the crisis, Greece has been one of the lowest investors in research in the EU. But once the crisis began, calls for research proposals, which were always modest and irregular, nearly disappeared. Scientists had to survive on international funding sources, particularly those from the EU. The country still manages to host several internationally competitive research centres, but Fotakis says that even this is not sustainable. \u201cScientific output is obviously not going to be sustained for ever when the brain drain is so intense.\u201d The initial total of \u20ac240 million earmarked for the agency will support fundamental research, but the HFRI will eventually support a second stream for translational research. Beyond 2018, Fotakis expects the government to support the fundamental research stream with an annual \u20ac20\u00a0million. \u201cAnd now that the EIB has demonstrated its confidence in Greek science with this loan, it\u2019ll be much easier to attract other sources of financing to the HFRI,\u201d he says. Greece fixed a few more bugbears when it passed a general law on research in May \u2014 for example, researchers will now be able to top up salaries for themselves and their groups if they bring in outside grants. No one imagines that the problems of Greek science are now solved. \u201cStill,\u201d says Tavernarakis, \u201cthese measures show things are at least going in the right direction.\u201d \n                     Greek bailout set to free up research funds 2015-Aug-15 \n                   \n                     Greek scientists lose access to digital journals 2015-Jul-02 \n                   \n                     Greek cash grab 2015-May-06 \n                   \n                     New Greek government raises hopes for science 2015-Jan-27 \n                   \n                     Greek science haunted by hydra of problems 2015-Jan-06 \n                   \n                     Greek science on the brink 2012-Jan-11 \n                   \n                     European Investment Bank loan to Greece \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20273", "url": "https://www.nature.com/articles/nature.2016.20273", "year": 2016, "authors": [{"name": "Amy  Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Genetics study confirms social cycle that helps infection to spread. Sex between young women and older men is no secret in South Africa. The name \u2018blesser\u2019 is commonly used to describe a man who may at first pay for a teenager\u2019s bus fare to high school, then buy school supplies she cannot afford, and perhaps lunch at a decent caf\u00e9. Over time, the adolescent sleeps with her provider. A genetic analysis now suggests how this social phenomenon plays into the cycle of HIV transmission in the country, which has  the world\u2019s largest HIV epidemic . By analysing the similarity of viral genetic sequences from nearly 1,600 people with HIV in one community in KwaZulu-Natal, the study shows that adolescent girls and women in their early 20s tend to pick up the virus from men aged around 30. When the women grow older, they go on to infect their long-term partners, who in turn may pass the virus on through affairs with younger women. \u201cThis is the engine driving high rates of HIV,\u201d says epidemiologist Salim Abdool Karim, senior author of the unpublished study and director of the Centre for the AIDS Program of Research in South Africa (CAPRISA). He presents the work this week at the International AIDS Conference in Durban. Karim thinks that the study adds to  growing evidence  that HIV-free young women in regions with very high rates of HIV should be encouraged to take antiretroviral medications regularly to prevent infection. The World Health Organization also recommends that people at substantial risk of HIV be offered what is known as PrEP (pre-exposure prophylaxis). But, owing in part to disappointing results in clinical trials, the South African\u00a0government has not yet recommended PrEP for young women. Karim's study also shows the importance of making broader social changes, adds Michel Sidib\u00e9, executive director of the Joint United Nations Programme on HIV/AIDS (UNAIDS). In parts of South Africa, 8 times as many teenage girls have HIV as do teenage boys, and in some communities in KwaZulu-Natal, a 15-year-old girl has an 80% risk of getting HIV in her lifetime. \u201cSomething that underlies the study is how common it is for older men to have sex with young girls. Pills are useful, but how can we break this silence around the lack of enforcement of laws that protect young women? How can we invest in the capacity of people to claim their rights and reduce this kind of violence?\u201d \n               Vicious cycle \n             Researchers have long known of the high burden of HIV infections in young South African women, and that they get infected by older men, says Thomas Quinn, an epidemiologist at Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland, who was not involved in the study. But, he says, \u201cit is very exciting to use molecular genetic information to actually show how the virus spreads among people\u201d \u2014 and to pinpoint the ages of women and men at key points in the cycle of HIV transmission. Karim has tracked HIV genetic data for the past couple of years, and his work has already affected how governments and international organizations tackle the virus. He has been sharing results regularly with Deborah Birx, the US Global AIDS Coordinator who oversees the US President\u2019s Emergency Plan for AIDS Relief (PEPFAR), the largest federal funder of HIV-prevention research. In 2014, PEPFAR launched an initiative called DREAMS to protect young women from HIV, in response to the finding that more than 1,000 women aged 16\u201324 become infected every day in southern and eastern Africa. When Birx heard details of Karim\u2019s results last year, she convinced PEPFAR to target particular demographic groups. For example, she says, half of the recipients of the US$85-million DREAMS Innovation Challenge, announced on 18 July, are 15- to 19-year-old girls. \n               Prevention problems \n             Despite the results, health officials remain reluctant to recommend PrEP for adolescent girls and young women. In June, the South African government endorsed PrEP for sex workers \u2014 but not for other high-risk groups, such as gay men and young women. One reason for its hesitancy is that the treatments have not proved effective in clinical trials, and blood tests have suggested that is because women in these trials did not consistently take their medications (either daily pills or a vaginal gel). But at the conference, the CAPRISA team announced another as-yet-unpublished finding that suggests a woman\u2019s vaginal microbiome may be in part responsible for the inefficacy of PrEP. A study of women who used the gel tenofovir to prevent HIV infection suggests that it was less effective in those who had  Gardnerella vaginalis  bacteria in their vaginal lining. The researchers found that  G. vaginalis  absorbed the PrEP drugs, reducing the amount of medication in the blood. This hints that more women may actually have taken their medications than the disappointing blood tests from earlier trials suggested, Karim says \u2014 and also that treatment for an imbalance in vaginal bacteria might help PrEP to work better in some young women.  Travel for this story was supported by the Pulitzer Center on Crisis Reporting. \n                     South Africa ushers in a new era for HIV 2016-Jul-13 \n                   \n                     World Health Organization to recommend early treatment for everyone with HIV 2015-Jul-20 \n                   \n                     How to beat HIV 2015-Jul-07 \n                   \n                     Wary approval for drug to prevent HIV 2012-Jul-17 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20212", "url": "https://www.nature.com/articles/nature.2016.20212", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "A fortuitous observation by Japan's Hitomi probe shows the calm centre of the Perseus cluster. From the last gasp of a failed satellite comes a brief glimpse of galaxies far, far away. Before it broke in March, one month after launch,  Japan\u2019s Hitomi X-ray satellite  managed to gaze at the Perseus galaxy cluster \u2014 one of the Universe's most massive objects, 250 million light-years from Earth. And researchers discovered that superheated gas at the cluster's heart flows much more placidly than expected. Understanding how turbulence roils this gas allows astronomers to explore how galaxies form and evolve. \u201cClusters are one of our most important probes of cosmology,\u201d says Craig Sarazin, an astronomer at the University of Virginia in Charlottesville who was not involved with the work. \u201cMost of the gas in the Universe lies between galaxies,\u201d adds Andrew Fabian, an astronomer at the University of Cambridge, UK, and a member of the international team that reported its findings on 6 July in  Nature 1 . So Hitomi's peek into these areas could affect how scientists see most of the Universe's matter.  Hitomi launched on 17 February and made the Perseus observations on 25 February and 4 March, weeks before  losing communication with Earth  on 26 March. An investigation by the Japan Aerospace and Exploration Agency subsequently revealed that  human errors in a software command  caused the satellite to rotate so fast that it flew apart. \n             Just in case \n           Researchers wouldn\u2019t have had even this short glimpse of Perseus if they hadn\u2019t targeted the cluster early on, as engineers were still calibrating the satellite. Because galaxy clusters contain so much mass in the form of visible stars and unseen dark matter, they pull gas into a giant gravitational well. This process compresses and heats the gas to 50 million \u00b0C, causing it to glow intensely in X-ray wavelengths. Earlier studies with the  Chandra X-ray Observatory  and the XMM-Newton satellite explored the pressure of gas between Perseus\u2019s galaxies. Hitomi aimed to look instead at turbulence within the gas, because those motions can affect measurements of a cluster's mass and estimates of how galaxies come together. Hitomi\u2019s X-ray spectrometer revealed gas moving at 164 kilometres per second, measured near the centre of one of Perseus\u2019s galaxies. That speed is much lower than expected given the amount of astrophysical action in the region, which includes a powerful black hole. \n             Sound in the silence \n           Some other process \u2014 perhaps sound waves radiating outward \u2014 must be dissipating much of the cluster's energy, says Fabian. \u201cIt\u2019s telling us there are aspects of clusters that we don\u2019t fully understand,\u201d he says. The new Hitomi measurements aren\u2019t quite as precise as they could have been, because the team had not gone through all its calibrations before losing the satellite, notes Elizabeth Blanton, an astronomer at Boston University in Massachusetts. But the Perseus work is likely to stand as Hitomi\u2019s primary scientific legacy. \u201cOf course we had a programme planned to look at more clusters, and we would have carried on for the next few years had it only lived,\u201d says Fabian. \u201cIt feels like the door has been briefly opened, showing us a new and exciting landscape \u2014 and it\u2019s been slammed in our face again.\u201d The next big X-ray telescope is not scheduled until at least 2028, when the European Space Agency plans to launch  its ATHENA observatory . Read the related  News & Views . \n                   Software error doomed Japanese Hitomi spacecraft 2016-Apr-28 \n                 \n                   Japanese X-ray satellite loses communication with Earth 2016-Mar-27 \n                 \n                   High stakes as Japanese space observatory prepares for launch 2016-Feb-09 \n                 \n                   JAXA's Hitomi site \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20190", "url": "https://www.nature.com/articles/nature.2016.20190", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Forecasters warn that high ocean temperatures presage intense blazes in rainforest. The Amazon is ready to burn. After an unusually dry rainy season, the southern section of the rainforest is heading into winter with the largest moisture deficit since 1998. This has set the stage for an unusually intense fire season, according to a forecast issued on 29 June that is based on sea-surface temperature trends in the Atlantic and Pacific oceans. \u201cThe region is primed to have record fire activity,\u201d says forecast co-author Douglas Morton, a remote-sensing expert at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. More broadly, a team led by Morton and James Randerson, a biologist at the University of California, Irvine, says that it can predict fire risk across much of the globe \u2014 based in part on the influence of the weather pattern El Ni\u00f1o and its counterpart, La Ni\u00f1a. The Amazon burn predictions stem from  the epic El Ni\u00f1o weather event  that emerged last year. El Ni\u00f1os  warm the tropical Pacific Ocean , which tends to reduce rainfall during the rainy season, and the warmer temperatures in the tropical Atlantic Ocean can suppress rains during the dry season. The El Ni\u00f1o that emerged last year also helped to spawn devastating forest fires in Indonesia, the researchers say. Their work reveals that sea-surface temperatures in the Atlantic and Indian oceans foreshadow fire trends in Central America, Africa and some boreal forests in Earth\u2019s high northern latitudes. In each case, Morton and Randerson say, ocean conditions can provide a hint of precipitation trends in key forested areas on land several months in advance. \u201cAll of these processes are contributing to both the build-up of fuels and the moisture level of those fuels going into the dry season,\u201d Randerson says. \u201cThat\u2019s what leads to a predictability in global fire regimes.\u201d \n               Forecasting vulnerability \n             Other teams are looking to include fire risk in short-term and seasonal weather forecasts by incorporating independent fire models. These models attempt to account for factors such as vegetation type and the likelihood of lightning strikes or agricultural fires. Eventually, such forecasting systems could integrate more complex phenomenon such as the dynamics of vegetation growth, the way that fire tends to propagate across a landscape and the gases and particles that are emitted during a fire, says Allan Spessa, a fire modeller at the Open University in Milton Keynes, UK. The European Centre for Medium-Range Weather Forecasts in Reading, UK, plans to soon make public its prototype system to forecast fire risk about six weeks in advance, and the centre\u2019s modellers are working to include fire risk in their seasonal forecasts. Florian Pappenberger, who heads the centre\u2019s work on extreme-weather forecasting, says that the statistical approach used by Morton and Randerson is solid and can serve as an independent check on model forecasts, which come with their own uncertainties. Forecasts for water availability in rivers, reservoirs and agricultural systems operate in such a manner today. \u201cI don\u2019t think one method replaces the other,\u201d he says. \u201cI expect that merging both will be quite beneficial.\u201d However, whether forests actually go up in smoke depends on a host of factors, including law-enforcement and fire-suppression efforts that vary from region to region. For instance, almost all fires in the Amazon are started by landowners  clearing fields and forests  for cultivation and livestock. But once the humidity drops and the vegetation dries out, those agricultural fires can run wild. \n               Ready to burn \n             The likelihood that this will happen increases as the dry season wears on, but scientists can already see El Ni\u00f1o\u2019s impacts. Morton and Randerson\u2019s team analysed rainfall measurements from gauges and satellites during the rainy season, and used data from NASA\u2019s Gravity Recovery and Climate Experiment (GRACE) satellites to provide an estimate of the cumulative water storage on land \u2014 in soils, aquifers and rivers \u2014 going into the dry season. Randerson says that the situation in the Amazon is worse than it was during the  major droughts of 2005 and 2010  and on par with 1998, after the last major El Ni\u00f1o. As well as forecasting risk in the Amazon, Morton and Randerson are tracking and mapping fires there using infrared measurements collected by the Moderate Resolution Imaging Spectroradiometer (MODIS) sensors aboard NASA\u2019s Terra satellite. The device has detected almost 12,500 fires in the Mato Grosso region of Brazil this year alone \u2014 making 2016 the third-worst year in the MODIS record, which stretches back to 2003. In the Amazon, the question now is whether Atlantic storm systems will bring much-needed relief during the dry season. Morton and Randerson have identified a link between Atlantic hurricanes and Amazon fires: when the tropical Atlantic is warm, cyclones are more likely to form, and those cyclones pull the rain bands that often flow into the Amazon northwards. The US National Oceanic and Atmospheric Administration\u2019s hurricane forecast currently calls for a neutral season, but the tropical Atlantic has been cooling, which bodes well for the Amazon. \u201cIf there were to be a shift in north Atlantic sea-surface temperatures, that could short circuit this fire forecast,\u201d Morton says. \n                     Science can map a solution to a fast-burning problem 2016-Jun-14 \n                   \n                     Epic El Ni\u00f1o yields massive data trove 2016-Mar-02 \n                   \n                     Monster El Ni\u00f1o probed by meteorologists 2016-Jan-20 \n                   \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   \n                     California agriculture weathers drought \u2014 at a cost 2015-Sep-30 \n                   \n                     California snowpack lowest in past 500 years 2015-Sep-14 \n                   \n                     Parched California 2015-Sep-02 \n                   \n                     Stopping deforestation: Battle for the Amazon 2015-Apr-01 \n                   \n                     Deforestation: Carving up the Amazon 2014-May-21 \n                   \n                     Fire forecast from NASA/UCI \n                   \n                     Global fire-emissions database \n                   Reprints and Permissions"},
{"file_id": "534600a", "url": "https://www.nature.com/articles/534600a", "year": 2016, "authors": [{"name": "Jane Qiu"}], "parsed_as_year": "2006_or_before", "body": "Cooler, cloudier summers slow snowmelt in Himalayas The Indus River, which supports the lives of 300\u00a0million people, is supplying Pakistan with less water than it did 50\u00a0years ago, particularly in the spring and summer, researchers have found. The news comes as demand for water is projected to rise sharply. The findings contradict previous predictions that the river\u2019s volume would stay the same, or even grow, as climate change kicks in, although that increase is likely to occur in the next several decades, another team has found. Danial Hashmi, a hydrologist at the Pakistan Water and Power Development Authority in Lahore, reported the river\u2019s shrinkage for the first time in February at a conference in Kathmandu. Further data from India have also shown seasonal shifts. \u201cThe Indus is certainly changing, and local communities are feeling the pinch,\u201d Shresth Tayal, a glaciologist at the Energy and Resources Institute in New Delhi, told a meeting in Columbus, Ohio, last month. The Indus flows through India, Afghanistan and China before reaching Pakistan, which it crosses from north to south. For decades, population growth and agriculture have stressed the river, which, for 10 months of the year, dries up before it reaches the sea. Because demand is set to rise by 30% by 2025, \u201cwater shortage will be the single most destabilizing factor, not only for Pakistan but the entire region\u201d, says Arif Anwar, principal researcher at the International Water Management Institute in Lahore. But since the 2009 \u2018glaciergate\u2019 scandal\u00a0\u2014\u00a0in which it emerged that the Intergovernmental Panel on Climate Change had mistakenly included in its fourth assessment report a prediction that the Himalayan glaciers would disappear by 2035\u00a0\u2014\u00a0there has been a widespread belief that water resources in the region are stable, at least for now. Research by several groups even suggested that climate change might provide some relief in the short or medium term, thanks to faster melting of the glaciers that supply the river, and increased precipitation. Hashmi\u2019s data, which are unpublished, come from a network of hydrological stations in Pakistan that span the main stem of the Indus and three of its tributaries. They show that the total water supply fell by 5% between 1962, when the hydrological stations were built, and 2014. \u201cA reduction of 5% over five decades may not seem a lot,\u201d says Walter Immerzeel, a hydrologist at Utrecht University in the Netherlands, who led one of the studies that projected an increase in water supply in the Indus ( A. F. Lutz  et\u00a0al. Nature Clim. Change    4,  587\u2013592; 2014 ). \u201cBut if the trend persists, there could be devastating implications for water resources.\u201d Hashmi\u2019s team finds that the river\u2019s shrinkage is seasonal, with a decrease in flows between April and August that exceeds a slight increase during the rest of the year. And it reports a temperature drop across the four Pakistani river basins in the summer months\u00a0\u2014\u00a0even though the region is getting warmer overall. Because snow- and glacier melt contribute to 50\u201385% of river flow in those catchments, the team suspects that cooler springs and summers result in less melt and that this can explain the shrinking river. \u201cIt\u2019s a fascinating finding,\u201d says Tobias Bolch, a glaciologist at the University of Zurich in Switzerland. He notes that it is consistent with a phenomenon known as the Karakoram anomaly, in which some of the glaciers in the region have become stable or even grown\u00a0\u2014\u00a0in contrast to most mountain glaciers globally, which are retreating rapidly in response to climate change.  If the trend persists, there could be devastating implications for water resources.  Another study presented at the February meeting suggested a possible reason for the region\u2019s cooler summers. As the overall climate warms, monsoons increasingly invade the mountain chains of the Indus upstream, where glaciers reside, says study co-author Hayley Fowler, a climate modeller at Newcastle University, UK. Her modelling work shows that when monsoons penetrate into the region and push dry westerly winds northward, summer temperatures drop. The team suspects that monsoonal clouds hovering over a region that is normally hot and dry in the summer may have a cooling effect. The limitations of climate models and the scarcity of field measurements in the region make it hard to predict how Himalayan water resources will change, says Immerzeel. However, the latest work by him and his collaborators\u00a0\u2014\u00a0which took the Pakistani data\u00a0into account \u2014\u00a0finds that things will get much worse, but only in the long term. Using state-of-the-art climate models, and assuming a scenario in which global greenhouse-gas emissions peak around 2040, the team found that the flow of water in the river system will stabilize or even increase in the next few decades\u00a0\u2014 consistent with its previous results. But once glaciers have become depleted and regional temperatures have started to rise, water scarcity will ensue: the researchers predict a 15% drop between 2071 and 2100 compared with 1971\u20132000 levels, Immerzeel says. The team has submitted a paper for review. In any case, there is a pressing need for Pakistan to boost its water-storage capacity and efficiency of water usage, says Mobin-ud-Din Ahmad, a hydrologist at the Commonwealth Scientific and Industrial Research Organisation in Canberra, Australia. Right now, its reservoirs can hold only 30 days\u2019 worth of the country\u2019s water needs \u2014 compared with 800\u00a0days in Australia and 150 days in India. \u201cIt\u2019s an extremely danger\u00adous situation, especially now, when severe droughts are increasingly common,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Trouble in Tibet 2016-Jan-13 \n                   \n                     Tibetan plateau gets wired up for monsoon prediction 2014-Oct-01 \n                   \n                     Floods spur mountain study 2013-Sep-04 \n                   \n                     Flood of protest hits Indian dams 2012-Dec-05 \n                   \n                     Tibetan glaciers shrinking rapidly 2012-Jul-15 \n                   \n                     Thawing permafrost reduces river runoff 2012-Jan-06 \n                   \n                     International Water Management Institute \n                   \n                     International Centre for Integrated Mountain Development \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20189", "url": "https://www.nature.com/articles/nature.2016.20189", "year": 2016, "authors": [{"name": "Elena Bozhkova"}], "parsed_as_year": "2006_or_before", "body": "Agencies are less likely to fund studies that straddle multiple fields, a study of Australian grants finds. Scientists have long suspected that proposals that bridge diverse disciplines of science have lower odds of being funded. A study of Australian funding decisions now suggests that this is true. The findings seem to confirm the anecdotal evidence, says Rick Rylance, a chair of Research Councils UK, a major funding agency in the United Kingdom. \u201cI would be surprised if a similar study undertaken here did not come to the same conclusions.\u201d The study is itself a multidisciplinary project, combining methods of evolutionary biology and social sciences 1 . Lindell Bromham, a biologist at the Australian National University in Canberra, and her collaborators analysed data on more than 18,000 proposals \u2014 including successful and unsuccessful ones \u2014 submitted to the Australian Research Council (ARC) Discovery Programme between 2010 and 2014. To establish each proposal\u2019s level of interdisciplinarity \u2014 something that is notoriously difficult to evaluate \u2014 the team developed its own metric, which it calls \u2018interdisciplinary distance\u2019. The measure assigns a value of between 0 and 1 on the basis of the information included in the submissions. Every proposal to the ARC has to select one or more fields from the ARC\u2019s official list, which includes 1,238 hierarchically structured field-of-research codes. Candidates must also specify the relative weight given to the various fields. \n             Diversity ranking \n           The team gave proposals that indicated only one code an interdisciplinary distance of 0; the rest were assigned a value of up to 1 depending on the relative weights of the indicated fields and on how distant the fields were from each other in the hierarchical tree. The method is similar to a biodiversity metric that takes into account the distance between species on an evolutionary tree and their relative abundance in an ecosystem. The researchers found that the higher a proposal scores on their interdisciplinary scale, the lower the probability that the ARC would fund it. The authors say that they were unable to uncover the reason. In particular, they found no correlation between a university\u2019s success rates and the number of interdisciplinary proposals it submits, Bromham says. \u201cBut we cannot rule out that there are other indirect factors we cannot test \u2014 for example, whether more experienced or successful chief investigators tend to submit fewer interdisciplinary proposals.\u201d Still, she and her co-authors suggest some possible explanations for the pattern: perhaps, the way that the grant-review process works could be intrinsically skewed against interdisciplinary projects; or independent reviewers may have a hard time understanding the value of proposals that involve fields outside their area of expertise; or perhaps such proposals just tend be of lower quality, on average, or not as convincing. Whatever the cause of the pattern, the authors think that their study should prompt funding agencies to conduct further research to work out the possible reasons. They also suggest that the metric they developed could give a way to identify highly interdisciplinary proposals that might need a special approach to evaluate. \u201cThis work is a significant outcome and one that the continuing discussion of interdisciplinary research needs,\u201d Rylance says. \n             Useful metric \n           ARC chief executive Aidan Byrne says that his agency is taking a serious look at the results. \u201cTheir work gives us an independent way of determining the degree of interdisciplinarity of a research proposal\u201d, and that could help the agency to track the progress of any changes it implements in its selection process, he says. The paper\u2019s conclusions are similar to those drawn by the US National Institutes of Health (NIH) before it launched a roadmap programme in 2004 to stimulate interdisciplinary research, says Betsy Wilder, a director of the NIH Office of Strategic Coordination.\u201cIt would be interesting to use the metric devised by Bromham  et al.  to assess interdisciplinarity of applications versus funded projects in the NIH portfolio and to determine whether the ratio has changed over the past ten years.\u201d Vincent Larivi\u00e8re, an information scientist at the University of Montreal in Canada, warns that assessing the level of interdisciplinarity through a principal investigator\u2019s choice of field codes could be misleading. \u201cThese self-declared disciplines might serve more as signalling devices rather than actual markers of the content of the proposal,\u201d he says. Using the cited references in grant proposals would give a more accurate picture, he says, in part because \u201cthe act of citing\u201d is something that is better understood. The authors say that it would be interesting to apply their techniques to data from other funding agencies. A 2015  review of research  commissioned by the Higher Education Funding Council for England showed that research publications that straddled disciplines tended to have a lower citation impact. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "nature.2016.20191", "url": "https://www.nature.com/articles/nature.2016.20191", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Panel recommends scrapping proposed changes to 'Common Rule' on human-subjects research. The US government\u2019s proposed overhaul of regulations that govern research with human subjects is flawed and should be withdrawn, an independent advisory panel said today. The regulations, which are known collectively as the \u2018Common Rule\u2019, address ethical issues such as informed consent and storage of study participants\u2019 biological specimens. In its report on 29 June 1 , the US National Academies of Sciences, Engineering and Medicine said that  the government\u2019s proposed changes  are \u201cmarred by omissions and a lack of clarity\u201d, and would slow research while doing little to improve protections for patients enrolled in studies. Instead, the panel recommends that the government appoint an independent commission to craft new rules for such research. The Common Rule, which was introduced in 1991, is based on the Belmont Report, a 1978 document that lays out principles for ethical research with humans, such as minimizing patient harm and maximizing the benefit of such research to society. Over time, achieving such goals has become more complex because of technological advances \u2014 such as the rise of DNA identification and shared databases, which can make it  harder to maintain patient privacy . Larry Faulkner, president emeritus of the University of Texas at Austin and chair of the committee that wrote the academies\u2019 report, concedes that updating the Common Rule is a difficult task, no matter who takes the lead. \u201cSo much has happened,\u201d he says. \u201cThere are a wide range of issues that just could not have been comprehended\u201d when the regulations were drawn up. \n               Concerns about red tape \n             The changes  proposed in September  by the US Department of Health and Human Services (HHS) attempt to address concerns that have arisen since the Common Rule took effect. For instance, the HHS reforms would allow a multicentre clinical trial to rely on a single, central ethics-review board \u2014 rather than maintaining a review board at each participating institution, as the Common Rule now requires. The HHS proposal would also require participants\u2019 consent to use stored samples, such as blood or tissue, for future research. Even if identifying information is stripped from the samples, the HHS says, it is fairly simple to re-identify people on the basis of their DNA. But the US academies' panel says that introducing the new consent requirements would slow research unnecessarily because little harm is likely to come to a person as a result of the use of stored biospecimens. And if the specimens are de-identified, the extra consent forms themselves would further link the specimens to the person\u2019s name and therefore increase the risk that the person would be identified. The report also says that the HHS has not been sufficiently clear about how much access researchers would have to stored specimens, and what types of human-subjects study would be exempt from the Common Rule. \n               Back to the drawing board? \n             The HHS is reviewing more than 2,100 responses to its proposal, all of which were submitted during a 90-day public comment period that has already concluded. Many of these comments were critical of the HHS reforms, according to analysis by the Council on Government Relations, a non-profit group in Washington DC. Patients and clinicians alike felt that the changes to the Common Rule would slow the development of cures, and limit research. \u201cIt's really not just a burden for scientists\u201d alone, says Lisa Nichols, director of research and regulatory refor m for the COGR. But instead of altering the government proposal, the US academies' panel says that it should be scrapped and an independent commission should be created to recommend reforms to the Common Rule. \u201cThis is a total smack-down,\u201d says Ellen Wright Clayton, a bioethicist and lawyer at Vanderbilt University in Nashville, Tennessee, of the academies' report. Although she agrees that the Common Rule could use an update, she thinks that the HHS\u2019s proposal is \u201cfundamentally flawed\u201d in the monetary and regulatory burdens that it would impose. \u201cThis is just divorced from the reality researchers are facing,\u201d Clayton adds. The HHS has not said when it plans to release a final version of the Common Rule reforms. In a statement sent to  Nature , an agency spokesperson said that the government is still mulling both the public's comments and the report. She adds that the proposal comes after \u201cmany years of work\u201d, and that starting over would require many more. \n                     US agencies plan research-ethics overhaul 2015-Sep-03 \n                   \n                     US agency updates rules on sharing genomic data 2014-Sep-01 \n                   \n                     Delays in updates to ethics guidelines for research spark concern 2013-May-07 \n                   \n                     Report from the National Academies of Sciences, Engineering and Medicine \n                   \n                     US government's proposed changes to the Common Rule \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20183", "url": "https://www.nature.com/articles/nature.2016.20183", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Global regulation of chlorine compounds is giving the atmosphere time to heal, even as volcanic eruptions interfere. It's the beginning of the end for the hole that forms in the ozone layer over Antarctica every Southern Hemisphere spring, letting in dangerous ultraviolet light. An analysis led by a pioneer in the field shows that, on average, the hole is now staying smaller and forming later in the year than it did in 2000. The 1987 global treaty called the Montreal Protocol sought to reduce the ozone hole by banning chlorofluorocarbons, chlorine-containing chemicals \u2014 used as refrigerants in products such as air conditioners \u2014 that accelerated ozone loss in the stratosphere. The study shows  that it worked . \u201cWe as a planet have avoided what would have been an environmental catastrophe,\u201d says Susan Solomon, an atmospheric scientist at the Massachusetts Institute of Technology in Cambridge. \u201cYay us!\u201d She and her colleagues report the finding on 30 June in  Science 1 . \n             Evidence of healing \n           Other scientists have found hints that the ozone hole is on the mend: a 2008 study 2  found that the ozone layer\u2019s rate of decline had begun to slow, and a 2011 study 3  suggested that ozone levels had begun to rebound. A  2014 assessment by the World Meteorological Organization  found that healing had begun at high elevations in mid- and low latitudes. The latest work is another powerful example, says Birgit Hassler, an atmospheric scientist with the Cooperative Institute for Research in Environmental Sciences in Boulder, Colorado. \u201cIt is a very clear and unique piece of evidence that indeed the ozone hole is healing,\u201d she says. October 2015 saw one of the largest Antarctic ozone holes on record \u2014 with an area of 28.2\u00a0million square kilometres at its peak \u2014 which raised questions about whether the hole was really on the mend. But there was evidence that large volcanic eruptions could affect the chemistry of the ozone layer, so Solomon\u2019s team decided to investigate. The researchers found that the  Calbuco volcano  in Chile, which had erupted in April 2015 and filled the stratosphere with sulfur particles that triggered ozone-destroying reactions, was partly to blame for the large hole. The scientists\u2019 finely tuned climate model also found that the ozone hole over Antarctica in the month of September shrank by 4.5 million square kilometres, on average, between 2000 and 2015. September is important because it is when sunlight fully returns to the Antarctic after winter, initiating chemical reactions in the atmosphere that eat away at the ozone layer. \u201cThe trend is significant, and it\u2019s what you expect from chlorine chemistry,\u201d Solomon says. \n             A welcome change \n           Until now, most scientists had focused on October,  the month when the ozone hole is biggest . But Solomon says that the fingerprints of healing are most obvious in September: the hole is now opening up an average of ten days later than it used to. Measurements taken from weather balloons over Antarctica also show that ozone recovery is happening at the altitudes predicted by the team\u2019s model. \u201cIf you\u2019re getting the depth right and the shape right and the size right and the timing right, you start to feel very confident,\u201d says Solomon. The September trend is convincing, says Sophie Godin-Beekmann, an atmospheric chemist at the French National Centre for Scientific Research in Paris. But she would like to see more years included in the analysis. It will take many decades for the hole to heal completely. \u201cThe ozone hole remains nearly as potent as ever and is not expected to disappear before the end of the century, with all its implications for human and ecosystem health,\u201d says Michaela Hegglin, an atmospheric scientist at the University of Reading, UK. The smaller  Arctic ozone hole  over the North Pole, which is more variable than its southern counterpart, has not yet shown a trend towards healing. For Solomon, who has been working on Antarctic ozone loss since the 1980s 4 , the turnaround is a welcome change. \u201cTo see it getting better is really quite amazing,\u201d she says. \n                   Ozone-hole treaty slowed global warming 2013-Nov-10 \n                 \n                   Ozone loss warmed southern Africa 2013-Oct-13 \n                 \n                   First signs of ozone-hole recovery spotted 2011-May-16 \n                 \n                   Atmospheric science: Fixing the sky 2009-Aug-12 \n                 \n                   Antarctic ice threatened by ozone-hole recovery 2008-Apr-29 \n                 \n                   Blog: Ozone recovery helped by warming climate \n                 \n                   Ozone Hole Watch \n                 \n                   Montreal Protocol \n                 \n                   WMO 2014 ozone assessment report \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20192", "url": "https://www.nature.com/articles/nature.2016.20192", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Despite well-known problems with reproducibility, a common component of biomedical research often remains unchecked. Nearly one-third of junior scientists spend no time validating antibodies, even though accurate results depend on these reagents working as expected, according to the results of a survey reported today in  BioTechniques 1 . \u201cThis is quite alarming,\u201d says Matthias Uhl\u00e9n, a protein researcherat the Royal Institute of Technology in Stockholm who heads an international working group on antibody validation, but who was not directly involved in the survey. Poorly performing antibodies can give false positive signals if they bind to proteins other than their intended targets, and false negative signals when they fail to bind to the correct protein. Such problems have led scientists and journals to retract papers, and have caused researchers to reach invalid and highly disputed conclusions. Individual laboratories have reported that they  have wasted years of work , thousands of human samples, and hundreds of thousands of dollars when antibodies did not work as expected. Yet more than half of the nearly 400 biomedical researchers who answered the survey\u2019s online questions about how they assess antibodies said they had not received specific training on validation. \n             No time \n           The survey was carried out by the Global Biological Standards Institute (GBSI), a non-profit group in Washington DC devoted to improving the use of reagents in biomedical experiments. Last October, a separate GBSI survey showed that 52% of researchers failed to authenticate the identity of cell lines, which can easily become contaminated with alien fast-growing cells. By contrast, 70% of respondents in the more recent survey said that they validate antibodies purchased from commercial suppliers. But Leonard Freedman, president of the GBSI, thinks that unvalidated antibodies  probably represent a more significant problem . Because antibodies are so widely used in experiments, he says, the actual number of researchers who do not validate antibodies is probably much higher than those who don\u2019t validate cell lines. What\u2019s more, the gap in practices between senior researchers and junior researchers was striking. Whereas 76% of researchers with more than 10 years\u2019 experience reported validating commercial antibodies, only 43% of those with 5 or fewer years of experience did. The most common reason given was the time required to do so. \n             \u2018Two-headed monster\u2019 \n           Validating antibodies is more complex than cell authentication, says Freedman. Whether or not an antibody works depends on the particular assay. For example, some antibodies detect a protein in the \u2018denatured\u2019 state that is found in cell preparations, but not in the protein\u2019s natural, folded state \u2014 or vice versa. And an antibody that functions well for one type of tissue or preparation might produce false signals in other contexts. One-third of respondents in the GBSI\u2019s survey said that they did not apply different validation procedures depending on the assay. Freedman says that reproducibility problems attributed to antibodies can be blamed on \u201ca two-headed monster\u201d of poor antibodies and poor training. Both are fuelled by lack of clear, commonly accepted guidelines about what is required to validate an antibody, and what information companies should supply about the reagent\u2019s performance. This is a problem that Freedman hopes will soon be solved. In September, his group is hosting  a workshop at Asilomar  in California, the site made famous for producing guidance on recombinant DNA. The meeting will bring together antibody suppliers and users, as well as funders and journals, he says. \u201cWe are going to lock the doors and not let anyone out until we have elucidated a set of practical, user-friendly validation standards.\u201d \n                   Biomedical researchers lax in checking for imposter cell lines 2015-Oct-12 \n                 \n                   Reproducibility crisis: Blame it on the antibodies 2015-May-19 \n                 \n                   Reproducibility: Standardize antibodies used in research 2015-Feb-04 \n                 Reprints and Permissions"},
{"file_id": "534602a", "url": "https://www.nature.com/articles/534602a", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Users urge caution in revamp of service at the heart of physics. A multimillion-dollar funding drive is being readied to transform arXiv, the vastly popular repository to which physicists, computer scientists and math\u00adematicians flock to share their research preprints openly. But the results of an enormous user survey published this week suggest that researchers are wary of drastic changes to a site that has become an essential part of the infrastructure of modern science. Last year, the site served up around 139\u00a0million downloads, and it now holds more than 1.1\u00a0million free papers. But it is being sustained by fragile code, donations from libraries and a charitable foundation and the good will of about 150 or so volunteer moderators, says the site\u2019s programme director, Oya Rieger. With its 25th anniversary approaching in August, arXiv\u2019s advisory teams of scientists and librarians are considering a plan that involves raising US$2.5\u00a0million to $3 million to modernize the platform. That will sit on top of its $1-million annual budget for staff and servers. To attract support from donors, arXiv\u2019s operator, Cornell University Library in Ithaca, New York, is hoping to come up with a \u201ccompelling vision\u201d, Rieger says. Scientists seem to love arXiv: 95% of the survey\u2019s 36,000 respondents said that they were very satisfied or satisfied with it. And most want to keep it just the way it is, although perhaps with some modernization. They were enthusiastic about the possibility of tweaks to improve the site\u2019s search functions, and about allowing references to be hyperlinked directly to research papers, for example (see \u2018What do arXiv users want?\u2019). Some wanted the site to broaden into new subject areas, such as chemistry\u00a0\u2014\u00a0although such expansion would require the recruitment of scientists who are willing to moderate the manuscripts, notes David Morrison, chair of arXiv\u2019s scientific advisory board. \n               Social forum \n             When asked whether arXiv should embark on more transformational changes, respondents gave mixed answers. In particular, some questions focused on whether it should develop into a social forum that allows scientists to comment on papers or leave ratings. A few social-media sites have already been built around the repository\u00a0for just such purposes \u2014\u00a0such as SciRate and Arxiv Sanity Preserver\u00a0\u2014 and some argue that the site itself should begin to incorporate such functionalities. \u201cArXiv should be more dynamic\u00a0\u2014\u00a0allowing readers to filter the wheat from the chaff,\u201d says Al\u00e1n Aspuru-Guzik, a quantum chemist at Harvard University in Cambridge, Massachusetts. But one-third of respondents said that this wasn\u2019t important or that arXiv shouldn\u2019t be doing it. Only 34% voted in favour of such changes. That response points to a tension between researchers who want to see the site incorporate aspects of open review, and those who want it to stick to its core mission of allowing rapid exchange of scholarly papers, says Rieger. There were hints of a generational divide, with those aged under 30 more in favour of allowing comments. But even those who wanted a more social site said that they were keen to avoid a commenting free-for-all, Rieger adds. \u201cThe message was more or less \u2018stay focused on the basic dissemination task, and don\u2019t get distracted by getting overextended or going commercial\u2019,\u201d says Paul Ginsparg, a physicist at Cornell University who launched arXiv in 1991 as a pre-World-Wide-Web-era bulletin board. \n               Checks and balances \n             Ginsparg notes, however, that arXiv\u2019s users sometimes don\u2019t know what they want until they get it. Researchers said that they liked the quality control now built into the site, including checks of papers for text overlap with other reports (potential plagiarism), classifying papers into the correct subject areas and rejecting work that has little scientific value. \u201cThese are for the most part things that users never actually requested,\u201d Ginsparg says. In the past 5 or so years, he has introduced automated machine-learning code that filters through the more than 9,000 papers submitted each month and flags up potential issues to human moderators. In September, arXiv\u2019s advisory boards will meet to draw up a road map for progress and to discuss how to get the funds needed to modernize the site. The site is currently sustained by member institutions (mainly libraries, but also some research funding agencies) and by the Simons Foundation in New York. But some discussions have been held with other potential contributors such as the US National Science Foundation. It is also possible that publishers or scientific societies could be asked to contribute, says Rieger. She adds that the site will need to be careful to remain objective. \u201cWe want to make sure that arXiv continues to be a neutral, trusted service,\u201d she says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @Richvn \n               \n                     ArXiv rejections lead to spat over screening process 2016-Jan-29 \n                   \n                     Open journals that piggyback on arXiv gather momentum 2016-Jan-04 \n                   \n                     Leading mathematician launches arXiv 'overlay' journal 2015-Sep-15 \n                   \n                     The arXiv preprint server hits 1 million articles 2014-Dec-30 \n                   \n                     arXiv \n                   \n                     SciRate \n                   \n                     arXiv Sanity Preserver \n                   \n                     GitXiv \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20193", "url": "https://www.nature.com/articles/nature.2016.20193", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "A week on from the vote, reassurance, rage and racism all feature. In the week since UK voters chose to leave the European Union, the consequences for science continue to play out. Reports have surfaced that some EU scientists are reconsidering offers to work in the United Kingdom, and that British scientists could start being cut out of grant applications made with colleagues on the continent. And contributing to the confused state of UK politics, Boris Johnson \u2014 a prominent \u2018Leave\u2019 campaigner \u2014 announced on 30 June that he was dropping out of the race to replace David Cameron as prime minister. Anecdotal reports of racist incidents linked to the referendum vote have also emerged across the nation. At  an event in Parliament  on 28 June organised by the Royal Society of Biology, Robert Parker, chief executive of the Royal Society of Chemistry in Cambridge, said that some of his staff had been told on the street to \u201cgo home\u201d after the Brexit vote. On Twitter, George Freeman, UK minister for life sciences, called Parker's report \u201c appalling and totally unacceptable \u201d. \n             Fears of fracture \n           In the  wake of the vote , scientists immediately voiced  fears over jobs, funding and collaborations . The nation remains a full member of the European Union, and will continue to be one as it negotiates an exit. But is in unclear how long the break-up process will take, and the uncertainty is already causing problems. Robert Lechler, president of the Academy of Medical Sciences and a medical researcher at King\u2019s College London, said in a press conference on 29 June that three \u201ckey recruitments\u201d that are close to being finalized at King\u2019s are \u201call now at risk\u201d. This, he said, was \u201cbecause these are people from continental Europe who are questioning whether they are prepared to take a risk on coming to the United Kingdom, entirely on the basis of this referendum vote\u201d. Lechler would not provide names, but said that all three were due to take on senior roles in biomedical engineering and neuroscience. The referendum vote \u201cis the most serious threat and challenge to UK research in my lifetime,\u201d he said at the press conference, which took place at the Science Media Centre in London. \u201cWe\u2019re not going to stop brilliant people from coming to work in our universities and science institutes,\u201d UK science minister Jo Johnson said in a speech on 30 June. After the speech he told  Nature  that \u201cEU academics and students are welcome here, and their rights are unaffected as we stand today.\u201d But he would not say whether they would be able to remain under the same conditions in future. \u201cThere\u2019s a negotiation that will take place, and I can\u2019t pre-empt any of that,\u201d he said. Johnson\u2019s post will hang in the balance with the rest of the government in September, when Cameron will step down and a new prime minister can appoint his or her own team. Both politicians campaigned on the \u2018Remain\u2019 side, but after the referendum, Johnson supported the prime-minister candidacy of pro-Leave Boris Johnson, who is his brother. Now that Boris is out of the race, Jo\u2019s political future \u2014 including his ability to follow up on his promises to the scientific community \u2014 is more uncertain. But in the press conference \u2014 which had been scheduled long before the vote \u2014 he said that the government still plans to press ahead with a  major reorganization of research funding . \n             Nationals shunned \n           In his speech, the science minister also asked to be told of any cases of consortiums that might avoid the inclusion of UK partners into grant proposals because of the uncertainty over future EU membership \u2014 which he regards as discriminating against UK nationals. Johnson said that had already spoken to EU research commissioner Carlos\u00a0Moedas \u201cto make him aware of my vigilance on this question\u201d. But he added that so far, the evidence he has is only anecdotal. One attendee at the speech said that this was already happening. Andrew Graham, technical director of OC Robotics in Bristol, UK, which makes mechanical-arm technologies, later told  Nature  that he expected Italian colleagues to stop considering a potential UK partner in a funding proposal for the EU Horizon 2020 programme. \u201cGiven that lack of clarity,\u201d says Graham, \u201cwhile consortia are being built at the moment, for current calls and future calls I can see there is a rational reason for not selecting the British partner if there\u2019s an option.\u201d Earlier in the week, Faisal Islam, political editor of Sky News,  said on Twitter  that a member of the UK parliament had told him of \u201cUK academics being asked to take [their] name off funding applications for joint research grants by European colleagues post Brexit\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   UK scientists in limbo after Brexit shock 2016-Jun-28 \n                 \n                   Brexit vote highlights lack of leaving plan 2016-Jun-28 \n                 \n                   Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                 \n                   How scientists reacted to the Brexit 2016-Jun-24 \n                 Reprints and Permissions"},
{"file_id": "535017a", "url": "https://www.nature.com/articles/535017a", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Cytomegalovirus is a much greater global problem than Zika. A virus is killing hundreds of babies in the United States each year, and leaving thousands with debilitating birth defects, including abnormally small heads and brains. This is not the Zika virus. It is a common and much less exotic one: cytomegalovirus (CMV). Now, as the eyes of the media and health officials focus on the spread of Zika in the Americas and beyond, many researchers and advocates hope that funders and health agencies will at last pay more attention to a much greater global problem \u2014 the millions of babies born year in, year out, with often-serious birth defects. \u201cBirth defects are not high on the public-health agenda,\u201d says Stanley Plotkin, a vaccine researcher at the University of Pennsylvania in Philadelphia who in the 1970s developed the current vaccine against rubella (German measles). A 1960s rubella pandemic caused tens of thousands of birth defects in the United States alone. \u201cZika is an opportunity,\u201d he says\u00a0\u2014 to raise the profile of birth defects among research funders and public-health agencies, and to accelerate efforts to develop a CMV vaccine. The World Health Organization (WHO) estimates that, annually, more than a quarter of a million babies worldwide die shortly after birth from congenital anomalies, and many more are born with serious defects. The causes are many\u00a0\u2014 some known, some not. A global focus on reducing child mortality has meant that severe disabilities in children are a lower public-health priority, says Anita Kar, a specialist in congenital abnormalities at the University of Pune in India. CMV is a poster child for the problem\u00a0\u2014 and with Zika so much in the news, scientists and advocacy groups are voicing frustration and trying to seize the moment. The US National CMV Foundation is running information campaigns  comparing and contrasting Zika with CMV . It is lobbying politicians to build on the mandates enacted in several states for public-health authorities to produce outreach material, including billboards on sides of buses, and to do CMV tests for all infants with hearing difficulties. \u201cZika has become a way to open up conversations about CMV,\u201d says Janelle Greenlee, a co-founder of the CMV foundation, who lost one daughter to congenital CMV and has another, the daughter\u2019s twin, with serious hearing loss and cerebral palsy. CMV infections in adults, children and infants are mostly asymptomatic and harmless, but the virus is much more dangerous\u00a0\u2014 often lethal\u00a0\u2014 to the fetus. Worldwide, around 1\u00a0in 100 to 500 babies are born with congenital CMV, and of the 10\u201320% who show symptoms, about 30% will die. Survivors often have liver, lung or spleen damage, or neurological problems including developmental disability or loss of hearing or sight. CMV\u2019s link to birth defects has been known since the 1950s\u00a0\u2014 yet a 2012 survey found that only 13% of US women and 7% of men had heard of congenital CMV ( M. J. Cannon  et al.   Prev. Med.   54,  351\u2013357; 2012 ). Low awareness is deadly, says Gail Harrison, an infectious-disease researcher in CMV at the Baylor College of Medicine and the Texas Children\u2019s Hospital, both in Houston. There is no vaccine, so precautions \u2014 handwashing and avoiding contact with children\u2019s saliva and urine \u2014 are the only defence. Harrison works closely with patient groups to promote awareness, but says that she struggles with the inertia of state and federal agencies in helping to get these messages across. The administration of US President Barack Obama has requested more than US$1\u00a0billion for research and control measures for Zika, and the website of the US Centers for Disease Control and Prevention (CDC) is awash with information and advice on that virus, she notes. But the more modest amount of information on CMV has to be actively searched for. Leading health experts and the CDC expect that Zika in the United States will be limited to small, localized outbreaks in southern states where  Aedes aegypti , the mosquito that transmits the virus, is present during warm parts of the year. That prediction is based on the pattern of past US outbreaks of dengue and chikungunya, two other diseases carried by the same mosquito. For the United States, says Plotkin, \u201cthere is little doubt that CMV is a bigger problem than Zika\u201d. Contributors to birth defects include genetic abnormalities as well as many more preventable factors, such as infectious diseases, medications, diet and environmental chemicals. But the causes of almost three-quarters are unknown. Better training in birth-defects epidemiology is urgently needed, in particular in developing countries, says Kar. Such research is difficult, requiring population-scale surveillance registries, and often relies on questionnaires that ask mothers of children with congenital abnormalities to try to recall past exposures\u00a0\u2014 a process susceptible to inaccuracies. To improve matters, pan-European and US birth-defect registries are increasingly trying to match pregnancy outcomes with vast databases of histories of prescribed drugs, local water- and air-pollution levels, and other factors. Prescription histories are especially important because pregnant women are usually excluded from clinical trials, and so little may be known about the safety of medicines for fetuses. But many poorer countries lack even basic surveillance. In the case of neural-tube defects such as spina bifida, for example, a global review published in April found that 120 of the WHO\u2019s 194 member states had no prevalence data ( I.Zaganjoretal.PLoSONEhttp://doi.org/bkrj;2015 ). \u201cRegistries are urgently required,\u201d says Kar. See Editorial  page 8 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @DeclanButlerNat \n               \n                     Use Zika to renew focus on birth-defect research 2016-Jul-05 \n                   \n                     Human embryos grown in lab for longer than ever before 2016-May-04 \n                   \n                     Zika highlights role of controversial fetal-tissue research 2016-Mar-30 \n                   \n                     Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                   \n                     Pregnancy: Prepare for unexpected prenatal test results 2015-Jun-03 \n                   \n                     Prenatal-screening companies expand scope of DNA tests 2014-Mar-04 \n                   \n                     Pollutants' role in birth defects becomes clearer 2011-Jul-18 \n                   \n                     CDC birth defects site \n                   \n                     EUROCAT \n                   \n                     WHO Congenital anomalies \n                   \n                     National CMV Foundation \n                   Reprints and Permissions"},
{"file_id": "nj7610-190a", "url": "https://www.nature.com/articles/nj7610-190a", "year": 2016, "authors": [{"name": "Amber Dance"}], "parsed_as_year": "2006_or_before", "body": "Federal government will create 1,000 professorships. German chancellor Angela Merkel and state prime ministers have signed a \u20ac1-billion (US$1.1-billion) agreement to fund 1,000 new tenure-track professorships, in the hopes of retaining and recruiting top academic talent in the nation. According to the  Nachwuchspakt  ('junior pact'), as the contract is known, the federal government will pay young professors as they work towards tenure, after which state-funded universities will assume financial responsibility. \u201cIt's the first time that the federal government, as far as I know, is investing such a lot of money into the careers of young scientists,\u201d says Christian Sch\u00e4fer of the German Academic Exchange Service in Bonn. The agreement, signed on 16 June, reflects an effort to improve the job situation for young researchers in Germany, where tenure-track positions are rare. Scientists typically work in temporary posts until they are eligible for a faculty spot \u2014 usually not until their early 40s, at which point it is difficult to start a non-academic career. Because of the perceived insecurity, there are great minds who leave the academic world. Sch\u00e4fer and many young researchers say that the agreement is a positive step \u2014 but that more needs to be done. \u201cIt's better than nothing,\u201d says Andreea Scacioc, a structural biologist in G\u00f6ttingen, who earned a PhD in 2014. \u201cBut it's too little.\u201d Every year, about 28,000 PhD and medical students graduate from German universities. There are about 25,000 actively employed professors, according to the German Association of University Professors and Lecturers (DHV). The Society of Junior Professors, a national advocacy group for junior academics, has argued that tenure track ought to be the default entry-level post for junior academics, and DHV officials estimate that 7,500 more professorships are needed to offer young academics a better future. The pact will run from 2017 to 2032 and involve two major hiring waves, in 2017 and 2019. Universities must apply for funds to set up these professorships. The federal government will fund the first six years of a professor's position, as well as two extra years for those who earn tenure. But researchers will still need to obtain grant funding because the pact funds will mainly cover their salary. Fifteen percent of the total money will be set aside for universities to develop research career paths \u2014 for example, by instituting other kinds of permanent positions. German universities tend to hire few permanent professors. Those who are hired run a 'mini-department', says Jakob Macke, a computational neuroscientist at the Max Planck-affiliated neuroscience-research centre Caesar in Bonn. The general route to independence has been to perform a  Habilitation  \u2014 a sort of second thesis \u2014 under a professor's guidance, which qualifies a postdoc for a professorship. Starting in the late 1990s, German institutions introduced various sorts of junior professorships and group-leader positions. These allow young researchers to skip the  Habilitation  and run their own labs, but they are temporary \u2014 and many researchers still do a  Habilitation . \u201cBecause of the perceived insecurity, there are great minds who leave the academic world,\u201d says Jens P\u00f6ppelbu\u00df, a junior professor of industrial services at Germany's University of Bremen. Other talented scientists decamp for nations that offer more direct career paths. The  Nachwuchspakt  arose in part from changes to Germany's 2005 Excellence Initiative, which funded graduate schools; 'clusters of excellence' that offered international-scale training and research facilities; and competitive research programmes. The original initiative will expire in 2017, and the new version \u2014 also signed on 16 June \u2014 will drop its focus on graduate schools and early-career scientists, leaving a hole that the Nachwuchspakt will fill. But Scacioc points out that the pact does not set a quota for hiring women. She fears that it could perpetuate the status quo in which men are more likely to secure professorships, thanks in part to their winning more prestigious awards. Requirements for hiring and tenure will need to be clear and transparent to keep the process fair and to ensure that the best candidates get the positions, says Jule Specht, a personality psychologist at the Free University of Berlin. \u201cMoney from the federal government can only provide some incentives,\u201d says P\u00f6ppelbu\u00df. \u201cAll the different federal states and all universities must commit themselves to establishing more reliable and predictable career paths in academia.\u201d \n                     Germany's researchers welcome \u20ac5-billion funding boost \n                   \n                     Academia: The changing face of tenure \n                   \n                     Germany's 'junior professor' fails to germinate \n                   \n                     Supply-side academics \n                   \n                     New competition in Germany \n                   \n                     German Academic Exchange Service \n                   \n                     German Association of University Professors and Lecturers \n                   \n                     Association of Junior Professors \n                   \n                     DFG\u2014Excellence Initiative \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20220", "url": "https://www.nature.com/articles/nature.2016.20220", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "The charity hopes other funders will follow a similar model. One of the world\u2019s largest biomedical charities, the Wellcome Trust in London, will launch an open-access publishing venture later this year. The idea behind  Wellcome Open Research  is to allow Wellcome grant recipients to publish their findings more quickly and to create a model that, according to the charity, other funders might adopt in future. Management of the venture, which Wellcome announced on 6 July, will be contracted out to  F1000Research , an open-access publishing platform. The platform publishes manuscripts and data sets within days of their submission, after a quick sanity check by its in-house editors, and then arranges post-publication peer review. F1000Research  charges for its service per article  on the basis of word length , with a US$150 fee for articles of up to 1,000 words, $500 for 1,000\u20132,500 words and $1,000 for longer articles. Wellcome will pay these fees on behalf of its grantees. Articles that pass peer review will appear in abstract databases such as PubMed and in the PubMed Central and Europe PMC open-access repositories, with the citation  Wellcome Open Research . \n             Open review \n           Under the  F1000Research  system, authors choose the reviewers of their paper, whose names and reviews are published on the site alongside the article. These are advantages, says Robert Kiley, Wellcome\u2019s Head of Digital Services. \u201cThe transparent peer-review process provides authors with the ability to choose referees most appropriate to their subject, and whose comments they can subsequently use or cite to demonstrate the quality of their work,\u201d he says. Will the arrangement foster a system in which researchers choose reviewers who are likely to go easy on their work? Kiley says that making the authors of the reviews public guards against this possibility. Some have  questioned the rigour  of the  F1000Research  review process, noting that reviews tend to be short and positive. But Kiley, who calculates that reviews of research articles published using  F1000Research  are 400 words long on average, rebuts these criticisms: \u201cIt doesn\u2019t take very many words to explain that something is either seriously problematic or largely fine,\u201d he says. \u201cFurthermore, the fact that the referees\u2019 name and referee report are public means the referees are more careful and conscientious to back up their comments because they know that they will be publicly judged.\u201d Kiley hopes that other funders will follow suit, and over time, that the ventures could merge into one big, international platform. He says this would be in line with a desire from funders to shift away from individual journals and  controversial metrics such as the impact factor . \u201cThe expectation is that this, and other similar funder platforms that are expected to emerge, will ultimately combine into one central platform that ensures that assessment can only be done at the article level,\u201d he says. \n                   Dutch lead European push to flip journals to open access 2016-Jan-06 \n                 \n                   All that glitters 2015-Apr-07 \n                 \n                   UK funder explains clamp-down on open access 2014-Apr-09 \n                 \n                   Particle-physics papers set free 2014-Jan-07 \n                 \n                   Open access: The true cost of science publishing 2013-Mar-27 \n                 \n                   F1000 launches fast, open science publishing for biology and medicine \n                 \n                   The future of publishing \n                 \n                   Wellcome Open Research \n                 \n                   Wellcome Trust \n                 \n                   F1000Research \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20197", "url": "https://www.nature.com/articles/nature.2016.20197", "year": 2016, "authors": [{"name": "Elena Bozhkova"}], "parsed_as_year": "2006_or_before", "body": "Scientists from low-income backgrounds face barrier to entry, but no pay discrimination. Young people with parents in highly paid professions still take most of the jobs in science, an analysis of UK labour data suggests. But once they enter a science career, people from different backgrounds tend to earn similar wages, according to the study. Sociologists have chronicled multiple ways in which the science community does not reflect the diversity of society \u2014 including imbalances in gender, race and ethnicity. Studies often find, for example, that women and minorities face a 'glass ceiling' that prevents them from advancing to the top levels of their careers. Now, Daniel Laurison and Sam Friedman, two sociologists at the London School of Economics, have looked at scientists through the prism of socioeconomic class, looking for evidence of a barrier to entry, or 'glass floor'. Their study, which appeared on 23 June in  American Sociological Review 1 , looked at data from the UK Labour Force Survey collected in from July to September 2014, when the survey\u2019s questionnaire for the first time included a question about a parental occupation. Their analysis included almost 44,000 people between the ages of 23 and 69, around 5,000 of whom were high-status professionals, including 256 scientists. Laurison and Friedman found that if people from a working-class background get a high-paying professional job \u2014 such as law, finance and medicine \u2014 they earn about 17% less than people from privileged backgrounds. But for those in science professions, there is no difference in earnings. Still, the study found that only 15% of scientists in the United Kingdom come from a working-class background. \n             Education analysis \n           Louise Ashley, a sociologist at Royal Holloway, University of London, says that the findings support her suggestions that class tends to matter more in fields where knowledge is less objective. Educational advantages do pose barriers to entry into science, she says. \u201cBut where these barriers are overcome, we might expect the role of social class to fade in relation to objectively measured expertise.\u201d For Malcolm Brynin, a sociologist at the University of Essex in Colchester, UK, the results are not surprising, given that the higher-education sector experiences a glass-floor problem. For example, a study commissioned in 2013 2 , by the Sutton Trust \u2014 a non-profit organization that focuses on educational inequality \u2014 showed that in Australia, England and elite public colleges in the United States, children with professional parents are about three times more likely to enter a high-status university than those with working-class parents. But Brynin also points out that the numbers in the study are small, which makes its results less reliable. \u201cThis problem is compounded by the fact that occupations are recorded with a fairly large amount of error,\u201d Brynin says. Friedman says that he and Laurison have recently repeated their analysis with twice as many data, adding statistics from 2014 and 2015, and found highly similar results. In follow-up work, the authors also looked at data from the French Labour Force Survey. \u201cThe science-specific results in both France and the United Kingdom are strikingly similar,\u201d Friedman says. Reprints and Permissions"},
{"file_id": "nature.2016.20205", "url": "https://www.nature.com/articles/nature.2016.20205", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA mission will study the gas giant\u2019s origin and evolution. In the end, it went flawlessly. NASA\u2019s Juno spacecraft slipped into orbit around Jupiter last night, becoming the first mission in 21 years to visit the giant planet. The  US$1.1-billion Juno  threaded the needle between the searing radiation belts that surround the planet and its turbulent cloud tops. An engine burn slowed the robotic craft, which launched in August 2011, allowing it to be captured into an orbit around Jupiter that will take the craft soaring over the planet\u2019s poles once every 53.5 days. Mission controllers at NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California, burst into cheers and applause at 8:53 p.m. local time on 4 July, when they received a signal from Juno, indicating that the burn had gone as planned. At its closest approach, the spacecraft hurtled just 4,500 kilometres above Jupiter\u2019s clouds, at a speed of 58 kilometres per second. In the coming days, engineers will begin to check out the spacecraft\u2019s nine instruments, turning them on to see how they perform near Jupiter. \u201cWe\u2019ve been flying in interplanetary space for five years,\u201d says Tim Gasparrini, Juno\u2019s programme manager at Lockheed Martin Space Systems in Littleton, Colorado, which built the spacecraft. \u201cNow we need to learn how to fly in planetary space.\u201d \n             Surprises ahead \n           The next big milestone comes on 27 August, when Juno whizzes past Jupiter on its next close approach. \u201cThat\u2019s when we\u2019ll get our first really good look at Jupiter and learn how it will surprise us,\u201d says Steven Levin, Juno project scientist at JPL. \u201cWe will have all our eyes and ears open,\u201d adds Scott Bolton, the mission\u2019s principal investigator at the Southwest Research Institute in San Antonio, Texas. After that, Juno will fly a second 53-day orbit before burning its main engine again to settle into a series of 14-day orbits. Most of the science will be conducted during these later passes, in which Juno will swoop in close for several hours and then spend two weeks radioing the information that it gathers back to Earth so that researchers can make sense of it. Entering orbit was the most dangerous thing Juno had done since its launch. The risks included being zapped by Jupiter\u2019s blazing radiation or smashed by dust particles. As planned, Juno broke contact with Earth and turned away from the Sun to get into the proper orientation to burn its main engine. The craft, which is shaped like a wind turbine, spun up from its usual 2 revolutions per minute to 5, to keep it stable during the 35-minute blast. Then the spacecraft slowed back to 2 revolutions per minute, turned its face back towards the Sun, and began charging its solar-powered batteries again. \n             Solar power \n           Spinning slowly means that each instrument mounted on the spacecraft has its chance to study the planet as Jupiter passes through the instrument\u2019s field of view. Three enormous solar panels, each the size of a school bus, power the mission in a region of space where sunlight is 1/25th the intensity of that at Earth. The mission\u2019s goal is to  determine what Jupiter is made of  \u2014\u00a0including how much water it contains, what powers its Great Red Spot, and whether it has a core. Jupiter is the Solar System\u2019s biggest planet and was the first to condense around the Sun 4.5 billion years ago. Team scientists released  a movie taken during Juno\u2019s approach , showing Jupiter's biggest moons dancing around the planet over the course of 17 days. Juno is scheduled to fly 37 orbits around the planet, before diving into the cloud tops in a self-immolating plunge in early 2018.\n \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   NASA\u2019s Juno spacecraft prepares to probe Jupiter\u2019s mysteries 2016-Jun-28 \n                 \n                   Jupiter glimpsed as aliens would see it 2015-Feb-13 \n                 \n                   Europe plans mission to Jupiter 2012-May-02 \n                 \n                   NASA's Juno site \n                 \n                   Southwest Research Institute's Juno site \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20204", "url": "https://www.nature.com/articles/nature.2016.20204", "year": 2016, "authors": [{"name": "Elena Bozhkova"}], "parsed_as_year": "2006_or_before", "body": "World in three-star system also experiences unusual seasons. A bizarre solar dance has been uncovered by researchers who spotted a giant planet orbiting one of the three suns of a triple-star system. The system was found in the constellation Centaurus, about 98 parsecs (320 light years) from Earth 1 . As shown in an artist\u2019s impression in this video, the planet, called HD 131399Ab, orbits the largest of the three stars. The other two stars also orbit the largest, and each other. This is not the first planet to be found with three suns, but HD 131399Ab\u2019s enormously wide orbit makes it unlike any other known world. The planet, which is four times the size of Jupiter, is 82 astronomical units (the distance between Earth and the Sun) from its primary star, and 300\u2013400 astronomical units from the other two. A year on the planet lasts for about 550 Earth years. For the first few hundred years, when the planet is on the side of the system opposite all three stars, the team says that it will experience three sunrises and three sunsets each day. During its second \u2018season\u2019, it is in constant daylight. Now, the researchers that detected HD 131399Ab need to wait until it has moved within the system before they can say more about its origin and fate. The planet is young, and may not remain part of the system. \u201cComputer simulations predict that planets in such extreme configurations can experience exotic behaviour,\u201d says Kevin Wagner, an astronomer at the University of Arizona in Tucson, who led the study. Such behaviour could include irregular and rapidly evolving orbits or, in more extreme scenarios, the complete ejection of the planet from the solar system. \n                   The truth about exoplanets 2016-Feb-17 \n                 \n                   The exoplanet files 2015-Nov-18 \n                 \n                   NASA spies Earth-sized exoplanet orbiting Sun-like star 2015-Jul-23 \n                 Reprints and Permissions"},
{"file_id": "535019a", "url": "https://www.nature.com/articles/535019a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Shoebox-sized craft face a wait to be propelled beyond Earth\u2019s orbit. CubeSats \u2014 spacecraft built from 10-centimetre-sided cubes, often with off-the-shelf parts \u2014 are already ubiquitous in near-Earth orbit, doing everything from Earth observation to  studies of bacterial proteins in space . Now scientists are itching to send them farther afield, and more than a dozen deep-space CubeSats are in the pipeline. The cost\u00a0\u2014 typically no more than US$10\u00a0million for an interplanetary mission\u00a0\u2014 means that the mini-craft can take risks that a more costly venture could not. They can also work in swarms, which allows new kinds of experiments. CubeSats generally piggyback on the launch of other missions, and whereas trips to low-Earth orbit, such as the cargo ships that shuttle to the International Space Station, are relatively common, missions to other parts of the Solar System are much rarer. Lifts are so hard to come by that the first interplanetary CubeSat\u00a0\u2014 NASA\u2019s twin INSPIRE mini-spacecraft, intended to test key technology for future missions\u00a0\u2014 has been waiting for almost two years. \u201cWe still have to find a ride,\u201d says Anthony Freeman, who manages the Innovation Foundry at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. CubeSats were originally conceived as a teaching tool in 1999. Today, they carry out both commercial missions and near-space science. But deep space poses a much bigger challenge (see \u2018Miniature explorers\u2019). Their diminutive size cannot accommodate standard propulsion and long-range communications equipment, let alone complex scientific instruments. Engineers are starting to overcome these problems, says Roger Walker, who oversees CubeSat development at the European Space Agency (ESA). To solve the communications problem, ESA\u2019s first interplanetary CubeSats will talk to Earth through a mothership. CubeSats will take part in the joint ESA\u2013NASA Asteroid Impact and Deflection Assessment (AIDA) mission, planned for 2020, where they will take on risky jobs such as up-close data collection as a larger probe plunges into an asteroid. NASA\u2019s planned mission to Europa, currently under development, would also use the mother\u2013daughter model, deploying a fleet of CubeSats to make close fly-bys of the Jovian moon. Scientists think that Europa could harbour life under its icy surface. Lone deep-space CubeSat missions are also on the horizon. NASA has developed a miniature radio-communication system capable of talking directly to Earth from Mars and beyond. The agency will test the system on INSPIRE\u00a0\u2014 which has a side-mission of mapping interactions between Earth\u2019s magnetic field and the solar wind\u00a0\u2014\u00a0and on Mars Cube One (MarCO), twin communication satellites scheduled to fly on the InSight mission to Mars when it launches in 2018 after a two-year delay. NASA has also developed tiny, cold-gas firing thrusters for propulsion, and radiation-resistant electronics that can survive beyond the protection of Earth\u2019s magnetic field. Meanwhile, firms in Europe are developing high-efficiency ion engines, and a company in Rome called IMT is looking at ways to power such engines with deployable solar panels that can turn to constantly face the Sun. Together, all these technologies make solo CubeSats missions feasible, says Walker. Freeman predicts that more than a hundred CubeSats could be dispatched throughout the Solar System by the end of the next decade\u00a0\u2014\u00a0but only if they can get into space. He is calling on all space agencies to agree to carry at least one CubeSat on each major planetary mission. Walker agrees: \u201cIt would really stimulate the area. Ultimately, that\u2019s the main problem to overcome for interplanetary CubeSats, alongside communications.\u201d This would mean forging plans for a CubeSat tag-along early in the mission\u2019s design phase. To cope with the large number of CubeSat proposals, NASA also wants to see more low-cost commercial launchers developed, to carry tens to hundreds of kilograms of payload, in contrast to the 5 tonnes typical of launchers designed for communications satellites. Freeman says that such smaller rockets could carry perhaps a few dozen 5-kg CubeSats to low-Earth orbit, or be adapted to include an upper stage that could take a single CubeSat to deep space. He hopes to use a similar method to send a free-flying probe to Venus, where it would skim through the planet\u2019s acidic atmosphere. CubeSats aimed for the Moon might get an easier ride. NASA\u2019s Space Launch System, a heavy-lift rocket designed to send people beyond Earth\u2019s orbit, will carry 13\u00a0CubeSats and an uncrewed Orion capsule on its maiden launch in 2018. The cargo will include Lunar Flashlight, which will use a reflected beam of light to look for icy deposits in the Moon\u2019s dark craters, and Near-Earth Asteroid (NEA) Scout, designed to explore a nearby asteroid. ESA is developing a separate lunar approach. Together with Surrey Satellite Technology Ltd (SSTL) in Guildford, UK, and the Goonhilly Earth Station in Helston, UK, it is developing a system that could solve two problems: a commercial mothership that would provide transport to the Moon and a data relay for dozens of CubeSats, for a fee of around \u00a35\u00a0million (US$6.6 mllion) per craft. Eventually, such a model could expand, says the SSTL\u2019s Christopher Saunders. \u201cEssentially, we want to build a Solar-System internet,\u201d he told the Interplanetary CubeSat workshop in Oxford in late May. According to Freeman, CubeSats will soon be able to carry instruments that would have seemed off-limits only a few years ago, such as high-resolution imagers and radar altimeters. And a recent investigation by the US National Academies of Sciences, Engineering and Medicine of CubeSats\u2019 potential concluded that the probes are capable of doing \u201cfantastic science\u201d, Thomas Zurbuchen, a space scientist at the University of Michigan in Ann Arbor, said at the meeting. \u201cMuch of it has yet to be imagined.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Tiny \u2018chipsat\u2019 spacecraft set for first flight 2016-Jun-01 \n                   \n                     NASA reschedules troubled Mars InSight mission to 2018 2016-Mar-09 \n                   \n                     NASA narrows its list of planetary targets 2015-Sep-30 \n                   \n                     Mini satellites prove their scientific power 2014-Apr-16 \n                   \n                     iCubeSat 2016 \n                   Reprints and Permissions"},
{"file_id": "535015a", "url": "https://www.nature.com/articles/535015a", "year": 2016, "authors": [{"name": "Sara Reardon"}, {"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "John Holdren tells  Nature  about the highs and lows of nearly eight years in the White House. John Holdren is no stranger to the spotlight. Over his long career in science, Holdren \u2014 a physicist by training \u2014 has worked on controversial issues such as climate change and nuclear non-proliferation. But for nearly eight years, he has enjoyed an even higher profile, as US President Barack Obama\u2019s science adviser and director of the White House Office of Science and Technology Policy (OSTP). With Obama due to leave the White House in January 2017, Holdren \u2014 now the longest-serving US science adviser \u2014 recently sat down with  Nature  for a wide-ranging chat. The interview has been edited for length and clarity. \n               Opinion polls continue to show a divide between  \n               \n                   what the American public thinks about science \n                 \n                and what scientists think. Has Obama done enough to change the way that science is perceived? \n             The president has done an incredible job in making science cool for young people. This is already evident in all kinds of numbers: you see more kids enrolling in science courses, more kids participating in science fairs, more kids going to \u2018makerspaces\u2019. We have substantially increased the number of engineers graduating from college in this country. I say \u2018we\u2019, but obviously, that is a large cooperative operation that includes colleges and universities. I\u2019m not sure which polls you are referring to, but my impression is that the public is more interested in and enthusiastic about science, technology and innovation than it was at the beginning of this administration. \n               Leaders at the National Institutes of Health (NIH) and other government agencies have discussed the widespread perception that we are  \n               \n                   training too many PhDs \n                 \n               . Do you worry about that? \n             If every PhD we train believes that her or his only acceptable career trajectory is a tenured professorship in a college or university, then it\u2019s true: we are training more PhDs than there are slots of that kind. But the PhD is, in fact, a  very versatile degree . Far more than just demonstrating that you know more than practically anybody else about one narrow topic, it demonstrates that you have the fortitude, the focus, the commitment and the intellectual capacity to tackle a very tough problem. PhDs are finding constructive and rewarding employment  all across the economy , and, overall, our view is that there are still more opportunities for highly trained people in science, technology and innovation than there are people being trained. \n               If you were to go back in time, would you become a scientist again? Would you do anything differently? \n             I would certainly become a scientist again. My wife is a biologist \u2014 she has a PhD in biology from Stanford \u2014 and I have sometimes envied the biologist\u2019s life because they get to do their work in so many spectacular locations. She did her work on insect\u2013plant interactions at high altitude in the Rocky Mountains. We have dived together on coral reefs all around the world, while she was actually doing work. I\u2019ve sort of envied that life from time to time. \n               Do you worry about future science funding? \n             The president has consistently recommended more money for science and technology than Congress  has been willing to pass . The success ratio of  proposals to the NIH  is something like 17% \u2014 that is, we are funding one-sixth of the proposals that the NIH gets. And those proposals are already self-selected. Investigators don\u2019t bother writing a proposal to the NIH unless they think they have got a really good idea, a capable team and a plausible strategy. If you ask Francis Collins, the NIH director, what fraction of the proposals they get that are worthy of funding, he\u2019ll tell you 50%. That means we are funding about a third of the potentially productive, influential, path-breaking research that is proposed to the NIH. But the NIH has a budget of over US$30\u00a0billion per year. It\u2019s not very easy in these budget times to increase a $30-billion budget by a large factor, like 50% \u2014 never mind 100% or more, as director Collins would say is warranted in terms of the quality of the research. The  same is true at the National Science Foundation  \u2014 far more worthy proposals than they are able to fund. This is a consistent problem. I would like to see more public support for raising public spending on research and development. \n               The comprehensive climate bill that failed to pass in 2010 is sometimes mentioned as the administration\u2019s biggest failure. What did you tell the president then, and do you have any regrets? \n             One of the rules of the game in this environment is I don\u2019t talk about what I told the president or what the president said to me. But I will tell you that both the president and I very much wanted to see comprehensive climate legislation pass. We didn\u2019t get it. And so, of course, we were disappointed. We did everything we could  using executive authority  to advance a sensible climate-change agenda. We put in place the most ambitious fuel-economy and carbon dioxide-reduction standards for light-duty vehicles ever thought about in this country, and followed them with heavy-duty-vehicle standards. We put in place a large number of new standards to advance energy efficiency in appliances, in buildings, in industry. We boosted \u2014 to the extent that budgets allowed \u2014 Earth observations and climate science. Even today, we would love it if we could get a bill out of Congress that would enable us to do more than we are able to do with executive authority. \n               The administration\u2019s regulations to cut power plants\u2019 CO \n               \n                 2 \n               \n                emissions  \n               \n                   are already in limbo \n                 \n                because of legal challenges. And  \n               \n                   Republican presidential candidate Donald Trump \n                 \n                has said that if he is elected, he will try to pull the United States out of the Paris climate agreement. Are you optimistic that these policies are going to survive? \n             Yeah, I\u2019m optimistic. A lot of these policies \u2014 all of them \u2014 are being enthusiastically pursued by career civil servants and not just political appointees, because they are very clearly the right thing to do. And I think it\u2019s important to recognize that there is now a huge amount of global momentum behind this. The United States would become a pariah if we backed out of  the Paris agreement . And while I don\u2019t want to get into politics, I suspect that if Mr Trump were elected, he would discover that what he said during the campaign about Paris is not quite right. He said in the campaign that the Paris agreement means that foreign bureaucrats would be able to determine America\u2019s energy choices. That simply isn\u2019t true. It\u2019s far from true. If he is elected, he\u2019ll figure that out, and I think he \u2014 as any new president is likely to do \u2014 will stick with the Paris agreement. \n               Science is global today. How do you think that complicates matters? Can the regulators keep up? \n             I\u2019m going to China this week for a strategic and economic dialogue and for a US\u2013China dialogue on innovation policy. I\u2019ll be talking with my Chinese counterpart, Wan Gang, the minister of science and technology, about some of these very problems and what we are doing about them. We have a lot of cooperation with China on biomedical issues. We talk to them all of the time about  gain-of-function research  and about gene-editing issues. And in fact, when the current round of interest in gene editing emerged with  the rise of the CRISPR technology , the [US] National Academies of Science, Engineering, and Medicine  gathered leading scientists from all over the world  in a format  very much like Asilomar  [a landmark conference in 1975 that set rules for research on recombinant DNA], but strongly inter\u00adnational. The top Chinese people came to talk through what the implications of these technologies are, and how we should think as a global science community about regulating them. \n               With Asilomar, every scientist working on recombinant DNA came together. But now there are researchers in China who are editing the human germ line using CRISPR, because it\u2019s legal there \u2014 and there are plenty of others elsewhere. It\u2019s arguably legal here. \n             And we\u2019ve got high-school kids who can use  CRISPR technology , so I\u2019m not saying this is all tied up neatly with a bow. This is a very challenging question. When the technology is so widely available and so relatively easy to use, this is a very different matter than, for example, controlling nuclear-weapons technology. That has been a big challenge as well, as we know, but this is hard work. \n               Some scientists and policy experts worry that the United States is losing its edge in space, despite the rise of a commercial space industry here. How do you feel about the future of the US space programme? \n             We knew when we came in that we had to rebalance NASA, and we had a committee chaired by Norm Augustine that  looked at the space programme  and declared that Constellation [NASA\u2019s human space-flight effort] was \u201cunexecutable\u201d. And that report informed what we did to scale Constellation way back. We still have an Orion multi-purpose space capsule. We still have the Space Launch System, a heavy-lift rocket, under development. But we scaled them back to the point that there was enough money to revitalize Earth observation, to revitalize planetary science, to revitalize robotic exploration, to think about new missions. Shortly after he took office, Obama said that this was going to be the most transparent administration ever. But journalists have found some agencies to be  \n fairly opaque \n . In the first months of the administration, the president issued executive orders on transparency, on scientific integrity, on openness in government.  I was put in charge  of a number of the implementation [efforts]. That has been a focus of OSTP throughout this administration. We\u2019ve gotten virtually all of the departments and agencies to produce for public review and comment, and then to finalize,  policies on openness and on scientific integrity . I think we\u2019ve made great progress in terms of open data, in terms of the publication in open venues of federally funded research. But I would not argue that that job is finished. There is always a tendency in government, some of it quite legitimate, not to expose internal deliberations prematurely. You know, it\u2019s quite challenging to have a discussion between the president\u2019s senior advisers with reporters from  Nature ,  Science  and  The New York Times  sitting around in the room, because if you do that, nobody will float a trial balloon for fear that the trial balloon will get into the news as a done deal. \n               What is your greatest regret? \n             The biggest regret I have, first of all, is that we have not been able to do better on the budgets. And again, I don\u2019t think that is our fault. I don\u2019t know whether I really have a strategy to pass on to my successor to say, \u2018Here\u2019s how you can do better\u2019. \n               You\u2019ve spent almost eight years inside what is arguably the most powerful institution on Earth. Do you come away more or less optimistic about humanity\u2019s ability to deal with its problems? \n             I come away more optimistic, and that\u2019s in large measure due to the extraordinary leadership that President Obama has provided. I have felt for many decades that science, technology and innovation are crucial if human society is to get its arms around the biggest challenges we face. And I\u2019ve had the pleasure of working for a president for nearly eight years now who shares that view. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               Reprints and Permissions"},
{"file_id": "nature.2016.20134", "url": "https://www.nature.com/articles/nature.2016.20134", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Researchers plan for hits to community hubs. Researchers are protesting plans to reorganize and cut the budgets of five model-organism databases supported by the US National Institutes of Health (NIH).The databases host a rich trove of information on species of budding yeast, flies, roundworms, zebrafish and mice that hastens progress in biology and human disease, according to an  open letter  signed by 46 researchers, addressed to NIH director Francis Collins and NIH institute heads. It was published on 21 June on the Genetics Society of America website. The databases house information about the genetics and biology of model organisms, such as data on genes, proteins, gene expression and numerous other traits. They also host analysis tools.\u201cNIH\u2019s support for the [model organism databases] over the last two decades has enabled a bevy of pivotal discoveries that lie at the true heart of the NIH mission. We urge you to continue the far-sighted policy of support for vital research infrastructure,\u201d states the letter, which will be presented to Collins on 14 July at the Allied Genetics Conference in Orlando, Florida. \n             A move to become one \n           Officials with the National Human Genome Research Institute (NHGRI) told researchers in May that the agency plans to gradually cut support for the databases by 30\u201340% beginning next year. For the current fiscal year, the agency has dedicated US$17.6 million to support the 5 databases, each of which is run independently. Funding for data resources  has not kept up with the massive proliferation of data produced by research projects over the years; some previously free resources have resorted to charging  subscription fees  for access. Although the five model-organism databases affected by the cuts are funded solely by the NHGRI, they are also accessed by researchers who receive funding from other NIH institutes, and by scientists worldwide. Four other separate databases that collate data on humans and other organisms funded by NHGRI are also slated for cuts. The agency is hoping to get other NIH institutes to help to support the databases. But at a May meeting in Rockville, Maryland, NHGRI officials asked principal investigators in charge of the five databases to submit a proposal within several months for integrating some of their features. The agency would like to merge administration of the databases completely over the next few years. \u201cI know there is a lot of concern on the part of the community, but there is a need for the broad scientific community to support these resources better, and that is something that our institute currently cannot afford,\u201d says  Valentina Di Francesco , programme director for computational genomics and data science at the NHGRI. And, she adds, the independent operation of each database is confusing for users, who must navigate five separate user interfaces and sets of tools if they want to query information on all five species.\u201cIdeally, there will be one interface from which a user can extract all the information they need,\u201d Di Francesco says. \n             Caution: merge ahead \n           The plan has prompted concern among researchers who run the databases, who worry that the features that make each one most useful to their communities will be lost if the NHGRI merges them. Each database is curated by individual scientists who comb through the literature on each species to update entries on, for instance, the functions and features of specific genes. And each hub also hosts some features that are not duplicated elsewhere, says  David Bilder , a developmental biologist at the University of California, Berkeley, and president of the Drosophila Board, which represents scientists who work with the eponymous model organism.\u201cThe letter is not in opposition to integration, but it urges that this integration be done in a carefully considered manner that maintains the high quality, and particularly the utility, of each of these databases to the communities who have developed them over many years,\u201d Bilder says. Di Francesco says that the NGHRI appreciates the value of curation and of each database serving as a community hub. But, she says, it should be possible to streamline some of the back-end technology and administration features of the databases without compromising their quality.\u201cWe are trying to preserve the value addition and community tradition that these databases provide,\u201d Di Francesco says. \n                   Popular plant database set to charge users 2013-Aug-31 \n                 \n                   Databases fight funding cuts 2012-Sep-05 \n                 \n                   Databases in peril 2005-Jun-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20135", "url": "https://www.nature.com/articles/nature.2016.20135", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The US government plans to evacuate a sick crew member from an isolated research station. \n             UPDATE: The Twin Otter rescue flight successfully made it to the South Pole on 21 June and returned to Rothera the following day, the National Science Foundation reports. \n           A Twin Otter aeroplane has left  Rothera station  near the Antarctic Peninsula, embarking on a daring mid-winter mission to rescue a sick crew member at the South Pole. Only twice before \u2014 in 2001 and 2003 \u2014 has the US National Science Foundation (NSF) deemed a medical condition at its  Amundsen\u2013Scott South Pole Station  serious enough to risk an evacuation. The journey involves flying one small, ski-equipped plane more than 2,400 kilometres into the icy polar night, landing in the pitch dark, picking up the sick person, refuelling, and attempting to lift off without freezing to the runway. Meanwhile, a second Twin Otter plane remains at Rothera in case the first itself needs rescuing. \u201cWe are very, very concerned and will be until this is over,\u201d says Kelly Falkner, director of the NSF\u2019s polar programmes. \u201cBut I\u2019m glad I\u2019ve spent a lot of time in Twin Otters with some of the best pilots in the world.\u201d The NSF is not releasing the name or medical condition of the person who requires evacuation. There are 48 people overwintering at the South Pole: 39 men and 9 women. Whatever the person does, those tasks will be split between the remaining crew members, Falkner says. There is a possibility that a second person will be flown out at the same time. That person has a different medical condition that was being managed at the station and would normally have continued to be treated there, Falkner says. But given that the first person will be evacuated, the second might leave at the same time. \n             Extreme effort \n           The Twin Otters are owned and operated by  Kenn Borek Air , an aviation company based in Calgary, Canada, with broad experience in both the Arctic and Antarctic. Almost certainly, the pilot flying from Rothera, a British Antarctic Survey outpost, to the South Pole will have landed at the pole before \u2014 though in more temperate weather conditions. Temperatures in mid-winter average about \u201360 \u00baC at the pole. The Twin Otters are rated to fly in conditions as low as \u201375 \u00baC. They work at lower temperatures than the military LC-130 cargo planes that are the workhorse for supplying the pole in the summer months. Depending on headwinds, the flight from Rothera to the pole should take around 10 hours. After returning to Rothera, the patient will probably be transported to Punta Arenas in Chile, and onward to a hospital yet to be disclosed. Winter staff at the station maintain various areas of research, including  the IceCube neutrino observatory  and an experiment to  probe the cosmic microwave background glow  left over from the very early Universe. Astronomy takes precedence during the long polar night, which stretches from March to September. \n             Pushing the limits \n           Landing in mid-winter at the pole was long thought to be impossible. In 1999, when physician Jerri Nielsen developed breast cancer during the winter, the NSF airdropped equipment and drugs so that she could track and treat the disease, but she was not evacuated. \u201cYou're far, far away from hope down there,\u201d says Dar Gibson, an engineer who worked that season with Nielsen. In 2001, Ron Shemenski, another physician overwintering at the station, came down with gallstones and pancreatitis. The NSF decided his condition was severe enough to warrant bringing him out. \u201cI didn't want to look back on that year and think there might have been something we could have done to save his life,\u201d says  Jerry Macala , who was the station manager for the winter and participated in discussions about whether to evacuate Shemenski. Eventually, a Twin Otter flown by Kenn Borek pilots touched down on a runway outlined by flaming barrels. \u201cIt was very cold, more than 90 below,\u201d says Nathan Tift, who served as one of two meteorologists that winter. The evacuation was \u201cso strange\u201d, he says, \u201cjust because it had never happened before\u201d. Crew members filed out and took a photograph of themselves with the visiting Twin Otter. But then, when the plane tried to take off, they realized that its skis had frozen to the runway from the friction of landing. Workers had to rock the plane from side to side to liberate it, so that it could eventually take off. \u201cFor the second time that winter, we waved goodbye to the last plane of the season,\u201d says Stephen Hudson, who was at the pole as a University of Washington graduate student in atmospheric science. \n             Long polar night \n           In 2003, another overwintering crew member developed gall-bladder problems and was evacuated. But most of the time, 'polies' expect that they will see no one until the end of the winter. In 2001, Tift developed epileptic seizures after his colleague was evacuated, and was successfully treated with medication, remaining at the pole until the first flights out resumed in the spring. In 2002, Gibson underwent knee surgery at the pole, the first time the physician on-site had performed telemedicine with the help of doctors via a satellite link. Other polies helped in the makeshift operating theatre. \u201cOne day you're having lunch with these guys,\u201d Gibson says, \u201cand days later you're lying on a table and these people are going to do surgery on you.\u201d In 2011, the station manager had a stroke and, despite a campaign from her family to have her evacuated, she was kept at the station through the winter. This year, the last flight left the pole in mid-February. Polies hadn't expected the next one until November. Macala says he would pass along to the current station manager the advice he was given by an old Antarctic hand: \u201cYou're going to hear a lot of things from a lot of people, but ultimately you have to make the calls down there.\u201d That, and make sure to keep the plane's skis clear. \n                   Exotic space particles slam into buried South Pole detector 2014-Apr-10 \n                 \n                   Researchers question rescued polar expedition 2014-Jan-15 \n                 \n                   Polarization detected in Big Bang's echo 2013-Jul-24 \n                 \n                   http://www.nature.com/news/icediary-1.18738 \n                 \n                   Blog: Fatal helicopter crash at French Antarctic research base \n                 \n                   Blog: Antarctic mishaps \n                 \n                   US Antarctic Program \n                 \n                   Antarctic Sun newspaper \n                 \n                   South Pole Station news and history \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20138", "url": "https://www.nature.com/articles/nature.2016.20138", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "The parasitic tumours showed up in clams, mussels and other bivalves. Some clams, mussels and other bivalve molluscs carry infectious cancer cells that can leap between individuals \u2014 and that may even have jumped between species. The discovery, reported on 22 June in  Nature 1 , means that transmissible tumours have now been found in six organisms. Two are well known in mammals: a facial tumour that  threatens to wipe out Tasmanian devils  ( Sarcophilus harrisii ) and a venereal cancer  found in dogs all over the world . \u201cWe thought these things happen now and then in nature, but that this was a fluke. Now, the finding that these seem to be fairly widespread in bivalves changes that outlook,\u201d says Elizabeth Murchison, a molecular biologist at the University of Cambridge, UK, who studies the cancers prevalent in dogs and Tasmanian devils. The further finding that a cancer might have jumped between species is \u201cshocking\u201d, she says. \n             Shell shock \n           The latest work is led by virologist Stephen Goff of Columbia University in New York City, whose team last year found the first transmissible cancer among invertebrates 2  \u2014 an edible soft-shell clam called  Mya arenaria  that lives in the tidal mudflats of the Atlantic, ranging from Canada to the southern United States. Goff, who studies cancers caused by viruses, was looking for the source of a leukaemia common among clams, and discovered that tumours collected from animals in Long Island, Maine and Canada seemed to have the same genome sequence. \u201cWe were forced to come to the conclusion that somehow this clone had spread from animal to animal in the oceans up and down the coast,\u201d he says. After the discovery, Goff\u2019s team reached out to marine biologists to see whether transmissible cancers were prevalent in other molluscs. In mussels (Mytilus trossulus) from British Columbia in Canada, and in cockles (Cerastoderma edule) and golden carpet-shell clams (Polititapes aureus) from the Galician coast in northwest Spain, the team found the same hallmarks of transmissible cancers: tumour cells from different individuals that shared the same genetic markers. Two different lineages of cancers cells were found in infected cockles, which suggests that transmissible cancers emerged at least twice. \n             Barriers to entry \n           According to genetic analysis of the cancer DNA, the tumours in golden carpet-shell clams seemed to originate from another species of clam that lives in the same sea beds \u2014 the pullet shell clam ( Venerupis corrugata ). \u201cThis is the first time that\u2019s ever been seen,\u201d says Goff. But peculiarly, Goff\u2019s team found no signs of this cancer in the species in which it originated. It could be that the tumour wiped out vulnerable individuals in the original species, Goff suggests, and jumped to another species to find susceptible hosts. Murchison says that the spreading of cancer between individuals requires the tumour to elude an immune attack, and she expects that the barrier is even higher between species. Clams have more-primitive immune systems than mammals, but Murchison still expects that transmissible tumours must overcome some level of resistance when moving within and between species. Another mystery is how the cancer cells jump between individuals. Molluscs are voracious filter feeders, and the cancer cells floating around the ocean could make it to their bloodstream to seed new leukaemias. Tumour cells might be released when an animal dies, but Goff notes that the molluscs' faeces are also full of blood cells. \"It may just be that they're pooping out these cells into the ocean,\u201d he says. Read the related  News & Views  article, \" Transmissible tumours under the sea \". \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "534443a", "url": "https://www.nature.com/articles/534443a", "year": 2016, "authors": [{"name": "Nicky Phillips"}], "parsed_as_year": "2006_or_before", "body": "Rival parties avoid carbon controversy of former years. Australia\u2019s elections often feature a fierce debate over climate-change policy. In recent years, arguments over whether and how to put a price on carbon emissions have even swayed voters and toppled govern\u00adments. Australia is on the front lines of climate change: it is one of the world\u2019s largest coal exporters and biggest carbon emitters per capita, and is already experiencing increasingly frequent extreme weather and coral bleaching. But political uproar over climate change has been more subdued in the run-up to the election on 2\u00a0July, which pits the current Liberal\u2013National coalition government against the opposition Australian Labor Party. In part, that is because politicians are more focused on the country\u2019s economy. But policy analysts say the lack of debate suggests that the opposing parties are more closely aligned on climate action this time around. \u201cWe\u2019re not in as tumultuous a place as we were in previous years,\u201d says Frank Jotzo, director of the Centre for Climate Economics and Policy at the Australian National University in Canberra. Both parties have set emissions targets, and \u201cunder both parties something will be done\u201d, he says. A poll of 250,000\u00a0Australians, published on 2\u00a0June by the broadcaster ABC, suggested that 63% want a price on carbon, up from 50% before the 2013 election. \u201cIt is an issue that keeps forcing itself into the conversation,\u201d says John Connor, chief executive of the Climate Institute, a policy think tank in Sydney. At face value, the policies of the two main parties seem distinct. The government, led by Prime Minister Malcolm Turnbull, is promising to continue a scheme that came into effect in 2014, which sees companies bid for funding for emissions-reduction programmes. From 1\u00a0July, firms will be forced to buy carbon credits if they exceed a ceiling on carbon emissions. But falling demand for electricity means that is unlikely to happen to electricity generators, says Dylan McConnell, a research fellow at the Melbourne Energy Institute at the University of Melbourne, because the ceiling is set at a high point for emissions that was reached between 2009 and 2014. He says that the government\u2019s policies are \u201cdefinitely not adequate\u201d to achieve its targets of cutting emissions to 26\u201328% below 2005 levels by 2030. A spokesperson for environment minister Greg Hunt disagreed, saying that the government\u2019s policies put it on track to meet its 2030 targets. The Labor opposition, which under leader Bill Shorten has a slight edge in opinion polls, is more ambitious: it has pledged to reduce emissions by 45% below 2005 levels by 2030, and to be carbon neutral by 2050. Labor would also introduce an emissions-trading scheme for electricity producers. \u201cLabor\u2019s policies are stronger with a clearer pathway to credibility than the coalition\u2019s, but much detail remains to be sorted,\u201d says Connor. For example, it is not clear where the threshold on emissions intensity would be set.  Australia has one of the lowest emissions-reduction targets.  Climate analysts think that in practice, the two approaches could end up operating in a similar way \u2014 with the coalition\u2019s pay-to-cut-emissions plan morphing into an emissions-trading scheme similar to the Labor proposal. \u201cWhen you look at the policies, unless you\u2019re a policy nerd, there\u2019s not really much difference,\u201d says Tony Wood, head of the energy programme at the Grattan Institute, a think tank in Melbourne. Hunt\u2019s spokesperson rebuffed any comparison, saying that the government was not running an emissions-trading scheme. With warming oceans causing extensive damage to Australia\u2019s iconic Great Barrier Reef, rival politicians are keen to be seen as promising action. On 30\u00a0May, Shorten pledged Aus$377\u00a0million (US$279\u00a0million) in new funding to improve the health of the reef, if he is elected. Turnbull then announced that his government would use up to Aus$1\u00a0billion from an existing clean-energy programme to support the reef\u2019s health through projects to improve water quality, reduce emissions and provide clean energy. But marine biologist Terry Hughes, director of the ARC Centre of Excellence for Coral Reef Studies at James Cook University in Townsville \u2014 who has made headlines with his reef-bleaching studies (see also   Naturehttp://doi.org/bj45;2016 ) \u2014 says that the money will make little difference because it won\u2019t tackle the fact that global warming is the greatest threat to the reef. \u201cAustralia has one of the lowest emissions-reduction targets of any developed country and the highest per capita emissions. Those are the two areas the government should be addressing,\u201d says Hughes. The government also refused to intervene when cuts to climate-change programmes at the national science agency, the Commonwealth Scientific and Industrial Research Organisation (CSIRO), were revealed earlier this year. The opposition has committed to an independent review of the agency and, on 12\u00a0June, promised CSIRO Aus$250\u00a0million extra as part of a package to fund various science programmes, if the party is elected. Jotzo and Wood see the quieter consensus for action on carbon emissions as a relief after a decade of contentious climate politics. Those years saw a carbon \u2018tax\u2019 introduced by Labor\u2019s Julia Gillard in 2012, and then dismantled by a conservative coalition led by Tony Abbott in 2014. \u201cThere is an opportunity for bipartisanship, which is part of the reason why the toxicity of the debate in this election hasn\u2019t been so strong,\u201d says Wood. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Coral crisis: Great Barrier Reef bleaching is \u201cthe worst we\u2019ve ever seen\u201d 2016-Apr-13 \n                   \n                     Australia's scientists give new prime minister a cautious welcome 2015-Sep-15 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20119", "url": "https://www.nature.com/articles/nature.2016.20119", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Study of 44 ancient Middle Eastern genomes supports idea of independent farming revolutions in the Fertile Crescent. Two Middle Eastern populations independently developed farming and then spread the technology to Europe, Africa and Asia, according to the genomes of 44 people who lived thousands of years ago in present-day Armenia, Turkey, Israel, Jordan and Iran. Posted on 17 June on the bioRxiv preprint server 1 , the research supports archaeological evidence about the multiple origins of farming, and represents the first detailed look at the ancestry of the individuals behind one of the most important periods in human history \u2014 the Neolithic revolution. Some 11,000 years ago, humans living in the ancient Middle East region called the Fertile Crescent shifted from a nomadic existence, based on hunting game and gathering wild plants, to a more sedentary lifestyle that would later give rise to permanent settlements. Over thousands of years, these early farmers domesticated the first crops and transformed sheep, wild boars and other creatures into domestic animals. Dozens of studies have examined the genetics of the first European farmers, who emigrated from the Middle East beginning some 8,000 years ago, but the hot climes of the Fertile Crescent had made it difficult to obtain ancient DNA from remains found there.  Advances in extracting DNA from a tiny ear bone called the petrous  allowed a team led by Iosif Lazaridis and David Reich, population geneticists at Harvard Medical School in Boston, Massachusetts, to analyse the genomes of the 44 Middle Eastern individuals, who lived between 14,000 and 3,500 years ago. \n             Geographical divide \n           The team found stark differences between the genomes of Neolithic individuals from the southern Levant region, including Israel and Jordan, and those living across the Zagros Mountains in western Iran. The Zagros early farmers were instead more closely related to nearby hunter-gatherers who lived in the region before the Neolithic. This pattern of ancestry adds to the evidence that the hunter-gatherers in the southern Levant and Iran independently developed farming, says Roger Matthews, an archaeologist at the University of Reading, UK, who co-directs the Central Zagros Archaeological Project in Iran. \u201cThere has been a school of thought arguing that everything happens first in the southern Levant and everyone learns how to be farmers from this initial dispersal,\u201d he says. \u201cBut\u00a0the archaeological evidence shows very strong local traditions that are clearly not in communication with each other, persisting for centuries if not millennia.\u201d The Zagros farmers domesticated goats as well as cereals such as emmer, whereas their counterparts to the west had their own crops, including barley and wheat. Around 9,500 years ago, these traditions began spreading around the Middle East, Rogers says, noting that the two populations of farmers may have mixed in eastern Turkey while seeking out sources of obsidian, which was useful for making tools. By the time farmers in present-day Turkey began migrating to Europe, they carried a 'Neolithic toolkit' that included crops, animals and tools from both farming traditions. \n             How farming fanned out \n           The latest study also finds traces of the diverse foundations of farming beyond Europe. Iranian farmers moved north into\u00a0the Eurasian steppe and eastwards into present-day India and Pakistan. Southern Levant farmers made a trek to Africa, perhaps bringing new farming traditions to East Africa. The study notes that this is in line with previous work suggesting that humans from Eurasia launched  a \u2018back-to-Africa\u2019 migration  some 3,000 years ago. Rogers says that the study offers a first glimpse of the spread of farming to Asia, \u201cbut we need an awful lot more work looking at how farming spread eastward,\u201d he says. \u201cThe study has the grandeur of providing a big picture of the advent of farming and how this shift from hunting and gathering to food production had a crucial impact on the evolutionary history of Europe, East Africa, India and Central Asia,\u201d says\u00a0Carles LaLueza-Fox, a palaeogeneticist at the Institute of Evolutionary Biology in Barcelona, Spain. A second bioRxiv preprint, posted by some of the same team on 19 June 2 , reports the whole genome of one the Zagros farmers: a female who lived 10,000 years ago. (By contrast, the report from Reich and Lazaridis samples thousands of single-letter genetic variants peppered across the genomes of the 44 individuals). Differences between her genome and those of farmers in Turkey supports the broad conclusion that farming emerged independently in the region, the paper says. LaLueza-Fox sees such research as an indication that scientists can reliably collect ancient DNA from hotter climates, where much of human prehistory played out. \u201cRetrieving genomic data from the ancient Near East is a palaeogenomic dream come true,\u201d he says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Ancient DNA dispute raises questions about wheat trade in prehistoric Britain 2015-Nov-03 \n                 \n                   Ancient DNA from hot climes yields its secrets 2015-Oct-13 \n                 \n                   First ancient African genome reveals vast Eurasian migration 2015-Oct-08 \n                 \n                   DNA data explosion lights up the Bronze Age 2015-Jun-10 \n                 \n                   Ancient European genomes reveal jumbled ancestry 2014-Jan-02 \n                 \n                   Ancient Swedish farmer came from the Mediterranean 2012-Apr-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20142", "url": "https://www.nature.com/articles/nature.2016.20142", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Elena Cattaneo is a relentless campaigner against the misuse of science. It isn\u2019t a scam, as neuroscientist Elena Cattaneo had first assumed. A total stranger really has left the prominent Italian, who is also a senator and a relentless campaigner against the misuse of science, his entire fortune to distribute for research. The sum is likely to be upwards of \u20ac1.5 million (US$1.7 million). The short, handwritten will of Franco Fiorini, an accountant from the small town of Molinella near Bologna, was officially made public on 21 June. \u201cI\u2019ll never know for sure why he decided to do this,\u201d says Cattaneo, who adds that she has wept with regret that she cannot thank Fiorini. \u201cBut it gives a hopeful message that there are some people like Franco who are able to work out on their own the importance of science and research for Italy\u2019s future.\u201d She intends to make the money available for fellowships for young scientists in Italy, where  funds for research are notoriously scarce . Cattaneo, who is based at the University of Milan, is no ordinary researcher. In 2013, then-president Giorgio Napolitano appointed her a senator-for-life in recognition of her activities in promoting science. One of her most famous achievements, made with a handful of colleagues, was a successful  two-year battl e  to stop the Stamina Foundation in Brescia from  administering unproven stem-cell therapies . Fiorini died on 21 May at the age of 64. A wheelchair user since a bout of childhood polio left him partially paralysed, he had been director of a construction company in Molinella before taking early retirement 15 years ago. \n             One-sentence testament \n           Earlier this year, he developed a serious infection that eventually led to his death. On 29 March, while ill, he wrote a new, one-sentence will: \u201cI leave all my movable and fixed possessions to Dr Elena Cattaneo, senator for life, for her to use in scientific research as best she sees fit.\u201d His lawyer and confidant Paolo Ghedini told  Nature  that Fiorini had no immediate family and few friends, and rarely went out. \u201cHe was a closed person, who never spoke about personal things,\u201d he says. \u201cBut he was constantly reading \u2014 books and online \u2014 and would speak to me about history, medicine, politics, everything.\u201d Fiorini loved to order and reorder his collection of 5,000 or so books, many on philosophy and science. Reading is probably how he came to know about Cattaneo, whose campaigning for science made her a regular presence in the media in the months before Fiorini rewrote his will. During this time, she  raised concerns about possible data manipulation  in papers presented in parliamentary debates on genetically modified crops, submitted a complaint to parliament about appropriate transparency and competition in the  establishment of a major research centre in Milan  and promoted the responsible use of  animals in research . On 28 May, a notary sent an e-mail to her office in the Senate informing Cattaneo of the bequest. She thought it was a joke. But two days later, her Senate assistant, having checked things out, called her in her lab. \u201cI\u2019ve got news,\u201d he said. \u201cYou\u2019d better sit down.\u201d\u00a0 Many anonymous donors give significant amounts of money to medical-research foundations, notes Tullio Pozzan, director of the CNR Institute for Neuroscience at the University of Padua. \u201cBut giving money to an individual \u2014 someone you only know through the press \u2014 is unusual,\u201d he says. \u201cIt shows the importance of publicizing research in the press.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Row over proposed Italian biomedical centre intensifies 2016-May-11 \n                 \n                   Italian papers on genetically modified crops under investigation 2016-Jan-18 \n                 \n                   When right beats might 2015-Feb-24 \n                 \n                   Stem cells: Taking a stand against pseudoscience 2014-Jun-16 \n                 Reprints and Permissions"},
{"file_id": "534447a", "url": "https://www.nature.com/articles/534447a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Stark differences between men and women\u2019s immune responses pose medical conundrum. The immune systems of men and women respond very differently to infection\u00a0\u2014\u00a0and scientists are taking notice. Research presented last week at a microbiology meeting in Boston, Massachusetts, suggests that the split could influence the design of vaccination programmes and lead to more targeted treatment of illness. Hints that men and women  deal with infection differently  have been  around for some time . In 1992, the World Health Organization hastily withdrew a new measles vaccine after it was linked to a substantial increase in deaths of infant girls in clinical trials in Senegal and Haiti. It is still not clear why boys were unaffected, but the incident was one of the first such examples to catch scientists\u2019 attention. Women might have evolved a particularly fast and strong immune response to protect developing fetuses and newborn babies, says Marcus Altfeld, an immunologist at the Heinrich Pette Institute in Hamburg, Germany. But it comes at a cost: the immune system can overreact and attack the body. This might explain why more women than men tend to develop autoimmune diseases such as multiple sclerosis and lupus. Yet very few studies assess men and women separately, so any sex-specific effects are masked. And many clinical trials include only men, because menstrual cycles and pregnancies can complicate the results. \u201cIt\u2019s sort of an inconvenient truth,\u201d says Linde Meyaard, an immunologist at University Medical Center Utrecht in the Netherlands. \u201cPeople really don\u2019t want to know that what they study in one sex is different from the other.\u201d Now, scientists are beginning to tease out some precise mechanisms. At the meeting, infectious-disease researcher Katie Flanagan at the University of Tasmania in Australia reported on a tuberculosis vaccine given to Gambian infants. She found that the vaccine suppressed production of an anti-inflammatory protein in girls, but not boys. This boosted the girls\u2019 immune responses, and may have made the vaccine more effective. Hormones also play a part. Oestrogen can activate the cells involved in antiviral responses, and testosterone suppresses inflammation. Treating nasal cells with oestrogen-like compounds before exposing them to the influenza virus has revealed further clues, says Sabra Klein, an endocrinologist at Johns Hopkins University in Baltimore, Maryland. Only the cells from females responded to the hormones and fought off the virus ( J.\u00a0Peretzet\u00a0al.Am.J.Physiol.http://doi.org/bj5w;2016 ).  It\u2019s a sort of inconvenient truth.  Genetic factors may also guide how the sexes deal with infection. Meyaard studies a protein called TLR7, which detects viruses and activates immune cells. Encoded by a gene on the X chromosome, the protein causes a stronger immune response in women than in men ( G.Karnametal.PLoSPathogenshttp://doi.org/bj5x;2012 ). Meyaard suspects that this is because it somehow circumvents the process whereby one of the two X chromosomes in women is shut down to avoid overexpression of proteins. A study set to begin later this year could help to tease apart the relative influence of genes and hormones on infection. Altfeld and his colleagues will look at 40 adults going through sex-change operations. If female hormones are responsible, the transgender women in the study should begin mounting stronger immune reactions to infections and develop more autoimmune problems than the transgender men. Whether such results will lead to changes in how drugs are administered is an open question. In 2014, the US National Institutes of Health (NIH) announced that researchers must  report the sex of animals  used in preclinical research. Similar efforts are under way in Europe. But a 2015 report from the US Government Accountability Office (GAO) found that the NIH does a poor job of enforcing rules requiring that clinical trials include both sexes (see  go.nature.com/28ll4nb ). According to the GAO, even if studies include both sexes, the NIH also does not routinely track whether researchers have actually evaluated any differences between them. Klein argues that gathering such data could lead to more-effective programmes \u2014 halving vaccine doses for women, for instance. \u201cPeople are tending to ignore it for as long as possible,\u201d Flanagan says. \u201cPeople will get a lot of surprises.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     Policy: NIH to balance sex in cell and animal studies 2014-May-14 \n                   \n                     Women are more vulnerable to infections 2013-Jul-26 \n                   \n                     HIV vaccine trials struggle to enrol women 2012-Sep-13 \n                   \n                     Why can't a woman be more like a man? 2000-Jan-05 \n                   \n                     ASM Microbe 2016 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20136", "url": "https://www.nature.com/articles/nature.2016.20136", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "The technique would help address problems that classical computers can't handle. Physicists have performed the first full simulation of a high-energy physics experiment \u2014 the creation of pairs of particles and their antiparticles \u2014 on a quantum computer 1 . If the team can scale it up, the technique promises access to calculations that would be too complex for an ordinary computer to deal with. To understand exactly what their theories predict, physicists routinely do computer simulations. They then compare the outcomes of the simulations with actual experimental data to test their theories. In some situations, however, the calculations are too hard to allow predictions from first principles. This is particularly true for phenomena that involve the strong nuclear force, which governs how quarks bind together into protons and neutrons and how these particles form atomic nuclei, says Christine Muschik, a theoretical physicist at the University of Innsbruck in Austria and a member of the simulation team. Many researchers hope that future quantum computers will help to solve this problem. These machines, which are still in the earliest stages of development, exploit the physics of objects that can be in multiple states at once, encoding information in \u2018qubits\u2019, rather than in the on/off state of classical bits. A computer made of a handful of qubits can perform many calculations simultaneously, and can complete certain tasks exponentially faster than an ordinary computer. \n             Coaxing qubits \n           Esteban Martinez, an experimental physicist at the University of Innsbruck, and his colleagues completed a proof of concept for a simulation of a high-energy physics experiment in which energy is converted into matter, creating an electron and its antiparticle, a positron. The team used a tried-and-tested type of quantum computer in which an electromagnetic field traps four ions in a row, each one encoding a qubit, in a vacuum. They manipulated the ions\u2019 spins \u2014 their magnetic orientations \u2014 using laser beams. This coaxed the ions to perform logic operations, the basic steps in any computer calculation. After sequences of about 100 steps, each lasting a few milliseconds, the team looked at the state of the ions using a digital camera. Each of the four ions represented a location, two for particles and two for antiparticles, and the orientation of the ion revealed whether or not a particle or an antiparticle had been created at that location. The team\u2019s quantum calculations confirmed the predictions of a simplified version of quantum electrodynamics, the established theory of the electromagnetic force. \u201cThe stronger the field, the faster we can create particles and antiparticles,\u201d Martinez says. He and his collaborators describe their results on 22 June in  Nature 1 . Four qubits constitute a rudimentary quantum computer; the fabled applications of future quantum computers, such as for breaking down huge numbers into prime factors, will require hundreds of qubits and complex error-correction codes. But for physical simulations, which can tolerate small margins of error, 30 to 40 qubits could already be useful, Martinez says. John Chiaverini, a physicist who works on quantum computing at the Massachusetts Institute of Technology in Cambridge, says that the experiment might be difficult to scale up without significant modifications. The linear arrangement of ions in the trap, he says, is \u201cparticularly limiting for attacking problems of a reasonable scale\u201d. Muschik says that her team is already making plans to use two-dimensional configurations of ions. \n             Are we there yet? \n           \u201cWe are not yet there where we can answer questions we can\u2019t answer with classical computers,\u201d Martinez says, \u201cbut this is a first step in that direction.\u201d Quantum computers are not strictly necessary for understanding the electromagnetic force. However, the researchers hope to scale up their techniques so that they can simulate the strong nuclear force. This may take years, Muschik says, and will require not only breakthroughs in hardware, but also the development of new quantum algorithms. These scaled-up quantum computers could help in understanding what happens during the high-speed collision of two atomic nuclei, for instance. Faced with such a problem, classical computer simulations just fall apart, says Andreas Kronfeld, a theoretical physicist who works on simulations of the strong nuclear force at the Fermi National Accelerator Laboratory (Fermilab) near Chicago, Illinois. Another example, he says, is understanding neutron stars. Researchers think that these compact celestial objects consist of densely packed neutrons, but they\u2019re not sure. They also don\u2019t know the state of matter in which those neutrons would exist. Read the related News & Views article, \" Quantum simulation of fundamental physics \". \n                   Google moves closer to a universal quantum computer 2016-Jun-08 \n                 \n                   Physics: Quantum computer quest 2014-Dec-03 \n                 \n                   Simulation: Quantum leaps 2012-Nov-14 \n                 \n                   Christine Muschik \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20137", "url": "https://www.nature.com/articles/nature.2016.20137", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "The technique's first test in people could begin as early as the end of the year. CRISPR, the genome-editing technology that has  taken biomedical science by storm , is finally nearing human trials. On 21 June, an advisory committee at the US National Institutes of Health (NIH) approved a proposal to use CRISPR\u2013Cas9 to help augment cancer therapies that rely on enlisting a patient\u2019s T cells, a type of immune cell. \u201cCell therapies [for cancer] are so promising but the majority of people who get these therapies have a disease that relapses,\u201d says study leader  Edward Stadtmauer , a physician at the University of Pennsylvania in Philadelphia. Gene editing could improve such treatments and eliminate some of their vulnerabilities to cancer and the body\u2019s immune system, he says. This first trial is small and designed to test whether CRISPR is safe for use in people, rather than whether it effectively treats cancer or not. It will be funded by a US$250-million immunotherapy foundation formed in April by former Facebook president Sean Parker. The trial itself does not yet have a budget. The University of Pennsylvania will manufacture the edited cells, and will recruit and treat patients alongside centres in California and Texas. The researchers will remove T cells from 18 patients with several types of cancers and perform three CRISPR edits on them. One edit will insert a gene for a protein engineered to detect cancer cells and instruct the T cells to target them, and a second edit removes a natural T-cell protein that could interfere with this process. The third is defensive: it will remove the gene for a protein that identifies the T cells as immune cells and prevent the cancer cells from disabling them. The researchers will then infuse the edited cells back into the patient. \n             On the move \n           \u201cLast year\u2019s excitement over CRISPR was in anticipation of this,\u201d says  Dean Anthony Lee , an immunologist at MD Anderson Cancer Center in Houston, Texas, and a member of the NIH\u2019s Recombinant DNA Research Advisory Committee (RAC), which reviewed the proposal. CRISPR, he says, makes genome engineering easy enough that such trials can move forward quickly. The RAC reviews all proposals for human trials involving modified DNA that are conducted in the United States. Stadtmauer\u2019s team will now have to convince US regulators and review boards at their own institutions to allow the trial. Immunologist Carl June at the University of Pennsylvania, who is a science adviser on the project, says that it could begin by the end of the year. Other trials may not be far behind.  Editas Biotechnologies  in Cambridge, Massachusetts, for instance, has said that it wants to use CRISPR in a clinical trial for a rare form of blindness as soon as 2017. However, RAC members say that they have not yet been approached about reviewing the trial. \n             Other techniques \n           CRISPR has courted most attention because of its ease of use, however the T-cell trial will not be the first test of the efficacy of using gene editing to fight diseases. In 2014, June led a trial using a different gene-editing system called zinc-finger nuclease. His group took blood from 12 people with HIV and removed the gene that encodes a protein on T cells that the virus targets. They hoped that this would prevent infection of the cells. The results were encouraging, and the technique is now being used in clinical trials for several other conditions. And last week, researchers at Great Ormond Street Hospital for Children in London began a safety study with 10  children  using a similar technique called TALENS. Instead of using a patient\u2019s own cells, the system uses T cells from a donor that have been edited to remove genes that would cause the patient\u2019s body to reject them. The gene editing then directs the T cells to attack the cancer and protects the cells from damage by other immunotherapy drugs. Although CRISPR is easier to use than the other techniques, and better at editing multiple genes at once, June says that the main challenge will be overcoming CRISPR's propensity for \u2018off-target\u2019 edits. These are instances in which the system cuts or mutates unintended parts of the genome. And despite precautions, the immune system could still attack the edited cells. \n             Once bitten, twice shy \n           During the RAC meeting, one of the committee\u2019s greatest concerns was a potential conflict of interest. Among other financial involvements, June has ties to the pharmaceutical company Novartis, holds patents on T-cell technologies, and could stand to benefit from the success of this trial. June declined to give details on the exact nature of his conflicts of interest, but says that his university is taking steps to manage it, such as preventing him from being involved in selecting patients. Several RAC reviewers suggested that the University of Pennsylvania not be allowed to recruit patients at all and to leave it to other institutions: this language did not make it into their final approval. However, the RAC members say they are being extra careful with this study. \u201cPenn has a very extensive conflict and has a history,\u201d says  Laurie Zoloth , a bioethicist at Northwestern University in Evanston, Illinois. Looming over the discussion is the name Jesse Gelsinger, who died at age 18 while participating in an early gene-therapy trial conducted by researchers at the University of Pennsylvania in 1999. A subsequent investigation found numerous problems with the study, including unreported animal data on the therapy\u2019s ill effects and the fact that the investigators had a financial stake in the study\u2019s outcome. The incident is generally considered to have set gene therapy back by decades. \u201cAny first use in humans we have to be extraordinarily careful,\u201d Zoloth says. So a lot is riding on this trial. But Mildred Cho, a bioethicist at Stanford University in California and an RAC member, says that safety work in animals for a new therapy will take researchers only so far. \u201cOften we have to take the leap of faith.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                 \n                   CRISPR, the disruptor 2015-Jun-03 \n                 \n                   Gene-editing method tackles HIV in first clinical test 2014-Mar-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20141", "url": "https://www.nature.com/articles/nature.2016.20141", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Team behind relocation scheme strongly defends attempt to establish \u2018insurance population\u2019. An ambitious project to relocate rhinos from South Africa to Australia has been accused by some conservation researchers of being a waste of money. The Australian Rhino Project charity, headquartered in Sydney, has attracted huge publicity for its plans to move 80 rhinos to Australia \u201cto establish an insurance population and ensure the survival of the species\u201d. It raised more than Aus$800,000 (US$600,000) in the year to September 2015, and hopes to start by flying out six rhinos later in 2016. The charity says that eventually, rhinos from the Australian herd could be sent back to Africa to re-establish wild populations there, when poaching \u2014 which is devastating rhino populations in Africa \u2014 becomes less of a threat. But in a letter published in  Nature  this week 1 , four researchers warn that the project \u201cis diverting funds and public interest away from the actions necessary to conserve the animals\u201d. The million-dollar cost of moving 80 animals would be better put towards poaching prevention, the researchers say. \u201cAnyone associated with conservation in Africa is well aware of the massive poaching crisis going on,\u201d says Matt Hayward, a conservation researcher at Bangor University, UK, and lead author of the  letter . But he says that moving rhinos to Australia is a bad solution. \u201cI don\u2019t think it can do any harm, but the pot of money is limited. We\u2019re better off focusing  in situ .\u201d But the rhino project\u2019s founder, Ray Dearlove, strongly defends the initiative. A \u201cstaggering amount of money\u201d has been put towards anti-poaching initiatives and animals are still being poached, he says, adding that moving rhinos to Australia is \u201cone possible strategy in the complex web of saving the rhino\u201d. (He also criticizes the letter for stating that the rhino-relocation effort will cost US$3.5 million, when the costs are not yet precisely known, and for, before a correction, misstating that 16 rhinos \u2014 not 6 \u2014 were to be transported in 2016.)\u00a0 Dearlove adds that he takes exception to the letter-writers\u2019 suggestion that the project \u201chas echoes of colonial times, when African resources were exploited\". \u201cIn terms of exploitation, it is completely opposite to that,\u201d he says. \u201cThis is an attempt to try and save the species.\u201d \n             Moving time \n           Hayward says that he is not opposed to moving animals for conservation purposes. He himself works on projects to reintroduce European bison ( Bison bonasus ) to Poland and red squirrels ( Sciurus vulgaris ) to parts of Wales. And conservationists are increasingly looking to move animals around to establish new or more secure populations, as climate change and activities such as logging or poaching disrupt their habitats. But Hayward argues that rhinos should not be removed from Africa. A rhino\u2019s value lies not just in the animal itself, but also in its connection to the landscape and environment of its native ecosystem, he says. Hayward and others also criticize the project for moving white rhinos ( Ceratotherium simum ), which have a global population of 20,170, rather than the much more endangered black rhinos ( Diceros bicornis ), of which fewer than 4,880 are left. Mark Stanley Price, a reintroduction specialist at the University of Oxford\u2019s Wildlife Conservation Research Unit, UK, notes that although black rhinos are more threatened, it is not clear whether these animals could be kept wild in Australia. They are browsing feeders \u2014 eating leaves, branches and fruit \u2014 which makes them less likely to adapt to the local vegetation than the more generalist, grazing white rhinos. \u201cIt would be much more difficult to manage black rhinos under those situations. And it is the blacks that need the help,\u201d he says. Stanley Price adds, \u201cThis is an interesting initiative. It\u2019s going to have some particular difficulties. Is it really the right answer?\u201d But the debate may prove academic: Dearlove says that although not all the permissions required for the relocation effort are yet in place, he still intends to transport the first rhinos this year. \n                   Stem-cell plan aims to bring rhino back from brink of extinction 2016-May-03 \n                 \n                   Worst year ever for rhino poaching in Africa 2016-Jan-25 \n                 \n                   Will China\u2019s new ivory controls make a difference? 2015-Jun-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20153", "url": "https://www.nature.com/articles/nature.2016.20153", "year": 2016, "authors": [{"name": "Daniel Cressey"}, {"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Future of science uncertain after referendum result. It was the result that  most scientists didn\u2019t want . The United Kingdom\u2019s vote to leave the European Union has plunged it into political and economic uncertainty \u2014 and left researchers worried over the future of their funding and collaborations, the UK\u2019s participation in  major European research programmes , and the freedom of movement and employment status of thousands of scientists.\u00a0 Many researchers in the UK  expressed shock and dismay  as the result of the 23 June referendum \u2014 with 52% of people voting in favour of \u2018Brexit\u2019 to 48% against \u2014 sank in. (See  'How scientists reacted to the Brexit' .) \u201cThis is a poor outcome for British science and so is bad for Britain,\" Paul Nurse, the head of the Francis Crick Institute in London and a Nobel-prizewinning geneticist, told journalists. \"British scientists will have to work hard in the future to counter the isolationism of Brexit if our science is to continue to thrive,\u201d he said. The messy and protracted process of negotiating a UK departure from the EU means that  it may not become clear  for years how science is affected. Politicians campaigning for a UK divorced from the EU had pledged before the vote that universities and scientists in the country would not lose out. But immediate concerns for researchers revolve around funding: UK universities currently get around 16% of their research funding, and 15% of their staff, from the EU. \u201cThis is going to be very damaging,\u201d says Jonathan Butterworth, a physicist at University College London who works on  the ATLAS experiment at the Large Hadron Collider  near Geneva, Switzerland. Another urgent worry, he says, is for students and postdocs from elsewhere in Europe at universities in England, Wales, Scotland and Northern Ireland. \u201cWe need strong statements that the level of research and education funding that was coming though the EU will be guaranteed,\u201d he adds. Jamie Martin, an advocate for the UK's exit from the EU and a former special adviser to the pro-Brexit politician Michael Gove, said that he would offer \u201ctotal reassurance\u201d to worried scientists. Although most academic groups had lobbied for the UK to remain in the EU, Martin says that \u201cthe good news for them is that the people at the top of the Vote Leave campaign share their instincts on science\u201d. This includes being open to skilled people from outside the UK and understanding the importance of continued funding, he says. \n             Losing access \n           Researchers fear that if the UK leaves the EU, the country could lose access to the bloc\u2019s research programmes, including  the Horizon 2020 programme of research grants . The UK currently hosts more EU-funded holders of grants under the European Research Council than any other member state. Being outside the EU would not automatically rule out the UK\u2019s involvement in EU research programmes. Horizon 2020, for instance, has association agreements with 15 other countries, which gives them equal rights to participation as EU member states in return for a negotiated financial contribution. But associate membership may not be possible for the UK if it moves to restrict the free movement of people. Swiss scientists, for example, experienced numerous problems when a referendum in that country to restrict the freedom of movement of people from Croatia across its borders led to its researchers being cut out of Horizon 2020 programmes. (A patched-up deal whereby Switzerland\u2019s government is paying for individual Swiss scientists to take part in research programmes is an interim measure that currently holds only until February 2017.) Before the vote, a report from Digital Science (a consultancy in London operated by the Holtzbrinck Publishing Group, which also has a share in  Nature \u2019s publisher), estimated that the UK could lose \u00a31 billion (US$1.4 billion) in science funding each year if the government did not make up the shortfall in EU-linked research funds. Researchers have already begun to call for the UK to maintain science funding and to welcome researchers from abroad. \u201cAny failure to maintain the free exchange of people and ideas between the UK and the international community including Europe could seriously harm UK science,\u201d said the head of the Royal Society in London, Venkatraman Ramakrishnan, a Nobel-prizewinning structural biologist. And Julia Goodfellow, president of the umbrella group Universities UK, which had campaigned against a leave vote, said that her group\u2019s \u201cfirst priority\u201d would be to try to convince the government that EU staff and students should be allowed to continue studying in the country. Brexit \u201ccreates opportunities for science\u201d, says Martin \u2014 such as possible increases in science funding, repealing EU rules that some say hamper research, and the possibility that controlling unskilled migration could in turn mean more scope for increased migration of skilled workers, such as scientists. \u201cNow what it\u2019s about is scientists lobbying to get these changes,\u201d he adds. In a tweet this morning, science minister Jo Johnson, a supporter of the UK remaining in the EU and the brother of the prominent 'leave' campaigner Boris Johnson, simply said: \u201cBig decision. Let's make it work.\u201d What is your reaction to the result of the UK's EU referendum?  Tell us your thoughts . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   How scientists reacted to the Brexit 2016-Jun-24 \n                 \n                   Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                 \n                   Brexit: UK should remain 2016-Jun-15 \n                 \n                   Scientists say \u2018no\u2019 to UK exit from Europe in Nature poll 2016-Mar-30 \n                 \n                   Better together 2016-Feb-03 \n                 \n                   Academics across Europe join \u2018Brexit\u2019 debate 2016-Feb-03 \n                 Reprints and Permissions"},
{"file_id": "534446a", "url": "https://www.nature.com/articles/534446a", "year": 2016, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Sea-floor instruments will monitor seismic activity very close to the Cascadia fault. On 15 June, Canada broke ground on an offshore earthquake early-warning system. Sea-floor sensors will monitor the  Cascadia subduction zone off British Columbia  to provide crucial seconds of warning if the \u2018big one\u2019 hits. Putting sensors so close to the fault should give the Canadian system an edge over a more developed sister project in the United States. To produce early warnings of quakes, scientists rely on a network of seismometers and accelerometers to detect the tremor\u2019s first, non-destructive primary (P) waves. Those waves travel faster than the destructive secondary (S) waves, and so hit cities seconds to minutes earlier. The closer that detectors are to the source of an earthquake, the more warning they can provide. That time can be used to stop high-speed trains, shut down nuclear reactors and tell the general population to brace for shaking. But with offshore faults, getting close to the action means  putting sensors under water , which is very expensive. Japan pioneered earthquake early warnings. The country has had a system to stop bullet trains since the 1960s, and public warnings have been issued since 2007. During  the magnitude-9 Tohoku earthquake of March 2011 , residents of Sendai, the major city nearest to the epicentre, got 15\u2009seconds of warning; Tokyo got more than a minute. Japan added data from an array of undersea seismometers to its earthquake early-warning system in August 2011, and a second phase of that project was completed in March, more than doubling the number of offshore detectors to 50. Now, the country is working on an ambitious 150-station network called S-net. Connected by 5,700\u2009kilometres of cable, it could provide up to an extra 30\u2009seconds of warning for a large offshore quake. The United States and Canada have lagged far behind Japan, despite the fact that the Cascadia subduction zone off North America\u2019s west coast is expected to one day produce a catastrophic \u2018megathrust\u2019 quake similar to the Tohoku one. By the end of June, the research non-profit group Ocean Networks Canada (ONC) in Victoria plans to have installed three accelerometers on its NEPTUNE sea-floor observatory, which consists of more than 840\u2009kilometres of ocean-bottom cable looped out past the Cascadia fault (see \u2018Quake watch\u2019). \u201cI took this job and asked, \u2018Why aren\u2019t we doing earthquake early warning?\u2019\u201d says ONC president Kate Moran, who joined the organization in 2011 as director of NEPTUNE. The network already has a handful of seismometers, but these send data back in packets instead of instantaneously, and the information is subject to censorship by the navy. As such, Moran says, they are ill-suited for an early-warning system. The new accelerometers, which have a simpler data stream designed to circumvent these issues, were made possible by a Can$5-million (US$3.9\u2011million) grant from the British Columbia govern\u00adment in February. The team is also hoping to install a tilt\u00admeter down a 300-metre borehole, to detect slow, almost imperceptible movement of the tectonic plates at the fault. Clusters of such slow-slip events  occurred before the 2011 Japan quake , and detecting them might help seismologists to track the strain that is building on the fault. Moran anticipates that within 5 years, the ONC will have 40 accelerometers on- and offshore to produce public early warnings. The instruments will be positioned specifically to detect an earthquake resulting from a subduction-zone tremor. Spotting quakes from other faults, which would be smaller but potentially much closer to cities, would require a significantly denser network of accelerometers. On the US west coast, a network of onshore accelerometers can already alert a select group of users \u2014 such as the Bay Area Rapid Transit system in northern California \u2014 to the early rumbles of earthquakes. That prototype programme,  called ShakeAlert , is hoping to get its information to a wider audience soon. \u201cI think we\u2019re really now, finally, at the beginning of rolling out a public system, after years of trying to get funding,\u201d says ShakeAlert lead Richard Allen, a seismologist at the University of California, Berkeley, who anticipates issuing public alerts within five years. ShakeAlert got its first congressional funding in December 2014, and now has about half the funds it needs for a full system, says Allen. To reliably detect quakes from multiple fault lines, Allen reckons that the network needs about 1,100\u00a0detectors just in California, where it currently has about 500. The US National Science Foundation supports a handful of wired sea-floor seismometers off the coast of Oregon as part of its Ocean Observatories Initiative. But these sensors have the same problems as the current Canadian ones, says Martin Heesemann, a marine geoscientist with the ONC. He adds that the group\u2019s new accelerometers will be the only instruments on North America\u2019s megathrust fault designed specifically for early warning rather than research. The offshore Canadian system \u201cwill totally be better\u201d than the US system, says Moran with a laugh. \u201cIt\u2019s nice to be better than the United States.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     In Japan, small shakes presage big quakes 2016-Jan-28 \n                   \n                     California quake puts warning system in the spotlight 2014-Aug-29 \n                   \n                     Global seismic network takes to the seas 2014-Mar-12 \n                   \n                     Hidden depths 2011-Jun-22 \n                   \n                     Undersea project delivers data flood 2010-Apr-20 \n                   \n                     Cascadia quake zone gets wired up 2010-Jan-28 \n                   \n                     Ocean Networks Canada \n                   \n                     S-net \n                   \n                     ShakeAlert \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20176", "url": "https://www.nature.com/articles/nature.2016.20176", "year": 2016, "authors": [{"name": "Dalmeet Singh Chawla"}], "parsed_as_year": "2006_or_before", "body": "The apparent trend has been on the rise over the past two\n              decades. Men cite their own papers 56% more than women on average, according to an\n            analysis of 1.5 million studies published between 1779 and 2011. The analysis looked at papers across disciplines in the digital library\n            JSTOR and found that men\u2019s self-citation rate had risen to 70% more than women\u2019s over\n            the past two decades, despite an increase of  women in academia  in recent years. Around 10% of a given paper\u2019s references are likely to\n            be self-citations by the paper\u2019s authors regardless of their gender. What the analysis, posted on arXiv on TK June, cannot clarify is whether\n            this trend is a by-product of the  under-representation of women  in senior academic positions or some separate effect. According to the paper, academics working in ecology and evolution,\n            sociology and molecular biology are the most likely to cite themselves, whereas\n            historians and classical scholars are the least likely. \n             Tooting their own horns \n           Citations define scholars, for better or worse. They are the currency of\n            widely debated metrics such as the  h -index that\n            measure productivity and the impact of researchers\u2019 publications. These metrics are\n            often the basis of decisions made on tenure and grant applications. Most self-citations are \u201cappropriate,\u201d where scholars are legitimately\n            citing past work, says Molly King, the study's lead author and a sociologist at Stanford\n            University in California. They aren\u2019t necessarily a conscious attempt to game the\n            system. However, a small fraction could be deliberate attempts to boost an\n            academic\u2019s own citation count. \u201cEvery citation a paper receives will attract additional\n            future attention from other scholars,\u201d says King. So if men are citing their own papers\n            more, they will receive extra attention from their peers, she notes. It\u2019s something that  hiring and tenure committees  should take into account when assessing the impact of researchers and\n            their work, King says. \n             But wait \u2026 \n           There are some limitations to the study. King and her colleagues deciphered the gender of all authors listed on a\n            publication based on first names and their associated sex in US Social Security\n            Administration records. They discarded gender-neutral names. But they also dropped\n            authors listed with only a first initial, which the researchers acknowledge may have\n            excluded women disproportionately. In fact, the paper suggests that female authors may in some cases be\n            using only their first initials to obscure the fact that they are women. \u201cOnly 56.4% of all the authors in their database were able to be assigned\n            a gender,\u201d says Adrian Letchford, a data scientist at the University of Warwick in\n            Coventry, UK. \u201cThat's a very big portion left out, especially considering that women may\n            be actively hiding their gender.\u201d There was also no way to control for an academic\u2019s productivity \u2014 or the\n            fact that men generally have more senior positions in academia, publish more papers and\n            therefore have more work to self-cite, says Cassidy Sugimoto, an information scientist\n            at Indiana University Bloomington. \u201cSelf-referencing is highly dependent upon productivity: one cannot\n            reference a work one has not written,\u201d she says. Around 78% of the authors in the\n            study\u2019s sample population are men and roughly 22% are women. There are other possible explanations for the trend, according to the\n            study authors, including the idea that men view their abilities more positively than\n            women do or that men face fewer  societal penalties  for self-promotion than do women. Another possible contributing factor\n            may be that men tend to specialize more. That means that they would have fewer peers\n            working in the same field, and so they might end up citing themselves more. Nevertheless, says Sugimoto, the topic is an important one to look into.\n            \u201cThe degree to which there is gendered behaviour in self-referencing is an important\n            observation and one that can open new lines of inquiry and has potential implications\n            for science policy.\u201d \n                   Researchers debate whether female computer coders face bias\n                      2016-Feb-15 \n                 \n                   Bibliometrics: Global gender disparities in science\n                      2013-Dec-11 \n                 \n                   Inequality quantified: Mind the gender gap 2013-Mar-06 \n                 \n                   Molly King \n                 \n                   Adrian Letchford \n                 \n                   Cassidy Sugimoto \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20158", "url": "https://www.nature.com/articles/nature.2016.20158", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Researchers respond to the UK's momentous decision to leave the EU. Nature  rounds up reaction from institutions and researchers across the world to the  United Kingdom's historic vote to leave the European Union.  \n             Emily Morris is a PhD student working on plant root development at the University of Nottingham, UK: \n           \u201cI am 9 months into my PhD and this result makes me terrified about my future in science. Many people are commenting that young researchers would be better off moving away from the UK now. The atmosphere in the lab today is depressing. A day of grieving should be allowed but I hope by Monday scientists will be discussing initiatives to save UK science rather than how to jump ship.\u201d \n             Anne Glover is Dean for Europe at the University of Aberdeen, UK, and former EU chief scientific adviser: \n           \u201cI am personally heartbroken and I have great concern for the future of British science, engineering and technology. Our success in research and resulting impact relies heavily on  our ability to be a full part of European Union science arrangements  and it is hard to see how they can be maintained upon a Brexit.\" \n             Christian M\u00f6stl studies physics at the Space Research Institute of the Austrian Academy of Sciences in Graz, Austria: \n           \u201cWhile collaborative funding may get much more difficult,  researchers from the EU should collaborate with their UK colleagues like we've always done  it and like we don't care about this result. Even more so now. I work in space and astrophysics and I am currently participating in an EU-funded FP7 project on the prediction of solar storms, led by the UK\u2019s Rutherford Appleton Laboratory. The Brexit directly affects us, as we are planning on a follow-up project and now have no idea if that is even possible.\u201d \n             Robert Lechler is president of the UK's Academy of Medical Sciences in London: \n           \"This is a very disappointing outcome for medical science. The scientific community needs to send a strong message that we are still open for business. As part of this, research will need access to funding sources to replace those put at risk by exiting the EU, as well as clear plans to maintain access to European research talent and mechanisms for scientific collaboration.\u201d \n             Wendy Piatt is director-general of the UK's Russell Group of universities: \n           \u201cLeaving the European Union creates significant uncertainty for our leading universities but we will work with the government to minimize any disruption caused by this decision.\u00a0The UK has not yet left the EU so it is important that our staff and students from other member countries understand that there will be no immediate impact on their status at our universities. However, we will be seeking assurances from the government that staff and students currently working and studying at our universities can continue to do so after the UK negotiates leaving the EU.\" \n             Glenn Crocker is chief executive of the bioscience incubator BioCity Nottingham, UK: \n           \"I am deeply concerned about the impact on UK research and on funding for small companies, both of which have benefited greatly from  EU support . I am also concerned about the impact on the free movement of labour and the restriction on the skills base if the UK turns inwards.\" \n             Vanessa Sancho-Shimizu studies childhood infectious diseases at Imperial College London, and has been an EU-funded Marie Curie research fellow since 2008: \n           \"I'm shocked and thoroughly disappointed. I was on a career panel only yesterday singing the praises of the UK as a  wonderful place of opportunity  for young scientists and I feel like that has changed overnight. The only reason I'm here is because EU finding brought me over. It's devastating for science.\" \n             Gary McDowell is the executive director of The Future of Research, a non-profit foundation in Massachusetts, USA: \n           \"Already I'm discussing with UK citizens postdoc\u2019ing and studying in the United States the harsh reality of this new situation, and how this will make a science funding system already strained into an unworkable mess. I feel many now will not return and a brain drain is inevitable.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                 \n                   Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                 \n                   Brexit: UK should remain 2016-Jun-15 \n                 \n                   Scientists say \u2018no\u2019 to UK exit from Europe in Nature poll 2016-Mar-30 \n                 \n                   Better together 2016-Feb-03 \n                 \n                   Academics across Europe join \u2018Brexit\u2019 debate 2016-Feb-03 \n                 Reprints and Permissions"},
{"file_id": "534444a", "url": "https://www.nature.com/articles/534444a", "year": 2016, "authors": [{"name": "Sarah Wild"}], "parsed_as_year": "2006_or_before", "body": "Struggle in Northern Cape province highlights a balancing act that scientists leading gigantic projects face. Northern Cape Province \u201cMove it away! We don\u2019t want it!\u201d a farmer shouted at a crowded meeting in Carnarvon, a small town in the semi-arid, sparsely populated Northern Cape,  one of South Africa\u2019s poorer provinces . He was talking about what will be the largest radio telescope in the world, the international Square Kilometre Array (SKA), a portion of which is due to be built nearby. Representatives from SKA South Africa, an organization of scientists, engineers and technocrats, were attending the meeting of farmers in May, in an attempt to respond to rising criticism of the project from local people. \u201cIt\u2019s fine to be part of the international community, but how is it helping this community?\u201d came a faceless call from the other side of the meeting hall. In 2012, the SKA\u2019s coordinating organization decided that it would divide its thousands of dishes and many more antennas, whose combined \u2018collecting area\u2019 for radio waves will span approximately one square kilometre, between Australia and South Africa. The site in the Northern Cape will include 197\u00a0dishes, and form part of the project\u2019s first phase, SKA1. The 64-dish MeerKAT tele\u00adscope, which will be part of SKA1, is already being built. The rest of the dishes will be added from 2018. Last year,  opposition to the Thirty Meter Tele\u00adscope  on Mauna Kea, Hawaii,  prompted the state\u2019s supreme court to invalidate the telescope\u2019s construction permit . Opposition to the SKA is unlikely to derail the project because legislation protects most of the Northern Cape for astronomy. But SKA South Africa officials say that they need community buy-in if the project is to be sustainable over its 50-year life. The struggle that is playing out in the Northern Cape illustrates the balancing act that scientists who lead gigantic projects must pull off\u00a0\u2014 to highlight the benefits that the project will bring to an area without over\u00adinflating expectations. When SKA South Africa proposed the SKA project to the Northern Cape community, starting with the MeerKAT telescope in 2008, it said that the project would lead to local economic development, create jobs and improve opportunities for children through education and science. But the organization never quantified these objectives\u00a0\u2014 and now its director, Rob Adam, is struggling to manage the expectations of the poorest members of the Northern Cape, who are largely \u2018coloured\u2019 people, a recognized racial classification in South Africa. SKA South Africa has already come good on some of its promises. It now employs a high-school maths and science teacher for Carnarvon, for example, and is paying for five coloured students at Carnarvon high school to attend university as part of a pan-African bursary programme that it runs. But members of the coloured community complain that such resources haven\u2019t materialized across the board\u00a0\u2014 not all the towns in the area have gained a high-school teacher, for example. And although a small influx of scientists, engineers and contractors has to some extent improved the economies of the province\u2019s towns, the communities are not yet satisfied. \u201cWhat\u2019s in it for us?\u201d asked one resident at a meeting in the Northern Cape town of Brandvlei in May. Adam says that the community\u2019s expectations have risen beyond what the SKA can provide. \u201cYou must understand, we are not the government, the education department and the police, all rolled into one,\u201d he told the crowd in Brandvlei. The problem is different for members of the richer, mainly white, sheep-farming community of the Northern Cape, who are concerned about SKA South Africa\u2019s land acquisition. According to the Astronomy Geographic Advantage Act, which was passed in 2007, the government has the right to acquire land for the project within a designated \u2018core\u2019 area if negotiations fail, and if the land is required for the SKA and the organization has offered a fair price. In 2008, the government bought Losberg farm, the site of the MeerKAT telescope. What is riling this community is that SKA South Africa is now eyeing 36 other farms\u00a0\u2014\u00a0which comprise about 118,000\u2009hectares\u00a0\u2014\u00a0to accommodate the further 133\u00a0dishes that make up SKA1. Many farmers say that the loss of their farms will destroy the local, agriculture-based economy, and that they are being forced to sell. Although the amount of land needed for the SKA is now agreed, the farmers are also suspicious about the scope of the project. \u201cThey don\u2019t believe things will stop here,\u201d says Henning Myburgh, general manager of farmers\u2019 organization Agri Northern Cape in Kimberley. The spectre of Zimbabwe-style land expropriation, in which the government took land from white farmers without compensation, is also present. \u201cIt\u2019s a land grab, one way or the other, be it for SKA or something else,\u201d says Eric Torr, a former resident of the province who owns a local aviation company. Expropriation would be a last resort, say SKA South Africa officials. \u201cIt\u2019s not in the best interests of the SKA to do that because we have to live in this community,\u201d says Alice Pienaar-Marais, who is in charge of the land-acquisition process. She is confident that SKA South Africa will acquire the 36 farms by the end of next year, in time for SKA1 construction in 2018. SKA Australia, meanwhile, \u201ccould be doing more\u201d with respect to community engagement, project director David Luchetti told  Nature . The Australian SKA Pathfinder telescope, which is currently being commissioned, is to be built on an area that traditionally belongs to the Wajarri Yamatji tribe. Following the 2009 Indigenous Land Use Agreement, which was negotiated between the government and the indigenous group, the tribe has received benefits worth more than Aus$18.1\u00a0million (US$13.5\u00a0million) in exchange for the use of the land for radio\u00adastronomy. But the agreement needs to be renegotiated for the SKA before construction starts. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Hawaiian court revokes permit for planned mega-telescope 2015-Dec-03 \n                   \n                     Telescope array could usher in astronomy revolution in Africa 2014-Jan-24 \n                   \n                     Nations to split telescope project 2012-May-25 \n                   \n                     Astronomy in South Africa: The long shot 2011-Dec-14 \n                   \n                     Square Kilometre Array \n                   \n                     SKA South Africa \n                   \n                     SKA Australia \n                   Reprints and Permissions"},
{"file_id": "534599a", "url": "https://www.nature.com/articles/534599a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The mission will peek through the gas giant\u2019s swirling clouds in search of a planetary core. On 4 July, NASA intends to finish a job that started with the agency\u2019s Galileo mission 21 years ago. At 8:18 p.m. Pacific time, the Juno spacecraft will ignite its main engine for 35 minutes and nudge itself into orbit around Jupiter. If all goes well, it will eventually slip into an even tighter path that whizzes as close as 4,200 kilometres above the planet\u2019s roiling cloud-tops \u2014 while dodging as much of the lethal radiation in the planet\u2019s belts as possible. The US$1.1-billion mission, which launched in 2011, will be the first to visit the Solar System\u2019s biggest planet since NASA\u2019s Galileo spacecraft in 1995. Picking up where Galileo left off, Juno is designed to answer basic questions about Jupiter, including what its water content is, whether it has a core and what is happening at its rarely seen poles (see \u2018Mission to Jupiter\u2019). Scientists think that Jupiter was the first  planet to condense  out of the gases that swirled around the newborn Sun 4.6 billion years ago. As such, it is made up of some of the most primordial material in the Solar System. Scientists know that it consists mostly of hydrogen and helium, but they are eager to pin down the exact amounts of other elements found on the planet. \u201cWhat we really want is the recipe,\u201d says Scott Bolton, the mission\u2019s principal investigator and a planetary scientist at the Southwest Research Institute in San Antonio, Texas. \n               A murky disposition \n             Jupiter\u2019s familiar visage, with its broad brown belts and striking Great Red Spot, represents only the tops of its churning clouds of ammonia and hydrogen sulfide. Juno \u2014 named after the Roman goddess who could see through clouds \u2014\u00a0will peer hundreds of kilometres into the planet\u2019s atmosphere using microwave wavelengths. Exploration of Jupiter\u2019s interior should reveal more about the formidable atmospheric convection that powers the planet, says Paul Steffes, an electrical engineer at the Georgia Institute of Technology in Atlanta. Steffes and his colleagues have run a series of laboratory experiments to simulate what different layers of Jupiter\u2019s atmosphere might look like: from near the cloud-tops, where experimental temperatures are \u2013100\u2009\u00b0Cto deeper in the planet, where they rise to more than 300\u2009\u00b0C. By comparing Juno\u2019s observations to their simulations, the scientists hope to determine how much ammonia, water vapour and other materials swirl at different atmospheric depths. \u201cOnce we understand the recipe for Jupiter\u2019s atmosphere, we\u2019ll get a clearer insight into how it evolved,\u201d says Steffes. Different theories predict varying amounts of water in Jupiter\u2019s atmosphere, depending on whether the planet coalesced at its current distance from the Sun or somewhere else. Actual measurements of atmospheric water content could help to clarify this debate. \n               Normal is good \n             In anticipation of Juno\u2019s arrival, professional and amateur astronomers have been observing Jupiter with ground-based and space-based telescopes. For now, the planet is not experiencing any unusual atmospheric changes. \u201cIt\u2019s kind of in its normal state, which is good,\u201d says Amy Simon, a planetary scientist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. This \u2018normal\u2019 behaviour gives researchers confidence that they will be able to understand Juno\u2019s findings. The Great Red Spot continues to shrink, as it has done in recent years, and to interact less and less with the jet streams on either of its edges. The broad belt just north of the planet\u2019s equator has been expanding since late 2015 \u2014 a change that might be connected to processes deep in the atmosphere. \u201cTrying to connect events that are happening at one level to events happening in another tells you how well coupled the whole atmosphere is,\u201d says Leigh Fletcher, a planetary astronomer at the University of Leicester, UK. As Juno probes deeper and deeper into the planet\u2019s atmosphere, researchers hope to get information on a layer of hydrogen compressed into a liquid by  increasing pressures . That liquid conducts electricity, which powers Jupiter\u2019s enormous magnetic field. Deeper still, the spacecraft will look for evidence of a core \u2014 a dense nugget of heavier elements that most scientists think exists, but has never been observed. Juno will make precise measurements of how Jupiter\u2019s gravity tugs on the spacecraft, which should reveal whether a core is present. \n               Pole position \n             Juno will also get an unprecedented glimpse of Jupiter\u2019s poles. To avoid the most dangerous radiation belts that surround the gas giant \u2014 which over the lifetime of the mission could fry the spacecraft with the equivalent of more than 100 million dental X-rays\u2014 Juno will take a long elliptical dive around the planet on every orbit. The spacecraft will fly directly over Jupiter\u2019s magnetically intense auroras, and could spot unusual circulation patterns that resemble a hexagon-shaped feature parked on Saturn\u2019s north pole. The lessons that scientists learn from Jupiter will apply to  other gas giants , including those outside the Solar System. \u201cIf we understand how it formed, we\u2019ll have a much better handle on giant-planet influences in planetary systems around other stars,\u201d Fletcher says. Juno will provide scientists\u2019 last chance to look at Jupiter for a long time. It is scheduled to make 37 total orbits before performing a kamikaze run in early 2018, burning up inside the planet\u2019s clouds to keep it from contaminating the moon Europa. The only other mission planned to the gas giant is the European Space Agency\u2019s  Jupiter Icy Moons Explorer (JUICE)  spacecraft, which could launch as early as 2022 and will focus mainly on the moon Ganymede. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Jupiter glimpsed as aliens would see it 2015-Feb-13 \n                   \n                     Diamond drizzle forecast for Saturn and Jupiter 2013-Oct-09 \n                   \n                     Europe plans mission to Jupiter 2012-May-02 \n                   \n                     Closing in on Jupiter's past 2011-Aug-01 \n                   \n                     NASA\u2019s Juno site \n                   \n                     Southwest Research\u2019s Institute\u2019s Juno site \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20152", "url": "https://www.nature.com/articles/nature.2016.20152", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Pioneering techniques could settle longstanding controversy about the accuracy of previous simulations. For the first time, cosmologists have used the full power of Albert Einstein's general theory of relativity to perform detailed calculations of the Universe\u2019s evolution. The two groups\u2019 techniques \u2014 which break with nearly a century of tradition \u2014 could help to settle a controversy over the accuracy of previous, simplified simulations, and could help researchers to interpret the results of astronomers\u2019 increasingly precise observations. General relativity interprets gravity as the warping of space-time. Soon after Einstein proposed his theory in 1915, others realized that it had dramatic implications on the cosmic scale. Belgian cosmologist Georges Lema\u00eetre and others pointed out in the 1920s that a Universe that satisfies Einstein\u2019s theory should either expand or contract. (Meanwhile, astronomer Edwin Hubble and others showed that it was, in fact, expanding 1 .) But solving Einstein\u2019s equations on a cosmic scale was impossible without making assumptions to simplify the calculations. To reach their conclusions, Lema\u00eetre and the other early relativists assumed that matter was uniformly distributed as a continuum across space, rather than being concentrated in stars and galaxies. \n             A matter of distribution \n           The advent of technology did not substantially change the situation, because the full relativistic calculations were difficult even for supercomputers. Most cosmologists have continued to model the Universe, starting with the Big Bang, in this way. To explain how large structures such as galaxies and clusters of galaxies form from a diffuse primordial gas, researchers start with regions of slight 'overdensity', which then develop into lumpy structures under the pull of gravity. Such models, however, assume an uneven spread of matter only for the relatively small area that they are studying \u2014 while maintaining a uniform distribution on the largest scales. Some cosmologists say that this was more of a necessary stratagem than a well-justified assumption. \u201cThe homogeneity of the Universe is a philosophical invention,\u201d says Sabino Matarrese, a general-relativity theorist at the University of Padua in Italy. In the past decade or so, Matarrese and others have argued that this assumption might even have led astronomers to misinterpret their data when they concluded that the Universe\u2019s expansion has been accelerating under the action of a mysterious \u2018dark energy\u2019. This, he says, triggered a heated debate. But, he adds, the assumption of homogeneity \u201cis, in part, circular reasoning, which we could try to question without getting into drama\u201d. Numerical relativist Eloisa Bentivegna of the University of Catania, Italy, says that, \u201cin principle, in an inhomogeneous Universe, distant galaxies could appear as if they were receding at an accelerated pace,\u201d mimicking the effects of dark energy. \n             Coming together \n           Now, she and Marco Bruni of the University of Portsmouth, UK, and independently Glenn Starkman of Case Western Reserve University in Cleveland, Ohio, and his colleagues, have performed the first full simulations of a Universe that follows general relativity without restrictions. Each group used supercomputers to model how an early Universe expands and how its warping evolves as matter begins to gather in large pools under the force of gravity, leaving other regions with more-rarefied gas. Their papers, which appear on 24 June in  Physical Review Letters 2 , 3  and in  Physical Review D 4  , still do not reproduce the full complexity of the actual Universe, but their full embrace of relativity is \u201drevolutionary\u201d, says Matarrese. The two groups used slightly different techniques with an emphasis on different questions: the Europeans focused more on the formation of 'overdense' structures, whereas the US group concentrated on how the Universe expands and how its curvature affects the propagation of light. Both teams say that, in the future, they plan to increase the sophistication of their models and to connect them to quantities that astronomers can actually measure. Both groups built on numerical-simulation techniques that had been developed for calculating  the warping of space-time around pairs of mutually orbiting black holes  and the resulting gravitational waves \u2014 the very predictions that were confirmed earlier this year 5   by the Advanced Laser Interferometer Gravitational-Wave Observatory  (LIGO). \u201cIt\u2019s a marriage between numerical relativity and cosmology that hasn't happened before,\u201d says Starkman. It will take perhaps two decades to unravel the potential of these techniques, Matarrese says. He and others say that \u2014 while dark energy is probably here to stay \u2014 researchers will need increasingly precise predictions to interpret the results of upcoming big-science observatories. These will include data from the Square Kilometer Array in Australia and South Africa. The big question is whether the pooling of matter in dense regions \u2014 and the subsequent formation of galaxies \u2014 can have effects on the overall expansion of the Universe. This 'back-reaction' effect might be tested by next-generation experiments, something that would be a \u201cgreat triumph\u201d, says cosmologist Scott Dodelson of the Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois. But, he says, it is unclear yet whether the teams' techniques are necessary to understand such effects, or if the more conventional methods suffice. Calculations by Robert Wald, a general relativity theorist at the University of Chicago in Illinois, and a colleague suggest that any such effects will be practically negligible[6]. \u201cI\u2019m claiming that the fact that the matter is concentrated in little blobs doesn't affect the expansion rate.\u201d Still, he says, the fully relativistic methods will be important in corners of cosmology that involve high energies, such as the very early stages of the Big Bang or the propagation of the light elementary particles called neutrinos. Starkman expects that, in the end, as far as the big picture is concerned, the standard model of cosmology will hold \u2014 including the existence of dark energy. \u201cBut we have to check.\u201d \n                   Measurement of Universe's expansion rate creates cosmological puzzle 2016-Apr-11 \n                 \n                   Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                 \n                   3D simulations of colliding black holes hailed as most realistic yet 2015-Apr-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20150", "url": "https://www.nature.com/articles/nature.2016.20150", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "June\u2019s sharpest science shots, selected by  Nature \u2019s photo team. Spacecraft going up and coming down, art in agar, turtles being tracked. All this and more in the return of  Nature \u2019s Images of the Month picture gallery. \n             Peake performance \n           \n             FishJellyFish \n           \n             BEAM is up \n           \n             Antarctic rescue \n           \n             Turtle trackers \n           \n             Tibetan Sentinel \n           \n             Shark-nappers busted \n           \n             Agar art \n           \n             Heavy load \n           Reprints and Permissions"},
{"file_id": "nature.2016.20162", "url": "https://www.nature.com/articles/nature.2016.20162", "year": 2016, "authors": [{"name": "Rachel Becker"}], "parsed_as_year": "2006_or_before", "body": "Preserved feathers and tissue provide a picture of hatchlings from the Cretaceous. Two tiny wings locked in amber 99 million years ago suggest that in the middle of the Cretaceous period \u2014 when dinosaurs still walked the planet \u2014 bird feathers already looked a lot like they do today. A team of researchers led by  Lida Xing , a palaeontologist at the China University of Geosciences in Beijing, recovered a first for the time period: a few cubic centimetres of amber from northeastern Myanmar that contained the partial remains of two bird wings. The specimens include bone, feathers and skin, according to a study published on 28 June in  Nature Communications 1 . Prior evidence of bird plumage from the Cretaceous, which stretched from 145 million to 66 million years ago, came from 2D impressions left in  sedimentary rocks  and  feathers  that had been preserved in amber but that gave no skeletal clues to their species of origin. \u201cFor the first time, we\u2019re seeing the feathers associated with the skeletal materials,\u201d says co-author  Ryan McKellar , who studies fossils in amber as curator of invertebrate palaeontology at the Royal Saskatchewan Museum in Regina, Canada. \n             Minute details \n           The amber even preserved claw marks, signs that before it died, one of the birds had struggled against the sticky resin that had engulfed its wing. The feathers retained their original colouring from pale dots and undersides to darker browns elsewhere, and on both wing fragments, the structures and arrangements of the feathers were similar to those seen in modern birds. The bones were smaller than a hummingbird's and incompletely developed. This suggests that the wings belonged to hatchlings, probably of enantiornithine birds \u2014 a primitive group that had teeth and clawed wings, and that went extinct at the same time as the dinosaurs, 66 million years ago. However, the feathers themselves were more like those of adults and showed no signs that they had moulted \u2014 suggesting they had developed quickly and skipped the downy juvenile stage of modern birds entirely. \u201cThey\u2019re basically hatching, and ready to go,\u201d says McKellar. Peter Makovicky , a curator at the Field Museum in Chicago, Illinois, who studies dinosaurs, says that these finds will help to reduce some of the detective work needed to infer a 3D structure from 2D fossils. \u201cThe colour patterns are preserved; the exact arrangement of feathers in three dimensions relative to the bone are preserved,\u201d he says. \u201cIt\u2019s fantastic because you get so much more detail.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Exquisite bird fossils reveal egg-producing ovary 2013-Mar-17 \n                 \n                   Early birds flew on four wings 2013-Mar-14 \n                 \n                   Beep Beep! from the Cretaceous 2007-Jul-13 \n                 \n                   Lida Xing \n                 \n                   Ryan McKellar \n                 \n                   Peter Makovicky \n                 Reprints and Permissions"},
{"file_id": "534597a", "url": "https://www.nature.com/articles/534597a", "year": 2016, "authors": [{"name": "Alison Abbott"}, {"name": "Daniel Cressey"}, {"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Researchers organize to lobby for science as country prepares for life outside the EU. The dust from  last week\u2019s vote  by the United Kingdom to leave the European Union is nowhere near settled, but the country\u2019s researchers are already bracing for the fallout. On 23 June, 52% of those who voted in the country\u2019s referendum came out in favour of leaving the EU. No one is sure how \u2018Brexit\u2019 will affect science, but many researchers are worried about long-lasting damage. Beyond the immediate economic impacts and the potential loss of EU funding\u00a0\u2014\u00a0which currently supplies some 16% of UK university research money\u00a0\u2014\u00a0scientists fear a loss of mobility between the country and the continent. \u201cI was on a career panel only yesterday, singing the praises of the UK as a wonderful place of opportunity for young scientists, and I feel like that has changed overnight,\u201d said Vanessa Sancho-Shimizu, an infectious-diseases researcher at Imperial College London, in response to a  Nature  survey last Friday . She is a Spanish national and one of many scientists who expressed similar views. Researchers are already mobilizing to lobby for the United Kingdom to remain a participant in EU science programmes, and for domestic funding to make up any shortfalls. \u201cWe need some kind of rapid monitoring to catch fallout problems early and implement remedial measures,\u201d says Mike Galsworthy, who led the Scientists for EU campaign. \u201cIf the science community wants to have an impact on the UK\u2019s negotiation strategy, it needs to clearly know what its own priorities are and start the process of making that case, strongly,\u201d says John Womersley, chief executive of the UK Science and Technology Facilities Council. Getting a guarantee to remain part of Horizon 2020, the EU\u2019s \u20ac74.8-billion (US$82.9-billion) programme of research grants, should be the community\u2019s top \u2014 and only \u2014 objective, he adds. Jamie Martin, an independent education consultant who advocated for Brexit, offers \u201ctotal reassurance\u201d to worried scientists. Most academic groups had lobbied for the United Kingdom to remain in the EU. Martin says that \u201cthe good news for them is that the people at the top of the Vote Leave campaign share their instincts on science\u201d. This includes being open to skilled people from other countries and understanding the importance of continued funding, he says. \n               People \n             Exactly when the United Kingdom will leave the EU is unclear. There is no set date for the government to invoke \u2018article 50\u2019 of the EU Lisbon treaty, but once it does, it will trigger a process of negotiation that must conclude within two years. Campaigners for a Leave vote\u00a0\u2014\u00a0including former London mayor Boris Johnson, whom many expect will lead the next government\u00a0\u2014\u00a0have said that there is no need to do this immediately, and informal negotiations with the rest of the EU can take place first. Those in favour of Brexit say that a United Kingdom outside the EU could allow in more skilled researchers while still driving down overall immigration numbers. \u2018Leave\u2019 campaigners have advocated a points-based immigration system such as Australia\u2019s, which would attempt to level the playing field between EU and non-EU researchers. But it\u2019s unclear whether the United Kingdom will still be attractive to talented researchers. Some have said that they feel less welcome in the country as a result of both the vote and the campaign leading up to it, which featured highly charged rhetoric around immigration. \n               Money \n             Even laboratories staffed primarily by UK nationals could feel the pinch. EU research funds have supplied an estimated \u20ac8\u00a0billion to the country over the past decade. The United Kingdom is also by far the largest recipient of loans to EU universities and research institutions from the European Investment Bank (EIB), receiving more than \u20ac2.8\u00a0billion since 2005\u00a0\u2014\u00a0some 28% of total EIB loans for higher education and research over that period. Agreed loans are secure, but the fate of those that are just beginning to be considered is unclear, says EIB spokesman Richard Willis. Leading campaigners for the Leave side pledged before the vote that universities and scientists in the United Kingdom who now get funding from the EU \u201cwill continue to do so\u201d. The country could try to negotiate access similar to the agreements that 15 other non-EU countries currently hold within Horizon 2020. But that might not be possible if the country acts to restrict free movement of people, as many Leave supporters have demanded. Switzerland, a non-EU member, is an associated country, but its researchers were cut out of full access to Horizon 2020 after the nation voted in a 2014 referendum to restrict immigration.  The long-term future worries the hell out of me.  \u201cThe long-term future worries the hell out of me,\u201d says Steven Cowley, who directs the Culham Centre for Fusion Energy in Abingdon, UK. The centre operates the Joint European Torus (JET), a nuclear-fusion facility, on behalf of the European Commission. The contract for JET runs out in 2018, but Cowley says he is confident that it will be extended, because it provides crucial expertise for ITER, the international fusion experiment under construction in southern France. The real problem, he says, is that the United Kingdom will not be able to compete to host the next major European facility. As for ITER itself, the EU is one of seven major international members of the project. The United Kingdom will have to rejoin it, either as an individual nation member\u00a0\u2014\u00a0which would mirror its membership of CERN, the European particle-physics lab\u00a0\u2014\u00a0or perhaps with \u2018associate member\u2019 status similar to that held by Switzerland. \n               Policy \n             A UK exit from the EU could also reshape the policy landscape for the countries that remain in the bloc. Germany, Italy and Austria are among the nations that have opposed EU funding for research on human embryonic stem cells. Others, including the United Kingdom and Sweden, called for research to be funded under appropriate ethical oversight\u00a0\u2014\u00a0leading to a deal in which research collaborations can be funded as long as partners from countries where the research is forbidden do not handle human embryonic stem cells themselves. The United Kingdom was \u201cin the forefront of guiding us into an acceptable and workable way around the issues\u201d, says stem-cell researcher Christine Mummery of the Leiden University Medical Center in the Netherlands. \u201cIf the UK cannot participate in decisions like this, it makes me nervous.\u201d Other European scientists fear for the future of their own countries\u2019 science bases if the UK vote empowers other anti-EU movements. Right-wing populist politicians in France, the Netherlands and Denmark are already calling for their own referendums. James Wilsdon, a science-policy researcher at the University of Sheffield, UK, says that beyond the questions about continued access to EU funding and policy, there is a more fundamental issue that UK researchers must come to grips with: the fact that most academic experts, research lobby groups and other experts came out in favour of staying in the EU and were ignored by the public. \u201cHere you have such a major question around which there was such a torrent of solid analysis and empirical evidence, and we\u2019ve had a rejection of that by 52% of the public,\u201d he says. \u201cThat needs to provoke some serious soul searching and reflection.\u201d See Editorial  page 589 Additional reporting by Davide Castelvecchi and Elizabeth Gibney. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Brexit vote highlights lack of leaving plan 2016-Jun-28 \n                   \n                     Researchers reeling as UK votes to leave EU 2016-Jun-24 \n                   \n                     How scientists reacted to the Brexit 2016-Jun-24 \n                   \n                     Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                   \n                     Brexit: UK should remain 2016-Jun-15 \n                   \n                     Scientists say \u2018no\u2019 to UK exit from Europe in Nature poll 2016-Mar-30 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20223", "url": "https://www.nature.com/articles/nature.2016.20223", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Giant UN report also reveals sustainability problem for wild-caught fish. The world is eating more fish now than ever \u2014 with farmed, rather than wild-caught, animals driving the increase in recent decades. These revelations emerge from a huge trawl of data that the Food and Agriculture Organization (FAO) of the United Nations releases every two years. The \u2018 State of World Fisheries and Aquaculture \u2019 (SOFIA) report, released on 7 July, shows an increase in fish production and consumption, largely driven by farmed fish. The report also says that 2014 was the first year in which more fish for consumption came from farming than were captured from the wild. In that year, people ate an average of 20.1 kilograms of fish, up from an average of 9.9 kg in the 1960s. Harvests of farmed shrimp, molluscs and seaweed have also grown markedly over the decades. Manuel Barange, director of the Fisheries and Aquaculture Policy and Resources Division at the FAO notes that 50% of aquaculture now uses species that do not need to be actively fed. The \u2018fishmeal\u2019 often used for feeding in aquaculture is made mostly of wild-caught animals, a wasteful and inefficient practice. Yet the overall picture is not rosy for wild fish. \u201cThe state of the world\u2019s marine fish stocks has not improved overall, despite notable progress in some areas,\u201d the SOFIA report notes. In 1974, the FAO assessed 90% of commercial, wild stocks as being fished at sustainable levels. By 2013, this had declined to 68.6%. Barange says that the rise in overexploitation appears to be slowing, but he adds:\u00a0\u201cThe message from SOFIA 2016 is we have 31% of the world\u2019s stocks that are being fished unsustainably. That figure has been increasing over time. And that is an issue of concern.\u201d There are other estimates  of how many animals the world\u2019s millions of fishers haul ashore every year, but the SOFIA report remains the go-to document for academics, says Barange. \n                   Fisheries: Eyes on the ocean 2015-Mar-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20224", "url": "https://www.nature.com/articles/nature.2016.20224", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Senior staff at leading journals want to end inappropriate use of the measure. The tide is turning against the impact factor \u2014one of publishing\u2019s most contentious metrics \u2014 and its outsized impact on science. Calculated by various companies and promoted by publishers, journal impact factors (JIFs) are a measure of the average number of citations that articles published by a journal in the previous two years have received in the current year. They were designed to indicate the quality of journals, but researchers often use the metric to assess the quality of individual papers \u2014 and even, in some cases, their authors. Now, a paper posted to the preprint server bioRxiv 1  on 5 July, authored by senior employees at several leading science publishers (including  Nature\u2019 s owner, SpringerNature), calls on journals to downplay the figure in favour of a metric that captures the range of citations that a journal\u2019s articles attract. And in an editorial that will appear on 11 July in eight of its journals, the American Society for Microbiology in Washington DC will announce plans to remove the impact factor from its journals and website, as well as from marketing and advertising. \u201cTo me, what\u2019s essential is to purge the conversation of the impact factor,\u201d says ASM chief executive Stefano Bertuzzi, a prominent critic of the metric. \u201cWe want to make it so tacky that people will be embarrassed just to mention it.\u201d Bertuzzi was formerly\u00a0the executive director of the American Society for Cell Biology, which banned the mention of impact factors from its annual meeting. \n               Brace for impact \n             Heidi Siegel, a spokesperson for London-based business-analytics firm Thomson Reuters, the major publisher of the JIF, says that the measure is a broad-brush indicator of a journal\u2019s output \u2014 and should not be used as a proxy for the quality of any single paper or its authors.\u00a0\u201cWe believe it is important to have a measure of the impact of the journal as a whole, and this is what the JIF does,\u201d says Siegel. But many scientists, funders and journals do not use it that way, notes Stephen Curry, a structural biologist at Imperial College London who is lead author on the bioRxiv preprint paper. Many researchers evaluate papers by the impact factor of the journals in which they appear, he worries, and impact factor can also influence decisions made by university hiring committees and funding agencies. Past research suggests that such uses are inappropriate. To emphasize some of the limitations of the impact factor, Curry\u2019s team plotted the distribution of citations for articles published in 2013\u201314 in 11 journals, including  Science ,  Nature ,  eLife  and three Public Library of Science (PLoS) journals. These are the citations used to calculate the 2015 impact factors. Curry\u2019s co-authors include senior employees at SpringerNature, eLife, PLoS, the Royal Society (which publishes several journals) and EMBO Press, and Marcia McNutt, who stepped down on 1 July from her role as editor-in-chief of  Science . Most of the papers garnered fewer citations than the impact factor for their journal: 74.8% of  Nature  articles were cited below its impact factor of 38.1, and 75.5% of  Science \u00a0papers were cited fewer than 35 times in two years (its impact factor was 34.7).  PLoS Genetics \u00a0had the lowest proportion of papers with fewer citations than its impact factor of 6.7, at 65.3%. Highly cited papers explain this disconnect.  Nature \u2019s most cited paper in the analysis was referenced 905 times and  Science \u2019s 694 times.  PLoS ONE \u2019s biggest paper accrued 114 citations, versus its impact factor of 3.1. \n               A measure of change \n             Some journals, such as those published by the Royal Society and EMBO Press, already publicize citation distribution. Curry and his fellow authors explictly recommend that other publishers play down their impact factors, and, instead, emphasize citation distribution curves such as those that his team generated, because they provide a more informative snapshot of a journal\u2019s standing. The preprint includes step-by-step instructions for journals to calculate their own distributions. A spokesperson for  Nature  says that the journal will soon update its websites \u201cto cover a broader range of metrics\u201d, and a representative of  Science  has stated that the journal will consider the proposal once the preprint article is published in a peer-reviewed journal. Ludo Waltman, a bibliometrics researcher at Leiden University in the Netherlands, says that citation distributions are more relevant than impact factors for high-stakes decisions, such as hiring and promotion. But he is wary of doing away with impact factors entirely; they can be useful for researchers who are trying to decide which among a pile of papers to read, for instance. \u201cDenying the value of impact factors in this situation essentially means that we deny the value of the entire journal publishing system and of all the work done by journal editors and peer reviewers to carry out quality control,\u201d Waltman says. \u201cTo me, this doesn\u2019t make sense.\u201d Anti-impact-factor crusaders say that it will take time to diminish the influence of the figure, let alone exile it. \u201cThis is a cultural thing,\u201d says Bertuzzi, \u201cand it takes pressure from multiple points to change behaviour\u201d. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     NIH metric that assesses article impact stirs debate 2015-Nov-06 \n                   \n                     We need a measured approach to metrics 2015-Jul-08 \n                   \n                     Evaluation: Moving away from metrics 2015-Apr-29 \n                   \n                     Transparency promised for vilified impact factor 2014-Jul-29 \n                   \n                     The maze of impact metrics 2013-Oct-16 \n                   \n                     Researchers feel pressure to cite superfluous papers 2012-Feb-02 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20226", "url": "https://www.nature.com/articles/nature.2016.20226", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Xenophobia and mobility fears among issues facing researchers two weeks on. Two weeks after the United Kingdom voted to leave the European Union, the future remains opaque. Concerns within the research community are particularly intense for those who rely on the EU for funding, or who have the right to work in the United Kingdom only because they are citizens of other EU countries. Here is  Nature \u2019s selection of the week\u2019s post-Brexit science news. \n             Location in limbo \n           Whether non-UK EU nationals currently living in the United Kingdom will be able to remain there has become a hotly debated issue \u2014 and 15% of academics working in the United Kingdom fall into this category. Theresa May, the current Home Secretary and leading candidate to be the next prime minister, has said that the future right to residence for these people will be part of negotiations with the rest of the EU. Other ministers have  backed her up on this,  and science minister Jo Johnson has said that he can  make no promises in this area . \n             Xenophobic incidents \n           Reports of xenophobia directed towards scientists and academics have surfaced since the vote. In the days that followed, Robert Parker, chief executive of the Royal Society of Chemistry, said that some of his staff were  told to \u201cgo home\u201d  while Exeter University, UK,  reported verbal abuse of staff and students . Since then, the Russell Group of leading UK universities  has expressed concern about racism . In a statement issued on 5 July, the group\u2019s chair, David Greenaway, and its chief executive, Wendy Piatt, said that universities have \u201calways warmly welcomed people from different cultures, ethnicities and beliefs. \u2026 So we are especially concerned by reports of increasing xenophobic incidents and how this could impact on our communities.\u201d \n             Medical moves \n           The Spanish government is eyeing up the European Medicines Agency, which is currently based in London. Spain\u2019s deputy prime minister, Soraya S\u00e1enz de Santamar\u00eda, says that a working group is looking to ensure that either or both the European Banking Authority, which is also in London, and the European Medicines Agency end up in Madrid. \u201cBoth are of great interest to Spain, and we will work on the possibility that at least one of them will be located on Spanish territory,\u201d she  told the  Financial Times . In the UK, life sciences minister George Freeman has enlisted GSK head Andrew Witty and Astra Zeneca boss Pascal Soriot to co-chair with him a Life Science Steering Group that will produce recommendations on how to deal with issues including regulation, trade and intellectual property in any new relationship with the EU. \n             Collaboration chill \n           There are also fresh fears that British researchers are being  frozen out of pan-EU funding proposals  made under the EU\u2019s Horizon 2020 programme, following  similar concerns last week.  Chris Husbands, vice-chancellor at Sheffield Hallam University, UK,  told the BBC : \u201cSince the referendum result, of the 12 projects that we have people working on for submission for an end-of-August deadline, on four of those projects researchers in other European countries have said that they no longer feel that the UK should be a partner.\u201d Brexit \"will add bureaucratic impediments for academic cooperation and mobility of students and researchers\", Peter Strohschneider, president of the DFG, Germany\u2019s main research funding agency,  told the German Press Agency (DPA) . \"Research collaborations will continue - they succeed so well with many other countries - but it will become ever more expensive and difficult,\" said Schneider. \n             Neuroscience worries \n           Brexit was the word on everyone\u2019s lips at the  Federation of European Neuroscience Societies  meeting in Copenhagen this week. Monica Di Luca, a neuroscientist at the University of Milan, Italy, and current president of the federation, issued a statement saying that she was \u201cdeeply concerned about the potential negative consequences for European neuroscience due to the decision of the UK to leave the EU\u201d. The federation's president-elect, Barry Everitt of the University of Cambridge, UK, said: \u201cThe UK\u2019s highest goal in the negotiations must be to remain part of the  European Research Council  and to preserve the essential freedom of movement for researchers at all stages of their careers.\u201d \n             Open access \n           Scientific journal  PeerJ  has  offered British researchers a discount  on its open-access publishing fee, on the grounds that \u201cEU grants to the UK look to dry up to the tune of billions of pounds each year\u201d. \n             Commons committee \n           The House of Commons Science and Technology Committee  opened its inquiry  into the implications of the referendum vote. Committee chair Nicola Blackwood  writes in  The Guardian : \u201cWe won\u2019t solve Brexit. I don\u2019t think even our most distinguished witness will have all the answers yet. What our inquiry will do, however, is identify the questions that need to be asked, the key priorities for negotiations and zero in on the main risks and opportunities.\u201d \n             Wanted: your stories \n           The Scientists for EU lobby group is  collecting stories from researchers  on how the vote is affecting them. Its head, Mike Galsworthy, has also  written up his take  on the year leading up to the vote, and where he goes from here, in  Research Fortnight . \n             Additional reporting by Alison Abbott \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "534159a", "url": "https://www.nature.com/articles/534159a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Network of deep-water observatories streams data in real time. Nearly 10 years, US$386\u00a0million and many grey hairs after it got the go-ahead, an enormous US ocean-observing network is finally up and running. On 6 June, the National Science Foundation (NSF) announced that most data are now flowing in real time from the Ocean Observatories Initiative (OOI), a collection of seven instrumented arrays. Oceanographers have the chance to test whether the  technologically complex and scientifically unprecedented project  will ultimately be worth it. \u201cIt has been stressful,\u201d says Richard Murray, the NSF\u2019s director for ocean sciences. \u201cIt\u2019s not for the faint-hearted.\u201d The raw data streams came online in April \u2014 months behind schedule, in part because of  a 2014 switch between university subcontractors . Through an open-records request,  Nature  obtained more than 1,200 pages of e-mails between project managers at the NSF and the Consortium for Ocean Leadership in Washington DC, which built the observatory. The records reveal an extraordinary level of tension throughout 2014 and into early 2015, as the final instruments were installed in the water and the contract for handling the data streams was switched from the University of California, San Diego, to Rutgers University in New Brunswick, New Jersey. \u201cPlease excuse my display of stress in this email, but the InBox is overflowing with high-priority, short-fuse items \u2014 none of which deserve to be ignored \u2014 but all of which cannot be completed within the requested time frames,\u201d Timothy Cowles, then programme director at the Consortium for Ocean Leadership, wrote to the NSF in January 2014. The NSF cited cost overruns and performance delays in changing the cyberinfrastructure contract later that year. In April 2015,  an underwater volcano laden with OOI instruments erupted , just as scientists had predicted \u2014 but the live data were not yet flowing to the wider scientific community. \n               Sea change \n             Now, about 85% of OOI data are available in real time on the project\u2019s website, with the percentage growing every week, says Greg Ulses, the current programme director at the Consortium for Ocean Leadership. The information \u2014 on factors such as temperature and salinity \u2014 streams from more than 900 sensors at the 7 sites. The OOI consists of one high-tech cable on the tectonically active sea floor of the northeast Pacific Ocean, together with two lines of oceano\u00adgraphic instruments \u2014 one off the US east coast and the other off the west coast \u2014 and four high-latitude sites, near Greenland, Alaska, Argentina and Chile. Each array involves a combination of instruments, from basic salinity sensors to sophisticated underwater gliders. The NSF built the network as a community resource, hoping to stimulate an era of virtual oceanography in which scientists explore real-time data sets open to all (see \u2018Virtual view\u2019). \u201cWe know the data are valuable,\u201d says Lisa Campbell, a biological oceanographer at Texas A&M University in College Station. \u201cHow to implement it is what we\u2019re working on.\u201d Those involved in the OOI\u2019s painful birth are happy to see it working at last. \u201cWhen I finally got through and saw the real-time data, I shouted so loud someone had to come down the hall and close the door,\u201d says Glen Gawarkiewicz, a physical oceanographer at the Woods Hole Oceanographic Institution in Massachusetts. The array off the coast of Massachusetts has already captured some unprecedented observations, he says. In 2014, it measured air\u2013sea fluxes when a hurricane passed overhead. The following winter, it measured dramatic shifts in the boundary at which shallow waters interact with deep ones. \u201cThat has tremendous practical implications, because there\u2019s a lot of commercial fishing in that area,\u201d Gawarkiewicz says. Using OOI data, he is now working with local fishers to share real-time information on changes in temperature and currents. The west-coast array has studied a warm blob of water linked to weather patterns that are strengthening the ongoing drought in California. And in the North Atlantic, off the coast of Greenland, OOI scientists have coordinated their measurements with those of others, such as an international programme to measure heat flow in this key region. \u201cThese are high-scientific-value sites that we have dreamed about, and now we have occupied them,\u201d says Robert Weller, a physical oceanographer at the Woods Hole Oceanographic Institution. \n               Rough waters \n             But the OOI\u2019s future remains murky. A 2015 review of US ocean-science priorities suggested that the programme\u2019s operational  budget should be slashed by 20% , to around $44\u00a0million a year. Yet each of the arrays must be serviced every year or two to replace broken instruments and install new ones. The NSF has not yet decided how it will save that 20% \u2014 whether it would cut back dramatically on servicing one particular site, spread the cuts across the entire system, or come up with some other plan. Later this year, the agency will be soliciting bids from organizations to manage the OOI for the next five to ten years. Who responds, and with what suggestions, will help to determine what gets cut. \u201cWe built this thing, and will be funding operations for what the community feels is best,\u201d says Murray. Ultimately, there is no metric for what constitutes a successful OOI. Ulses says that the project needs to run for a full year before managers can assess which scientists are using which data, and how stable and successful the data streams are. Weller would like to see a set of OOI measurements become as iconic as the records of atmospheric carbon dioxide levels taken at Mauna Loa, Hawaii, since the 1950s. \u201cOn any given day, I step back,\u201d he says, \u201cand am still sort of amazed that it\u2019s all out in the water and most of it\u2019s working.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Massive underwater volcano erupts 2015-May-01 \n                   \n                     US ocean sciences told to steer a new course 2015-Jan-23 \n                   \n                     Ocean observatory project hits rough water 2014-Nov-26 \n                   \n                     Marine science: Oceanography's billion-dollar baby 2013-Sep-25 \n                   \n                     Ocean Observatories Initiative \n                   Reprints and Permissions"},
{"file_id": "534160a", "url": "https://www.nature.com/articles/534160a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "With drug companies\u2019 policies hard to decipher, frustrated patients often resort to social-media campaigns and other public appeals. Nancy Goodman wanted to spend as much time as possible with her dying child. But even as ten-year-old Jacob\u2019s brain cancer worsened, Goodman spent months contacting pharmaceutical companies that were developing drugs that might help him. \u2018Compassionate-use\u2019 laws in the United States allow pharmaceutical companies to provide unapproved drugs to patients in desperate need, but many firms provide little or no information on how to request these treatments. They are often reluctant to supply drugs in response to such pleas, especially if drug stocks are limited, although media campaigns on behalf of individual patients can sometimes embarrass firms into providing unapproved treatments. Anecdotes suggest that money and connections are also influential. Now, ethicists and medical experts are testing what they hope is a fairer system to distribute drugs in short supply. The approach, presented on 6 June at the American Society of Clinical Oncology meeting in Chicago, Illinois, is inspired by the method used to prioritize organ transplants. In a test case, researchers worked with Janssen Pharmaceuticals to determine how to distribute limited supplies of daratumumab, an experimental drug intended to treat multiple myeloma. The 10-person panel combed through 76\u00a0anonymized applications to determine how likely the drug was to work for each person, ultimately approving 60. \u201cIt\u2019s hard to say no, because people die,\u201d says Arthur Caplan, a bioethicist at New York University\u2019s Langone Medical Center who is leading the effort. But he says that a systematic approach could help companies to make unbiased decisions. In Goodman\u2019s case, six of the eight companies that she contacted never responded. The other two declined to give her son their drugs because the treatments had never been tested in children. Jacob died in 2009, and his mother went on to found the advocacy group Kids v Cancer in Washington DC. There are many legitimate reasons that companies might refuse to provide unapproved drugs, says Aaron Kesselheim, who studies health-care ethics at Brigham & Women\u2019s Hospital in Boston, Massachusetts. People who request such treatments are often very ill, and companies worry that their deaths while receiving the drug would reduce the compound\u2019s chances of approval from the US Food and Drug Administration (FDA). Giving patients access to experimental drugs could also discourage them from enrolling in controlled trials that might assign a placebo, and would leave less drug available for use in the trial. \u201cThese requests are some of the most difficult decisions I face as a physician,\u201d says Amrit Ray, chief medical officer of Janssen in Titusville, New Jersey. \u201cIt\u2019s a trade-off we have to consider carefully.\u201d Since 2014, 28 US states have enacted \u2018right\u2011to-try\u2019 laws, which allow companies to provide drugs to patients without involving regulators. Caplan calls these \u201cfeel-good\u201d laws, because the FDA approves most of the compassionate-use requests that it receives. (It is not clear how many applications are denied by companies and never reach the FDA.) Vickie Buenger, president of the advocacy group Coalition Against Childhood Cancer in Philadelphia, Pennsylvania, says that right-to-try statutes contribute to patients\u2019 misunderstanding about the factors that go into a decision to supply or deny access to a drug. \u201cIt implies that companies and the FDA are either angels of mercy if they come through, or devils who have no compassion if they withhold it.\u201d This lack of clarity, and poor communication by companies, has led many patients and their families to launch social-media campaigns to secure unapproved drugs.  These requests are some of the most difficult decisions I face as a physician.  Perhaps the most famous case came in 2014, when the family of seven-year-old Josh Hardy began a Facebook campaign for an unapproved antiviral drug called brincidofovir to treat a life-threatening infection. Its manufacturer, Chimerix of Durham, North Carolina, had declined, on the grounds that giving the drug to Josh \u2014 and any subsequent petitioners \u2014 would leave less of the compound available for an ongoing clinical trial. Within days, the Facebook page and Twitter campaign #savejosh were featured on national television. Chimerix quickly created a small clinical trial with Josh as its first patient. \u201cEvery single CEO woke up the next morning and said, \u2018Oh my gosh, that might happen to me\u2019,\u201d says Elena Gerasimov, who directs a programme at Kids v Cancer that helps parents of children with cancer to petition companies for drug access. (The FDA is attempting to make this process easier. On 2 June, it released new forms to simplify the filing of compassionate-use appeals.) Former Chimerix chief executive Kenneth Moch says that dozens of companies have since enlisted him as an adviser on such issues. His advice is simple: every company should create a transparent system to handle compassionate-use requests, guided by the FDA. That is in line with the advice of the Biotechnology Innovation Organization, an industry group in Washington\u00a0DC that encourages its members to develop clear policies to explain whether they provide expanded access and to help physicians to request drugs. \u201cThat\u2019s the least we can do, to facilitate people being able to contact us,\u201d says Kay Holcombe, the group\u2019s senior vice-president for science policy. Caplan and Ray plan to test their system on another treatment later this year \u2014 possibly a mental-health drug or a childhood vaccine. Caplan hopes that more companies will adopt the approach, and imagines eventually creating a compassionate-use consulting panel to aid small companies. Moch cautions that the approach might not be appropriate for every drug or company, but he likes how it helps to level the playing field. \u201cHad Josh been a 37-year-old guy who kicked his dog and smoked, he wouldn\u2019t have gotten the same support as a lovely seven-year-old boy,\u201d he says. Patient advocates also support Caplan\u2019s system for distributing drugs. \u201cPutting it in the hands of people who understand the drug\u2019s possibilities is a reasonable thing,\u201d Buenger says. But many also want the FDA to create incentives for companies to provide drugs for compassionate use. Until that happens, or until companies adopt programmes such as Caplan\u2019s, social-media campaigns and other public appeals may be some patients\u2019 only option. \u201cI\u2019d do it,\u201d Goodman says. \u201cI\u2019d do anything to save my kid \u2014 anything to give Jacob a few more months.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @Sara_Reardon \n               \n                     Personalized medicine: Time for one-person trials 2015-Apr-29 \n                   \n                     Ebola drug trials set to begin amid crisis 2014-Sep-02 \n                   \n                     Should experimental drugs be used in the Ebola outbreak? 2014-Aug-12 \n                   \n                     Stem-cell ruling riles researchers 2013-Mar-26 \n                   \n                     Blog post: Human-rights court rules that evidence must support compassionate therapy \n                   \n                     Kids v Cancer \n                   \n                     Janssen Pharmaceuticals \n                   \n                     Coalition Against Childhood Cancer \n                   \n                     Chimerix \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20038", "url": "https://www.nature.com/articles/nature.2016.20038", "year": 2016, "authors": [{"name": "Laurence Denis"}], "parsed_as_year": "2006_or_before", "body": "Defensive electrocution added to annals of electric fish behaviour. This must be one of the more bizarre videos to accompany a scientific paper this year: an electric eel leaping out of a tank to shock a fake alligator head. The experiment, which demonstrates how eels react to half-submerged predators by leaping up out of water and administering defensive volleys of high-voltage electricity, is the brainchild of Kenneth Catania, a biologist at Vanderbilt University in Nashville, Tennessee. Catania first spotted the behaviour during earlier laboratory experiments with electric eels ( Electrophorus electricus ), when they would leap upwards to attack a metal-rimmed net as he was trying to fish them out of their tanks. He analysed it by presenting the eels with carbon rods and aluminium plates at which they struck; the video\u2019s plastic alligator, with its flashing light-emitting diodes that are powered by the eel\u2019s electrocution, is his dramatic demonstration of the effect. The results are published this week in the  Proceedings of the National Academy of Sciences 1 . The behaviour allows eels to directly shock their opponents, rather than having their voltage dissipated by water. It is the first time that this has been recorded in a research paper, Catania says \u2014 although he argues that his discovery supports a widely disbelieved observation made more than 200 years ago by the Prussian explorer and naturalist Alexander von Humboldt. In a paper published in 1807, von Humboldt recounted 2  that he had seen South American native fishermen herding horses into a pool of electric eels; the eels would discharge themselves against the horses and could be fished safely when they were exhausted. \n             Historic leap \n           Harold Zakon, who studies electric fish at the University of Texas at Austin, says that the work is an attractive blend of science history and experimental science. \u201cWhat makes Ken's paper so nice is that, like an eel, Ken made a leap: from a behaviour that he noticed to Humboldt's account. Then he did the experimental work to get the details,\u201d he says. Catania says that his latest work adds to findings that electric eels are more sophisticated than just being crude giant batteries that discharge shocks. For example, as he showed in research that made media headlines in  2014  and  2015 , eels on the attack can use their electricity first to force prey to twitch, then \u2014 like a taser \u2014 to freeze the muscles of their victims, and finally to monitor fast-moving prey 3 , 4 . Catania doesn\u2019t know what he\u2019ll study next, but adds that one of the biggest questions about eels is still unresolved: no one knows how an eel can electrocute its victim without shocking itself. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Animal behaviour: Electric eels use shocks to sense 2015-Oct-21 \n                 \n                   Animal behaviour: Electric eel zaps neurons of its prey 2014-Dec-10 \n                 \n                   Please sequence my eel 2008-Feb-08 \n                 \n                   The body electric 1999-Jul-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20032", "url": "https://www.nature.com/articles/nature.2016.20032", "year": 2016, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Combining the best of analog and digital approaches could yield a full-scale multipurpose quantum computer. For 30 years, researchers have pursued the universal quantum computer, a device that  could solve any computational problem , with varying degrees of success. Now, a team in California and Spain has made an experimental prototype of such a device that can solve a wide range of problems in fields such as chemistry and physics, and has the potential to be scaled up to larger systems. Both IBM and a Canadian company called D-Wave have created functioning quantum computers using different approaches. But their devices are not easily scalable to the  many quantum bits  (qubits) needed for solving problems that classical computers cannot. Computer scientists at Google\u2019s research laboratories in Santa Barbara, California, and physicists at the University of California at Santa Barbara and the University of the Basque Country in Bilbao, Spain, describe their new device online in  Nature 1 . \u201cIt\u2019s terrific work in many respects, and is filled with valuable lessons for the quantum computing community,\u201d says Daniel Lidar, a quantum-computing expert at the University of Southern California in Los Angeles. The Google prototype combines the two main approaches to quantum computing. One approach constructs the computer\u2019s digital circuits using qubits in particular arrangements geared to solve a specific problem. This is analogous to a tailor-made digital circuit in a conventional microprocessor made from classical bits. Much of quantum computing theory is based on this approach, which includes methods for correcting errors that might otherwise derail a calculation. So far, practical implementations have been possible only with a handful of qubits. \n             Analog approach \n           The other approach is called adiabatic quantum computing (AQC). Here, the computer encodes a given problem in the states of a group of qubits, gradually evolving and adjusting the interactions between them to \u201cshape\u201d their collective quantum state and reach a solution. In principle, just about any problem can be encoded into the same group of qubits. This analog approach is limited by the effects of random noise, which introduces errors that cannot be corrected as systematically as in digital circuits. And there\u2019s no guarantee that this method can solve every problem efficiently, says computer scientist Rami Barends, a member of the Google team. Yet only AQC has furnished  the first commercial devices  \u2014 made by D-Wave in Burnaby, British Columbia \u2014 which sell for about US$15 million apiece. Google owns a D-Wave device, but Barends and colleagues think that there\u2019s a better way to do AQC. In particular, they want to find some way to implement error correction. Without it, scaling up AQC will be difficult, because errors accumulate more quickly in larger systems. The team thinks the first step to achieving that is to combine the AQC method with the digital approach\u2019s error-correction capabilities. \n             Virtual chemistry \n           To do that, the Google team uses a row of nine solid-state qubits, fashioned from cross-shaped films of aluminium about 400 micrometres from tip to tip. These are deposited onto a sapphire surface. The researchers cool the aluminium to 0.02 degrees kelvin, turning the metal into a superconductor with no electrical resistance. Information can then be encoded into the qubits in their superconducting state. The interactions between neighbouring qubits are controlled by \u2018logic gates\u2019 that steer the qubits digitally into a state that encodes the solution to a problem. As a demonstration, the researchers instructed their array to simulate a row of magnetic atoms with coupled spin states \u2014 a problem thoroughly explored in condensed-matter physics. They could then look at the qubits to determine the lowest-energy collective state of the spins that the atoms represented. This is a fairly simple problem for a classical computer to solve. But the new Google device can also handle so-called \u2018non-stoquastic\u2019 problems, which classical computers cannot. These include simulations of the interactions between many electrons, which are needed for accurate computer simulations in chemistry. The ability to simulate molecules and materials at the quantum level could be one of the most valuable applications of quantum computing. This new approach should enable a computer with quantum error correction, says Lidar. Although the researchers did not demonstrate that here, the team has previously shown how that might be achieved on its nine-qubit device 2 . \u201cWith error correction, our approach becomes a general-purpose algorithm that is, in principle, scalable to an arbitrarily large quantum computer,\u201d says Alireza Shabani, another member of the Google team. The Google device is still very much a prototype. But Lidar says that in a couple of years, devices with more than 40 qubits could become a reality. \u201cAt that point,\u201d he says, \u201cit will become possible to simulate quantum dynamics that is inaccessible on classical hardware, which will mark the advent of \u2018quantum supremacy\u2019.\u201d Reprints and Permissions"},
{"file_id": "nature.2016.20053", "url": "https://www.nature.com/articles/nature.2016.20053", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "US science academies advise caution in experimenting with gene drives. A technique that allows particular genes to spread rapidly through populations is not ready to be set loose in the wild, warns a committee convened by the US National Academies of Sciences, Engineering, and Medicine. In a report released on 8 June, the committee argued that such \u2018gene drives\u2019 pose complex ecological risks that are not yet fully understood. \u201cIt is not ready \u2014 and we are not ready \u2014 for any kind of release,\u201d says Elizabeth Heitman, co-chair of the committee and a research integrity educator at Vanderbilt University School of Medicine in Nashville, Tennessee. \u201cThere is a lot of work that needs to be done.\u201d Even so, Heitman and other members of the committee felt that the potential of gene drives, for example to combat insect-borne diseases, is compelling enough to warrant additional laboratory and field studies. Gene drives have been studied for more than half a century, and have long been postulated as a way to eradicate mosquito-borne diseases such as malaria. But the field was hampered by technical challenges until the recent advent of sophisticated \u2014 and easy-to-use \u2014 tools for engineering genomes. In the past two years, researchers have used a  popular gene-editing technique called CRISPR\u2013Cas9  to develop gene drives that spread a given gene through a population almost exponentially faster than normal in  yeast , fruit flies and  two   species  of mosquitoes. But as molecular biology research on gene drives has surged forward, it has outpaced our understanding of their ecological consequences, says Heitman. Even a small, accidental release from a laboratory  holds the potential to spread around the globe : \u201cAfter release into the environment, a gene drive knows no political boundaries,\u201d the committee wrote. As a result, oversight of gene drive projects should be coordinated across countries, the committee argued, and best practices should be openly shared among laboratories. The committee also detailed multiple phases of testing that should be used to assess the effects of a gene drive, and stressed the need to involve researchers' home institutions, regulators and even the public in decision-making. It is a good overall strategy, says Todd Kuiken, who studies science policy at the Wilson International Center for Scholars, a think tank in Washington DC. But the committee missed an opportunity to set out the infrastructure and safety measures that would be needed to conduct field trials of gene drives, he adds. \u201cThey don\u2019t talk about how you would actually do this and where the money is going to come from.\u201d A gene drive could have unintended effects on the environment if it is unleashed in wild populations: removing one species of insect, for example, could endanger the animals that feed on it. Given this risk, the report also stressed the importance of layering multiple  methods of containment  to prevent accidental release of engineered species, and of consulting with the public even before gene drive experiments are undertaken in the laboratory. It\u2019s a message that evolutionary engineer Kevin Esvelt worries may not come through strongly enough to individual researchers. \u201cIf you were to accept that there is a risk that building it in the laboratory could lead to its release, then that demands that you tell the world what you\u2019re doing before you do the experiments,\u201d says Esvelt, who works at the Massachusetts Institute of Technology in Cambridge. Heitman notes that researchers lack tried and tested ways of soliciting input from the public at large about their work. For Esvelt, the bigger barrier is a scientific culture that often discourages researchers from sharing their experiments before they are published, for fear of being beaten to the finishing line by another group. \u201cNo one would rationally design the current scientific enterprise,\u201d he says. \u201cAnd right now it\u2019s easier to engineer biology than culture.\u201d \n                   Why transgenic insects are still not ready for prime time 2016-Apr-22 \n                 \n                   Mosquitoes engineered to pass down genes that would wipe out their species 2015-Dec-07 \n                 \n                   'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                 \n                   Defensive drives 2015-Nov-17 \n                 \n                   Safety upgrade found for gene-editing technique 2015-Nov-16 \n                 \n                   Caution urged over editing DNA in wildlife (intentionally or not) 2015-Aug-04 \n                 \n                   CRISPR: The good, the bad, and the unknown \n                 \n                   Report by the US National Academies of Sciences, Engineering and Medicine \n                 Reprints and Permissions"},
{"file_id": "534164a", "url": "https://www.nature.com/articles/534164a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Jaw and teeth discovered in Indonesia are triumph for team that almost gave up hope. More than a decade after the discovery that a diminutive relative of modern humans once  lived on the Indonesian island of Flores , Gerrit van den Bergh was losing faith that he would find any clues to the ancestors of the \u2018hobbit\u2019. It was October 2014, and for four years he had co-led an industrial-scale excavation near the cave where the metre-tall skeleton had been found. Then, weeks before packing it in for the year, a local worker found a 700,000-year-old molar. More teeth and a partial jaw quickly followed. \u201cWe had given up hope we would find anything, then it was \u2018bingo!\u2019,\u201d says van den Bergh, a palaeontologist at the University of Wollongong, Australia, whose team reports the finds in two papers in this issue ( G.\u2009D. van den Bergh et\u00a0al. Nature 534, 245\u2013248; 2016 ; and  A.\u2009Brumm et\u00a0al. Nature 534, 249\u2013253; 2016 ). \u201cWe had this enormous party. We had a cow slaughter and there was dancing. It was marvellous.\u201d The unusually petite jaw and teeth are from at least one adult and two children \u2014 the first possible ancestors of  Homo floresiensis  ever to be discovered \u2014 and resemble the  hobbit remains found on the island , which are between 60,000 and 100,000 years old. The jaw and teeth address two questions that have dogged the study of the species \u2014 where did it come from and how did it get so small? But as with all things hobbit, there is little consensus among researchers, who say that firm conclusions require more fossils. Gerrit van den Bergh explains how new fossils shed light on the mysterious hobbit. The hobbit\u2019s discovery in 2003 in Liang Bua cave, by a team led by the late Australia-based rock-art specialist Mike Morwood, was an instant sensation. But its place in the human family tree is contentious. Morwood\u2019s team proposed that it was a shrunken  Homo erectus , the same species that probably evolved into  Homo sapiens  in Africa and that roamed as far as Europe and Asia. Other scientists who have examined features of  H. floresiensis,  such as its  long, flat feet , think that it descended from a smaller, more primitive human relative such as  Homo habilis  or even  Australopithecus , known only from remains in sub-Saharan Africa. Seeking the hobbit\u2019s ancestors , in 2004, Morwood\u2019s team returned to a site 74\u00a0kilometres from Liang Bua called Mata Menge, where elephant bones and tools had been found in the 1960s. The dig started small, but in 2010 the team scaled up. Bulldozers cleared an area of 2,000\u00a0metres square, and more than 100\u00a0locals then dug for 6\u00a0days a week using chisels and hammers. They found hundreds of stone tools, thousands of fossils from animals such as crocodiles, rats and komodo dragons, but no hominin bones. By then ill with advanced prostate cancer, Morwood visited the area for the last time in 2012. \u201cHe really made an effort to walk through the site, you could see he was in pain, but he was so detailed-minded,\u201d van den Bergh says. \u201cHe increased the pressure to dig more holes and go faster. He really wanted to find them.\u201d Morwood, who  died in 2013  before the teeth and jawbone were found, is an author on the  Nature  papers, which were co-led by scientists based in Japan, Australia and Indonesia. The team concludes that the jaw excavated at Mata Menge is from an adult (its wisdom tooth had erupted) who was even smaller than the hobbit, and that two canines are the milk teeth of two different children. The thin jaw looks more like that of  H.\u00a0erectus  and  H.\u00a0floresiensis  than the beefier jaws of more primitive hominins such as  H. habilis.  The square-shaped teeth are intermediate between  H.\u00a0erectus  and  H.\u00a0floresiensis . One tooth and the rock around it led the team to estimate that the remains are some 700,000\u00a0years old. The oldest artefacts in the region, meanwhile, suggest that a group of  Homo erectus  arrived on Flores about one million years ago, says van den Bergh. \n               Dwarfed by diet \n             He and his team note that the remains point to large-bodied  H. erectus  as the likeliest ancestor of the hobbit, and propose that it became dwarfed in just a few hundred thousand years to cope with the meagre resources on Flores. Elephants and other large creatures have been known to  shrink over time  to cope with the lack of food typical of islands, and red deer on the island of Jersey in the English Channel became one-sixth of their original size in just 6,000\u00a0years, says van den Bergh. Both Fred Spoor, a palaeontologist at University College London, and palaeoanthropologist Chris Stringer at London\u2019s Natural History Museum agree that  H.\u00a0erectus  is now the best fit for the hobbit\u2019s ancestor, although Stringer isn\u2019t so sure that the shrinkage happened on Flores. It\u2019s just as likely that the hobbit emerged on another island, such as Sulawesi, and then moved to Flores, he says. But William Jungers, a palaeoanthropologist at Stony Brook University in New York, says that the fossils are not complete enough to favour the  H.\u00a0erectus  origin: \u201cI don\u2019t believe these scrappy new dental specimens inform the competing hypotheses for the origin of the species one way or another.\u201d A small river that leads down a hill deposited the sandstone in which the teeth and jaw were found, and van den Bergh expects that more hominin remains lie there. His colleagues, meanwhile, have found stone tools in Sulawesi, north of Flores. For once, the prospect of more hobbits isn\u2019t looking so bleak.\n See  Editorial p.151  and  News & Views p.188 \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     Did humans drive 'hobbit' species to extinction? 2016-Mar-30 \n                   \n                     The discovery of Homo floresiensis: Tales of the hobbit 2014-Oct-22 \n                   \n                     Human evolution: Small remains still pose big problems 2014-Oct-22 \n                   \n                     'Hobbit' was a dwarf with large feet 2009-May-06 \n                   \n                     Will the hobbit argument ever be resolved? 2006-Aug-25 \n                   \n                     Palaeoanthropology: Looking for the ancestors 2005-Mar-23 \n                   \n                     Critics silenced by scans of hobbit skull 2005-Mar-03 \n                   \n                     Fossil finders in tug of war over analysis of hobbit bones 2005-Mar-02 \n                   \n                     Little lady of Flores forces rethink of human evolution 2004-Oct-27 \n                   \n                     Nature  special: The hobbit at 10 \n                   \n                     Nature  special: Flores man \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20072", "url": "https://www.nature.com/articles/nature.2016.20072", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "The spiny mouse could one day aid studies of women's reproductive problems. Mice are a mainstay of biomedical research laboratories. But the rodents are poor models for studying  women\u2019s reproductive health , because they don\u2019t menstruate. Now researchers at Monash University in Clayton, Australia, say that they have found a rodent that defies this conventional wisdom: the spiny mouse ( Acomys cahirinus ). If the finding holds up, the animal could one day be used to research women's  menstruation -related health conditions. \u201cWhen you do science you\u2019re not surprised at anything \u2014 but wow, this was a really interesting finding,\u201d says Francesco DeMayo, a reproductive biologist at the US National Institute of Environmental Health Sciences in Research Triangle Park, North Carolina, who was not involved in the work. The study, which was posted to bioRxiv preprint server on 3 June 1 , involved 14 female spiny mice. The researchers found that the animals averaged a 9-day menstrual cycle and spent 3 days \u2014 or 20\u201340% of their cycle \u2014 bleeding. This ratio is similar to that in women, who typically bleed for 15\u201335% of their 28-day cycle. To track the mice's periods, the team flushed the animals\u2019 vaginas with saline solution daily for 18 days. To ensure that the procedure itself did not cause the bleeding, the team treated five common lab mice in the same way. The scientists also dissected uteri taken from four spiny mice, each at a different stage of the menstrual cycle. The team is continuing research into exactly how and when the mouse uterine lining breaks down and regrows. Jared Mamrot, a reproductive physiologist at Monash and a co-author of the study, has just sequenced the spiny mouse transcriptome \u2014 all of the RNA expressed by the animal's genes at a given time. This could provide information on how genes regulate different stages of the spiny mouse's menstrual cycle. \n             Similar or different? \n           Warren Nothnick, a researcher at the University of Kansas in Kansas City who studies the uterine-lining disorder endometriosis, says that it will take a lot of work to prove that the spiny mouse is  a good model  for human menstruation. But he is intrigued. \u201cThere\u2019s some really simple studies that they could do to see if these animals would develop endometriosis spontaneously,\u201d he says. A finding that the animals do develop the disease naturally would be a major breakthrough, Nothnick adds. The current animal model for endometriosis is the baboon, and primate research is expensive and time-consuming. Laboratory mice can be induced to menstruate, but only if their ovaries are removed and they are given abnormally large doses of hormones. Only 1.5% of mammals menstruate naturally, and most of them are primates. The spiny mouse could also help to shed light on healthy menstrual function, DeMayo says. Scientists don\u2019t know the source of the cells that repopulate the uterine lining after each menstrual cycle, he notes. But DeMayo cautions that there is more to learn about how similar menstruation is in spiny mice and women, including the patterns of gene expression involved and how the hormones oestrogen and progesterone regulate the process in the mouse. Study co-author Hayley Dickinson., a reproductive physiologist at Monash University, says that the mouse discovery was hiding in plain sight. Monash established a breeding colony of spiny mice in 2003, and later transferred the animals to the nearby Hudson Institute for Medical Research. When Dickinson's lab announced the menstruation discovery, several past students asked her how they could have missed it. \u201cThe answer, as with many discoveries in science, is that no one really looked,\u201d Dickinson says. \u201cEveryone knew that rodents didn't menstruate.\u201d \n                   Dirty room-mates make lab mice more useful 2016-Apr-20 \n                 \n                   Fighting the menstruation taboo in the field 2016-Feb-12 \n                 \n                   Preclinical research: Make mouse studies work 2014-Mar-26 \n                 \n                   Mammals put embryo development on hold 2012-Mar-15 \n                 \n                   Saying goodbye to periods 2006-Dec-13 \n                 \n                   Hayley Dickinson \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20069", "url": "https://www.nature.com/articles/nature.2016.20069", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Welcome nihonium, moscovium, tennessine and oganesson. The periodic table will soon have four new names added to its lower right-hand corner. Element 113 is set to be named nihonium (Nh); element 115, moscovium (Mc); element 117, tennessine (Ts); and element 118, oganesson (Og), according to proposals  outlined on 8 June  by chemistry\u2019s governing body, the International Union of Pure and Applied Chemistry (IUPAC). The laboratories that were  credited with the discovery of the elements  \u2014 in Russia, the United States and Japan \u2014 got to propose the names, under the constraint that elements can be named only after one of their chemical or physical properties, a mythological concept, a mineral, a place or country, or a scientist. \u201cAlthough these choices may perhaps be viewed by some as slightly self-indulgent, the names are completely in accordance with IUPAC rules,\u201d said Jan Reedijk, president of IUPAC\u2019s inorganic-chemistry division, in a media statement. Perhaps the most striking choice, although  it was widely predicted , is for element 118, oganesson. It is named after Yuri Oganessian, an 83-year-old researcher at Russia\u2019s Joint Institute for Nuclear Research (JINR) in Dubna, who has helped to discover numerous superheavy elements. It will mark only the second time that an element has been named after a living scientist. The first such occasion led to huge controversy, when in 1993, a team at the Lawrence Berkeley National Laboratory in Berkeley, California, proposed naming element 106 seaborgium, after US nuclear-chemistry pioneer Glenn Seaborg. At first, a IUPAC committee rejected the proposal after passing a resolution that elements should not be named after living scientists, but it ultimately relented.  Moscovium (115) \u2014 named after the Moscow region \u2014 honours \u201cthe ancient Russian land that is the home of the Joint Institute for Nuclear Research\u201d, says IUPAC. And tennessine (117) \u201cis in recognition of the contribution of the Tennessee region, including Oak Ridge National Laboratory, Vanderbilt University, and the University of Tennessee at Knoxville, to superheavy element research\u201d. A collaboration between the JINR, Lawrence Livermore National Laboratory in Livermore, California, and the Oak Ridge laboratory was credited with the discovery of these two elements. Element 113, nihonium, is the first artificial element to be named in East Asia. When its creation was first claimed 12 years ago by a team at the RIKEN Nishina Center for Accelerator-based Science in Wako, near Tokyo, \u2018japonium\u2019 was suggested as a name. But the RIKEN group (which  followed up with a more convincing report in 2012 ) chose nihonium instead:  Nihon  (\u65e5\u672c) is one way to say \u2018Japan\u2019 in Japanese. \u201cThe name is proposed to make a direct connection to the nation where the element was discovered,\u201d says IUPAC.\u00a0 Before this, the most recent additions to the periodic table were  flerovium (Fl, 114) and livermorium (Lv, 116) . All such artificial elements, including the latest four, are created in trace amounts in the laboratory by smashing lighter atomic nuclei together \u2014 and last mere fractions of a second before they fall apart into smaller, more stable fragments.  IUPAC is allowing five months for public comment on the suggestions, but unless there is an upswell of public protest, the names will be confirmed in November. \n                   Four chemical elements added to periodic table 2016-Jan-04 \n                 \n                   Element 113 at last? 2012-Sep-27 \n                 \n                   Blogpost: Flerovium and livermorium suggested as new element names \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20070", "url": "https://www.nature.com/articles/nature.2016.20070", "year": 2016, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Tracking space rocks that reach Earth will give insight into the early Solar System. Scientists in France have launched an unprecedented campaign to catch shooting stars, an effort that will rely on thousands of volunteers to comb the ground for bits of space rock. The programme already includes 68 cameras that scan the skies for meteors, which are seen when bits of asteroid, comet or other planetary material  streak through Earth\u2019s atmosphere . By the end of this year, some 100 cameras will blanket France, organizers say. That would make it one of the biggest and densest meteor-spotting networks in the world. \u201cIf tomorrow a meteorite falls in France, we will be able to know where it comes from and roughly where it has landed,\u201d says J\u00e9r\u00e9mie Vaubaillon, an astronomer at the Paris Observatory and one of organizers of the system. Dubbed the Fireball Recovery and InterPlanetary Observation Network, or FRIPON, it was officially inaugurated on 28 May. Meteorites \u2014 chunks of stone that have fallen from space and reached Earth\u2019s surface \u2014 provide valuable insights into everything from the history of the Solar System to the identity of  asteroids that could potentially collide with Earth . Snagging such objects is \u201cthe one chance you get to see Solar System material in your hands\u201d, says David Clark, who studies meteors at the University of Western Ontario in London, Canada. \u201cWe simply don\u2019t have enough of this stuff.\u201d Especially prized are meteorites that were tracked on their inward journey. Scientists can use data on the journey to reconstruct the object\u2019s trajectory and reveal where in the Solar System it came from. People manage to scoop up only one to three meteorites each year with known trajectories, says Peter Jenniskens, an astronomer at the SETI Institute in Mountain View, California. \n               Fire in the sky \n             FRIPON\u2019s organizers dream of collecting one tracked meteorite per year from the French landscape. By comparison, researchers with the Spanish Meteor Network \u2014 another large and dense network \u2014 have scored 2 meteorites in the past 12 years. The French network\u2019s cameras are very densely and evenly spaced, sitting roughly 70\u201380 kilometres apart at laboratories, science museums and other buildings. That is close enough together to yield good information about where meteorites land. \u201cThat increases your chance of finding something,\u201d says Jenniskens. FRIPON is also the first fully connected and automated network, says principal investigator Fran\u00e7ois Colas, of the Paris Observatory. When a camera detects a meteor, it sends a message to a central computer in Paris. If two or more cameras spot the fireball, FRIPON scientists receive an e-mail describing where it was seen. Eventually, the e-mail will include automatically generated information about the object\u2019s probable landing zone, pinpointing it to an area roughly 1 kilometres by 10 kilometres. The researchers will then face the arduous job of searching this area to find the object. At first, scientists will conduct the ground searches. But in the next few years, FRIPON organizers plan to train an army of citizen scientists to walk the French landscape looking for bits of meteorite \u2014 and to hand over any finds. Perhaps one in 1,000 volunteers will actually turn up for a search, estimates Brigitte Zanda, a meteorite specialist at the National Museum of Natural History in Paris, who heads the volunteer effort. Organizers hope to field a search team of 30 people in every part of France, so they will have to recruit hundreds of thousands of people, she says. \u201cIt\u2019s ambitious.\u201d But hundreds of people have already signed up, even though the official recruitment drive is just getting underway. Northern France's extensive forests could also make meteorite recovery challenging, says Josep Trigo-Rodr\u00edguez, an astrophysicist at the Institute of Space Sciences in Barcelona, Spain, and a co-founder of the Spanish Meteor Network. Still, he thinks that FRIPON could help investigators to find more meteorites. An average of just one meteorite was recovered per decade in France in the twentieth century, down from one every other year in the previous 100\u00a0years. \u201cThat means it can be done,\u201d Zanda says. \u201cPerhaps we can do better.\u201d \n                     Incoming space junk a scientific opportunity 2015-Oct-23 \n                   \n                     Newfound meteor showers expand astronomical calendar 2015-Sep-16 \n                   \n                     Risk of massive asteroid strike underestimated 2013-Nov-06 \n                   \n                     Russian meteor may have gangmates in tow 2013-Aug-02 \n                   \n                     Rock samples suggest meteor caused Tunguska blast 2013-Jun-10 \n                   \n                     The death of the Chebarkul meteor 2013-Mar-05 \n                   \n                     Russian meteor largest in a century 2013-Feb-15 \n                   \n                     US meteorite was fastest on record 2012-Dec-20 \n                   \n                     FRIPON \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20071", "url": "https://www.nature.com/articles/nature.2016.20071", "year": 2016, "authors": [{"name": "Claudio Angelo"}], "parsed_as_year": "2006_or_before", "body": "But politicians say that restoring a stand-alone science ministry is unlikely. Brazil\u2019s scientists have been taking to the streets to protest against  last month\u2019s demotion  of their country\u2019s science ministry (MCTI) \u2013 but politicians say the demonstrations won\u2019t change the controversial decision. The protests followed an efficiency drive by interim president Michel Temer, who took office in May after Dilma Rouseff was impeached. He angered researchers by merging the MCTI with a telecommunications ministry. The move was part of a bid to cut public expenses, Temer said: overall, he cut the number of ministries in his cabinet from 32 to 22. Researchers, already  struggling with massive funding cuts , saw the move as weakening the status of science, which has had its own cabinet ministry for most of the past three decades.\u00a0\u201cThe government is signaling that science is unimportant and shall remain so\u201d, says Sergio Rezende, a physicist at the Federal University of Pernambuco in Recife, who was science minister from 2005 to 2010. Within days of Temer\u2019s action, the culture ministry \u2014 which he also demoted \u2014 was reinstated after protests by artists. Inspired by that action, some researchers launched the Internet campaigns  #VoltaMCTI  (\u201ccome back, MCTI\u201d) and  #FicaMCTI  (\u201cstay, MCTI\u201d) and scheduled demonstrations. In Natal, 200 people, some in white lab coats, some wearing paper masks of Temer and Albert Einstein, demonstrated on 2 June. In a protest in Rio de Janeiro two days later, a banner carried a picture of the interim president with the words, \u201cWithout science there\u2019s no Viagra\u201d. (Temer, 75, is married to a beauty queen 32 years his junior.) This week, protests continued in university campuses and outside national labs and public buildings in Rio, Porto Alegre, Bras\u00edlia, Belo Horizonte, Petr\u00f3polis and Bel\u00e9m. \n             No going back \n           \u201cWe\u2019re not as quick to mobilize ourselves as artists, but we\u2019ve been against the merger right from the start\u201d, says physicist Ildeu Moreira, vice-president of the Brazilian Society for the Advancement of Science (SPBC) in S\u00e3o Paulo, and one of the organizers of the #FicaMCTI campaign. As part of the protest, several prominent scientists have changed the picture in their profiles in the national online academic registry, substituting the campaign\u2019s hashtag. Among them is mathematician Artur Avila, winner of the 2014 Fields Medal, who said in a video recorded for the campaign that merging two unrelated ministries \u201cgoes against the notion that science and technology are key for Brazil\u201d. Gilberto Kassab, the new minister of the science\u2013communications superministry, says there\u2019s no going back. \u201cI believe the ministry has become stronger, with more political weight given by the fusion\u201d, he told  Nature . On 8 June, for example, he told the SBPC that his ministry would now be able to spend 1 billion reais (US$350 million) that Rouseff\u2019s administration had withheld from MCTI\u2019s 4.2-billion-reais budget for 2016 to help to relieve the country\u2019s fiscal deficit. Kassab also said that he would negotiate a US$1.4-billion loan with the Inter-American Development Bank to revive science spending \u2014 a measure previously proposed and approved during the Rouseff administration, but which needed to be renegotiated by the new government after Rouseff\u2019s impeachment. Scientists are pleased with these announcements, but say it will take more than that to charm them. \u201cMy opinion is that the protests will continue\u201d, says physicist Tatiana Rappoport at the Federal University of Rio de Janeiro. If anything, she says, the demonstrations are getting stronger. \n                   Demotion of science ministry angers beleaguered Brazilian researchers 2016-May-12 \n                 \n                   Brazilian science paralysed by economic slump 2015-Sep-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20076", "url": "https://www.nature.com/articles/nature.2016.20076", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Researchers tease out different definitions of a crucial scientific term. A semantic confusion is clouding one of the most talked-about issues in research. Scientists agree that there is a crisis in reproducibility, but they can\u2019t agree on what \u2018reproducibility\u2019 means. The muddle is hampering communication about the problem and efforts to address it, a  meeting last week on improving the reproducibility of preclinical research  was told. Most scientists \u2014 at least, those in biomedical research \u2014 have the idea that reproducible findings are those that give generally consistent results across slight variations in experimental set-up, says Ferric Fang,\u00a0a microbiologist at the University of Washington in Seattle. \u201cReproduction is taking the idea of a scientific project and showing that it is robust enough to survive various sorts of analysis,\u201d he says. That is, that it supports an expectation, for example that \u2018reproducible\u2019 preclinical results are those worth taking forward to clinical trials. But Fang adds that other definitions of the term are in common use. A second one is much narrower: a finding is reproducible if another researcher gets the same results when doing exactly the same experiment. On this interpretation, a fragile experiment that works under certain conditions in the laboratory, but not in other contexts, is still \u2018reproducible\u2019. And a third definition holds that a reproducible experiment is merely one that has been published with a sufficiently complete description \u2014 such as detailed methods \u2014 for another scientist to repeat it. All these definitions point to the various problems that plague research. Scientists don\u2019t want experiments that are poorly documented or unreliable, or that don\u2019t give similar findings when the methods are slightly tweaked. But all of these issues have at times been framed as issues of reproducibility. \u201cReproducibility is shorthand for a lot of problems,\u201d Jon Lorsch, head of the National Institute of General Medical Sciences, told attendees at the meeting, which was held in Bethesda, Maryland. Without a shared understanding of the term, it can be unclear how scientists should respond when told that someone is \u201cunable to reproduce\u201d results in their paper, adds Ulrich Dirnagl, a stroke researcher at the Charit\u00e9 Medical University in Berlin. Challenges to research should be more clearly explained, he says. \n             Expanded terms \n           Instead of advocating for a common definition, several scientific leaders are calling for an expanded set of terms. Earlier this month, researchers at the Meta-Research Innovation Center at Stanford in California proposed three 1 : methods reproducibility, results reproducibility and inferential reproducibility, mapping roughly onto the three concepts described by Fang. But the term can be split according to other kinds of distinctions. Victoria Stodden, a data scientist at the University of Illinois at Urbana-Champaign, makes the distinction between \u2018empirical\u2019 reproducibility (supplying all the details necessary for someone to physically repeat and verify an experiment) and \u2018computational\u2019 and \u2018statistical\u2019 reproducibility, which refer to the resources needed to redo computational and analytical findings. Achieving each type of reproducibility calls for different remedies, she says. Last year, a  white paper  by the American Society for Cell Biology in Bethesda dismissed reproducibility as a catch-all term,\u00a0and introduced a four-tier definition instead. According to this paper, \u201canalytic replication\u201d refers to attempts to reproduce results by reanalysing original data; \u201cdirect replication\u201d refers to efforts to use the same conditions, materials and methods as an original experiment; \u201csystematic replication\u201d describes efforts to produce the same findings using different experimental conditions (such as trying an experiment in a different cell line or mouse strain), and \u201cconceptual replication\u201d, which refers to attempts to demonstrate the general validity of a concept, perhaps even using different organisms. Agreeing on ways to assess reproducibility can be fraught with complications \u2014 even within a research field. Last year, the Reproducibility Project: Psychology,  which conducted 100 replication studies to assess psychology publications , used five indicators of whether a study had been successfully replicated 2 . Earlier this year, a paper that aimed to distil best practices for neuroimaging  outlined  10 levels of reproducibility in such experiments across three categories, called \u2018measurement stability\u2019, \u2018analytical stability\u2019 and \u2018generalizability\u2019. They differed according to whether, for example, an attempted repeat experiment used the same scanners, analysis methods, subject population, stimulus type and so on across 11 variables. Ultimately, each discipline may need to come to its own definition, says Lee Ellis, a surgical oncologist at the University of Texas MD Anderson Cancer Center in Houston. \u201cI don\u2019t think we can define reproducibility across the board,\u201d he says. Arguments over such distinctions are not just fruitless wordplay, says Dirnagl. An appreciation of the nuances of reproducibility could help researchers to communicate when they can\u2019t reach common ground on apparently differing findings. Some of science\u2019s most enlightening results arise when an effect is partially reproducible \u2014 seen under some conditions but not others. \u201cScience advances through differential reproduction,\u201d he says. \n                   1,500 scientists lift the lid on reproducibility 2016-May-25 \n                 \n                   A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                 \n                   Announcement: Reducing our irreproducibility 2013-Apr-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20077", "url": "https://www.nature.com/articles/nature.2016.20077", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Defence ministry says army needs more recruits because of country's low-birth rate. A proposal from the South Korean defence ministry to scrap exemptions from military service for science and engineering students is being met with fierce resistance by researchers and students alike. They say that it will disrupt PhD studies and could trigger an academic 'brain drain' if researchers choose not to do graduate studies in South Korea as a result. Leading members of South Korea\u2019s major political parties as well as the science ministry have voiced their opposition to the idea, which was announced on 17 May. \u201cIt will immediately lead to a weakening of competitiveness in science and technology,\u201d Hyunwook Park, provost of the technical university KAIST in Daejeon, told the  Chosun Ilbo  newspaper. At a 3 June press conference and rally held outside the defence ministry\u2019s Seoul headquarters, students presented a petition containing more than 14,000 signatures against the plan.  The defence ministry says that it is still negotiating details with other ministries. \u201cIt\u2019s an open plan,\u201d spokesperson Hwang Yun-jeong told  Nature . South Korea technically remains in a state of war with North Korea, and all able-bodied men aged 18 to 35 are required to serve two years in the military. But each year, the military gives roughly 2,500 exemptions to science and engineering graduate students with master's degrees, known as technical research personnel (TRP). About 1,000 of them can fulfil the service with three years of study in a PhD programme, while others do research at government institutes or in industry. \n             Soldier shortage \n           In its 17 May announcement, South Korea\u2019s defence ministry projected a shortfall of up to 30,000 troops by 2023. \u201cIt\u2019s inevitable because of the low birth rate,\u201d a ministry official told Korean media. To close the gap, it plans to eliminate all exemptions by 2023. A total of 28,000 are issued annually; the rest include exemptions for the police, firefighters and public-health workers. Under the plan, the military would stop issuing sought-after doctoral exemptions after 2018. Current undergraduates would have no prospect of getting an exemption. \u201cAll of our Korean science and technology universities are very shocked about it,\u201d says Kim Sang Soo, a fourth-year biology student who is president of the undergraduate student council at Pohang University of Science and Technology (POSTECH). \u201cI really want to go to POSTECH for graduate school, so it\u2019s a huge shock to me, too.\u201d Many undergraduates, reasoning that the exemptions now look unlikely, are already considering getting their military service out of the way and joining this summer, says Hong Jinwoo, a third-year student in chemical and biological engineering at Seoul National University. A student protest movement has been coordinated through a Facebook page called  TRP Helper . Kim argues that the military\u2019s plan is self-defeating, because it would deplete the talent pool for the considerable amount of defence research that the military funds at universities. A student-led analysis at POSTECH showed that more than one-fifth of its PhD candidates are currently classed as TRP, and eliminating their positions would wipe out 23% of the university\u2019s defence-related projects. Some students think that they now have the momentum. \u201cI\u2019m optimistic that the military plan will fail,\u201d says Yong Seok Hong, a first-year graduate student at Seoul National University. \n                   Why South Korea is the world\u2019s biggest investor in research 2016-Jun-01 \n                 \n                   South Korea trumpets $860-million AI fund after AlphaGo 'shock' 2016-Mar-18 \n                 Reprints and Permissions"},
{"file_id": "534303a", "url": "https://www.nature.com/articles/534303a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Firms chase a new breed of advanced veterinary care, from antibodies to cell therapies. Little Jonah once radiated pain. The 12-year-old Maltese dog\u2019s body was curled and stiff from the effort of walking with damaged knees. But after Kristi Lively, Jonah\u2019s veterinary surgeon, enrolled him in a clinical trial of a therapeutic antibody to treat pain, his owner returned to the Village Veterinary Medical Center in Farragut, Tennessee, with tears in her eyes. Her tiny companion trotted easily alongside her. \u201cI got my dog back,\u201d she said. Such cutting-edge treatments were once reserved for humans. But in recent years, the changing nature of pet ownership has sparked a boom in  sophisticated therapies for animals  \u2014 and many are now approaching the market. On 9\u00a0June, the company that sponsored the antibody trial, Nexvet of Dublin, presented its results at the American College of Veterinary Internal Medicine Forum in Denver, Colorado. Other companies are working on bone-marrow transplants, sophisticated cell therapies and cancer vaccines. \u201cWhen I was a child and just wanted to be a veterinarian, certainly I didn\u2019t imagine I\u2019d be doing what I\u2019m doing now,\u201d says Heather Wilson-Robles, a veterinary oncologist at Texas A&M University in College Station, who is engineering canine immune cells to fight cancer. Cancer, arthritis and other diseases  associated with old age  are becoming more common as pets live longer, thanks in part to better treatment by their owners. \u201cA generation ago, as beloved as Snoopy was, he lived in the backyard in the doghouse,\u201d says Steven St.\u00a0Peter, president of Aratana Therapeutics, a pet-therapy company in Leawood, Kansas. Now, pets are considered family members, often sharing beds with owners who are willing to pay hefty veterinary bills. Many standard pet treatments are human drugs given at lower doses to account for animals\u2019 smaller size. But antibodies and cell therapies generally cannot be used across species without provoking an unwanted immune response. And some human treatments simply will not work in pets: many common pain medications are toxic to cats. Nexvet, which has raised more than US$80\u00a0million from investors since it was founded in 2011, takes antibodies that have been approved as human medicines and alters their structures to make them effective in cats or dogs. Moving from a drug lead to safety testing takes about 18\u00a0months, says chief executive Mark Heffernan, who estimates that Nexvet\u2019s antibody therapies for pain will cost around $1,500 a year. The company is now looking into developing antibodies that block a protein called PD-1, thereby unleashing the immune system to fight cancer. This approach has shown tremendous promise for treating cancer in people. Aratana is also developing antibody therapies for pets, and has applied for regulatory approval of a cancer vaccine that uses a bacterium to target malignant cells. The company hopes to move into cell therapies, and to develop a way to manufacture stem cells from fat for use against joint pain. St.\u00a0Peter wants his company to be the first to win approval from the US Food and Drug Administration for a stem-cell therapy \u2014 ahead of firms developing such treatments for people. Other forms of cell therapy could also result in new veterinary remedies. Last July, veterinary oncologist Colleen O\u2019Connor founded a cancer-treatment company in Houston, Texas, called CAVU Biotherapies. To treat lymphoma, CAVU aims to isolate a sick dog\u2019s immune cells, rejuvenate them in culture, and then infuse them back into the dog\u2019s blood to stimulate an immune response. O\u2019Connor used a similar approach in 2011 to treat Dakota, a bichon frise that belonged to then-US Senator Kent Conrad (Democrat, North Dakota). The dog, a Capitol Hill fixture known as the \u2018101st senator\u2019, entered remission but later died of cancer. For many pet owners, cost is no object. Steven Suter, a veterinary oncologist at North Carolina State University in Raleigh, runs a bone-marrow transplant clinic for dogs that claims to cure 33% of lymphomas. Suter\u2019s clinic was booked solid after it opened in 2008, despite offering treatment that can cost a dog owner up to $24,000. Still, Suter has worked to drive down the cost of care: to filter stem cells from blood, his clinic uses second-hand machines that were donated by a physician with a soft spot for schnauzers. Earlier this year, several major pet-insurance companies added bone-marrow transplants to the lists of procedures that they will pay for. But when it comes to the latest pet treatments, some animals might be more equal than others. Cats are \u201c physiologically finicky \u201d, Suter says, noting that they may be too small to allow bone-marrow transplants using his usual machines. And O\u2019Connor notes that cats\u2019 immune systems also differ wildly from those of both humans and dogs \u2014 meaning that more basic research must be done before sophisticated immunotherapies can be deployed against feline ailments. At Lively\u2019s clinic, many dog and cat owners were grateful that their animals could participate in Nexvet\u2019s clinical trial. But about a month after the trial ended, the effects of the antibody therapy began to fade. Jonah\u2019s owner was among the clients who called Lively, desperate for a way to access the treatment again. \u201cIt\u2019s tough,\u201d Lively says. \u201cThey\u2019ll have to wait until this product comes to market.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Dog DNA probed for clues to human psychiatric ills 2016-Jan-26 \n                   \n                     \u2018I can haz genomes\u2019: cats claw their way into genetics 2015-Jan-14 \n                   \n                     Pet dogs set to test anti-ageing drug 2014-Oct-29 \n                   \n                     Stem cells boom in vet clinics 2013-Apr-10 \n                   \n                     Nexvet \n                   \n                     Aratana Therapeutics \n                   \n                     CAVU Biotherapies \n                   Reprints and Permissions"},
{"file_id": "534307a", "url": "https://www.nature.com/articles/534307a", "year": 2016, "authors": [{"name": "Alison Abbott"}, {"name": "Declan Butler"}, {"name": "Elizabeth Gibney"}, {"name": "Quirin Schiermeier"}, {"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Nature  examines five core ways that the European Union shapes the course of research. More than 500 million people and 28 nations make up the European Union. It will lose one of its richest, most populous members, if the United Kingdom votes to leave on 23\u00a0June. Ahead of a possible  \u2018Brexit\u2019 ,  Nature  examines five core ways that the EU shapes the course of research. \n               Scientist superhighway \n             Science doesn\u2019t respect national boundaries, so it helps if scientists don\u2019t have to either \u2014 and EU rules and programmes encourage researchers to hit the road. EU citizens have the right to live and work in any country in the bloc, and the European Commission\u2019s  Marie Sk\u0142odowska-Curie actions  pay for 9,000 scientists each year to move to or within the EU. The actions fill a gap left by national funders, which are often reluctant to fund researchers outside their country, says Caroline Whelan, a senior scientific officer at Science Europe, the Brussels-based organization of national research councils. The EU Erasmus exchange programme has transplanted more than 3.3 million students, and 470,000 teaching and administrative staff, since 1987. Although there is little information on how such programmes affect  scientists\u2019 overall mobility , they boost opportunities for collaboration. And because Marie Sk\u0142odowska-Curie fellows often return to their home country, they redistribute skills and knowledge. \u201cThis is fantastic for Eastern Europe and other less-well developed countries to build research capacity,\u201d says Lidia Borrell-Damian, director for research and innovation at the European University Association in Brussels. A 2011\u201313 study found that 31% of EU academics had worked outside their country of residence in the previous decade. And leading scientists say that hiring from abroad helps them to respond to local skills shortages. The survey also found that 80% of those who had worked internationally saw a positive effect on their research skills, and 60% thought that mobility had strongly increased their research output (see  go.nature.com/28wvqta ). But the experiences were not all positive: more academics said that their job options had decreased as a result of moving than said that opportunities had increased, for example. Another downside of mobility is that much of the flow goes just one way, says Maria Helena Nazar\u00e9, a physicist and former rector of the University of Aveiro in Portugal. \u201cI think that\u2019s already creating problems.\u201d Countries such as the United Kingdom, the Netherlands and Sweden tend to be net attractors for the Marie Sk\u0142odowska-Curie actions, whereas Spain, Greece and Italy lose talent. Nazar\u00e9 also notes that transferring pension and benefits between countries can be tough. Still, the commission is committed to further greasing the wheels. Funding aimed at encouraging mobility has soared in the past two decades to \u20ac6.2 billion (US$6.9 billion) in 2014\u201320 \u2014 and the commission is tackling the pensions issue. It is also growing its EURAXESS portal, an EU-wide website that lists jobs and support for moving researchers, and has revamped its \u2018scientific visa\u2019 package for non-EU researchers. Notably, the United Kingdom has opted out of the visa, together with Denmark. \n               Unique science \n             Scientists like to complain loudly about some aspects of the commission\u2019s \u2018Framework\u2019 funding programmes, which are dedicated to research and innovation (see \u2018EU spending\u2019). To access a vast pot of cash geared to meeting \u2018Societal Challenges\u2019 \u2014 which amounts to an estimated \u20ac28.6 billion of the \u20ac74.8 billion available under  Horizon 2020, the Framework programme for 2014\u201320  \u2014 they must meld themselves into large multinational collaborations, and adjust their research to fit EU strategic goals. But these constraints have fostered many valuable projects. \u201cI am a big fan of these programmes,\u201d says Nadia Rosenthal, scientific director of the Jackson Laboratory in Bar Harbor, Maine, who has collaborated with several EU consortia on mouse-genetics projects, which she says generated world-class science. \u201cThe coordination of talents they can achieve would be very hard to pull off in the United States \u2014 or in the UK alone, if it were not connected to Europe.\u201d Take research into the health effects of  low-dose radiation , which people may encounter during a CT scan or if they live within a few tens of kilometres of the site of the Fukushima disaster in Japan. So  small are the risks  \u2014 if they exist at all \u2014 that such research is low on most funding agencies\u2019 list of priorities. But the issue is of perennial concern to the public. And studying it requires collaboration between radiation-protection agencies and academics, as well as the use of large data sets, which can be gathered only by multiple collaborating nations. These factors make low-dose-radiation studies perfect fodder for EU funding, says Thomas Jung, head of radiation protection and health at the German Federal Office of Radiation Protection in Munich, which has participated in the series of low-dose-radiation projects that the commission has supported since 2010. Societal Challenges funding has also supported projects that others shy away from, such as transplanting cells derived from the brains of fetuses into the brains of people with Parkinson\u2019s disease. In 2003, researchers around the world abandoned this controversial line of research \u2014 which tries to replace the neurons whose loss causes the illness\u2019s symptoms \u2014 after many trial participants failed to benefit and no one could work out why. Then, in 2014,  the commission-funded TRANSEURO trial began . TRANSEURO aims to transplant neurons into 150 people with Parkinson\u2019s in the United Kingdom, Sweden, France and Germany using harmonized clinical protocols to help establish which conditions work best. The large collaboration, which joins 14 biomedical laboratories, clinics and companies, is essential, says TRANS-EURO\u2019s coordinator, neurologist Roger Barker at the University of Cambridge, UK. \u201cWithout the EU, I doubt this would have happened.\u201d Trust between companies is crucial to the Advanced Immunization Technologies (ADITEC) project, which aims to create a generic toolbox to speed up vaccine development. Under the confidentiality agreements of the consortium, which the commission has funded since 2011, companies are comfortable sharing the components of their proprietary vaccines. The project has already produced the first direct comparison of different companies\u2019 \u2018adjuvants\u2019, substances that strengthen immune responses ( N. P. H. Knudsen  et al. Sci. Rep.    6,  19570; 2016 ). \u201cWe had always thought it would be impossible to compare them,\u201d says ADITEC coordinator Rino Rappuoli, chief scientist of GSK Vaccines in Siena, Italy. \n               Lifted the East \n             In late 2000, when NATO sponsored a meeting on science in Central and Eastern Europe, much of the region was a world apart from the EU. Years of communist thinking had nourished the illusion that the mere existence of institutes and research facilities was more important than their actual performance. Attitudes have changed , partly thanks to the EU, which absorbed the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Poland, Slovakia and Slovenia in 2004, then Bulgaria and Romania in 2007 and Croatia in 2013. These countries have had a low rate of success in winning grants from the Framework programmes. But all of the former communist states are recipients of the commission\u2019s \u2018structural funds\u2019 \u2014 subsidies designed to reduce social and economic disparities, a goal of the EU. How the funds are used is decided locally, but of the \u20ac170 billion available for \u2018cohesion and regional development\u2019 in 2007\u201313, the commission pushed for \u20ac20 billion to be spent on research. In 2014\u201320, almost \u20ac44 billion is meant to be used for science and innovation in poorer regions. The cash has been most effective when used to refurbish universities and provide labs with the equipment needed to train students and entice researchers to stay, says Peter Tindemans, secretary-general of science-advocacy group EuroScience in Strasbourg, France. The funds have also financed the \u20ac850-million  Extreme Light Infrastructure , a pan-European laser facility under construction at sites in the Czech Republic, Hungary and Romania. The facility is expected to attract leading talent from around the world to the region, but Tindemans cautions that improvements to the research environment must come first. \u201cYou can\u2019t jump-start scientific development solely with large infrastructures,\u201d he says. \n               Fostering excellence \n             To win cash from EU funding programmes, researchers must often fit their work into broader societal or economic goals. But one corner of the European funding apparatus is all about science for science\u2019s sake. Set up in 2007 to  raise the quality of research across Europe , the European Research Council (ERC) awards generous grants that are open to any discipline, come with minimum bureaucracy and are judged solely on the quality of the application. The ERC budget has grown from \u20ac7.5 billion in 2007\u201313 to \u20ac13.1 billion for 2014\u201320. At up to \u20ac2.5 million over 5 years per researcher, its grants are longer and larger than those of most national funders. The approach seems to work: 7% of ERC-generated papers come in the top 1% of the most highly cited articles by discipline, publication type and year. Not everyone is happy with the \u2018excellence at all costs\u2019 approach. Since the ERC\u2019s inception, half of the grants it awarded under its three core schemes have gone to just three countries: the United Kingdom, Germany and France. But the ERC system lifts the quality of research beyond the projects that it funds. Either in an attempt to win more of its grants or simply inspired by the ERC, member states are redesigning national policies to make their science more competitive, says Jose Labastida, head of the ERC\u2019s scientific department. He cites Poland\u2019s National Science Centre, set up in 2011, as an example. And 17 countries have run schemes that fund ERC runners-up \u2014 applicants who met the quality threshold but were unsuccessful \u2014 essentially reusing the agency\u2019s high-quality peer-review process. \u201cThe ERC has raised the scientific level all over Europe,\u201d says Catherine Cesarsky, an astronomer at the French Atomic Energy Commission near Paris. \n               Research melting pot \n             Science thrives on  collaboration  \u2014 and the EU has partnered with other agencies (see \u2018European, but not EU\u2019) and creates myriad opportunities for researchers to pool ideas and cooperate. \n               boxed-text \n             Most of the funding for the EU\u2019s Framework programmes is reserved for projects in which partnerships are formed by at least three organizations from different countries. The last programme, FP7, which ran from 2007 to 2013, spent \u20ac41.7 billion of its \u20ac50.5-billion budget on some 26,000 joint projects, generating more than 500,000 pairs of collaborative links between research organizations, according to the commission. The Framework programmes also fund mobility grants that foster collaboration. In less-well-off countries, meanwhile, structural funds equip researchers to work with their counterparts in more scientifically developed nations, says R\u00e9mi Barr\u00e9, an emeritus researcher at the National Conservatory of Arts and Crafts in Paris. The gradual political, economic and research integration of the EU\u2019s member states has created an environment that is conducive to collaboration, according to geneticist Paul Nurse, head of the Crick Institute in London. Research is now embedded across the EU\u2019s activities, from the bloc\u2019s negotiation of the  COP21 climate accord in December 2015  to its environmental-protection policies and regulatory bodies such as the London-based European Medicines Agency. Contact between science ministers from different member states and researchers has become the norm, says Frank Gannon, former head of the intergovernmental European Molecular Biology Organization. By contrast, he recalls how fragmented European research was a few decades ago when he was a researcher in Ireland. \u201cThe sense of isolation of a researcher was massive.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Turning point 2016-Jun-15 \n                   \n                     Scientists say \u2018no\u2019 to UK exit from Europe in Nature poll 2016-Mar-30 \n                   \n                     Academics across Europe join \u2018Brexit\u2019 debate 2016-Feb-03 \n                   \n                     Europe's research commissioner lays out his ambitions 2015-Mar-23 \n                   \n                     Ukraine joins flagship European research programme 2015-Mar-20 \n                   \n                     After the Berlin Wall: Central Europe up close 2014-Nov-05 \n                   \n                     EU\u2013Swiss research on shaky ground 2014-Feb-18 \n                   \n                     Global mobility: Science on the move 2012-Oct-17 \n                   \n                     EU Horizon 2020 \n                   Reprints and Permissions"},
{"file_id": "534305a", "url": "https://www.nature.com/articles/534305a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Economists, investors and medical insurers can\u2019t figure out how to pay for cutting-edge drugs. Drugs that act by modifying a patient\u2019s genes are close to approval in the United States, and one is already available in Europe. The developments mark a triumph for the field of gene therapy, once  considered controversial . But with estimated price tags of at least US$1\u00a0million per patient, how will anyone pay for these treatments? The question is just one in a broader debate about how to finance a range of super-expensive drugs that are now available, thanks to an explosion in genetic and molecular-biology research over the past 20 years. \u201cAdvances in science are presenting a social affordability question like never before,\u201d says economist Mark Trusheim at the Massachusetts Institute of Technology in Cambridge. \u201cDo we want to convert the science into therapies that we actually would have to pay for?\u201d Trusheim spoke at the Biotechnology Innovation Organization (BIO) meeting in San\u00a0Francisco, California, on 6\u20139\u00a0June, which featured much discussion about how society will pay for the rising costs of new drugs. At the American Society of Clinical Oncology meeting in Chicago, Illinois, on 3\u20137\u00a0June, dozens of talks and abstracts focused specifically on the growing cost of cancer care.  Cancer drugs that unleash the power of the immune system  cost up to $40,000 per month. Gene therapies that are close to US approval include treatments for haemophilia\u00a0B, sickle-cell anaemia and the neurodegenerative disease cerebral adrenoleukodystrophy. A therapy under development at Spark Therapeutics in Philadelphia, Pennsylvania, for a  type of blindness  is considered the  most advanced . Many of the treatments deliver corrective genes using a modified virus that is considered safer than vectors used in earlier attempts. But many of the target disorders are rare, limiting the population that can be treated. And there are often no previously approved drugs that work similarly, removing the pressure on companies to lower their prices. Such therapies could cost $1 million per patient, estimate haematologist Stuart Orkin of Harvard Medical School in Boston, Massa\u00adchusetts, and Philip Reilly, an investor with Third Rock Ventures in Boston ( S. H. Orkin and P. Reilly  Science    352,  1059\u20131061; 2016 ). Reilly co-founded Cambridge-based Bluebird Bio, which is working on several of the gene therapies that are close to market. That\u2019s the same price as Glybera, the gene therapy given the green light by European regulators in 2012, which has been taken by only one person so far. Experts attribute this low uptake to the high price and to doubts about its efficacy. If newer gene therapies are to do better, they will have to produce convincing data that they are worth the money, Trusheim says. For medicines that are already approved, one increasingly popular solution is a deal between insurers and drug companies that ties payments to how well medicines perform. Last November, for example, Boston-based Harvard Pilgrim Health Care, a major New England insurer, announced that it will cover treatment for its clients with Repatha (evolocumab), one of a new class of cholesterol-lowering medication that is made by Amgen and costs $14,000. But if patients don\u2019t reach pre-agreed cholesterol levels, or if Harvard Pilgrim ends up paying more than it has budgeted for, Amgen will refund the insurer. Networks set up by insurance companies to gather and share data from health centres make such deals possible, says Michael Sherman, chief medical officer at Harvard Pilgrim. And they are on the rise around the world: one study found \u2018pay-for-performance\u2019 deals across 14\u00a0countries in 2013, predominantly in Europe and the United States, but also in middle-income countries such as China and Brazil. These deals may work for some conditions, such as haemophilia\u00a0B, for which several drugs might be approved. But for others, such as adrenoleukodystrophy, only one company is developing a product, so there won\u2019t be the incentive for companies to negotiate, Trusheim says. At the BIO meeting, investors and economists discussed a range of alternative solutions, including the medical equivalent of a  mortgage or annuity , in which insurance companies or governments might spread the cost of a one-time treatment over many years, as long as a patient continues to benefit from it. One complication of such arrangements in the United States is that patients often move between insurers, so it is unclear who would continue to make these payments on a patient\u2019s behalf. The difficulties of paying for the fruits of the biotechnology revolution are something that governments are already struggling with. The state of Arkansas last year settled a lawsuit filed by three people who said they had been denied access to the $300,000 cystic fibrosis drug Kalydeco (ivacaftor) because of the cost. And in April, the Japanese government imposed a 50% price cut on a new hepatitis\u00a0C treatment, Sovaldi (sofosbuvir). A US federal judge in Seattle, Washington, ruled on 27\u00a0May that states cannot delay treatment with Sovaldi, which costs up to $84,000, because of price concerns. But those working on gene therapy are confident that a solution is out there. \u201cLet\u2019s say that a gene therapy that really made a world of difference in the life of a small child should cost a million dollars for one event,\u201d Reilly says. \u201cI can think of many things in medicine that cost that much or more, and we don\u2019t think twice about that.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Success against blindness encourages gene therapy researchers 2015-Oct-21 \n                   \n                     Curing blindness: Vision quest 2014-Sep-10 \n                   \n                     Immunotherapy\u2019s cancer remit widens 2013-May-28 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20080", "url": "https://www.nature.com/articles/nature.2016.20080", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Widespread bleaching gives scientists new urgency to avert decline of key ocean ecosystems. It has been a bleak year for the world\u2019s coral. Ecologists have watched in horror as unusually warm ocean temperatures have  prompted corals to \u2018bleach\u2019 , or expel the symbiotic algae that provide much of their food. The result has been death and damage to reefs from Kiribati in the Pacific to the Indian Ocean's Maldives. With such episodes projected to occur more often even if climate change is mitigated, researchers are redoubling efforts to identify the factors that can make a reef resilient to harsh conditions. An analysis published this week in  Nature  points to some answers 1 . The study identifies 15 \u2018bright spots\u2019 where ecosystems are in a much better shape than researchers had predicted they should be. These include unpopulated, unfished regions such as the Chagos Islands in the Indian Ocean, and areas that are close to towns and where fishing takes place \u2014 such as Kiribati and the Solomon Islands, also in the Pacific. The study also pinpoints 35 \u2018dark spots\u2019 where conditions were surprisingly poor, such as Montego Bay in Jamaica and Lord Howe Island between Australia and New Zealand. \n             Common factors \n           The research team, led by Joshua Cinner, a social scientist who studies coral-reef systems at the Australian Research Council Centre of Excellence for Coral Reef Studies at James Cook University in Townsville, Australia, based its analysis on data that describe conditions at more than 2,500 reefs. The researchers used information on a reef\u2019s habitat, depth, nearby human population and amount of fishing to model how many fish could live at each site. The bright spots shared several characteristics, including high levels of local engagement in resource management, high dependence on local marine resources, and protective cultural taboos \u2014 such as excluding fishers from outside the local village. Cinner\u2019s work also suggests that the proximity of urban centres is a key driver of change in marine systems. It can damage reef systems that seem to be performing well to the naked eye, such as sites in the northwestern Hawaiian Islands that are part of a well-policed marine reserve but are still classified as a dark spot. \u201cMarine reserves will never be enough,\u201d says Cinner, who presented his results on 6 June at a meeting in London organized by the Central Caribbean Marine Institute. Instead, he says, the creation and maintenance of reserves should be coupled with other efforts to reduce threats to reefs. Emily Darling, a marine conservation scientist at the Wildlife Conservation Society, an environmental group in New York, calls the study impressive. \u201cIt\u2019s absolutely a novel approach that brings together ecological and social information, and bridges approaches from human health and development to conservation,\u201d she says. \u201cIdentifying what conditions create bright spots is incredibly hopeful for coral-reef conservation and sustainable fisheries.\u201d \n             Search for solutions \n           Cinner's work was among a number of coral studies presented at last week's meeting, which aimed to shake up the community of scientists who study corals, and catalyse a push for solutions to the avert the decline of these ecosystems. Terry Hughes, director of the coral-reef centre at James Cook University, says that the 2016 bleaching events have given researchers new motivation to  seek solutions . \u201cThey\u2019re seeing a level of damage they haven\u2019t seen before.\u201d He argues that current methods to promote reef sustainability are falling short. Even Australia\u2019s Great Barrier Reef, widely considered to be the best-managed reef ecosystem in the world,  is suffering . The  latest estimate from Hughes\u2019s centre , released on 30 May, suggests that this year\u2019s bleaching has killed 35% of corals at 84 survey sites on the northern and central Great Barrier Reef. Gareth Williams, who researches remote reefs from Bangor University, UK, told the meeting that modelling work currently under review suggests that even if the world manages to reduce its greenhouse-gas emissions, many reefs will bleach annually by 2030. Corals can recover from mild to moderate bleaching, but severe bleaching is deadly and repeated bleaching will likely cause drastic changes to the ecosystem in the long term.\u201cI don\u2019t think we can save them all,\u201d Williams said. \u201cSome reefs are just going to go. Investing in those will be a waste of time and resources.\u201d \n             Essential changes \n           Many participants at the meeting agreed that the research community needs to shift from cataloguing the decline of reefs to finding ways to encourage their resilience to climate change. \u201cWe\u2019ve stood by for the last 25 years trying to understand what\u2019s happening and watching coral reefs die globally,\u201d said Carrie Manfrino, research director at the Cayman Islands-based Central Caribbean Marine Institute, which organized the meting. What\u2019s needed now, she told the audience, is \u201cto establish a new road map that can give us a future\u201d. Tom Frazer, a meeting attendee and director of the School of Natural Resources and Environment at the University of Florida in Gainsville, says that it is a positive sign that there are some reefs that have proven to be resilient to human-induced change or to have recovered from disturbances such as bleaching or cyclones. \u201cThese are bright spots and provide hope for the future,\u201d said Frazer \u2014 adding that social factors such as behavioural change and innovative governance for marine systems are going to be \u201cabsolutely essential\u201d to saving reefs. Reprints and Permissions"},
{"file_id": "nature.2016.20093", "url": "https://www.nature.com/articles/nature.2016.20093", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "After historic first discovery last September, twin observatories detected gravitational waves again on Boxing Day. Just before 4 a.m. on 26 December, B. S. Sathyaprakash woke up to some good news: gravitational waves had been detected for only the second time in history. The theoretical physicist from Cardiff University, UK, had his laptop next to his bed, set up to ring in response to automated e-mail alerts from computers at the Advanced Laser Interferometer Gravitational-wave Observatory (LIGO). \u201cI got up and I went and checked the computer. Lo and behold, there was an event from just two minutes before,\u201d he says. At 3:38:53 UTC (Coordinated Universal Time), LIGO\u2019s twin detectors in Louisiana and Washington state had both picked up the signature ripples of two massive objects \u2014 probably two black holes \u2014 in the final stages of spiralling into each other. At the time, the international LIGO collaboration and its colleagues at Virgo, a European observatory near Pisa, Italy, were busy analyzing LIGO's first discovery: the  event they had detected on 14 September . The scientists would  announce that finding  in February, to  great global fanfare . They did not run a full analysis of the second event until weeks later, says LIGO physicist Bruce Allen, managing director of the Max Planck Institute for Gravitational Physics in Hanover, Germany. \n               Second success \n             \u201cIt was absolutely mind-boggling how within a few months of the first event we had a second one,\u201d Sathyaprakash says. The second detection \u201cshows that this whole business is not a fluke\u201d, says Clifford Will, a theoretical physicist at the University of Florida in Gainesville who is not a member of either the LIGO or Virgo teams. In principle, the September discovery could have been a huge stroke of luck, but this second event suggests that there is a large population of black-hole pairs out there that will produce frequent mergers. LIGO and Virgo can look forward to regular detections, says Will, who studies gravitational waves and other predictions of Albert Einstein's general theory of relativity. \u201cThis is going to be a new kind of astronomy.\u201d Einstein predicted that any accelerating or rotating bodies should produce ripples in the fabric of space, which are vaguely similar to sound waves but move at the speed of light and can propagate in a vacuum. The detailed analysis of this second detection confirmed that the signature had to be the ripples from a pair of black holes (see video below). This time, the signal from the gravitational waves lasted one full second, instead of one-fifth of a second as in the first event. The second event encompassed the objects\u2019 last 27 orbits around each other, versus just five or so from the first detection. This enabled the researchers to get a test of general relativity that was in some respects twice as precise as their test during the first detection. This was true even though the September event was 'louder' than the December event. The first pair of black holes weighed as much as 36 and 29 times the mass of the Sun, whereas the holes in the second pair were relatively lightweight, at 14 and 8 solar masses, and radiated one-third as much gravitational energy. (In both cases, the black-hole pairs might have been in mutual orbits for millions or billions of years, but LIGO only captured the finale, where the orbits and the gravitational waves they produced had frequencies within the observatory's window of sensitivity.) \n               Well-timed gift \n             The LIGO and Virgo scientists estimate that both collisions occurred more than 400 megaparsecs (1.3 billion light years) away, although the distances could not be measured precisely. The teams presented their latest results on 15 June at a meeting of the American Astronomical Society in San Diego, California, and published them in  Physical Review Letters 1 . The latest discovery was especially exciting for physicist Chad Hanna, a LIGO collaborator at Pennsylvania State University in University Park. When Hanna got the alert via text message, it was still Christmas Day in the US, and he was visiting with family. The collaboration requires members to keep data completely confidential, so Hanna hopped out of his chair, got his laptop and went upstairs to an empty room. At first, he was sceptical, he says: \u201cI just didn't think the Universe had such a sense of humour to send a real event on Christmas.\u201d But he soon realized that although the signal was relatively quiet, it was genuine. It was a crucial test for the software that combs the data from the two observatories in real time, which he helped to design. The system could catch events even if they were half-buried in the noise, but didn't produce too many false positives. \n               Other events \n             Eventually, the automated alerts will also immediately notify dozens of teams of astronomers. The researchers would then reposition their telescopes in the hopes of detecting visible light, or other electromagnetic waves, that originate from the same events that produce the gravitational waves. After its first four-month science run between September 2015 and January 2016, the US$620-million Advanced LIGO \u2014 an upgraded version of an earlier observatory \u2014 shut down for an upgrade, and is scheduled to start another run this September, accompanied by an upgraded Virgo. The results released today complete the search for black-hole mergers in LIGO\u2019s autumn run, but the collaboration is still sifting its data for  other types of event  \u2014 and may yet announce further discoveries before the next run even begins. In particular,  the Einstein@home project  is looking for signals with the help of computers belonging to volunteers around the world. \n               \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               Reprints and Permissions"},
{"file_id": "nature.2016.19958", "url": "https://www.nature.com/articles/nature.2016.19958", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Antibody provider Santa Cruz Biotechnology settles with government after complaints about treatment of goats. The US government has fined Santa Cruz Biotechnology, a major antibody provider, US$3.5 million over alleged violations of the US Animal Welfare Act. The penalty from the US Department of Agriculture is the largest in the agency\u2019s history. The company, which is headquartered in Dallas, Texas, will pay the fine as part of a settlement with the US Department of Agriculture (USDA). The agency had  lodged three animal-welfare complaints  against Santa Cruz Biotech, after USDA inspectors found evidence that the company mistreated goats at its facility in California. Santa Cruz Biotech contested the government complaints, and the 19 May settlement agreement says that the company \u201cneither admits nor denies\u201d that it violated US animal-welfare regulations. The settlement also permanently revokes Santa Cruz Biotech\u2019s government licence to sell, buy, trade or import animals. And it requires the company to cancel its registration to operate as a research facility that uses animals. The company had extracted antibodies for research from animals such as goats and rabbits after injecting the animals with proteins to stimulate antibody production. Neither Santa Cruz Biotech nor representatives of Covington & Burling, a Washington DC law firm that represents the company, have responded to  Nature \u2019s request for comment on the settlement. Cathy Liss, president of the Animal Welfare Institute, an advocacy group in Washington DC, says that she is shocked by the unprecedented size of the fine on Santa Cruz Biotech. The largest previous fine that the USDA had imposed for animal-welfare complaints was a $270,000 penalty levied in 2011 against Feld Entertainment, which operates the Ringling Brothers and Barnum & Bailey Circus. \n             Probe ends \n           The settlement with Santa Cruz Biotech marks the end of a long-running investigation of the company\u2019s animal-welfare practices. The USDA has lodged three animal-welfare complaints against Santa Cruz Biotech since 2007, after agency inspectors reported finding problems such as goats with untreated coyote bites and  massive tumours , and rabbits being housed in cruel conditions. USDA inspectors also discovered that Santa Cruz was  keeping 841 goats in a hidden facility . In February,  Nature  reported that more than 5,000 goats and rabbits had disappeared from Santa Cruz\u2019s facilities before a scheduled hearing on the USDA complaints. Santa Cruz would not confirm whether the animals were killed or sold. After news of the animals' disappearance became public, some scientists took to social media to call for a boycott of Santa Cruz\u2019s products. Among them was Stephen Floor, a biologist at the University of California, Berkeley, who says that his lab has since sought out other antibody providers. Floor says that losing Santa Cruz as an antibody provider will create extra work for researchers. Because the quality and type of antibodies varies widely, individual labs often stick with products from a single company to ensure that their experiments are replicable. \u201cThat said, I think any scientist will happily do that work in order to ensure that animal rights are a priority,\u201d he says. \n                   Thousands of goats and rabbits vanish from major biotech lab 2016-Feb-19 \n                 \n                   Discovery of goat facility adds to antibody provider's woes 2013-Jan-14 \n                 \n                   NIH retires research chimps at troubled facility 2012-Sep-21 \n                 \n                   Antibody provider investigated over treatment of goats \n                 \n                   Santa Cruz Biotechnology \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19972", "url": "https://www.nature.com/articles/nature.2016.19972", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Impoverished adolescents acquire DNA marks, brain changes and depression over time. Children from impoverished families are more prone to mental illness, and alterations in DNA structure could be to blame, according to a study published on 24 May in  Molecular Psychiatry 1 . Poverty brings with it a number of different stressors, such as poor nutrition, increased prevalence of smoking and the general struggle of trying to get by. All of these can affect a child\u2019s development, particularly in the brain, where the structure of areas involved in response to stress and decision-making have been linked to low socioeconomic status. Poor children are more prone to mental illnesses such as depression than their peers from wealthier families, but they are also more likely to have cognitive problems. Some of these differences are clearly visible in the brain structure and  seem to appear at birth , which suggests that prenatal exposure to these stressors can be involved 2 . \n             From birth to adolescence \n           But neurodevelopment does not stop at birth. Neuroscientist Ahmad Hariri of Duke University in Durham, North Carolina, suspected that continual exposure to stressors might affect older children as well. He decided to test this idea by studying chemical tags known as methyl groups, which alter DNA structure to regulate how genes are expressed. There is some evidence that methylation patterns can be passed down through generations, but they are also altered by environmental factors, such as smoking. To test whether these mechanisms are involved in the increased likelihood of depression seen in impoverished children, Hariri and his colleagues zeroed in on a gene called  SLC6A4 , which encodes a protein that transports the brain-signalling molecule serotonin into neurons. The gene has long been known to be involved in depression, and the serotonin receptor is the target of many antidepressant drugs. Hariri and his colleagues collected blood samples from 183 Caucasian children aged 11\u201315, and tested the children for symptoms of depression. They also examined how the children responded to stress by scanning their brains to monitor activity when shown a picture of a frightened face. People who are highly sensitive to threats show more activity in the amygdala \u2014 the brain\u2019s \u2018fight or flight\u2019 centre \u2014 when they see such an emotion. \n             Test of time \n           The researchers repeated these experiments on the same children several times over the course of three years. Then they compared the results for each child with changes in his or her brain activity over the same time period, as well as shifts in methylation patterns near the  SLC6A4  gene. The scientists found that children who grew up in poverty had more methylation in this region compared to their wealthier peers. This might have suppressed the poor children's production of serotonin transporter protein, so that they had less serotonin available to the brain \u2014 a condition linked to depression. The children\u2019s amygdalas also became more active, and those who had a family history of depression were more likely to become depressed themselves. Seth Pollak, a child psychologist at the University of Wisconsin\u2014Madison, says that it is unclear whether poverty harms cognition and mental health, or whether a person\u2019s intrinsic biology increases the likelihood that he or she will be poor as adults. But epigenetic research, such as the new study, shows that genetic differences are not the only important factors. \u201cYou might have a particular gene \u2014 but depending on the experience you have or don\u2019t have, the gene might never be turned on,\u201d Pollak says. The new paper is notable in that it looks at the effects of low-level stress over a long period of time, he says, rather than the effects of an extreme trauma. But Pollak cautions that the sample is small for a study that attempts to understand complex interactions between genetics and the environment, and that some individuals are much more susceptible than others to the impact of poverty. \n             Gene extensions \n           Hariri says that his group now wants to look at the methylation of genes in a group of about 1,000 people in Dunedin, New Zealand, whose health has been tracked since 1972\u201373. \u201cIt\u2019s very nice to see such a well-constructed experiment,\u201d says Dan Notterman, a molecular biologist at Princeton University in New Jersey. He is surprised at how clear the links between epigenetics, behaviour and socioeconomic status are. Notterman\u2019s own research has found 3  that telomeres, DNA sequences found at the ends of chromosomes,  are shortened in children from impoverished families . Telomere length is involved in ageing and in poor general health. If researchers can identify DNA markers that are strongly linked to brain activity and behaviour, Notterman says, they could be used as a test for whether depression drugs are effectively treating a person's disease. But Robert Philibert, a behavioural geneticist at the University of Iowa in Iowa City, says that for impoverished children, the answer may be simpler \u2014 at least from a scientific perspective. \u201cWhat this points out here is that if you really want to change neurodevelopment, alter the environment,\u201d he says. Reprints and Permissions"},
{"file_id": "533448a", "url": "https://www.nature.com/articles/533448a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Two blueprints emerge from centre tasked with creating a practical quantum device. Silicon is at the heart of the multibillion-dollar computing industry. Now, efforts to harness the element to build a quantum processor are taking off, thanks to elegant designs from an Australian collaboration. In July, the Centre for Quantum Computation and Communication Technology, which is based at the University of New South Wales (UNSW) in Sydney, will receive the first instalment of a Aus$46-million (US$33-million) investment. The money comes from government and industry sources whose goal is to create a practical quantum computer. At an innovation forum in London on 6\u00a0May, hosted by  Nature  and start-up accelerator Entrepreneur First, two physicists from a group at the UNSW pitched a plan to reach that goal. Their audience was a panel of entrepreneurs and scientists, who critiqued ideas for commercializing a range of quantum technologies, including sensors, computer security and a quantum internet as well as quantum computers. So far, the UNSW team has demonstrated a system with quantum bits, or qubits, only in a single atom. Useful computations will require linking qubits in multiple atoms. But the team\u2019s silicon qubits hold their quantum state nearly a million times longer than do systems made from superconducting circuits, a leading alternative, UNSW physicist Guilherme Tosi told participants at the event. This helps the silicon qubits to perform operations with one-sixth of the errors of superconducting circuits. If the team can pull off this low error rate in a larger system, it would be \u201cquite amazing\u201d, said Hartmut Neven, director of engineering at Google and a member of the panel. But he cautioned that in terms of performance, the system is far behind others. The team is aiming for ten\u00a0qubits in five years, but both Google and IBM are already approaching this with superconducting systems. And in five years, Google plans to have ramped up to hundreds of qubits. A second group from the UNSW has a less robust silicon design that has already demonstrated calculations that link up two qubits, a building block that paves the way for creating more-complex devices. In a regular computer, each bit can be \u2018on\u2019 or \u2018off\u2019. In a quantum computer, the qubits can be both on and off at once, which allows them to perform many computations in parallel. This should allow quantum computers to zip through calculations that would take a normal computer longer than the age of the Universe, although the best devices are still much too small to do so. Silicon is an attractive base for a universal quantum computer \u2014 one that can carry out any quantum algorithm \u2014 because it is potentially compatible with the microelectronics of existing computers. But silicon systems are still years behind their rivals. One issue has been how to keep delicate quantum states alive for long enough to perform operations. The scheme showcased at the innovation forum by Tosi and fellow physicist Vivien Schmitt \u2014 who are both part of Andrea Morello\u2019s lab at the UNSW \u2014 addresses this challenge. The qubits are the spins of the electrons and nuclei in phosphorus atoms embedded in a silicon lattice, and are controlled using a special system of electric fields. Because the spins respond only to very specific, tuneable frequencies, they are robust to electrical noise. That allows the qubits to keep their quantum states for one minute and to operate perfectly 99.9% of the time, said Tosi. Moreover, the electrically controlled qubits can communicate with each other at larger distances than can the qubits in other silicon designs. That bodes well for scaling up because the qubits can be far enough apart to allow room for control and read-out instruments to be placed between them. The atoms also do not need to be placed precisely, so they would fit with existing microprocessor-fabrication techniques, added Tosi. Although Morello\u2019s team has demonstrated the high precision only in a single atom, the researchers have started to experiment with a two-atom system, and expect this level of performance to scale up. \u201cFrom there, there are no basic first-principle barriers,\u201d said Tosi. He has patented a design for a larger-scale computer and says that it should be possible to manufacture chips that use their system in plants similar to those already used to make present-day microprocessors. \n               Spin city \n             Another silicon project from UNSW, led by physicist Andrew Dzurak, uses as its qubits the spins of electrons in a set-up that is based on modified electrical transistors. Although the qubits are less robust than those in the Morello design, Dzurak\u2019s team demonstrated two-qubit calculations last October. At the London event, Tosi and Schmitt were grilled on the Morello team\u2019s plan. \u201cIt\u2019s a beautiful scheme,\u201d said John Morton, an electrical engineer at University College London. But he cautioned that aspects of the business model that the duo presented as part of the event seemed reliant on superconducting qubits not getting any better. \u201cThat\u2019s a risky thing to do,\u201d Morton said. Neven agreed, pointing out that silicon qubits will need to demonstrate advantages in other areas if they are to get a foothold in the future quantum-computer market. Like superconducting qubits, silicon qubits must be kept at a fraction of a degree above absolute zero. Morton said that the Morello design\u2019s big advantage is that the qubits are atomic scale. In principle, that would allow many more to be placed on each chip than is possible with superconducting qubits, which are around 100\u00a0micrometres across. To seize this opportunity, the design needs to shed the bulky microwave devices that it proposes as its means to operate between distant qubits, said Neven. The successes of the Australian quantum centre \u2014 which is led by UNSW physicist Michelle Simmons \u2014 are partly down to its wider expertise in nanoscale silicon fabrication, says Peter Knight, a physicist at Imperial College London and a panel member at the event. When it comes to fabrication, he says, the centre is way ahead of others working in silicon. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Europe plans giant billion-euro quantum technologies project 2016-Apr-21 \n                   \n                     Physics: Quantum computer quest 2014-Dec-03 \n                   \n                     Quantum computation: Silicon comes back 2014-Oct-12 \n                   \n                     Computing: The quantum company 2013-Jun-19 \n                   \n                     Centre for Quantum Computation and Communication Technology \n                   Reprints and Permissions"},
{"file_id": "533450a", "url": "https://www.nature.com/articles/533450a", "year": 2016, "authors": [{"name": "Emily Waltz"}], "parsed_as_year": "2006_or_before", "body": "Biotech firm seeks government approval to market mosquitoes as a pesticide to prevent spread of Zika and dengue viruses. The United States could soon become the first country to approve the commercial use of a common bacterium to fight the spread of mosquitoes that can transmit viruses such as Zika,  dengue  and  Chikungunya . The US Environmental Protection Agency (EPA) is reviewing an application from the biotechnology start-up MosquitoMate to use the bacterium  Wolbachia pipientis  as a tool against the Asian tiger mosquito ( Aedes albopictus ). The company plans to market  Wolbachia  as a pesticide \u2014 one that kills only mosquitoes, and leaves other insects untouched. The EPA\u2019s decision on the matter will come after a public-comment period that ends on 31 May. MosquitoMate\u2019s strategy involves rearing mosquitoes infected with a particular strain of  Wolbachia  and releasing the males into the environment. When these male mosquitoes mate with wild females who do not carry the same strain of  Wolbachia , the resulting fertilized eggs don\u2019t hatch, because the paternal chromosomes do not form properly. As infected male mosquitoes continue to be released to breed with wild partners, the pest population dwindles. Eight countries have now reported  cases of microcephaly or other fetal birth defects  that are probably caused by Zika, leading officials in many areas to  consider new options  for reducing mosquito populations. \u201cWe need as many effective tools as we can get, so we need to give  Wolbachia  a try,\u201d says Tom Scott, an entomologist at the University of California, Davis. \u201cThat will require a well-developed plan for how trials would be done.\u201d MosquitoMate, which was started by researchers at the University of Kentucky in Lexington, has tested  Wolbachia  in  A.\u00a0albopictus  mosquitoes in three states over the past three years. The approach has reduced the wild mosquito population by more than 70% in those areas, says Stephen Dobson, an entomologist at the University of Kentucky and founder of the company. MosquitoMate is also using  Wolbachia  to target the mosquito  Aedes aegypti , which is thought to be the main vector for Zika. The firm began field trials this month of infected  A. \u2009 aegypti  mosquitoes in Clovis, California, and has applied to conduct similar tests in Florida and in Orange County, California. Other groups are also investigating  Wolbachia \u2019s ability to stamp out  A.\u00a0albopictus . Researchers from Sun Yat-sen University in Guangzhou, China, and Michigan State University in East Lansing began field trials of  Wolbachia -infected mosquitoes last year on Shazai Island in Guangzhou. In March, the tests expanded to Dadao Island, also in Guangzhou. The researchers are releasing 1.5\u00a0million male  A.\u00a0albopictus  per week, with plans to increase that to 5\u00a0million per week by the end of August. \u201cOur mosquito factory is currently the largest one in the world,\u201d says Zhiyong Xi, a medical entomologist and microbiologist at Michigan State, who oversees the project.  We need as many effective tools as we can get.  But such large, ongoing releases of mosquitoes may be too expensive for many countries or cities. With this in mind, the non-profit international collaboration Eliminate Dengue is testing an approach that requires the rearing of many fewer mosquitoes. Instead, it uses a starter set of mosquitoes that carry  Wolbachia  to  infect an entire wild population . The resulting offspring harbour the bacteria yet develop normally. But the  Wolbachia  infection prompts an immune response and consumes key cellular resources, which helps to prevent viruses \u2014 such as Zika and dengue \u2014 from growing and replicating in these mosquitoes ( H.\u00a0L.\u00a0C.\u00a0Dutraet\u00a0al.CellHostMicrobehttp://doi.org/bhsh;2016 ). \u201cWe\u2019re not trying to kill or suppress the mosquito population, we\u2019re just making them ineffective at transmitting a range of pathogens to people,\u201d says Scott O\u2019Neill, head of Eliminate Dengue and dean of science at Monash University in Melbourne, Australia. The group is testing the technology against  A.\u00a0aegypti  in open trials in Indonesia, Vietnam, Australia, Brazil and Colombia. O\u2019Neill hopes to make the system affordable for developing countries at a cost of about US$1 per person. But using  Wolbachia  to suppress or infect mosquito populations has never been proved to reduce the incidence of Zika or dengue in humans. O\u2019Neill says that the Eliminate Dengue group has seen \u201ca collapse of dengue transmission\u201d where it has released  Wolbachia -infected mosquitoes. The group is trying to verify those observations with controlled, randomized studies that are now under way in Indonesia and Vietnam. So far, tests of mosquitoes infected with  Wolbachia  have prompted little public resistance. By contrast, US residents have used yard signs, social-media campaigns and a petition  to protest against proposed trials  of genetically engineered mosquitoes developed by Oxitec of Milton Park, UK. Oxitec and MosquitoMate each alter male mosquitoes using a lethal reproductive weapon before releasing them into the environment to mate with and suppress their own kind. But Oxitec modifies its mosquitoes with a gene, whereas MosquitoMate uses a bacterium. The US Food and Drug Administration, which is considering Oxitec\u2019s proposal for a field trial in Florida, received more than 2,600\u00a0public comments on the plan. But as  Nature  went to press, the EPA, which is accepting public input on MosquitoMate\u2019s plan until 31\u00a0May, had received just one comment. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Why transgenic insects are still not ready for prime time 2016-Apr-22 \n                   \n                     Sickly mosquitoes stymie malaria\u2019s spread 2013-May-09 \n                   \n                     Florida abuzz over mosquito plan 2012-Jul-17 \n                   \n                     Modified mosquitoes set to quash dengue fever 2012-Jan-10 \n                   \n                     Bacterium offers way to control dengue fever 2011-Aug-24 \n                   \n                     Ecology: A world without mosquitoes 2010-Jul-21 \n                   \n                     Bacteria could help control dengue fever 2009-Jan-01 \n                   \n                     MosquitoMate \n                   \n                     Eliminate Dengue \n                   \n                     Oxitec \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19975", "url": "https://www.nature.com/articles/nature.2016.19975", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Walls of stalagmites in a French cave might have had a domestic or a ceremonial use.\u00a0 Neanderthals built one of the world\u2019s oldest constructions \u2014 176,000-year-old semicircular walls of stalagmites in the bowels of a cave in southwest France. The walls are currently the best evidence that Neanderthals built substantial structures and ventured deep into caves, but researchers are wary of concluding much more. \u201cThe big question is why they made it,\u201d says Jean-Jacques Hublin, a palaeoanthropologist at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany who was not involved in the study, which is published online in  Nature  on 25 May  1 . \u201cSome people will come up with interpretations of ritual or religion or symbolism. Why not? But how to prove it?\u201d Speleologists first discovered the structures in Bruniquel Cave in the early 1990s. They are located about a third of a kilometre from the cave entrance, through a narrow passage that at one point requires crawling on all fours. Archaeologists later found a burnt bone from an herbivore or cave bear nearby and could detect no radioactive carbon left in it \u2014 a sign that the bone was older than 50,000 years, the limit of carbon dating. But when the archaeologist leading the excavation died in 1999, work stopped. Then a few years ago, Sophie Verheyden, a palaeoclimatologist at the Royal Belgian Institute of Natural Sciences in Brussels and a keen speleologist, became curious about the cave after buying a holiday home nearby. She assembled a team of archaeologists, geochronologists and other experts to take a closer look at the mysterious structures. \n             Neanderthal hearths? \n           The six structures are made of about 400 large, broken-off stalagmites, arranged in semi-circles up to 6.7 metres wide. The researchers think that the pieces were once stacked up to form rudimentary walls. All have signs of burning, suggesting that fires were made within the walls. By analysing calcite accreted on the stalagmites and stumps since they were broken off, the team determined that the structures were made 174,400 to 178,600 years ago. \u201cIt\u2019s obvious when you see it, that it\u2019s not natural,\u201d says Dominique Genty, a geoscientist at the Institute Pierre-Simon Laplace in Gif-sur-Yvette who co-led the study with Verheyden and archaeologist Jacques Jaubert, at the University of Bordeaux, in France. Their team found no signs that cave bears had hibernated near the structures, and so might have broken the stalagmites off themselves. The researchers have so far found no remains of early humans, stone tools or other signs of occupation, but they think that Neanderthals made the structures, because no other hominins are known in western Europe at that time. \u201cSo far, it\u2019s difficult to imagine that it\u2019s not human made, and I don\u2019t imagine any natural agent creating something like that,\u201d Hublin agrees. \n             Spiritual to domestic \n           But Harold Dibble, an archaeologist at the University of Pennsylvania in Philadelphia, isn\u2019t so sure. \u201cWhen they say there\u2019s no evidence of cave bears in this spot, maybe they\u2019re looking at the evidence for cave bears,\u201d he says. The authors could make a stronger case for Neanderthals if they can show, for instance, that the stalagmite pieces are uniform in size or shape and therefore selected. If Neanderthals did build the structures, it\u2019s not at all clear why. \u201cIt\u2019s a big mystery,\u201d says Genty, whose team speculates that their purpose may have ranged from the spiritual to the more domestic. Evidence for symbolism among Neanderthals is limited, ranging  from etchings on a cave wal l to eagle talons possibly  used as jewelry . \u201cTo me, constructing some sort of structure \u2014 things a lot of animals do, including chimps \u2014 and equating that with modern cultural behaviour is quite a leap,\u201d says Dibble. Marie Soressi, an archaeologist at the Leiden University in the Netherlands, says that it is no surprise that Neanderthals living 176,000 years ago had the brains to stack stalagmites. They made complex stone tools and even used fire to forge specialized glues. More surprising is the revelation that some ventured into deep, dark spaces, says Soressi, who wrote a  News and Views article  for  Nature  that accompanies the report. \u201cI would not have expected that, and I think it immediately changes the way we are going to investigate the underground in the future,\" she says. Read the related  News and Views article Reprints and Permissions"},
{"file_id": "nature.2016.19957", "url": "https://www.nature.com/articles/nature.2016.19957", "year": 2016, "authors": [{"name": "Edwin Cartlidge"}], "parsed_as_year": "2006_or_before", "body": "Radioactive decay anomaly could imply a new fundamental force, theorists say. A laboratory experiment in Hungary has spotted an anomaly in radioactive decay that could be the signature of a previously unknown fifth fundamental force of nature, physicists say \u2013 if the finding holds up. Attila Krasznahorkay at the Hungarian Academy of Sciences\u2019s Institute for Nuclear Research in Debrecen, Hungary, and his colleagues reported their surprising result in 2015  on the arXiv preprint server , and this January in the journal  Physical Review Letters 1 . But the report \u2013 which posited the existence of a new, light boson only 34 times heavier than the electron \u2013 was largely overlooked. Then, on 25 April, a group of US theoretical physicists brought the finding to wider attention by publishing  its own analysis of the result on arXiv 2 . The theorists showed that the data didn\u2019t conflict with any previous experiments \u2013 and concluded that it could be evidence for a fifth fundamental force. \u201cWe brought it out from relative obscurity,\u201d says Jonathan Feng, at the University of California, Irvine, the lead author of the arXiv report. Four days later, two of Feng's colleagues discussed the finding at a workshop at the SLAC National Accelerator Laboratory in Menlo Park, California. Researchers there were sceptical but excited about the idea, says Bogdan Wojtsekhowski, a physicist at the Thomas Jefferson National Accelerator Facility in Newport News, Virginia. \u201cMany participants in the workshop are thinking about different ways to check it,\u201d he says. Groups in Europe and the United States say that they should be able to confirm or rebut the Hungarian experimental results within about a year. \n             Search for new forces \n           Gravity, electromagnetism and the strong and weak nuclear forces are the four fundamental forces known to physics \u2014 but researchers have made many as-yet unsubstantiated claims of a fifth. Over the past decade, the search for new forces has ramped up because of the inability of the standard model of particle physics to explain  dark matter  \u2014 an invisible substance thought to make up more than 80% of the Universe\u2019s mass. Theorists have proposed various exotic-matter particles and force-carriers, including \u201c dark photons \u201d, by analogy to conventional photons that carry the electromagnetic force. Krasznahorkay says his group was searching for evidence of just such a dark photon \u2013 but Feng\u2019s team think they found something different. The Hungarian team fired protons at thin targets of lithium-7, which created unstable beryllium-8 nuclei that then decayed and spat out pairs of electrons and positrons. According to the standard model, physicists should see that the number of observed pairs drops as the angle separating the trajectory of the electron and positron increases. But the team reported that at about 140\u00ba, the number of such emissions jumps \u2014 creating a \u2018bump\u2019 when the number of pairs are plotted against the angle \u2014 before dropping off again at higher angles. \n             Bump in confidence \n           Krasznahorkay says that the bump is strong evidence that a minute fraction of the unstable beryllium-8 nuclei shed their excess energy in the form of a new particle, which then decays into an electron\u2013positron pair. He and his colleagues calculate the particle\u2019s mass to be about 17 megaelectronvolts (MeV). \u201cWe are very confident about our experimental results,\u201d says Krasznahorkay. He says that the team has repeated its test several times in the past three years, and that it has eliminated every conceivable source of error. Assuming it has done so, then the odds of seeing such an extreme anomaly if there were nothing unusual going on are about 1 in 200 billion, the team says. Feng and colleagues say that the 17-MeV particle is not a dark photon. After analysing the anomaly and looking for properties consistent with previous experimental results, they concluded that the particle could instead be a \u201cprotophobic  X  boson\u201d. Such a particle would carry an extremely short-range force that acts over distances only several times the width of an atomic nucleus. And where a dark photon (like a conventional photon) would couple to electrons and protons, the new boson would couple to electrons and neutrons. Feng says that his group is currently investigating other kinds of particles that could explain the anomaly. But the protophobic boson is \u201cthe most straightforward possibility\u201d, he says. \n             Unconventional coupling \n           Jesse Thaler, a theoretical physicist at the Massachusetts Institute of Technology (MIT) in Cambridge, says that the unconventional coupling proposed by Feng\u2019s team makes him sceptical that the new particle exists. \u201cIt certainly isn\u2019t the first thing I would have written down if I were allowed to augment the standard model at will,\u201d he says. But he adds that he is \u201cpaying attention\u201d to the proposal. \u201cPerhaps we are seeing our first glimpse into physics beyond the visible Universe,\u201d he says. Researchers should not have to wait long to find out whether a 17-MeV particle really does exist. The DarkLight experiment at the Jefferson Laboratory is designed to search for dark photons with masses of 10\u2013100 MeV, by firing electrons at a hydrogen gas target. Now, says collaboration spokesperson Richard Milner of MIT, it will target the 17-MeV region as a priority, and within about a year, could either find the proposed particle or set stringent limits on its coupling with normal matter. Also searching for the proposed boson will be the LHCb experiment at CERN, Europe\u2019s particle-physics lab near Geneva, which will study quark\u2013antiquark decays, and two experiments that will fire positrons at a fixed target \u2014 one at the INFN Frascati National Laboratory near Rome, due to switch on in 2018, and the other at the Budker Institute of Nuclear Physics in the Siberian town of Novosibirsk, Russia. Rouven Essig, a theoretical physicist at Stony Brook University in New York and one of the organizers of the SLAC workshop, thinks that the boson\u2019s \u201csomewhat unexpected\u201d properties make a confirmation unlikely. But he welcomes the tests. \u201cIt would be crazy not to do another experiment to check this result,\u201d he says. \u201cNature has surprised us before!\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Dark matter may feel a \"dark force\" that the rest of the Universe does not 2015-Apr-20 \n                 \n                   Bouncing neutrons probe dark energy on a table-top 2014-Apr-18 \n                 \n                   Physicists hunt for dark forces 2012-Apr-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19971", "url": "https://www.nature.com/articles/nature.2016.19971", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "A molecule made by trees can seed clouds, suggesting that pre-industrial skies were less sunny than thought. Molecules released by trees can seed clouds, two experiments have revealed. The findings, published on 25 May in  Nature 1 , 2  and  Science 3 , run contrary to an assumption that the pollutant sulphuric acid is required for a certain type of cloud formation \u2014 and suggest that climate predictions may have underestimated the role that clouds had in shaping the pre-industrial climate. If the results of the experiments hold up, predictions of future climate change should take them into account, says Reto Knutti, a climate modeller at the Swiss Federal Institute of Technology (ETH Zurich). For 20 or more years, clouds have been the largest source of uncertainty in understanding how manmade emissions affect the atmosphere, he says. In addition to releasing carbon dioxide, burning fossil fuels indirectly produces sulphuric acid, which is known to seed clouds. So, climate scientists have assumed that since pre-industrial times, there has been a large increase in cloud cover, which is thought to have an overall cooling effect by reflecting sunlight back into space. And they have assumed that this overall cooling effect has partially masked the climate\u2019s underlying sensitivity to rising carbon dioxide levels. The latest experiments suggest that it may have been cloudier in pre-industrial times than previously thought. If this is so, then the masking effect, and in turn the warming effects of carbon dioxide, might have been overestimated, says Jasper Kirkby, a physicist at the CERN, Europe\u2019s particle-physics laboratory near Geneva, Switzerland, who led one of the experiments. But Kirkby adds that it is too early to say whether this is true in practice, or by how much, because there are so many factors that play into such projections. \u201cThere are many uncertainties; we are only talking about one,\u201d says Kirkby. Knutti says the results will probably not affect  the most likely projections of warming , as laid out by the Intergovernmental Panel on Climate Change. \u201cOur best estimate is probably still the same,\" he says. \n             Aerosols needed \n           Clouds are made of microscopic droplets of liquid water or, in some cases, of small ice crystals. But in the atmosphere, water vapour cannot simply turn into a cloud: it needs solid or liquid particles, known as aerosols, on which to condense. About half of these aerosols originate, already in solid form, from Earth\u2019s surface: for instance, dust from deserts, salt crystals from the oceans or soot from combustion. The other half forms anew in the atmosphere from gaseous impurities. The individual gas molecules capture more molecules from the air to form solid particles. If they grow to 50\u2013100 nanometres, water vapour can condense on them. Until recently, atmospheric scientists thought that only sulphuric acid vapour, which can be produced by volcanic emissions or by burning fossil fuels, could trigger this process. As a result, it was thought that pre-industrial skies were somewhat less cloudy than present ones because they contained less of this pollutant, says Kirkby. To investigate the process, he turned to the Cosmics Leaving Outdoor Droplets (CLOUD) experiment, which he founded. A three-metre tall stainless steel tank that can reproduce a vast range of atmospheric conditions, CLOUD can be hooked up to the beams of particles that feed the Large Hadron Collider (LHC) at CERN. This simulates the effects of cosmic rays \u2014 high-energy subatomic particles that come from outside the Solar System and are thought to have  a role in cloud formation  \u2014 in the atmosphere.  \n             Cosmic-ray starter kit \n           In the two  Nature  papers 1 , 2 , Kirkby and his co-authors report that aerosols can form and grow to the size needed to seed a cloud from compounds emitted by trees \u2014 without any sulphuric acid and accelerated by simulated cosmic rays. In these experiments, the team used \u03b1-pinene, a molecule that helps to give fir forests their characteristic smell, but compounds from other types of vegetation might show a similar effect, the scientists say. In the third paper, published in  Science 3 , a team that includes some of Kirkby\u2019s co-authors reported a similar finding using a different experiment. Federico Bianchi, a chemist now at the University of Helsinki, and his collaborators measured the composition of air and monitored the weather at the Jungfraujoch Research Station in the Swiss Alps at around 3,500 metres in altitude. They found that molecules similar to \u03b1-pinene that could also originate from vegetation can seed clouds without much sulphuric acid. In addition to feeding into climate predictions, the findings have another potential implication, says atmospheric scientist Bjorn Stevens of the Max Planck Institute for Meteorology in Hamburg, Germany. Some scientists have warned that measures such as scrubbing sulphur dioxide from coal-plant emissions could remove some of the beneficial cooling effect of clouds and boost global warming, but this may now be less of a concern because trees can seed clouds too. \u201cWhat it means is, we don\u2019t have to fear clean air,\u201d says Stevens. It is also interesting to speculate whether trees emit these compounds in part because there is a benefit to them in making their own climate, Kirkby says. \u201cThis really does touch on the Gaia hypothesis,\u201d he says, referring to the theory that Earth\u2019s life behaves as a single organism that tends to preserve itself.  \u201c It\u2019s a beautiful mechanism for trees to control their environment.\u201d See the  related News & Views . Reprints and Permissions"},
{"file_id": "533446a", "url": "https://www.nature.com/articles/533446a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Space agencies envisage system of probes to track whether countries are achieving emissions goals. Today just two satellites monitor Earth\u2019s greenhouse-gas emissions from space. But if the world\u2019s leading space agencies have their way, a flotilla of such probes could be launched beginning in 2030. The ambitious effort would help climate scientists to improve their forecasts \u2014 and it could also help to verify whether  countries are upholding their commitments  to reduce greenhouse-gas emissions. But researchers will need to clear a daunting array of political and technical hurdles if they are to get the system \u2014 estimated to cost several\u00a0billion dollars \u2014 off the ground. Competition for satellite launch slots is stiff: last year, for instance, the European Space Agency shelved plans for  an advanced carbon-dioxide-monitoring probe  in favour of a mission to measure plant growth. And scientists must still prove that satellite measurements of gases such as CO 2  and methane can match the accuracy of data from observatories on Earth. \u201cWe have a small fleet of satellites that are being launched, but these are all just scientific experiments,\u201d says David Crisp, science team leader for NASA\u2019s Orbiting Carbon Observatory-2 (OCO-2). \u201cWhat we are trying to do now is just figure out how to monitor greenhouse gases from space.\u201d Scientists have access to data from a pair of pioneering satellites: OCO-2,  which launched in 2014  and measures CO 2 , and Japan\u2019s Greenhouse Gases Observing Satellite (GOSAT), which launched in 2009 and tracks CO 2  and methane. NASA and the Japan Aerospace Exploration Agency are working to calibrate the instruments against each other and with a network of ground-based monitoring stations. Both probes have a margin of error of about 0.5%, Crisp says. His team wants to reduce that to just 0.25% for the OCO-2 measurements. Meanwhile, nations are queuing up a new suite of satellites to lay the foundations for a larger monitoring effort (see \u2018Counting carbon\u2019). China will launch a pair of CO 2 -monitoring satellites this year, and Japan plans to send up GOSAT-2 in 2018. NASA is looking ahead to OCO-3, which could launch as early as 2018. Unlike its predecessor, OCO-3 will not be a free-flying satellite, but a spectrometer built from OCO-2\u2019s spare parts that will be installed  on the International Space Station . Crisp says that NASA scientists know how to build an instrument that is 20 times more powerful than OCO-2\u2019s spectrometer, but that the agency does not have the funds to construct and launch it. \u201cI can\u2019t even compete for the money,\u201d he says, \u201cbecause it doesn\u2019t exist.\u201d At present, NASA is developing a satellite called ASCENDS that would use a laser to measure CO 2 ; unlike OCO-2, it would be able to track the gas at night and during winter at high latitudes. \n               Sharper vision \n             Together, these satellites will extend a continuous record of CO 2  measurements that began in 2002 with SCIAMACHY, a spectrometer on the European Space Agency\u2019s Envisat probe. The world\u2019s space agencies want to transform this ad hoc system into a coordinated fleet of about six\u00a0probes by 2030. More than 60 agencies collaborated on a declaration finalized on 16\u00a0May that sets out a broad vision to develop and implement new monitoring technologies and to share the resulting data. France kick-started the effort last year, before December\u2019s United Nations climate summit in Paris. At that meeting, nations adopted an agreement to curb heat-trapping emissions that also commits them to  develop ways to verify  whether they are meeting their climate goals. The nascent satellite programme could help nations to fulfil that requirement. \u201cIt\u2019s very general, but it\u2019s a beginning,\u201d says Jean-Yves Le Gall, the head of the French space agency, CNES. He says that the group is discussing how to distribute and use data from the system before its meeting in Mexico in September. The space agencies\u2019 efforts are a welcome surprise to many researchers. \u201cI think it\u2019s very important,\u201d says Heinrich Bovensmann, a remote-sensing specialist at the University of Bremen in Germany. \u201cNow we have to see what really comes out of it.\u201d  We\u2019ve got training wheels on for the next decade.  The current generation of satellites measure how much CO 2  is in a given column of air. But what scientists and governments really want to know is where that CO 2  came from. To pinpoint emissions produced by industrial activity, researchers must also determine how much CO 2  is absorbed and released by land and ocean ecosystems. This requires combining atmospheric CO 2  measurements with accurate information about how the natural environment takes up and releases the gas, and plugging the data into detailed air-current models that can trace where the CO 2  probably came from. In essence, the task requires developing something akin to current weather forecast systems \u2014 but run in reverse. Achieving the precision needed to verify whether nations are meeting their emissions goals is a tall order, says Stephen Pacala, a climate researcher at Princeton University in New Jersey who led a 2010 report on space-based carbon monitoring for the US National Academies of Sciences, Engineering, and Medicine. He says that satellites would need to be more accurate than current greenhouse-gas inventories, which are calculated using a variety of data on fossil-fuel consumption and economic and land-use trends. But Crisp and his colleagues remain confident that they can deliver greenhouse-gas data that will be useful for both scientists and policy\u00admakers. \u201cWe\u2019ve got training wheels on for the next decade,\u201d he says. \u201cOnce we learn how to ride, we\u2019ll build a bicycle.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @jefftollef \n               \n                     Climate change: Track urban emissions on a human scale 2015-Sep-07 \n                   \n                     The hunt for the world\u2019s missing carbon 2015-Jun-30 \n                   \n                     Satellite maps global carbon dioxide levels 2014-Dec-18 \n                   \n                     Space budget blow to climate science 2012-Nov-27 \n                   \n                     Mourning Glory 2011-Mar-07 \n                   \n                     NASA satellite crashes to Earth 2011-Mar-04 \n                   \n                     OCO-2 \n                   \n                     GOSAT \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19976", "url": "https://www.nature.com/articles/nature.2016.19976", "year": 2016, "authors": [{"name": "Michele Catanzaro"}], "parsed_as_year": "2006_or_before", "body": "Omid Kokabee has been granted temporary medical leave after having a kidney removed. Omid Kokabee, a former physics PhD student who has been in prison for more than five years in Iran, has been granted a brief medical leave on bail to recover from kidney-cancer surgery, sources close to the situation tell  Nature . The 33-year-old left a hospital in Tehran on 25 May \u2014 where he has been recovering from the surgery since 20 April \u2014 and is expected to be allowed to stay out of prison for one to three months after his friends posted a bail of 5 billion Iranian rials (US$165,000). Officially, the medical leave must be renewed every two weeks, but Kokabee\u2019s contacts hope to have the leave extended further, by appealing to an article of Iran\u2019s penal code that permits the postponement of a jail sentence that may harm a prisoner\u2019s health. The doctoral student, who has studied laser physics in Spain and the United States, was arrested in Iran in 2011 while visiting family, and was  sentenced to ten years in prison  for \u201ccollaboration with a hostile government\u201d and \u201cillegal enrichment\u201d. The young scientist and his supporters  say that he was sentenced for refusing to cooperate with Iran\u2019s nuclear programme . Numerous appeals  have been made for Kokabee\u2019s release by human rights organizations and scientific societies \u2014 including a letter signed by 31 Nobel physics laureates. In 2014, Iran's supreme court granted Kokabee a retrial, but another court upheld the sentence in 2015. \n             Declining health \n           Last year, both the American Physical Society and the American Association for the Advancement of Science  requested Kokabee\u2019s release  on humanitarian grounds, noting that the doctoral student had become increasingly ill during his incarceration. Both societies have given Kokabee human-rights awards. The Scholars at Risk Network, a human-rights group in New York City, had raised the alarm about Kokabee\u2019s deteriorating health, including kidney stones and stomach pain, as early as December 2012. But it was only in November 2015 that Kokabee was transferred to hospital for treatment, and \u2014 during a second visit to hospital \u2014 a sonogram revealed a cancer in his right kidney. In April, the kidney was removed. Kokabee\u2019s contacts say that if he had received the sonogram years earlier, his health might not have declined to the point that the total removal of the kidney was needed. Other human-rights groups and North American academics have also suggested that a lack of proper medical treatment has exacerbated Kokabee\u2019s ill health.\u00a0 Also concerning are the conditions that await Kokabee if he returns to prison, sources with knowledge of the situation say. Since September 2014, they told  Nature , he has been held in a windowless, bedbug-plagued quarantine ward with other political prisoners and deprived of opportunities for sport or physical activity. Many of the prisoners are reported to have physical health problems or be suffering from depression. \n               Tweet \n               Follow @NatureNews \n             \n                   Iranian says he was jailed for refusing to engage in military research 2013-Apr-26 \n                 \n                   Scientists protest against prison sentence for Iranian student 2012-Jun-11 \n                 \n                   Iranian physicist sentenced to prison 2012-May-15 \n                 \n                   Nobel laureates call for release of Iranian physicist \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19994", "url": "https://www.nature.com/articles/nature.2016.19994", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}, {"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "The Department of Energy says the US should fund ITER until 2018, and then re-evaluate its progress. The troubled multibillion-euro nuclear-fusion project ITER has improved its performance and management, and the United States should continue to support the experiment at least until 2018, the US Department of Energy (DOE) said in a report to Congress released on 26 May. After that, the agency said, the country should re-evaluate its position.\u00a0 ITER is an unprecedented collaboration between the European Union, China, India, Japan, South Korea, Russia and the United States. Its ambitious goal is to show that fusing hydrogen nuclei to make helium \u2014 the same process that heats up the Sun and powers hydrogen bombs \u2014 is a technologically feasible way to produce electricity. The experiment is under construction at a site in St-Paul-lez-Durance in southern France, but the work is more than a decade behind schedule, and its costs have spiralled far above the original budget.  In its report , the DOE acknowledges ITER\u2019s immense scientific potential, and the substantial improvements in the project\u2019s management and performance since  current director-general Bernard Bigot took over in March 2015 . \u201cITER remains the best candidate today to demonstrate sustained burning plasma, which is a necessary precursor to demonstrating fusion energy power,\u201d US energy secretary Ernest Moniz writes in the report\u2019s introduction. But the DOE also notes that it will take more time to determine whether ITER will ultimately succeed. The agency says that the project\u2019s promising improvements \u201cmust be balanced against several years of inadequate performance\u201d. Its recommendation to continue US funding is contingent \u201con continued and sustained progress on the project, increased transparency of the ITER project risk management process, as well as a suite of management reforms proposed in this report that we expect will be agreed upon by the ITER Council\u201d, according to Moniz\u2019s introduction. \u201cI think it\u2019s an outstanding report that says all of the right things,\u201d says William Madia, a former director of Oak Ridge National Laboratory in Tennessee who led  an independent review of ITER in 2013 . That report excoriated the way in which ITER was run, and proposed reforms to save the project from failure \u2014 recommendations that ITER\u2019s governing council embraced. Madia says that the DOE is appropriately encouraged by recent management changes, and appropriately cautious about whether the project is actually back on track. \u201cBernard is doing a terrific job, but my goodness, he\u2019s got a lot of work to do,\u201d he says. Bigot acknowledges as much, and says that the DOE\u2019s conclusions are as much as he could have hoped for at this point. \u201cWe passed this important milestone, but we know there is still a long way to go,\u201d he says. \n               Crucial expertise \n             The DOE is a major funder of fusion research, but it is Congress that holds the purse strings. Although the United States is bound by an international treaty to provide its share of ITER\u2019s costs \u2014 a relatively small 9% of the project\u2019s budget \u2014 it cannot meet its contributions if Congress does not approve them. The report\u2019s recommendations have already provoked scepticism on Capitol Hill. Senator Dianne Feinstein of California, the highest-ranking Democrat on the Senate panel that oversees DOE spending, says that the United States cannot afford to keep pace with ITER\u2019s growing budget. The DOE estimates that the country\u2019s current annual contribution to ITER, US$115 million, will more than double by 2018. \u201cThe cost of ITER has grown too large and the timeframe for completion is too long,\u201d Feinstein said in a statement. \u201cIt\u2019s time to wind down our role.\u201d Last year, the Senate proposed to end support for ITER, but backed down during final budget negotiations with the House of Representatives. This year, it is not clear that ITER will win a reprieve. On 12 May, the Senate approved an energy-funding bill for fiscal year 2017 that cut all spending on ITER in favour of higher-priority projects. And on 26 May, the House rejected its own  2017 energy-spending bill , which included money for ITER. If the United States were to pull out, ITER would probably survive, says Mark Koepke, a plasma physicist at West Virginia University in Morgantown, who  leads a government advisory panel on fusion research . But at hearings in April, Bigot told US lawmakers that the country\u2019s fusion experts provide expertise that would be difficult to replace. Madia says that it\u2019s impossible to predict how ITER would be affected by a US exit. \u201cIt makes good cocktail conversation, but no one knows what would actually happen,\u201d he says. \n               Tokamak test \n             The ITER project began in 2007, with the treaty signed by its international members came into force. Its approach to fusion is to trap heavy isotopes of hydrogen in a doughnut-shaped vacuum vessel known as a tokamak and heat them up to 150 million \u00b0C. This should force their nuclei to fuse into helium, releasing vast amounts of energy. Tokamaks have existed around the world for decades, but ITER would be the first to release substantially more energy than was put into the hydrogen plasma. It is predicted to produce about 500 megawatts of electricity. The project was originally due to be completed in 10 years for \u20ac5 billion (US$5.6 billion), but it has been plagued by a series of delays. The latest DOE report comes against a backdrop of criticism directed at ITER\u2019s former management, and some subsequent progress towards improvement. Observers say that under previous director-general Osamu Motojima, who was in office from 2010 to 2015, the experiment was in denial about slipping deadlines and witnessed a drop in staff morale. After the independent review by Madia, the ITER Council accelerated the transition to a new director-general,  nominating Bigot , a French nuclear physicist with extensive management experience, in late 2014. By November 2015, Bigot\u2019s team had presented a revised timetable for the project, and estimated that it would cost an extra \u20ac4.6 billion to bring it to completion. The team said that the earliest possible date for getting hydrogen plasma to run inside the machine was 2025, and that it would take several years after that for the project to inject the heavier hydrogen isotopes tritium and deuterium, and achieve fusion. \n               Rigorous schedule \n             In April, an external review from the ITER Council Working Group confirmed that progress had been made on implementing the recommendations of the Madia report, and that the new management had been realistic about the earliest possible date for plasma. \u201cOne of the things we came away with is that the schedule that has been prepared by the ITER team is very rigorous,\u201d says group member Steven Cowley, head of the UK Atomic Energy Authority. But the reviewers also pointed out that the estimates of costs and completion date did not take into account possible contingencies. Keeping to this plan would require ITER's members to increase their contributions. So Bigot\u2019s team also proposed a more modest plan, which focuses on achieving first plasma on time but delays fusion. This should save money by postponing the parts of construction that are not needed for first plasma, but no one has yet calculated how much. \u201cThis is the most complicated piece of engineering anybody has ever attempted, ever,\u201d says Cowley. \u201cAnybody who thought this project was going to be easy and was going to sail through has never seen a big project.\u201d The latest DOE report recommends funding the cost increases cited by Bigot, but remains sceptical about the schedule. It outlines two funding scenarios: one based on achieving first plasma in 2025, and a more realistic scenario that pushes the date back to 2028. Bigot insists that the 2025 deadline is technically achievable, and says that partner countries should do everything they can to meet that deadline. \u201cIf we are successful, it will be a real breakthrough for the energy supply of the world,\u201d he says. \u201cWe are fully committed to deliver.\u201d \n                     Nuclear physics: Pull together for fusion 2015-Jun-09 \n                   \n                     ITER's new chief will shake up troubled fusion reactor 2014-Nov-21 \n                   \n                     US plans for future of fusion research 2014-Sep-22 \n                   \n                     Five-year delay would spell end of ITER 2014-Jul-31 \n                   \n                     ITER keeps eye on prize 2013-Oct-15 \n                   \n                     Fusion project struggles to put the pieces together 2012-Oct-26 \n                   \n                     US fusion in budget vice 2012-Jul-24 \n                   \n                     Energy Department report to Congress \n                   \n                     ITER \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19990", "url": "https://www.nature.com/articles/nature.2016.19990", "year": 2016, "authors": [{"name": "Evelyn  Lamb"}], "parsed_as_year": "2006_or_before", "body": "A computer cracks the Boolean Pythagorean triples problem \u2014 but is it really maths? Three computer scientists have announced the largest-ever mathematics proof: a file that comes in at a whopping 200\u00a0terabytes 1 , roughly equivalent to all the digitized text held by the US Library of Congress. The researchers have created a 68-gigabyte compressed version of their solution \u2014 which would allow anyone with about 30,000 hours of spare processor time to download, reconstruct and verify it \u2014 but a human could never hope to read through it. Computer-assisted proofs too large to be directly verifiable by humans have become commonplace, and mathematicians are familiar with computers that solve problems in combinatorics \u2014 the study of finite discrete structures \u2014 by checking through umpteen individual cases. Still, \u201c200 terabytes is unbelievable\u201d, says Ronald Graham, a mathematician at the University of California, San Diego. The previous record-holder is thought to be a 13-gigabyte proof 2 , published in 2014. The puzzle that required the 200-terabyte proof, called the Boolean Pythagorean triples problem, has eluded mathematicians for decades. In the 1980s, Graham offered a prize of US$100 for anyone who could solve it. (He duly presented the cheque to one of the three computer scientists, Marijn Heule of the University of Texas at Austin, earlier this month.) The problem asks whether it is possible to colour each positive integer either red or blue, so that no trio of integers  a ,  b  and  c  that satisfy Pythagoras\u2019 famous equation  a 2 \u00a0+\u00a0 b 2 \u00a0=\u00a0 c 2  are all the same colour. For example, for the Pythagorean triple 3, 4 and 5, if 3 and 5 were coloured blue, 4 would have to be red. In a paper  posted on the arXiv server  on 3 May, Heule, Oliver Kullmann of Swansea University, UK, and Victor Marek of the University of Kentucky in Lexington have now shown that there are many allowable ways to colour the integers up to 7,824 \u2014 but when you reach 7,825, it is impossible for every Pythagorean triple to be multicoloured 1 . There are more than 10 2,300  ways to colour the integers up to 7,825, but the researchers took advantage of symmetries and several techniques from number theory to reduce the total number of possibilities that the computer had to check to just under 1 trillion. It took the team about 2 days running 800 processors in parallel on the University of Texas\u2019s Stampede supercomputer to zip through all the possibilities. The researchers then verified the proof using another computer program. \n               Facts vs theory \n             The Pythagorean triples problem is one of many similar questions in Ramsey theory, an area of mathematics that is concerned with finding structures that must appear in sufficiently large sets. For example, the researchers think that if the problem had allowed three colours, rather than two, they would still hit a point where it would be impossible to avoid creating a Pythagorean triple where  a ,  b  and  c  were all the same colour; indeed, they conjecture that this is the case for any finite choice of colours. Any proof for more colours will probably be much larger even than the 200-terabyte 2-colour proof, unless researchers can simplify the case-by-case checking process with a breakthrough in understanding. Although the computer solution has cracked the Boolean Pythagorean triples problem, it hasn\u2019t provided an underlying reason why the colouring is impossible, or explored whether the number 7,825 is meaningful, says Kullmann. That echoes a common philosophical objection to the value of computer-assisted proofs: they may be correct, but are they really mathematics? If mathematicians\u2019 work is understood to be a quest to increase human understanding of mathematics, rather than to accumulate an ever-larger collection of facts, a solution that rests on theory seems superior to a computer ticking off possibilities. That did ultimately occur in the case of the 13-gigabyte proof from 2014, which solved a special case of a question called the Erd\u0151s discrepancy problem. A year later, mathematician Terence Tao of the University of California, Los Angeles,  solved the general problem  the old-fashioned way 3  \u2014 a much more satisfying resolution. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Graph-theory breakthrough tantalizes mathematicians 2015-Nov-19 \n                   \n                     Maths whizz solves a master\u2019s riddle 2015-Sep-25 \n                   Reprints and Permissions"},
{"file_id": "534013a", "url": "https://www.nature.com/articles/534013a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Satellites and research aeroplanes could offer a better, broader view of coral health. Eric Hochberg has studied coral reefs for two decades, but the marine ecologist is about to see them in a fresh light. Beginning on 6\u00a0June, Hochberg and his colleagues will use a specially outfitted NASA aeroplane to map the spectra of sunlight reflecting off reefs spread across the Pacific Ocean far below. The scientists aim to tease out the spectral signatures of coral, algae and sand\u00a0\u2014 and to check the health of the reefs. The three-year, US$15-million Coral Reef Airborne Laboratory (CORAL) project will be the biggest and most detailed study yet of entire reefs, rather than just the small patches that scuba divers can reach. CORAL is part of a growing push to map reefs faster, and in more detail, than ever before. Marine scientists are putting new instruments onto planes, satellites and even drones to gain a broader perspective on how well corals are doing \u2014 or not. After its surveys in Hawaii, Australia\u2019s Great Barrier Reef, the Mariana Islands and Palau (see \u2018Under the sea\u2019), CORAL will have mapped about 3\u20134% of the world\u2019s reef area, hundreds of times more than previous scuba surveys. Warming ocean waters have led to massive coral-bleaching events such as the one  now devastating the Great Barrier Reef . The CORAL scientists hope to learn how individual reefs  respond to such threats . \u201cWe want to start looking at things at the ecosystem scale, which is really hard to do in the water,\u201d says Hochberg, at the Bermuda Institute of Ocean Sciences in St George\u2019s. Remote sensing of coral reefs is hard because the oceans reflect so much less light than the land, says Heidi Dierssen, a marine ecologist at the University of Connecticut Avery Point in Groton, who is part of the CORAL team. And scientists have to do elaborate calculations to correct for the distortion of light on its journey through the atmosphere and through water \u2014 a bright, deep ocean bottom and a dark, shallow bottom can both look the same to a remote-sensing camera. Teasing out such distinctions requires scanning an area using as many wavelength bands as possible. \u201cWhen you have the full spectrum, you can say so much more about what is there,\u201d Dierssen says. One of the latest views from above comes from  the Sentinel-2 satellite , launched by the European Space Agency in June 2015. Although the satellite was not designed to study reefs, it has relatively sharp vision and can operate over more and narrower spectral bands than the US Geological Survey\u2019s Landsat-8 satellite, another workhorse of Earth observing. And unlike data from keen-eyed commercial satellites, Sentinel\u2019s observations are free to use. Sentinel-2 will also eventually revisit the same spot every 5\u00a0days, compared with Landsat-8\u2019s 16-day return period. That makes it a better choice for studying short-term marine phenomena such as coral bleaching and algal blooms, says John Hedley, a remote-sensing expert at Environmental Computer Science in Tiverton, UK, who is on the science team for the Sentinel-2 coral study, Sen2Coral. Team members are set to report early results on mapping reef bottoms at a coral-reef symposium in Honolulu, Hawaii, on 22\u00a0June. But in the wavelength range applicable to underwater sensing \u2014 430\u2013710 nanometres \u2014 Sentinel-2 cannot capture details that CORAL\u2019s plane can. The plane carries an instrument that gathers data in more than 100 narrow spectral bands in that range, including the signature of photosynthetic organisms within the living coral itself at 570\u2013575\u00a0nanometres. CORAL will focus on one simple metric: how much coral cover there is on a given reef, as opposed to algae and sand. From that, researchers can calculate how well the coral is doing at transforming sunlight into energy to maintain a reef structure. Hochberg and his colleagues hope to use that information to better understand how local changes, such as an increase in pollution, might affect coral\u2019s health. The June flights in Hawaii will test whether all the equipment is working. From there, the Gulfstream IV plane will go to the Great Barrier Reef in September and October, followed by Hawaii, the Mariana Islands and Palau in 2017. Divers will simultaneously measure the optical properties of the surrounding seawater and the reef condition up close, to cross-check what the plane sees from 8,500\u00a0metres above. The flights will provide a snapshot of some of the world\u2019s most important reefs, says Serge Andr\u00e9fou\u00ebt, a marine ecologist at the Research Institute for Development (IRD) in Noum\u00e9a, New Caledonia, who led an earlier coral-mapping effort with the Landsat-7 satellite. But CORAL will be a one-time glimpse only. With limited funding, there are no plans to repeat any flights to see  how the reefs change over time , Hochberg says. Instead, the team hopes to provide a rich set of baseline data for future coral studies. \u201cYou have to pick and choose where you go to try to understand how the ecosystem is working,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alexwitze \n               \n                     Coral crisis: Great Barrier Reef bleaching is \u201cthe worst we\u2019ve ever seen\u201d 2016-Apr-13 \n                   \n                     Landmark experiment confirms ocean acidification\u2019s toll on Great Barrier Reef 2016-Feb-24 \n                   \n                     Corals worldwide hit by bleaching 2015-Oct-08 \n                   \n                     Radiant reefs found deep in the Red Sea 2015-Jun-24 \n                   \n                     Climate-change adaptation: Designer reefs 2014-Apr-23 \n                   \n                     Why some corals can take the heat 2013-Jan-07 \n                   \n                     CORAL project \n                   \n                     Sen2Coral project \n                   \n                     International Society for Reef Studies \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19999", "url": "https://www.nature.com/articles/nature.2016.19999", "year": 2016, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "Gold-mining boom in southeastern Amazon is driving high levels of mercury contamination. Long-running concerns about the environmental effects of gold-mining in the Peruvian Amazon came to a head last week. Peru\u2019s government declared a 60-day public-health emergency on 23 May in an attempt to address the problem of mercury pollution caused by unregulated gold-mining along the Madre de Dios River. Health-care and emergency workers will this week begin providing medical and food aid for 25 affected villages, after a flurry of studies showed high levels of mercury in people, fish and sediments in the Madre de Dios region. The government estimates that some 48,000 people across 85,301 square kilometres have been affected.  \u201cWe now know with certainty what the source of the exposure is,\u201d says Peru\u2019s deputy health minister, Percy Minaya. \u201cWe are not going to solve this in two months, or even in a year, but the Health Ministry has to start.\u201d Symptoms of mercury poisoning include vomiting and diarrhoea. Extreme cases can lead to brain or kidney damage. The Madre de Dios region has  a long history of small-scale alluvial gold-mining , but the rise in international gold prices in the past decade has brought a boom in the activity. Peru\u2019s National Institute of Statistics and Information in Lima reported on 23 May that gold production for March in Madre de Dios was 1,583 kilograms, up 28% from the same month last year. The region\u2019s miners extract the gold by sluicing sediment to separate gold-bearing sand, which they then mix with mercury to form an amalgamated lump of metal. Heating the lump vaporizes the mercury, leaving pure gold behind. The process sends an estimated 30\u201340 tonnes of mercury each year into waterways, where  bacteria convert the metal into methylmercury . The methylmercury accumulates in fish, which are a key source of food for people in the Madre de Dios region. \n               Body burden \n             Perhaps unsurprisingly, researchers at Duke University in Durham, North Carolina, found high levels of mercury (above the maximum recommended by the World Health Organization) in hair samples from 40% of the Madre de Dios residents that they tested. The Duke team has examined about 800 people living  along a major highway in the region , 100 people living beside the river and 2,000 in the Amarakaeri Indigenous Reserve. Some communities in the region are closer to the gold-mining activities than others, but the 40% exposure rate held across the highway, river and reserve, says study leader William Pan, an epidemiologist with Duke\u2019s Global Health Initiative. The presence of mercury in human hair generally indicates that a person has been exposed to the metal through a dietary source. Pan says that the Duke studies in Madre de Dios show a strong correlation between human mercury exposure and fish consumption. Since 2009, studies by Pan\u2019s group 1 ,  and by tropical ecologist Luis Fernandez  at the Carnegie Institution for Science at Stanford University in California, have found high mercury levels in some species of fish, particularly large catfish and in fish that eat other fish. Peru\u2019s government used the Duke team\u2019s latest study to determine which riverside communities should receive the emergency aid. Officials are trying to help affected residents to replace the high-risk fish in their diets with other sources of protein. During the emergency period, the government will give food, including canned ocean fish, and multivitamins to combat anaemia, to roughly 15,000 of the 48,000 people affected. \n               Routes of exposure \n             Pan says that these steps should reduce the body burden of mercury in people who also cut their consumption of contaminated fish, because the primary route of mercury exposure in the region seems to be through food. The government is also considering whether its food aid should include supplies of the grain quinoa. Preliminary data from Duke's household surveys in the Madre de Dios region shows a correlation between quinoa consumption and lower mercury levels. Minaya says that the government\u2019s long-term plan also includes helping communities to establish fish farms.\u00a0However, the 60-day emergency period is set to end days before a new president \u2014 who will be elected on 5 June \u2014 takes office on 28 July. But Minaya is confident that the next administration will continue to monitor and address the mercury pollution problem, despite opposition from regional and local government officials. They have criticized the emergency decree, arguing that the link between high mercury levels in people and fish consumption in the Madre de Dios region has not been proved. These officials are also worried that the government\u2019s decision to declare a public-health emergency could harm tourism in the nearby Man\u00fa National Park and Tambopata National Reserve. Because of the growing concerns about mercury exposure, Fernandez is leading a project at Wake Forest University in Winston-Salem, North Carolina, to study the metal\u2019s effects on human and environmental health in the Amazon. As director of the Center for Amazonian Scientific Innovation at Wake Forest, Fernandez will lead a team of US researchers who are collaborating with colleagues at the Peruvian Amazon Research Institute and the National Amazonian University of Madre de Dios.  \n                     Deforestation: Carving up the Amazon 2014-May-21 \n                   \n                     Tough talk over mercury treaty 2013-Jan-09 \n                   \n                     Peru battles the golden curse of Madre de Dios 2012-Jun-20 \n                   \n                     Peru to boost science-industry links 2012-Jan-12 \n                   \n                     Scientists hopeful over election of new Peruvian president 2011-Jun-07 \n                   \n                     William Pan \n                   \n                     Luis Fernandez \n                   Reprints and Permissions"},
{"file_id": "534015a", "url": "https://www.nature.com/articles/534015a", "year": 2016, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Launch in July will test new way to explore the Solar System \u2014 and beyond. On 6 July, if all goes to plan, a pack of about 100 sticky-note-sized \u2018chipsats\u2019 will be launched up to the International Space Station for a landmark deployment. During a brief few days of testing, the minuscule satellites will transmit data on their energy load and orientation before they drift out of orbit and burn up in Earth\u2019s atmosphere. The chipsats, flat squares that measure just 3.2\u00a0centimetres to a side and weigh about 5\u00a0grams apiece, were designed for a PhD project. Yet their upcoming test in space is a baby step for the much-publicized Breakthrough Starshot mission, an effort led by billionaire Yuri Milner to send tiny probes on an interstellar voyage. \u201cWe\u2019re extremely excited,\u201d says Brett Streetman, an aerospace engineer at the non-profit Charles Stark Draper Laboratory in Cambridge, Massachusetts, who has investigated the feasibility of sending chipsats to Jupiter\u2019s moon Europa. \u201cThis will give flight heritage to the chipsat platform and prove to people that they\u2019re a real thing with real potential.\u201d The probes are the most diminutive members of a growing family of small satellites. Since 2003, researchers have launched hundreds of 10-centimetre-sided CubeSats \u2014 more than 120 last year alone. Engineer Jekan Thanga at Arizona State University in Tempe is now working on an even smaller \u2018femto\u00adsatellite\u2019, a 3-centimetre cube that he says has the technological capacity of the first CubeSats. Chipsats, which are smaller and cheaper still, are seen as disposable sensors that could be sent on suicide missions to explore hostile environments, such as Saturn\u2019s rings. \u201cThey\u2019re all part of the toolbox for next-generation space missions,\u201d says Thanga. The upcoming chipsat test, called KickSat-2, is the second incarnation of a crowdfunded mission developed by researchers at Cornell University in Ithaca, New York. The shoebox-sized KickSat-1 spacecraft successfully launched on 18 April 2014, but it failed to deploy its cargo of 104 chipsats after a cosmic radiation burst reset the clock on its release mechanism. The craft fell out of orbit and burned up with the chipsats still in its hold. \u201cI was a little bummed out,\u201d says Zachary Manchester, an aerospace engineer who built the satellites as a doctoral student in aerospace engineering at Cornell. Fortunately, enough spare parts were lying around to make a second batch relatively quickly and easily. The chipsats, called Sprites, carry little more than a pair of 60-milliamp solar cells, a radio and an antenna. The KickSat-2 payload includes some newer Sprites that can \u2018sail\u2019 by tilting towards or away from the Sun. A current is run through a coil, turning the chip into a compass needle that aligns with Earth\u2019s magnetic field, allowing the chipsat to control its orientation. The probes can be reprogrammed on the fly from the space station. Sprite prototypes have already proved that they can survive the rigours of space. In 2011, three chipsats were attached to the outside of the space station. They were still working when scientists retrieved them in 2014. That commercial electronics are good enough to survive space\u2019s vacuum and extreme temperatures is a \u201cpretty big deal\u201d, says Mason Peck, an aerospace engineer who leads Cornell\u2019s chipsat team. But on a flight into deep space, chipsat electronics would face a high risk of damage from radiation. \u201cThere are some clear paths to radiation hardening, but it\u2019s expensive,\u201d says Peck. \u201cAnd that\u2019s not the point. You don\u2019t want to make an exquisite satellite. You just launch a million; if only 1% survive then that\u2019s fine. You put statistics on your side.\u201d There is plenty of science that Sprites can do closer to home. Peck says that the tiny satellites could be used to verify models of how small bits of debris behave in the upper atmosphere. Like feathers on Earth, the small, flat objects would be heavily affected by drag. \u201cWe\u2019re not very good at modelling that,\u201d says Peck. Another potential project would be to use Sprites to make a high-spatial-resolution map of Earth\u2019s magnetic field. \u201cThat would be really useful,\u201d agrees Jeffrey Love, a geophysicist with the US Geological Survey in Denver, Colorado, who studies Earth\u2019s magnetism. \u201cIdeally you\u2019d want to be measuring it everywhere all the time. This could be a step in that direction.\u201d For the long-term interstellar goal, chipsats will need much better laser-communication capacity. That should be possible, say Peck and Manchester, who are both on the Breakthrough Starshot advisory committee. \u201cWe have gone a long way towards proving we can have a functional tiny craft,\u201d says Peck. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Billionaire backs plan to send pint-sized starships beyond the Solar System 2016-Apr-13 \n                   \n                     Solar sail to hitch free ride on light breeze in 2016 2014-Jul-17 \n                   \n                     Mini satellites prove their scientific power 2014-Apr-16 \n                   \n                     Blog post: Chipsat pioneer named NASA\u2019s chief technologist \n                   \n                     KickSat specifications \n                   \n                     KickSat at Kickstarter \n                   \n                     Breakthrough Starshot \n                   Reprints and Permissions"},
{"file_id": "534014a", "url": "https://www.nature.com/articles/534014a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Biology's big funders announce investment will continue to 2022. When three of the world\u2019s biggest private biomedical funders launched the journal  eLife  in 2012, they wanted to shake up the way in which scientists published their top papers. The new journal would be unashamedly elitist, competing with biology\u2019s traditional \u2018big three\u2019,  Nature ,  Science  and  Cell , to publish the best work. But unlike these,  eLife  would use working scientists as editors, and it would be open access. And with backers providing \u00a318\u00a0million (US$26\u00a0million) over five years, authors wouldn\u2019t need to pay anything to publish there. Four years and more than 1,800 publications later,  eLife \u2019s funders \u2014 the Howard Hughes Medical Institute in Chevy Chase, Maryland, the Wellcome Trust in London and the Max Planck Society in Berlin \u2014  announced on 1\u00a0June  that they will continue their support. They will back the non-profit  eLife  organization with a further \u00a325\u00a0million between 2017 and 2022 (see \u2018 eLife  by the numbers\u2019). \u201c eLife \u2019s status in the field is rising quite quickly,\u201d says Sjors Scheres, a structural biologist at the Laboratory of Molecular Biology in Cambridge, UK. He became an editor at the journal in 2014, overseeing papers on electron microscopy. \u201cI liked the idea behind it \u2014 to make a high-impact journal completely driven by scientists, and open,\u201d he says. But although scientists like publishing in the journal, it\u2019s less clear whether it will drive wider transformation at the elite end of science publishing. \n               boxed-text \n             \n               Collaborative attraction \n             eLife  has gained high-profile converts. Palaeoanthropologist Lee Berger at the University of Witwatersrand in Johannesburg, South Africa, is used to publishing descriptions of the fossils he finds in  Science  and  Nature . But his team\u2019s latest find \u2014 more than 1,500 remains attributed to  a newly designated species  Homo naledi  \u2014 became  eLife \u2019s first palaeontology papers in September, and Berger hopes that more are on the way. \u201cOur next big discoveries are going to appear in  eLife  \u2014 if they\u2019re accepted by the referees,\u201d he says. \u201cIf not, we may submit them to  Nature  or  Science .\u201d Huda Zoghbi, a neuroscientist at Baylor College of Medicine in Houston Texas and an editor at  eLife , says that her postdocs \u2014 soon to be on the job market \u2014 still feel the need to publish in the big three journals. But she thinks that attitudes are changing. With some work, \u201cPeople ask me \u2018Why did you send it to  eLife ? You could have sent this to one of the top three journals\u2019,\u201d says Zoghbi. \u201cI told them  eLife  is a top journal.\u201d The journal\u2019s most innovative feature, according to its authors and reviewers, is its collaborative peer-review process. It turns conventional peer review \u2014 in which referees submit individual, and sometimes contradictory, reports \u2014 on its head. Instead, referees and scientist\u2013editors work together to identify a submitted paper\u2019s strengths and weaknesses and any needed revisions. Authors receive one decision letter, not individual reports from each referee. That makes for a speedy review: last year,  eLife \u2019s published papers took, on average, 116\u00a0days from submission to acceptance. For comparison,  Nature  and  Cell  take around 150\u00a0days, although  Science  says that in 2013 it took 99\u00a0days from submission to acceptance.  Cell  and two of its sister journals have experimented with a similar peer-review model but none has yet adopted it. Pete Binfield, the publisher of another open-access journal,  PeerJ , in San Francisco, California, says that he likes  eLife \u2019s peer-review system, but he thinks that the approach would be impossible to scale up to adopt for all published articles. \n               Selective but open \n             As it bids to become a top journal,  eLife  has started to turn down more of its submissions. The journal\u2019s acceptance rate dropped from 26% in 2014 to 15.4% by 2015, says its editor-in-chief Randy Schekman, a cell biologist at the University of California, Berkeley. That\u2019s approaching the acceptance rates of  Nature  and  Science , which are both below 10%. In 2013, Schekman denounced  Nature ,  Science  and  Cell  as \u201cluxury journals\u201d, and likened their low acceptance rates and high impact factors to high-end \u201cfashion designers\u201d that artificially stoke demand for their brand through scarcity. Now, he says,  eLife  has become \u201cmore selective than I had imagined, but it\u2019s not based on any instructions I have conveyed to the editors. It\u2019s based on their sensibility of important work.\u201d eLife \u2019s funders hoped to show that a highly selective, innovative journal could also be open access. When in 2014 the selective journal  Nature Communications , which is owned by  Nature \u2019s publisher, made all its articles open access, a spokesperson for the publisher cited  eLife \u2019s existence as an influence. But  eLife  has also demonstrated that such a model costs a lot of money. In 2014, the most recent year for which financial information is publicly available,  eLife  published 537\u00a0research articles with expenses of \u00a33.4\u00a0million \u2014 equating to around \u00a36,300 for each article. \u201cIt appears to be a very expensive way to innovate in the publishing space,\u201d says Binfield. The journal says that its per-article cost has dropped \u2014 to \u00a33,522 in 2015. It points out that it spends money on technology development, too; it has launched a series of open-source publishing tools to manage peer review and to display articles. Six publishers that use the third-party publishing platform HighWire have tested the  eLife -developed Lens display technology, but Binfield says he doesn\u2019t see people flocking to use  eLife \u2019s platforms. Schekman says that  eLife  plans to diversify its income by asking governments and other charities for funding. It will also eventually charge scientists to publish in the journal, although Schekman doubts that such income will ever cover all the organization\u2019s expenses. But it won\u2019t, he says, establish other open-access journals that accept more papers and have lower selectivity \u2014 a strategy that some organizations, such as the Public Library of Science, or PLoS, have demonstrated can shore up finances. \u201cWe have no interest in creating other lesser journals with lower standards,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n                 Follow @ewencallaway \n               \n                     Does it take too long to publish research? 2016-Feb-10 \n                   \n                     Crowdsourcing digs up an early human species 2015-Sep-10 \n                   \n                     Open access: The true cost of science publishing 2013-Mar-27 \n                   \n                     Blog post: Three major funders launch new open access journal, but why exactly? \n                   \n                     \n                         eLife \n                       \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20028", "url": "https://www.nature.com/articles/nature.2016.20028", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Some admire project's ambition; others say that it hasn't justified its aims. Proposals for a large public\u2013private initiative to synthesize an entire human genome from scratch \u2014 an effort that could take a decade and require billions of dollars in technological development \u2014 were formally unveiled on 2 June, almost a month after they were first aired at a secretive meeting. Proponents of the effort, named \u2018Human Genome Project\u2014Write\u2019 (HGP-write), write in  Science  that US$100 million from a range of funding sources would help to get their vision off the ground 1 . The team is led by synthetic biologist Jef Boeke at New York University; genome scientist George Church at Harvard Medical School in Boston, Massachusetts; and Andrew Hessel, a futurist at the commercial design studio Autodesk Research in San Rafael, California. But the idea \u2014 which essentially aims\u00a0to develop technologies that reduce the cost of DNA synthesis \u2014 has not met with universal excitement among researchers. To some, the proposal to create a human genome is praiseworthy for its ambition and sheer chutzpah: at present, only  tiny bacterial genomes  and  a portion of a yeast genome  have been made from scratch. But other researchers feel that HGP-write represents a needless centralization of work that is already taking place in companies trying to lower the price of synthesizing strings of DNA. Some of HGP-write\u2019s proponents have financial stakes in those firms, which include Gen9 in Cambridge, Massachusetts. \u201cMy first thought was \u2018so what\u2019,\u201d says Martin Fussenegger, a synthetic biologist at the Swiss Federal Institute of Technology in Zurich. \u201cI personally think this will happen naturally. It\u2019s just a matter of price at the end.\u201d Others think that the project should be delayed until its leaders can win broader support for the idea. In an e-mail sent to reporters, synthetic biologist Drew Endy, at Stanford University in California, and religion scholar Laurie Zoloth, at Northwestern University in Evanston, Illinois, say that the HGP-write team has not properly justified its aims, and that the project should be abandoned. \u201cWe are still waiting for a serious public debate with participation from a broad range of people,\u201d they say. \n               Secretive start \n             Endy and Zoloth had already questioned the scientific rationale for synthesizing a human genome in May, when HGP-write was first aired at an invitation-only meeting at Harvard University that was attended by more than 100 scientists, entrepreneurs, lawyers and ethicists. The closed nature of the meeting also attracted criticism: Church  told the health and medicine news service  Stat  that this was because the paper describing the effort was under embargo. \u201cThere was a lot of confusion on the day about what was going on,\u201d says Tom Ellis, a synthetic biologist at Imperial College London, who attended the meeting. \u201cSome people were in the know on the [paper\u2019s] review process and others were trying to find out.\u201d The three-page announcement of HGP-write fills in some detail. It notes that current technologies are both too expensive and too primitive to synthesize the 3-billion-base-pair human genome. The team calls for a series of pilot projects, including synthesizing much shorter segments of the genome and making slimmed-down chromosomes to do specific tasks, to make its eventual goal doable. The whole project should require less than $3 billion (the price of the publicly funded Human Genome Project), the researchers say. \u201cI think it\u2019s a brilliant project,\u201d says Paul Freemont, a structural biologist at Imperial College London, who attended the meeting. \u201cIf you want to do this, it\u2019s going to be on the same scale as the Human Genome Project, it\u2019s going to need some big funding agencies and hundreds and hundreds of researchers around the world.\u201d Ellis and others worry that a centralized project that explicitly focuses only on the human genome might needlessly narrow the products of the effort. But Boeke \u2014 who in 2014 reported synthesizing a 270,000-base-pair yeast chromosome 2  \u2014 brushes that objection aside. He envisions HGP-write eventually producing synthetic genomes from mice, microbes and all sorts of organisms. \u201cTangible products may be slow to follow at first, but writing DNA more cheaply and at large scale will make researchers more efficient and comprehensive in their work, leading to practically unlimited potential for indirect products,\u201d adds Danielle Tullman-Ercek, a biochemical engineer at the University of California, Berkeley. \n               Barriers to genome writing \n             Cheaper DNA synthesis isn\u2019t the only thing that stands in the way of writing a human genome that could function inside a cell. Ellis says that there are no methods for inserting very large pieces of DNA into a mammalian cell and making them function normally, and researchers have little clue how to design a complex genome that has anything more than trivial changes to an existing one. Freemont worries that commercial bodies such as DNA-synthesis companies may stake a claim on the project. \u201cI think it\u2019s good if this is an open, publicly funded initiative,\u201d he says. Boeke would prefer that there be no intellectual-property restrictions on the products of HGP-write, as is the case with his synthetic yeast genome project. But, he says, the \u201cchances are good\u201d that companies involved in HGP-write will be granted such rights \u201cto get the job done\u201d. To allow wider access, the effort may establish patent pools to allow users to easily license the fruits of the project, he adds. In the  Science  article, the HGP-write team says that it will seek broader public buy-in before beginning work. Boeke says that much of the Harvard meeting centred on the ethics of the project. Boeke also says that the synthetic cells will be engineered to make reproduction impossible. \u201cWe\u2019re not trying to make an army of clones or start a new era of eugenics. That is not the plan.\u201d Additional reporting by Erika Check Hayden. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     \u2018Minimal\u2019 cell raises stakes in race to harness synthetic life 2016-Mar-24 \n                   \n                     First synthetic yeast chromosome revealed 2014-Mar-27 \n                   \n                     Genomics: DNA's master craftsmen 2010-Nov-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19918", "url": "https://www.nature.com/articles/nature.2016.19918", "year": 2016, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "Synthetic polymerase is a small step along the way to mirrored life forms. Researchers at Tsinghua University in Beijing have created a mirror-image version of a protein that performs two of the most fundamental processes of life: copying DNA and transcribing it into RNA. The work is a \u201csmall step\u201d along the way to making mirror-image life forms, says molecular biologist Jack Szostak of Harvard Medical School in Boston, Massachusetts. \u201cIt\u2019s a terrific milestone,\u201d adds his Harvard colleague George Church, who hopes one day to create an entire mirror-image cell. Many organic molecules are \u2018chiral\u2019: that is, they can exist in mirror-image forms that cannot be superimposed, like a right-handed and left-handed glove. But life almost always employs one version: cells use left-handed amino acids, and have DNA that twists like a right-handed screw, for instance. In principle, looking-glass versions of these molecules should work together in the same way as normal ones \u2014 but they might be resistant to attack by conventional viruses or enzymes that have not evolved in a looking-glass world. That makes mirror-image biochemistry a potentially lucrative business. One company that hopes so is Noxxon Pharma in Berlin. It uses laborious chemical synthesis to make mirror-image forms of short strands of DNA or RNA called aptamers, which bind to therapeutic targets such as proteins in the body to block their activity. The firm has several mirror-aptamer candidates in human trials for diseases including cancer; the idea is that their efficacy might be improved because they aren\u2019t degraded by the body\u2019s enzymes. A process to replicate mirror-image DNA could offer a much easier route to making the aptamers, says Sven Klussmann, Noxxon Pharma\u2019s chief scientific officer. \n               Through the looking-glass \n             Researchers have been making chunks of mirror-DNA for decades, so the Tsinghua team could order much of what they needed for their looking-glass DNA replication attempt from a chemical supplier: a mirror-DNA strand to be copied, mirror-DNA building blocks and a shorter mirror \u2018primer\u2019 strand that could pick up these building blocks in the right order. The difficult task was to make the mirror-image enzyme that coordinates the copying process, called DNA polymerase. That would need to be synthesized from right-handed amino acids, but commonly used polymerase enzymes have more than 600 amino acids \u2014 meaning that they are too big for current synthetic methods.\u00a0 So the Tsinghua team turned to the smallest known polymerase: African swine fever virus polymerase X, which contains just 174 amino acids. Unfortunately, it is also spectacularly slow \u2014 probably because of its small size, says synthetic biologist Ting Zhu, a former graduate student of Szostak\u2019s who helped to lead the work. The team made a mirror version of the enzyme and found that, like its natural equivalent, it could extend a mirror-primer consisting of 12 nucleotides (DNA building blocks) to an 18-nucleotide mirror-DNA strand in about four hours; and to a 56-nucleotide strand in 36 hours. When the normal and mirror-image versions of these systems were mixed together in the same test tube, both replication processes worked independently without interference. The mirror-image polymerase could also transcribe mirror-DNA into mirror-RNA, again at a glacial pace. The work is published in  Nature Chemistry 1 . Klussmann says that Noxxon Pharma is interested in pursuing a similar approach with a more efficient enzyme. Indeed, Zhu and his colleagues next hope to build a mirror-image of a more efficient polymerase known as Dpo4, which is built of 352 amino acids. \n               Life, backwards \n             In their research paper, the Tsinghua researchers also present their work as an effort to investigate why life\u2019s chirality is the way it is. This remains mysterious: it may simply be down to chance, or it could have been  triggered by a fundamental asymmetry in nature . But Steven Benner, at the Foundation for Applied Molecular Evolution in Alachua, Florida, says it\u2019s unlikely that creating a mirror form of biochemical life could shed any light on this question. Almost every physical process behaves identically when viewed in a mirror. The only known exceptions \u2014 called \u2018parity violations\u2019 \u2014 lie in the realm of subatomic physics. Such tiny differences would never show up in these biochemical experiments, says Benner. (He is also interested in making DNA that can avoid unwanted degradation by natural enzymes or viruses, but rather than using mirror-DNA, he has created  artificial DNA with non-natural building blocks .) Church\u2019s ultimate goal, to make a mirror-image cell, faces enormous challenges. In nature, RNA is translated into proteins by the ribosome, a complex molecular machine. \u201cReconstructing a mirror-image of the ribosome would be a daunting task,\u201d says Zhu. Instead, Church is trying to  mutate a normal ribosome  so that it can handle mirror-RNA. Church says that it is anyone\u2019s guess as to which approach might pay off. But he notes that a growing number of researchers are working on looking-glass versions of biochemical processes. \u201cFor a while it was a non-field,\u201d says Church. \u201cBut now it seems very vibrant.\u201d \n                     Force of nature gave life its asymmetry 2014-Sep-25 \n                   \n                     There's no place like home 2008-Feb-15 \n                   \n                     Meteorite molecules spin sugars 2004-Feb-20 \n                   \n                     Synthetic biologists prepare to leap through the looking glass \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19913", "url": "https://www.nature.com/articles/nature.2016.19913", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Tools and bones from Florida could put to rest the \u2018Clovis-first\u2019 theory of America\u2019s colonization. Scuba-diving archaeologists have unearthed artefacts from an ancient butchering site that seem to settle a debate about when humans spread across the Americas. Working in the murk of a river in Florida, the team found stone tools dating back 14,550 years that could have been used to carve up ancient elephant-like beasts called mastodons, whose remains have been recovered from the same site. The findings, published today in  Science Advances 1 , add to  ever-growing evidence  that humans were living in much of the Americas well before the cultural group known as Clovis were present about 13,000 years ago. The alternative theory \u2014\u00a0that the Clovis group were the first Americans\u00a0\u2014 has been increasingly disputed. \u201cI think this paper is a triumph for underwater archaeology and yet another nail in the coffin of the Clovis-first theory,\u201d says Jon Erlandson, an anthropologist at the University of Oregon in Eugene. The site was originally a sinkhole with a pond in the centre, but it has since been covered by the Aucilla River. Using hand trowels, laser levels and a suction tube to draw disturbed sediment to the surface for screening, the underwater archaeologists found six stone artefacts that had clearly been made by people. One \u2014 a knife fragment (pictured) \u2014 was surrounded by bits of organic material that were dated to 14,550 years ago by radiocarbon testing. In addition, a mastodon tusk of the same age found at the site years ago by another team shows clear marks that the researchers attributed to efforts by people to remove the tusk from the head. Daniel Fisher, a palaeontologist at the University of Michigan in Ann Arbor and an author of the latest study, reanalysed the tusk and agrees that the marks were probably caused by butchering, most likely to extract the roughly 7 kilograms of nutritious tissue that would have been found inside. Fisher and his team also looked for evidence of large animals by examining the sediment in the old pond for spores of  Sporormiella , a fungus that lives on the dung of herbivores. Researchers have suggested that human hunting might have quickly driven animals such as the mastodon to extinction, but the spores were most abundant 13,700 years ago and did not disappear until around 12,600 years ago. This suggests that people were living with these large animals for a few thousand years before the animals went extinct. Fisher says that it isn't clear whether the knife-wielders killed the mastodon or simply scavenged the carcass, but \u201chowever humans and mastodons interacted, it took at least two millennia for the process of extinction to run to completion\u201d. \n             Clovis second \n           With evidence of other clearly pre-Clovis sites in Chile and Oregon 2 , 3 , many people are now convinced that humans had made it to Florida as far back as 14,550 years ago. There are still some sceptics about the Florida dates. Donald Grayson, an anthropologist at the University of Washington, worries that dates from the site\u00a0might have been contaminated by ancient carbon from the huge aquifer that sits under much of Florida. \u201cI see no reason to accept their radiocarbon dates as accurate,\u201d he says. But Michael Waters, an anthropologist at Texas A&M University in College Station and another author of the latest paper, dismisses Grayson\u2019s concerns, for reasons including that samples were treated to remove soluble contaminants. \u201cFor some reason, there is still great resistance to the concept of pre-Clovis,\u201d he says. \u201cThe data are strong.\u201d David Madsen, an archaeologist at the University of Texas at Austin\u00a0known for reserving judgement on when the Americas were first colonized, is convinced. He thinks that it is now time to re-examine a host of sites that were dated to before 13,500 years ago but dismissed because \u201cthe idea the first Americans were Clovis age was so pervasive\u201d. \u201cNow that the Clovis-first paradigm has been largely refuted it may be possible to revalidate the original evidence from those sites with careful work, using more modern techniques,\u201d Madsen says. \n                   Fishing for the first Americans 2015-Sep-08 \n                 \n                   Bone DNA reveals humanity\u2019s trek into South America 2015-Apr-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19931", "url": "https://www.nature.com/articles/nature.2016.19931", "year": 2016, "authors": [{"name": "Bethany  Augliere"}], "parsed_as_year": "2006_or_before", "body": "Scientists spot mutations that could explain how giraffes became the world\u2019s tallest living mammals. Call it a tall task: researchers have decoded the genomes of the giraffe and its closest relative, the okapi. The sequences, published on 17 May in  Nature Communications 1 , reveal clues to the age-old mystery of how the giraffe evolved its unusually long neck and legs. Researchers in the United States and Tanzania  analyzed the genetic material  of two Masai giraffes (Giraffa camelopardalis tippelskirchi) from the Masai Mara National Reserve in Kenya, one at the Nashville Zoo in Tennessee and an okapi fetus (Okapia johnstoni) from the White Oak Conservation Center in Yulee, Florida. \u201cThis is one more wonderful demonstration of the power of comparative genomics to connect the evolution of animal species on this planet to molecular events that we know must underpin the extraordinary diversity of life on this planet,\u201d says David Haussler, director of the Genomics Institute at the University of California, Santa Cruz. \n             Long view \n           As the tallest mammals on Earth, giraffes can reach heights up to nearly 6 metres, with necks stretching 2 metres. To prevent fainting when they lower their heads to drink water, giraffes have developed an unusually strong pumping mechanism in their hearts that can maintain a blood pressure 2.5 times greater than that of humans. To keep their balance and reach sprints up to 60 kilometres per hour, giraffes have a sloped back, long legs and short trunks. But their closest relative \u2014 the okapi \u2014 resembles a zebra, and lacks those modifications. Previous genetic research has suggested that the okapi and the giraffe diverged from a common ancestor roughly 16 million years ago, says study co-author Douglas Cavener, a biologist at Pennsylvania State University in University Park. But the latest study found that the two species diverged much more recently, about 11.5 million years ago. To identify genetic changes associated with the giraffe\u2019s unique qualities, Cavener and his colleagues compared gene-coding sequences of the giraffe genome to those of the okapi, and then to those of more than 40 other mammals, including sheep, cows and humans. \n             Tall tale \n           The scientists found about 70 genes in the giraffe genome that showed adaptations not seen in other mammals. Two-thirds of these genes code for proteins linked with regulating different aspects of development and physiology, particularly in the skeletal and cardiovascular systems. Four of them, for instance, are 'homeobox' genes associated with development of the spine and legs. \u201cAll of these genes in the giraffe \u2014 we have them ourselves. What made giraffes unique is just to tinker with them a bit and alter them in subtle ways,\u201d Cavener says. Some of the specific genes identified are involved in regulating both skeletal and cardiovascular development. This could mean that mutations in a small number of genes are driving the giraffe\u2019s adaptations, such as a long neck and a turbocharged cardiovascular system, in parallel, says Cavener. This study identifies genes associated with the giraffe\u2019s adaptations, but does not prove their role in the animal\u2019s evolution. Cavener and co-author Morris Agaba \u2014 a molecular geneticist at the Nelson Mandela African Institute for Science and Technology in Arusha, Tanzania \u2014 plan to test this connection by introducing the spine- and leg-related mutations in mice using gene-editing techniques. \u201cThe ultimate would be to make a long-necked mouse,\u201d Cavener jokes. Conservationists such as Derek Lee, a quantitative ecologist at the Wild Nature Institute in Weaverville, North Carolina, see a more immediate benefit of the new findings: bringing attention to the plight of giraffes. In Africa's savannah woodlands, giraffes feast on acacia trees and serve as prey for predators such as lions and hyenas. But in the past 15 years, their numbers have plummeted by 40% as a result of habitat loss and illegal hunting for bushmeat. There are roughly 80,000 giraffes left on the continent. \u201cGiraffes have declined precipitously in the wild,\u201d says Lee. \u201cIt would be a travesty to lose this magnificent animal when we are just beginning to understand its genetic code.\u201d  \n                   Oldest ancient-human DNA details dawn of Neanderthals 2016-Mar-14 \n                 \n                   Genomics: From sea to sea 2016-Jan-20 \n                 \n                   Rank giraffes in rude health 2002-Oct-21 \n                 \n                   Tiny valve opens rich vein 2001-Apr-25 \n                 \n                   Giraffe Conservation Foundation \n                 \n                   Wild Nature Institute \n                 \n                   Douglas Cavener's page on the giraffe genome \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19919", "url": "https://www.nature.com/articles/nature.2016.19919", "year": 2016, "authors": [{"name": "Zoe  Cormier"}], "parsed_as_year": "2006_or_before", "body": "Researchers' long fight to test psilocybin's safety finally yields fruit. A hallucinogenic drug derived from magic mushrooms could be useful in treating depression, the first safety study of this approach has concluded. Researchers from Imperial College London gave 12 people psilocybin, the active component in magic mushrooms. All had been clinically depressed for a significant amount of time \u2014 on average 17.8 years. None of the patients had responded to standard medications, such as selective serotonin re-uptake inhibitors (SSRIs), or had electroconvulsive therapy. One week after receiving an oral dose of psilocybin, all patients experienced a marked improvement in their symptoms. Three months on, five patients were in complete remission.\u00a0 \u201cThat is pretty remarkable in the context of currently available treatments,\u201d says Robin Carhart-Harris, a neuropsychopharmacologist at Imperial College London and first author of the latest study, which is published in\u00a0 The Lancet Psychiatry 1 . The equivalent remission rate for SSRIs is around 20%. The study's authors are not suggesting that psilocybin should be a treatment of last resort for depressed patients. \u201cOur conclusion is more sober than that \u2014 we are simply saying that this is doable,\u201d says Carhart-Harris. \u201cWe can give psilocybin to depressed patients, they can tolerate it, and it is safe. This gives us an initial impression of the effectiveness of the treatment.\u201d \n             Drug problems \n           Demonstrating the safety of psilocybin is no small task. Magic mushrooms are categorized as a Class A illegal drug in the United Kingdom \u2014 the most serious category, which also includes heroin and cocaine. The ethics committee that granted approval for the trial was so concerned that trial volunteers could experience delayed onset psychotic symptoms that it requested a three-month follow-up on the subjects. \u201cThis was unprecedented,\u201d says neuropsychopharmacologist David Nutt at Imperial, who is senior author of the study. It took 32 months between having the grant awarded and dosing the first patient, says Nutt. By comparison, it took six months \u201cto get through the machinations\u201d for his team\u2019s\u00a0 previous studies using the equally illegal drugs LSD \u00a0and MDMA, he says. \u201cEvery interaction \u2014 applying for licenses, waiting for licenses, receiving the licenses, applying for contracts for drug manufacture, on and on \u2014 involved a delay of up to two months. It was enormously frustrating, and most of it was unnecessary,\u201d says Nutt. \u201cThe study result isn\u2019t the remarkable part \u2014 it\u2019s the fact that we did it at all.\u201d Scientists at the Heffter Research Institute in Santa Fe, New Mexico, have been investigating how psilocybin could be used to alleviate depression and anxiety in people with terminal cancer, but this is the first study to look specifically at how psilocybin could be used to treat depression alone. The World Health Organisation calls depression \u201cthe leading cause of disability worldwide\u201d. But effective therapies are hard to find. Searching for new treatments, researchers have looked to potent and quirky alternatives such as\u00a0 ketamine \u00a0and\u00a0 ayahuasca , both of which have shown promise in clinical trials. \u201cIt\u2019s worth noting that we have not developed any new treatments which are widely used since the 1970s for depression, despite the fact that this is the major public-health problem in the Western world and middle-income countries,\u201d says Glyn Lewis, who studies psychiatric disorders at University College London. Particularly interesting, he says, is the fact that psilocybin seems to take effect with a single dose, unlike some current medications for depression that must be taken daily. \u201cThis study is simply asking: is this interesting enough to pursue further as a treatment for depression?\u201d says Lewis. \u201cMy own judgement is that yes, it is.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Depression: Ketamine steps out of the darkness 2016-May-04 \n                 \n                   Brain scans reveal how LSD affects consciousness 2016-Apr-11 \n                 \n                   Ayahuasca psychedelic tested for depression 2015-Apr-06 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19914", "url": "https://www.nature.com/articles/nature.2016.19914", "year": 2016, "authors": [{"name": "Clara Moskowitz"}], "parsed_as_year": "2006_or_before", "body": "The nonprofit Simons Foundation will fund a new observatory to search for signs of stretching in the very early universe. An article from    Scientific American . How did it all begin? The origin of the cosmos is probably the biggest mystery in science\u2014but amazingly, researchers do have some hard evidence to consult in their attempts to solve it. The cosmic microwave background (CMB), a microwave fog that pervades space, is the oldest light in existence\u2014it was released about 13.7 billion years ago when the extremely hot and dense baby universe cooled enough to allow photons to travel freely for the first time. That was about 380,000 years after the Big Bang, and the light has been flying through space ever since. Although the light itself is already unimaginably ancient, it may preserve a record of things that happened even earlier\u2014specifically, it might contain imprints from gravitational waves that may have ripped through the cosmos in the very first moments of space and time. To search for these waves, scientists are launching the Simons Observatory, a $40 million telescope project to be built in Chile\u2019s Atacama Desert and funded by the New York-based nonprofit Simons Foundation. \u201cWe don\u2019t know the level at which [gravitational waves] will appear, but there\u2019s a level where if they\u2019re smaller we won\u2019t be able to measure them,\u201d says Simons Observatory spokesperson Mark Devlin, a cosmologist at the University of Pennsylvania. \u201cNone of the current experiments are anywhere close to being able to do that. What this Simons grant allows us to do is make a huge leap forward in making progress.\u201d These primordial gravitational waves\u2014not to be confused with the  waves recently spotted to much fanfare \u00a0by the Laser Interferometer Gravitational-Wave Observatory (LIGO)\u2014are predicted by a theory called inflation, which suggests the universe may have dramatically ballooned in size during the first fractions of a second after its birth. Such wrenching, rapid expansion would have produced gravitational ripples in spacetime that could have been imprinted on the CMB in the form of so-called \u201cb-modes\u201d\u2014a curling pattern in the polarization, or orientation, of the CMB light. \u201cI think we have a very good shot at getting the answer to whether or not inflation really took place,\u201d says Simons Foundation founder Jim Simons. \n             Smoking gun? \n           The discovery of b-modes would be taken by many as smoking-gun proof of inflation, but would not convince everyone. The theory has a  growing number of skeptics \u00a0who say the fact that primordial gravitational waves have not been seen to date already rules out many of the most plausible versions of inflation. \u201cIt\u2019s already profoundly important that we don\u2019t see them, and if we continue to not see them, I think it will be an important psychological effect on people, making them hopefully look around and see if there are better ideas,\u201d says Princeton University physicist Paul Steinhardt, who is one of the founders of inflation but has grown disillusioned with the theory. Yet many astrophysicists stand by inflation because it can explain numerous features of our current universe, such as the fact that space appears to be flat and roughly the same in all directions. \u201cInflation is the best idea we have at the moment, but I wouldn\u2019t be surprised if it\u2019s not the theory we\u2019ll have of the early universe in 50 years,\u201d says Princeton University theoretical physicist David Spergel, a member of the Simons Observatory\u2019s executive board. \u201cThat\u2019s to me one of the motivations for getting better data. We might find some intriguing anomaly that points the way toward a deeper theory.\u201d This possibility appeals to scientists on all sides of the debate. \u201cI think it\u2019s an extraordinarily generous and visionary contribution to the field,\" Steinhardt says of the Simons Foundation grant (he is not affiliated with the project). \u201cIt\u2019s going to have historic value, I think, whichever way it goes. The team of people involved in these experiments are absolutely terrific, highly reliable, and this is very challenging, precision work that requires the utmost care.\u201d About two years ago scientists made a\u00a0 false-alarm announcement of primordial gravitational waves . Researchers with the Background Imaging of Cosmic Extragalactic Polarization 2 (BICEP2) experiment at the South Pole claimed to have seen strong evidence of b-modes, but their findings later turned out to be based on contamination from dust in our galaxy. BICEP2 is one of a handful of experiments\u2014including telescopes on the ground and airborne balloons\u2014still searching for signs of ancient gravitational waves. \n             The next big step \n           The Simons Observatory will be equipped with about 50,000 light-collecting detectors\u2014about 10 times more than anything currently operating. This project in turn will set the stage for an even larger future initiative dubbed CMB Stage Four, which will build radio dishes with a total of some 500,000 detectors, Devlin estimates. The Department of Energy\u2019s High Energy Physics division\u00a0 plans to help fund Stage Four , along with likely funding from the National Science Foundation and possibly international agencies. \u201cSometimes private philanthropy gets something going which government support then continues,\u201d Simons says. \u201cBy our getting it going, it will encourage them to fall in.\u201d The Simons Observatory is also being funded by the participating institutions\u2014Princeton University, The University of California at San Diego, The University of California at Berkeley, The University of Pennsylvania and the Lawrence Berkeley National Laboratory\u2014as well as the Heising-Simons Foundation. The telescope\u2014or perhaps telescopes\u2014will likely begin construction in around three years, and could start observing in a decade. \u201cThe CMB is just so rich and powerful scientifically,\u201d says University of Chicago physicist John Carlstrom, who is not participating in the Simons Observatory project. \u201cWe\u2019ve been trying as a community to figure out how we can continue to extract this information. It\u2019s getting to the point where we really need to pull together and need a community effort to get to the next level. This looks like a way to really start pushing for that.\u201d \n                   Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                 \n                   Young scientists poised to ride the gravitational wave 2016-Feb-16 \n                 \n                   Einstein's gravitational waves found at last 2016-Feb-11 \n                 \n                   Gravitational waves discovery now officially dead 2015-Jan-30 \n                 \n                   Dust to dust 2014-Oct-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19917", "url": "https://www.nature.com/articles/nature.2016.19917", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Technique tested on Britons' genomes provides first look at human genetic adaptation over the past 2,000 years. Humans may be members of an advanced species, but we haven't stopped evolving. Over the past 2,000 years, British people have adapted to become taller and blonder, more likely to have blue eyes and  better able to digest milk , according to researchers who have developed a technique to track very recent changes in the human genome. Some previous methods to suss out such adaptation could only do so over the past 25,000 years. Others have been able to track selection pressures that work to shape the modern human genome over shorter time periods, but they  rely upon ancient human DNA  or the comparison of closely related populations, which are often unavailable. The new technique, which is based on a statistical analysis of whole-genome sequences, narrows this window to just two millennia. It is also able to pinpoint the adaptation of complex traits \u2014 such as height \u2014 which are influenced by many different genes, the researchers report in a paper posted to the preprint server bioRxiv 1 . \u201cThis method is pretty exciting,\u201d says Laura Scheinfeldt, a human geneticist at Temple University in Philadelphia, Pennsylvania. \n             Frequent favourites \n           Jonathan Pritchard, a geneticist at Stanford University in California, and his colleagues developed the technique and tested it on the whole-genome sequences of 3,195 people collected as part of a project to study the genomes of 10,000 Britons. Their method takes advantage of the fact that genetic variants, or alleles, favoured under natural selection are, by definition, increasing in frequency. This means that the population that they came from is smaller than the population they are currently in. Alleles from smaller populations have less variability, and so favoured alleles should have fewer single mutations near them. In the British population, the researchers found that natural selection over the past 2,000 years has favoured genes for lactase (an enzyme that allows people to digest milk), blond hair and blue eyes. It has also favoured a more complex trait: increased height.  Height is complicated to study over time  because it is a polygenic trait, which means that many genes are involved in determining it. In fact, the researchers estimate that tens of thousands, or even hundreds of thousands, of genes affect height. \u201cMost of the genome is close to a variant that affects height,\u201d says Pritchard. The method identified other favoured polygenic traits, including larger head sizes in infants and larger hip size and later first menstruation in women. Taken together, the findings hint at a larger story about how a demand for bigger brains in humans has physically shaped the species, even in modern times. But Pritchard urges caution, noting that the evidence for the other polygenic traits is a little weaker than for height, and that the results need to be replicated. \n             Room to expand \n           Although his study examined British people only, the method could be used to look at other groups, especially as more and more whole-genome data become available. The technique could shed light on whether different populations around the world are currently experiencing selection for the same traits or different ones. It could also illuminate for the first time the twisting and turning trajectories of how exactly an adaptation has changed in recent times. For example, scientists knew that the gene variant for lactase was first selected for about 7,500 years ago 2 , but this study provides evidence that it has been actively selected for in the past 2,000 years. These other traits make for many tantalizing applications of the technique. \u201cI think, for human data, it could be used to be look at any recent adaptation in any global population,\u201d says Scheinfeldt. \u201cI\u2019m just speculating, but I would think that there are many other as-of-yet unknown genetic variants that contribute to immune response or autoimmune disease.\u201d  \n                   Astronaut twins study raises questions about genetic privacy 2015-Mar-26 \n                 \n                   Human evolution: The Neanderthal in the family 2014-Mar-26 \n                 \n                   Archaeology: The milk revolution 2013-Jul-31 \n                 \n                   Baseball players reveal how humans evolved to throw so well 2013-Jun-26 \n                 \n                   Parasites drove human genetic variation 2011-Nov-11 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19932", "url": "https://www.nature.com/articles/nature.2016.19932", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "The Social Science Research Network says that it will continue to offer free submissions and downloads under its new owner. After trying without success more than a decade ago to set up preprint servers \u2014 where academics share their papers before peer review \u2014 science-publishing giant Elsevier is now buying one. It is paying an undisclosed sum for the  Social Science Research Network  (SSRN), one of the world\u2019s most popular repositories of research in economics, law and the social sciences. Analysts say that the acquisition,  announced on 17 May , exemplifies the morphing business strategy of what is arguably the world\u2019s largest scientific-journal publisher. As well as selling its subscription content through libraries, Elsevier is starting to attract more academics to its sites by providing services such as online scholarly social networks and preprint servers.\u00a0 \u201cIt seems the obvious direction to take in a context where content is increasingly freely available,\u201d says Michael Jubb, a scholarly-publishing consultant in London. He points to the rise both of open-access publishing and of  piracy sites, such as Sci-Hub , as drivers of the trend. \u201cElsevier is now getting closer and closer to researchers with business models that don't involve libraries,\u201d says Joe Esposito, a publishing consultant in New York City. \u201cThe positioning is well thought out: lock up revenues to the legacy publishing business, move into areas where piracy is not much of an issue, create deeper relationships with researchers and become more and more essential to researchers even as librarians become less so.\u201d \n             Fluid transition \n           Tens of thousands of academics routinely upload working papers to the SSRN, which is \u201csuper-important to economists\u201d, says Mark McCabe, an economist at the Questrom School of Business at Boston University in Massachusetts. The SSRN will continue to offer free submissions and downloads after it is acquired by Elsevier, says Gregg Gordon, chief executive of the small, private firm Social Science Electronic Publishing. The company, which founded SSRN in 1994 from its headquarters in Rochester, New York, makes money with the network by offering some premium services, such as selling subscriptions to regular e-mail updates of the latest research. Gordon says that the purchase will allow the SSRN to add social-networking and research-workflow tools for its users. These would be along the lines of those offered on research-collaboration platform Mendeley, a London-based start-up that Elsevier purchased in 2013. The Mendeley purchase attracted some criticism from academics who were angry that a large publisher \u2014 which in 2012 attracted widely publicized boycotts over its prices \u2014 had bought the popular networking site. McCabe expects that there might be a similar reaction to the SSRN deal, although economists and legal scholars have been more indifferent to the finances of their journals and online servers, he says. The SSRN is unusual among preprint servers in its ability to succeed for many years under the ownership of a for-profit firm. Besides Elsevier, other for-profit firms \u2014 including the publisher of  Nature  \u2014 have in the 2000s tried and failed to establish long-lasting preprint servers. The granddaddy of all preprint servers today, the physics and mathematics site arXiv, is operated by Cornell University Library in Ithaca, New York, and funded by a host of institutions, including the Simons Foundation in New York City. It has no plans to be acquired by a publishing firm or any for-profit entity, says Paul Ginsparg, a physicist at Cornell who co-founded it 25 years ago. \u201cI always felt that it was an advantage that arXiv was not aligned with any particular publisher (or any academic ideology for that matter), making it more natural to ingest preprints that could simultaneously go to any publisher,\u201d he says. \n                   Paper piracy sparks online debate 2016-May-02 \n                 \n                   Biologists urged to hug a preprint 2016-Feb-16 \n                 \n                   Open journals that piggyback on arXiv gather momentum 2016-Jan-04 \n                 \n                   The arXiv preprint server hits 1 million articles 2014-Dec-30 \n                 \n                   Open access: The true cost of science publishing 2013-Mar-27 \n                 Reprints and Permissions"},
{"file_id": "533299a", "url": "https://www.nature.com/articles/533299a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "A court ruling paves the way for disease-containment measures, but the risk of spread to other regions and nations remains. Bari, Italy From a small hill in the Puglia region of southern Italy, plant pathologist Donato Boscia gestures towards a landscape of the dullest brown \u2014 dead and dying olive trees as far as the eye can see. Six months earlier, he says, that canopy was mostly green, with just a few tell-tale brown spots marking the relentless advance of a vicious pathogen,  Xylella fastidiosa , that was previously unknown in Europe. Almost three years ago, Boscia, who heads the Bari unit of the CNR Institute for Sustainable Plant Protection (IPSP), and other colleagues identified a subspecies of the bacterial pathogen,  Xylella fastidiosa pauca , as the cause of olive quick decline syndrome (OQDS) in Puglia. They said that it probably arrived with an ornamental plant imported from the Americas, where some  Xylella  species are endemic. But an alarming political and legal impasse has stopped measures to contain the pathogen, which has invaded nearly 200,000\u00a0hectares of olive groves and is killing most olive trees in its wake \u2014 including beloved specimens that are more than 1,000\u00a0years old. Now the gridlock shows some signs of easing. On 12\u00a0May, the European Court of Justice declared that containment measures agreed by the European Union more than a year ago \u2014 but that were quickly blocked by dismayed protesters \u2014 were indeed appropriate, paving the way for them to now go ahead. These include monitoring the disease\u2019s spread, uprooting infected trees and, in some cases, any apparently healthy trees surrounding them, and killing the insects that carry the bacteria. There is currently no cure for  Xylella , and evidence from the Americas indicate that it cannot be eradicated. Still, challenges to fighting the outbreak remain. The infected area has grown over the past year, increasing the chance that the disease will spread to other countries in the Mediterranean basin, which accounts for 95% of the world\u2019s olive production (see \u2018Olive geography\u2019). In February last year, Italian authorities began implementing the EU-agreed containment plan. But protesters, with local political support, dismissed the evidence that OQDS was caused by  Xylella , and that it cannot be cured or eradicated. They argued that the measures were not warranted and took their case to a local administrative court, which referred it to the European Court of Justice. Paralysed by uncertainty, local authorities blocked even monitoring efforts. Aside from their economic importance, olive trees have a long historical and cultural connection with these regions. \u201cSo the public resistance is understandable,\u201d says plant geneticist Francesco Salamini, who is leading a small group of scientists preparing an independent report on the affair for Italy\u2019s national academy. Confusing perceptions further, last December  public prosecutors opened an investigation  into whether five scientists \u2014 Boscia included \u2014 and five public officials negligently spread the disease, deceived officials about it and caused environmental pollution, among other things. IPSP director Gian Paolo Accotto, who is based in Turin, calls these notions \u201clogically absurd\u201d. \n               Control plan \n             The case against containment began to unravel about eight weeks ago when the Parma-based European Food Safety Authority (EFSA), which provides independent scientific advice to the EU, released three reports 1 , 2 , 3  supporting the role of the bacteria in causing the disease and endorsing the EU-agreed containment measures. Puglia regional authorities then approved a new containment plan that defines a greater area of the region as infected (see inset in \u2018Olive geography\u2019). Early this month, administrators there agreed to restart monitoring. A few days later, the European Court of Justice made its declaration. The need for containment is highlighted by Boscia\u2019s work over the past year inoculating different plant species with  X.\u00a0f.\u00a0pauca  in modest greenhouses at the IPSP in Bari. This has revealed that citrus trees and grape vines are immune to the pathogen, but that it can infest a large number of local species such as lavender, oleander and polygala. Researchers say that even if all infected olive trees were destroyed, the bacteria would be so widely harboured in the environment that containment is the best measure. The Bari experiments also revealed that some cultivars of olive tree \u2014 including Leccino, the main cultivar in the Tuscany region \u2014 developed milder symptoms of disease than do the predominant cultivars of Puglia. This could inform efforts to deal with the pathogen should it spread to other regions. It also helps replanting schemes, although more seasons of growth are required to see whether the Leccino trees survive long-term, says Boscia. Other experiments at the IPSP are analysing gene expression in infected trees to determine which molecular characteristics might offer some resilience. This could one day inspire treatments for infected trees. The Bari scientists, together with a group of worried olive producers, are also carrying out experiments in the infected zone. Enzo Manni, head of an association that represents 600 small olive groves there, says that he was stonewalled a few years ago when he tried to interest local institutions in what seemed to be a threatening new disease. \u201cBut I knew something was really wrong,\u201d he says. Now he helps the Bari researchers by identifying land for outdoor experiments and monitoring the tests. \n               Tolerance test \n             In one of these experiments, the team of scientists and producers \u2014 which has now grown to 40 \u2014 has planted different cultivars to test whether any show tolerance over many seasons. Such experiments could guide which trees get planted in the region, or elsewhere. In another study, the scientists are grafting different cultivars onto newly infected trees to see whether some survive, thereby offering hope of recreating canopies on diseased root stock. In some cases, they are funding some of these experiments themselves so as not to lose time. Accotto applauds the scientists\u2019 commitment in spite of the police investigations. \u201cYou can stop humans from trying to help, but you can\u2019t stop bacteria, or put them in jail,\u201d he says. Fearing the spread of  Xylella , scientists in other countries are looking to join in. Those from Spain, the world\u2019s largest producer of olives, have added a couple of the country\u2019s cultivars to the experiments to get an idea of how fast their trees might succumb to the disease. The United Nations Food and Agriculture Organization (FAO), based in Rome, organized an April workshop in Bari to share information with scientists and agriculture officials from olive-growing countries in Europe, North Africa and the Middle East. The delay to the containment programme in Italy has probably increased the risk of OQDS spreading abroad, says Shoki Al-Dobai, head of the FAO\u2019s North Africa and Middle East office in Cairo. He is organizing a contingency plan for that area. Syria and Libya, where olive cultivation is believed to have begun in 2,500\u00a0 bc , are of particular concern, he says, because wars in those countries make appropriate monitoring impossible. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @alison_c_abbott \n               \n                     Italian scientists under investigation after olive-tree deaths 2015-Dec-21 \n                   \n                     Italian scientists vilified in wake of olive-tree deaths 2015-Jun-01 \n                   \n                     Orange bugs unpeeled 2000-Jul-13 \n                   \n                     EFSA: Treatment solutions to cure  Xylella fastidiosa  diseased plants (PDF) \n                   \n                     EFSA: Scientific opinion on four statements questioning the EU control strategy against  Xylella fastidiosa  (PDF) \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19886", "url": "https://www.nature.com/articles/nature.2016.19886", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "As a human trial of optogenetics for retinal diseases begins, researchers eye other applications. Every time something poked its foot, the mouse jumped in pain. Researchers at Circuit Therapeutics, a start-up company in Menlo Park, California, had made the animal hypersensitive to touch by tying off a nerve in its leg. But when they shone a yellow light on its foot while poking it, the mouse did not react. The treatment is one of several nearing clinical use that draw on optogenetics \u2014 a technique in which  light is used to control genes and neuron firing . In March, RetroSense Therapeutics of Ann Arbor, Michigan, began the first clinical-safety trial of an optogenetic therapy to treat the vision disorder retinitis pigmentosa. Many scientists are waiting to see how the trial turns out before they decide how to move forward with their own research on a number of different applications. \u201cI think it will embolden people if there\u2019s good news,\u201d says Robert Gereau, a pain researcher at Washington University in St Louis, Missouri. \u201cIt opens up a whole new range of possiblilities for how to treat neurological diseases.\u201d Retinitis pigmentosa destroys photoreceptors in the eye. RetroSense\u2019s treatment seeks to compensate for this loss by conferring light sensitivity to  retinal ganglion cells , which normally help to pass visual signals from photoreceptors to the brain. The therapy involves injecting patients who are blind or mostly blind with viruses carrying genes that encode light-sensitive proteins called opsins. The cells fire when stimulated with blue light, passing the visual information to the brain. Chief executive Sean Ainsworth says that the company has injected several individuals in the United States with the treatment, and plans to enroll a total of 15 blind patients in its trial. RetroSense will follow them for two years, but may release some preliminary data later this year. Rival company GenSight Biologics in Paris is attempting to treat retinitis pigmentosa with an opsin protein that responds to red light, which is less harsh on the eyes than blue light. At a meeting of the Association for Research in Vision and Ophthalmology in Seattle, Washington, earlier this month, GenSight researchers presented data showing that injecting a gene-carrying virus into healthy monkeys made their retinal ganglion cells responsive to light. Chief executive Bernard Gilly says that GenSight hopes to begin a small human trial early in 2017. Neither company developing retinitis pigmentosa therapies expects patients to fully recover their vision. But Gilly and Ainsworth both say that the trials will be a success if participants gain the ability to navigate independently or even recognize faces. \n             Light touch \n           The eye is an enticing target for optogenetic therapies, in part because immune cells can\u2019t enter the eye to attack the foreign proteins introduced during such treatments. But Circuit Therapeutics is taking a different approach with its pain therapy, relying on light\u2019s ability to pass through the skin. \u201c The nerves are tantalizingly poised at the surface of the skin, just waiting,\u201d says Chris Towne, the company\u2019s head of gene therapy. He presented preliminary data on the treatment on 4 May at a meeting of the American Society of Gene and Cell Therapy in Washington DC. Unlike the retina therapies, Circuit Therapeutics\u2019 treatment uses opsins that prevent neurons from firing. Shining yellow light on mice with these proteins reduces pain by preventing pain signals from travelling to the brain. Towne hopes that the approach, now being tested in pigs, will be the first non-retinal optogenetic therapy to reach the clinic. He envisions a light-producing patch that humans with severe pain sensitivity could wear on the skin and trigger when they perform a painful activity. Researchers still have to determine how well opsins would function in human tissue and whether they will be toxic, but Gereau, who is also pursuing optogenetics for pain relief, says that the results are promising. In a paper in press at  Nature Protocols , his group showed that flashing light at similar opsins inserted into the neurons of donated human organs can activate them or prevent them from firing. Other applications are not far behind. Stimulating neurons in the inner ear with light has been shown to restore some neuron function in deaf mice. Some researchers are developing light-emitting implants that trigger nerves to control bladder function and  vocal cords . Many others hope to use optogenetics to treat Parkinson\u2019s disease and other brain disorders. Such a therapy would be similar to, but more precise than, current deep-brain-stimulation devices that trigger neuron firing. Martin Fussenegger, a biologist at the Swiss Federal Institute of Technology in Zurich (ETH Zurich), says that scientists pursuing optogenetic therapies still face some technical challenges. These include developing  smaller, less obtrusive light-emitting implants , and addressing the risk that optogenetic treatment could overheat neurons. Still, researchers such as neuroscientist Ivan Soltesz of Stanford University in California are watching industry developments closely. He hopes to use optogenetics to stop seizures through a system that automatically flashes a light when a device detects brain patterns that indicate a seizure is about to start or is in progress. Such seizure-detection technologies have worked in animals 3 , and early trials of similar systems that use deep brain stimulation for this purpose are promising. Soltesz says that optogenetics could allow more precise targeting of the right neurons, if scientists can deliver functioning opsins into brain cells. \u201cAs soon as I see that it's feasible I'm all over it,\u201d he says. \n                   Light opens up the larynx 2015-Jun-02 \n                 \n                   Human brainwaves light up mouse genes 2014-Nov-11 \n                 \n                   Neuroscience: Illuminating the brain 2010-May-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19916", "url": "https://www.nature.com/articles/nature.2016.19916", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Meteorite impacts triggered enormous waves in now-vanished ocean. Some 3.4 billion years ago, giant meteoroids slammed into a frigid ocean covering Mars's northern hemisphere. The impacts kicked up enormous waves that raced across the water and swamped the shoreline, research suggests. On the scale of planetary catastrophes, such tsunamis would have dwarfed  most Earthly ones . \u201cImagine this enormous red wave coming towards you, up to 120 metres high,\u201d says Alexis Rodriguez, a Mars researcher at the Planetary Science Institute in Tucson, Arizona. \u201cIt would have been pretty spectacular.\u201d Rodriguez and his colleagues mapped traces of two of these tsunamis. They describe the findings in  Scientific Reports 1 . If the idea stands up to further scrutiny, it may help resolve longstanding arguments about  whether Mars had an ancient northern ocean . As evidence, some scientists point to what they call the remains of a shoreline, like a bathtub ring left behind when the water drained away. But the purported shoreline isn\u2019t visible everywhere that it should be. Mega-tsunamis could have wiped away some of that shoreline, happening as often as every 3 million years or so, Rodriguez says. \n             Wave function \n           Researchers have previously suggested tsunamis on Mars. A 2010 study 2  calculated that high-energy waves should have left an imprint on the proposed Martian shoreline. A 2014 paper 3  simulated how fast and how tall such waves might have moved \u2014 up to 20 metres a second as they rushed outward from the impact site, and up to 120 metres high when they reached the shore. Rodriguez began thinking about Martian tsunamis after visiting the eastern coast of Japan in 2011, which had been devastated by a tsunami generated by a magnitude-9 earthquake. His team grew to include some top Martian geology experts. The group zeroed in on a region on Mars where the highlands known as Arabia Terra bump up against the lowlands of Chryse Planitia \u2014 a place where the waters of an ancient ocean might have lapped at the shoreline. Using imagery from several Mars-orbiting spacecraft, Rodriguez\u2019s group identified two particular geological formations that they say formed during two different tsunamis. The first, older formation looks as if an enormous wave had rushed up onto the edge of the highlands, dropping boulders as big as 10 metres across. The water then drained back down into the ocean, leaving channels cut through the freshly deposited debris. Then, millions of years passed. Temperatures dropped and glaciers crept across the landscape, scouring deep valleys. Finally, a second impact-generated tsunami came rushing again towards the shore. \u201cBut this time it is different,\u201d Rodriguez says. Because the climate was so much colder, the tsunami moved over the landscape like an icy slurry. It froze before it had a chance to wash back into the ocean, leaving dense lobes of frozen debris on the ground. The new study is consistent with earlier ideas about how these Martian features formed, says Timothy Parker, a planetary scientist at the Jet Propulsion Laboratory in Pasadena, California, who originally came up with the idea of a northern Martian ocean. In previous work 4  he described the backwash channels as forming when big waves washed up on a beach and drained back down again. \u201cThough I didn't specifically talk about tsunamis in my interpretations, the implication of scale was certainly there,\u201d he says. \n             Iced out \n           The icy-looking lobes are particularly exciting, says James Dohm, a planetary scientist at the University Museum of the University of Tokyo. Even as the ocean eventually  froze out and died , the tsunami deposits remained untouched by wind or other types of erosion for more than 3 billion years. (Dohm adds that he would have liked to have witnessed the Mars tsunamis, preferably from a high ridge and without an astronaut helmet blocking his vision.) Rodriguez is now looking for evidence of tsunamis in other parts of Mars, as well as analogues on Earth that could help him to understand them better. One area of interest is a group of small craters near the shoreline that could have been drenched by the tsunami, and then trapped that water for millions of years. Such isolated pockets of water could have been places for Martian life to evolve, if it ever existed, Rodriguez says. This summer, he hopes to travel to Tibet to study high, cold mountain lakes that may give him a glimpse into those long-ago Martian craters. \n                   Island boulders reveal ancient mega-tsunami 2015-Oct-02 \n                 \n                   Ancient Mars probably too cold for liquid water 2014-Apr-13 \n                 \n                   Dreams of water on Mars evaporate 2012-Apr-11 \n                 \n                   USGS geologic map of Mars \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19952", "url": "https://www.nature.com/articles/nature.2016.19952", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Rare genetic variant in Icelanders lowers risk of heart attack by more than one-third. A rare mutation found in Icelanders could be the basis for the next blockbuster heart drug. The genetic variant, reported on 18 May in the  New England Journal of Medicine 1  by scientists at a subsidiary of the biotechnology giant Amgen, lowers the risk of heart disease by more than one-third. Amgen, headquartered in Thousand Oaks, California, has already made drugs that mimic the effects of the variation, says Kari Stef\u00e1nsson, a geneticist at DeCODE Genetics (which was bought by Amgen in 2012) in Reykjavik. The variant inactivates a protein that recycles a class of sugar-coated proteins. But precisely which biomolecules it affects is not entirely clear, and the researchers do not yet know why it is associated with such a significantly-decreased risk of heart disease. The DeCODE team identified the variation by comparing the genomes of thousands of Iceland's residents to their medical records. It has fully sequenced about 2,600 Icelanders, and inferred the sequences of another 398,000 inhabitants using more-limited genome data and family-tree records. The company found that 1 in 120 Icelanders has a mutation that inactivates one copy of a gene called  ASGR1 , and that these people have much lower levels of non-high-density lipoprotein\u00a0(non-HDL) cholesterol, compared to the rest of the population. A follow-up analysis of nearly 300,000 individuals from Iceland and 4 other countries found that carriers of this variant were 34% less likely to develop heart disease. The variant didn't seem to be linked to any adverse health effects. \n             Drug implications \n           The level of protection is comparable to that offered by a human gene variant discovered more than a decade ago that dramatically reduces cholesterol levels.The first drugs to mimic that mutation, which block a protein called PCSK9 that influences blood cholesterol levels, were approved by the US Food and Drug Administration last year.  PCSK9 inhibitors have been touted as the next blockbusters  in a cholesterol-lowering drug market that is worth tens of billions of dollars. Anne Tybj\u00e6rg-Hansen, a cardiologist at the University of Copenhagen, says that the new finding could provide a new drug target to prevent heart disease, but \u201cwe need to know more about how this works\u201d \u2014 for instance, which proteins ASGR1 targets for breakdown. One possible explanation for its beneficial effects is that it reduces inflammation. \u201cThat is one of the things we are working on now,\u201d Steff\u00e1nson says. \u201cIt is very important to know what biology you\u2019re manipulating.\" Stef\u00e1nsson contends that the  ASGR1  variation reduces heart-disease risk more substantially than would be expected on the basis of its effect on cholesterol alone, which makes the finding potentially even more valuable. \u201cThis is a genetic discovery that is pointing to the possibility of manipulating something other than just blood lipids,\u201d he says. \u201cWe have no drugs, really, that affect the risk of coronary heart disease that work on alternative mechanisms.\u201d Harlan Krumholz, a cardiology researcher at Yale University in New Haven, Connecticut, says that particular claim is speculative. \u201cThis study is far from identifying an alternative mechanism of risk reduction for a variant associated with non-HDL reduction,\u201d he says. Stef\u00e1nsson expects discoveries from human genomes to have an ever-greater role in drug development \u2014 at least at Amgen. He says that the company now pursues drug targets only with strong genetic evidence in hand, and has killed \u201ca bunch\u201d of drug-development programmes on the basis of genome studies. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   'Good' cholesterol mutation linked to heart disease 2016-Mar-10 \n                 \n                   Genetics: A gene of rare effect 2013-Apr-09 \n                 \n                   Cholesterol limits lose their lustre 2013-Feb-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19944", "url": "https://www.nature.com/articles/nature.2016.19944", "year": 2016, "authors": [{"name": "Dyani Lewis"}], "parsed_as_year": "2006_or_before", "body": "Details of redundancies at CSIRO alarm global climate community. Job losses at Australia\u2019s national science agency will threaten the monitoring and analysis of the Southern Hemisphere\u2019s seas, air and climate, scientists say. Staff at the Commonwealth Scientific and Industrial Research Organisation (CSIRO), which employs thousands of scientists across Australia, were told over the past week where  long-awaited job cuts in climate science  are likely to fall. Many CSIRO researchers who spoke to  Nature  about the lay-offs requested anonymity so as not to breach the organization's communications policy, which tells researchers not to discuss funding or management decisions. But the information that is trickling out means that scientists are already evaluating the likely impact on research \u2013 although a consultation process means that it may be months before an expected 140 lay-offs in climate research are complete. \u201cIt\u2019s significant beyond the numbers because of our overall uniqueness,\u201d says oceanographer Peter Craig, who worked for CSIRO for 30 years but retired from the agency at the end of March. \u201cThe rest of the world does rely on us for both measurements and interpretation of what\u2019s going on on this side of the world.\u201d \n             Ice lab threatened \n           CSIRO scientists in Melbourne who analyse ice cores from an ice cap called Law Dome in Antarctica \u2013 a group colloquially known as the \u2018Ice Lab\u2019 \u2013 fear their programme is one that might be curtailed. Because the Law Dome accumulates ice very rapidly and traps low levels of impurities as it grows, its cores constitute the most reliable record of greenhouse-gas emissions over the past 2,000 years, says Malte Meinshausen, a climate modeller at the University of Melbourne and the Potsdam Institute for Climate Impact Research in Germany. Climate models that predict how many degrees of warming will occur under different greenhouse-gas emissions scenarios rely heavily on its record, Meinshausen says. David Etheridge, head of ice core research, says that he has not been told he will lose his job, but that other scientists who do ice core analysis are facing redundancy. CSIRO has said that the Ice Lab will remain open, but Etheridge believes that cuts will have negative consequences for palaeo-climate research and the climate models that rely on it. \n             Aerosol fear \n           CSIRO researchers also fear that Australia\u2019s contributions to the world\u2019s largest ground-based network of aerosol sensors, called AERONET \u2014 a NASA-led project to verify the sometimes ambiguous aerosol measurements made by satellite \u2014 are in jeopardy. On 1 May, Brent Holben, who leads the AERONET project in Greenbelt, Maryland, wrote to CSIRO to urge that it reconsider its cuts. He said that they would cause the loss of aerosol measurements over a large region of the Southern Hemisphere. Asked for a statement, the agency said: \u201cCSIRO is working with partners to identify the most efficient way of delivering this work.\u201d \n             Sea-level expertise \n           Notable among individual staff set to lose their jobs is John Church, an expert on sea-level rise who has worked for CSIRO for 38 years and who coordinated a chapter on sea-level change for the most recent assessment report of the Intergovernmental Panel on Climate Change (IPCC), released in 2014. Church was at sea on the research vessel RV  Investigator  when he learnt last week that, as he had expected, he would be made redundant. \u201cJohn has probably done more to lay a really firm scientific foundation under the issue of sea-level rise than anyone else in the world,\u201d says Steve Rintoul, a fellow oceanographer at the CSIRO. \u201cThe signal that this sends to both staff within and outside of CSIRO is really horrible.\u201d The RV  Investigator \u2019s voyage from the Southern Ocean to the Equator is currently mapping deep-ocean temperature and chemistry under the international GO-SHIP program, and is also deploying\u00a0 Argo and biogeochemistry floats  that gather data at the ocean surface. CSIRO says that neither the frequency of the ship\u2019s expeditions\u00a0nor the associated data analysis will be adversely affected. But researchers who did not want to be named said that, with the cuts, they doubted that such extensive surveys would be possible in the future, or that other Australian agencies could fill the gaps in expertise if oceanography groups were disbanded. CSIRO had  first announced in February  that it planned to shed hundreds of jobs as part of a strategic shift away from basic climate science; in April, it  confirmed  that this included almost 140 lay-offs in its \u2018Oceans and Atmosphere\u2019 and \u2018Land and Water\u2019 divisions. The CSIRO cuts are \u201cinexplicable\u201d, says Thomas Stocker at the University of Berne, who co-chaired the IPCC\u2019s Working Group I (which examines the physical science of climate change) between 2008 and 2015. He is particularly concerned about the cuts to the sea-level research group. \u201cIt\u2019s simply not understandable for me that the stewards of a country that is so fundamentally exposed to sea-level rise is able to basically terminate research activity in their own country,\u201d he says. Negotiations since February have staved off cuts in some programmes, says one senior scientist at CSIRO\u2019s Aspendale site in Melbourne. For example, CSIRO ratcheted back cuts for a team that analyses air pollution from data drawn from the remote Cape Grim Observatory in Tasmania, so that Australia could continue to meet obligations to international agreements such as the Montreal Protocol, which governments signed in 1987 to protect the stratospheric ozone layer from damage by chlorofluorocarbons. But it seems that the bulk of the cuts will not be reversed. Although more than 3,000 scientists have urged Australian politicians and CSIRO management in an open letter to reconsider the proposed lay-offs, the government has distanced itself, saying that they are an agency-level decision. With national elections set for 2 July, the opposing Labor party has said that if it were elected, it would direct the CSIRO's board to stop the lay-offs. However, it would not reappoint scientists who accept redundancies before then. \n                   Australia softens blow of climate job cuts 2016-Apr-26 \n                 \n                   Massive network of robotic ocean probes gets smart upgrade 2016-Mar-22 \n                 \n                   Job cuts in Australia target climate scientists 2016-Feb-05 \n                 \n                   Australian budget hits science jobs 2014-Jul-01 \n                 Reprints and Permissions"},
{"file_id": "533302a", "url": "https://www.nature.com/articles/533302a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Ice-going vessels like Britain\u2019s RRS  Sir David Attenborough  \u2014 named Boaty McBoatface by the Internet \u2014 are being built across the world. The United Kingdom\u2019s new polar research vessel has become a national obsession. A proposal to christen the ship Boaty McBoatface captured the public imagination \u2014 so much so that the decision to name the ship instead after broadcaster and naturalist David Attenborough triggered  questions in a parliamentary inquiry . But the RRS  Sir David Attenborough , which will probe both the Arctic and Antarctic, is also notable because it will carry more scientists and push deeper into polar ice than any UK research vessel ever has. It joins a wave of ice-strengthened research vessels \u2014 from Norway to China to Australia \u2014 that promise to expand scientists\u2019 ability to explore harsh polar environments (see \u2018Ships of the future\u2019). China is soliciting bids to build a large research icebreaker to accompany its existing ship  Xuelong , and the Australian government signed a contract last month for a replacement for its ageing  Aurora Australis . Germany has started the process of replacing its vessel  Polarstern , and Sweden is beginning to discuss what to do after its ship  Oden  is retired towards the end of the next decade. (A proposed pan-European icebreaker, costing up to \u20ac800\u00a0million (US$900\u00a0million), is on hold owing to its enormous price tag.) The 129-metre-long  Attenborough  is designed by the team behind the  Kronprins Haakon , an icebreaker being built for the Norwegian Polar Institute in Troms\u00f8. When  Kronprins Haakon  sets off on its first science cruise in 2018, it will give Norwegian researchers a serious upgrade in their access to Arctic seas. It will replace a smaller vessel that can carry fewer scientists and operate only in light ice. \u201cIt\u2019s a whole new world for us,\u201d says project manager \u00d8ystein Mikelborg of the Norwegian Polar Institute. \n               Over ice \n             Within weeks, architects will finalize the  Attenborough \u2019s design and workers in Merseyside, UK, will begin cutting steel for its hull, on track for a 2019 delivery. Designers are cramming as many research goodies as possible into the \u00a3200-million (US$290-million) ship. The  Attenborough  will have a helicopter deck and, unlike Britain\u2019s existing polar-research vessels, a hangar. This will allow scientists to fly to otherwise inaccessible lakes or islands in Antarctica. And the  Attenborough  will have a hole in the hull known as a moon pool, allowing researchers to deploy oceanographic and geological equipment more smoothly and safely than by swinging it off the side of the ship. Laboratory spaces will be kept at different temperatures, allowing storage and experiments of different types. The deck will have extra room for custom-made equipment for different cruises. Modern fibre-optic cables will deliver a live camera feed from as deep as 6,000 metres, from a remotely operated vehicle that will be called Boaty McBoatface, in a concession to the public vote. Yet this increased research capability comes at a price: fewer days of actual science. The British Antarctic Survey (BAS) currently operates two polar vessels, the 25-year-old RRS\u00a0 James Clark Ross  for science, and the 21-year-old RRS  Ernest Shackleton , which delivers equipment, food and people to its bases. To cut annual operating costs by 20%, the bigger  Attenborough  will replace both ships. Instead of 180\u00a0days of science a year, UK scientists will get 150. The rest of the time (and space on the ship) will go to ferrying cargo. \u201cI don\u2019t like to use the word compromise, but there is a trade-off,\u201d says Andrew Jeffries, project manager for the new boat and a BAS engineer in Cambridge, UK. There have been other trade-offs between research and logistics. Ship designers have had to place the vessel\u2019s enormous diesel generators on isolating platforms to make the ship run silently, to avoid disturbing seismic and biological acoustics studies. The current design may also have to be tweaked to avoid vents from the helicopter fuel storage opening directly into areas where atmospheric scientists were counting on having clean air for their measurements. Even with these trade-offs, researchers are eager for the  Attenborough  to launch. Not only will it be able to push through thicker ice and carry more scientists, but the ship will also be able to explore deeper environments than any other UK research vessel, says Katrin Linse, a deep-sea biologist at the BAS. That ability will allow it to carry out the first direct sampling of the 8.5-kilometre-deep South Sandwich Trench in the southern Atlantic Ocean. \u201cWe might find a new ecosystem there that we are not aware of yet,\u201d she says. \u201cIt\u2019s pretty exciting to get a new vessel. That only happens once every 30\u201340\u00a0years.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @alexwitze \n               \n                     US Arctic research ship ready to cast off 2014-May-27 \n                   \n                     Researchers question rescued polar expedition 2014-Jan-15 \n                   \n                     Oil cost hits ship studies 2008-Jul-23 \n                   \n                     Blog post: Polar icebreaker pledged as UK launches science-spending consultation \n                   \n                     RRS  Sir David Attenborough \n                   \n                     NERC science consultation \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19946", "url": "https://www.nature.com/articles/nature.2016.19946", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Chemists generate variations on erythromycin in \u2018daring\u2019 synthesis. A 64-year-old class of antibiotics that has been a cornerstone of medical treatment has been dramatically refreshed by dogged chemists searching for ways to overcome antibiotic-resistant bacteria. In work described today in  Nature [1], a team of chemists built molecules similar to the drug erythromycin, a key member of the macrolide class, from scratch. In doing so, they were able to generate more than 300 variations on erythromycin that would not have been feasible by merely modifying the original drug \u2014 the way that scientists would normally search for new variants of existing antibiotics. The process generated several variants on erythromycin that can kill bacteria that are resistant to the antibiotic. Although much testing remains before any of the molecules could be used in people, many of them show promise, says chemist Phil Baran of the Scripps Research Institute in La Jolla, California. He adds that the work holds potential for the future of antibiotics: \u201cThe fact that you can now make deeply modified analogues in a practical way with chemical synthesis opens the door to a whole host of derivatives that could never have been dreamt of before.\u201d \n             A new recipe \n           Erythromycin was first isolated in 1952  from a bacterium in a soil sample  taken from the Philippines. But natural erythromycin is a poor drug: although it can kill bacteria, it is unstable in the acidic environs of the stomach, and rearranges there to form a toxic compound. Chemists quickly became experts at modifying erythromycin to make it more stable and less toxic.\u00a0 Over time, researchers had another reason to develop analogues of the molecule: the rise of erythromycin-resistant bacteria. But after decades of chemically altering the antibiotic, chemists were beginning to run out of options. \u201cChemists over the past 60 years have been incredibly inventive, but it\u2019s extremely challenging to modify a molecule as complicated as erythromycin,\u201d says Andrew Myers of Harvard University in Cambridge, Massachusetts. \u201cAnd that\u2019s all we\u2019ve had for a long time.\u201d Myers and his team decided to go about the problem another way: by synthesizing variations of erythromycin from scratch. The work took five years and led to the discovery of new ways to manufacture molecules. \n             Successful screening \n           The team screened 305 of its macrolides against several bacterial strains. Most of the compounds had some antibiotic activity: 83% of them were active against  Streptococcus pneumoniae , a bacterium that is susceptible to macrolide antibiotics. Some were also effective against strains that are resistant to multiple antibiotics. The compounds have not yet been tested in animals, and additional chemical tweaks may be necessary to enhance their potency as well as their safety. Myers has founded a company called Macrolide Pharmaceuticals in Watertown, Massachusetts, to develop the compounds further. But Baran, who calls the approach \u201cdaring\u201d and \u201cfearless\u201d because it started from scratch, says that the success is a testament to the  power of organic chemistry . \u201cIt shows the power of synthesis to revitalize what is one of the oldest classes of antibiotics.\u201d \n                   Mirror-image enzyme copies looking-glass DNA 2016-May-16 \n                 \n                   Chemistry: Why synthesize? 2015-Dec-16 \n                 \n                   The slow-chemistry movement 2015-Aug-04 \n                 \n                   Mining the microbial dark matter 2015-Jun-16 \n                 \n                   Macrolide Pharmaceuticals \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19948", "url": "https://www.nature.com/articles/nature.2016.19948", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Technique to stop children inheriting mitochondrial diseases has potential to backfire. A gene-therapy technique that aims to prevent mothers from passing on harmful genes to children through their mitochondria \u2014 the cell\u2019s energy-producing structures \u2014 might not always work. Mitochondrial replacement therapy  involves swapping faulty mitochondria for those of a healthy donor. But if even a small number of mutant mitochondria are retained after the transfer \u2014 a common occurrence \u2014 they can outcompete healthy mitochondria in a child\u2019s cells and potentially cause the disease the therapy was designed to avoid, experiments suggest. \u201cIt would defeat the purpose of doing mitochondrial replacement,\u201d says Dieter Egli, a stem-cell scientist at the New York Stem Cell Foundation Research Institute who led the work. Egli says that the finding could guide ways to surmount this hurdle, but he recommends that the procedure not be used in the meantime. The UK government last year  legalized mitochondrial replacement therapy , although the country\u2019s fertility regulator has yet to green-light its use in the clinic.\u00a0In the United States, a panel convened by the National Academies of Sciences, Engineering, and Medicine has this year  recommended that clinical trials of the technique be approved  if preclinical data suggest that it is safe. \n               Faults carried over \n             As many as 1 in 5,000 children are born with diseases caused by harmful genetic mutations in the DNA of their mitochondria; the diseases typically affect the heart, muscles and other power-hungry organs. Children inherit all their mitochondria from their mothers. To prevent a mother who has harmful mitochondrial mutations from passing them to her children, the proposed remedy is to transplant the nuclear DNA of her egg into another, donor egg that has healthy mitochondria (and which has been emptied of its own nucleus). The resulting embryo would carry the mitochondrial genes of the donor woman, and the nuclear DNA of their father and mother. These are sometimes called three-person embryos. Current techniques can\u2019t avoid dragging a small number of the mother\u2019s mitochondria into the donor egg, totalling less than 2% of the resulting embryo\u2019s total mitochondria. This isn\u2019t enough to cause health problems. But researchers have worried that the proportion of faulty, 'carried-over' mitochondria may rise as the embryo develops. The UK Human Fertilisation and Embryology Authority (HFEA) \u2014 which will oversee clinical applications of mitochondrial replacement \u2014 has called for research into this possibility. Egli\u2019s study, published today in  Cell Stem Cell 1 , offers some clarity. His team used eggs from women with healthy mitochondria, but otherwise followed a procedure similar to a real therapy: transplanting nuclear DNA from one set of egg cells into another woman\u2019s egg cells. The team then converted these eggs into embryos with two copies of the maternal genome, a process called parthenogenesis. (Mitochondrial replacement is normally performed on eggs fertilized with sperm, but Egli\u2019s team wanted to discount any role for paternal DNA.) The researchers then extracted stem cells from the embryos and grew the cells in dishes in the lab. The embryos, on average, had just 0.2% of carried-over mitochondrial DNA (mtDNA), and the resulting embryonic stem cells at first harboured similarly minuscule levels. But one stem-cell culture showed a dramatic change: as the cells grew and divided, levels of the carried-over mtDNA jumped from 1.3% to 53.2%, only to later plummet down to 1%. When the team split this cell line into different dishes, sometimes the donor egg\u2019s mtDNA won out; but in others, the carried-over mtDNA dominated. In another set of experiments, the low levels of carried-over mtDNA consistently outcompeted the donor mtDNA, both in embryonic stem cells and in tissues made from these cells. \n               Competing DNA \n             Exactly how the carried-over mitochondria rose to dominance is hazy. Egli\u2019s team found no evidence that they helped cells to divide any faster \u2014 for instance, by delivering extra energy. Egli suspects that the resurgence happened because one mitochondrion was able to copy its DNA faster than the others could, which he says is more likely to occur when large DNA-sequence differences exist between the two populations of mitochondria. In his team's study, the most dramatic rebound in carried-over mtDNA occurred when the nucleus of a woman with mitochondria common among Europeans was inserted into the egg cell of a woman with mitochondria usually found in people with African ancestry. Iain Johnston, a biomathematician at the University of Birmingham, UK, says that this theory makes sense. He was part of a team that found that, in mice with mitochondria from both lab and distantly related wild populations, one mitochondrial lineage tended to dominate 2 . If mitochondrial replacement does reach the clinic, Johnston says that donors should be chosen such that their mitochondria closely match those of the recipient mother. But Mary Herbert, a reproductive biologist at the University of Newcastle, UK, who is part of  a team pursuing mitochondrial replacement , says that mitochondria behave very differently in embryonic stem cells compared to normal human development. Levels of mutant mitochondria can fluctuate wildly in stem cells. \u201cThey are peculiar cells, and they seem to be a law unto themselves,\u201d she says, calling the biological relevance of the latest report \u201cquestionable\u201d. She thinks that data from  embryos cultured for nearly two weeks in the laboratory  will provide more useful information than Egli's stem cell studies. An HFEA spokesperson says that the agency is waiting for further experiments on the safety and efficacy of mitochondrial replacement (including data from Herbert\u2019s team) before approving what could be the world\u2019s first mitochondrial replacement in humans. Egli hopes that the HFEA considers his team\u2019s data. He thinks the problem they identified can be surmounted, for instance, by improving techniques to reduce the level of carried-over mitochondria or matching donors such that their mitochondria are unlikely to compete. Until this is shown for sure, he advocates caution. \u201cI don\u2019t think it would be a wise decision to go forward with this uncertainty.\u201d \n                     US panel greenlights creation of male 'three-person' embryos 2016-Feb-03 \n                   \n                     World hails UK vote on three-person embryos 2015-Feb-10 \n                   \n                     Reproductive medicine: The power of three 2014-May-21 \n                   \n                     Regulators weigh benefits of \u2018three-parent\u2019 fertilization 2013-Oct-15 \n                   \n                     Wide support in UK for novel DNA 'transplants' in human egg cells 2013-Mar-20 \n                   \n                     DNA-swap technology almost ready for fertility clinic 2012-Oct-24 \n                   \n                     UK sets sights on gene therapy in eggs 2012-Jan-24 \n                   Reprints and Permissions"},
{"file_id": "533304a", "url": "https://www.nature.com/articles/533304a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Financial woes of leading biotech firm highlight challenges of developing innovative therapies. Not long ago, investors flocked to a firm in Massachusetts that was hailed as the leader in a wave of next-generation nanotechnology companies developing ways to ferry cancer drugs to tumours. But on 2 May, the company\u00a0\u2014\u00a0BIND Therapeutics\u00a0\u2014\u00a0declared bankruptcy. Researchers in the field of nanomedicine are waiting anxiously to see whether the Cambridge-based firm will pull through its financial crisis \u2014 and whether its troubles will taint the swiftly evolving field of nanoparticle drug delivery. \u201cIt\u2019s been a rapid rise and fall,\u201d says Eric Schmidt, a biotechnology analyst at the investment bank Cowen and Company in New York City. \u201cIt\u2019s all unravelled pretty quickly.\u201d Because nanoparticles lessen the amount of contact that cancer drugs have with healthy tissue, they offer a chance to deliver  higher doses with fewer side effects . In 1995, the US Food and Drug Administration approved the first such treatment, Doxil, which packages a chemotherapy drug called doxorubicin in a lipid nanoparticle. The particles are too large to escape from normal blood vessels \u2014 and so are less toxic to the heart than naked doxorubicin \u2014 but they can seep out of the leaky blood vessels often found in tumours. BIND\u2019s nanoparticles were designed to target tumours more precisely than liposome particles can. The company\u2019s lead product, BIND-014, involves a polymer particle coated with a molecule that steers the particle to a protein found in many tumours. The particle releases the chemotherapy drug it carries, called docetaxel, inside the tumour. Early tests in animals and small clinical trials showed that the approach was safer than docetaxel alone \u2014 and fuelled BIND\u2019s US$70.5-million initial public offering in 2013. But later clinical trials disappointed. BIND-014 failed against cervical and head-and-neck cancers. Although it was somewhat effective against one type of lung cancer, it was not clear whether the drug worked any better than regular docetaxel, says BIND\u2019s chief scientific officer Jonathan Yingling. In April, the company announced that it would cut back on its work with BIND-014, and Yingling says that the firm will now explore new targets. It cut the number of employees by 38% and aims to trim its expenses to $6\u00a0million per quarter \u2014 a dramatic decrease for a company that spent $11 million on research and development alone in the first quarter of 2016. After one of its creditors demanded that BIND repay a loan ahead of schedule, the company filed for bankruptcy (see \u2018Troubled times\u2019). It plans to dispute the need for early repayment at a legal hearing on 18\u00a0May. \u201cBIND is and will remain open for business,\u201d Andrew Hirsch, president of the company, told investors on 9\u00a0May. Schmidt says that BIND remains at the technological forefront of nanoparticle drug delivery, but waited too long to move away from BIND-014. By then, the investor enthusiasm for biotechnology that had driven BIND\u2019s initial public offering had cooled. \u201cPeople are not interested in funding technology right now,\u201d Schmidt says. \u201cThey\u2019re interested in funding later-stage projects. And the one at this company didn\u2019t have what it takes.\u201d In the time since BIND-014 was developed, researchers have also realized that differences between tumours \u2014 such as size, density and leakiness of the blood vessels that lace through them \u2014 can affect how well nanoparticles penetrate them, says Warren Chan, a biomedical engineer at the University of Toronto in Canada. \u201cYou should eventually be able to personalize the nanoparticles to the need,\u201d he says. \u201cIt\u2019s just that we\u2019re not even close to there yet.\u201d \n               Personal approach \n             Omid Farokhzad, who studies nano\u00admedicine at Brigham and Women\u2019s Hospital in Boston, Massachusetts, and is a co-founder of BIND, thinks that companies should determine whether a nanoparticle would penetrate a patient\u2019s tumour before administering the therapy. Farokhzad points to Merrimack Pharmaceuticals, also in Cambridge, which used an imaging agent called ferumoxytol to assess the effects of its liposome-encased chemotherapy in a clinical trial last year. Early results suggested that tumours that took up ferumoxytol were more likely to respond to the nanoparticle-encased drug. Meanwhile, a third generation of nanoparticles is in the works: particles that shuttle larger molecules such as RNAs, says Pieter Cullis, who studies nanomedicine at the University of British Columbia in Vancouver, Canada. Cullis has been working with Alnylam, a biotechnology firm also in Cambridge, to develop nanoparticles that  deliver therapeutic RNA molecules to the liver . The excitement over gene-editing techniques such as CRISPR\u2013Cas9, which could one day be used to correct disease-causing genes, is also fuelling interest in using nanoparticles to shuttle in the RNAs and proteins needed for the method, he says. But some are worried that BIND\u2019s struggles could frighten investors away from the field. Mark Davis, a chemical engineer at the California Institute of Technology in Pasadena, is quick to note that other nanoparticles are showing promise. Last month, Celator Pharmaceuticals of Ewing, New Jersey, announced that its liposome-wrapped chemotherapies are effective against a form of leukaemia. And Cerulean Pharma of Waltham, Massachusetts \u2014 a company that Davis co-founded \u2014 is making a polymer-based, targeted nanoparticle that has shown promising results in early trials when combined with other chemotherapies. \u201cI personally would be shocked if 20 years from now, we\u2019re not seeing a lot of nanotechnologies helping a lot of people,\u201d says  Robert Langer , a bioengineer at the Massachusetts Institute of Technology and a co-founder of BIND. \u201cIt will happen.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Science expresses concern over controversial chemistry paper 2016-Jan-21 \n                   \n                     Nanoparticles disguised as blood-cell fragments slip past body's immune defence 2015-Sep-16 \n                   \n                     The tiniest Lego: a tale of nanoscale motors, rotors, switches and pumps 2015-Sep-02 \n                   \n                     Stealth nanoparticles sneak past immune system\u2019s defences 2013-Feb-21 \n                   \n                     National Institutes of Health: Drug delivery systems \n                   \n                     BIND Therapeutics \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19871", "url": "https://www.nature.com/articles/nature.2016.19871", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Many publications did not reapply after leading directory tightened its quality criteria. A leading index of open-access journals is set to shrink by more than one-quarter after delisting around 3,300 titles as part of an effort to exclude questionable and inactive publishers. The  Directory of Open Access Journals (DOAJ) , which at the beginning of the year listed more than 11,000 open-access academic journals, announced two years ago that  it would be tightening its standards for inclusion . It asked every journal in its index to provide more details about their operations so it could ensure that they adhere to  basic publishing standards . The crackdown came after the index was criticized for including \u2018 predatory publishers \u2019 \u2014 journals that profess to publish articles openly, often after charging fees, but that are either outright scams or do not provide expected services such as a minimal standard of peer review or archiving. The DOAJ is  now striking off journals  that did not submit the necessary paperwork in time, says Lars Bj\u00f8rnshauge, the directory\u2019s managing director. He says that he is \u201cabsolutely sure\u201d that the majority of the journals that did not reapply are not publications with poor ethics; rather, he thinks, they are small outfits that are unfamiliar with providing the information  required for reapplication . Some 6,700 journals have reapplied, and Bj\u00f8rnshauge thinks that most of them will pass. Many of the journals that failed to reapply claimed to be based in the United States. But after investigating publishers\u2019 claims about where they are based, the DOAJ suspects that some in fact operate from other countries, says Dominic Mitchell, community manager for the directory. \n             Improving trust \n           The tightened policy is a \u201chuge improvement\u201d, says Walt Crawford, a retired library-systems analyst in Livermore, California, who is currently analysing DOAJ-listed journals. \u201cI believe DOAJ will be a reasonably trustworthy source of journals that at least intend to do honest, serious open access.\u201d If anything, he says, he worries that legitimate journals may be omitted. But Jeffrey Beall, a librarian at the University of Colorado, Denver, who assembled  a blacklist  of open-access journals that he terms \"potential, possible or probable\" predatory publishers,\u00a0fears that the index still contains weak publications. A problem with \u2018whitelists\u2019 such as the DOAJ\u2019s, he says, is that they rely on data supplied by publishers, which might exaggerate or misstate information to make their journals look more attractive. Bj\u00f8rnshauge agrees that there are publishers that cheat authors; the DOAJ has supported an  educational campaign  and plans to hire almost a dozen  \u2018ambassadors\u2019  to identify questionable publishers and to promote good publishing practices across the developing world, he says. Assessing journals on a case-by-case basis should be straightforward, says Crawford. \u201cMy guess is that most scholars can figure out whether a journal is an appropriate outlet with 10\u201315 minutes work.\u201d The number of open-access journals is soaring: the DOAJ gets about 80 applications every week, Bj\u00f8rnshauge says, and over the past 2 years it has rejected about 5,400 applications, most of them new applicants.\u00a0Lack of information about licensing rights, publication permissions and editorial transparency are all important issues in rejecting publications, he says. Whitelists such as the DOAJ and blacklists like Beall\u2019s are not the only tools to make sense of open-access journals. Some crowdsourced efforts \u2014 such as Journalysis.org \u2014  ask academics to review journals . The most recent of these, a website called  QOAM  (Quality Open Access Market)\u00a0asks volunteers with academic credentials to evaluate a journal\u2019s policies and to describe their experience if they published with the journal \u2014 and then sorts journal titles into one of four categories, including \u201cthreat to authors\u201d.\u00a0 \u201cWe go beyond what the DOAJ does to allow the stakeholders to rank the journals,\u201d says Jelte Wicherts, who studies publication bias and data sharing at Tilburg University in the Netherlands and who helped to develop the QOAM scoring system. He thinks that there are reliable proxies \u2014 notably the transparency of a peer review system \u2014 that can be used to gauge the quality of a journal 1 . Such crowdsourced systems can fall prey to extreme minority views, and to being gamed by pro-journal reviewers, unless many disinterested authors can be persuaded to take part, points out Bj\u00f8rnshauge. Beall, too, is sceptical that a crowdsourced effort can take off. But it should be given a chance to succeed, he says. \u201cIt's great that there\u2019s experimentation going on.\u201d \n                   Rate that journal 2015-Mar-30 \n                 \n                   Open-access website gets tough 2014-Aug-06 \n                 \n                   Investigating journals: The dark side of publishing 2013-Mar-27 \n                 \n                   Price doesn't always buy prestige in open access 2013-Jan-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19862", "url": "https://www.nature.com/articles/nature.2016.19862", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Breakdown product of drug reduces signs of depression in mice without side effects. The popular club drug ketamine \u2014 or 'Special K' \u2014 is also a fast-acting antidepressant, but how it works has eluded scientists. Now a team reports in  Nature 1  that the mood-lifting effect may not be caused by the drug itself, but by one of the products formed when the body breaks the drug down into smaller molecules. If the findings, from a study in mice, hold true in humans, they could suggest a way to provide quick relief for people with depression \u2014 without patients having to experience ketamine\u2019s \u2018high\u2019. Such a drug would be welcome news to the  many people with major depressive disorder who do not find relief  in currently available antidepressants. Ketamine also  eases depression in a matter of hours , whereas other drugs take weeks to reach their full effect. \u201cThe whole field has become interested in ketamine,\u201d says Todd Gould, a neuroscientist at the University of Maryland School of Medicine in Baltimore who led the study. \u201cIt does something different in patients than any other drug we have available.\u201d But ketamine has its drawbacks: some people are turned off by the high \u2014 a feeling of dissociation and sensory distortion that lasts for about an hour. For others, the effect is an incentive to misuse the drug. Ketamine is not yet approved to treat depression in the United States, but ketamine clinics have sprung up around the country to administer it off-label. Researchers have been racing to find other drugs that produce ketamine\u2019s antidepressant effects without the high, but have been struggling to do so without a clear idea of how ketamine fights depression. Many of those efforts have focused on drugs that target cellular receptors in the brain called NMDA receptors. These were thought to be ketamine\u2019s target, but clinical trials of other drugs that target them have largely yielded disappointing effects on depression, says Gould. \n             Metabolic lift \n           \u201cKetamine probably represents a new chapter in the treatment of depression,\u201d says Roberto Malinow, a neuroscientist at the University of California, San Diego. \u201cBut there have been some big questions regarding how it works.\u201d Gould teamed up with clinicians, analytical chemists, and neurophysiologists to fill in the gaps in understanding. Gould and his colleagues used a battery of behavioural tests in mice to show that one of ketamine's breakdown products \u2014 a compound called ( 2R,6R )-hydroxynorketamine \u2014 is responsible for much of the drug\u2019s antidepressant effects. And to Gould\u2019s surprise, the metabolite did not cause side effects in the mice even at doses nearly 40 times higher than the antidepressant dose of ketamine. The mice also did not tend to press a lever to receive the metabolite when given the option to self-administer it. The researchers plan to gather the safety data needed to take the metabolite into clinical testing in humans, a process that Gould cautions could still take years. But Husseini Manji, head of neuroscience research and development at Janssen Pharmaceutical Companies in Titusville, New Jersey, cautions against assuming that results in mice will bear out in humans. \u201cWe have to keep reminding ourselves that clinical data trump rodent data,\u201d he says. Janssen has developed a specific form of ketamine, called esketamine, that it is testing in five large clinical trials. \n             Receptive targets \n           Gould\u2019s study in mice held another surprise: the metabolite that is active in mice did not act through NMDA receptors. The group did not find its direct target, but did find evidence that it stimulates another set of receptors called AMPA receptors. If the same result holds true in humans, it could provide an explanation for why drugs that target NMDA receptors have failed to capture ketamine\u2019s full effects. \u201cThis could shake the windows and rattle the walls of those companies that have been putting a lot of money into this research,\u201d says Malinow. Manji, who describes the study as elegant, is not ready to give up on NMDA receptors until the results have been borne out in human studies. But he is among the researchers who believe that AMPA receptors may be important as well. Janssen and others have been pursing those receptors and proteins associated with them as potential drug targets. \u201cThis paper gives us even more impetus to go after them,\u201d says Manji. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Brain study seeks roots of suicide 2015-Nov-25 \n                 \n                   Ayahuasca psychedelic tested for depression 2015-Apr-06 \n                 \n                   Rave drug holds promise for treating depression fast 2015-Jan-07 \n                 \n                   Medical research: If depression were cancer 2014-Nov-12 \n                 \n                   World Health Organization: Depression \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19866", "url": "https://www.nature.com/articles/nature.2016.19866", "year": 2016, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Machine-learning approach mines unpublished 'dark' reactions that don't work, as well as ones that do. Did your experiment fail? Don\u2019t bin the data just yet \u2014 they could be useful. Chemists in the United States say that they have created a machine-learning algorithm that beats humans at predicting ways to make crystals, by training it on data both from successful experiments and from trials that didn\u2019t work. The team terms these failures \u2018dark reactions\u2019, because they are either never written down or are recorded only privately in laboratory notebooks. \u201cFailed reactions contain a vast amount of unreported and unextracted information,\u201d says Alex Norquist, a materials-synthesis researcher at Haverford College in Pennsylvania, who is part of the team that has reported the work in  Nature 1 . \u201cThere are far more failures than successes, but only the successes generally get published.\u201d\u00a0 The work \u201cshows a great example of what can be done by mining scientific experience \u2014 to start unravelling the \u2018dark magic\u2019 of synthesis\u201d, says Kristin Persson, a materials chemist at the Lawrence Berkeley National Laboratory in California. She leads an  initiative called the Materials Project  that gathers information on known materials to aid the design and synthesis of new ones. \n             Learning from dark data \n           Several researchers are creating  algorithms that learn from past experiments how to make new molecules , with the idea that computers might be able to glean patterns from reaction data more effectively than a human can 2 . The idea has been pursued for years in drug synthesis to find the most efficient route of making a complex molecule in multiple reaction steps. The Haverford team of materials scientists, co-led by Norquist, Sorelle Friedler and Joshua Schrier, set themselves a slightly simpler goal: simply to predict whether a particular set of reagents will, when mixed in a solvent and heated, produce a crystalline material. To narrow down their task further, they looked only at materials called templated vanadium selenites: compounds of vanadium, selenium and oxygen, in which small organic molecules, such as amines, guide (or 'template') the arrangement of the elements. (These particular crystals don't currently have a commercial use, but are being studied for their unusual interactions with light).\u00a0 The researchers adopted a standard machine-learning approach. They trained an algorithm on data from almost 4,000 attempts to make the crystals under different reaction conditions (such as temperature, concentration, reactant quantity and acidity). That work included transcribing information on dark, failed reactions from the team\u2019s archived lab notebooks into a format that a machine could analyse. Then they asked the computer to pick out principles that separated successful experiments from failures. \n             Decision tree \n           To test the algorithm, the team picked out previously untried combinations of reactants, and tried to guess the best processing conditions for making selenite materials. The reaction conditions suggested by the algorithm generated a crystalline product in 89% of around 500 cases. By comparision, using intuition and rules of thumb developed from more than ten accumulated years of experience with the materials, the researchers' own best guesses were successful only 78% of the time. The algorithm doesn\u2019t make clear its reasoning, so the chemists converted the results into handy rules of thumb which they rendered as an intuitive \u2018decision tree\u2019 that scientists can use for guidance in the lab. It involves questions such as 'Is sodium present?' and 'Is the pH greater or less than 3?'. The team has set up a website, called the  Dark Reactions Project , to encourage others to share \u2014 in a machine-readable format \u2014 their own failed attempts to make new crystals. One barrier to sharing is that other chemists' data might not take the same form as their own, Norquist says \u2014 but the researchers hope to be able to adjust the interface of their site to \"accommodate the idiosyncrasies of others\u2019 data\u201d, he says. \"The planning and development of such tools is essential if we are to eventually make full use of our 'failed' experiments,\" adds Richard Cooper, a crystallographer at Oxford University, UK. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Can artificial intelligence create the next wonder material? 2016-May-04 \n                 \n                   Chemistry: Why synthesize? 2015-Dec-16 \n                 \n                   Complex molecules made to order in synthesis machine 2015-Mar-12 \n                 \n                   Organic synthesis: The robo-chemist 2014-Aug-06 \n                 \n                   Technology: Sharing data in materials science 2013-Nov-27 \n                 \n                   Dark Reactions Project \n                 Reprints and Permissions"},
{"file_id": "533015a", "url": "https://www.nature.com/articles/533015a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Embryos cultured for up to 13 days after fertilization open a window into early development. Developmental biologists have grown human embryos in the lab for up to 13 days after fertilization, shattering the previous record of 9 days. The achievement has already enabled scientists to discover new aspects of early human development, including features never before seen in a human embryo. And the technique could help to determine why some pregnancies fail. The work, reported this week in  Nature 1  and  Nature Cell Biology 2 , also raises the possibility that scientists could soon culture embryos to an even more advanced stage. Doing so would  raise ethical , as well as technical, challenges. Many countries and scientific societies ban research on human embryos that are more than 14 days old; in light of this, the authors of the studies ended their experiments before this point. Scientists have well understood the earliest stages of life in many other animals for decades. \u201cIt\u2019s really embarrassing at the beginning of the twenty-first century that we know more about fish and mice and frogs than we know about ourselves,\u201d says Ali Brivanlou, a developmental biologist at the Rockefeller University in New York City and lead author of the study in  Nature . \u201cThis is a bit difficult to explain to my students.\u201d Magdalena Zernicka-Goetz, a developmental biologist at the University of Cambridge, UK, and her colleagues developed the culture technique using mouse embryos. Many scientists have attempted to simulate conditions in the womb by growing embryos on a layer of maternal cells, but Zernicka-Goetz\u2019s group chose instead to use a gel matrix with higher levels of oxygen. The mouse embryos survived past gastrulation \u2014 the stage at which they form layers of cells that will become organs 3 . \u201cIt\u2019s incredible to look at,\u201d Zernicka-Goetz says. \n               Human insight \n             In  Nature Cell Biology , she and her colleagues describe how they adapted the technique to work for human embryos donated by an  in vitro  fertilization (IVF) clinic 2 . Zernicka-Goetz and Brivanlou tracked the embryos\u2019 progress by comparing the genes that they expressed with those expressed in other animal embryos at similar stages 1 . The scientists were able to evaluate the embryos\u2019 structural development using data from a 1956 study in which researchers examined embryos found in women undergoing hysterectomies and other procedures 4 . The teams watched as the cells in the embryos began to differentiate \u2014 and reveal features that are unique to human development. For instance, Brivanlou and his colleagues have identified a group of cells that shows up in the embryo around day 10 and disappears around day 12. The scientists don\u2019t yet know the function of the cell cluster, which, at its peak, forms 5\u201310% of the embryo. But it seems to be a transient organ, akin to the tails that human embryos grow much later in development and then lose before birth. \u201cThis is like discovering a new organ in your body,\u201d Brivanlou says. The culture method has also revealed vast differences between the genes expressed in human and mouse embryos, which suggests that rodents may not be good models for understanding human development. The culture technology is likely to be of broad interest to scientists. Martin Pera, a stem-cell researcher at the University of Melbourne in Australia, says that studying embryos  in vitro  could help researchers who are trying  to grow stem cells into embryo-like structures  to judge the accuracy of their work. Once that feat is achieved, scientists could use these structures to conduct larger and more-complicated experiments to explore topics such as the development of birth defects or the effects of toxic compounds. The fertility industry could also benefit from new  in vitro  technology. Norbert Gleicher, head of the Center for Human Reproduction, an IVF clinic in New York City, notes that about 50% of embryos that implant into a mother\u2019s uterus do not survive. Studies of embryos  in vitro  could help researchers to understand what goes wrong in such cases. \u201cThe implantation process is a big black box for us clinicians,\u201d says Gleicher, who has collaborated with Brivanlou. Gleicher was not involved in the latest work, but he is beginning to use the  in vitro  culture method to study how to evaluate the viability of embryos for implantation in IVF clinics. The ability to grow an embryo  in vitro  for 13 days raises ethical and policy considerations. At least 12 countries, including the United Kingdom, bar scientists from working with embryos older than 14 days. The US government drew up guidelines suggesting the limit in 1979, on the basis that 14 days marks the beginning of gastrulation in humans. It is also around the latest point at which an embryo can split into identical twins. After this time, the logic goes, a unique individual comes into being. Zernicka-Goetz and Brivanlou doubt that their embryos would survive much beyond the 14-day mark, because work in mice suggests that more-developed embryos need an unknown mix of hormones and nutrients from the mother to survive. To develop further, the embryos might also require a 3D scaffold to grow on, rather than the flat plates used in the initial tests. To learn more, the researchers are beginning to run experiments with embryos from non-human primates and from cows. But their achievements in the lab may be grounds for re-examining the limit, says George Daley, a stem-cell researcher at Children\u2019s Hospital Boston in Massachusetts. He says that it is somewhat arbitrary. Such a debate would be complex and heated, and it could reach beyond researchers working directly with human embryos. If scientists succeed in growing stem cells into embryo-like structures, it could be difficult to determine whether the structures count as embryos, and thus are subject to the 14-day rule 5 . \u201cIt\u2019s an interesting ethical discussion we\u2019ve got ahead of us here,\u201d says Pera. However it plays out, Brivanlou says that the new technology will give developmental biologists plenty to work on. \u201cEvery hour as we move forward in development is a treasure box for me,\u201d he says. See also  Comment  and  News & Views \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @Sara_Reardon \n               \n                     Human embryology: Implantation barrier overcome 2016-May-04 \n                   \n                     Embryology policy: Revisit the 14-day rule 2016-May-04 \n                   \n                     The boom in mini stomachs, brains, breasts, kidneys and more 2015-Jul-29 \n                   \n                     Rudimentary egg and sperm cells made from stem cells 2014-Dec-24 \n                   \n                     Policy: Regulate embryos made for research 2014-Apr-28 \n                   \n                     Embryo screening 'doesn't improve' pregnancy success 2007-Oct-17 \n                   \n                     IVF embryos meet contrasting fates 2004-Aug-27 \n                   \n                     Ali Brivanlou \n                   \n                     Magdalena Zernicka-Goetz \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19864", "url": "https://www.nature.com/articles/nature.2016.19864", "year": 2016, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Scholars excited by depiction of actual objects on the body of a 3,000-year-old woman. A mummy from ancient Egypt was heavily tattooed with sacred symbols, which may have served to advertise and enhance the religious powers of the woman who received them more than 3,000 years ago. The newly reported tattoos are the first on a mummy from dynastic Egypt to show actual objects, among them lotus blossoms on the mummy\u2019s hips, cows on her arm and baboons on her neck. Just a few other ancient Egyptian mummies sport tattoos, and those are merely patterns of dots or dashes. Especially prominent among the new tattoos are so-called wadjet eyes: possible symbols of protection against evil that adorn the mummy\u2019s neck, shoulders and back. \u201cAny angle that you look at this woman, you see a pair of divine eyes looking back at you,\u201d says bioarchaeologist Anne Austin of Stanford University in California, who  presented the findings  last month at a meeting of the American Association of Physical Anthropologists. Austin noticed the tattoos while examining mummies for the French Institute of Oriental Archaeology, which conducts research at Deir el-Medina, a village once home to the ancient artisans who worked on tombs in the nearby Valley of the Kings. Looking at a headless, armless torso dating from 1300 to 1070  bc , Austin noticed markings on the neck. At first, she thought that they had been painted on, but she soon realized that they were tattoos. \n               Hidden history \n             Austin knew of tattoos discovered on other mummies using infrared imaging 1 , which peers more deeply into the skin than visible-light imaging. With help from infrared lighting and an infrared sensor, Austin determined that the Deir el-Medina mummy boasts more than 30 tattoos, including some on skin so darkened by the resins used in mummification that they were invisible to the eye. Austin and C\u00e9dric Gobeil, director of the French mission at Deir el-Medina, digitally stretched the images to counter distortion from the mummy\u2019s shrunken skin. The tattoos identified so far carry powerful religious significance. Many, such as the cows, are associated with the goddess Hathor, one of the most prominent deities in ancient Egypt. The symbols on the throat and arms may have been intended to give the woman a jolt of magical power as she sang or played music during rituals for Hathor. The tattoos may also be a public expression of the woman\u2019s piety, says Emily Teeter, an Egyptologist at the University of Chicago\u2019s Oriental Institute in Illinois. \u201cWe didn\u2019t know about this sort of expression before,\u201d Teeter says, adding that she and other Egyptologists were \u201cdumbfounded\u201d when they heard of the finding. Some tattoos are more faded than others, so perhaps some were made at different times. This could suggest that the woman\u2019s religious status grew with age, Austin says. \n               Penetrating gaze \n             She has already found three more tattooed mummies at Deir el-Medina, and hopes that modern techniques will uncover more elsewhere. Even infrared imaging can\u2019t penetrate an intact mummy\u2019s linen binding. But a nineteenth-century penchant for unwrapping mummies could enable the discovery of more tattoos, says Marie Vandenbeusch, a curator at the British Museum in London. Such examples could provide needed evidence \u201cto really pinpoint the use of those tattoos\u201d, she says. Austin argues that the scale of the designs, many of them in places out of the woman\u2019s reach, implies that they were more than simple adornment. The application of the tattoos \u201cwould\u2019ve been very time consuming, and in some areas of the body, extremely painful\u201d, Austin says. That the woman subjected herself to the needle so often shows \u201cnot only her belief in their importance, but others around her as well\u201d.\n \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Image software spots links in tattoo ink 2015-Jun-09 \n                   \n                     Mummies reveal that clogged arteries plagued the ancient world 2013-Mar-11 \n                   \n                     Ancient DNA: Curse of the Pharaoh's DNA 2011-Apr-27 \n                   \n                     Anne Austin \n                   \n                     British Museum: Tattoos in ancient Egypt and Sudan \n                   \n                     University College London: Tattoos in ancient Egypt \n                   Reprints and Permissions"},
{"file_id": "533019a", "url": "https://www.nature.com/articles/533019a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Space-based detector draws interest, but regulatory hurdles might complicate a partnership. In the wake of the historic detection of gravitational waves by a terrestrial US experiment, a space-borne European effort is drawing interest from a range of parties. But although advisers to the European Space Agency (ESA) recommended increasing international contributions to the billion-euro gravitational-wave detector on 12\u00a0April, regulatory hurdles may hinder proposed partnerships with the United States and China. In February, researchers working on the US-based  Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO)  announced that they had detected ripples in space-time that had been produced by the merger of two black holes. The space-based observatory planned by ESA would be able to detect ripples with much lower frequencies than would be possible on Earth, bringing into view a greater variety of astronomical events, including mergers between supermassive black holes. Such a detector is widely seen as \u201cthe best thing you could do in gravitational waves\u201d, says Robin Stebbins, an astrophysicist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland.  After a mission to test crucial technologies for the observatory  proved successful, the ESA advisory team last month concluded that not only are the agency\u2019s plans feasible, but also that the launch could even be brought forward, from 2034 to 2029. Initially, NASA and ESA were partners in the effort, but funding issues led NASA to pull out in 2011. The US space agency has since stated that it wants only a minor role in the observatory. But excitement around the LIGO findings mean that US scientists are keen for NASA to become an equal partner again, says Rainer Weiss, a physicist at the Massachusetts Institute of Technology in Cambridge who was instrumental in creating LIGO. Stebbins expects that the committee tasked with assessing progress on the US decadal review, which decides the priorities of NASA and other funding agencies,will express support for a larger role in the ESA observatory later this month. But such a role might require NASA to find more money before the next review, in 2020, and that would mean either diverting money away from other projects or persuading the US Congress to give it more. Any plan to cooperate with ESA on an equal footing could also come up against ESA\u2019s policy of capping international contributions to large missions at 20% to stop projects from falling apart if a partner pulls out. It is too early in discussions to know whether the policy will present a problem, says Fabio Favata, head of science planning and community coordination at ESA. The United States is not the only country seeking to capitalize on the LIGO breakthrough. Japan\u2019s gravitational-wave community is also looking for a way to contribute to the ESA mission. And  Chinese scientists have expressed interest for several years  now, says Stebbins. They could provide financial or in-kind contributions to the ESA mission in exchange for technical know-how, he says. US participation could also complicate any potential collaboration between ESA and China. An amendment to US law introduced in 2011 blocks NASA scientists from working directly with Chinese counterparts under almost all circumstances. Stebbins\u2019s superiors have told him that the law applies to bilateral collaboration, so it might not apply to a collaboration with ESA that also includes China. But Congress might try to prevent this kind of collaboration anyway, says Brian Weeden, the technical adviser for the Secure World Foundation in Washington DC, which promotes the peaceful use of outer space. And Congress\u2019s scepticism of collaboration with China could stop NASA scientists from even trying to participate. That the gravitational-wave detector is purely a science mission may reassure Congress, Weeden adds. \u201cThere may be less concern over that type of cooperation than there would be on cooperation with a more political component, such as human spaceflight.\u201d China is a growing space power  \u2014 it is scheduled to launch several high-profile space-science missions this year \u2014 so the United States will eventually work with China in some capacity, Weeden says. And that would probably be through some kind of multilateral project, he thinks. \u201cThe challenge is finding a topic that both the United States and China want to work on. I think the gravitational-wave detector could be one of those.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n                 Follow @LizzieGibney \n               \n                     Chinese gravitational-wave hunt hits crunch time 2016-Mar-09 \n                   \n                     Successful test drive for space-based gravitational-wave detector 2016-Feb-25 \n                   \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     China\u2019s dark-matter satellite launches era of space science 2015-Dec-17 \n                   \n                     Freefall space cubes are test for gravitational wave spotter 2015-Nov-17 \n                   \n                     US row threatens Chinese links 2011-Oct-18 \n                   \n                     Nature  special: Gravitational waves \n                   \n                     Gravitational Observatory Advisory Team report \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19875", "url": "https://www.nature.com/articles/nature.2016.19875", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Nature  rides along on an international research mission to sample South Korean air quality. Korean Peninsula The turbulence on this flight is intense. To take a picture I\u2019m forced to crawl to the window, alternately wobbling on my knees and pinned to the floor in between millions of dollars of scientific kit. But the view is worth it \u2014 I\u2019ve never seen Seoul like this. Just 300 metres above the Han River, we are headed straight over Gangnam, one of Seoul\u2019s busiest areas, participating in one of the most comprehensive air-quality studies ever attempted. This bumpy ride means that our NASA research aeroplane has descended into the boundary layer, the lowest part of the atmosphere where heat and friction from the ground affects the wind, and cause the air to swirl. And that means the plane is now sampling pollution from the ground that has been carried up into the air. The readings it takes could help to bring some clarity to a long-standing source of tension with China \u2014 understanding how much pollution and dust drifts over from that country, and how much is home-grown in South Korea. In the spring, westerly winds from China drift over the peninsula, carrying not only pollution but also hazardous yellow dust kicked up from the deserts of Mongolia and Northern China. These dust particles\u00a0are small enough to get into lungs and cause respiratory illnesses. Data from the state-run Korea Environment Corporation showed that in April, levels of PM 10 \u2014a measure of small dust particles\u2014in downtown Seoul exceeded safe levels of 80 micrograms (\u03bcg) per cubic metre on 20 days, peaking at more than 400 \u03bcg per cubic metre on 24 April. A 2011 study commissioned by the city of Seoul concluded the problem comes roughly equally from local sources and countries upwind of South Korea, notably China. In Korea, many single out the contribution of Chinese industry, but environmental group Greenpeace has claimed that as much as 70% of some types of pollution originate locally. The NGO says South Korea\u2019s government has in the past focused on China\u2019s contribution to shift the blame from its own failing to tackle home-grown pollution sources. Some in South Korea are also growing frustrated with the unreliability of national forecasts of particulate matter. Current forecasts are accurate only 60% of the time, You-Deog Hong of South Korea\u2019s National Institute of Environmental Research (NIER) in Incheon said at a 29 April press briefing at the US air base near Osan where the NASA plane is based for this project. \n             Air support \n           South Korea makes for a \u201cnatural air quality laboratory\u201d, says James Crawford of NASA's Langley Research Center in Hampton, Virginia, who is the US lead scientist on the international Korean air-quality study, known as KORUS-AQ. The Yellow Sea between China and the Korean peninsula acts as a natural divider, allowing scientists to measure China\u2019s contribution over the water before it mixes with South Korea\u2019s air. All told, KORUS-AQ involves more than 580 researchers from 72 institutions, three planes, two ships and 300 ground-based monitoring sites. The DC-8 research plane NASA is operating is cleared to fly at low altitudes across the peninsula \u2014 both in rural areas and through the urban heart of Seoul, which is crucial to understanding how urban emissions and emissions from plants and agriculture mix. \u201cThis way of flying is entirely new to the way this field works,\u201d says Crawford. He has previously led the DC-8 on studies based in Asia, but those were only cleared to operate over the Pacific. \u201cYou couldn't go to the source; you couldn't measure directly.\u201d On a typical flight, the NASA plane will fly up and down the length of the Yellow Sea at varying altitudes, sampling the air with 25 instruments operated by dozens of scientists on board \u2014 then repeat the run over the Korean peninsula, flying as low as 300 metres. The scale of the project dwarfs all previous, similar air-quality studies in South Korea, says Jeong-Hoo Park of the NIER. The last one, 14 years ago, involved \u201cjust three ground sites and one small airplane\u201d, he says. The new data will significantly improve understanding of atmospheric chemistry, particularly how gas-phase pollutants interact with particulate matter \u2014 the biggest weakness in these forecasts, says Lee Tae Sik, an atmospheric chemist at the Korea Polar Research Institute in Incheon. \"Nowadays the weather forecasting is quite good, which means we understand more or less the physics, the meteorology,\u201d Sik says. \"But still we need some knowledge about the chemistry, especially between the solid phase and the gas state.\" It could lay some groundwork for South Korean negotiations with China about the pollution issue, says Sik. \u201cIf this kind of collaboration project gives us some result, then China will pay attention.\u201d \n             Dust in the wind \n           After passing over Seoul, the 4 May flight I\u2019m on heads for the Yellow Sea. Near the southwest coast of Korea, we start descending to the surface, buzzing Chinese fishing boats every few minutes. \u201cToo low! Terrain!\u201d blares an automated voice as we dip below 200 metres. \u201cToo low! Terrain!\u201d Co-pilot David Fedors calmly turns the alarm off.\u00a0 Back in the cabin, spiking instrument readings indicate that we\u2019re flying through plumes of Chinese pollution. The researchers consult with each other, debating which altitude to take for the next pass. Just another day chasing dust. \n                   Atmospheric chemistry: China\u2019s choking cocktail 2015-Oct-21 \n                 \n                   Environmental science: Pollution patrol 2015-Jan-07 \n                 \n                   Air pollution: Clean up our skies 2014-Nov-19 \n                 \n                   Air quality to suffer with global warming 2014-Jun-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19876", "url": "https://www.nature.com/articles/nature.2016.19876", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Silicone polymer mimics youthful elasticity of skin. Materials scientists working with cosmetics firms have developed a transparent film that, for the first time, mimics the skin\u2019s youthful elasticity. The silicone-based coating can be smeared onto the face or other areas of the body through two gel applications. Once hardened, it clings closely to the skin for more than 16 hours, says Robert Langer, a bioengineer at the Massachusetts Institute of Technology in Cambridge, who co-led development of the material. The film \u2014 which Langer\u2019s team dubs \u2018second skin\u2019 \u2014 can reduce the appearance of bags under the eyes and wrinkles, and can increase the elastic recoil of skin when it is pinched, he and colleagues report in a paper published in  Nature Materials 1 . It also acts as a barrier that prevents water loss from dry skin, they report, suggesting that besides its cosmetic use, the film might offer an alternative to greasy ointments for people with skin complaints such as eczema, although it hasn't yet been trialled for that idea. A version of the film has been on sale as a daily treatment through dermatologists since 2014, marketed by a firm called Living Proof in Cambridge, Massachusetts, that Langer co-founded \u2014 and which film star Jennifer Aniston has invested in. (Beauty bloggers writing about the product two years ago said that it was like \u2018shapewear for skin\u2019.) Langer calls that product a \"very early version\" of the material described in the research paper, which marks the first time that the film has been detailed in the scientific literature. \u201cUp until now, there has been nothing that could restore the elastic property of skin, and this material does that,\u201d says Barbara Gilchrest, a dermatologist at Harvard Medical School in Boston, Massachusetts, and a co-author of the report. John Rogers, a biomaterials scientist at the University of Illinois at Urbana\u2013Champaign, says that the team\u2019s results are \u201cimpressive\u201d. The team screened more than 100 variant polymers to create the elastic yet transparent film. Users first smear on a gel-like polymer that is based on siloxanes (chains of molecules containing silicon and oxygen), and then add another gel that contains a platinum-based catalyst. This cross-links the polymer chains together to toughen up the material \u2014 effectively \u2018setting\u2019 the film \u2014 which is only 40\u201370 micrometres thin; Langer says it is \"essentially invisible\". \u201cIt\u2019s not a cure for eye bags and wrinkles \u2014 it\u2019s more like transparent make-up,\u201d says Ardy Bayat, a specialist in skin biology and regeneration at the University of Manchester, UK. By changing the chemical formulation of the film or the way that is applied, it may also be possible to use it for medical applications, says Langer \u2014 such as to hydrate dry skin, or to trap anti-inflammatory corticosteroids on the skin\u2019s surface, thereby enhancing their absorption. He is advising another firm called Olivo Labs, a spin-off from Living Proof and also in Cambridge, that will focus on these ideas. \n                   Wearable sweat sensor paves way for real-time analysis of body chemistry 2016-Jan-27 \n                 \n                   The inside story on wearable electronics 2015-Dec-01 \n                 \n                   \u2018Electronic skin' equipped with memory 2014-Mar-30 \n                 \n                   Profile: Being Bob Langer 2009-Mar-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19863", "url": "https://www.nature.com/articles/nature.2016.19863", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Ancient alga developed large size and complex structure independently of other plants. A mysterious deep-ocean seaweed diverged from the rest of the green-plant family around 540 million years ago, developing a large body with a complex structure independently from all other sea or land plants. All of the seaweed\u2019s close relatives are unicellular plankton. The finding, published today in  Scientific Reports 1 , upends conventional wisdom about the early evolution of the plant kingdom. \u201cPeople have always assumed that within the green-plant lineage, all the early branches were unicellular,\u201d says Frederik Leliaert, an evolutionary biologist at Ghent University in Belgium. \u201cIt is quite surprising that among those, a macroscopic seaweed pops up.\u201d There are only a few described species in this odd order of sea life, known as the Palmophyllales. All live at great depth, usually more than 80 metres below the surface. Five years ago, Leliaert was one of the team that first investigated the order\u2019s genetics. But even though it looked superficially like many green algae, the seaweed turned out to be only very distantly related to any other macroscopic green algae or land plant 2 . At this point, the scientists could do little more than show that the species was very different. Now the researchers have mapped the strange seaweed\u2019s place in the tree of life, using a specimen dredged from the Gulf of Mexico after the 2010 Deepwater Horizon oil spill. The work became more feasible as next-generation sequencing technologies dropped the price for a detailed look at the genome of Palmophyllales' chloroplast \u2014 the energy-producing structure in a plant cell \u2014 to roughly US$8,000. \n             Green genes \n           With more genes in hand, the scientists could better compare Palmophyllales to an ever-growing collection of green algae. It also allowed the researchers to use phylogenetic software to pinpoint when Palmophyllales branched off from related plant species. It turns out that the group diverged from the rest just after the green plants themselves split into their two main lineages, back when such plants were newfangled upstarts. Brent Mishler, a botanist at the University of California, Berkeley, finds the new work to be convincing. \u201cIt nails down the relationships,\u201d he says. \u201cThe green plants are one of the most diverse branches on the tree of life, with a half million species that range in size from planktonic unicells to redwood trees. This paper makes a huge contribution to unravelling how this enormous and important lineage got started.\u201d But although Palmophyllales split off early from other plants, its macroscopic size might not have developed until later in its evolution. And Leliaert says that he\u2019s wary of calling the seaweed \u201cmulticellular\u201d because its cells are undifferentiated and suspended in a stiff gel. Still, he says, the whole plant has a distinct structure that includes a root-like holdfast, a stem, and blades. How the cells of the plant communicate with one another remains unknown. For Charles Delwiche, a molecular systematist at the University of Maryland in College Park, and one of the principal investigators of the  Assembling the Green Algal Tree of Life  project that supported the work, the result shows how little is known about green algae, despite the fact that they gave rise to all land plants. \u201cWe still need to do a lot more sampling of those lineages,\u201d says Delwiche. \u201cI think the tree of life will become a lot more shrubby.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   How the first plant came to be 2012-Feb-16 \n                 \n                   When Earth greened over 2009-Jul-08 \n                 \n                   Scientists identify algae that almost swamped the Olympics 2008-Aug-04 \n                 \n                   Ancient algal mixup sorted 2007-Dec-20 \n                 \n                   Assembling the Green Algal Tree of Life \n                 \n                   Frederik Leliaert \n                 \n                   Brent Mishler \n                 \n                   Charles Delwiche \n                 Reprints and Permissions"},
{"file_id": "533154a", "url": "https://www.nature.com/articles/533154a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Huge study uncovers 74 genetic markers that influence the number of years spent in education. The largest-ever genetics study in the social sciences has turned up dozens of DNA markers that are linked to the number of years of formal education an individual completes. The work, reported this week in  Nature , analysed genetic material from around 300,000 people. \u201cThis is good news,\u201d says Stephen Hsu, a theoretical physicist at Michigan State University in East Lansing, who studies the genetics of intelligence. \u201cIt shows that if you have enough statistical power you can find genetic variants that are associated with cognitive ability.\u201d Yet the study\u2019s authors estimate that the 74\u00a0genetic markers they uncovered comprise just 0.43% of the total genetic contribution to educational achievement ( A.Okbayet\u00a0al.Naturehttp://dx.doi.org/10.1038/nature17671;2016 ). By themselves, the markers cannot predict a person\u2019s performance at school. And because the work examined only people of European ancestry, it is unclear whether the results apply to those with roots in other regions, such as Africa or Asia. The findings have proved divisive. Some researchers hope that the work will aid studies of biology, medicine and social policy, but others say that the emphasis on genetics obscures factors that have a much larger impact on individual attainment, such as health, parenting and quality of schooling. \u201cPolicymakers and funders should pull the plug on this sort of work,\u201d said anthropologist Anne Buchanan and genetic anthropologist Kenneth Weiss at Pennsylvania State University in University Park in a statement to  Nature . \u201cWe gain little that is useful in our understanding of this sort of trait by a massively large genetic approach in normal individuals.\u201d The study is the latest to apply genetic analysis to social science. Some of its authors have also studied the genetics of happiness, and plan to examine the genetics of fertility and of risk-taking behaviour. \u201cThere\u2019s been a long-standing assumption that [genetic] differences among people are not really relevant for social-science studies,\u201d says study co-author Christopher Chabris, a cognitive psychologist at Union College in Schenectady, New York. \u201cThe main effect of this work may be the increasing realization that genetic differences matter, and now people can start to figure out how and why.\u201d Robert Plomin, a behavioural geneticist at King\u2019s College London, agrees. The study\u2019s authors identified 9 million genetic variants that, as a group, have some influence on school success; these include the 74\u00a0genetic markers that show strong individual influence. Considered as part of an overall \u2018polygenic\u2019 score, the variants explain 3.2% of the differences in educational attainment between individuals. Plomin says that such studies could pave the way to predictive genetics for traits such as how well children perform on standardized tests. Still, the researchers estimate that a person who carries two copies of the genetic variant that has the strongest known effect would complete nine more weeks of schooling over a lifetime than a person with no copies. The authors also report that the markers they found overlap with those associated with better performance in cognitive tests, bolstering the idea that educational attainment is a proxy for intelligence. Because few large studies have tested individuals\u2019 cognitive performance, it has been difficult to discern genetic factors linked to intelligence. But it is much easier to amass large amounts of data that have sufficient statistical power to uncover genetic effects related to educational attainment, because medical studies routinely record data on participants\u2019 years of schooling. Hsu predicts that growing knowledge of genetic contributions to intelligence could be used to help parents to select embryos created through  in\u00a0vitro  fertilization.\u201cYou could allow the parents to decide whether they want to implant or not implant an embryo that has a serious cognitive impairment,\u201d Hsu says. \u201cWhat is missing is the ability to know what places in the genome are affecting cognitive ability, but studies like this one will get us to that point.\u201d But even if all the genetic contributors to educational attainment were known, the study\u2019s authors say, their effect would probably be overshadowed by other factors such as the socio-economic and educational status of a child\u2019s family. Says Chabris, \u201cIt would be irresponsible to look at a polygenic score and use it to make a prediction for a single individual\u201d. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Genetic variants associated with subjective well-being, depressive symptoms, and neuroticism identified through genome-wide analyses 2016-Apr-18 \n                   \n                     'Smart genes' prove elusive 2014-Sep-08 \n                   \n                     Ethics: Taboo genetics 2013-Oct-02 \n                   \n                     Social Science Genetic Association Consortium \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19910", "url": "https://www.nature.com/articles/nature.2016.19910", "year": 2016, "authors": [{"name": "Claudio Angelo"}], "parsed_as_year": "2006_or_before", "body": "New President Michel Temer \u2014 who replaces impeached Dilma Rousseff \u2014 is fusing the science and telecommunications ministries.\u00a0 Brazil\u2019s scientists, already  struggling to absorb massive funding cuts , are protesting against another blow: the country\u2019s science ministry has been demoted by interim president Michel Temer, who took over the government on 12 May after a Senate impeachment vote ousted Dilma Rousseff from the presidency. Among Temer's first actions was to announce the fusion of the federal Ministry of Science, Technology and Innovation (MCTI) with the ministry that deals with telecommunications and Internet regulations. Science is now a main office within a \u2018superministry\u2019 led by Gilberto Kassab, a former mayor of S\u00e3o Paulo. The move, which Temer began hinting at a few days ago, has angered some Brazilian researchers. On 11 May, 13 scientific associations, led by the Brazilian Society for the Advancement of Science (SBPC) and the Brazilian Academy of Sciences (ABC), sent a letter to Temer warning that the fusion would be \u201cdetrimental to the country\u2019s scientific and technological development\u201d. Researchers say that it would corrode the authority of the MCTI, which has formed the backbone of federal support for science and innovation in Brazil for the past three decades. \u201cAn administrative reorganization should stem from a vision for the country. It shouldn\u2019t simply be an artificial lumping of disparate activities,\u201d says ABC president Luiz Davidovich. The move is \u201ca step backwards\u201d, he says. Temer had first raised concern among scientists last week, when he hinted to local media that he might appoint a creationist evangelical bishop to lead the science ministry \u2014 a suggestion that led both the SBPC and the ABC to ask Temer to spare the agency in eventual reforms. \u201cUnfortunately, the science ministry is usually among the first bargaining chips in every new government,\u201d says Jos\u00e9 Eduardo Krieger, dean of research at the University of S\u00e3o Paulo. Brazil has had three science ministers in the past 16 months \u2014 and each was seemingly appointed for political ends rather than for any particular expertise. In January last year, Rousseff picked  Aldo Rebelo, an avowed climate sceptic  in the Communist party (the closest ally of Rousseff\u2019s centre\u2013left Worker\u2019s Party). He was followed by Celso Pansera, whose nomination was regarded as an attempt to lure votes from Temer\u2019s Brazilian Democratic Movement Party (PMDB) party against Rousseff\u2019s impeachment. And Em\u00edlia Ribeiro, former vice-minister of the MCTI, has been science minister since April 2016. Pansera admits that such high turnover is detrimental to research. \u201cIt gives you a lot of discontinuity,\u201d he says. \n               Funding slashed \n             The most hurtful discontinuity for Brazil\u2019s researchers has been startling cuts to federal funding. Last year, as the nation\u2019s fiscal crisis began to bite, the MCTI\u2019s budget was chopped by some 1.9 billion reais (US$540 million), to 5.4 billion reais. Its budget for this year was set 37% lower than last year\u2019s \u2014 and its authorized spending has been chopped by another 6%. The collapse of oil prices and a bribery scandal that involves Petrobras, the behemoth state-run oil company, have further reduced cash flows for Brazilian research, which partly depends on oil revenue. A major victim of the economic downturn is the flagship exchange programme Science Without Borders, which by the end of 2015 had sent nearly 94,000 Brazilian undergraduate and postgraduate students to leading institutions abroad. The programme intended to send a further 100,000 students abroad by 2018, but its second phase, scheduled to start this year, has been called off. To revive science spending, the government had authorized the MCTI to negotiate a US$1.4 billion loan from the Inter-American Development Bank, headquartered in Washington DC. But that operation has been reset because of the impeachment, Pansera says. \u201cNow we\u2019ll have to renegotiate everything with the new government\u2019s economic team.\u201d Research institutes are struggling to survive. At the Brain Institute at the Federal University of Rio Grande do Norte in Natal, researchers split basic maintenance expenses such as Internet bills among themselves and buy equipment with their own money, says institute director Sidarta Ribeiro. And some scientists are already planning to leave the country. Suzana Herculano-Houzel, a neuroscientist at the Federal University of Rio de Janeiro, launched a crowdfunding campaign last year to buy new parts for a microscope. But she has now decided to move to Vanderbilt University in the United States: this September, she will shut down her lab in Brazil, which had been running for a decade. Brazilian scientists are familiar with economic crises. In the 1990s, budget constraints were the rule, recalls Paulo Artaxo, a physicist at the University of S\u00e3o Paulo. But before the current crisis, the country\u2019s research had been experiencing unprecedented expansion, with funding on the rise and the number of PhD students soaring. In 2011, Brazil jumped to 13th in the world in terms of research-paper production, up from 17th in 2001. That trend is already reversing, says Rog\u00e9rio Meneghini, a specialist in science metrics and scientific director of SciELO, a subsidized collection of mainly Latin American journals. Brazil\u2019s research-paper production grew at a steady rate of 16% between 2011 and 2014 \u2014 but his preliminary figures suggest that it had dropped by 4% in 2015. \u201cWhat is cruel about this is that, when you cut off on science, you can never resume from where you stopped\u201d, Krieger says. \u201cYou lose position.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Brazilian law grants patients right to use untested cancer \u2018drug\u2019 2016-Apr-15 \n                   \n                     Brazilian science paralysed by economic slump 2015-Sep-30 \n                   \n                     Political appointments spur concerns for Amazon 2015-Jan-12 \n                   \n                     Stars of South American science 2014-Jun-11 \n                   \n                     Brazil's science investment reaches record high 2013-Aug-01 \n                   Reprints and Permissions"},
{"file_id": "533158a", "url": "https://www.nature.com/articles/533158a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Document submitted to the Italian Senate criticizes institute that will oversee a \u20ac1.5-billion project. A plan to create a \u20ac1.5-billion (US$1.7-billion) centre for biomedical and nutritional research has been causing rifts between Italian scientists ever since Prime Minister Matteo Renzi announced it last November. Now the row has escalated, courtesy of a 48-page document submitted to the Italian Senate on 4\u00a0May by Senator Elena Cattaneo, who is also a neuroscientist at the University of Milan. In the document, she complains that the idea for the centre, called the Human Technopole, was conceived by a small group of scientists behind closed doors, and that the large sum of money involved should not be concentrated in a single project, in particular because Italy\u2019s research community as a whole has been  starved of funds for years . \u201cTo allocate money in this way without discussion of ideas corrupts the ethics of science,\u201d Cattaneo told  Nature . That sentiment is in line with arguments already made by Cattaneo and others. Cattaneo\u2019s report also lists a series of complaints against the Italian Institute of Technology (IIT) in Genoa, which Renzi has designated to oversee the Technopole project. The complaints against both institutes are \u201centirely political\u201d, says Roberto Cingolani, who is the Technopole\u2019s main architect and director of the IIT. He designed the Technopole concept together with scientists from various universities and research institutes in Milan, and now plans to submit a detailed rebuttal of Cattaneo\u2019s document to the parliament. Like the IIT, the Human Technopole was approved by government decree, and, although supported with public money, will be a private foundation. As such, it will avoid much of the red tape that holds back state universities and publicly funded research institutes. According to Cingolani\u2019s plan, the Technopole will focus on genomics and personalized medicine, with an emphasis on nutrition, cancer and neuro\u00addegenerative diseases. The plan is now being evaluated by a panel of international scientists. But many researchers are incensed that the project was announced without an open call for ideas. \u201cThe evaluators should have had the opportunity to compare different proposals,\u201d says astrophysicist Giovanni Bignami, former director of the Rome-based National Institute for Astrophysics. Earlier this year, physicist Giorgio Parisi at the Sapienza University of Rome  initiated a petition , now signed by more than 72,000 people, arguing for Italy to invest more in research. But even he takes issue with the way in which the cash is to be doled out. \u201cAn investment of this magnitude should have involved the whole scientific community, and different projects should have been compared,\u201d he says.  An investment of this magnitude should have involved the whole scientific community.  Supporters of the Technopole say that what matters is the progress of Italian science, not the specifics of how the project was chosen, and that the government is within its rights to set up such a centre by decree. It is \u201cnothing unusual for a government to set science policy\u201d, says neuroscientist Emilio Bizzi at the McGovern Institute for Brain Research at MIT in Cambridge, Massachusetts, and a member of the IIT scientific advisory board. Cattaneo\u2019s report also questions the choice of the IIT to coordinate the Technopole project. She notes that although the IIT is rated top among the country\u2019s institutes for nanotechnology when measured by the impact of its publications, it is not in the top five for the life sciences or biomedicine, which are the subjects that will be the focus of the Technopole. She cites a  news\u00adpaper article from 6\u00a0January  that reported that the IIT had not spent all of the money it received in 2013, and raised the issue of why the executive had not turned down the payments if it was not going to use them, so that they could be used by other research institutes. And Cattaneo\u2019s report says that, according to the IIT\u2019s internal regulations, the institute appoints members of a national committee to evaluate the institute\u2019s progress, without the oversight of an external body. Cingolani refutes all of these criticisms. He says that there are many ways to measure scientific success, and accuses Cattaneo of cherry-picking the facts to fit her argument. He points out that any money that the IIT doesn\u2019t spend gets returned to the state. And he says that the IIT undergoes many levels of evaluations and that all are carried out according to best practice. \u201cI am preparing my rebuttal line by line, point by point,\u201d he told  Nature . Parliament has yet to decide on whether to debate the issues raised by Cattaneo\u2019s sub\u00admission. But the ongoing public discussion is fuelling calls for Italy to reform how it funds research. It is one of the few countries in the European Union without a national research agency, and in a  Correspondence in this week\u2019s Nature , 15 Italian members of Europe\u2019s life-sciences organization EMBO emphasize the need for such an agency, to provide \u201ctransparent jurisdiction over the funding and execution of research\u201d. \u201cThe agency,\u201d the scientists add, \u201cwould also monitor the progress of the Human Technopole and oversee its accountability.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @alison_c_abbott \n               \n                     Reforms at stake in Italian election 2013-Feb-20 \n                   \n                     Robotics: The bot that plays ball 2009-Aug-26 \n                   \n                     Italian Institute of Technology \n                   Reprints and Permissions"},
{"file_id": "533153a", "url": "https://www.nature.com/articles/533153a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "A wave of user-friendly devices is making the technology an attractive research tool. Devices that have slashed the cost of virtual reality, and transformed its performance, have implications for scientists as well as gamers. Researchers who are experimenting with the head-mounted displays say that they have the potential to find widespread use as a research tool. Virtual reality (VR), which lets users experience a computer-generated, three-dimensional world, has produced recurring waves of hype since the 1980s \u2014 but this time could be different, says Mel Slater, a computer scientist at the University of Barcelona in Spain who has worked in the field for two decades. Thanks to technologies originally developed for smartphones and video-gaming graphics, the performance of these headsets is now comparable to that of high-end devices that cost tens of thousands of dollars. They are sophisticated, affordable and user-friendly enough to become a staple of research labs, says Slater, rather than tools available to only very few researchers. A gadget that has transfixed technology-news outlets is the Oculus Rift, made by Facebook-owned start-up Oculus VR of Menlo Park, California. It costs US$600 \u2014 but operating it also requires a high-end computer that can cost more than $1,000. Similarly priced gadgets made by smartphone-maker HTC and Sony are expected to become available this year. Vastly cheaper sets made by Google and Samsung turn a smartphone into a more basic VR device. A lab can now buy a VR device without a dedicated equipment grant, says Anthony Steed, a computer scientist who heads a virtual-environments group at University College London. He and Slater have been experimenting for more than a year with early prototypes of the HTC and Oculus devices, and say that the performance is just as good as that of higher-end devices, and getting better. The new devices are light enough to be worn for extended periods, and they react quickly to the user\u2019s movement, preventing the motion sickness that can occur when using VR. \u201cTwo to three years ago, the lab we used for our research cost \u20ac100,000 [US$114,000] to set up. Now we can do the same for about \u20ac4,000,\u201d says Slater. For years, Slater has run VR experiments with psychologists, including one that tested how white people\u2019s biases change after they have virtually inhabited the body of a black person. Last week, Slater and Daniel Freeman, a clinical psychologist at the University of Oxford, UK, and their collaborators published a study that suggests that VR could help to treat people with severe paranoia, who often avoid crowded places because of a perception that other people want to hurt them ( D.Freemanetal.Br.J.Psychiatr.http://doi.org/bgrr;2016 ). The experimental therapy attempts to teach people to lower their defences and to trust others by letting them visit virtual environments such as crowded lifts or underground trains. Other studies have used VR to try to treat post-traumatic stress disorder and fear of heights or spiders. These experiments used expensive, high-end gear, but several of the researchers involved say that they now plan to start using consumer headsets instead. As well as being cheap, the headsets are simple to set up. \u201cIt\u2019s a proper out-of-the-box experience,\u201d says Steed. If larger studies prove the therapies to be effective, patients could borrow the equipment and use it at home, Freeman says. Neuroscientist Elizabeth Buffalo at the University of Washington in Seattle is also considering how to use the Oculus Rift. Her team studies monkeys as the animals explore interactive environments that are represented on a screen. Head-mounted sets that create a 3D environment would create a more immersive, and therefore natural, experience, she says, but current products are too big to fit on a monkey\u2019s head. \u201cWe are working on hacking the Oculus to achieve this,\u201d Buffalo says. Creating complex virtual environments still requires specialized computer skills, says Slater. But costs are falling now that some software developed to aid video-game companies is free to use, and many labs outsource the work. A related technology called augmented reality (AR), which superimposes images onto the user\u2019s field of view rather than replacing the scene with a different one, could also be of use in the lab, helping researchers to visualize and share data sets, says Mark Billinghurst, who studies human\u2013computer interaction at the University of South Australia in Adelaide. Google Glass, an early attempt at AR that projected images into the corner of a pair of glasses, was a commercial flop, but Microsoft is about to launch a more sophisticated AR headset called HoloLens. \u201cWith AR technology like HoloLens,\u201d says Billinghurst, \u201cresearchers could easily see a complex virtual data set superimposed on a real table in front of them, and also see each other face to face across the table and talk about the data.\u201d Mary Whitton, a computer scientist who works on virtual environments at the University of North Carolina at Chapel Hill, says that there is still room for improvement in the way the systems track users\u2019 motions and in how users can interact with the virtual world using their hands. Still, she says: \u201cI\u2019ve had most fun seeing how people use what we\u2019ve built in ways we never imagined.\u201d\n See also News & Views  Neuroscience: Virtual reality explored \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               Reprints and Permissions"},
{"file_id": "nature.2016.19903", "url": "https://www.nature.com/articles/nature.2016.19903", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "New statistical method quickly checks the status of planetary candidates. The latest batch of planets spotted by  NASA\u2019s Kepler space telescope  is its biggest yet: 1,284 newfound worlds beyond the Solar System. The discoveries \u2014 which more than double Kepler's total planetary haul \u2014 were made possible by a new statistical method that can quickly analyse whether a signal is a bona fide planet or a false alarm. \u201cIt\u2019s really exciting because now we have more planets to play with,\u201d says Lisa Kaltenegger, an astronomer at Cornell University in Ithaca, New York. The haul includes nine worlds in  the habitable zones of their stars  \u2014 the realm in which liquid water and, potentially, extraterrestrial life could exist. Kepler has now found 21 planets that are roughly Earth analogues \u2014 those that lie in the habitable zones of their stars and are no bigger than twice the size of Earth. \u201cIt is showing us the first hint of the diversity of worlds out there,\u201d Kaltenegger says. Timothy Morton, an astronomer at Princeton University in New Jersey, and his colleagues report the new planets in  The Astrophysical Journal 1 . \n             Speedy software \n           Kepler raked in  thousands of candidate planets  between 2009 and 2013, when it stared at a patch of sky and looked for the temporary dimming caused when a planet moves in front of its star. But other phenomena, such as two stars orbiting one another, can produce the same sort of signal. Astronomers have had to laboriously investigate each of the Kepler candidate signals, usually one at a time, by watching the stars using ground-based telescopes. Morton's team developed a method for sorting through the candidate planets using a software package known as Vespa. It calculates the likelihood that a planetary-looking signal could be caused by something other than a real planet. The team used Vespa to analyse sightings of more than 7,000 possible planets. Along with the 1,284 new discoveries, the researchers also found planets that had been confirmed previously by other methods. They left more than 2,000 sightings in the \u201ccandidate\u201d category because they could not confirm them at a 99% or greater level of confidence. \n             False positives \n           Other astronomers have previously developed search programmes to sift through Kepler candidate planet signals. The Vespa system is much faster because it is fully automated and takes just a few minutes per candidate, Morton says. The code is open-source and is being used by other teams on their own planetary candidates. \u201cIn the early years we were really plagued by false alarms,\u201d says Natalie Batalha, Kepler\u2019s mission scientist at the NASA Ames Research Center in Moffett Field, California. One recent study estimated that as many as half of the gas-giant candidates \u2014 a relatively small percentage of Kepler's work, which focuses on smaller rocky planets \u2014 could be false positives 2 . The Vespa work is helping scientists to be more confident in the planets they do confirm, Batalha says. Kepler  briefly entered emergency mode last month  but has now resumed its planet-hunting work. \n                   Kepler spacecraft in emergency mode 2016-Apr-10 \n                 \n                   Rebooted Kepler spacecraft hauls in the planets 2016-Jan-07 \n                 \n                   The exoplanet files 2015-Nov-18 \n                 \n                   Three 'super-Earth' exoplanets seen orbiting nearby star 2015-Jan-16 \n                 \n                   Exoplanet bounty includes most Earth-like worlds yet 2015-Jan-06 \n                 \n                   Kepler & K2 science center \n                 \n                   NASA exoplanet archive \n                 Reprints and Permissions"},
{"file_id": "533156a", "url": "https://www.nature.com/articles/533156a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Scientists fear that security-driven switch to X-ray irradiators will harm their research. Anybody who wants to conduct experiments on mice in Margaret Goodell\u2019s immunology lab must submit to a host of security measures, starting with a background check by the FBI. That\u2019s because Goodell, a researcher at Baylor College of Medicine in Houston, Texas, uses a caesium-based irradiator to destroy bone marrow in mice that are set to receive stem-cell transplants. The US government fears that the radioactive caesium could be stolen to make a \u2018dirty\u2019 bomb. Now the US National Nuclear Security Administration (NNSA) is working with scientists to investigate how \u2014 or whether \u2014 to replace caesium irradiators with less dangerous X-ray technology. Researchers have used the caesium devices for decades, to study every\u00adthing from immunotherapy to cancer treatment, and some fear that switching to X-ray irradiators will affect their results. Goodell, who has found subtle differences in how the mouse immune system responds to the two types of device, prefers Baylor\u2019s caesium irradiator. Her research has revealed that immune cells called B lymphocytes recovered more slowly in mice treated with an X-ray irradiator than in those exposed to caesium. But other immune cells, known as myeloid cells, rebounded faster after the X-ray treatment ( B.\u00a0W.\u00a0Gibson  et al .  Comp. Med.    65,  165\u2013172; 2015 ). Because of this, she says, \u201cit would be difficult to compare studies using X-rays to the research that was done ten years ago\u201d. For nuclear regulators, the risk posed by caesium is clear. The element\u2019s highly radio\u00adactive isotope caesium-137 comes in a powdered form that can be dispersed in air or water; exposure to the substance can cause burns, radiation sickness or death, depending on the dose. Caesium irradiators, which have long been used to eliminate pathogens in supplies of blood as well as for research applications, rely on small capsules of radioactive caesium chloride encased in a lead-covered box. There are more than 800 such devices in US medical and research facilities. Several countries \u2014 including France, Norway and Japan \u2014 are shifting away from using caesium irradiators in blood banks because of security fears, and last year the NNSA began working with hospitals in the United States to do the same. But finding alternative ways to treat blood is relatively simple. The NNSA is working with researchers to pin down the more complicated issue of how X-ray irradiators might differ from conventional caesium instruments for other applications. \u201cYou talk to the doctors, and they are afraid that we are going to be taking away their devices,\u201d says Maegon Barlow, director of radiological security at the NNSA. \u201cBut it\u2019s really trying to facilitate, not force.\u201d The agency is negotiating with the Mount Sinai Health System in New York City to support a new round of studies that will compare X-ray and caesium irradiators. Jacob Kamen, Mount Sinai\u2019s chief radiation-safety officer, notes that some researchers there have already conducted similar experiments. Peter Heeger, head of organ-transplant research at Mount Sinai\u2019s Icahn School of Medicine, and his colleagues use caesium irradiators when testing immune responses in people who are going to receive organs. To predict whether a recipient\u2019s body will reject a new organ, the researchers culture B\u00a0lymphocytes from the organ donor and test them against immune cells from the recipient. But B\u00a0lymphocytes will not divide unless they are activated \u2014 here, by the presence of connective-tissue cells called fibroblasts. Heeger\u2019s team irradiates the fibroblasts to prevent them from replicating during this process. The scientists have run a series of unpublished experiments to determine how much X-ray radiation is necessary to suppress fibroblast growth. \u201cNow we know, and we are now comfortable switching for this particular procedure,\u201d says Heeger. But Goodell says that many researchers would have to conduct lengthy experiments to ensure that they can make the transition without losing confidence in their results. Nor is she convinced that a switch to X-rays is necessary, given the security safeguards that are already in place. Anybody who needs to use the caesium irradiator at Baylor must present a security badge, enter a personal identification number and then submit to an iris scan. And if a person inside the secure room that contains the irradiator breaches any security protocols, an alarm automatically goes off in the university\u2019s security office. \u201cAs a biologist, it\u2019s not clear to me what case has been made for [caesium irradiators] being an enormous security risk,\u201d she\u00a0says. Advocates of ending use of the devices say that the goal is to eliminate the risk of nuclear material falling into the wrong hands wherever possible. The security measures in place to protect caesium irradiators would not necessarily prevent the theft of nuclear material by somebody with permission to access these instruments, says Charles Ferguson, president of the Federation of American Scientists in Washington DC. Efforts to secure nuclear materials are often focused on this \u2018insider threat\u2019, as well as the disposal and recycling of irradiators, which can contain enough caesium to pose a hazard for centuries. \u201cI would not want humanity to lose the benefits of science,\u201d says Ferguson. \u201cBut if we can develop alternative technologies that prove comparable and can reduce the security threat to zero, I think that\u2019s a good thing.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     The nuclear option 2016-May-04 \n                   \n                     Safety in neutrons 2016-Apr-06 \n                   \n                     Nuclear summit a test for Obama's legacy 2016-Mar-30 \n                   \n                     National Nuclear Security Administration \n                   \n                     Nuclear Threat Initiative \n                   \n                     Fissile materials working group \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19904", "url": "https://www.nature.com/articles/nature.2016.19904", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Electron and holes smashed together inside a crystal. Smashing things together at high energies is a productive way for physicists to learn about the Universe \u2014 as the Large Hadron Collider (LHC) has shown. Now, physicists in Germany and the United States have described a way to smash things together inside a semiconductor crystal. But rather than protons or electrons, the researchers instead collide short-lived entities known as quasiparticles. The experiments should reveal more about the properties and interactions of quasiparticles, some of which are fundamental to basic processes in physics \u2014 such as light-emission and superconductivity \u2014 but remain poorly-understood. Quasiparticles are a way of modelling the cluster of interactions between many particles inside a solid material. An electron quasiparticle, for example, represents the combination of an electron moving in a material and the movements that it triggers in nearby atomic nuclei and electrons as it travels. Mathematically, this behaviour can be modelled as if all these motions represented a single, isolated particle travelling through empty space, with a defined mass, charge and energy. It is intuitive for physicists to think in terms of quasiparticles, in the same way that it makes sense to follow a moving bubble in water, rather than trying to chart every molecule that surrounds it, says Mackillo Kira, a physicist at the University of Marburg in Germany and co-author of a report on the quasiparticle collider, published in  Nature 1 . \n             Quasiparticle collider \n           The principle behind the collider is the same as at  the LHC  \u2014 smash things together at a predetermined moment, then learn about their structure and interactions by studying the collision debris. But the set-up is very different. At the LHC, protons are isolated inside a 27-kilometre vacuum tube, and collided at nearly the speed of light. Kira\u2019s collisions take place within a tiny chunk of semiconductor and happen with one-quadrillionth (one-millionth of one-billionth) of the energy of those at the LHC. Kira and his team use precisely timed terahertz pulses to collide electron quasiparticles with positively charged quasiparticles known as holes \u2014 the vacancies left when electrons are freed from atoms. The team first shines an ultrashort laser pulse, lasting just 100 femtoseconds (10 \u221215  seconds), onto a 60-nanometre-thick slab of the semiconductor tungsten diselenide. In the same way that light creates a current in a solar cell, the laser sets electrons free from atoms to move around the semiconductor, leaving positively charged holes behind. In this material, the electrons and holes don\u2019t drift apart freely: they are bound by their electric attraction in a pair known as an exciton, another kind of quasiparticle. The researchers then apply a strong, oscillating electromagnetic field that pulls the excitons apart, accelerating the electron and hole quasiparticles in opposite directions. Finally, it sends the quasiparticles smashing back into each other in a controlled collision. When pairs of oppositely charged quasiparticles meet, they annihilate and produce photons \u2014 particles of light \u2014 that the team maps. Wang Yao, a physicist at the University of Hong Kong, says that the collisions reveal important information, such as the internal structure of the parent exciton, and how strongly electrons and holes bind together. That might help physicists to design  new types of efficient light-emitting devices and solar cells . Applied to other kinds of quasiparticles, the technique might help to elucidate mysterious phenomena within materials, such as  high-temperature superconductivity , says Kira. It should be possible, for instance, to collide exotic quasiparticles such as Bogoliubov quasiparticles, which are broken halves of Cooper pairs, the weakly bound electrons responsible for superconductivity , or dropletons, a liquid-like cluster of three or more electron\u2013hole pairs. \u201cWe are convinced that our new collider is quite broadly applicable to many quasiparticles in many different solids,\u201d he says. Read the related  News & Views . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "nature.2016.19909", "url": "https://www.nature.com/articles/nature.2016.19909", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Stem-cell scientists attempt to fend off the need for government regulation that could impede research. The international society that represents stem-cell scientists has  updated its research guidelines  in the wake of dramatic progress in several fields \u2014 in particular in research that involves the manipulation of human embryos. The authors hope that the updated guidelines will allay various ethical concerns, and avoid the need for strict government regulations that could impede the progress of science. \u00a0 \u201cSelf-regulation is the best form of regulation,\u201d says Charles Murry, a member of the committee that  updated the guidelines , and a bioengineer at the University of Washington in Seattle. \u201cThe biomedical community is best poised to strike the balance between rapid progress and safe, ethical research practice.\u201d The  International Society for Stem Cell Research  (ISSCR), which was founded in 2002, has previously released guidelines in 2006 and 2008 on embryonic-stem-cell research and on clinical translation of stem-cell research. The latest guidelines have broader scope, and cover all research on human embryos \u2014 including gene-editing of embryos, which has in the past year  advanced significantly  and  generated much controversy. \n             Embryos and pluripotent cells \n           The revised guidelines recommend that all research involving the manipulation of human embryos now undergo a similar review as experiments that use embryos to create stem-cell lines, which has been  one of the most divisive research procedures of recent decades . They suggest that such research be added to the remit of existing embryonic stem cell research oversight (ESCRO) committees. Scientists previously balked at the introduction of ESCRO committees, and there is likely to be resistance to the idea of adding bureaucratic review to other research areas. \u201cNo scientist or physician jumps for joy when new regulations are put in place,\u201d says Murry. But he says that the updates are necessary to avoid \u201ca wild-west environment where sensitive research is done without proper regard for community standards\u201d. At the same time, the new guidelines attempt to clear the way for more  research using induced pluripotent stem (iPS) cells , which, like embryonic stem cells, are able to turn into all cell types in the human body but are not taken from embryos. The authors recommend explicitly excluding the generation of iPS cells from regulations on embryonic stem cell research and relying instead on the existing oversight for donor cell recruitment. Some institutions have been confused about how to classify iPS cells, says George Daley, a stem-cell scientist at the Boston Children's Hospital in Massachusetts and one of the authors of the new guidelines. \n             14-day rule \n           Also included in the guidelines is a call for continued observance of a moratorium on growing human embryos  in vitro  beyond 14 days \u2014 a somewhat arbitrary limit that has become the global standard. Two papers published on 4 May reported experiments that  showed that it would soon be possible to breach the limit , sparking debate about  whether the rule should be reconsidered . \u201cThe ISSCR deserves credit for bringing up and discussing these important issues,\u201d says stem-cell biologist Ali Brivanlou of the Rockefeller University in New York City, who is a lead author on one of the embryo papers. But he adds that further discussion of the issues is needed. \u201cWe need to get together the positives and negatives of moving forward,\u201d he says. The authors also take the opportunity to reinforce a warning that the ISSCR has long made \u2014 that researchers shouldn't overstate the clinical implications of stem-cell experiments. Hype surrounding such experiments has enabled a worldwide market for unproven, and often ineffective or  dangerous, stem-cell therapies , which has been  difficult to regulate . \u201cWe take a swipe at hyperbole in scientific communication, essentially asking researchers to \u2018take it down a notch\u2019 when they speak about the implications of their work,\u201d says Murry. Read the related  Comment . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Embryology policy: Revisit the 14-day rule 2016-May-04 \n                 \n                   Human embryos grown in lab for longer than ever before 2016-May-04 \n                 \n                   Stem cells in Texas: Cowboy culture 2013-Feb-13 \n                 \n                   Guidelines for stem cell science and clinical translation \n                 \n                   ISSCR \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19907", "url": "https://www.nature.com/articles/nature.2016.19907", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "A simple signal may incentivize researchers to make data and materials publicly available. Awarding colourful badges as part of an advocacy campaign seems to be\u00a0an effective way to get scientists to publicly share the data behind their research papers, researchers have suggested after an 18-month experiment with the strategy. In 2014, the journal  Psychological Science  announced that it would award badges \u2014 in the form of blue or orange icons at the top of a research paper \u2014 to publications that made relevant data or research materials publicly available. Eric Eich, who was editor-in-chief of the journal at the time, got the idea from a suggestion by social psychologist Brian Nosek in around 2013. During that period, Nosek was setting up the Center for Open Science (CoS), a non-profit organization\u00a0in Charlottesville, Virginia, that is dedicated to increasing the openness and reproducibility of research. Working independently of staff at  Psychological Science , researchers at the CoS checked each article\u2019s claims about data availability and compared this with the level of data sharing offered by articles in other journals. They published their results in a paper that appears in  PLoS Biology  today 1 . By the first half of 2015, the proportion of articles in  Psychological Science  stating that data were available had shot up to around 40%, even as rates in four other psychology journals remained unchanged at below 10%. Out of 171 eligible papers published between July 2014 and May 2015, 43 received a badge for open data \u2014 although the CoS researchers found that not all of these actually made all relevant data available in a way that other researchers could readily use. But badges were a better indicator of data availability than were mere statements that resources could be obtained, says Mallory Kidwell, a CoS project coordinator who led efforts to analyse more than 2,000 articles across five journals. \u201cThere is a sense of accountability when someone applies for a badge,\u201d she says. Rates also rose for  Psychological Science  research papers that declared the availability of research materials, but these patterns were less pronounced. \n             Multiple influences \n           It is impossible to prove that the badges themselves increased sharing, concedes Nosek.  Psychological Science  asked all authors of accepted papers whether they wanted to earn a badge by making their research resources available, so the mere act of asking might have had an influence. So might advocacy by Eich. But Nosek thinks that the combination is important \u2014 a journal stating that it values the sharing of data and materials, evaluating whether scientists have done it, and then publicly signalling papers that conform. Besides  Psychological Science , nine other journals have now implemented badges or have announced plans to do so. Eich, who was not involved in the analysis, thinks that the results may help to convince editors at other journals to give badges a try. \u201cThey are bound to hear scattered complaints about badges being gimmicks or contrivances, but the empirical evidence presented in Kidwell  et al .'s new paper should allay most serious concerns,\u201d he says. Information scientist Youngseek Kim\u00a0at the University of Kentucky in Lexington calls badges a creative way to increase data sharing. The choice to share data is heavily influenced by expected norms of behaviour \u2014 and badges serve to increase that expectation, he says. \n                   Web widget nudges scientists to share their data 2016-Mar-10 \n                 \n                   Data sharing: An open mind on open data 2016-Jan-06 \n                 \n                   Digital badges aim to clear up politics of authorship 2015-Sep-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19901", "url": "https://www.nature.com/articles/nature.2016.19901", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Chemical assembly bolsters theory that life might have begun with RNA. If life began with RNA \u2014 as one theory posits \u2014 then the first RNA molecules would have emerged from simple ingredients on early Earth. In a step towards supporting this 'RNA world' theory, biochemists have now shown that all four of RNA\u2019s major components can be assembled efficiently from simple chemicals in conditions that, they argue, might have been present billions of years ago on our planet. A study published in 2009 described  an easy way to create two of RNA\u2019s building blocks , called ribonucleotides 1 . And in a paper published in  Science  on 12 May, scientists now demonstrate a straightforward chemical pathway to the formation of the other two 2 . \u201cIt is a very nice piece of work and certainly comparable in significance to the 2009 paper,\u201d says Gerald Joyce, an origins-of-life researcher at the Scripps Research Institute in La Jolla, California. But objectors who favour other explanations of life\u2019s origins are not swayed. While chemists have sought ways to create RNA out of pools of simple chemicals in warm water, these might not be the most plausible conditions for the beginnngs of life on Earth, they argue. \n             RNA from scratch \n           RNA, a complex polymer related to DNA, can catalyse chemical reactions and even duplicate itself \u2014 leading some to suggest that its creation might have jump-started life. But in modern cells, it takes a menagerie of enzymes that would not have been present on primordial Earth to make an RNA strand. So chemists have tried to find simpler ways to do it. The molecule\u2019s ribonucleotide building blocks are themselves made up of three parts: a sugar molecule, a phosphate group and one of the four bases that form the alphabet of RNA's genetic code \u2014 adenine, uracil, cytosine and guanine. In the 2009 paper, John Sutherland, a biochemist now at the University of Cambridge, UK, and his collaborators found a way to synthesize uracil and cytosine from simple ingredients. Now, organic chemist Thomas Carell of Ludwig Maximilian University in Munich, Germany, and his team have shown how the other two bases, guanine and adenine, can form from simpler molecules and spontaneously link up with the sugar molecule, creating a precursor to the full ribonucleotide called a nucleoside. They have not yet demonstrated how to complete the process by adding a phosphate group. The starting ingredients in their research include aminopyrimidines, which in turn can assemble from molecules that the European Space Agency\u2019s Rosetta probe has detected on the comet 67P/Churyumov-Gerasimenko. \n             Deep-sea rival \n           \u201cIt\u2019s very fine chemistry,\u201d says Bill Martin, a microbiologist at Heinrich Heine University of D\u00fcsseldorf in Germany. But he and others don\u2019t hold with the RNA-world hypothesis. Martin is a proponent of an opposing view that\u00a0 life is likely to have emerged in alkaline conditions in hot deep-sea vents . There, the argument runs, geological conditions could have set up gradients in the concentration of protons across pores in rocks \u2014 a very simple version of the flow of protons across membranes that every living cell today uses to generate chemical energy. Once the energetic flows necessary for life to persist arose, they could have led to the creation of simple organic molecules and cells. On this view, RNA-from-scratch chemistry is not relevant to the emergence of the earliest life. \u201cI remain sceptical that it is reflecting\u00a0any process that were involved in how we \u2014 our ancestors \u2014 arose,\u201d Martin says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Origins of life: An improbable journey 2015-Apr-29 \n                 \n                   How life emerged from deep-sea rocks 2012-Dec-20 \n                 \n                   Debate bubbles over the origin of life 2012-Feb-13 \n                 \n                   RNA world easier to make 2009-May-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19949", "url": "https://www.nature.com/articles/nature.2016.19949", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Labour law will change how many postdocs \u2014 long a troubled segment of the US research hierarchy \u2014 are paid. A change in US labour regulations will render many postdocs eligible for overtime pay \u2014 and create an incentive to raise their wages. The law may ultimately mean fewer postdocs. But some say that the policy could spark much-needed changes to a research system that relies heavily on postdocs yet offers them  few opportunities for career advancement . The new rule, finalized on 18 May by the US Department of Labor, will make overtime pay mandatory for many postdoctoral researchers who make less than US$47,476 per year. Overtime, which is paid at 1.5 times the normal hourly wage, kicks in once workers exceed 40 hours on the job in one week. But rather than pay the overtime, funders and universities are expected to raise minimum postdoc salaries to meet that threshold. On 17 May, Francis Collins, head of the US National Institutes of Health (NIH) in Bethesda, Maryland, said that he would do so for some NIH-funded postdocs. \u201cIt\u2019s a win for postdocs,\u201d says Benjamin Corb, director of public affairs at the American Society for Biochemistry and Molecular Biology (ASBMB) in Rockville, Maryland. \u201cAnd I think it\u2019s the right move for the community.\u201d The average salary for a postdoc in the United States is currently around $45,000, with many making substantially less. Even so, employers will probably balk at paying overtime, says Kate Sleeth, chair of the board of the National Postdoctoral Association in Washington DC. \u201cPostdocs work very, very hard,\u201d she says. \u201cI assume nobody would want to count the number of hours a postdoc would work and pay them overtime \u2014 it would be easier to raise their salary.\u201d Doing so could be cheaper and easier to administer than tallying up excess hours. \n               Approach with caution \n             But not all postdocs will reap those benefits: the new regulations will not apply to postdocs in the humanities whose primary duty is teaching, for instance. And Corb says that he was disappointed to learn that the new rules must be implemented by 1 December. The ASBMB had argued for them to be rolled out over the course of three years, to allow investigators with multiyear grants enough time to budget for the change. \u201cIt\u2019s going to be a bumpy road to implement,\u201d Corb says. As postdoctoral researchers become more expensive, laboratories may begin to cut back on the number that they hire. \u201cYou can\u2019t just say everybody\u2019s going to get more money,\u201d says Paula Stephan, who studies the economics of scientific research at Georgia State University in Atlanta. \u201cThere will be fewer postdocs.\u201d But that, she argues,  may be what the system needs . In December 2014, the US National Academies of Sciences, Engineering and Medicine published a report 1  arguing that postdoc salaries should be raised to $50,000 a year, and that many postdocs should be reclassified \u2014 and better paid \u2014 as staff scientists. In 2015, a  poll of 20,000 Nature readers  found that scientists are eager to see more permanent staff-scientist positions created. That change has been difficult to implement while postdoc salaries remain low. \u201cIf postdoc salaries were raised it would make the relative costs of postdocs more expensive and make staff scientists relatively cheaper,\u201d says Stephan. \u201cPostdocs have been seen as a cheap substitute.\u201d Corb agrees that the short-term pain of cutting back on postdocs could yield a healthier research system: \u201cTo increase postdoc pay and thin out the pool of postdocs may end up, in the long run, being a net positive for the enterprise.\u201d See Editorial  page 438 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Crunch time 2016-May-24 \n                   \n                     US postdocs hope for overtime pay 2015-Jul-08 \n                   \n                     Wanted: staff-scientist positions for postdocs 2015-Apr-10 \n                   \n                     The future of the postdoc 2015-Apr-07 \n                   \n                     US Department of Labor final rule \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19915", "url": "https://www.nature.com/articles/nature.2016.19915", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "US government and private investors team up for proposed effort to study Earth\u2019s microbes. The US government is launching an effort to study the vast, and mostly invisible, array of microorganisms that  thrive in the human body  and across ecosystems. The US$121-million National Microbiome Initiative will attempt to map and investigate these collections of microorganisms over the next two years with help from multiple federal agencies, the White House Office of Science and Technology Policy said today. Private investors will contribute another $400 millionto the effort over several years. Among them are the Bill & Melinda Gates Foundation, which will spend $100 million over 4 years on nutrition and pest-control programmes in developing countries, and several research institutions that will examine the role of microbes in matters such as cancer therapeutics and  marine microbiology . Scientists\u2019 interest in microbiomes has grown in recent years. Improvements in genome-sequencing, imaging and computing tools have begun to reveal the breadth of influence that microorganisms have on areas such as  human health ,  food production  and  climate change 1 , 2 . Yet much about Earth\u2019s microbiomes is unknown, says Tim Donohue, a bacteriologist at the University of Wisconsin-Madison and director of the Great Lakes Bioenergy Research Center. \u201cI think we know how to figure out who\u2019s there,\u201d he says. \u201cBut we don\u2019t have the tools to generate the knowledge about what they\u2019re doing and how their activities benefit ecosystems or are detrimental to ecosystems.\u201d \n             Funding fight \n           The White House project still faces a major hurdle: convincing Congress to approve the full funding proposed by the White House. Its plan for the initiative rests on lawmakers approving the bulk of the funding as part of the government\u2019s fiscal year 2017 budget. But the Republican lawmakers who control the House of Representatives and the Senate have generally not supported US President Barack Obama\u2019s initiatives. And they may be especially reluctant to devote more money to research on the role of microbes in  alternative energy  and climate change. \u201cI think it\u2019s going to be a fight,\u201d says Stefano Bertuzzi, executive director of the American Society for Microbiology in Washington DC. Under the White House plan, the US Department of Agriculture, which is interested in how soil microbes affect crops and animals, is proposing nearly $24 million for the effort. The National Institutes of Health hopes to add $20 million to the hundreds of millions that it already spends to understand the part that microbes play in infectious disease and conditions such as obesity and  mental health . And the National Science Foundation proposes to spend about $16 million to fund a wide variety of microbiome research. Also joining in are the Department of Energy, which plans to spend $10 million on interests such as the potential for producing biofuels, and NASA, which is interested in searching for extraplanetary life and how microbes affect humans in space. Few, if any, science initiatives have included so many government agencies, Bertuzzi says. \u201cIt\u2019s gotten so complicated and so specialized,\u201d he says. \u201cThat\u2019s why we need initiatives like this.\u201d \n                   Scientists bust myth that our bodies have more bacteria than human cells 2016-Jan-08 \n                 \n                   Scientists debate mega-microbiome initiatives 2015-Oct-30 \n                 \n                   Microbiology: Create a global microbiome effort 2015-Oct-28 \n                 \n                   Mining the microbial dark matter 2015-Jun-16 \n                 \n                   Microbiology: Here's looking at you, squid 2015-Jan-14 \n                 \n                   Gut\u2013brain link grabs neuroscientists 2014-Nov-12 \n                 \n                   Microbiome therapy gains market traction 2014-May-13 \n                 \n                   White House fact sheet: National Microbiome Initiative \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19861", "url": "https://www.nature.com/articles/nature.2016.19861", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Effort to identify damaged areas combines crowdsourcing with machine-learning algorithms. After a magnitude-7.8 earthquake struck Ecuador\u2019s Pacific coast on 16 April, a new ally joined the international relief effort: a citizen-science network called Zooniverse. On 25 April, Zooniverse  launched a website  that asks volunteers to analyse rapidly-snapped satellite imagery of the disaster, which led to more than 650 reported deaths and 16,000 injuries. The aim is to help relief workers on the ground to find the most heavily damaged regions and identify which roads are passable. Several  crisis-mapping programmes  with thousands of volunteers already exist \u2014 but it can take days to train satellites on the damaged region and to transmit data to humanitarian organizations, and  results have not always proven useful . The Ecuador quake marked the first live public test for an effort dubbed the  Planetary Response Network (PRN) , which promises to be both more nimble than previous efforts, and to use more rigorous machine-learning algorithms to evaluate the quality of crowd-sourced analyses. The network relies on imagery from the satellite company Planet Labs in San Francisco, California, which uses  an array of shoebox-sized satellites  to map the planet. In order to speed up the crowd-sourced process, it uses the Zooniverse platform to distribute the tasks of spotting features in satellite images. Machine-learning algorithms employed by a team at the University of Oxford, UK, then classify the reliability of each volunteer\u2019s analysis and weight their contributions accordingly. \n             Rapid-fire data \n           Within 2 hours of the Ecuador test project going live with a first set of 1,300 images, each photo had been checked at least 20 times. \u201cIt was one of the fastest responses I\u2019ve seen,\u201d says Brooke Simmons, an astronomer at the University of California, San Diego, who leads the image processing. Steven Reece, who heads the Oxford team\u2019s machine-learning effort, says that results \u2014 a \u201cheat map\u201d of damage with possible road blockages \u2014 were ready in another two hours. In all, more than 2,800 Zooniverse users contributed to analysing roughly 25,000 square kilometres of imagery centred around the coastal cities of Pedernales and Bahia de Caraquez. That is where the London-based relief organization Rescue Global \u2014 which requested the analysis the day after the earthquake \u2014 currently has relief teams on the ground, including search dogs and medical units. The resolution of Planet Labs\u2019s pictures \u2014 roughly 3\u20135 metres per pixel \u2014 is not high enough to assess individual-building damage reliably, but the images can be used to identify heavily damaged regions and roads. \u201cFor what Rescue Global needs \u2014 basically, where\u2019s the worst damage and are the main roads okay \u2014 we\u2019re in the sweet spot with Planet Labs's imagery,\u201d says Simmons. \n             Future scope \n           The data have been challenging to work with, but they have succeeded in helping relief workers to plan which roads to take and which to avoid, says chief executive of Rescue Global, David Jones. He warns against hyping a technology that is still in its early days, but he thinks that PRN systems \u201cwill contribute to saving lives and mitigating risk \u2026 in the very near future\u201d. The Ecuador project is a proof-of-principle test and shows that the PRN can operate at large scale, Simmons says. (It will only activate when a relief agency on the ground requests its analysis, however.) Meier says that details of future image sharing from Planet Labs have not yet been worked out, but he is optimistic about the imagery. For this test, imagery was supplemented with pre-disaster images from the European Space Agency\u2019s Sentinel-2 satellite, but Planet Labs hopes that in future, it will have a web of small, globe-encircling satellites that can take accurate snapshots every 24 hours. These images could be downloaded, crowd-tagged and analysed before other efforts are able to point higher-resolution satellites to an area, or send drones to assess damage of individual buildings. \u201cI think Planet Labs will be the first on the scene,\u201d says Patrick Meier, who leads the humanitarian-impact team at the company. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Crisis mappers turn to citizen scientists 2014-Nov-19 \n                 \n                   Crowdsourcing goes mainstream in typhoon response 2013-Nov-20 \n                 \n                   Citizen science goes 'extreme' 2012-Feb-17 \n                 \n                   Planetary Response Network website \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19951", "url": "https://www.nature.com/articles/nature.2016.19951", "year": 2016, "authors": [{"name": "Brian Owens"}], "parsed_as_year": "2006_or_before", "body": "Government's 'global challenges' fund hoovers up extra cash for developing-world problems, cutting grants elsewhere. Funds dedicated for research on developing-world problems will eat into the core science grants of the United Kingdom's research councils over the next five years, documents released by the councils show. After enduring years of flat funding, scientists had celebrated in November as the  government committed to increasing science spending , rather than delivering the cut many had feared was imminent. But although the science budget \u2014 which in 2016 will be \u00a34.7 billion (US$7.1 billion) \u2014 will rise in line with inflation, some of it will be diverted into government-defined research programmes. The remaining portion \u2014 the \u2018responsive-mode\u2019 allocation that the research councils hand out on the basis of competitive applications from scientists \u2014 will fall. \u201cIt's going to be a very constrained situation going forward,\u201d says Alison Davenport, a materials scientist at the University of Birmingham and chair of the Science and Technology Facilities Council science advisory board. That constraint is down to the creation of a Global Challenges Research Fund (GCRF), dedicated to research that addresses the problems faced by developing countries and backed with \u00a31.5 billion for 2016\u201320. The fund was announced in November, but the release of the research councils\u2019 delivery plans  earlier this month \u00a0makes clear exactly how much cash is being allocated to the GCRF by the government and what this will mean for responsive-mode grants.\u00a0 \n             More cuts to come? \n           In 2015\u201316, the six science-based research councils have \u00a32.3 billion in their day-to-day 'resource' spending. This will be roughly the same in 2020, but by then the councils will have been allocated around \u00a393 million per year for the GCRF, with a concomitant cut to the rest of the resource spending of around 5%. James Wilsdon, who studies research policy at the University of Sheffield, warns that there could be even more pain to come, as another new fund is also on the way. This will fund interdisciplinary research and could slice another 3\u20135% from councils' research budgets, he says. The combination of money being taken by the GCRF and this new fund will mean the amount available for traditional grants is even further reduced,\u00a0says Wilsdon. \u201cIt's pretty bad news for bottom-up, researcher-led research, in favour of more directed work.\u201d Andrew Steele, a computational biologist at London\u2019s Francis Crick Institute and vice-chair of the campaign group Science is Vital, points out that even the money promised for the GCRF is not exactly new. It comes from the budget of the Department for International Development, and is part of the United Kingdom's commitment to spend 0.7% of its gross national income\u00a0on overseas aid. \u201cIt's taken from one department and tacked on to the research councils, so it looks like the budget is going up,\u201d he says. \u201cBut the total amount of money for science is the same as before.\u201d \n             Winners and losers \n           Details on how the global-challenges fund will work are scarce. A modest portion of its budget will go directly through the research councils, but the lion's share will be controlled by  a new 'super-council'  called UK Research and Innovation. This will in future\u00a0absorb the research councils as well as several other aspects of UK research funding, the government announced on 16 May. Mark Claydon-Smith, the GCRF programme manager for Research Councils UK, says that the fund will award money in areas aligned with Britain's strategic priorities for overseas aid, as well as the United Nations' Sustainable Development Goals. He says that the fund will \u201cfollow the norms of the research councils\u201d \u2014 for example, it will have an independent advisory board to guide its strategic direction and will consult with the research community. \u201cIt's very formative at the moment, we're just developing the processes and structures,\u201d he says. \u201cWe expect to consult the research community over the next several months to refine and develop the broad themes, and make sure the agenda makes sense.\u201d The first calls for proposals using the research councils\u2019 portion of the GCRF  were released on 13 May , offering more than \u00a340 million for work in agriculture, food, infectious diseases and non-communicable diseases. Lee Cronin, a chemist at the University of Glasgow, points out that it will be easier for some researchers to take part than others \u2014 much of the work done by biomedical researchers, for example, is already relevant to international-development work. \u201cIt will be harder for others to do work that falls into this fund,\u201d he says. Although Cronin welcomes the new fund \u2014 \u201cit's a great way to incentivize scientists to help the world\u201d, he says \u2014 he still would have liked to see an increase in conventional grants too. \u201cI don't mind the challenge,\u201d he says. \u201cBut if the research base is eroded, my ability to respond to that challenge is eroded.\u201d \n                   UK scientists celebrate slight rise in research budget 2015-Nov-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19795", "url": "https://www.nature.com/articles/nature.2016.19795", "year": 2016, "authors": [{"name": "Nala Rogers"}], "parsed_as_year": "2006_or_before", "body": "Researchers pinpoint gene for beak-size and track how it changed during a severe drought. Researchers are pinpointing the genes that lie behind the varied beaks of Darwin\u2019s finches \u2013 the iconic birds whose facial variations have become a classic example of Charles Darwin's theory of natural selection.\u00a0 Last year, researchers  identified a gene  that helps to determine the shape of the birds\u2019 beaks 1 . Today in  Science,  they report a different gene that controls beak size 2 .\u00a0Shifts in this gene underlay an evolutionary change that researchers watched in 2004\u201305, during a drought that ravaged the Galapagos Islands, where the finches live. The beak sizes of one population of finches shrank, so as to avoid competing for food sources with a different kind of finch \u2013 and their genetics changed accordingly. \u201cA big question was, \u2018Is it possible to identify genes underlying such evolution in action, even in a natural population?\u2019,\u201d says Leif Andersson, a geneticist at Uppsala University in Sweden and one of the study\u2019s authors. \u201cWe were able to nail down genes that have directly played a role in this evolutionary change.\u201d The story begins about two million years ago, when the common ancestor of all Darwin\u2019s finches arrived on the Galapagos Islands. By the time of Charles Darwin\u2019s visit in 1835, the birds had diversified into more than a dozen species, each adapted to different ecological niches.\u00a0Some had massive beaks for cracking seeds, some had delicate beaks for snatching insects, and some even had sharp beaks for feeding on blood.\u00a0 To examine the genetic basis for this variation, the researchers compared the genomes of 60 birds representing six species of Darwin\u2019s finches, along with 120 specimens from other species to help them tease out phylogenetic relationships. As expected, closely related species had the most similar genomes. \n             Gene for size \n           But in those six finch species one region of the genome correlated more with bird size than with relatedness. Small species had one variation of this genomic region, large species had another and medium-sized species had a mixture of the two, suggesting that at least one of the genes in this region affected size. The most likely candidate was  HMGA2 , which is known to affect size and face structure in other animals. Further analysis showed that in Darwin\u2019s finches, the  HMGA2  region is especially important in controlling the size of the beak. The researchers then looked at the role of  HMGA2  in a dramatic evolutionary event. After drought struck the Galapagos in 2003, many of the medium ground finches ( Geospiza fortis ) with larger-than-average beaks starved to death. They couldn\u2019t compete with a bigger species ( Geospiza magnirostris ) that had recently colonized the island and was better at eating large seeds. After the drought, the medium ground finches that managed to survive had smaller beaks than those that had perished, probably because they were better suited to eating the small seeds that their competitors avoided. By analysing DNA from medium ground finches that lived around the time of the drought, the researchers found that the large-beak  HMGA2  variant was more common in birds that starved to death, while the small-beak variant was more common in birds that survived. This genetic shift is likely responsible for some of the reduction in beak size, the researchers say. The discovery opens up new questions for biologists to explore, such as when gene variants arise and how they contribute to splits between species, says Dolph Schluter, an evolutionary biologist at the University of British Columbia in Vancouver, Canada. \u201cOn the one hand it doesn't change anything, in that we already knew there was an evolutionary response to competition during that drought,\u201d says Schluter. \u201cBut on the other hand, it changes everything, because we can point to a physical, material basis for that change.\u201d  \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Evolution of Darwin\u2019s finches and their beaks revealed by genome sequencing 2015-Feb-11 \n                 \n                   Darwin\u2019s iconic finches join genome club 2015-Feb-11 \n                 \n                   Darwin's finches tracked to reveal evolution in action 2009-Nov-16 \n                 \n                   The calmodulin pathway and evolution of elongated beak morphology in Darwin's finches 2006-Aug-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19796", "url": "https://www.nature.com/articles/nature.2016.19796", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Third European Union flagship will be similar in size and ambition to graphene and human brain initiatives. The European Commission has quietly  announced  plans to launch a \u20ac1-billion (US$1.13 billion) project to boost a raft of quantum technologies \u2014 from secure communication networks to ultra-precise gravity sensors and clocks.\u00a0 The initiative, to launch in 2018, will be similar in size, timescale and ambition to two existing European flagships, the decade-long  Graphene Flagship  and the  Human Brain Project , although the exact format has yet to be decided, Nathalie Vandystadt, a commission spokesperson, told  Nature . Funding will come from a mixture of sources, including the commission, as well as other European and national funders, she added. The commission is likely to have a \u201csubstantial role\u201d in funding the flagship, says Tommaso Calarco, who leads the Integrated Quantum Science and Technology centre at the Universities of Ulm and Stuttgart in Germany. He co-authored a blueprint behind the initiative, which was published in March, called the  Quantum Manifesto.  Countries around the world are investing in these technologies, says Calarco. Without such an initiative, Europe risks becoming a second-tier player, he says. \u201cThe time is really now or never.\u201d On 19 April, the commission formally announced its intention to support the initiative. Confusingly, the project is included under plans to launch a cloud-computing portal called the  European Open Science Cloud , even though the remit of the quantum project will extend far beyond computing. (In the same announcement, the commission said it would spend \u20ac2 billion on the cloud-computing initiative by 2020).\u00a0 \n               Quantum buzz \n             High-profile  US companies are already investing in quantum computing , and Chinese scientists are nearing the completion of a  2,000-kilometre long quantum-communication  link \u2014 the longest in the world \u2014 to send information securely between Beijing and Shanghai. In Europe, the flagship is expected to fuel the development of such technologies, which the commission calls part of a \u201csecond quantum revolution\u201d (the first being the unearthing of the rules of the quantum realm, which led to the invention of equipment such as lasers and transistors). The initiative will include support for relatively near-to-market systems, such as quantum-communication networks, ultra-sensitive cameras, and  quantum simulators  that could help to design new materials. It will also look to the longer term, pushing more-futuristic visions such as all-purpose quantum computers and  high-precision sensors  that fit into mobile phones. Success will be judged by how well the flagship succeeds in boosting industry take up of the technologies and in seeding investment in the field, says Calarco. \u201cIf this doesn\u2019t happen, it will be a failure. But everyone is very confident it will,\u201d he says. Quantum-technology projects already exist in several individual European Union countries, such as the  UK Quantum Technologies Programme  and the Netherlands\u2019 QuTech initiative, notes Marco Genovese, a quantum physicist at the Italian National Institute of Metrological Research in Turin. But to reach commercial level in the near future, an EU-wide initiative is essential, he says. \u201cAt the moment, EU industry is still only marginally involved,\u201d he says. \n               Quieter birth \n             Europe\u2019s graphene and brain-project flagships were announced with great fanfare in 2013 after a multiyear competition, but the latest initiative has had a much quieter birth. Calarco says that it was driven by an 18-month dialogue between the commission and a group of researchers who, at the organization\u2019s request, produced the manifesto. Not everyone is pleased with the commission\u2019s new approach. Hans Lehrach, a geneticist at the Max Planck Institute for Molecular Genetics in Berlin, points out that a narrower but similar proposal surrounding quantum-based information technology, called ICT Beyond Limits, was considered but did not make the shortlist for the 2013 flagship competition. \u201cI find it very surprising that a project which had already been eliminated in the first round in the last flagship competition is simply announced as a new flagship project, without any form of competition of different ideas and concepts against each other,\u201d he says. Unsuccessful shortlisted proposals from the 2013 competition \u2014 such as his own, which was designed to use data and information technology to improve healthcare \u2014 also deserved consideration this time around, he argues. Choosing flagships on the basis of bilateral discussions and manifestos risks turning them into \u201ca competition of lobbying, rather than of arguments evaluated objectively in a fair competition of scientific ideas\u201d, adds Adrian Ionescu, a nanoscientist at the Swiss Federal Institute of Technology in Lausanne. He led another shortlisted proposal, the Guardian Angels for a Smarter Life project, which would develop sensors to track environmental pollution and human health. The commission says that it is still running a separate consultation to identify candidates for future flagship projects, and that the quantum initiative does not prevent other flagships being launched. Funds for the first phase of the quantum initiative in 2018, it added, would be granted to proposals evaluated by panels of independent experts. Genovese warns that the new project must be careful to avoid the problems faced by existing giant flagships, which included  accusations of mismanagement and veering off course . \u201cThe building of the flagship must involve all the main research groups that have really significantly worked in the field through a bottom-up approach, and the concentration of power should be avoided,\u201d he says. The commission is set to announce more details on the initiative at the Quantum Europe Conference in Amsterdam on 17\u201318 May, at which the manifesto will also be officially launched. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Physics: Unite to build a quantum Internet 2016-Apr-12 \n                   \n                     Troubled billion-euro Brain Project unlocks more funding 2015-Nov-02 \n                   \n                     Quantum communications leap out of the lab 2014-Apr-23 \n                   \n                     Quantum physics: Flawed to perfection 2014-Jan-22 \n                   \n                     Graphene: The quest for supercarbon 2013-Nov-20 \n                   \n                     Simulation: Quantum leaps 2012-Nov-14 \n                   \n                     Quantum Manifesto \n                   \n                     European Commission announcement \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19794", "url": "https://www.nature.com/articles/nature.2016.19794", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Largest-ever genetic-sequencing study of healthy ageing released. Scientists who have studied the genomes of hundreds of healthy older people say that one of their secrets might be genetic protection against the loss of mental function.The researchers' study, published on 21 April in  Cell 1 , is the largest ever to sequence the genomes of people who have lived long, disease-free lives. Cardiologist Eric Topol of the Scripps Translational Science Institute in La Jolla, California, a leader of the work, says that one of the most difficult challenges was simply to find people who have lived to an old age (around 80 and upwards in this instance) without suffering autoimmune disease, blood clots, most cancers, diabetes, dementia, heart attack, kidney failure or stroke. Topol\u2019s daughter Sarah drove to retirement facilities throughout southern California to recruit people without these conditions, and who were not taking any medication, for the study. Recruits from elsewhere in the United States and other countries heard about the study through word of mouth. \u201cThey\u2019re too smart to go to doctors or be in hospitals so you would never get them in a medical center \u2014 you have to go to them,\u201d Topol says. \n             Genetic differences \n           One of the big questions that his group wanted to address was whether these 'Wellderly' (well elderly) are genetically different from either people who don't reach very old age, or those who do thanks to medical interventions (such as drugs for controlling blood pressure or cholesterol). The team compared the sequenced genomes of 511 long-lived well elderly people with those of 686 adults\u00a0who had been sequenced for a different study and represented the general population. The scientists found that, as a group, the well elderly had a lower genetic risk of Alzheimer\u2019s disease and coronary artery disease than the control group, but were at roughly the same genetic risk of developing diabetes and cancer. Ten of the long-lived volunteers, and none of the control population, carried rare variants of a gene called  COL25A1 , a gene that has been associated with the brain plaques seen in patients with Alzheimer\u2019s disease. This result was not statistically significant, but the study authors suggest that this may be because of the small number of well elderly people available. \n             Health and longevity \n           Topol says that the results suggest that healthy long-lived people are genetically distinct from people who reach extreme old age having survived major health problems. Other researchers think that the jury is still out. Marian Beekman, a genetic epidemiologist at Leiden University Medical Center in the Netherlands, says that the well elderly are also more educated, on average, than the general population \u2014 and higher educational attainment is known to be associated with longer lifespan. This makes it difficult to tell whether the Wellderly live longer because of genetic protection from cognitive decline, or because they are more aware of disease risk and have better access to preventive medical care. Beekman also says that the study shows some of the limitations of large genetic-sequencing studies aimed at understanding health and disease risk. She argues that the findings could have been uncovered with a study of genetic variants, called single nucleotide polymorphisms (SNPs) \u2014 a quicker and cheaper way to look at genetic risk than using full genetic sequencing. The project may be the largest ever case-control study \u2014 a type of study that compares people with one condition to those without it \u2014 in which the genomes of all participants were sequenced. But it still recruited relatively few people compared with typical genome-wide association studies, which can analyse SNPs in hundreds of thousands of people. \u201cResearchers want to use the fancy NGS data,\u201d Beekman says, referring to next-generation sequencing. \u201cBut we do not yet know how it could be of value in population genetics, because there is not enough data around to make significant observations.\u201d  \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Anti-ageing pill pushed as bona fide drug 2015-Jun-17 \n                 \n                   Selling long life 2015-Jan-09 \n                 \n                   Old as time: What we can learn from past attempts to treat aging 2014-Dec-04 \n                 \n                   Pet dogs set to test anti-ageing drug 2014-Oct-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19802", "url": "https://www.nature.com/articles/nature.2016.19802", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Giant survey suggests journals should pay more attention to detecting inappropriate duplications. Around 1 out of every 25 biomedical papers contains inappropriately duplicated images, a huge analysis of 20,621 research articles suggests 1 . The finding has prompted renewed calls for research journals to routinely check images in accepted papers before they publish them. Previous studies have analysed image duplication rates, but the latest analysis is unusually large and has the advantage of spanning multiple journals, says Bernd Pulverer, who is chief editor of  The EMBO Journal  in Heidelberg, Germany. He notes that although most duplications do not point to fraud or malevolence, they do misrepresent experiments. \"The rates were higher than I had initially expected,\u201d says Elisabeth Bik, a sharp-eyed microbiologist who led the analysis. Though she still thinks most scientists are honest, she had even higher expectations when she began the project, she says. Bik, who is at Stanford University in California, spent two years looking at articles published from 1995 to 2014 in 40 different journals, hunting for instances in which identical images were used to represent different experiments within the same paper. She cross-checked the duplications that she found with her two co-authors, both microbiologists. Overall, 4% of the inspected papers contained such images, the researchers found. But rates ranged from over 12% in the  International Journal of Oncology , to 0.3% in the  Journal of Cell Biology , which has since 2002 systematically scanned images in its accepted papers before publication. Journals with higher impact factors generally had lower rates of duplicated images. The study, which has not yet been peer-reviewed, was  posted on the biology preprint server bioRxiv  on 20 April, and was first reported by the  Retraction Watch  blog. \n             Sloppy mistakes? \n           Many of the problems were probably sloppy mistakes where people selected the wrong photograph, says Bik. But half or more look deliberate \u2014 because images are flipped or rotated or the same features occur twice in the same photograph. The 4% duplicated image rate is about what Pulverer would expect. Unlike most journals, his has screened images in papers it accepts since 2012 \u2013 and last year reported that it finds image aberrations (including problems other than duplication) in around 20% of papers 2 . When the journal editors look at the raw data, they usually find that the issue can be corrected before publication, Pulverer adds; only in a few cases do they end up rejecting the paper.  Previous studies have found higher rates of image duplication than Bik's team, but it's not clear that they are directly comparable. A small study of 120 cancer-biology papers in three journals, published last year, found that one-quarter contained duplicated figures \u2014 but only around 1 in 8 (13%) were the inappropriate kind that Bik's team were hunting, notes Bik  3 . She adds that she screened 427 papers in the same journals, and found the average problematic duplication rate to be 6.8%. Still, both Bik and Pulverer think that their screens miss duplications because they would not detect well-executed fraud or duplications across different papers. \n             Quality control \n           In 2013, Enrico Bucci, who heads the biomedical services and information consultancy firm BioDigitalValley in Aosta, Italy,  told  Nature  that he had examined gel images in biomedical papers authored by Italian scientists with close links to researchers who had retracted papers and found that about one-quarter contained anomalous images (including issues wider than duplications). Around 10% contained breaches such as cutting and pasting of gel-electrophoresis bands. Overall, fewer than 1% of research papers are corrected each year, according to data from Thomson Reuters' Web of Science; retraction rates, despite a recent rise, are at around 0.02% 4 . Bik\u2019s findings \u201cadd to a body of evidence that has indicated there is an urgent need to institute better quality-control mechanisms at journals\u201d, says Pulverer. He says that several publishers have contacted him to learn how to set up  systematic screening for accepted papers , which should help to stamp out inaccurate data before it is printed. The scientific community also needs to improve with more training, self-policing and a stronger sense of publication ethics, he adds. Bik says that she has reported all the papers with duplicated images to journals, which has so far resulted in 62 corrections and 6 retractions. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   The image detective who roots out manuscript flaws 2015-Jun-12 \n                 \n                   Image search triggers Italian police probe 2013-Dec-04 \n                 \n                   Meeting targets lab lapses 2013-May-14 \n                 \n                   Science publishing: The trouble with retractions 2011-Oct-05 \n                 \n                   Science journals crack down on image manipulation 2009-Oct-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19778", "url": "https://www.nature.com/articles/nature.2016.19778", "year": 2016, "authors": [{"name": "Olive Heffernan"}], "parsed_as_year": "2006_or_before", "body": "Intergovernmental body that tracks world ecosystems is criticized for its own lack of diversity. A global science body set up to assess the ecological health and biodiversity of the planet is struggling to solve its own lack of diversity: a monoculture of natural scientists on its staff. The Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES) was  established in 2012  to assess scientific and local knowledge on the state of the natural world. From the outset, the United Nations body planned to recruit a mixture of specialists to help to inform its reports: from natural scientists and economists to social scientists, anthropologists, environmental philosophers and indigenous peoples such as fishers and farmers with local knowledge about their environment. But that hasn\u2019t happened, concedes IPBES chair Robert Watson, a climate scientist at the UK\u2019s Tyndall Centre for Climate Change Research in Norwich who formerly chaired the Intergovernmental Panel on Climate Change (IPCC) \u2014 the organization on which IPBES is roughly modelled. \u201cWe have to up our game,\u201d he says. \u201cWe\u2019re now asking experts within IPBES to talk to people in their communities, to explain what IPBES is about and show that social scientists have a key role.\u201d He and other researchers emphasized the need for the organization to reach out to social scientists in a  correspondence published on 20 April in  Nature . But IPBES has also decided to postpone its main social-sciences programme for 2016 \u2014 which critics say won\u2019t endear the organization to the people it is now urgently trying to recruit. \n             Lack of diversity \n           IPBES does not publish data on the disciplinary diversity of the authors of its reports, which itself is an annoyance for critics, but some researchers have pieced together estimates. In February, a few days before IPBES held a meeting in Kuala Lumpur to release its first report \u2014 on  the global decline of pollinators  \u2014 three academics  estimated in another correspondence to  Nature  that the social sciences and humanities made up less than 10% of most expert groups within IPBES. They argued that the proportion should be at least 30%. Alice Vadrot, a political scientist at the University of Cambridge, UK, who co-authored that correspondence, says that one reason for the imbalance may be a difference in world view between specialists. Environmental ethicists and anthropologists \u2014 the kinds of academic that IPBES wants to attract \u2014 might be put off by language such as \u2018ecosystem services\u2019 that dominates IPBES programmes, which is more typically used by economists and natural scientists, she says. Another difficulty, as Watson sees it, is that there\u2019s more funding for natural scientists to do environmental research than there is for social scientists \u2014 making for a larger pool of experts to choose from. But others say that a major problem is how IPBES picks its experts. Processes for nominating IPBES authors are largely handled through UN member states\u2019 environment ministers, who typically have contacts within the natural-science community, says Watson. From those nominated, researchers within IPBES are supposed to select men and women from different geographical regions and with diverse expertise \u2014 but given the slim pickings they have to choose from, this doesn\u2019t always happen. A fairer process, says Malte Timpte, a political scientist at the Natural History Museum, Berlin, who attended the Kuala Lumpur meeting as an observer on behalf of the non-profit German Network-Forum for Biodiversity Research, might start by altering the rule that 80% of authors must be selected from nominations by UN member states and just 20% from environmental or scientific organizations, such as the International Union for the Conservation of Nature. The IPCC does not stipulate such a split, for instance. But Watson argues that governments are better placed than non-governmental organizations to make recommendations. \n             Social science on hold \n           IPBES\u2019s failure to attract more diversity isn\u2019t for lack of will, says Esther Turnhout, a political scientist at Wageningen University, the Netherlands. But she does think there have been missed opportunities. At its February meeting, for instance, IPBES said that it would postpone some of this year\u2019s programmes \u2014 one of which is a report on understanding the diverse ways in which people value biodiversity and nature\u2018s benefits. \u201cThis is the main social science deliverable, so now it will be even harder to attract social scientists,\u201d says Turnhout. Instead, member states voted to go ahead with a global assessment of biodiversity, as well as several regional assessments and a report on land degradation. Watson says that the postponements were needed because IPBES is not getting funding fast enough (it hopes to raise US$42.7 million by 2019, and will have accrued $28 million by the end of 2016). \u201cMany governments can only promise one year of funding at a time,\u201d he says, adding that member states were also concerned about the heavy workload associated with kicking off so many work packages simultaneously. Another contentious outcome of the February meeting was a decision to scrap a mid-term external review of IPBES\u2019s performance. Instead, the organization will have one external independent review, probably in 2019, when its biodiversity global assessment is complete. \u201cIt\u2019s regrettable because that would have been a good opportunity to look at how IPBES is performing\u201d, says Turnhout. \u201cInternally we will have reviews\u201d, says Watson. \u201cWe want to be honest about those, because we all have an interest in making this work\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Disciplinary balance: How to engage social scientists in IPBES 2016-Mar-09 \n                 \n                   Global biodiversity report warns pollinators are under threat 2016-Feb-26 \n                 \n                   Social sciences: IPBES disciplinary gaps still gaping 2016-Feb-10 \n                 \n                   IPBES: Biodiversity panel should play by rules 2014-Feb-12 \n                 \n                   Policy: Biodiversity needs a scientific approach 2012-Oct-03 \n                 \n                   Conservation policy: Listen to the voices of experience 2012-Aug-22 \n                 \n                   World governments establish biodiversity panel 2012-Apr-23 \n                 \n                   New UN science body to monitor biosphere 2010-Jun-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19776", "url": "https://www.nature.com/articles/nature.2016.19776", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Trials of mindfulness to improve mental health selectively report positive results. There\u2019s a little too much wishful thinking about mindfulness, and it is skewing how researchers report their studies of the technique. Researchers at McGill University in Montreal, Canada, analysed 124 published trials of mindfulness as a mental-health treatment, and found that scientists reported positive findings 60% more often than is statistically likely. The team also examined another 21 trials that were registered with databases such as ClinicalTrials.gov; of these, 62% were unpublished 30 months after they finished. The findings \u2014 reported in  PLoS ONE  on 8 April 1  \u2014 hint that negative results  are going unpublished . Mindfulness is the practice of being aware of thoughts and feelings without judging them good or bad. Mental-health treatments that focus on this method include mindfulness-based stress reduction \u2014 an 8-week group-based programme that includes yoga and daily meditation \u2014 and mindfulness-based cognitive therapy. A bias toward publishing studies that find the technique to be effective withholds important information from mental-health clinicians and patients, says Christopher Ferguson, a psychologist at Stetson University in Florida, who was not involved in the study. \u201cI think this is a very important finding,\u201d he adds. \u201cWe\u2019ll invest a lot of social and financial capital in these issues, and a lot of that can be misplaced unless we have good data.\u201d \n             Publication bias \n           For the 124 trials, the researchers calculated the probability that a trial with that sample size could detect the result reported. Experiments with smaller sample sizes are more affected by chance and thus worse at detecting statistically significant positive results. The scientists\u2019 calculations suggested that 66 of 124 trials would have positive results. Instead, 108 trials had positive results. And none of the 21 registered trials adequately specified which of the variables they tracked would be the main one used to evaluate success. This doesn\u2019t necessarily suggest that none of the mindfulness treatments work, says study co-author Brett Thombs, a psychologist at McGill and at the Jewish General Hospital in Montreal. \u201cI have no doubt that mindfulness helps a lot of people,\u201d he says. \u201cI\u2019m not against mindfulness. I think that we need to have honestly and completely reported evidence to figure out for whom it works and how much.\u201d Trials with larger sample sizes \u2014 and thus more statistical power \u2014 would be an improvement. In the McGill team's analysis, the 30 trials with the most statistical power showed no over-reporting of positive results. The bias towards reporting positive results is pervasive across many types of  mental health, psychology and medical research , says Ferguson. For example, the widely popularized theory of ego depletion \u2014 that people have limited self-control for decisions \u2014 recently  failed to hold up  in a large replication trial. \u201cA lot of these things are reported to be true, they\u2019re in a TEDx talk,\u201d he says. \u201cNow we're seeing, when we look at things much more closely,\u00a0we\u2019ve kind of been bullshitting people [for] a decade.\u201d He advocates  pre-registering studies , in which a journal reviews and accepts a study \u2014 including the outcomes that it will measure \u2014 before data collection begins. This way, the journal publishes the trial results regardless of whether they are negative or positive. Without this kind of agreement, journals are more likely to publish only positive results, and scientists need published papers to get funding and tenure. This creates a perverse incentive that does not make sense from a care standpoint. \u201cFor the health-care system,\u201d says Thombs, \u201cit\u2019s just as important to know what doesn\u2019t work.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Academics fall short in reporting results of clinical trials 2016-Feb-22 \n                 \n                   Registered clinical trials make positive findings vanish 2015-Aug-13 \n                 \n                   US government cracks down on clinical-trials reporting 2014-Nov-19 \n                 \n                   Social sciences suffer from severe publication bias 2014-Aug-28 \n                 \n                   We dislike being alone with our thoughts 2014-Jul-03 \n                 \n                   US behavioural research studies skew positive 2013-Aug-26 \n                 \n                   Beware the creeping cracks of bias 2012-May-09 \n                 \n                   Beware the creeping cracks of bias 2012-May-09 \n                 \n                   Christopher Ferguson \n                 \n                   Brett Thombs \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19804", "url": "https://www.nature.com/articles/nature.2016.19804", "year": 2016, "authors": [{"name": "Reinaldo Jose Lopes"}], "parsed_as_year": "2006_or_before", "body": "Brazil's health-regulatory agency wants more evidence before allowing sale of GM mosquitoes. The UK biotechnology firm Oxitec has been waiting two years for permission to sell genetically modified mosquitoes to battle dengue fever in Brazil. But the company now knows that it will have to wait a good while longer before it can sell its insects for release in Brazilian municipalities. After much deliberation, Brazil\u2019s health-regulatory agency, Anvisa, declared on 12 April that it would regulate Oxitec\u2019s mosquitoes \u2014 effectively, classing them as a novel medical technology. Anvisa says that it is now creating a legal framework that could pave the way for the commercial release of the GM insects. For that to happen, it wants Oxitec to demonstrate not only that its technology is safe, but also that it can reduce the transmission of mosquito-borne viruses.\u00a0 Oxitec\u2019s  Aedes aegypti  insects carry a gene that causes their offspring to die young. The release of millions of the male GM mosquitoes could, the firm hopes, cause population crashes in the wild mosquito population that spreads dengue and Zika virus. (The technique is not the only proposal put forth to reduce mosquito populations: others include technology known as  gene drives , or  the release of mosquitoes infected with a bacterium  that stops dengue virus from replicating.) The company says that it has already shown that its insects are safe, and that releasing them can cause  A. aegypti  populations to plummet. But it has not yet published evidence that this effect definitely reduces disease. Anvisa declined to tell  Nature  whether it had a timetable for a final verdict concerning commercial release, or what data on safety and efficacy it would require. \n             Clamour for release \n           Oxitec\u2019s evidence comes from  earlier field trials  that it has run in Brazil and elsewhere. In 2014, Brazil\u2019s national biosafety body, CTNBio, which is responsible for regulating transgenic organisms and approved the Brazilian trials, declared the mosquitoes safe for commercial release. Since that decision was made, clamour to release the mosquitoes as a commercial product has grown.  The recent spread of Zika virus through Brazil  has further fuelled support for novel weaponry against its carrier,  A. aegypti.  But some scientists and environmental groups have argued that the transgenic mosquito's environmental safety isn't certain, despite CTNBio\u2019s clearance. And uncertainty over Anvisa\u2019s potential regulatory role has stalled any progress. Oxitec says that Anvisa\u2019s latest decision puts its trials on a surer footing (if only because the involvement of Brazil\u2019s health regulator may assuage earlier criticism of CTNBio\u2019s decision-making). Anvisa says that it has given the firm a temporary license to run research trials. \u201cThe important point is that things are moving along again,\u201d says Glen Slade, the firm\u2019s head of business development in Brazil. \n             Field-trial evidence \n           Last year, the company published a paper showing that its release of GM mosquitoes in a suburb of Juazeiro, in Bahia state in Brazil, could \u2014 at least for a season \u2014 reduce the population of wild-type  A. aegypti  by as much as 90% 1 . It argued that the sustained release of transgenic insects \u201cwould likely be sufficient to prevent dengue epidemics in the locality tested\u201d. Pedro Antonio de Mello, municipal secretary of health in Piracicaba, in the state of S\u00e3o Paulo, says that a similar trial conducted by Oxitec in his city has provided some real evidence of a decrease in dengue cases, although this has not yet been published. In a small, 5,000-person neighbourhood within Piracicaba in which transgenic mosquitoes were released, confirmed cases of dengue have fallen from 132 in the 2014\u201315 dengue season to just 4 in 2015\u201316 so far. Detailed epidemiological data from the trial is expected to be made public later this year, he says. A new batch of GM mosquitoes will be released in Piracicaba in the next few weeks, in a more populated area. Other cities in Brazil\u2019s northeast region may also receive batches of transgenic mosquitoes in the near future, Slade says, but he did not say which.\u00a0 Oxitec is in the early stages of planning a study that could prove that the GM mosquitoes reduce viral transmission, but it could be a \u201cmultimillion-dollar endeavour\u201d that takes several years, says Simon Warner, the company's chief scientific officer. The idea would be to choose multiple test sites and run the mosquito intervention in half of them. By monitoring dengue (or Zika) infections with blood tests, it should be possible to show whether targeted areas see a significant reduction in disease. Warner says that he is working on the trial design, but that there is no clear timetable for it yet; the firm would need partnerships with medical scientists, community engagement and evaluation by ethics committees. Even if the transgenic mosquitoes can be proven to reduce dengue or Zika infections, it is possible that natural selection could reduce their effectiveness. Females could develop a preference for wild-type  A. aegypti  males \u2014 stopping the company's currently furthest-developed lineage of GM insects (called OX513A) from spreading in the wild. \u201cIt\u2019s hard to say if this lineage is going to solve the problem once and for all,\u201d says Margareth Capurro-Guimar\u00e3es, a molecular biologist at the University of S\u00e3o Paulo, who was part of the team that released GM mosquitoes in Oxitec's first field trials. \u201cWe need to keep on working to breed improved lineages \u2014 it\u2019s ultimately a moving target.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   'Gene drive' mosquitoes engineered to fight malaria 2015-Nov-23 \n                 \n                   Brazil tests GM mosquitoes to fight Dengue 2012-Apr-11 \n                 \n                   Modified mosquitoes set to quash dengue fever 2012-Jan-10 \n                 \n                   Ecology: A world without mosquitoes 2010-Jul-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19797", "url": "https://www.nature.com/articles/nature.2016.19797", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Drug company aims to pool genomic and medical data in hunt for rare genetic sequences associated with disease. One of the world\u2019s largest pharmaceutical companies has launched a massive effort to compile genome sequences and health records from two million people over the next decade. In doing so, AstraZeneca and its collaborators hope to unearth rare genetic sequences that are associated with disease and with responses to treatment. It\u2019s an unprecedented number of participants for this type of study, says Ruth March, vice-president and head of personalized health care and biomarkers at AstraZeneca, which is headquartered in London. \u201cThat\u2019s necessary because we\u2019re going to be looking for very rare differences among individuals.\u201d To achieve that ambitious goal, AstraZeneca will partner with research institutions including the Wellcome Trust Sanger Institute in Hinxton, UK, and Human Longevity, a biotechnology company founded in San Diego, California, by genomics pioneer Craig Venter. AstraZeneca also expects to draw on data from 500,000 participants in its own clinical trials, and medical samples that it has accrued over the past 15 years. In doing so, AstraZeneca will be following a burgeoning trend in genetics research. For years, geneticists pursued common variations in human DNA sequences that are linked to complex diseases such as diabetes and heart disease. The approach yielded some important insights, but these common variations often accounted for only a small percentage of the genetic contribution to individual diseases. Researchers are now increasingly focusing on the contribution of unusual genetic variants to disease. Combinations of these  variants  can hold the key to an individual's traits, says Venter. The hunt for important rare variants has led AstraZeneca to partner with the Institute for Molecular Medicine Finland, says Aarno Palotie, who heads the Human Genomics Program there. Finland\u2019s population was geographically isolated until recently, he notes, which makes for a unique genetic make-up. As a result, some variations that are very rare in other populations may be more common in Finland, making them easier to detect and study. \n               Familiar road \n             AstraZeneca did not disclose exactly how much it would be investing in the project \u2014 \u201chundreds of millions of dollars\u201d over the course of ten years was all that  Menelas  Pangalos , executive vice-president of the company's innovative medicines programme, would say. The company intends to use the data to inform drug development in all of its major disease areas, from diabetes to inflammation to cancer, says March. It is not the first time that a large drug company has poured money into genomics in hopes of fuelling drug discovery, notes David Goldstein, who studies human genetics at Columbia University in New York City and is an adviser to AstraZeneca. \u201cGenomicists have for decades now been promising that genomics is going to revolutionize the way that medicines are developed and the way that medicines are used,\u201d he says. \u201cWe are now here saying it again.\u201d Those past efforts often disappointed, but the field has turned a corner, Goldstein adds. Genome sequencing is faster and cheaper than ever before, and researchers are armed with better bioinformatics tools to interpret the data. Advances in stem-cell biology and genome-editing methods such as CRISPR\u2013Cas9 are making it much easier for researchers to determine how a particular change in a DNA sequence affects living cells. In all, the project should generate about 5 petabytes of data. \u201cIf you put 5 petabytes on DVDs, it would be four times the height of the Shard,\u201d said Pangalos, referring to a nearly 310-metre London skyscraper. \u201cIf you wanted to put it on your iPod, it would take about 5,000 years to listen to it all.\u201d \n               Refined predictions \n             Much of that data will come from Human Longevity. The company, which ultimately hopes to accrue 10 million human genomes, already has 26,000 completed and paired with medical records. Its databases also contain additional partial genome sequences. \u201cWe\u2019re adding one about every 15 minutes on average,\u201d Venter says. Using DNA sequence alone, Venter says that his company can now predict a person\u2019s height, weight, eye colour and hair colour, and produce an approximate picture of their face. Much of that detail is lurking in rare sequence variations, says Venter, whose own genome has been in public databases for more than a decade. Human Longevity's databases are kept locked behind layers of security. \u201cIf I were advising a younger Craig Venter, I\u2019d say, \u2018Think carefully before you just dump your genome on the Internet\u2019,\u201d Venter says. \u201cThe levels of prediction are getting much more interesting.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Geneticists tap human knockouts 2014-Oct-28 \n                   \n                     Genetics: A gene of rare effect 2013-Apr-09 \n                   \n                     The view from the bottom of the patent cliff 2012-Nov-13 \n                   \n                     Humans riddled with rare genetic variants 2012-May-17 \n                   \n                     David Goldstein: Institute of Genomic Medicine \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19801", "url": "https://www.nature.com/articles/nature.2016.19801", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Enthusiasm comes amid worries that the therapy may prove too complex to manufacture. It is precision medicine taken to the extreme: cancer-fighting vaccines that are custom designed for each patient according to the mutations in their individual tumours. With early clinical trials showing promise, that extreme could one day become commonplace \u2014 but only if drug developers can scale up and speed up the production of their tailored medicines. The topic was front and centre at the American Association for Cancer Research (AACR) annual meeting in New Orleans, Louisiana, on 16\u201320 April. Researchers there described early data from clinical trials suggesting that personalized vaccines can trigger immune responses against cancer cells. Investors seem optimistic that those results will translate into benefits for patients; over the past year, venture capitalists have pumped cash into biotechnology start-ups that are pursuing the approach. But some researchers worry that the excitement is too much, too soon for an approach that still faces many technical challenges. \u201cWhat I do really puzzle at is the level of what I would call irrational exuberance,\u201d says Drew Pardoll, a cancer immunologist at Johns Hopkins University in Baltimore, Maryland. \n               Target practice \n             The concept of a vaccine to treat cancer has intrinsic appeal. Some tumour proteins are either mutated or expressed at different levels than in normal tissue. This raises the possibility that the immune system could recognize these unusual proteins as foreign \u2014 especially if it were alerted to their presence by a vaccine containing fragments of the mutated protein. The immune system\u2019s army of T cells could then seek out and destroy cancer cells bearing the protein. Decades of research into cancer-treatment vaccines have thus far yielded disappointing clinical trial results, but recent advances \u2014 including  a suite of drugs  that may amplify the effects of cancer vaccines \u2014 have rekindled hope for the field. And DNA sequencing of tumour genomes has revealed  a staggering diversity of mutations , producing proteins that could serve as \u2018antigens\u2019 by alerting the immune system. Last year, researchers reported that they had triggered an immune response in three patients with melanoma by  administering a vaccine tailored to their potential tumour antigens 1 . The vaccines' effects on tumour growth are not yet clear, but by the end of 2015, several companies had announced their intention to enter the field. Gritstone Oncology, a start-up firm in Emeryville, California, raised US$102 million to pursue the approach, and Neon Therapeutics of Cambridge, Massachusetts, raised $55 million. A third company, Caperna, spun out of  a prominent biotechnology company called Moderna Therapeutics , also in Cambridge. \n               Cancer criteria \n             Academic groups are also moving quickly. At the AACR meeting, Robert Schreiber of Washington University in St. Louis described six ongoing studies at his institution in cancers ranging from melanoma to pancreatic. Cancer researcher Catherine Wu of the Dana-Farber Cancer Institute in Boston, Massachusetts, also presented data from a trial in melanoma, showing signs of T-cell responses to the vaccine. But it takes Wu\u2019s team about 12 weeks to generate a vaccine, and the Washington University team needs about 8 weeks. That could limit the treatment to slow-growing cancers, says Wu. There is also a reason that so many researchers choose melanoma for proof-of-principle trials. Melanoma tumours tend to harbour many mutations \u2014 sometimes thousands \u2014 which provide scientists with ample opportunity to select those that may serve as antigens. Some researchers worry that tumours with fewer mutations may not be as suitable for personalized vaccines. But Schrieber notes that researchers have been able to design a vaccine for a woman with the brain tumour glioblastoma \u2014 which often has relatively few mutations. In that case, however, the tumour had many mutations, some of which may have been caused by her previous cancer treatment. The number of potential antigens could be crucial. At the AACR meeting, Ton Schumacher, an immunologist at the Netherlands Cancer Institute in Amsterdam, noted that many of the mutant proteins that his group has found are not required for tumour survival. As a result, a tumour could maintain its cancerous lifestyle but become resistant to the vaccine if the proteins used to design the vaccine mutate again. \u201cWe will need to attack tumours from many different sides,\u201d he says. Pardoll, meanwhile, is concerned that the field is shifting too quickly to the personalized-vaccine approach and leaving behind decades of research on antigens that might be shared across tumours \u2014 an approach that has not borne out in clinical trials thus far, but would be much simpler to manufacture and deploy on a large scale. \u201cI will be the happiest person in the world to be proven wrong on these,\u201d he says of personalized vaccines. \u201cBut I think one has to nonetheless be cognizant of where the challenges are.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Cancer therapy: an evolved approach 2016-Apr-13 \n                   \n                     Cocktails for cancer with a measure of immunotherapy 2016-Apr-13 \n                   \n                     Tumour mutations harnessed to build cancer vaccine 2015-Apr-02 \n                   \n                     Immune system offers clues to cancer treatment 2014-Nov-26 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Nature Outlook: Cancer Immunotherapy \n                   \n                     National Cancer Institute: Cancer vaccines fact sheet \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19824", "url": "https://www.nature.com/articles/nature.2016.19824", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Molecule that controls flowering time misfolds when expressed in yeast. Prions, the misfolded proteins that are known for causing degenerative illnesses in animals and humans, may have been spotted for the first time in plants. Researchers led by  Susan Lindquist , a biologist at the Whitehead Institute for Biomedical Research in Cambridge, Massachusetts, report that they have found a section of protein in thale cress ( Arabidopsis ) that behaves like a prion when it is inserted into yeast. In plants, the protein is called Luminidependens (LD), and it is normally involved in responding to daylight and controlling flowering time. When a part of the LD gene is inserted into yeast, it produces a protein that does not fold up normally, and which spreads this misfolded state to proteins around it in a domino effect that causes aggregates or clumps. Later generations of yeast cells inherit the effect: their versions of the protein also misfold. This does not mean that plants definitely have prion-like proteins, adds Lindquist \u2014 but she thinks that it is likely. \u201cI\u2019d be surprised if they weren\u2019t there,\u201d she says. To prove it, researchers would need to grind up a plant and see whether they could find a protein such as LD in several different folded states, as well as show that any potential prion caused a misfolding cascade when added to a test-tube of protein. Lindquist adds that because she's not a plant scientist \u2014 her focus is on  using yeast to investigate prions  \u2014 she hasn't tried these experiments. The study is reported on 25 April in the  Proceedings of the National Academy of Sciences 1 . \n             Plant puzzle \n           It is not clear\u00a0why LD might behave as a prion in plants. Prions are notorious for inducing ill effects: in\u00a0humans, their misfolding and clumping can cause variant Creutzfeldt\u2013Jakob Disease (vCJD); in sheep and goats, the same effect can cause scrapie. But Lindquist has  shown that prion proteins can provide evolutionary advantages  for some living organisms \u2014 such as, in yeast, surviving harsh environmental conditions. So the same might be true in plants, she speculates. Lindquist says that a clue could come from work done by other researchers, which has suggested that \u2014 in fruit flies \u2014 the build-up of prion-like proteins might help to form or stabilize long-term memories, by creating long-lived protein clusters at synapses 2 . Plants also need to keep track of their outside environment, which is a kind of memory-formation: for example, some plants won't flower until they have experienced many weeks of cold temperature. In the paper, Lindquist's team suggest that if LD does act as a prion in plants, one of its functional roles might possibly be to create a permanent trace of outside temperatures through the accumulation of protein clusters. Other plant scientists whom  Nature  contacted consider this idea to be extremely speculative. But, \u201cit would be really cool to find that prion-like behaviour is playing a role in some normal aspect of plant development\u201d, says Richard Amasino, a plant biochemist at the University of Wisconsin\u2013Madison. Lindquist is looking for more possible prions: her study picked out LD using a computerized algorithm to identify lengths of proteins in the thale cress plant\u00a0that are similar to known yeast prions. The ability to switch between \u2018normal\u2019 and \u2018misfolded\u2019 states of folding \u201cseems to be a fundamental property that a lot of proteins have\u201d, she says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Deadly animal prion disease appears in Europe 2016-Apr-18 \n                 \n                   Prions and chaperones: Outside the fold 2012-Feb-15 \n                 \n                   The beneficial side of prions 2009-Apr-02 \n                 \n                   Prion proteins may store memories 2003-Dec-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19831", "url": "https://www.nature.com/articles/nature.2016.19831", "year": 2016, "authors": [{"name": "Myles Gough"}], "parsed_as_year": "2006_or_before", "body": "New research centre at national science agency CSIRO adds 40 jobs, amid hundreds of redundancies. After controversially  ditching hundreds of jobs in climate research , Australia\u2019s national science agency has announced that it will launch a new climate-science centre \u2015 but researchers say the move won\u2019t make up for the damage the cuts will cause. The Commonwealth Scientific and Industrial Research Organisation (CSIRO) said on 26 April that the centre \u2015 to be located in Hobart, Tasmania \u2015 would employ 40 full-time research staff working on climate modelling, projections and adaptation, and that its funding and staffing levels would be guaranteed for a decade. But the CSIRO also confirmed details of the job cuts it had announced in February, which have sparked protests in support of Australia's climate scientists. The agency said that 275 jobs would be lost (revising its earlier estimate of 350 redundancies), with about 145 of them in CSIRO\u2019s Oceans and Atmosphere, and Land and Water divisions. \u201cNoting the importance of the climate-science field and following consultation with staff and stakeholders, we determined to maintain a higher level of staffing in this field than [was] flagged earlier in the year,\u201d a CSIRO spokesperson told  Nature . The new climate centre is \u201ca good news story in terms of what otherwise might have been\u201d, says Andy Pitman, director of the Australian Research Council's Centre of Excellence for Climate System Science in Sydney. \u201cBut we don\u2019t want to lose sight of the fact that the total scale of capability in CSIRO is being very significantly reduced,\u201d he added.\u00a0 Other scientists were harsher in their judgement. \u201cWhile the retention of some of CSIRO's climate science capabilities is welcome, the level announced is analogous to trying to put a sticking plaster over a gaping wound,\u201d said Dave Griggs, a sustainability researcher at Monash University in Melbourne, in a statement released through the Australian Science Media Centre. \u201cThis new climate science centre will be clearly flagging to the international community that CSIRO is committed to a long-term climate science research capability,\u201d Australia\u2019s chief scientist, Alan Finkel, told  Nature . Finkel, who has helped to broker discussions between the CSIRO and climate scientists, acknowledged that there had been \u201cquestions raised about CSIRO\u2019s reputation\u201d by the cuts. \n               Climate protests \n             Opposition to CSIRO's cuts \u2015 the result of a strategic shift away from basic climate science \u2015 has been strong. Almost 3,000 scientists have signed an  open letter  to CSIRO and to Australia's government, raising concerns over the effects of the move on the nation's climate research capacity. Rallies have been held in major Australian cities, and CSIRO management has been questioned by the Australian senate about its decision, as part of an ongoing inquiry scrutinizing government budget cuts. But much damage has already been done. One senior scientist from CSIRO who did not want to be named told  Nature  that senior staff were already finding new jobs or looking for work elsewhere, and that the organisation would find it difficult to keep climate scientists after demonstrating that it does not value their work. Another researcher \u2014 John Church, a specialist in sea-level rise who has worked for the CSIRO for 38 years \u2014 says that the new centre is a positive step, but that the overall job losses are \u201cstill an incredible cut\u201d to the organization\u2019s capability. \u201cYou can\u2019t hope to cover the range of activities that we did previously when we [CSIRO\u2019s Oceans and Atmosphere unit] had more than 100 staff, with only 40,\u201d he says. Church told  Nature  that he expects to be among the scientists made redundant later this year. The reputational damage to the CSIRO is \u201cnot going to disappear overnight\u201d, he says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Job cuts in Australia target climate scientists 2016-Feb-05 \n                   \n                     Australian science-agency staff announce strike 2015-Jun-11 \n                   \n                     Australian cuts rile researchers 2014-Oct-08 \n                   \n                     Australian budget hits science jobs 2014-Jul-01 \n                   Reprints and Permissions"},
{"file_id": "532422a", "url": "https://www.nature.com/articles/532422a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Google, Facebook and other tech firms are changing how artificial-intelligence research is done. When Andrew Ng joined Google from Stanford University in 2011, he was among a trickle of artificial-intelligence (AI) experts in academia taking up roles in industry. Five years later, demand for expertise in AI is booming \u2014 and a torrent of researchers is following Ng\u2019s lead. The laboratories of tech titans Google, Microsoft, Facebook, IBM and Baidu (China\u2019s web-services giant) are stuffed with ex-university scientists, drawn to private firms\u2019 superior computing resources and salaries. \u201cSome people in academia blame me for starting part of this,\u201d says Ng, who in 2014 moved again to become chief scientist at Baidu, working at the company\u2019s research lab in California\u2019s Silicon Valley. Many scientists say that the intense corporate interest is a boon to AI \u2014 bringing vast engineering resources to the field, demonstrating its real-world relevance and attracting eager students. But some are concerned about the more subtle impacts of the industrial migration, which leaves universities temporarily devoid of top talent, and could ultimately sway the field towards commercial endeavours at the expense of fundamental research. Private firms are investing heavily in AI\u00a0\u2014\u00a0and in particular in an AI technique called  deep learning  \u2014 because of its promise to glean understanding from huge amounts of data. Sophisticated AI systems might be able to create effective digital personal assistants, control  self-driving cars , or take on a host of other tasks that are too complex for conventional programming. And corporate labs\u2019 resources allow progress that might not be possible in academic departments, says Geoffrey Hinton, a deep-learning pioneer at the University of Toronto in Canada who took up a post at Google in 2013. The fields of speech and image recognition, for instance, had been held up for years by a lack of data to use in training algorithms and a shortage of hardware, he says \u2014 bottlenecks that he was able to get past at Google. \u201cAI is so hot right now. There are so many opportunities and so few people to work on them,\u201d says Ng, who says he was attracted by Google\u2019s reams of data and computing power, and its ability to tackle real-world problems. Another temptation is that private firms can offer \u201castronomical\u201d wages, says Tara Sinclair, chief economist at Indeed, a firm headquartered in Austin, Texas, that aggregates online job listings and has chronicled a rising demand for jobs in AI in Britain and the United States. The excitement shows that AI is at a point at which it can achieve real-world impact \u2014 and companies are the natural way to make this happen, says Pieter Abbeel, a specialist in AI and deep learning at the University of California, Berkeley. In the 1950s, a similar job migration occurred in semiconductor research, when many of the field\u2019s leading figures were poached to become heads of industrial research-and-development labs, says Robert Tijssen, a social scientist at Leiden University in the Netherlands. Moving academics bring expertise while extending their new-found corporate networks back to their former colleagues and students \u2014 making the scenario a \u201cclassic win\u2013win situation\u201d, Tijssen says. \n               Corporate collaborations \n             Herman Herman, director of the US National Robotics Engineering Center based at Carnegie Mellon University in Pittsburgh, Pennsylvania, subscribes to that view. In 2015, car-hailing app Uber, which was collaborating with the centre, hired almost 40\u00a0of his 150\u00a0researchers, mainly those working on self-driving cars. Reports at the time suggested that the centre was left in crisis, but Herman says this was overblown; the project was one of dozens across Carnegie Mellon\u2019s Robotics Institute, which has about 500 faculty members. The move was a chance to bring in new blood, and shortly afterwards, Uber donated US$5.5\u00a0million to support student and faculty fellowships at the institute. Meanwhile, the publicity raised the profile of the centre\u2019s work, says Herman \u2014 and student applications are up. The loss of expertise in academia concerns Yoshua Bengio, a computer scientist at the University of Montreal in Canada, which has also seen a surge in graduate-student applications. If industry-hired faculty members do retain university roles \u2014 as Hinton has at the University of Toronto and Ng has at Stanford University in California \u2014 they are usually only minor, says Bengio. Losing faculty members reduces the number of students that can be trained, especially at PhD level, adds Abbeel. Hinton predicts that the shortage in deep-learning experts will be temporary. \u201cThe magic of graduate research in universities is something to be protected, and Google recognizes that,\u201d he says. Google is currently funding more than 250\u00a0academic research projects and dozens of PhD fellow\u00adships. In supplying industry with talent, universities are fulfilling their natural role, says Michael Wooldridge, a computer scientist at the University of Oxford, UK. And with interest in AI generally booming, he struggles to see a situation in which academia is left deserted. The London-based firm  Google DeepMind  hired ten researchers from Oxford in 2014 \u2014 but Google gave the university a seven-figure financial contribution, and formed a research collaboration (see \u2018Google DeepMind\u2019s talent grab\u2019). Many of the poached staff still hold active teaching positions at the university \u2014 giving students opportunities they might otherwise never have had. Bengio is also concerned about the long-term impacts of corporate domination. Industry researchers are more secretive, he says. Although scientists in some corporate labs (such as those at Google and Baidu) are still publishing papers and code openly \u2014 allowing others to build on their work \u2014 Bengio argues that corporate researchers still often avoid discussing their work ahead of publication because they are more likely than academics to have filed for patents. \u201cThat makes it more difficult to collaborate,\u201d he says. Some industry insiders are concerned about transparency, too. In December 2015, SpaceX founder Elon Musk was among a group of Silicon Valley investors who launched a non-profit firm called OpenAI in San Francisco, California. With $1\u00a0billion promised by its backers, it aims to develop AI for the public good, sharing its patents and collaborating freely with other institutions. Although Google, Facebook and the like seem committed for the moment to tackling fundamental questions in AI, Bengio fears that this might not last. \u201cBusiness tends to be pulled to short-term concerns. It\u2019s in the nature of the beast,\u201d he says. He cites telecommunications firms Bell Labs and AT&T as examples of companies that had strong research labs, but eventually lost their talent by putting too much emphasis on the short-term objective of making money for the company. Hinton insists that basic research can thrive in industry. And because of the urgent need for AI research, some of today\u2019s expansion in basic research is inevitably taking place at corporate firms, he adds. But academia will still play a crucial part in AI research, he says. \u201cIt\u2019s the most likely place to get radical new ideas.\u201d See Editorial  page 413 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Anticipating artificial intelligence 2016-Apr-26 \n                   \n                     A world where everyone has a robot: why 2040 could blow your mind 2016-Feb-24 \n                   \n                     Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                   \n                     Why biomedical superstars are signing on with Google 2015-Oct-21 \n                   \n                     Machine ethics: The robot\u2019s dilemma 2015-Jul-01 \n                   \n                     Computer science: The learning machines 2014-Jan-08 \n                   Reprints and Permissions"},
{"file_id": "532424a", "url": "https://www.nature.com/articles/532424a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Fears rise that US government and private funders are working at cross purposes. The recent launch of multiple major US cancer initiatives has infused cash into immunotherapy, one of the most promising new methods of cancer treatment. But researchers warn that the money may be wasted without concrete plans to coordinate the programmes. \u201cThere\u2019s a lack of overt leadership, and in the absence of a logical strategy we have a tendency to throw plates of spaghetti against the wall and hope it sticks,\u201d says Ira Mellman, vice-president of cancer immunology at the biotechnology company Genentech in South San Francisco, California. The broadest programme is  the US govern\u00adment\u2019s National Cancer Moonshot , which hopes to receive US$1\u00a0billion by next year for 8 areas of cancer research. Immunotherapy, which  recalibrates the body\u2019s own immune defence  against cancer, is among them. It \u201cis poised to be a critical part of our nation\u2019s anticancer strategy\u201d, the project\u2019s leader, US vice-president Joe Biden, said last week at the annual meeting of the American Association for Cancer Research (AACR) in New Orleans, Louisiana. An advisory panel will release more-detailed plans for the government programme in June. Meanwhile, three privately funded immuno\u00adtherapy research projects are gearing up: the $250-million Parker Institute for Cancer Immunotherapy, funded by Sean Parker, co-founder of the music-file-sharing company Napster, and announced on 13\u00a0April; a $125-million Immunotherapy Center at Johns Hopkins University in Baltimore, Maryland, unveiled in March; and the Cancer MoonShot 2020 Program, announced in January by biotechnology billionaire Patrick Soon-Shiong. This sudden proliferation of cancer initiatives is reminiscent of the spate of brain-research projects launched in the past few years \u2014 some of which have foundered through poor leadership. Europe\u2019s Human Brain Project, for instance,  almost ran aground  after a series of top-down decisions alienated the neuroscience community. By contrast, the US BRAIN Initiative set priorities after consulting with neuroscientists, and awarded grants through a conventional peer-reviewed process, ensuring community acceptance. Now cancer researchers are left wondering how their moonshots will proceed. At the AACR meeting, Biden said that he had met representatives of many cancer-funding projects. \u201cWhy is all of that being done separately?\u201d he asked scientists in the audience, noting that progress is accelerated by collaboration. The privately funded initiatives are more concerned with meeting their own goals \u2014 and satisfying their funders \u2014 than with coordinating efforts in the field. \u201cI don\u2019t see my role as trying to answer this larger question about how does this all fit together,\u201d says Jeffrey Bluestone, chief executive of the Parker Institute. \u201cI\u2019m focused on how to make sure what we do is impactful for patients.\u201d But Douglas Lowy, acting director of the US National Cancer Institute (NCI), which is coordinating the government moonshot, notes an overlap with the leadership of the various projects. Soon-Shiong, Bluestone and leaders of immunotherapy initiatives at Johns Hopkins and the University of Texas MD Anderson Cancer Center in Houston are on the government initiative\u2019s advisory panel. And on 18\u00a0April, the Biden moonshot launched a website to solicit research ideas. The aim, Lowy says, is to ensure that research areas recommended by the advisory panel do not duplicate topics being covered by the private initiatives. There is wide agreement on major questions regarding immunotherapy, how\u00adever. For instance, researchers don\u2019t understand why the approach works in only 15\u201320% of patients.  Combining immunotherapies , and studying what distinguishes patients who respond, could make treatments more effective. Pharmaceutical companies are already developing new drugs and testing therapies in combination. Philip Gotwals, executive director of oncology research at the Novartis Institutes for BioMedical Research in Cambridge, Massachusetts, estimates that industry has spent upwards of $1 billion on the field. But scientists see a lack of basic cancer immunology research, even in the new programmes. \u201cMany of these initiatives are moving forward ideas that are already out there,\u201d says David Raulet, faculty director of the Immunotherapeutics and Vaccine Research Initiative at the University of California, Berkeley, which began in March. Many researchers are looking to the Biden project to make a big investment in basic cancer immunology and to address broader barriers to research, such as data hoarding. Gotwals, for instance, notes that the results of industry-sponsored clinical trials now under way could help other companies to decide which approaches to test, but that results are typically not made public until 9\u201312\u00a0months after a trial ends. Companies are reluctant to share data before then, both to comply with regulatory requirements and to protect their intellectual property. \u201cIt\u2019s not trivial to figure out how to make that work,\u201d Gotwals says. Biden seems to be hearing that message. At the AACR meeting, he said that data sharing often comes up when he speaks to scientists about the moonshot. Lowy says that the NCI is already planning to open a Genomic Data Commons in June to host detailed information on cancer patients. Sharing data collected in company-sponsored clinical trials is trickier because patients must give informed consent. In the meantime, the government moonshot faces a major hurdle: its funding is at the mercy of legislators who may be loath to give US President Barack Obama a victory in his last year in office. \u201cIt will be very difficult for us to initiate all of the programmes that we\u2019re looking forward to the blue-ribbon panel recommending if there isn\u2019t funding,\u201d Lowy says. Additional reporting by Heidi Ledford See Editorial  page 414 \n                 Tweet \n                 Follow @NatureNews \n               \n                     Biden time 2016-Apr-27 \n                   \n                     Back to Earth 2016-Feb-17 \n                   \n                     Obama proposes cancer \u201cmoonshot\u201d in State of the Union address 2016-Jan-13 \n                   \n                     Cancer treatment: The killer within 2014-Apr-02 \n                   \n                     Immunotherapy\u2019s cancer remit widens 2013-May-28 \n                   \n                     National Cancer Moonshot Initiative \n                   \n                     The Parker Foundation Immunotherapy \n                   \n                     Cancer Moonshot 2020 \n                   \n                     Press release: Johns Hopkins Immunotherapy Center \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19835", "url": "https://www.nature.com/articles/nature.2016.19835", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Space agency declares the astronomy satellite a loss. Japan\u2019s flagship astronomical satellite Hitomi, which launched successfully on 17 February but  tumbled out of control  five weeks later, may have been doomed by a basic engineering error. Confused about how it was oriented in space and trying to stop itself from spinning, Hitomi's control system apparently commanded a thruster jet to fire in the wrong direction \u2014 accelerating, rather than slowing, the craft's rotation. On 28 April, the Japan Aerospace Exploration Agency (JAXA) declared the satellite, on which it had spent \u00a531 billion (US$286 million), lost. At least ten pieces \u2014 including both solar-array paddles that had provided electrical power \u2014 broke off the satellite\u2019s main body. Hitomi had been seen as  the future of X-ray astronomy . \u201cIt\u2019s a scientific tragedy,\u201d says Richard Mushotzky, an astronomer at the University of Maryland in College Park. The satellite managed to make one crucial astronomical observation before the accident, capturing gas motions in a galaxy cluster in the constellation Perseus. The instrument that made the observation, a high-resolution spectrometer, had been in the works for three decades. Two earlier versions of it were lost in previous spacecraft failures. Hitomi\u2019s troubles began in the weeks after launch, with its 'star tracker' system, which is one of several systems on board that are designed to keep the satellite oriented in space. The star tracker experienced glitches whenever it passed over the eastern coast of South America, through a region known as the South Atlantic Anomaly. Here, the belts of radiation that envelop Earth dip relatively low in the atmosphere, exposing satellites to extra doses of energetic particles. By itself that should not have been a fatal problem. But the star tracker issue kicked off a series of cascading failures. \n               Spin cycle \n             At 3:01 a.m. Japan time on 26 March, the spacecraft began a preprogrammed manoeuvre to swivel from looking at the Crab Nebula to the galaxy Markarian 205. Somewhere along the way, the problems with the star tracker caused Hitomi to rely instead on another method, a set of gyroscopes, to calculate its orientation in space. But those gyroscopes were reporting, erroneously, that the spacecraft was rotating at a rate of about 20 degrees each hour. Tiny motors known as reaction wheels began to turn to counteract the supposed rotation. Once the reaction wheels reached their maximum spin, a magnetic rod would normally deploy to keep them from accelerating out of control. But the magnetic rod must be oriented properly in three dimensions to work, and so it failed to slow the reaction wheels. Hitomi spun faster and faster. The spacecraft then automatically switched into a safe mode and, at about 4:10 a.m., fired thrusters to try to stop the rotation. But because the wrong command had been uploaded, the firing caused the spacecraft to accelerate further. (The improper command had been uploaded to the satellite weeks earlier without proper testing; JAXA says that it is investigating what happened.) All this took place when Hitomi was on the other side of the Earth from Japan and unable to communicate with its controllers in real time. In the United States, team scientists went to bed on Friday 25 March, having celebrated what looked like a successful start to the mission. Saturday morning, they woke up to a terse email from the project manager, Tadayuki Takahashi, saying that the spacecraft had been in an emergency. Ground-based telescopes have since taken pictures of Hitomi spinning roughly once every 5.2 seconds. \n               Lost opportunities \n             Dan McCammon, an astronomer at the University of Wisconsin\u2013Madison, helped to design and build Hitomi\u2019s premiere scientific instrument, an X-ray calorimeter that measures the energy of X-ray photons with exquisite precision. He has been working on the technology for more than three decades, flying versions of it on the ASTRO-E mission, which failed on launch in 2000, and the Suzaku spacecraft, in which a helium leak rendered the instrument useless weeks after its 2005 launch. McCammon says that it would take about US$50 million from NASA, and another 3\u20135 years, to build a replacement calorimeter. A version of it is slated to fly on the European Space Agency\u2019s Athena mission, but that is not due to launch until 2028. The calorimeter is the biggest loss, says Makoto Tashiro, an astrophysicist at Saitama University in Japan. It was to have gathered extraordinary detail on exploded stars, galaxy clusters, the gas between the galaxies and more. \u201cWe lose the new science,\u201d he says. But Hitomi could still contribute to science. Because of the early failure with Suzaku, Hitomi scientists planned one important early observation. About eight days after launch, Hitomi turned its X-ray gaze on the Perseus cluster, about 250 million light years from Earth. By measuring the speed of gas flowing from the cluster, Hitomi can reveal how the mass of galaxy clusters changes over time as stars are born and die \u2014 a test of the crucial cosmological parameter known as dark energy. That one observation may yield a set of Hitomi papers, says Mushotzky. But no more. \u201cWe had three days,\u201d he says. \u201cWe\u2019d hoped for ten years.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Japanese X-ray satellite loses communication with Earth 2016-Mar-27 \n                   \n                     High stakes as Japanese space observatory prepares for launch 2016-Feb-09 \n                   \n                     Crunch time for pet theory on dark matter 2015-Jan-21 \n                   \n                     Satellites watch stellar death throes 2012-Aug-02 \n                   \n                     JAXA's Hitomi site \n                   Reprints and Permissions"},
{"file_id": "532421a", "url": "https://www.nature.com/articles/532421a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Scientists race to determine origin of Bangladesh outbreak, which they warn could spread farther afield. Update:    On 26 April, a team led by microbial population geneticist Daniel Croll, who is at the Swiss Federal Institute of Technology in Zurich,  reported on github.com  that the Bangladeshi wheat-blast strain is closely related to those collected in Brazilian wheat fields and on nearby weeds. His team\u2019s analysis, which uses the data on the website Open Wheat Blast, reveals that the sample is not closely related to known rice-blast-causing strains of  M. oryzae . Croll\u2019s team concludes that wheat blast was probably introduced to Bangladesh from Brazil, and warns that other Asian countries that import Brazilian wheat, including Thailand, the Philippines and Vietnam, should be on the lookout for the disease. Fields are ablaze in Bangladesh, as farmers struggle to contain Asia\u2019s first outbreak of a fungal disease that periodically devastates crops in South America. Plant pathologists warn that wheat blast could spread to other parts of south and southeast Asia, and are hurrying to trace its origins. \u201cIt\u2019s important to know what the strain is,\u201d says Sophien Kamoun, a biologist at the Sainsbury Laboratory in Norwich, UK, who has created a website, Open Wheat Blast ( go.nature.com/bkczwf ), to encourage researchers to share data. Efforts are also under way to find wheat genes that confer resistance to the disease. First detected in February and confirmed with genome sequencing by Kamoun\u2019s lab this month, the wheat-blast outbreak has already caused the loss of more than 15,000 hectares of crops in Bangladesh. \u201cIt\u2019s really an explosive, devastating disease,\u201d says plant pathologist Barbara Valent of Kansas State University in Manhattan, Kansas. \u201cIt\u2019s really critical that it be controlled in Bangladesh.\u201d After rice, wheat is the second most cultivated grain in Bangladesh, which has a population of 156 million people. More broadly, inhabitants of south Asia grow 135\u00a0million tonnes of wheat each year. Wheat blast is caused by the fungus  Magnaporthe oryzae . Since 1985, when scientists discovered it in Brazil\u2019s Paran\u00e1 state, the disease has raced across South America. The fungus is better known as a pathogen of rice. But unlike in rice, where  M. oryzae  attacks the leaves, the fungus strikes the heads of wheat, which are difficult for fungicides to reach. A 2009 outbreak in wheat cost Brazil one-third of that year\u2019s crop. \u201cThere are regions in South America where they don\u2019t grow wheat because of the disease,\u201d Valent says. Wheat blast was spotted in Kentucky in 2011, but vigorous surveillance helped to stop it spreading in the United States. In South America, the disease tends to take hold in hot and humid spells. Such conditions are present in Bangladesh, and the disease could migrate across south and southeast Asia, say plant pathologists. In particular, it could spread over the Indo-Gangetic Plain through Bangladesh, northern India and eastern Pakistan, warn scientists at the Bangladesh Agricultural Research Institute (BARI) in Nashipur. Bangladeshi officials are burning government-owned wheat fields to contain the fungus, and telling farmers not to sow seeds from infected plots. The BARI hopes to identify wheat varieties that are more tolerant of the fungus and agricultural practices that can keep it at bay, such as crop rotation and seed treatment. It is unknown how wheat blast got to Bangladesh. One possibility is that a wheat-infecting strain was brought in from South America, says Nick Talbot, a plant pathologist at the University of Exeter, UK. Another is that an  M.\u00a0oryzae  strain that infects south Asian grasses somehow jumped to wheat, perhaps triggered by an environmental shift: that is what happened in Kentucky, when a rye-grass strain infected wheat. To tackle the question, this month Kamoun\u2019s lab sequenced a fungus sample from Bangladesh. The strain seems to be related to those that infect wheat in South America, says Kamoun, but data from other wheat-infecting strains and strains that plague other grasses are needed to pinpoint the outbreak\u2019s origins conclusively. The Open Wheat Blast website might help. Kamoun has uploaded the Bangladeshi data, and Talbot has deposited  M. oryzae  sequences from wheat in Brazil. Talbot hopes that widely accessible genome data could help to combat the outbreak. Researchers could use them to screen seeds for infection or identify wild grasses that can transmit the fungus to wheat fields. Rapid data sharing is becoming  more common in health emergencies , such as the outbreak of Zika virus in the Americas. Kamoun and Talbot say that their field should follow suit. \u201cThe plant-pathology community has a responsibility to allow data to be used to combat diseases that are happening now, and not worry too much about whether they may or may not get a  Nature  paper out of it,\u201d says Talbot. Last month, Valent\u2019s team reported the first gene variant known to confer wheat-blast resistance (C.\u00a0D.\u00a0Cruzetal.CropSci. http://doi.org/bfk7;2016 ), and field trials of crops that bear the resistance gene variant have begun in South America. But plant pathologists say that finding one variant is not enough: wheat strains must be bred with multiple genes for resistance, to stop  M.\u00a0oryzae  quickly overcoming their defences. The work could help in the Asian crisis, says Talbot. \u201cWhat I would hope for out of this sorry situation,\u201d he says, \u201cis that there will be a bigger international effort to identify resistance genes.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Italian scientists under investigation after olive-tree deaths 2015-Dec-21 \n                   \n                     Pathogen genome tracks Irish potato famine back to its roots 2013-May-21 \n                   \n                     The resistant rice of the future 2009-Aug-20 \n                   \n                     Bioterror: The green menace 2008-Mar-12 \n                   \n                     Genome blasts open rice research 2005-Apr-20 \n                   Reprints and Permissions"},
{"file_id": "532158a", "url": "https://www.nature.com/articles/532158a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Committee begins study to guide oversight of modified organisms. The industry that has blanketed more than 181 million hectares of the world\u2019s farmland with genetically modified (GM) crops is in the middle of a sea change. Improved techniques for altering crop genomes are already bringing a new generation of plant varieties to the market \u2014 and around the world, regulators are playing catch-up. \u201cA few brave countries have already made statements,\u201d says Piet van der Meer, a biologist and lawyer at Ghent University in Belgium. \u201cBut most are struggling with it.\u201d On 18 April, the US National Academies of Sciences, Engineering and Medicine will begin its first meeting of a committee charged with ending the struggle. The committee, which is sponsored by the US Department of Agriculture (USDA) and two other agencies, has been asked to predict what advances will be made in biotechnology products over the next 5\u201310\u00a0years. It is scheduled to report by the end of the year on the steps that regulators need to take to prepare themselves. The result could inform  an ongoing USDA effort  to re-assess its process for evaluating engineered crops. Researchers around the world are watching closely (see \u2018Global governance\u2019). \u201cCrops travel around the globe,\u201d says Ren\u00e9 Custers, manager of regulatory and responsible research at VIB, a life-sciences research institute in Ghent. \u201cIt is important to see what is happening in the rest of the world.\u201d \n               boxed-text \n             \n               Ripe for change \n             Many feel that regulations in the United States, which grows more GM crops than any other country, are particularly ripe for change. The USDA itself has acknowledged that it might be over-regulating some crops if they have traits that have already been scrutinized. Also, it uses its authority to restrict the release of \u2018plant pests\u2019 as a way to regulate GM crops\u00a0\u2014\u00a0an approach that applied widely in the 1980s, when crops were often created using genetic elements from plant viruses or bacteria. But researchers have since developed  tools that do not rely on these components . Over the past five years, the USDA has determined that about 30 types of GM plant\u00a0\u2014\u00a0from soya beans whose oil has a longer shelf life, to pineapples with rose-coloured flesh\u00a0\u2014\u00a0do not fall under its regulatory rubric. Some were made  using gene-editing techniques . \u201cOne of the things that has to happen is to plug that huge hole,\u201d says Doug Gurian-Sherman, director of sustainable agriculture at the Center for Food Safety, an environmental-advocacy group in Washington DC. \u201cWhether you think they\u2019re over-regulated or under-regulated or just not intelligently regulated, there\u2019s nobody who thinks this is appropriate.\u201d And developers eager to market gene-edited varieties want clarity as to how the USDA will view the crops, says Daniel Voytas, chief science officer at Calyxt, a plant biotechnology company in New Brighton, Minnesota. The agency has already determined that it will not regulate several crops that have been developed using two editing tools \u2014 zinc-finger nucleases and TALENs \u2014 and it is currently considering a non-browning mushroom that was made using another, CRISPR\u2013Cas9. \n               Case by case \n             These crops embody the simplest application of genome modification: deleting a small section of the genome to disrupt a gene. Calyxt, for example, used TALENs to edit a single gene in the parent plant and generate a variety of wheat with improved resistance to powdery mildew. On 11 February, the USDA informed Calyxt that it would not regulate the crop. But more-sophisticated edits \u2014 such as rewriting genes or inserting new ones \u2014 are around the corner, Voytas says. \u201cWe don\u2019t understand how those crop varieties are going to be regulated,\u201d he says. \u201cAnd they\u2019re already in the works.\u201d On 5 February, the USDA released four broad regulatory scenarios that are open to public comment until 21 April. The draft proposed a definition of \u201cproducts of biotechnology\u201d that encompasses organisms in which segments of the genome have been deleted, added or altered. \u201cSometimes you are using these technologies to introduce genetic variation that already exists in wild relatives,\u201d says Custers. \u201cThe question is whether or not that differs from traditional plant breeding.\u201d Custers therefore advocates a definition that excludes plants carrying genetic changes that are already present in nature. But including such plants in the definition does not mean that they would be heavily regulated, notes Greg Jaffe, director of biotechnology at the Center for Science in the Public Interest, a consumer advocacy group in Washington DC. \u201cThe USDA is capturing them under the rubric, but it sounds like they\u2019re also going to exempt many of them from oversight,\u201d he says. Some activists are unlikely to support the idea. Gurian-Sherman notes that gene-editing technology is still relatively new, can be applied in many ways and sometimes makes unintended genetic changes. \u201cWe feel very strongly that this technology still needs to be regulated as we learn more about it,\u201d he says. \u201cMaybe at some point it wouldn\u2019t need to, but this is still a new technology.\u201d See Editorial  page 147 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Breeding controls 2016-Apr-12 \n                   \n                     Policy: Reboot the debate on genetic engineering 2016-Mar-09 \n                   \n                     Europe\u2019s genetically edited plants stuck in legal limbo 2015-Dec-15 \n                   \n                     US regulation misses some GM crops 2013-Aug-20 \n                   \n                     Transgenic grass skirts regulators 2011-Jul-20 \n                   \n                     Environmental Impact Statement: Introduction of the Products of Biotechnology \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19832", "url": "https://www.nature.com/articles/nature.2016.19832", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Specialized proteins can protect monkeys against the virus for months. A single infusion of antibodies can protect monkeys from infection with a virus that is similar to HIV for nearly six months. The finding provides further evidence that antibodies \u2014 specialized proteins that the body produces to fight infections \u2014 could one day be used as a method to prevent people from becoming infected with HIV. \u201cA caveat is that monkeys are not humans, but the model the authors use is about as good as it gets, and the results are a boost to HIV vaccine research and the use of passive antibodies as long-acting preventives,\u201d said immunologist Dennis Burton of the Scripps Research Institute in La Jolla, California, who was not involved with the work. Researchers have struggled to produce an effective vaccine against HIV, and the scientists behind this study say that administering periodic doses of antibodies might provide a stopgap measure while vaccine research continues. \u201cThis might turn out to be a seasonal alternative to a vaccine until we really know how to make one,\u201d says HIV researcher Malcolm Martin of the US National Institute of Allergy and Infectious Diseases in Bethesda,\u00a0Maryland, who led the work. \n             Long-term protection \n           Previous studies had found that antibodies derived from HIV-infected people can  drastically reduce  the amount of HIV in an infected person\u2019s blood for short periods of time. Researchers have also found that antibodies given one or two days before monkeys were exposed to an HIV-like virus  prevented them  from becoming infected. Martin and his colleagues wanted to test whether an antibody strategy could have a lasting effect, because in the real world, people might be exposed to HIV weeks or months after being dosed with protective antibodies. His team found that, in the absence of any protection, monkeys exposed to a chimeric virus containing portions of both HIV and its monkey equivalent SIV became infected after two to six exposures. The researchers then gave four other groups of monkeys a single injection of antibodies: each group was given a different antibody. These monkeys were then exposed to the chimeric virus once per week until the scientists could detect the pathogen in the animals\u2019 blood. To more closely mimic human HIV infection, the researchers exposed the animals to lower virus doses than had been used in previous studies, which gave deliberately high virus doses to make sure that animals became infected. All of the treated animals became infected at between 12 and 23 weeks, depending on which antibody they were given at the start 1 . The probability of an animal becoming infected grew as the amount of antibody in its blood declined.  The results add to growing positivity about the potential use of antibodies as preventive tools against HIV. The practicality of the approach has been questioned because antibodies are expensive and it has not been clear how often they\u2019d need to be used to prevent people from becoming infected. But the findings released today demonstrate that antibodies might provide reasonably long-term protection from a single dose. And Martin says that the antibodies might even last longer in people: the monkey immune system sees them as 'foreign' proteins, but that might be less of a problem in humans, he says. His team is now modifying one of the antibodies used in the study, 3BNC117, to make it endure for longer in the body. And in the paper released today, the group shows that modifying a different antibody, VRC01, extends how long it provides protection against the chimeric virus in monkeys. Using combinations of these long-lived antibodies could prove an alternative to existing prevention regimens, such as pre-exposure prophylaxis (PrEP), which can involve taking a pill each day to protect against HIV. \u201cThis has the advantage over PrEP because you don't have to worry every day \u2014 that's the take-home point here,\u201d Martin says. \n                   Almighty antibodies? A new wave of antibody-based approaches aims to combat HIV 2015-Jul-07 \n                 \n                   Antibody shows promise as treatment for HIV 2015-Apr-08 \n                 \n                   Researchers see antibody evolve against HIV 2013-Apr-03 \n                 \n                   HIV trial under scrutiny 2013-Jan-16 \n                 Reprints and Permissions"},
{"file_id": "532160a", "url": "https://www.nature.com/articles/532160a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Revelation could have implications for how scientists approach quantum problems. With particles that can exist in two places at once, the quantum world is often considered to be inherently counterintuitive. Now, a group of scientists has created a video game that follows the laws of quantum mechanics, but at which non-physicist human players excel ( J. J. W. H. S\u00f8rensen et al. Nature 532, 210\u2013213; 2016 ). One implication of the team\u2019s results is that efforts to use computer games to crowdsource solutions to science problems  can now be extended to quantum physics . In the past, such gamification projects have been limited to challenging but less mind-bending problems, such as  protein folding . But the work also suggests that the human mind might be more capable of grasping the rules of the bizarre quantum world than previously thought \u2014 a revelation that could have implications for how scientists approach quantum physics, says Jacob Sherson, a quantum physicist at Aarhus University, Denmark, who led the study. \u201cMaybe we should allow some of that normal intuition to enter our problem solving,\u201d he says. Scientists studying quantum foundations have also long said that finding a  more intuitive approach to quantum physics  could help to crack outstanding puzzles, although many doubted that this would ever be possible without new theories. The game, called  \n                   Quantum Moves \n                 , is based on a real problem in quantum computing: how fast a laser can move an atom between wells in an egg-box-like structure without changing the energy of the atom, which is in a delicate quantum state. In the quantum world, speed and energy are a trade-off limited by Heisenberg\u2019s uncertainty principle, so the trick is to find the sweet spot where the transition from one place to another is as fast as possible without disturbing the quantum state. Endless possible combinations of movement and timing exist, and scientists have designed computer algorithms to try to solve the problem. In the game, an atom is represented by what looks like a liquid sloshing around in a well, which reflects the wave-like nature of a quantum particle. In one level, players move a cursor to control a second well, which they use to collect the sloshing liquid and take it back to a base. The liquid behaves according to the laws of quantum mechanics rather than like an actual bucket of water \u2014 for example, to pick up the liquid, players can get it to \u2018quantum tunnel\u2019 from one well to another, something that players must learn to adapt to. Once they find ways to transfer the liquid, a computer can then convert their mouse movements to solutions to the real-world quantum egg box. Sherson\u2019s team got around 300 people to play this level a total of 12,000 times on a volunteer-research platform called ScienceAtHome. The researchers then fed the human solutions into a computer for further refinement. Not only were more than half of the human-inspired solutions more efficient than those produced by just computer algorithms, but the two best hybrid strategies were faster than what the quickest computers had been able to achieve working alone. \u201cI was completely amazed when we saw the results,\u201d says Sherson. \n               Human advantage \n             What abilities humans bring to the mix is unclear. Although an interest in physics seems to correlate with ability in the game, success did not correlate with years spent studying quantum physics. Sherson suggests that the superior human strategies stem from the mind\u2019s ability to capture the essence of a problem. Quantum concepts may seem less bizarre to people in a game than they do in other contexts, because it is an environment in which they expect rules to be broken, adds Sabrina Maniscalco of the Turku Centre for Quantum Physics in Finland, who runs an event aimed at making games that might benefit quantum physics. Adam Levy tries the video game that helps use human intuition to solve quantum problems. To Sherson, the results also suggest that physicists could use their own intuition more. \u201cWe should try to be more spontaneous and intuitive about problem solving,\u201d he says. To that end, his team is building a version of the game in which physicists can tweak the scenario to represent different set-ups, potentially offering them new insights into their work. Other quantum physicists agree that the finding that people can develop an intuition for quantum processes is surprising, but think that scientists already use intuition to solve quantum problems, at least at the mathematical level. By playing the game, people perhaps gain a form of that intuition, says Seth Lloyd, a physicist at the Massachusetts Institute of Technology in Cambridge. He notes that before babies learn to expect an object to stay where it is, they have a form of quantum intuition, which they lose. \u201cBefore three months, if it disappears, they guess that\u2019s just how things are in the world. After three months, they think, \u2018Where\u2019d the toy go\u2019?\u201d Lloyd also says that much of the success of  Quantum Moves  is due to its clever design, which successfully translates a quantum problem to a visual one, but which could fail with more-complex quantum problems. Physicists who are trying to develop quantum-computing algorithms already play around with graphical interfaces to help them to improve on existing solutions, says Charles Tahan, a theoretical physicist at the University of Maryland in College Park. But Tahan does think that teaching quantum intuition through games has benefits. He has developed another game,  Meqanic , that gets players to perform basic quantum computations and intuit the rules as they play. He hopes that it could boost student\u2019s abilities and help to find individuals who have an untapped natural flair for the field. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Physics: Quantum problems solved through games 2016-Apr-13 \n                   \n                     Rise of the citizen scientist 2015-Aug-18 \n                   \n                     Quantum physics: What is really real? 2015-May-20 \n                   \n                     Physics: Quantum computer quest 2014-Dec-03 \n                   \n                     Physics: Quantum quest 2013-Sep-11 \n                   \n                     Experts still split about what quantum theory means 2013-Jan-11 \n                   \n                     Victory for crowdsourced biomolecule design 2012-Jan-22 \n                   \n                     Quantum Moves \n                   \n                     How gameplay helps ScienceAtHome build a quantum computer \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19750", "url": "https://www.nature.com/articles/nature.2016.19750", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "$100-million initiative would be proof of concept for high-speed galactic travel. Space has long fascinated humans, but few have dared to initiate an interstellar space programme. Now a coalition of entrepreneurs and scientists aims to design a fleet of laser-powered spacecraft that could reach \u03b1 Centauri, the star system closest to the Solar System, in just two decades. The group envisions probes that could complete that journey \u2014 a distance of 4.37 light years (1.34 parsecs) \u2014 at 20% the speed of light. \u201cFor the first time in human history we can actually do more than observe the stars,\u201d said Yuri Milner, a Russian Internet billionaire who is funding the initiative, at a 12 April press conference in New York. \u201cWe can reach them.\u201d Called Breakthrough Starshot, the programme is based on an idea that has been around for decades:  the solar sail . The theory is that a lightweight space sail could harness the momentum carried by photons in order to travel without fuel. The Breakthrough Starshot team is betting that a burst of concentrated lasers, fired from the ground, could rapidly accelerate a mobile-phone-sized device equipped with microelectronics and a tiny sail \u2014 providing much more energy than could be harnessed from the Sun. Whereas NASA\u2019s plutonium-powered New Horizons spacecraft took  nine years to reach Pluto , the \u201cnanocraft\u201d envisioned by Breakthrough Starshot would pass by the dwarf planet and exit the Solar System in three days.\u00a0 The project's initial US$100-million budget covers only research and development of such a spacecraft. But Breakthrough Starshot's ultimate goal is to demonstrate proof of concept for an international programme that would send a fleet of nanocraft into space. Doing so would require the group to surmount enormous scientific and engineering challenges in developing the necessary laser technology, materials and communications systems. Advocates are optimistic, citing recent advances in microelectronics and photonics. \u201cIt\u2019s an ambitious project, but we don\u2019t see any showstoppers, any dealbreakers, based on fundamental physics,\u201d says Avi Loeb, a theoretical physicist at Harvard University in Cambridge, Massachusetts, who advises the Breakthrough Prize Foundation \u2014 an organization that receives funding from Milner. \u201cBasically, the success of this project depends on us.\u201d \n             Far target \n           Breakthrough Starshot would launch its probes into space on a conventional rocket, and release them into Earth orbit. The probes would then open up their sails, and an array of high-powered lasers would blast\u00a0one into motion every day or two. Each spacecraft could be equipped with sensors to study the planets or asteroids that they pass; the data would then be transmitted back to Earth by tiny on-board lasers. Perhaps the biggest question of all \u2014 even assuming that some of these spacecraft would survive to reach \u03b1 Centauri and transmit their data back \u2014 is how much scientists would learn from the feat. The project would certainly spur innovation, but would have to compete scientifically against a new generation of space-based telescopes, says Scott Pace, director of the Space Policy Institute at George Washington University in Washington DC. \u201cIf I was wearing purely a science hat, and I had a marginal dollar to spend, I would spend it on  an exoplanet telescope ,\u201d Pace says. Still, Breakthrough Starshot has attracted high-profile support from the likes of Facebook founder Mark Zuckerberg and physicist Stephen Hawking, who was present at the 12 April press conference. \u201cWhat makes us human is transcending our limits,\u201d Hawking said. \u201cHow do we transcend these limits? With our minds and our machines.\u201d The Starshot project will be led by Pete Worden, who retired as director of NASA\u2019s Ames Research Center in California last year. Worden said that the group has already reached out to NASA, the European Space Agency and other space agencies to build support and perhaps partnerships. Achieving Breakthrough Starshot's goals would be comparable in scale and cost to building and operating the Large Hadron Collider at CERN, Europe's particle-physics lab near Geneva, Switzerland. The entire programme will be open to outside collaborations, and all of the data will be published openly. Indeed, Loeb says that its success will depend on engagement by the broader scientific community. \u201cOur goal is to get people from all over the world involved, especially young people who will be around when we get there,\u201d Loeb says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   On the hunt for a mystery planet 2016-Mar-15 \n                 \n                   Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                 \n                   Hint of new boson at LHC sparks flood of papers 2015-Dec-24 \n                 \n                   Breakthrough Starshot \n                 Reprints and Permissions"},
{"file_id": "532155a", "url": "https://www.nature.com/articles/532155a", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Scientists warn vaccine stocks would be overwhelmed in the event of large urban outbreaks. As the  largest outbreak of yellow fever in almost 30\u00a0years  continues to spread in Angola, scientists are warning that the world is ill-prepared for what would be a public-health calamity: the re-emergence of urban epidemics of the deadly infection, which could overwhelm vaccine stockpiles. Yellow fever virus caused devastating outbreaks in cities in the past, but by the 1970s its mosquito carrier in urban areas \u2014  Aedes aegypti  \u2014 had been wiped from large swathes of the globe; vaccination programmes also helped to confine the virus to the jungle. But now, as a result of the scaling-back of control efforts,  Aedes  mosquitoes have re-emerged in  densely populated tropical and subtropical cities where many people are unvaccinated  \u2014 and the Angolan situation has renewed fears that the virus might be poised to break out from the jungle. Worst of all would be if yellow fever gains a foothold in Asia \u2014 where, mysteriously, it has never become established despite apparently ideal ecological conditions. \u201cWe don\u2019t know if this will happen, but if it does it would be a public-health disaster,\u201d says Duane Gubler, a researcher in mosquito-borne diseases at Duke-NUS Medical School in Singapore. Yellow fever, which is endemic in parts of South America and Africa, causes at least 60,000\u00a0deaths each year. Many people who become infected recover quickly (there are 84,000\u2013170,000 annual infections, more than 90% of them in Africa), but some develop jaundice, bleed from their orifices and sustain fatal organ damage. A 2006 initiative led by the World Health Organization (WHO) upped mass vaccinations and introduced routine immunization of children in many high-risk countries in Africa, but vaccination rates remain too low. The Angolan outbreak points to the continued risk posed by yellow fever: it began last December in the capital Luanda and has since spread to 6 of the country\u2019s 18 provinces. Officially, some 490\u00a0people have been infected and 198 have died, although the true figures are probably much higher. The immediate concern is that the virus might spread to larger African urban centres, as happened in the biggest previous outbreak, which began in 1986 in Nigeria and ultimately infected 116,000 people and killed 24,000 (see \u2018Where might yellow fever go next?\u2019). Africa\u2019s urban populations are now much larger than they were in the 1980s, notes Thomas Monath, a yellow fever and vaccine specialist who is chief scientific officer of NewLink Genetics in Ames, Iowa. People who contracted the infection in Angola have already carried it to Kenya, Mauritania and the Democratic Republic of the Congo, although this hasn\u2019t yet sparked new outbreaks. \n               From jungle to city \n             As long as the virus is confined mainly to small outbreaks in Africa, the world\u2019s vaccine production \u2014 just over 40\u00a0million doses annually \u2014 should be sufficient to replenish emergency stockpiles and contain outbreaks, says William Perea, who coordinates the WHO\u2019s Control of Epidemic Diseases Unit in Geneva, Switzerland. But the fear is that yellow fever could follow the same path as other less-severe mosquito-borne diseases, such as  dengue ,  chikungunya  and  Zika , which have already seen major urban epidemics tied to the resurgence of  Aedes  mosquitoes. Scientists are struggling to assess that risk, in part because there is little research on the virus. In South America, for instance, despite endemic jungle yellow fever and  A. aegypti- infested cities, urban outbreaks are almost unheard of. This may be because populations of monkeys and jungle mosquitoes (the reservoirs for the virus) are smaller than in Africa, and because of relatively high vaccination rates among people living in or near the jungle. Yellow fever also seems to spread less easily by  Aedes  mosquitoes than do other viruses such as dengue, says Pedro Fernando da Costa Vasconcelos, an infectious-disease researcher who is director of the Evandro Chagas Institute in Ananindeua, Brazil. Nevertheless, the WHO estimates that South America is now \u201c at greater risk of urban epidemics than at any time in the past 50 years \u201d. Vaccination is officially recommended only in areas where the virus is endemic, because the vaccine can have serious \u2014 sometimes fatal \u2014 side effects in around 1 in 100,000 people. This means that few people are vaccinated on the densely populated eastern seaboard of Brazil, for example, because the region is the only part of the country where the virus is not endemic. In Asia, the absence of yellow fever is an enigma: the continent has the monkeys, mosquitoes and climate in its warm regions that seem ideal conditions for the virus to thrive. Furthermore, infected travellers from elsewhere have introduced the virus to the region many times, and Asian populations don\u2019t have any specific resistance to yellow fever. One hypothesis, says Gubler, is that strains of dengue and other related flaviviruses have for centuries been so prevalent that they offer cross-protection against yellow fever \u2014 and so viral loads are reduced to levels below those required to sustain mosquito-borne cycles of disease. But with the recent unbridled growth of large cities and mosquito-infested slums, Asia\u2019s past freedom from yellow fever may be no guide to its future, Gubler cautions. The Angolan outbreak has also heightened concerns because hundreds of thousands of people from China and other Asian countries now work in Angola and in other at-risk parts of Africa, and many are unvaccinated, says Monath. Several unvaccinated individuals have fallen ill with yellow fever after returning from Angola to southern China. \n               Vaccine stocks \n             Many specialists want authorities to increase international vaccine stockpiles and to accelerate vaccination campaigns in endemic areas. But that would require boosting funding commitments to guarantee a market for manufacturers of the vaccine, Pereas says. Currently, there are only four suppliers worldwide, and supply is falling short of demand. (In a crisis, the WHO could dilute vaccines tenfold to boost its stocks without negating the vaccines\u2019 effectiveness. But the process would require a specific kind of single-use, small-volume syringe, which is not commercially available, Pereas adds.) Gubler argues that vaccination should be considered in  A. aegypti -infested cities close to endemic regions in Africa and South America. In Asia, the risk is too uncertain to recommend vaccination now, he says, but health-care workers there need to be trained to identify cases so that any outbreaks can be nipped in the bud. Renewed efforts to curb  A.\u00a0aegypti  mosquitoes globally are also essential, he adds. For now, the area of most immediate concern is Africa \u2014 where some countries, such as Nigeria, have less than 50% yellow fever vaccination coverage. The availability of vaccines has led to ill-founded complacency about the threat posed by yellow fever, warns Perea. \u201cIt\u2019s a neglected and forgotten disease.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Viral complacency 2016-Apr-05 \n                   \n                     Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                   \n                     Disease: Poverty and pathogens 2016-Mar-16 \n                   \n                     How to beat the next Ebola 2015-Aug-05 \n                   \n                     US assesses virus of the Caribbean 2014-Aug-12 \n                   \n                     Ecology: A world without mosquitoes 2010-Jul-21 \n                   \n                     Yellow Fever Initiative (PDF) \n                   \n                     GAVI Alliance yellow-fever support \n                   \n                     UNICEF yellow fever vaccine market updates \n                   \n                     WHO yellow-fever website \n                   \n                     UN World Urbanization Prospects (PDF) \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19754", "url": "https://www.nature.com/articles/nature.2016.19754", "year": 2016, "authors": [{"name": "Emily Waltz"}], "parsed_as_year": "2006_or_before", "body": "A fungus engineered with the CRISPR\u2013Cas9 technique can be cultivated and sold without further oversight. The US Department of Agriculture (USDA) will not regulate a mushroom genetically modified with  the gene-editing tool CRISPR\u2013Cas9 . The long-awaited decision means that the mushroom can be cultivated and sold without passing through the agency's regulatory process \u2014 making it the first CRISPR-edited organism to receive a green light from the US government. \u201cThe research community will be very happy with the news,\u201d says Caixia Gao, a plant biologist at the Chinese Academy of Sciences\u2019s Institute of Genetics and Developmental Biology in Beijing, who was not involved in developing the mushroom. \u201cI am confident we'll see more gene-edited crops falling outside of regulatory authority.\u201d Yinong Yang, a plant pathologist at Pennsylvania State University (Penn State) in University Park, engineered the common white button ( Agaricus bisporus ) mushroom to resist browning. The effect is achieved by targeting the family of genes that encodes polyphenol oxidase (PPO) \u2014 an enzyme that causes browning. By deleting just a handful of base pairs in the mushroom\u2019s genome, Yang knocked out one of six  PPO  genes \u2014 reducing the enzyme\u2019s activity by 30%. The mushroom is one of about 30 genetically modified organisms (GMOs) to sidestep the USDA regulatory system in the past five years. In each case, the agency's Animal and Plant Health Inspection Service (APHIS) has said that the organisms \u2014 mostly plants \u2014 do not qualify as something the agency must regulate. (Once a crop passes the USDA reviews, it may still undergo a voluntary review by the US Food and Drug Administration.) Several of the plants that bypassed the USDA were made using gene-editing techniques such as the zinc-finger nuclease (ZFN) and transcription activator-like effector nuclease (TALEN) systems. But until now, it was not clear whether the USDA would give the same pass to organisms engineered with  science\u2019s hottest new tool , CRISPR\u2013Cas9. \n               All clear \n             Yang first presented the crop to a small group of USDA regulators in October 2015, after being encouraged to do so by an APHIS official. \u201cThey were very excited,\u201d Yang says. \u201cThere was certainly interest and a positive feeling\u201d at the meetings. He followed up with  an official letter of inquiry  to the agency later that month. The USDA\u2019s answer came this week. \u201cAPHIS does not consider CRISPR/Cas9-edited white button mushrooms as described in your October 30, 2015 letter to be regulated,\u201d  the agency wrote in a 13 April letter  to Yang. Yang\u2019s mushroom did not trigger USDA oversight because it does not contain foreign DNA from \u2018plant pests\u2019 such as viruses or bacteria. Such organisms were necessary for genetically modifying plants in the 1980s and 1990s, when the US government developed its framework for regulating GMOs. But newer gene-editing techniques that do not involve plant pests are quickly supplanting the old tools. The United States is  revamping its rules for regulating GMOs , which collectively are known as  the Coordinated Framework for Regulation of Biotechnology . To that end, the US National Academies of Sciences, Engineering and Medicine have convened a committee that is charged with predicting what advances will be made in biotechnology products over the next 5\u201310 years. It will hold its first meeting on 18 April. In the meantime, Yang is mulling over whether to start a company to commercialize his modified mushroom. Fruits and vegetables that resist browning are valuable because they keep their color longer when sliced, which lengthens shelf life. In the past 18 months, biotech companies have commercialized genetically engineered  non-browning apples  and  potatoes . \u00a0\u201cI need to talk to my dean about that. We\u2019ll have to see what the university wants to do next,\u201d he says about the prospect of bringing his mushroom to market. But he notes that in September 2015, Penn State filed a provisional patent application on the technology. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Gene-editing surges as US rethinks regulations 2016-Apr-12 \n                   \n                     Policy: Reboot the debate on genetic engineering 2016-Mar-09 \n                   \n                     Welcome to the CRISPR zoo 2016-Mar-09 \n                   \n                     Genome editing: 7 facts about a revolutionary technology 2015-Nov-30 \n                   \n                     Super-muscly pigs created by small genetic tweak 2015-Jun-30 \n                   \n                     CRISPR, the disruptor 2015-Jun-03 \n                   \n                     Nature  special: CRISPR \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19752", "url": "https://www.nature.com/articles/nature.2016.19752", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Stem cells derived from older people may need to be screened before use in therapies. Induced pluripotent stem cells (iPS) \u2014 those derived from adult cells \u2014 are inching closer to the clinic. But as a new study helps to show, much work remains before the field can yield mainline treatments. The older a patient is, the more likely it is that induced pluripotent stem (iPS) cells derived from them will carry genetic mutations that could affect the cells\u2019 function, researchers report in  Cell Stem Cell 1 . These mutations are found in the DNA of mitochondria, organelles that power the cell and have their own genomes. Each cell can contain hundreds of mitochondria. To test how genetic variations in mitochondria might affect iPS cells, a team led by reproductive biologist Shoukhrat Mitalipov at Oregon Health and Science University in Portland collected skin and blood samples from a 72-year-old volunteer. The scientists sequenced DNA from the samples, then transformed the adult cells into stem cells by infecting them with viruses that cause the expression of several genes involved in early embryonic development. When the researchers isolated and sequenced DNA from the resulting stem cells, they did not find a high rate of mutations in the mitochondria overall. But when they examined DNA from individual cells chosen at random, they found a wide variety of mutations in mitochondria that had been obscured in the larger pool of cells. \n             Cracking the code \n           Next, the researchers analysed skin and blood samples from 14 people aged between 24 and 72. The older the person was, the more mutations his or her mitochondria acquired. A few of the mutations occurred in DNA that coded for proteins \u2014 which might affect how well the iPS cells would function if transplanted into a patient. \u201cIt\u2019s one of those things most of us don\u2019t think about,\u201d says Jeanne Loring, a stem-cell biologist at the Scripps Research Institute in La Jolla, California. Her lab is working towards using iPS cells to treat Parkinson\u2019s disease, and Loring now plans to go back and examine the mitochondria in her cell lines. She suspects that it will be fairly easy for researchers to screen cells for use in therapies. Mitalipov suggests that researchers who want to use iPS cells in treatments should isolate at least ten cells, and then use the one with the best mitochondria to create a cell line. He also says that the findings support the use of a technique called somatic-cell nuclear transfer, in which embryonic stem cells are created by transferring the nucleus of a patient\u2019s cell into a healthy young egg cell stripped of its own nucleus. This altered donor cell is then used to generate a blastocyst, or early-stage human embryo, that contains mitochondria from the healthy donor and nuclear DNA from the patient. But Loring says that this technique is much more difficult than creating iPS cells, and only a few labs \u2014 including Mitalipov\u2019s \u2014 have the skill to do it. \n             Subtle variations \n           Dieter Egli, a regenerative-medicine researcher at the New York Stem Cell Foundation, says that the findings provide an argument for using embryonic stem cells instead of iPS cells. \u201cThis is definitely going to have an impact\u201d on iPS trials, he says. Screening cell lines is especially important if researchers are to use them in the clinic rather than just in the lab. \u201cFor therapy, you can't just assume it does or doesn\u2019t work,\u201d he says. Mitalipov says that many researchers are moving away from the idea of using a person\u2019s own cells for every treatment, and towards creating banks of iPS cells derived from a variety of people; patients could receive a transplant from the donor whose cells most closely match their own.  The Japanese trial was halted  after a recipient\u2019s cells acquired mutations during the iPS process, and the researchers have applied for permission to treat future trial participants with cells from such a bank.\u00a0 But Egli adds that researchers will also have to determine how meaningful the mitochondrial mutations are, because many biological factors could present problems. Researchers studying how iPS cells differ from embryonic stem cells have found that the two cell types can have differences in chemical markers on their DNA that affect how genes can be expressed 2 , for instance. \u201cIt\u2019s going to be very hard to find a cell line that\u2019s perfect,\u201d he says. \n                   RIKEN suspends first clinical trial involving induced pluripotent stem cells 2015-Sep-08 \n                 \n                   Japan stem-cell trial stirs envy 2014-Sep-16 \n                 \n                   Japanese woman is first recipient of next-generation stem cells 2014-Sep-12 \n                 \n                   Reproductive medicine: The power of three 2014-May-21 \n                 \n                   Human stem cells created by cloning 2013-May-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19749", "url": "https://www.nature.com/articles/nature.2016.19749", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Technique moves man's arm by decoding his thoughts and electrically stimulating his own muscles. A quadriplegic man who has become the first person to be implanted with technology that sends signals from the brain to muscles \u2014 allowing him to regain some\u00a0movement in his right arm\u00a0hand and wrist \u2014 is providing novel insights about how the brain reacts to injury. Two years ago, 24-year-old Ian Burkhart from Dublin, Ohio, had a microchip implanted in his brain, which facilitates the \u2018reanimation\u2019 of his right hand, wrist and fingers when he is wired up to equipment in the laboratory. Researchers led by Chad Bouton, currently at the Feinstein Institute for Medical Research in Manhasset, New York, have been studying Burkhart ever since, and publish their results on 13 April in  Nature 1 . Previous studies have suggested that after spinal-cord injuries, the brain undergoes 'reorganization' \u2014 a rewiring of its connections. But this new work suggests that the degree of reorganization occurring after such injuries may be less than previously assumed. \u201cIt gives us a lot of hope that there are perhaps not as many neural changes in the brain as we might have imagined after an injury like this, and we can bypass damaged areas of the spinal cord to regain movement,\"\u00a0says Bouton. Previously, such a \u2018neural bypass\u2019 had been  done in monkeys , and brain signals had been decoded in people and used to  animate a robotic prosthetic arm , but this is the first time a person has had their own body part reanimated. Burkhart \u2014 who is paralysed from the shoulders down but can move his shoulders and, to a small extent, his elbow \u2014 broke his neck after diving into waves during a beach holiday when he was 19. He later discovered that 25 minutes away from his home, researchers at Ohio State University in Columbus were developing the reanimation technology and decided to volunteer to have the microchip implanted. Bouton and his colleagues took fMRI (functional magnetic resonance imaging) scans of Burkhart\u2019s brain while he tried to mirror videos of hand movements. This identified a precise area of the motor cortex \u2014 the area of the brain that controls movement \u2014 linked to these movements. Surgery was then performed to implant a flexible chip that detects the pattern of electrical activity arising when Burkhart thinks about moving his hand, and relays it through a cable to a computer. Machine-learning algorithms then translate the signal into electrical messages, which are transmitted to a flexible sleeve that wraps around Burkhart\u2019s right forearm and stimulates his muscles. \u201cThe first day we hooked it up I was able to get movement, and open and close my hand,\u201d he says (see 'Ian talks about his new-found movement') \n             boxed-text \n           Since then, he has been attending training sessions up to three times a week. As a result, Burkhart is currently able to make isolated finger movements and perform six different wrist and hand motions, enabling him to, among other things, pick up a glass of water, and even play a guitar-based video game. \n             Brain insights \n           The study provides insights into the brain\u2019s ability to adapt to and exploit new situations. \u201cIt is interesting that, even some years after injury, when these circuits have presumably been sitting there not able to do much, that they still seem to be related to hand movements and haven\u2019t been co-opted by something else,\u201d says Andrew Jackson at Newcastle University, UK, who is separately developing a neural prosthesis to overcome spinal-cord injury. Burkhart\u2019s brain has also learned to coordinate the activity of his reanimated hand with muscles that he already has some control over. His ability to maintain grip while moving objects has gradually improved, and this has been associated with significant changes in his brain activity. The algorithms developed by Bouton\u2019s team register and adapt to such changes in brain activity \u2014 effectively learning with the patient and fine-tuning his movements. There are limitations on the freedom that the device affords Burkhart. The system can be used only in the laboratory and currently needs to be recalibrated at the start of each session. \u201cThis process is time-consuming and relatively technical,\u201d says Jackson. \u201cWhat we\u2019d really like is neural interfaces that are stable from day-to-day and don\u2019t require recalibration.\u201d Burkhart also can\u2019t feel the objects that he\u2019s manipulating; providing the brain with sensory feedback from his hand would enable him to adjust his grip strength more effectively, and to pick up objects that he can\u2019t see. It's not yet clear whether a neural bypass would work in people who don't have the type of residual elbow and shoulder movement that Burkhart does, or in people whose muscles are always contracted, a relatively common problem. \u201cBeing able to combine the recording of brain signals and produce the muscle contractions to make the hand do the correct things is a big step, but we\u2019re still at a point where we\u2019re talking about something that would benefit a small number of people,\u201d says Elizabeth Tyler-Kabara, who directs the Neural Enhancement Laboratory at the University of Pittsburgh.\u00a0 \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Brain implant allows mute man to speak 2008-Nov-21 \n                 \n                   Monkeys move paralysed muscles with their minds 2008-Oct-15 \n                 \n                   Paralysed man sends e-mail by thought 2004-Oct-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19753", "url": "https://www.nature.com/articles/nature.2016.19753", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Damning report blames failure to deliver on goals on management problems and funding issues. An ambitious initiative to fuel innovation in the European Union has swallowed up enormous amounts of money, but has little to show for the investment, its auditors say. Backed with almost \u20ac3 billion in EU cash, the European Institute of Innovation and Technology (EIT) was established in 2008 to stimulate economic growth in the EU by transferring research and innovation from academia into commercial applications. But the institute is a long way from achieving its goals, according to  an audit report  released on 14 April. \"If the EIT wants to become the groundbreaking innovative institute it was originally conceived to be, significant legislative and operational adjustments are required,\" says Alex Brenninkmeijer, the member of the European Court of Auditors who chaired the team behind the report. The auditors identified management problems, ill-suited short-term grants and potential conflicts of interest. They\u00a0recommend, among other things, that the EIT\u2019s funding model be thoroughly revised. The EIT had a  rough start . It was first suggested by former European Commission president Jos\u00e9 Manuel Barroso in 2005 as a centralized research powerhouse to rival the Massachusetts Institute of Technology (MIT) in Cambridge. Critics countered that an institution built from scratch could never mimic the success of MIT. The compromise that emerged \u2014 a distributed network of academic and business partners \u2014 has failed to convince many experts. \u201cThe EIT\u2019s design hasn\u2019t been properly thought out,\u201d says Helga Nowotny, a science-policy adviser to the Austrian government and former president of the European Research Council. \u201cIt makes a lot of sense to improve entrepreneurial spirit and education, especially at technical universities. But stimulating actual innovation by adding more bureaucracy where less is needed just doesn\u2019t work.\u201d \n               KIC-ing off \n             The institute operates through what are known as Knowledge Information Communities (KICs): groups of universities, research institutes and businesses working in specific technologies. Three initial KICs, set up in 2010, cover information and communication; sustainable energy; and climate-change mitigation and adaptation technologies. KICs agreed in 2014 will target health products and services for ageing societies, and innovative raw materials for industrial use, but these are too recent to be included in the audit. The funding that KICs get from the EIT is limited to 25% of their overall costs \u2014 the rest must come from other sources. According to the KIC business plan, participants can apply for money to conduct research on new technologies or prototype products, for instance a novel energy-storage device or a diagnostic assay, or for education and training. In 2014, the three initial KICs created 90 start-ups, 400 business ideas and 71 new or improved products, services or processes. But auditors say that the EIT\u2019s contribution to these projects\u00a0is modest at best, and in most cases it made little difference to business as usual. The EIT claims that every euro spent from the EIT\u2019s budget\u00a0triggers four extra euros for innovation, but the auditors say this is \u201cundemonstrated and implausible\u201d.\u00a0A survey that auditors conducted among the three initial KICs revealed that most of their claimed activities would have been carried out whether or not the EIT existed. The failure to deliver has to some extent been result of the \u201climited leadership abilities\u201d and high staff turnover, including at senior management level, the auditors say. Despite financial checks and reporting requirements, the actual performance of beneficiaries is poorly demonstrated, there is a lack of transparency and possible conflicts of interest. The survey of the KICs revealed that project partners are sometimes involved in reviewing funding proposals in which they themselves stand to benefit. The European Commission, which is funding the EIT, and the EIT\u2019s management have accepted most of the criticism and say that they will promptly address the concerns. The management has already begun to modify project administration processes to improve transparency and ease red tape, the report acknowledges. \u201cWe agree with this report\u2019s important finding and recommendations,\u201d says Martin Kern, the Budapest-based\u00a0interim director of the EIT. \u201cBut we have moved on since, and we have already addressed many concerns.\u201d Since he took office in 2014, Kern has set up a task force to streamline administration. He also asked all EIT-funded collaborations to focus more on results and impacts. Meanwhile, the KICs have adopted principles of good governance to prevent any conflicts of interest. \u201cWe will monitor that issue very closely,\u201d he says. Because its task is to navigate\u00a0activities where market failure is the norm, the EIT deserves another chance, says Kurt Deketelaere, the Leuven-based secretary-general of the League of European Research Universities, a partnership of 21\u00a0top universities. \u201cMany of our members have been complaining about the EIT,\u201d he says. \u201cBut if existing concerns are properly addressed, I am confident that after all those years we are heading in a direction where it may finally deliver.\u201d\u00a0 Others are not so sure.\u00a0\u201cSomething that problematic shouldn\u2019t be that big,\u201d says Paul Nightingale, deputy director of the of the science policy and research unit of the University of Sussex in the UK. \u201cAny researcher, especially in poorer EU countries, will know lots of things that would provide much better value for money than a mostly ineffective innovation scheme.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Redirection home 2015-Feb-04 \n                   \n                     Europe cuts funding red tape 2011-Oct-04 \n                   \n                     Europe's innovation hub finally KICs off 2011-Feb-21 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19756", "url": "https://www.nature.com/articles/nature.2016.19756", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "But researchers warn that there is no real evidence that it actually works. Brazilian President Dilma Rousseff has sidestepped the country\u2019s drug regulators, signing into law a bill that guarantees people with cancer access to an unapproved \u2018miracle drug\u2019 that has never been tested in clinical trials. The law went into effect on 14 April and came just weeks after Brazil\u2019s science ministry reported that the compound, called synthetic phosphoethanolamine, had failed to fight cancer in its laboratory tests. \u201cIt\u2019s very sad,\u201d says Paulo Hoff, an oncologist at the University of S\u00e3o Paulo. \u201cIt undermines the regulatory agency and it legalized something which at this point we don't know if it helps, or it has even some unknown side effects. Rousseff was under significant political pressure to wave the bill through: she is facing possible impeachment for financial impropriety, and lawmakers and their constituents have been  clamouring for access to the compound . The law allows anyone with a medical report that certifies their cancer diagnosis to acquire the drug, and does not require a prescription. \n             Limited access \n           For now, patients may have difficulty getting their hands on the pills, says Jailson de Andrade, secretary for research-and-development policy at Brazil's science and technology ministry. The law also demands that the compound be made at a facility that is approved for making human drugs. But no such facility is currently manufacturing phosphoethanolamine in Brazil, de Andrade says. Even so, Hoff says that patients regularly arrive at his hospital saying that they have taken the drug, even though he is still waiting for a pharmaceutical company to produce just enough of the compound to treat the ten patients he wants to enrol in an initial clinical trial. \u201cI don\u2019t know where they are getting it, but the reality is they are,\u201d he says. For years, patients got the compound from a chemistry lab at the University of S\u00e3o Paulo\u2019s campus in S\u00e3o Carlos. When the university attempted to halt distribution, thousands of patients sued. In the past, some judges have orderd the university to give patients phosphoethanolamine made in the chemistry laboratory, but it is not authorized to produce medicines. In response to the debacle, the science and technology ministry committed about 10 million reais (US$2.9 million) to study the compound. Early results from the study show that it is not toxic to cells grown in culture \u2014 but it is equally harmless to cancer cells. Animal studies are ongoing, says de Andrade. \n             Pushing on \n           Hoff hopes that his trial, which is sponsored by the state of S\u00e3o Paulo, will get under way in a few weeks. He and his colleagues are not waiting on the animal studies because the compound has already been taken by thousands of people, he says, with no obvious signs of toxicity. His team plans to first test whether the dose that patients are currently taking is safe in ten people. After that, the trial will expand and will test whether the drug works against cancer. He anticipates results in about six months, but it is likely that some patients will refuse to accept any data that question the effectiveness of phosphoethanolamine. Hoff says that some of his patients who took the compound had a hard time believing it when their cancer progressed. \u201cA patient told me, \u2018No, there is a mistake. I want to keep taking this\u2019,\u201d he says. \u201cIt has become a matter of faith.\u201d Meanwhile, de Andrade is worried about reports of patients \u2014 even those with early, potentially treatable disease \u2014 who decline standard treatment with chemotherapy or surgery in favour of taking the untested compound. \u201cWe are urging everyone: do not stop the formal treatment,\u201d he says. \u201cDo not stop.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Brazilian courts tussle over unproven cancer treatment 2015-Nov-24 \n                 \n                   Brazilian science paralysed by economic slump 2015-Sep-30 \n                 \n                   Science safe in Brazil elections 2010-Sep-29 \n                 \n                   Ministry of Science, Technology, and Innovation (MCTI): Phosphorylethanolamine (in Portuguese) \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19755", "url": "https://www.nature.com/articles/nature.2016.19755", "year": 2016, "authors": [{"name": "Carrie Arnold"}], "parsed_as_year": "2006_or_before", "body": "Lab-made antibodies could produce high-volume, high-quality snakebite treatments. When the medical charity M\u00e9decins Sans Fronti\u00e8res called the worldwide shortage of snake antivenom a public-health crisis last September, Brazilian biochemist Paulo Lee Ho wasn\u2019t surprised. He has spent his career at S\u00e3o Paulo\u2019s Butantan Institute searching for better ways to create antivenom to treat bites from coral snakes. Conventional methods rely on natural coral-snake venom, which is hard to come by: the snakes produce only small amounts with each bite and are hard to raise in captivity. So Ho and others have turned to proteomics and synthetic biology in the hope of improving the quality and availability of antivenom. \u201cWe need a new way to meet the demand for antivenom from the Ministry of Health,\u201d he says. These efforts are now bearing fruit. Last month, Ho and his colleagues reported 1  that they had engineered short pieces of DNA that, when injected into mice, triggered antibodies against coral-snake venom. The scientists then boosted the animals\u2019 immune response by injecting them with small pieces of synthetic venom antibodies synthesized in  Escherichia coli  bacteria. In a separate study also published last month 2 , another group of researchers in Brazil used synthetic antibody fragments to neutralize the effects of bites by the pit viper  Bothrops jararacussu . Such progress is encouraging, given the severe medical burden caused by snakebites in the developing world, says Robert Harrison, head of the Alistair Reid Venom Research Unit at the Liverpool School of Tropical Medicine, UK. Each year, around 90,000\u00a0people die after being bitten by venomous snakes 3 . Yet antivenoms are still made using a method that has not changed for more than a century. Large animals, typically horses, are injected with small amounts of purified proteins extracted from snake venom, which prompts the production of antibodies. Plasma containing these antibodies is then given to snakebite victims. But this life-saving treatment is limited in important ways. Each antivenom is effective against only a single species or, at most, a small group. And the drugs must be refrigerated, a major problem in tropical countries without reliable electricity. \u201cWhen you think about it, it\u2019s amazing these antivenoms work at all,\u201d says Leslie Boyer, director of the Venom, Immunochemistry, Pharmacology and Emergency Response Institute at the University of Arizona in Tucson. \n               Trial and error \n             The number of pharmaceutical companies that make antivenoms is declining, because the drugs are not very profitable. In 2010, for instance, pharmaceutical giant Sanofi of Paris, ended production of the antivenom Fav-Afrique, which is designed to treat the bites of ten of Africa\u2019s most poisonous snakes. Ho hopes that his approach will help to fill this void. Rather than relying on venom milked from live coral snakes, he began with small pieces of coral-snake DNA that code for venom toxins. He and his colleagues injected these DNA pieces into mice to prime their immune systems; a month later, they gave the animals a booster shot containing synthetic venom antibodies. Only 60% of mice injected with a lethal dose of coral-snake venom survived after receiving Ho\u2019s experimental treatment, compared to nearly 100% for existing antivenoms. But Ho is undaunted. \u201cThis result shows there are other ways to obtain neutralizing antibodies,\u201d he says. \u201cMaybe to get better results, we need to try again but use more antibodies. We just don\u2019t know yet.\u201d The second Brazilian team, led by molecular biologist Carla Fernandes of the Funda\u00e7\u00e3o Oswaldo Cruz (Fiocruz) biomedical research institute in Porto Velho, tested a different technique, using a phage display library to make synthetic versions of the antibodies that llamas produced when they were injected with  B. jararacussu  snake venom. Giving these antibodies to snakebite victims would eliminate the need to use animal plasma. It also could reduce muscle damage and tissue death at the site of the bite, compared to traditional antivenoms, because the synthetic antibodies are smaller and better able to penetrate into tissue. The path to newer antivenoms isn't straight, but researchers believe that moving quickly is key. \u201cThere has been significant, rapid progress in this area, but it needs to be fast. There are too many people dying from what is essentially a preventable disease,\u201d says Harrison. To Boyer, however, the antivenom shortage is not caused by a lack of science. \u201cIt costs 14\u00a0bucks to make a vial of antivenom that costs US$14,000 in the US,\u201d she says. \u201cYou\u2019re not going to get cheaper than that. The expensive parts aren\u2019t the science \u2014 it\u2019s everyone wanting a cut of the profits that drives the price up and puts it out of reach.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Africa braced for snakebite crisis 2015-Sep-16 \n                   \n                     Antivenoms needed, say officials, but companies won't bite 2010-Jun-01 \n                   \n                     Bringing antivenoms to Sub-Saharan Africa 2007-Feb-01 \n                   \n                     M\u00e9decins Sans Fronti\u00e8res (Doctors Without Borders) on snakebite \n                   \n                     Global Snakebite Initiative \n                   \n                     Australian Venom Research Unit \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19751", "url": "https://www.nature.com/articles/nature.2016.19751", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Seismic images from an unprecedented international collaboration hint at future eruption hazards. A rare collaboration between North Korean and Western scientists has probed the ground beneath a dangerous volcano on the Chinese\u2013Korean border. The work illuminates the geological plumbing that could underlie possible future eruptions. \u201cNow we can start to see into the underbelly of the volcano,\u201d says Kayla Iacovino, a volcanologist with the US Geological Survey in Menlo Park, California. She and her colleagues, led by Ri Kyong-Song of the Earthquake Administration in Pyongyang, Democratic People\u2019s Republic of Korea (DPRK), used seismic data to pinpoint molten rock beneath the mountain. The paper appears on 15 April in  Science Advances 1 . Called Mount Paektu on the Korean side and Changbaishan on the Chinese side, the volcano is considered one of the region\u2019s most hazardous. Around the year 946, it let loose one of the most powerful eruptions in recorded history, showering ash as far away as Japan. Today, more than 1.6\u00a0million people live within 100\u00a0kilometres of Paektu. \u201cThis volcano is quiet at the moment, but it\u2019s definitely got potential,\u201d says team member James Hammond, a seismologist at Birkbeck, University of London. \u201cWe need to keep an eye on it.\u201d Lava could potentially erupt as much as 20\u00a0kilometres away from the mountain\u2019s summit, says Haiquan Wei, a volcanologist at the China Earthquake Administration in Beijing who has studied the mountain\u2019s past activity 2 . \n               Sleeping giant \n             Because the volcano straddles the Chinese\u2013North Korean border, scientific studies have been fragmented between the two countries. \u201cPeople have spent their whole lives studying the volcano and have never seen it from the other side,\u201d says Iacovino. The mountain holds a special significance in Korea as the purported birthplace of both the founder of the first Korean kingdom and of former DPRK leader Kim Jong-Il. Paektu last erupted in 1903. In 2002 it began shaking with thousands of tiny earthquakes, possibly as magma shifted underground. The seismic unrest ended after several years without any lava erupting \u2014 but the episode prompted researchers on both sides of the border to reassess what they knew about the volcano and to try to prepare for what it might unleash in the future. In 2011, at the invitation of the DPRK government, Hammond went to North Korea with Clive Oppenheimer, a volcanologist at the University of Cambridge, UK. That meeting spawned an unprecedented collaboration to try to understand Paektu better from the Korean side 3 . With diplomatic support from the American Association for the Advancement of Science in Washington DC and the Royal Society in London, Hammond arranged to bring six state-of-the-art seismometers into North Korea. It wasn\u2019t easy. It took years to sort out the proper import licences, and the team had to ditch plans to measure conductivity beneath the volcano because the required equipment has a second use in submarine detection. But in the end, Hammond and his colleagues deployed the seismometers in a 60-kilo\u00admetre-long line east from Paektu\u2019s summit, deep into the countryside. \u201cEvery year I would visit these families and they would look after our stations for us,\u201d says Hammond. \u201cThey clearly wanted to understand this volcano.\u201d \n               Past as prologue? \n             The seismometers remained in place from August 2013 to August 2015 (which meant that they were not present during any of the DPRK\u2019s four nuclear-weapons tests). By analysing how seismic waves travelled beneath the volcano, the scientists found that a significant part of the crust must be at least partially molten. \u201cWhether or not that melt is going to turn into an eruption is a bigger question,\u201d says Iacovino. \u201cBut at least we can now start to draw a picture of what\u2019s happening.\u201d Other studies have hinted at the presence of molten rock beneath the volcano before, says Haibo Zou, a geoscientist at Auburn University in Alabama. But \u201cany new serious research,\u201d he says, \u201dis of interest\u201d. Chinese and North Korean scientists monitor Paektu using their own seismic networks as well as gas samples collected from hot springs. But until geologists have a better understanding of what the volcano has done in the past, it will be hard to tell emergency officials how they should prepare for future eruptions, says Iacovino. For instance, she has been mapping the geology of the ash, pumice and other rocks thrown outward in the AD 946 eruption. Enormous clouds of superheated gas and ash swept downhill, followed by destructive mudslides. If Paektu were to erupt again, it might send water rushing downhill from the summit lake, or clouds of ash skyward to interfere with aeroplane flights across Korea and Japan. By studying rocks collected during a 2013 visit, Iacovino has found that the AD 946 eruption probably spewed much more sulfur dioxide into the atmosphere than earlier studies reported 4 . That suggests that Paektu has the potential to alter global climate. Hammond will be in Pyongyang next week, working on future proposals to expand studies of Paektu. \u201cWe\u2019d really like to work together with the Chinese and North Koreans to study the volcano as a whole volcano, using instruments on both sides of the border,\u201d he says. \u201cUltimately, it\u2019s up to them to work together, and maybe we can be a part of it.\u201d \n                     What kind of bomb did North Korea detonate? 2016-Jan-08 \n                   \n                     World's deadliest volcanoes identified 2015-Mar-03 \n                   \n                     Why Japan missed volcano's warning signs 2014-Sep-29 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19759", "url": "https://www.nature.com/articles/nature.2016.19759", "year": 2016, "authors": [{"name": "Rachel Becker"}], "parsed_as_year": "2006_or_before", "body": "How brain disorder related to mad-cow disease spread to Norway is a mystery. A highly contagious and deadly animal brain disorder has been detected in Europe for the first time. Scientists are now warning that the single case found in a wild reindeer might represent an unrecognized, widespread infection. Chronic wasting disease (CWD) was thought to be restricted to deer, elk ( Cervus canadensis ) and moose ( Alces alces ) in North America and South Korea, but on 4 April researchers  announced  that the disease had been discovered in a free-ranging reindeer ( Rangifer tarandus tarandus ) in Norway. This is both the first time that CWD has been found in Europe and the first time that it has been found in this species in the wild anywhere in the world. \u201cIt\u2019s worrying \u2014 of course, especially for animals. It\u2019s a nasty disease,\u201d says Sylvie Benestad, an animal-disease researcher at the Norwegian Veterinary Institute in Oslo who, along with colleague Turid Vik\u00f8ren, diagnosed the diseased reindeer. A key question now is whether this is a rare \u2014 even unique \u2014 case, or if the disease is widespread but so far undetected in Europe. \u201cIf it\u2019s similar to our prion disease in the United States and Canada, the disease is subtle and it would be easy to miss,\u201d says Christina Sigurdson, a pathologist at the University of California, San Diego, who has shown that reindeer can contract CWD in a laboratory environment 1 . \n             Mysterious origins \n           Like both bovine spongiform encephalopathy \u2014 also known as mad-cow disease \u2014 and variant Creutzfeldt-Jakob disease in humans, CWD occurs when cellular proteins called prions  bend into an abnormal shape , inducing neighbouring, healthy proteins to do the same. The misfolded proteins aggregate in the brain and sometimes in other tissue, causing weight loss, coordination problems and behaviour changes. There is no cure or vaccine; as far as scientists know, CWD is always fatal. Although the disease is not known to be transmissible to humans, it is  highly contagious  among deer, elk and related animals, which can shed infectious misfolded prion proteins in their saliva, urine and faeces. Animals infected with CWD have been found in more than 20 states in the United States and 2 provinces in Canada. The disease has also been detected in captive animals in South Korea, which imported CWD with a shipment of live elk brought into the country for farming in the late 1990s. The infected reindeer ended up on Vik\u00f8ren\u2019s necropsy table thanks to scientists with the Norwegian Institute for Nature Research in Trondheim. They found it as they used a helicopter to track a free-ranging herd from the Nordfjella population in the alpine regions of southern Norway. Their goal was to capture adult female reindeer and collar them for satellite tracking \u2014 but when the researchers landed, they discovered a sick animal that could not move and soon died. During the necropsy, Benestad tested for the abnormally folded proteins as a matter of routine. Eventually, a total of three different antibody-based tests all confirmed the presence of prions. \u201cI was very afraid,\u201d Benestad says. During her long career as a prion researcher she has heard scientists from the United States and Canada discuss CWD, how contagious it is and how hard it is to stamp out. It is a mystery how this disease arrived on a mountaintop in Norway. Benestad and Vik\u00f8ren think it unlikely that it was it imported. They suspect that it might have arisen spontaneously, or jumped the species barrier from a prion disease in sheep called scrapie, although such a jump has never been seen before. \u201cThe $64,000 question is what is the origin of this case of CWD in Europe,\u201d says Glenn Telling, a prion-disease researcher at Colorado State University in Fort Collins. \u201cWhat we do know is that once CWD is detected in new locations, it typically takes a foothold in that location, and is difficult to eradicate.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Prions found in urine 2005-Oct-13 \n                 \n                   Chronic wasting disease spreads with ease 2003-Sep-04 \n                 \n                   Norwegian Veterinary Institute statement \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19758", "url": "https://www.nature.com/articles/nature.2016.19758", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "IPCC agrees to examine consequences of modest levels of warming. As the leaders of more than 130 nations prepare to sign the Paris climate agreement, the Intergovernmental Panel on Climate Change (IPCC) has agreed to embark on an in-depth review of what global warming of 1.5 \u00baC above pre-industrial levels might do to humans and ecosystems. \u201cWe have focused on what might happen at four or more degrees warming,\u201d says Corinne Le Qu\u00e9r\u00e9, director of the Tyndall Centre for Climate Change Research in Norwich, UK, and an author of many IPCC reports. \u201cThe impacts of relatively modest warming are much less studied.\u201d At a  meeting this week  in Nairobi, the group agreed to produce three special reports over the next few years. One will look at the impacts of 1.5 \u00baC of warming and is to be completed as early as 2018; the other two will assess the impacts of climate change on land use and on terrestrial ecosystems and on oceans, glaciers and polar ice sheets. The IPCC\u2019s last round of reports, completed in 2014, helped to create a sense of urgency around the negotiations in Paris in December, where  nations agreed  to try to keep the rise in the planet\u2019s temperature \u201cwell below\u201d 2 \u00b0C and to push for it to be limited to 1.5 \u00b0C. But the commitments made so far by nations are unlikely to keep warning much below 2.7 \u00baC. \u201cWe must learn to understand what that difference might mean for nature and society,\u201d\u00a0says Le Qu\u00e9r\u00e9. The reports\u2019 specific approaches and content will be determined in scoping meetings over the next month. The special report on 1.5 \u00baC will need to outline greenhouse-gas emission pathways that might limit global warming to safe levels, says Jan Fuglestvedt, a climate scientist with the Center for International Climate and Environmental Research in Oslo and a vice-chair of the IPCC\u2019s physical-sciences group. \u201cIt\u2019s essential that governments know how and when they need to act to keep warming below 1.5 degrees,\u201d he says. But others say that the report should focus on fundamental scientific uncertainties, such as how rising carbon dioxide concentrations will affect the temperature or how climate change will affect human health, rather than looking at hypothetical solutions to the climate dilemma, such as geoengineering technologies that might reflect back sunlight or capture and store CO 2 . \u201cUnrealistic mitigation pathways that rely on unproven geoengineering techniques are not very helpful,\u201d\u00a0says Le Qu\u00e9r\u00e9. \u201cWe must not miss the opportunity to gain knowledge in ranges that really matter.\u201d \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                 \n                   UN climate reports are increasingly unreadable 2015-Oct-12 \n                 \n                   Four challenges facing newly elected climate chief 2015-Oct-06 \n                 \n                   IPCC \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19775", "url": "https://www.nature.com/articles/nature.2016.19775", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Research-council grants will escape anti-lobbying crackdown, government confirms. UK university scientists who receive public funds will not be prevented by an \u2018anti-lobbying\u2019 rule from speaking about the political implications of their work, the government has confirmed. The news has reassured scientists who had  feared that the incoming ban on using public funds for political lobbying could have had a chilling effect on researchers . But it\u2019s still not clear whether all researchers who receive government funds will be exempted from the contentious ban, which is due to be applied to grants awarded from this May. In theory, the ban \u2014 first unveiled on 6 February \u2014 might have stopped scientists responding to government consultations or giving evidence to inquiries held by Parliament. But speaking in the House of Lords on 19 April, George Bridges, a senior official in the Cabinet Office (a government department that supports the activities of the prime minister and senior politicians) said that \"Grant recipients can continue to discuss the findings of publicly funded research with government or Parliament, whether that be giving evidence or in an advisory capacity.\" Bridges said that the implementation of the anti-lobbying clause, as it applied to science and research, was a matter for the department of Business, Innovation and Skills (BIS), which is responsible for most of the public funds channelled to British scientists and universities. But it was not the government\u2019s \u2014 or BIS\u2019s \u2014 intention that the clause would cover the UK\u2019s seven main public research-funding bodies (the research councils), he said. In a statement, science minister Jo Johnson said that he was \u201chappy to confirm that it is not our intention for the research councils, the Higher Education Funding Council for England (HEFCE) or the National Academies to be covered by the clause. We are continuing to talk to the research community and will outline more detail by 1 May, when this clause takes effect.\u201d \n             Welcome news \n           \u201cThis is good news and a huge step in the right direction. The message is loud and clear that science is a welcome and necessary part of Parliamentary debate and policy-making,\u201d said Sarah Main, director of the Campaign for Science and Engineering (CaSE), a London-based lobby group. Both HEFCE and the research councils are funded by BIS, and they supply money for much of the research conducted in universities. But the announcement leaves open the possibility that scientists not funded by BIS \u2014 such as those who receive government cash through the Department of Health or the Department for Environment, Food and Rural Affairs \u2014 could still be subject to the gagging clause. Bob Ward, policy and communications director at the Grantham Research Institute on Climate Change and the Environment in London, who led a widely supported petition against the clause, says Johnson, BIS and the Cabinet Office \u201cdeserve credit for at least recognizing the importance of an exemption for university research grants\u201d. He adds: \u201cIt\u2019s clear Jo Johnson has succeeded in making the case that HEFCE and the research councils will be exempted.\u201d Researchers now await those further details from BIS. Under the rule, it is possible for BIS to either completely remove the clause from research grants, or to add in \u2018qualifications\u2019 of some kind while still implementing the clause. \n                   Unintended consequences 2016-Mar-02 \n                 \n                   Confusion reigns as UK scientists face government \u2018gagging\u2019 clause 2016-Feb-26 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19793", "url": "https://www.nature.com/articles/nature.2016.19793", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Two NIH facilities that manufacture products for use in patients have been shut down because of safety violations. The US National Institutes of Health (NIH) has suspended two of its manufacturing facilities that were found to be at risk of contaminating materials intended for use in patients, the agency announced on 19 April. Several clinical trials that use products made by those facilities are also on hold and will not be recruiting new patients until the issues are resolved. Oncologist Steven Rosenberg\u2019s lab at the National Cancer Institute (NCI) in Bethesda, Maryland, is one of the two facilities affected. Rosenberg is developing cancer therapies using  immune cells called T lymphocytes , which he engineers to attack a specific patient's cancer. After discovering problems with Rosenberg\u2019s cell-manufacturing lab, the NCI suspended 13 trials that used materials from the facility. The second lab, at the National Institute of Mental Health (NIMH) in Bethesda, manufactures molecules used in brain imaging. The NIH has identified 15 studies with a total of 92 patients that have received injections of material from this lab. The safety violations came to light during a sweeping NIH-wide review that began last year. It was prompted by the  discovery of widespread contamination  by the US Food and Drug Administration (FDA) in a facility at the NIH Clinical Center in Bethesda that manufactures customized drugs for use in clinical trials. A whistleblower\u2019s tips led FDA investigators to fungal contamination in materials intended for injection into patients, lab workers with uncovered hair, and insects in the light fixtures. The NIH later formed a working group to develop remediation plans. The group will present these in a report to director Francis Collins on 21 April. \n             Clean sweep \n           To find out whether its other labs might have similar problems, the NIH hired two consultancy groups, Working Buildings in Atlanta, Georgia, and Clinical IQ in Madison, New Jersey, to perform independent evaluations. \u201cIt was to reassure ourselves that every other place that was manufacturing things to be infused into patients was up to snuff,\u201d says Kathy Hudson, NIH deputy director for science outreach and policy. The latest violations do not appear to involve contamination, she says, but rather problems with the labs such as airflow and workers\u2019 clothing. \u201cWe are working very hard and very collaboratively with [Rosenberg] and NCI and others across NIH to identify a path forward so that we can have him continue his research,\u201d Hudson says. The NIH says that it does not believe that any patients have been harmed by the safety lapses. The patients in the 13 cancer trials had already received their one-time injection of T cells and are being monitored. The NIMH says that it is following the people who received injections of a radioactive molecule that helps researchers to see the brain\u2019s structure under a scanner. About three-quarters of these people were healthy volunteers. Rosenberg declined to comment on the matter. NCI spokesperson Cynthia Vitelli says that the institute suspended the cancer trials on 6 April after identifying problems. \n             Looking ahead \n           Kite Pharma in Santa Monica, California, which collaborates with Rosenberg and plans to commercialize some of the T-cell therapies, broke the news about the NCI findings on 16 April at the annual meeting of the American Association for Cancer Research in New Orleans, Louisiana. Kite\u2019s executive vice-president, David Chang, says that the company was unaffected by the suspended trials, and the company\u2019s future trials will use cells and materials manufactured at its facilities in Santa Monica. Another Rosenberg collaborator, Lion Biotechnologies in New York City, said on 17 April that several trials it had been involved in were also unaffected. Contractors \u2014 who are still inspecting several NIH labs in Frederick, Maryland \u2014 discovered the contamination risk at the NIMH facility and alerted the NIH on 19 April. The agency announced that it had suspended operations at the NIMH and NCI facilities the same day. NIH spokesperson Renate Myles says that Working Buildings and Clinical IQ plan to file a systematic review of their findings by 29 April. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Contamination shuts down NIH pharmacy centre 2015-Jun-05 \n                 \n                   US health agency blasted over lab safety violations 2015-Mar-24 \n                 \n                   NIH finds forgotten smallpox store 2014-Jul-09 \n                 Reprints and Permissions"},
{"file_id": "532289a", "url": "https://www.nature.com/articles/532289a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Experiments are now approved in Sweden, China and the United Kingdom. At the Karolinska Institute in Stockholm, Fredrik Lanner is preparing to edit genes in human embryos. It\u2019s the kind of research that sparked an international frenzy in April last year, when a Chinese team revealed that  it had done the world\u2019s first such experiments 1 . But Lanner doesn\u2019t expect his work, which will explore early human development, to cause such a fuss. A year of discussion about the ethics of embryo-editing research, and perhaps simply the passage of time, seems to have blunted its controversial edge\u00a0\u2014\u00a0although such work remains subject to the same ethical anxieties that surround other reproductive-biology experiments. \u201cAt least in the scientific community, I sense more support for basic-research applications,\u201d says Lanner, who gained approval for his experiments last June. His instinct seems to be borne out by the fairly muted reaction to a 6\u00a0April report 2  of an experiment to edit human embryos\u00a0\u2014\u00a0only the second to be published. A team led by Yong Fan at Guangzhou Medical University in China used the gene-editing technology CRISPR\u2013Cas9  to try to introduce a mutation that makes humans resistant to HIV infection . \u201cI don\u2019t think there is anything wrong with what these scientists have done,\u201d says Sarah Chan, a bioethicist at the University of Edinburgh, UK. \u201cThis work isn\u2019t seeking to do what is still ethically in question. It\u2019s not seeking to create genetically modified human beings.\u201d The ethics committee of the university-affiliated hospital that approved Fan\u2019s work says that it has green-lighted two other embryo-editing projects; such research is ethically sound because it will lead to improvements in gene-editing technology and could help to prevent diseases, a committee spokesperson says. Last December, an international summit of scientists and ethicists declared that gene editing should not be done in human embryos that are intended for use in establishing a pregnancy\u00a0\u2014\u00a0but it  endorsed basic research . \u201cPeople are more understanding of this research,\u201d says Fan, who points to  UK fertility regulators\u2019 approval in February  of a proposal by developmental biologist Kathy Niakan to edit genes in healthy human embryos, at the Francis Crick Institute in London. \n               China's lead \n             Fan\u2019s team began its experiments in early 2014 and originally submitted the paper to  Cell Stem Cell , Fan says. By the time the manuscript ended up on the desk of David Albertini, editor-in-chief of the  Journal of Assisted Reproduction and Genetics , a different Guanghzou-based team had become the first to report human-embryo-editing experiments. That paper 1 , which tried to correct a mutation that causes a blood disease, fed into a firestorm over the ethics of modifying human reproductive cells (or \u2018germline\u2019 modification). Some researchers called for a moratorium even on proof-of-principle research in non-viable embryos. Albertini, a reproductive biologist at the University of Kansas Medical Center in Kansas City, felt that it was important to publish Fan\u2019s paper to educate scientists and clinicians. He says that the manuscript went through two rounds of review over eight\u00a0months\u00a0\u2014\u00a0twice as long as is normal for the journal\u00a0\u2014\u00a0and that he urged the researchers to discuss the ethical issues surrounding germline editing in the paper. Fan\u2019s paper should help to reassure international observers about the legitimacy of human-embryo-editing research in China, says Robin Lovell-Badge, a developmental biologist at the Crick. More such embryo-editing papers are likely to be published, he adds. \u201cI know that there are papers floating around in review,\u201d he says.\u201cI\u2019d much rather everything was out in the open.\u201d (Fan says that his team is now focusing on improving the efficiency of CRISPR using human stem cells). \n               Out in the open \n             Research involving the editing of human embryos will begin soon elsewhere in the world, if it hasn\u2019t done so privately already. In a  Cell  paper published on 7\u00a0April 3 , Lanner\u2019s team analysed gene expression in 88\u00a0early human embryos and is using those data to identify genes to disrupt in embryos using CRISPR\u2013Cas9. Lanner will discuss the work at a meeting on human gene editing organized by the US National Academy of Sciences and National Academy of Medicine this month in Paris. He says that the experiments could begin in the coming months. Evan Snyder, a stem-cell scientist at the Sanford Burnham Prebys Medical Discovery Institute in La Jolla, California, says that he doesn\u2019t know of anyone in the United States conducting human embryo editing. But he thinks that US scientists will inevitably take on such research, although federal funding of research on human embryos and germline modification is prohibited. It is important for such research to go forward, Snyder adds, to determine whether technical hurdles would prevent clinical applications. \n               Setting norms \n             Norms for conducting and publishing human-embryo-editing work are still taking shape. Snyder says that whenever possible, researchers should use alternatives, such as embryos of non-human primates. And when it is not, they should use only surplus embryos that would ordinarily be discarded from  in\u00a0vitro  fertilization clinics. Both Chinese teams used non-viable embryos, but Lovell-Badge says experiments in normal embryos are also important: to see, for instance, whether CRISPR\u2013Cas9 is more or less effective in such cells. Some scientists contend that gene-editing experiments designed to probe human development, such as those planned by Lanner and Niakan, are more valuable than experiments that are intended to lay the groundwork for creating genetically modified humans. \u201cAt the moment, there seems little point in pursuing long-term clinical goals when there\u2019s so much not known about the technique with human embryos,\u201d says Lovell-Badge. But Chan thinks there should be ethical latitude for both kinds of research to proceed. \u201cWe should give the public the credit for being able to understand the difference between research into genetically modified embryos and genetically modifying human beings,\u201d she says. \u201cI think it\u2019s a good thing if the hubbub dies down a bit.\u201d Additional reporting by David Cyranoski. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Second Chinese team reports gene editing in human embryos 2016-Apr-08 \n                   \n                     UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                   \n                     Where in the world could the first CRISPR baby be born? 2015-Oct-13 \n                   \n                     UK scientists apply for licence to edit genes in human embryos 2015-Sep-18 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   \n                     Don\u2019t edit the human germ line 2015-Mar-12 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19773", "url": "https://www.nature.com/articles/nature.2016.19773", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Disabled CRISPR enzyme allows efficient single-letter DNA changes. A painstaking re-engineering of the CRISPR gene-editing system has given researchers the ability to alter individual DNA letters efficiently in a given gene. The advance boosts the success of such\u00a0edits, and could boost scientists\u2019 ability to model human diseases and develop treatments for them. Researchers have been  quick to embrace a gene-editing tool called CRISPR\u2013Cas9 , which lets them modify targeted genes with unprecedented ease. But although it is easy to use the tool to wipe out a gene\u2019s function, it has been difficult to fix a \u2018point mutation\u2019 \u2014 caused by a change in a single DNA letter in a given gene \u2014 by correcting just the letter affected. Those point mutations are important. \u201cIt turns out that the majority of disease-associated human genetic variants are point mutations,\u201d says David Liu, a chemical biologist at Harvard University in Cambridge, Massachusetts. \u201cBut current genome methods correct point mutations much less efficiently and much less cleanly than we can disrupt a gene.\u201d \n             Search and destroy \n           Cas9 is an enzyme that can be targeted to a specific site in the genome by a guide RNA molecule. Once it finds a DNA sequence that matches the guide RNA, it breaks both strands of the double helix at that spot. Cells respond by healing the break, but tend to do so in a sloppy way, often inserting or deleting DNA letters, called bases. The result is usually a disabled gene. Researchers can try to encourage another form of repair by providing a DNA template that the cell can use as a guide, so that repair enzymes insert a matching DNA sequence into the break. But this method is generally successful less than 5% of the time \u2014 and sometimes much less. The rest of the repairs are done the sloppy way. So Liu and his team, including fellow Harvard chemical biologist Alexis Komor, set out to find a way to edit the genome without breaking it. They disabled the Cas9 enzyme so that it would no longer cut DNA, then tethered it to an enzyme capable of chemically converting one DNA letter to another: a cytosine (\u2018C\u2019) to a uridine (\u2018U\u2019). Uridines are usually found in RNA rather than DNA; in DNA, the cell reads them as if they were the \u2018T\u2019 base, thymidine. A guide RNA would direct the disabled Cas9 to its target in the genome, where the modified enzyme would change the DNA sequence rather than break the helix. The engineered enzyme worked on isolated DNA in test tubes about 44% of the time \u2014 a significant improvement, the team reports in  Nature 1 . But in cells, the efficiency was only 7.7% at best. One problem was that the enzyme was making changes to only one strand of DNA, creating a mismatch with the other strand. The cell was correcting that mismatch, undoing the work of the engineered enzyme. \n             Change management \n           Liu\u2019s team tacked another protein onto their engineered Cas9 to block the removal of U bases from DNA, and made a few other tweaks. The resulting base editor, as Liu calls it, corrected mutations associated with Alzheimer\u2019s disease in mouse cells grown in culture with an efficiency of up to 75%, the researchers report. The base editor was also able to correct a mutation in a cancer-associated gene with up to 7.6% efficiency in human cells. The standard CRISPR-Cas9 method failed to do so at all. There are hundreds of other disease-associated mutations that could be corrected using a C to U switch, says Liu. But the team is now working to expand its reach to other point mutations, and to try the technique in animals.\u00a0Liu hopes that his tricked-out enzymes will make it easier to create animal models that carry human mutations associated with disease. And eventually, after years of testing and refinement, the modified Cas9 could even be used to treat disease. The method could also be expanded to other enzymes. An  alternative to Cas9, called Cpf1 , was characterised last year 2  and may be better for inserting sequences into genes. Two papers published by  Nature  on 21 April shed new light on how Cpf1 works. One shows how the enzyme changes shape when bound to its guide RNA 3 ; the other describes a Cpf1 enzyme capable of cleaving both DNA and RNA 4 . Stanley Qi, a bioengineer at Stanford University in California, is eager to give Liu\u2019s modified Cas9 a try. He says that the method could be much simpler than the old CRISPR method one, which requires inserting a DNA template that is prone to degradation and was sometimes even toxic to cells. \u201cThis avoids a major barrier,\u201d he says. \u201cIt really expands the scope of CRISPR\u2019s applications.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   CRISPR: Pursuit of profit poisons collaboration 2016-Apr-13 \n                 \n                   Second Chinese team reports gene editing in human embryos 2016-Apr-08 \n                 \n                   CRISPR: gene editing is just the beginning 2016-Mar-07 \n                 \n                   Monkeys genetically modified to show autism symptoms 2016-Jan-25 \n                 \n                   Nature  special: CRISPR \n                 \n                   Addgene: CRISPR guide \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19777", "url": "https://www.nature.com/articles/nature.2016.19777", "year": 2016, "authors": [{"name": "Bethany Augliere"}], "parsed_as_year": "2006_or_before", "body": "Fossils found in the Panama Canal are the oldest evidence of monkeys in North America. Fossilized teeth unearthed in Panama suggest that monkeys reached North America millions of years earlier than scientists thought. The discovery, published on 20 April in  Nature 1 , reveals new information about the spread of primates across the Americas. A team led by Jonathan Bloch, a palaeontologist at the Florida Museum of Natural History in Gainesville, found seven monkey teeth in the Panama Canal Basin. The scientists have identified the fossils as belonging to a previously unknown species,  Panamacebus transitus , that lived nearly 21 million years ago, during the early Miocene epoch. \u201cWe never would've predicted they would've been here,\u201d says Bloch. The teeth are the oldest evidence for the dispersal of a mammal from South America to North America, he says. No other mammals are known to have made it across the body of water that separated the two continents in the early Miocene. Current theory suggests that  primates  crossed the Atlantic Ocean from Africa to South America roughly 37\u201334 million years ago by rafting on vegetation. These \u2018New World\u2019 monkeys \u2014 a group that includes  marmosets  and spider and howler monkeys \u2014 spread and diversified into tropical regions of South America. Scientists had thought that monkeys did not reach Central America until after the formation of the Isthmus of Panama 3.5 million years ago. The strip of land links North and South America. But Bloch\u2019s finding suggests that the primates crossed a water barrier and made it into North America nearly 18 million years earlier. \u201cThe discovery is absolutely astounding, and extraordinary claims do require extraordinary evidence,\u201d says Richard Kay, a biological anthropologist at Duke University in Durham, North Carolina. The route by which New World monkeys spread and diversified is hotly debated. Bloch and his colleagues suggest that modern monkeys emerged from the tropics. Others dispute this, arguing that fossils similar in age to  P. transitus  exist in Patagonia. But Bloch notes that  P. transitus  is at least equal in age to the oldest disputed fossil, if not a million years older. \n             Teeth in the tropics \n           The tropics have generally been a difficult place to uncover fossils owing to forest cover, says Bloch, who typically works in dry deserts full of exposed rock. But construction to  expand the Panama canal , which began in 2007, exposed fossil-bearing rock from the Miocene. \u201cIt was an incredible opportunity, a once-in-a-century opportunity to look at rocks in the tropics,\u201d he says. He and his colleagues found upper molars, a lower canine, two incisors and two premolars while digging through dirt and rock in a quarry near the banks of the canal. The team spent two years analysing high-resolution images of the teeth to place the species on the evolutionary tree. The molars resemble those from monkeys in the family Cebidae, which includes capuchin monkeys ( Cebus capucinus ) and squirrel monkeys ( Saimiri sciureus ). No evidence exists that the first monkeys to reach Central America survived long enough to establish a lasting population. The ancestors of monkeys found in the region today reached there much later, Kay says. Bloch suggests that New World monkeys were limited in their range by the northern extent of their preferred rainforest habitat. \u201cThat\u2019s why you don\u2019t get monkeys in Southern California, even to this day,\u201d says Daniel Gebo, a biological primatologist at Northern Illinois University in DeKalb. Bloch will head to Panama again next month and search the same quarry where his team found  P. transitus . \u201cI would really like to find a skull or parts of the rest of the skeleton,\u201d he says.  \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Oldest primate skeleton unveiled 2013-Jun-05 \n                 \n                   Fossils indicate common ancestor for two primate groups 2013-May-15 \n                 \n                   Fossil skull fingered as ape\u2013monkey ancestor 2010-Jul-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19757", "url": "https://www.nature.com/articles/nature.2016.19757", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Four published papers offer diverse explanations for a possible new particle. Hints of a new subatomic particle at the world\u2019s most powerful atom smasher have inspired theoretical physicists to write  more than 300 papers  in the past four months. Now, a journal has published four of them, forming a condensed guide to what has become a zoo of possible explanations for a mysterious anomaly in the data collected by the Large Hadron Collider (LHC). \u201cWe think that this set gives readers a sense of the kind of new physics that would be required to explain the data, if confirmed,\u201d wrote Robert Garisto, editor of  Physical Review Letters  ( PRL ), which published the four papers on 12 April, in an accompanying editorial 1 . PRL  received \u201cquite a few\u201d submissions related to the data bump, Garisto told  Nature . In addition to the ordinary peer-review process, the journal also enlisted experts who examined all the submissions to give informal advice, he says. The papers that  PRL  published span some of the most provocative ideas surrounding the particle, says Michael Peskin, a theoretical physicist at the SLAC National Accelerator Laboratory in Menlo Park, California. \n             Photon surprise \n           Last year, the 27-kilometre-long LHC at CERN, Europe\u2019s particle-physics laboratory near Geneva, Switzerland, began to collide protons at a record energy of 13 teraelectronvolts. On 15 December, the LHC\u2019s two largest particle detectors, called ATLAS and CMS, both  reported an unexpected excess of pairs of photons  with a combined energy of 750 gigaelectronvolts (GeV). The data could represent a random fluctuation. But that  has not stopped theorists from weighing in . Most of their explanations include the existence of a new particle with a mass of 750 GeV, which would decay into two photons. Such a particle would be \u201cmuch more thrilling than the Higgs boson\u201d, says Christoffer Petersson, a theoretical physicist at Chalmers University of Technology in Gothenburg, Sweden \u2014 the Higgs was already predicted by the standard model of particle physics when  it was discovered in 2012 .\u00a0Moreover, most of the theories also predict the existence of one or more other types of particle, some of which could also be discovered at the LHC. In one of the four newly-published papers 2 , Petersson and his colleague Riccardo Torre of the Federal Polytechnic School of Lausanne (EPFL), Switzerland, outline a particle that would have very weak interactions with other particles and would exist within a framework of theories known as  supersymmetry . \n             Exotic quarks \n           But some physicists say that the particular shape of the bump in the LHC data \u2014 when combined with other hints \u2014 could suggest the presence of strongly interacting particles. And another of the four papers proposes that a number of new particles that interact strongly are the cause of the photon excess. This theory 3  posits a particle made of two 'exotic' quarks \u2014 which are not currently part of the standard model \u2014 held together by a force similar to the strong nuclear force, says co-author Kohsaku Tobioka of the Weizmann Institute of Science, Rehovot, Israel, and Tel-Aviv University. In the third paper selected, theorist Chen Zhang of Peking University in Beijing and his co-authors propose that the mystery bump is produced by a particle similar to the Higgs boson, but six times more massive 4 . This has been one of the most popular explanations among physicists because the decay into a pair of photons is one of the signatures of the Higgs. The most surprising of the four papers, according to Peskin, comes from Doojin Kim of the University of Florida in Gainesville and six collaborators, three of whom are theorists on the CMS team. They propose 5  that there is no particle with a mass of 750 GeV. Instead, the two photons could represent part of the debris produced by the decay of a potentially much more massive particle. Physicists hope that the LHC, which is currently restarting after a shutdown, will have enough data to either make the excess go away or to confirm a historic discovery by the end of summer. In the meantime, Maria Spiropulu, an experimental particle physicist at the California Institute of Technology in Pasadena and a member of CMS is enjoying the ride: \u201cIt is great to see the theorists wrestling with this and going in loops \u2014 I love it.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Hints of new LHC particle get slightly stronger 2016-Mar-17 \n                 \n                   Who ordered that? 2016-Mar-08 \n                 \n                   Hint of new boson at LHC sparks flood of papers 2015-Dec-24 \n                 \n                   LHC sees hint of boson heavier than Higgs 2015-Dec-15 \n                 Reprints and Permissions"},
{"file_id": "532294a", "url": "https://www.nature.com/articles/532294a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Housing lab mice with pet-shop mice gives them more human-like immune systems. Most scientists stocking a lab with mice order the animals from a commercial supplier. But David Masopust, an immunologist at the University of Minnesota in Minneapolis, chose a more difficult route. He decided to catch wild mice in a barn at a petting zoo \u2014 where he then had to fend off a cockatoo vying for one of the trapped mice. \u201cYou do question what exactly you got yourself into,\u201d he says. Masopust went to such lengths because he doubted that commercial lab mice \u2014 selectively bred in sanitized environments \u2014 are good research analogues for people, who do not live in such clean conditions. In a paper online in  Nature  (Beura, L. K.  et al.   https://doi.org/10.1038/nature17655 ; 2016), he and his colleagues show that wild mice and mice from pet shops have strong, complex immune systems that mimic those of adult humans. Exposing lab mice to these \u2018dirty mice\u2019 strengthened their immune systems and made them more human-like. Therapies tested in lab mice  rarely translate into humans , and researchers have long thought that differences between human and rodent immune systems may be partly to blame. Lab mice, for instance, have very low levels of some types of the immune cells called memory CD8 +  T cells compared with adult humans. In people, these cells mature during childhood after exposure to viruses and other pathogens, and help to fight against infections and cancers.  People have known there\u2019s a problem for a long time, but in most cases they just want to ignore it.  But without a better alternative, most researchers still use lab mice to test therapies or study disease. \u201cPeople have known there\u2019s a problem for a long time, but in most cases they just want to ignore it,\u201d says Mark Davis, an immunologist at Stanford University in California. \u201cThere\u2019s so much invested in the inbred mouse model.\u201d To test whether differences between lab mice and their kin are genetic or are the result of environmental exposures, Masopust housed lab mice with those bought from pet shops and monitored them for two months. The lab mice had a tough time: many became sick from exposure to the dirt and pathogens carried by the outside mice and about 20% of them died. But the surviving lab mice emerged stronger for the experience. When the researchers infected the co-housed lab mice with  Listeria  bacteria, the animals fought off the infection much better than normal lab mice. The pet-shop mice and the co-housed mice had higher levels of mature immune cells, including CD8 +  cells, and expressed the same immune genes as adult humans. The genes and cells of unexposed lab mice, by contrast, were similar to those of newborn humans. \u201cIt\u2019s so nice to see these labs starting to step out of the box,\u201d says Amy Pedersen, an ecologist at the University of Edinburgh, UK, who studies how diseases arise in wild mice. Pedersen is not surprised that the mice have such different immune systems. She says that researchers\u2019 increasing interest in the microbiome\u00a0\u2014 the bacteria that colonize the body\u00a0\u2014 is leading to more papers supporting this idea. Masopust says that his work should not be taken as an argument  against using mice to model human diseases . Rather, he says that exposing lab mice to dirty mice could be one step in developing therapeutics. \u201cI\u2019d sure as heck want to pilot when possible anything I find in mice through this model before going into humans,\u201d he says, especially because human trials are extremely expensive. Now that he has the co-housing facility set up, Masopust hopes to collaborate with researchers who want to expose their research animals to his dirty mice. Studies on allergies, infectious disease and cancer could all be influenced by these changes to the animals\u2019 immune systems. Davis is impressed by the paper, calling it \u201ca simple solution to some aspects of the differences between inbred mice and actual humans on the streets\u201d. But he says that co-housing lab and dirty mice will not solve all the problems with mouse models of human disease. Ideally, Davis says, mouse vendors could produce and sell lines of research mice that have been exposed to dirty mice. But it would be logistically difficult for researchers to use these animals in clean mouse facilities, where some mice are engineered to lack immune systems, for instance, or are infected with specific pathogens for experiments. To conduct his experiments, Masopust had to convince the University of Minnesota to let him bring dirty wild mice into its meticulously clean and germ-free facilities\u00a0\u2014 which required housing them in a special wing dedicated to mice with dangerous infections, such as tuberculosis. In fact, Cory Brayton, a pathologist at Johns Hopkins University in Baltimore, Maryland, says that she is impressed that Masopust\u2019s experiment shows just how clean typical lab mice are. \u201cCongratulations to the mouse supplier,\u201d she says. Masopust says that the next phase of his research will test what happens when clean baby lab mice are raised with dirty mouse mothers. This could probe  the \u2018hygiene hypothesis\u2019  \u2014 the idea that allergies and autoimmune diseases result when babies are not exposed to enough microbes or allergens when they are young. \n                 Follow Sara on Twitter  \n                 \n                     @Sara_Reardon \n                   \n               \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                   \n                     Early exposure to germs has lasting benefits 2012-Mar-22 \n                   \n                     How microbes train our immune system 2011-Sep-21 \n                   Reprints and Permissions"},
{"file_id": "532157a", "url": "https://www.nature.com/articles/532157a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Streaked acidic clouds and a bow shape in the atmosphere are among Akatsuki\u2019s findings. After an unplanned five-year detour, Japan\u2019s Venus probe, Akatsuki, has come back to life with a bang. On 4\u20138 April, the Japan Aerospace Exploration Agency (JAXA) presented the first scientific results from the spacecraft since it was  rescued from an errant orbit  around the Sun and rerouted to circle Venus, four months ago. These include a detailed shot of streaked, acidic clouds and a mysterious moving \u2018bow\u2019 shape in the planet\u2019s atmosphere. Despite the probe\u2019s tumble around the Solar System, its instruments are working \u201calmost perfectly\u201d, Akatsuki project manager Masato Nakamura, a planetary scientist at JAXA\u2019s Institute of Space and Astronautical Science in Sagamihara, Japan, announced at the Inter\u00adnational Venus Conference in Oxford, UK. And if another small manoeuvre in two years\u2019 time is successful, he said, the spacecraft might avoid Venus\u2019s solar-power-draining shadow, and so be able to orbit the planet for five years, rather than the two it was initially assigned. Akatsuki, which means \u2018dawn\u2019 in Japanese, launched in 2010 and was supposed to enter into orbit around Venus later that year to study the planet\u2019s thick atmosphere. The mission would include looking for signs of active volcanos and other geology. But upon entry, a fault in a valve caused the probe\u2019s main engine to blow, and the  craft instead entered an orbit around the Sun . As Akatsuki passed near Venus in December, JAXA engineers managed to salvage the mission by instructing the craft\u2019s much smaller, secondary thrusters to push it into a looping elliptical orbit around the planet. The results presented in Oxford were captured from this vantage point with a suite of five cameras that capture light ranging from infrared to ultraviolet. A highly detailed shot of dense layers within Venus\u2019s sulfuric acid clouds elicited applause from the audience. The highest-quality infrared image of this view of Venus, it suggests that the processes that underlie cloud formation might be more complicated than thought, project scientist Takeshi Imamura told attendees. And the team expects still better results to come. The image was taken from 100,000 kilometres away \u2014 more than 10 times the probe\u2019s distance at its closest pass of Venus. \u201cWe will achieve better spatial resolution still,\u201d said Takehiko Satoh, principal investigator for the probe\u2019s 2-micrometre infrared camera, IR2, which took the image. \u201cWe promise to give a fantastic data set to the research community for years.\u201d The bow shape, which was seen in thermal images taken using a long-wave infrared (LIR) camera, provided some intrigue. The moving cloud formation, which swept from pole to pole across the planet for days, seemed to rotate with Venus\u2019s surface, rather than with its much quicker-moving atmosphere. The motion suggests that the front could be linked to features on the ground, said Makoto Taguchi, who leads the LIR camera. Others at the conference were at a loss as to what may have caused it. \u201cIt\u2019s certainly mysterious,\u201d says planetary scientist Suzanne Smrekar of NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. Akatsuki\u2019s success has cheered researchers, especially because it is now the only working probe deployed at Venus. \u201cThe mood is very good,\u201d says Colin Wilson, a planetary scientist at the University of Oxford, UK. Akatsuki\u2019s orbit \u2014 which was tweaked slightly on 4 April to give the probe the best chance of lasting for years to come, as well as to provide a good scientific vantage point \u2014 will allow it to survey Venus\u2019s equator as originally planned. The resulting images will complement surveys of the planet\u2019s poles from the European Space Agency\u2019s Venus Express orbiter, which ended its mission in 2014. But Akatsuki\u2019s new lease of life comes with compromises, too. Its current 10.5-day operational orbit takes it almost 5 times as far from Venus at its most distant point than its original intended orbit (see \u2018Orbital alteration\u2019). Except for those taken during the short period when the probe sweeps close to the planet, images will be lower in resolution than planned. This means that studies that require detail, such as spotting flashes of lightning, will take longer. But the team said that it plans to make the best of the probe\u2019s wide orbit to take whole-Venus images that track large-scale features over time. The mission has also not shrugged off all consequences of its long and unexpected cruise around the Sun. One camera malfunctioned in January, probably because of gradual contamination of a helium coolant with water vapour over the years, said Satoh. Engineers have now fixed the problem by warming the coolant to disperse the vapour, but it took a while. \u201cWe had a painful blank of about a month,\u201d says Satoh. Planetary scientists outside of JAXA will have to wait a year from acquisition to access the data, but they are nonetheless excited by the probe\u2019s initial success. Two Venus-based projects are among five proposals shortlisted by NASA for possible launch in the early 2020s. The agency is expected to decide by the end of December, and Venus missions could get a boost from Akatsuki\u2019s success \u2014 especially if the orbiter finds intriguing features that require follow up, says Smrekar, who leads one of the Venus proposals that NASA is considering, the proposed VERITAS radar orbiter. \u201cIf they\u2019re able to see new volcanism, for example, it definitely makes the case for going back to explore more fully,\u201d she says. See Editorial  page 148 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Destination Venus 2016-Apr-12 \n                   \n                     Japan\u2019s Venus orbiter makes comeback 2015-Dec-07 \n                   \n                     Japan orbiter seeks second shot at Venus 2015-Dec-04 \n                   \n                     NASA narrows its list of planetary targets 2015-Sep-30 \n                   \n                     Venus scientists fear neglect 2011-Sep-02 \n                   \n                     Venus miss is a setback for Japanese programme 2010-Dec-14 \n                   \n                     Venus may have had continents and oceans 2009-Jan-13 \n                   \n                     Akatsuki \n                   Reprints and Permissions"},
{"file_id": "531562a", "url": "https://www.nature.com/articles/531562a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Sea levels could rise by more than 15 metres by 2500 if greenhouse-gas emissions continue to grow. Choices that the world makes this century could determine the fate of the massive Antarctic ice sheet. A study published online this week in  Nature 1  finds that continued growth in greenhouse-gas emissions over the next several decades could trigger an  unstoppable collapse of Antarctica\u2019s ice  \u2014 raising sea levels by more than a metre by 2100 and more than 15 metres by 2500. \u201cThat is literally remapping how the planet looks from space,\u201d says study co-author Rob DeConto, a geoscientist at the University of Massachusetts Amherst. The good news, he says, is that it projects little or no sea-level rise from Antarctic melt if greenhouse-gas emissions are reduced quickly enough to limit the average global temperature rise to about 2 \u00b0C. The findings add to a  growing body of research  that suggests that  Antarctic ice is less stable than once thought . In its 2013 report 2 , the Intergovernmental Panel on Climate Change estimated that Antarctic melting would contribute just a few centimetres to sea-level rise by 2100. But as scientists develop a better understanding of how the ocean and atmosphere affect the ice sheet, their projections of the continent\u2019s future are growing more dire. DeConto and co-author David Pollard, a palaeoclimatologist at Pennsylvania State University in University Park, developed a climate model that accounts for ice loss caused by  warming ocean currents  \u2014 which can eat at the underside of the ice sheet \u2014 and for rising atmospheric temperatures that melt it from above. Ponds of meltwater that form on the ice surface often drain through cracks; this can set off a chain reaction that breaks up ice shelves and causes newly exposed ice cliffs to collapse under their own weight. They found that by including all of these processes, they could better simulate key geological periods that have long puzzled scientists. Before the last ice age began 130,000\u2013115,000\u00a0years ago, for instance, sea levels were 6\u20139 metres higher than today \u2014 yet atmospheric carbon-dioxide levels were about 30% lower. And 3 million years ago, when CO 2  levels roughly equalled today\u2019s, the oceans may have been 10\u201330 metres higher. Incorporating the physics of ice melt driven by atmospheric warming, along with cliff collapse, helped DeConto and Pollard to reproduce these key periods with their model. \u201cThat was sort of an epiphany that maybe we were on to something,\u201d DeConto says. Ultimately, he and Pollard tested how well different versions of their model simulated the past, and then used the ones that performed best to project future sea-level rise. They found that over time, atmospheric warming would become the main driver of ice loss. \u201cI think their processes are still a bit speculative, but it\u2019s good work,\u201d says Nick Golledge, an ice-sheet modeller at the Victoria University of Wellington in New Zealand. His research, published in  Nature  in October 3 , suggests that Antarctic ice melt driven by rising greenhouse-gas emissions could boost global sea levels by up to 39 centimetres by 2100, and by as much as 3 metres by 2300. Still, Golledge cautions, scientists know little about how the atmosphere and ocean affected ancient glaciers. \u201cWe don\u2019t really have a great handle on what the climate was like in the past,\u201d he says.  That was sort of an epiphany that maybe we were on to something.  A third  Nature  study, published in December 4 , suggested that Antarctic melting was unlikely to produce more than 30 centimetres of sea-level rise by 2100. But its authors noted that newly identified processes such as surface melting and the collapse of ice cliffs could increase ice loss. As such, DeConto and Pollard\u2019s projections \u201care consistent with our recent study\u201d, says co-author Tamsin Edwards, a physicist at the Open University in Milton Keynes, UK. Glaciologists are already aware of the destructive power of the atmospheric-warming and cliff-collapse mechanisms that DeConto and Pollard\u2019s model simulates. A string of unusually warm summers caused the  sudden collapse of Antarctica\u2019s Larsen B ice shelf  in 2002. And scientists have witnessed the basic physics of ice-cliff collapse during calving events on the Jakobshavn and Helheim glaciers in Greenland. \u201cOn the observational side, I see the things they are talking about,\u201d says David Holland, a physical-climate scientist at New York University. \u201cThere\u2019s a lot of observation and modelling to go, but they are adjusting people\u2019s thinking in a very scientific way.\u201d For DeConto, the new model results underscore the choice that humanity is facing. If he and Pollard have the physics correct, this process of ice-shelf disintegration, followed by ice-cliff collapse, will be nearly impossible to stop once it gets under way. \u201cOnce the ocean warms up, that ice will not be able to recover until the oceans cool back down,\u201d he says \u2014 a process that could take thousands of years. \u201cIt\u2019s a really long-term commitment.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Antarctic coast meltdown could trigger ice-sheet collapse 2015-Nov-02 \n                   \n                     Gains in Antarctic ice might offset losses 2015-Oct-02 \n                   \n                     'Stable' region of Antarctica is melting 2015-May-21 \n                   \n                     Oceans melt Antarctica's ice from below 2013-Jun-13 \n                   \n                     NASA IceBridge \n                   \n                     British Antarctic Survey's Bedmap \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19627", "url": "https://www.nature.com/articles/nature.2016.19627", "year": 2016, "authors": [{"name": "Sanjay Kumar"}], "parsed_as_year": "2006_or_before", "body": "Fund sets target of approving US$2.5 billion this year to help developing nations cope with climate change. The Green Climate Fund (GCF) has had an inauspicious start to life \u2014 but 2016 could be the year it springs into action. The organization, a flagship funding mechanism for the United Nations, was established in 2010 to channel billions of dollars to help developing nations to cope with climate change. But it hasn\u2019t yet handed out any money and has been  widely criticized  for its lack of accountability and transparency. At a  meeting of its governing board  earlier this month in Songdo, South Korea, however, the fund resolved to hire more staff, to become significantly more transparent about its operations, and \u2014 ambitiously \u2014 to approve projects worth US$2.5 billion this year alone. \u201cThis year will be important for demonstrating that the GCF can fund transformational actions in developing countries,\u201d says Niranjali Amerasinghe, who studies climate finance at the World Resources Institute in Washington DC. \n             More money, more staff \n           By the end of December 2015, governments had pledged $10.3 billion to the GCF (although exchange-rate fluctuations could cut that down to $8.7 billion, using December's rates). However, not all of those pledges had been formally agreed before the March meeting, and by the end of 2015, just $1.6 billion had made its way into the fund\u2019s coffers. At the March board meeting, the United States \u2014 the most significant missing donor \u2014 agreed to formalize the $3 billion offer it pledged in 2014, and to send as its first instalment a $500-million chunk of that commitment. More cash will also enable the fund to ramp up its personnel. It currently has \u201ca very limited number of staff when compared to other international funds\", a spokesperson told  Nature : just 56 permanent staff, compared to the 204 staff of Gavi, the Vaccine Alliance, and the 650 staff of the Global Fund to Fight AIDS, Tuberculosis and Malaria \u2014 both initiatives that have funding commitments similar to the GCF. By the end of 2016, the GCF says that it will have 100 staff, and reach 140 by 2017. And to address the heavily criticism that the fund has been reluctant to provide public information about its activities, under a new disclosure policy adopted at the March meeting it vows to provide as much information as possible. \u201cOne clear victory for civil society is the board's decision to allow webcasting of its meetings, which we have been pushing for since the first GCF board meeting in 2012,\u201d says Lidy Nacpil, who was at the March meeting and who coordinates a regional alliance of non-governmental and community organizations, called the Asia Pacific Movement on Debt & Development in Manila. \n             Climate aid \n           The pledges mean that in 2016 the GCF might finally be able to get down to business: vetting proposals for climate mitigation and adaptation projects in developing nations and sending them money. Before the Paris climate talks in December, the fund had approved $168 million for eight climate projects, including wetland resilience programmes in Peru and climate-resilient infrastructure in Bangladesh, although it has yet to hand out that cash. Given that sluggish pace, Nacpil calls the aim to approve $2.5 billion of projects this year \"challenging\". Researchers who have been watching the GCF\u2019s pipeline of possible projects say that a major issue is that many developing countries lack the capacity to develop sound proposals for projects in the first place. So the GCF has allocated $1.5 million to Rwanda and $75,000 to the Cook Islands to help their readiness to make project proposals. At this stage, \u201cdisbursal of project funds is less important than disbursing readiness funds\u201d, says Neha Rai, a researcher at the International Institute for Environment and Development in London. A GCF strategic plan adopted at the meeting suggests that besides capacity building and project funding, the GCF ultimately also intends to transfer \u201ccutting-edge climate technologies\u201d to developing nations. Those might include smart-grid technologies, electric vehicles and components used in solar electricity generation, says Chandra Bhushan, deputy director-general of the Center for Science and Environment, an advocacy group in New Delhi. The fund is currently also searching for a new director: last month, its incumbent head H\u00e9la Cheikhrouhou, announced that she would end her three-year term in September. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Climate changes 2016-Feb-23 \n                 \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Green Climate Fund faces slew of criticism 2015-Nov-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19643", "url": "https://www.nature.com/articles/nature.2016.19643", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Quest aims to uncover secrets of big craters across the Solar System. Geophysicists are returning to Earth\u2019s most famous cosmic bullseye. Around 7 April, from a drill-ship off the coast of Yucat\u00e1n, Mexico, they will start to penetrate the 200-kilometre-wide Chicxulub crater, which formed 66 million years ago when an enormous asteroid smashed into the planet. The aftermath of the impact  obliterated most life  on Earth,  including the dinosaurs . The expedition is the first to directly probe one of Chicxulub\u2019s most striking features \u2014 its \u2018peak ring\u2019, a circle of mountains that rises within the crater floor. Scientists have yet to fully explain how peak rings form, even though they are common in big impact craters across the Solar System. At Chicxulub, researchers will look for evidence to explain how a 14-kilometre-wide asteroid could have punched a hole that pushed rocks from the surface down some 20\u201330 kilometres. Flowing like liquid, the rocks then rebounded towards the sky \u2014 reaching as far as 10 kilometres above the original ground level \u2014 and finally splattered down to form a peak ring. All of this happened in the span of several devastating minutes, says Joanna Morgan, a geophysicist at Imperial College London and the project\u2019s co-chief scientist. \u201cIt\u2019s astounding.\u201d If the 2-month expedition goes as planned, it will bore 1,500 metres into sea-floor rocks. The drill will first pass through carbonate rocks that make up the bottom of the Gulf of Mexico (see map), and eventually reach the fractured \u2018impact breccias\u2019 that represent the obliterating impact. At least a dozen other boreholes and several oil-exploration wells have already penetrated the parts of Chicxulub that lie on land. They include a 1,511-metre-long core drilled near the crater rim in 2001\u201302 by a large international scientific consortium 1 . When combined with seismic surveys 2 , analyses of existing cores reveal a complex picture of nested rings of shattered rock, all created on a very bad day for life on Earth 3 . \n             Inner circle \n           The latest project will be the first to drill offshore at Chicxulub, and the first to target its peak ring. \u201cWe don\u2019t really know what this material will look like,\u201d says Jaime Urrutia-Fucugauchi, a geophysicist at the National Autonomous University of Mexico in Mexico City. \u201cIt could be a real surprise.\u201d The US$10-million project is funded primarily by the European Consortium for Ocean Research Drilling, and involves researchers from Europe, Mexico, the United States and elsewhere. The water at the drill site \u2014 about 30 kilometres offshore from the port of Progreso \u2014 is too shallow to accommodate conventional ocean-drilling vessels, so the project has hired  LB Myrtle , a \u2018lift boat\u2019 that will drop three enormous pillars to the sea floor, then jack itself up to form a temporary drilling platform. Chicxulub is the only impact crater on Earth both big enough and well-preserved enough to still have a peak ring. Finding out exactly how the rocks are layered in the core will help researchers to evaluate several competing models of peak-ring formation, says David Kring, a geologist at the Lunar and Planetary Institute in Houston, Texas. He and his colleagues studied the peak ring inside the lunar crater Schr\u00f6dinger to predict what sorts of rock might exist in the Chicxulub core 4 . Drillers will quickly bore their way through the top 500 metres of sediments, and then collect core samples more carefully as they go deeper. \u201cAt every level you\u2019ll get a win,\u201d says Sean Gulick, a geophysicist at the University of Texas at Austin and the expedition\u2019s other co-chief scientist. At about 600 metres, the core will pass through rock from the Palaeocene\u2013Eocene Thermal Maximum, when temperatures spiked about 55 million years ago, creating a greenhouse world. At 650 metres the core should hit the peak ring. \n             Primordial ooze \n           Perhaps the biggest question about the peak ring is where its rocks came from. If the rocks within the ring are relatively light in colour, they probably came from the topmost 5\u201310 kilometres of Earth\u2019s crust. Darker rocks are likely to be rich in elements such as iron and magnesium, and probably came from greater depths \u2014 perhaps 10\u201315 kilometres down. Confirming the depth of the peak-ring rocks will help modellers to understand how the crust fractures and flows during a giant impact. The core could also reveal whether the impact fostered life even while destroying it. When the asteroid shattered Earth\u2019s crust, heat and water began flowing through the fragmented rocks. Microbes may have thrived in that warm, watery habitat, so microbiologists will test the cores for ancient DNA and other signatures of living organisms. \u201cBy looking directly at ground zero, we can watch life recover,\u201d says Gulick. From the drill rig, the cores will be sent to Bremen, Germany, for more detailed study later this year. Urrutia-Fucugauchi hopes that some of the most dramatic samples will eventually return to Mexico, perhaps to a new core laboratory at the Yucat\u00e1n Science and Technology Park on the outskirts of M\u00e9rida. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Asteroid impact may have gassed Earth 2009-May-13 \n                 \n                   'Dinosaur-killing' impact did not start global wildfires 2009-Feb-23 \n                 \n                   Volcanoes implicated in death of dinosaurs 2008-Dec-16 \n                 \n                   Roast dinosaur off the menu? 2003-Dec-03 \n                 \n                   Expedition 364 overview \n                 \n                   Chicxulub educational site \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19671", "url": "https://www.nature.com/articles/nature.2016.19671", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "'Cello' automates the fast, reliable design of DNA-based logic circuits. Synthetic biologists have created software that automates the design of DNA circuits for living cells. The aim is to help people who are not skilled biologists to quickly design working biological systems, says synthetic biologist Christopher Voigt at the Massachusetts Institute of Technology in Cambridge, who led the work. \u201cThis is the first example where we\u2019ve literally created a programming language for cells,\u201d he says. In the new software \u2014 called  Cello  \u2014 a user first specifies the kind of cell they are using and what they want it to do: for example, sense metabolic conditions in the gut and produce a drug in response. They type in commands to explain how these inputs and outputs should be logically connected, using a computing language called Verilog that electrical engineers have long relied on to design silicon circuits. Finally, Cello translates this information to design a DNA sequence that, when put into a cell, will execute the demands. Voigt says his team is writing user interfaces that would allow biologists to write a single program and be returned different DNA sequences for different organisms. Anyone can access Cello through a  Web-based interface , or by downloading its  open-source code from the online repository GitHub . \u201dThis paper solves the problem of the automated design, construction and testing of logic circuits in living cells,\u201d says bioengineer Herbert Sauro at the University of Washington in Seattle, who was not involved in the study. The work is published in  Science . 1 \n             Working together \n           Creating Cello required a decade of labour, says Voigt. The hard part, he says, was not writing the software itself but working out how to make biological parts \u2014 logic gates, by analogy with electronic circuits \u2014 that reliably worked together to carry out the functions programmed into the circuit by Verilog. For instance, the team had to develop a combination of genetic components that work together as an 'insulator' \u2014 ensuring that each biological part works no matter where in the DNA sequence it is placed. How to design reliable, complex biological computing systems is a  central problem of synthetic biology , Voigt says. Researchers found that DNA-based analogues of electronic switches and transistors would work in simple cases but would often fail when organized into more complex circuits. But inexpensive gene-synthesis technologies and the use of fast, cheap genetic sequencing to look at what goes wrong have enabled  huge advances  in understanding. \u201cWhat we\u2019re finding over time is that biology isn\u2019t this kind of mysterious unpredictable substrate; it just felt that way because we didn\u2019t really have the tools to see what was going on,\u201d Voigt says.Voigt\u2019s team tested 60 designs made using Cello; 45 worked correctly the first time. He estimates that it would take about a week to design 60 biological circuits with Cello; by contrast, it took a postdoc three years to design, test and build one successful biological circuit for a paper published in 2012, he says 2 . Synthetic biologist Adam Arkin at the University of California, Berkeley, who was not involved in the work, says that Cello is one of  a series of steps  that aim to push synthetic biology closer to meeting its founding goals of using the principles of engineering to enable the design of new biological circuits.\u201cWhat is wonderful is seeing the original conception of synthetic biology \u2014 to build the infrastructure to make the engineering of new biological function vastly more efficient, predictable, transparent and safe \u2014 come to fruition in such powerful computational tools and biological reagents,\u201d Arkin says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Living factories of the future 2016-Mar-16 \n                 \n                   Synthetic biology\u2019s first malaria drug meets market resistance 2016-Feb-23 \n                 \n                   Synthetic biologists seek standards for nascent field 2015-Apr-07 \n                 \n                   Synthetic-biology firms shift focus 2014-Jan-29 \n                 \n                   Five hard truths for synthetic biology 2010-Jan-20 \n                 \n                   Cello \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19682", "url": "https://www.nature.com/articles/nature.2016.19682", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Four-decade analysis suggests that one-fifth of the world's population will be obese by 2025. TREND WATCH:  More of the global population is now obese than is underweight, according to an analysis of data from 186 countries. The study, published in  The Lancet  on 2 April 1 , compared data from 1975 to 2014 and provides the most complete picture of trends in adult body weight to date. It shows that many people are still underweight in the world\u2019s poorest regions, particularly in some regions of Asia and Africa. But obesity surpassed undernourishment globally, as the world\u2019s population\u00a0grew 1.5 kilograms heavier per person on average with each passing decade. Since 1975, the proportion of obese men has more than tripled and the proportion of obese women has more than doubled. Obese women outnumbered underweight women by 2004; for men, the changeover occurred in 2011. By 2025, the authors predict, roughly one-fifth of the population will be obese. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   High-fat diets raise risk of obesity in offspring 2016-Mar-14 \n                 \n                   The big fat truth 2013-May-22 \n                 \n                   Treat obesity as physiology, not physics 2012-Dec-12 \n                 \n                   Treat obesity as physiology, not physics 2012-Dec-12 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19695", "url": "https://www.nature.com/articles/nature.2016.19695", "year": 2016, "authors": [{"name": "Asher Mullard"}], "parsed_as_year": "2006_or_before", "body": "Analysts welcome focus on cancer drugs for poorest countries but caution that more work needs to be done. Public-health experts have applauded drug giant GlaxoSmithKline (GSK) for unveiling new patent policies that could make it easier for people in the world\u2019s poorest countries to access drugs. But they say that other companies will need to follow suit if patients are to see significant improvements in access to medicines \u2014 particularly for much-needed cancer drugs. After GSK's announcement last week, media attention focused on the London-based company's plan to stop filing for patents in 50 least developed and low-income countries (LDCs and LICs), such as Afghanistan and Zambia. That should make it easier for other manufacturers to supply generic versions of GSK\u2019s drugs in those countries without fear of litigation, but other pharmaceutical firms \u2014 including Merck KGaA and Roche \u2014 had previously announced similar moves. The announcement, made by GSK chief executive Andrew Witty, also revealed that for a further 35 lower-middle-income countries in which GSK will continue to file for patents, the company will grant licences to generics manufacturers who will then be able to make copycat drugs for domestic use and export. This, too, could encourage generics manufacturers to invest in providing cheaper medicines. Witty also said that the firm would consider submitting patents on future cancer drugs it develops to the United Nations-backed Medicines Patent Pool (MPP) \u2014 a particularly exciting possibility, say public-health experts. The MPP negotiates large-scale licensing agreements between drug developers and multiple generics manufacturers \u2014 enabling greater access to medicines for a larger group of up to 127 developing countries. But it has so far focused on HIV/AIDS drugs; companies had previously resisted calls to work with generics manufacturers to open up their cancer-drug cabinets to patients in the developing world. \u201cAny one of these things would have been a big deal by itself. When you put them all together, it\u2019s quite a strong statement,\u201d says James Love, director of the non-profit Knowledge Ecology International in Washington DC. \u201cBut a lot more still needs to be done.\u201d For instance, although Africa might benefit particularly from the changes, around 75% of the world\u2019s poor people live in \u2018middle income' countries that will not gain as much from the new measures. Poor people in countries such as China, India and Brazil won\u2019t benefit at all. GSK's announcement \"goes part of the way, but it is not nearly far enough,\u201d says Brook Baker, a legal expert at Northeastern University in Boston, Massachusetts. \n             Patently progressive \n           Industry has been improving its track record in enabling access to its drugs in developing countries \u2014 particularly when it comes to treatments for infectious and neglected tropical diseases. Several companies have signed licensing agreements with the MPP, allowing the non-profit organization to broker deals that have made cheap HIV drugs for millions of patients; last year, it expanded its mandate to include hepatitis C drugs. But the WHO estimates that cancer kills more than 5.3 million people in developing countries each year, making it deadlier than HIV/AIDS, tuberculosis and malaria combined. With GSK's suggestion that future patents on cancer drugs might be licensed via the MPP, \u201cWitty is clearly signalling that this is the way he thinks industry should go,\u201d says Ellen 't Hoen, director of medicines law and policy at the University Medical Center Groningen in the Netherlands. \u201cIt will be particularly important that other companies that have important cancer products join this move,\u201d she adds \u2014 but this may be a harder sell. Moreover, GSK sold all of its approved cancer drugs to Novartis last year, so it is only discussing opening up access to experimental cancer drugs that are years away from the market. \u201cThey are getting a lot of good publicity for what may be a fairly illusory benefit,\u201d cautions Baker. But Jayasree Iyer, executive director of the Access to Medicine Foundation, a non-profit organization in Haarlem, the Netherlands, which tracks pharmaceutical firms' efforts to improve access to medicine in developing countries, believes the move will prompt other companies with bigger cancer portfolios to open up. \u201cGlaxoSmithKline gets a \u2018well done\u2019,\u201d says Iyer, whose team is in the process of compiling a biennial report on the industry\u2019s efforts to open up access to medicines in the developing world. GSK has topped the ranking for the past four reports. \n             Improving infrastructure \n           Any progress on cancer drugs would bode well for improving access to expensive drugs for other noncommunicable diseases, such as anti-inflammatories for autoimmune conditions, Iyer says. When  Nature  asked Novartis for comment on whether it, too, might place cancer drugs into the patent pool, the company highlighted its alternative approach to increasing access to drugs. Last year, it launched a programme to enable access to 15 medicines for several non-communicable diseases (including breast cancer), for US$1 per treatment per month. The programme has started distributing drugs in Kenya and Ethiopia, a spokesperson says, and\u00a0plans to implement the programme in about 30 low- and lower-middle-income countries. Ultimately, people in poor countries will also need better access to screening programmes and medical centres if they are ever going to benefit from eventual increased access to drugs, adds 't\u00a0Hoen. \u201cGovernments need to step up their activity,\u201d she says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The GHIT fund shows its cards 2013-Nov-29 \n                 \n                   India spurns cancer patents 2013-Aug-13 \n                 \n                   Straight talk with...Ellen 't Hoen 2010-Dec-06 \n                 \n                   Drug patent plan gets mixed reviews 2009-Feb-23 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19672", "url": "https://www.nature.com/articles/nature.2016.19672", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}, {"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Human Brain Project asks wider neuroscience community to start using its hardware and software. Europe\u2019s major brain-research project has unveiled a set of prototype computing tools and called on the global neuroscience community to start using them. The move marks the end of the 30-month ramp-up phase of the Human Brain Project (HBP), and the start of its operational phase. The  release of the computing platforms  \u2014 which include brain-simulation tools, visualization software and a pair of remotely accessible supercomputers to study brain processes in real time \u2014 could help to allay concerns about the \u20ac1-billion (US$1.1-billion) project\u2019s benefits to the wider scientific community.\u00a0 \u201cThe new platforms open countless new possibilities to analyse the human brain,\u201d said Katrin Amunts, a neuroscientist at the J\u00fclich Research Centre in Germany and a member of the project\u2019s board of directors, at a press conference on 30 March. \u201cWe are proud to offer the global brain community a chance to participate.\u201d But it is not clear how the platforms \u2014 some freely accessible, others available only on the success of a peer-reviewed application \u2014 will resonate with brain researchers outside the project. \u201cAt this point, no one can say whether or not the research platforms will be a success,\u201d says Andreas Herz, chair of computational neuroscience at the Ludwig Maximilian University of Munich in Germany. \n               Brain simulation \n             The general mission of the HBP is to gather and combine neuroscience data of different types to reconstruct the human brain computationally at different scales, from the inside of brain cells to the entire functioning brain, and also to simulate it. Since the project launched in 2013, 800 scientists from 24 countries have been involved in developing tools to facilitate collaborative research for the general neuroscience community. The tools fall into in six areas: neuroinformatics, brain simulation, medical informatics, high-performance analytics and computing, neurorobotics and brain-inspired 'neuromorphic' computing. But the project has attracted  great controversy . Many in the greater neuroscience community complained that the management had exaggerated what the project's computing platforms would be able to do. In 2014, around 150 of them  signed a petition  claiming that the project was being mismanaged and running off its scientific course and pledged to boycott the HBP unless their concerns were addressed. (The petition has since accumulated more than 800 signatures). An  independent review completed in March 2015  confirmed these concerns and recommended management changes. It stressed that the computing infrastructure created by the HBP must be useful to the wider scientific community. The European Commission, which bankrolls much of the project, adopted the recommendations. \n               Data dream \n             The release of the neuroscience tools is a sign that the HBP\u2019s leadership accepts that the project needs to focus on providing concrete services from which the neuroscience community at large can profit, says Herz. But he cautions that the project still depends on \u201clogical flaws\u201d, such as \u201cthe dream\u201d that sparse recordings from neurons can generate dense data. Scientists will also need some time to learn to use the tools, says Karlheinz Meier, co-leader of the HBP\u2019s neuromorphic-computing platform, which is based in Manchester, UK, and Heidelberg, Germany. \u201cI trust that many useful applications will then start to emerge,\u201d he says. The platforms are to be developed with a view to eventually becoming a permanent, pan-European research infrastructure, said Philippe Gillet, head of project coordination for the HBP at the Swiss Federal Institute of Technology in Lausanne and a member of the project\u2019s board of directors, during the press conference. One example of such an infrastructure is the European Biobanking and Biomolecular Resources Research Infrastructure, a distributed network of centres that give researchers access to biological samples and corresponding data. However, for the HBP to reach this stage would require a commitment from governments to fund the project permanently. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Troubled billion-euro Brain Project unlocks more funding 2015-Nov-02 \n                   \n                     Rethinking the brain 2015-Mar-24 \n                   \n                     Mediators call for change to science of Human Brain Project 2015-Mar-09 \n                   \n                     Human Brain Project votes for leadership change 2015-Mar-04 \n                   \n                     Row hits flagship brain plan 2014-Jul-07 \n                   \n                     Brain fog 2014-Jul-07 \n                   \n                     Human Brain Project \n                   \n                     Human Brain Project Mediation Report \n                   Reprints and Permissions"},
{"file_id": "532013a", "url": "https://www.nature.com/articles/532013a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Rhetoric in US presidential campaign concerns researchers \u2014 particularly Muslims. Razi Nalim has lived in the United States for 30 years. An engineer at Indiana University\u2013Purdue University Indianapolis, he often travels around the world to recruit science and engineering students to his university. But last week, on the cusp of a recruitment trip to India, he hesitated when asked whether he would still encourage foreign, Muslim students to work or study in the United States. \u201cI would still say the opportunity for doing cutting-edge science here is unmatched,\u201d said Nalim, who is Muslim. \u201cWhere I think I would caution people to think more carefully is longer term: where would they want to live and raise a family? That\u2019s a harder question to answer.\u201d For Nalim and others, the roots of such concerns are apparent. In December, US presidential candidate Donald Trump, who has campaigned against immigration, boasted that he would ban Muslims from entering the country if elected. (On 30\u00a0March, Trump \u2014 now the Republican front runner \u2014 said that he would make exceptions for some Muslims, notably his wealthy Muslim friends.) Science advocates worry that Trump\u2019s broader anti-immigration stance could pose a threat to US research dominance. Roughly 5% of all students in the United States hail from other countries \u2014 including more than 380,000 people studying science, engineering, technology or mathematics. \u201cWe\u2019ve always been a nation which has welcomed scientific brainpower from other countries,\u201d says Mary Woolley, president of Research!America, a science-advocacy group in Alexandria, Virginia. \u201cWe don\u2019t want that to turn around now.\u201d Scientific issues have scarcely been mentioned on the campaign trail so far. Hillary Clinton, the Democratic front runner, has pledged to boost support for research into Alzheimer\u2019s disease, and has pushed back against Trump\u2019s anti-immigration and anti-Muslim stance. When she was a senator, Clinton backed health and research-related bills, and as first lady to former president Bill Clinton, she advocated for research on women\u2019s health. Trump is a wealthy real-estate mogul with no political legacy to mine for clues as to his scientific opinions. In the course of the campaign, he has linked autism to childhood vaccines, and dismissed climate change. (\u201cIt\u2019s called weather,\u201d he said.) In October, conservative radio host Michael Savage suggested on air that if elected, Trump should appoint him as head of the US National Institutes of Health (NIH). \u201cWell, you know you\u2019d get common sense if that were the case, that I can tell you,\u201d Trump replied, during the light-hearted conversation. \u201cBecause I hear so much about the NIH, and it\u2019s terrible.\u201d With little more than this to go on, advocates of science funding are worried. \u201cIt feels like there\u2019s a lot of cynicism toward science and scientists, and that\u2019s concerning,\u201d says Benjamin Corb, public-affairs director at the American Society for Biochemistry and Molecular Biology in Rockville, Maryland. Trump\u2019s position on immigration is clearer. He frequently boasts that if elected, he would build a wall along the border with Mexico \u2014 and force Mexico to pay for it \u2014 which has earned him both supporters and derision. A President Trump could bode ill for long-running efforts to boost the number of foreign professionals working in the United States on visas for highly skilled workers, known as H-1Bs. But Trump\u2019s statements regarding H-1B visas have been difficult to parse. At times, he has advocated bringing skilled workers into the country; at others, he has said that the H-1B programme is too often abused and should be restricted. Such statements worry Brad Hayes, a computer scientist at the Massachusetts Institute of Technology in Cambridge. Hayes is an US citizen, but says that some of his most outstanding colleagues are not. \u201cA lot of them want to end up here after they get their PhDs, but now that\u2019s in doubt,\u201d he says. \u201cWe absolutely want these people to stay. If they get lumped in with this \u2018close our borders, keep everybody out\u2019, we\u2019re doing ourselves a disservice.\u201d Hayes inadvertently cast a spotlight on the simplicity of Trump\u2019s rhetoric when he decided to use a neural network to model Trump\u2019s noticeably repetitive and simplistic speech patterns. He has been posting the results \u2014 computer-generated parody quotes based on Trump\u2019s campaign speeches \u2014 on Twitter using the handle @DeepDrumpf. (Trump\u2019s ancestral name, Drumpf, was changed by the family several generations ago.) \u201cWe\u2019re going to build the wall,\u201d says one tweet, in reference to Trump\u2019s Mexico plan. Hayes says that the project was only meant to be fun, but it ended up making a point. \u201cA lot of the rhetoric that\u2019s being used is fairly content-light.\u201d But that rhetoric is having an effect, says Ehab Abouheif, a developmental biologist at McGill University in Montreal, Canada, who is Muslim. On a recent trip to be interviewed for a position in the United States, recruiters\u2019 \u201cconstant question was, \u2018Are you really sure you would want to come?\u2019\u201d he says. \u201cMy scientist colleagues are really scared.\u201d To Abouheif, who fondly remembers completing his PhD and his postdoc in the United States, the current climate is surreal. \u201cIf you are trying to stop Muslims from coming in, it means that the ones who are there already are not going to feel comfortable either,\u201d he says. \u201cIt would be a shame to alienate this big swathe of society.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Nuclear summit a test for Obama's legacy 2016-Mar-30 \n                   \n                     The elephant in the room we can\u2019t ignore 2016-Mar-16 \n                   \n                     Obama makes risky bid to increase science spending 2016-Feb-10 \n                   \n                     Realistic risks 2015-Jul-29 \n                   \n                     Donald Trump: Immigration reform \n                   Reprints and Permissions"},
{"file_id": "532014a", "url": "https://www.nature.com/articles/532014a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Multiple teams finally have the material they need to repeat enigmatic experiment. It is the elephant in the room for dark-matter research: a claimed detection that is hard to believe, impossible to confirm and surprisingly difficult to explain away. Now, four instruments that will use the same type of detector as the collaboration behind the claim are in the works or poised to go online. Within three years, the experiments will be able to either confirm the existence of dark matter \u2014 or rule the claim out once and for all, say the physicists who work on them. \u201cThis will get resolved,\u201d says Frank Calaprice of Princeton University in New Jersey, who leads one of the efforts. The original claim comes from the DAMA collaboration, whose  detector sits in a laboratory deep under the Gran Sasso Massif , east of Rome. For more than a decade, it has reported overwhelming evidence 1  for dark matter, an invisible substance thought to bind galaxies together through its gravitational attraction. The first of the new detectors to go online, in South Korea, is due to start taking data in a few weeks. The others will follow over the next few years in Spain, Australia and, again, Gran Sasso. All will use sodium iodide crystals to detect dark matter, which no full-scale experiment apart from DAMA\u2019s has done previously. Scientists have substantial evidence that dark matter exists and is at least five times as abundant as ordinary matter. But its nature remains a mystery. The leading hypothesis is that at least some of its mass is composed of weakly interacting massive particles (WIMPs), which on Earth should occasionally bump into an atomic nucleus. DAMA\u2019s sodium iodide crystals should produce a flash of light if this happens in the detector. And although natural radioactivity also produces such flashes, DAMA\u2019s claim to have detected WIMPs, first made in 1998, rests on the fact that the number of flashes produced per day has varied with the seasons. This, they say, is exactly what is expected if the signal is produced by WIMPs that rain down on Earth as the Solar System moves through the Milky Way\u2019s dark-matter halo 2 . In this scenario, the number of particles crossing Earth should peak when the planet\u2019s orbital motion lines up with that of the Sun, in early June, and should hit a low when its motion works against the Sun\u2019s, in early December. There is one big problem. \u201cIf it\u2019s really dark matter, many other experiments should have seen it already,\u201d says Thomas Schwetz-Mangold, a theoretical physicist at the Karlsruhe Institute of Technology in Germany \u2014 and none has. But at the same time, all attempts to find weaknesses in the DAMA experiment, such as environmental effects that the researchers had not taken into account, have failed. \u201cThe modulation signal is there,\u201d says Kaixuan Ni at the University of California, San Diego, who works on a  dark-matter experiment called XENON1T . \u201cBut how to interpret that signal \u2014 whether it\u2019s from dark matter or something else \u2014 is not clear.\u201d No other full-scale experiment has used sodium iodide in its detector, although the Korea Invisible Mass Search (KIMS), in South Korea, used caesium iodide. So the possibility remains that dark matter interacts with sodium in a different way to other elements. \u201cNot until someone has turned on a detector made of the same material will you grow convinced that nothing is there,\u201d says Juan Collar at the University of Chicago, Illinois, who has worked on several dark-matter experiments. Many have found it challenging to grow sodium iodide crystals with the required purity. Contamination by potassium, which has a naturally occurring radioactive isotope, is a particular problem. But now three dark-matter-hunting teams \u2014 KIMS; DM-Ice, run from Yale University in New Haven, Connecticut; and ANAIS, at the University of Zaragoza, Spain \u2014 have each obtained crystals with about twice the level of background radioactivity of DAMA\u2019s. That is pure enough to test its results, they say. The KIMS and DM-Ice teams have built a sodium iodide detector together at Yangyang Underground Laboratory, 160\u00a0kilometres east of Seoul. This instrument uses an \u2018active veto\u2019 sensor that will enable it to separate the dark-matter signal from the noise better than DAMA does, says Yeongduk Kim, the director of South Korea\u2019s Center for Underground Physics in Daejeon, which manages KIMS. ANAIS is building a similar detector in the Canfranc Underground Laboratory in the Spanish Pyrenees. Together, KIMS/DM-Ice and ANAIS will have about 200\u00a0kilograms of sodium iodide, and they will pool their data. That is comparable to DAMA\u2019s 250\u00a0kilograms, enabling them to catch a similar number of WIMPs, they say. Even though the newer detectors will have higher levels of background noise, it should still be possible to either falsify or reproduce the very large DAMA signal, says Reina Maruyama of Yale, who leads DM-Ice. But Calaprice argues that high purity is more important than mass. He and his collaborators have developed a technique to lower contamination, and in January announced that they were the first to obtain crystals purer than DAMA\u2019s. He expects to reduce the background levels further, to one-tenth of DAMA\u2019s. The project, SABRE (Sodium-iodide with Active Background Rejection), will put one detector at Gran Sasso and the other at the Stawell Underground Physics Laboratory, which is being built in a gold mine in Victoria, Australia. SABRE will also use a sensor to pull out the dark-matter signal from noise, and will have a total mass of 50\u00a0kilograms. SABRE should complete its research and development stage in about a year, and will build its detectors soon after that, says Calaprice. It will then make its technology available to other labs \u2014 something that DAMA did not do. And having twin detectors in both the Northern and Southern hemispheres could clarify whether environmental effects could have mimicked dark matter\u2019s seasonality in DAMA\u2019s results \u2014 if the signal is from WIMPs, then both detectors should see peaks at the same time. DAMA will wait at least until 2017 to release its latest results, says spokesperson Rita Bernabei of the University of Rome Tor Vergata. She is not holding her breath about the upcoming sodium iodide detectors. \u201cOur results have already been verified in countless cross-checks in 14 annual cycles, so we have no reason to get excited about what others may do,\u201d she says. If other experiments do not see the annual modulation, she adds, her collaboration will conclude that they do not yet have sufficient sensitivity. Could the teams prove DAMA right? \u201cI was unwilling to believe the DAMA results or even take them seriously at first,\u201d says Katherine Freese, a theoretical astroparticle physicist at the University of Michigan in Ann Arbor, who with her collaborators first proposed the seasonal modulation technique used by DAMA 2 . But, as DAMA\u2019s data have accumulated, and no other explanation for their signal has arisen, Freese is now excited by the possibility that dark matter may have been discovered after all. The fact that many have tried and failed to repeat DAMA\u2019s experiment shows that it is not easy, says Elisabetta Barberio at the University of Melbourne, who leads the Australian arm of SABRE. \u201cThe more one looks into their experiment, the more one realizes that it is very well done.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Largest-ever dark-matter experiment poised to test popular theory 2015-Nov-12 \n                   \n                     Zombie physics: 6 baffling results that just won't die 2015-Oct-30 \n                   \n                     No sign of dark matter in underground experiment 2013-Oct-30 \n                   \n                     Gran Sasso: Chamber of physics 2012-May-23 \n                   \n                     Cosmology: The hunting of the dark 2011-Mar-23 \n                   \n                     DAMA \n                   \n                     XENON \n                   \n                     KIMS \n                   \n                     DM-Ice \n                   \n                     ANAIS \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19711", "url": "https://www.nature.com/articles/nature.2016.19711", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "But questions about the role of brain chemistry in depression may prevent the findings from spurring drug development. Prozac (fluoxetine) and similar antidepressants are among the most prescribed drugs in the United States, but scientists still don\u2019t know exactly how they work. Now one piece of that puzzle \u2014 the structure of a protein targeted by several widely used antidepressants \u2014 has been solved. The finding, reported on 6 April in  Nature 1 , could enable the development of better, more-targeted depression drugs. But it may come too late for drug companies, many of which have abandoned the search for depression treatments. Prozac and its kin \u2014 drugs called selective serotonin reuptake inhibitors (SSRIs) \u2014 were first discovered 2  in 1972. They address one hallmark of depression: low levels of the molecule serotonin, which neurons use to signal one another. By preventing a protein called serotonin transporter (SERT) form absorbing the serotonin back into neurons that release it, the drugs boost serotonin levels in the junctions between cells. But the details of this mechanism have long eluded researchers, who have sought to crystallize and visualize the SERT protein since the early 1990s. \u201cIt\u2019s tough to make, and once you make it, it tends to fall apart in your hands,\u201d says Eric Gouaux, a crystallographer at Oregon Health & Science University in Portland. Gouaux and his colleagues finally succeeded by creating small mutations in the SERT gene to make the protein more stable. For the first time, they were able to see the pocket in which two SSRIs \u2014 Paxil (paroxetine) and Lexapro (escitalopram) \u2014 bind. They also identified a second pocket, called an allosteric site. When escitalopram binds to both sites, the transporter protein and the drug bond more tightly, which increases the medicine's effect. \u201cIt\u2019s a beautiful piece of work,\u201d says Christopher Tate, a biochemist at the MRC Laboratory of Molecular Biology in Cambridge, UK. Understanding the structure, he says, could lead to the development of more-effective depression drugs with fewer side effects. \n             Rethinking depression \n           Over the past decade, most major pharmaceutical companies have ceased research into and development of new psychiatric drugs \u2014 a task that has proven to be complicated, expensive and fruitless. The vast majority of drugs approved to treat depression over the past few decades have been \u201cme-too\u201d drugs with similar structures and functions. The many SSRIs that followed Prozac are only one example of this. Kenneth Jacobson, a medicinal chemist at the National Institute of Diabetes and Digestive and Kidney Diseases in Bethesda, Maryland, hopes that the discovery of the SERT structure will revive interest. \u201cDrugs to treat behavioural disorders are still needed,\u201d he says. \u201cThis could possibly create a rebirth of the field.\u201d In the meantime, thinking about what actually causes mental illness has shifted. Researchers no longer believe that depression is solely caused by low levels of serotonin or other signalling molecules in the brain, says Richard Friedman, a psychiatrist at Weill Cornell Medical College in New York City. \u201cThey\u2019re really circuit-level disorders that involve problems with communication between different circuits in the brain,\u201d Friedman says. Rather, some types of depression involve abnormal serotonin levels in certain parts of the brain, he says, which may help to explain why SSRIs do not work for everyone. \n             The way forward \n           Yet Friedman and others still find the latest paper exciting. Gouaux says that his team and others are looking at naturally occurring mutations in SERT that may predispose some people to be more or less prone to depression. If the mutations result in different SERT protein structures, a person's DNA might predict whether SSRIs would work. Researchers are also working to crystallize the transporter proteins for two other neurotransmitters \u2014 dopamine and norepinephrine. Their DNA sequences are similar to that of SERT \u2014 \u201cthey\u2019re almost like a group of triplet humans,\u201d Gouaux says\u2014 but there are subtle differences in how the proteins bind molecules. Understanding these differences may elucidate the broader roles that various neurotransmitters have in mental illness and drug addiction. An paper published in April 3  from Jacobson\u2019s lab shows that the dopamine transporter (DAT) also has an allosteric site similar to that of SERT. Molecules such as cocaine bind to and block DAT, which increases dopamine levels outside the cell. Jacobson and his colleagues found a group of small molecules that can enhance this interaction by binding to the allosteric site. These findings could lead to better drugs for dopamine-deficiency problems, such as attention-deficit hyperactivity disorder. But in the meantime, researchers and patients are left waiting for other discoveries that might pin down the exact cause of depression. \u201cLook, I hope there\u2019s a miracle,\u201d says Steven Hyman, director of the Stanley Center for Psychiatric Research in Cambridge, Massachusetts. \u201cBarring that, what is really going to advance therapeutics are entirely new disease mechanisms.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Medical research: If depression were cancer 2014-Nov-12 \n                 \n                   Help luck along to find psychiatric medicines 2014-Nov-12 \n                 \n                   Depression genes show when the drugs won't work 2006-Oct-05 \n                 \n                   Antidepressants 'no better than placebo' \n                 Reprints and Permissions"},
{"file_id": "532017a", "url": "https://www.nature.com/articles/532017a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Airborne experiments aim to fill in the blanks of global water resources as the climate changes. When it comes to monitoring the world\u2019s frozen places, ice gets most of the love. Satellites such as CryoSat-2, run by the European Space Agency (ESA), measure minute changes in Earth\u2019s melting ice sheets. Now another group of cryo\u00adspheric scientists hopes to get in on the action \u2014 by monitoring not ice, but snow. Snow measurements are crucial for  understanding the world\u2019s water resources . But observations lag behind those of ice, mainly because remote sensing doesn\u2019t work consistently across all snowy environments. From mountains to prairies to tundra, the sheer variety of landscapes has frustrated efforts to produce high-resolution, worldwide maps. \u201cThe biggest hole in our knowledge of the global water budget is snow,\u201d says Jeffrey Deems, a research scientist at the US National Snow and Ice Data Center in Boulder, Colorado. \u201cWe really have no idea how much is out there.\u201d Last week, at a workshop in Seattle, Washington, Deems and his colleagues settled on a plan to change that, when they laid out details for a multiyear NASA field campaign scheduled to begin in September. The SnowEx experiment will fly aeroplanes carrying a combination of remote-sensing instruments \u2014 including radar, laser altimeters (lidar) and multispectral imagers \u2014 over snowy landscapes. The goal is to see which techniques work best for studying snow, and to combine those in a design for a snow-sensing satellite. Snow information is becoming more crucial as the climate changes, says Matthew Sturm, a snow scientist at the University of Alaska Fairbanks. More than 1.2 billion people worldwide rely on mountain snowpacks for water \u2014 but in many areas, snowfall may decrease in the future ( J.\u00a0S.\u00a0Mankin  et\u00a0al. Environ. Res. Lett.    10,  114016; 2015 ). In California, for example, the ongoing drought means that water managers are increasingly eager for any information about  how much runoff to expect , and when, throughout the summer. In Alaska, changing snow cover affects how fast permafrost thaws, destabilizing the landscape. And as  Arctic sea-ice cover shrinks , so too does  its protective snow cover , leading to feedback loops of increasing ice destruction. Current satellites have limited ability to track these changes. ESA\u2019s now-concluded GlobSnow project used satellite microwave data to map global \u2018snow water equivalent\u2019\u00a0\u2014 the crucial estimate of how much water is contained in the world\u2019s snowpacks, calculated by multiplying snow depth by density. But GlobSnow\u2019s maps, with pixels 25\u00a0kilometres on each side, are too low-resolution for precise estimates in individual watersheds. In the past few years, NASA and ESA have each rejected proposals for more-detailed snow-observing satellites. Both missions would have used radar to measure snow depth and calculate snow water equivalent, and both were doomed by doubts that researchers could reliably extract that information from the type of radar proposed. \u201cFor a long time we were on a quest for a single sensor,\u201d Sturm says. \u201cThe snow\u2019s just not that simple.\u201d Now the focus is shifting to testing multiple sensors simultaneously, to see which combination works best. The first SnowEx flights will carry lidar instruments and several types of radar (see \u2018Eyes on the snow\u2019) over the Sierra Nevada or Rocky Mountains in western North America. Each will measure snow cover by monitoring how lidar or radar pulses bounce off the ground and reflect back to the plane. The instruments will include new technologies that, when used together, may avoid the problems of the rejected satellite radar, says Edward Kim, lead scientist for SnowEx at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. One method is already becoming enormously popular in California and other parts of the western United States. For the past several years, NASA has flown a lidar-equipped plane called the Airborne Snow Observatory (ASO) over several western watersheds. The observatory measures the shape of the terrain in the summer, when there is no snow on the ground, and then returns throughout the winter to measure the changing depth of the snowpack. Project scientists can build up highly detailed maps \u2014 down to 1.5-metre resolution \u2014 of watersheds such as the Tuolumne River Basin, which supplies the city of San Francisco in California. Water managers use the resulting data to estimate how much runoff to expect in the spring. \u201cWe\u2019ve never had that across these mountain basins before,\u201d says Thomas Painter, who heads the ASO project at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. SnowEx will build on the ASO by testing extra instruments. \u201cThis is the number one priority,\u201d says Jessica Lundquist, a hydrologist at the University of Washington in Seattle. \u201cWe need to figure out how to measure snow right.\u201d\n \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     California snowpack lowest in past 500 years 2015-Sep-14 \n                   \n                     Snow survey hopes for avalanche of data 2012-Nov-13 \n                   \n                     Arctic snow cover shows sharp decline 2012-Oct-31 \n                   \n                     Rain kills reindeer 2003-Mar-10 \n                   \n                     NASA snow research \n                   \n                     International Snow Working Group Remote Sensing \n                   \n                     GlobSnow \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19713", "url": "https://www.nature.com/articles/nature.2016.19713", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "A simple, non-judgemental chat can lessen prejudice towards transgender people. In 46 years of canvassing neighbourhoods, going door-to-door in hopes of persuading voters to cast their ballots in a particular direction, David Fleischer has learned a few lessons. Some of them are counterintuitive. When a voter uses a hurtful slur during the conversation, it can be a sign of a breakthrough, he says. \u201cThat\u2019s a good thing,\u201d says Fleischer, who often canvasses to bolster support for the equal rights of  lesbian, gay, bisexual and transgender (LGBT) people . \u201cThey\u2019re being honest. And that means we\u2019re on the brink of having a wonderful, wonderful conversation.\u201d Fleischer is the director of the Leadership LAB project at the Los Angeles LGBT Center in California, where he teaches an unconventional approach that favours leisurely, non-judgemental conversations over hasty elevator pitches. And according to a study published 1  in  Science  on 7 April, that approach works: canvassers employing the method significantly reduced prejudice against transgender people in around 10% of a sample of roughly 250 individuals. The effect lasted for at least three months after the conversation with canvassers. The study, by political scientists David Broockman at Stanford University in California and Joshua Kalla of the University of California, Berkeley, opens the door to a new generation of rigorously designed field experiments to study prejudice, says Elizabeth Levy Paluck, a social psychologist at at Princeton University in New Jersey. \u201cMethodologically it\u2019s the gold standard,\u201d she says. \u201cAnd the bonus is that it has really encouraging results for tolerance and for the rights of transgender people.\u201d It may also help to remove some of  the stigma that has haunted political science  after accusations of misconduct and fabricated data led to the retraction of a similar study, published in  Science  in 2014 2 . The study claimed that canvassing changed attitudes towards gay marriage, an effect that purportedly lasted nine months. But when Broockman and Kalla, who were not involved in the 2014 study, set about to extend the work to transgender prejudice, they found  inconsistencies in its data and execution . That paper was retracted on 5 June 2015 at the behest of the study's second author, political scientist Donald Green of Columbia University in New York City. The study's first author, Michael LaCour \u2014 then a graduate student at the University of California in Los Angeles \u2014 stood by his results but did admit to misrepresenting some aspects of the work. \n             Hard knocks \n           It was a painful episode for those who were advocating the use of field trials in the social sciences, says political scientist Brian Calfano of Missouri State University in Springfield. Such studies are not the norm: Green and Paluck have sifted through hundreds of published and unpublished studies conducted prior to 2009, and found that only 11% of them tested the effect of a prejudice-reducing intervention in the field, rather than in a laboratory. When LaCour\u2019s paper came out, some social scientists were incredulous of his results \u2014 both because of the approach he took and because the findings ran counter to conventional wisdom. \u201cThere had been a lot of resistance to the idea that people can be persuaded on these controversial issues,\u201d says Calfano. \u201cThere was a \u2018too good to be true\u2019 reaction.\u201d The misconduct revelation, he says, only added to the pessimism. But the latest transphobia study could signal a reversal. Broockman and Kalla followed the efforts of 56 canvassers as they went door-to-door in Miami-Dade County, Florida. The canvassers talked to 255 voters about transgender equality, and to another 246 voters about recycling, as a control group. About one in ten voters that were canvassed about transgender discrimination became less prejudiced, according to responses to follow-up surveys up to three months after the canvassers made contact. Broockman says the magnitude of the change approximates the degree of improvement from 1998 to 2012 in the average opinion of an American towards gay and lesbian people. Broockman hopes to continue to check in on the study participants to find out how long their responses will last. But there are signs that the change in attitude was resilient, at least in the short-term: six weeks after the intervention, the researchers showed participants television advertisements that portrayed anti-transgender stereotypes. Follow-up surveys showed that the ads had no lasting effect on their opinions. \n             Opening doors \n           Broockman plans to extend his work to other issues, such as attitudes about climate change. Palluck, who uses field experiments to study everything from post-conflict resolution in Rwanda to bullying in school, says that Broockman\u2019s designs could be used to test whether attitudes towards undocumented immigrants could be changed. For Calfano, the big question is whether the technique could address deeply ingrained racial biases. \u201cYou\u2019re going to see a lot more of these studies going forward,\u201d he says. But the approach may have its limits. On 7 April, Broockman also released negative results from a study of attempts to change opinions in the United States about abortion 3 . For Fleischer, that need not bode ill for canvassing on other topics. It took him seven years to work out the right approach to talk to people about LGBT issues, he says, and he has less experience addressing attitudes toward abortion. It may take time to fine-tune the approach for other sensitive subjects. Meanwhile, the transphobia study offers hope that doing so could be worth the effort. \u201cWe don\u2019t know the full potential of these results yet,\u201d he says. \u201cBut they suggest we really could, if we want, live in a less prejudiced society.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Excluded, intimidated and harassed: LGBT physicists face discrimination 2016-Mar-22 \n                 \n                   Political science\u2019s problem with research ethics 2015-Jun-29 \n                 \n                   Retracted gay-marriage study debated at misconduct meet-up 2015-Jun-02 \n                 \n                   Diversity: Pride in science 2014-Sep-16 \n                 \n                   Nature blogpost: Clinical trials 'are excluding gay people' \n                 \n                   David Broockman \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19712", "url": "https://www.nature.com/articles/nature.2016.19712", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Virus can quickly develop mutations that resist attack by DNA-shearing enzymes. HIV can defeat efforts to cripple it with CRISPR gene-editing technology, researchers say. And the very act of editing \u2014 involving snipping at the virus\u2019s genome \u2014 may introduce mutations that help it to resist attack. At least half a dozen papers over the past three years have explored using the popular CRISPR\u2013Cas9 gene editing technique to combat HIV, but the latest finding, described in a study published on 7 April in  Cell Reports 1 , adds to questions about the feasibility of the approach. However, the researchers involved say that the discovery is a minor setback that does not preclude the idea altogether. Some researchers aim to edit genes made by the immune cells that HIV usually infects \u2014 called T helper cells \u2014 so that the virus cannot find a way in. Others take a different tack: equipping the T cells with gene-editing tools so that they can seek and destroy any HIV that infects them. This approach seemed simple and efficient in tissue culture, says Bryan Cullen, a virologist at Duke University in Durham, North Carolina, who has been using CRISPR to target viruses including HIV but was not involved in the latest study. When HIV infects a T cell, its genome is inserted into the cell\u2019s DNA and hijacks its DNA-replicating machinery to churn out more copies of the virus. But a T cell equipped with a DNA-shearing enzyme called Cas9, together with customized pieces of RNA that guide the enzyme to a particular sequence in the HIV genome, could find, cut and cripple the invader\u2019s genome. \n             Escape from attack \n           This seemed to work when a team led by virologist Chen Liang, at McGill University in Montreal, Canada, infected T cells that had been given the tools to incapacitate HIV. But two weeks later, Liang\u2019s group saw that the T cells were pumping out copies of virus particles that had escaped the CRISPR attack. DNA sequencing revealed that the virus had developed mutations very near the sequence that CRISPR\u2019s Cas9 enzyme had been programmed to cut. To some extent, this was not a surprise: HIV has already shown the ability to evolve resistance to all manner of antiviral drugs (as well as the human immune system). This happens because its genetic material is copied by enzymes that are prone to error. Most mistakes stop the virus working, but occasionally a mutation is beneficial for HIV, allowing it to evade attack. But Liang thinks that mutations caused by copying errors do not explain HIV\u2019s triumph over CRISPR. Instead, his team contends that the mutations, which involved the insertion or deletion of a few DNA letters, occurred when Cas9 cut the viral DNA. When DNA is cut, its host cell tries to repair the break; in doing so, it sometimes introduces or deletes DNA letters. These \u2018indels\u2019 usually inactivate the gene that was cut \u2014 which is how CRISPR works. But sometimes this doesn\u2019t happen. Occasionally, Liang thinks, some of the indels made by the T cell\u2019s machinery leave the genome of the invading HIV able to replicate and infect other cells. And worse, the change in sequence means the virus can't be recognized and targeted by T cells with the same machinery \u2014 effectively making it resistant to future attack. \u201cWe were a bit excited when we found this,\u201d Liang says. \n             Surmountable problem \n           A team led by molecular biologist Atze Das at the University of Amsterdam reported similar results in  Molecular Therapy  in February  2 . Das says he is not surprised that HIV can overcome CRISPR: \u201cWhat is surprising is the speed \u2014- how fast it goes.\u201d Both he and Liang think that the problem can be surmounted, for instance by inactivating several essential HIV genes at once, or by using CRISPR in combination with HIV-attacking drugs. Gene-editing therapies that make T cells resistant to HIV invasion (by altering human, not viral, genes) would also be harder for the virus to overcome. A clinical trial is under way to  test this approach using another gene-editing tool, zinc-finger nucleases . Cullen agrees that the resistance does not mean that there will never be a CRISPR-based treatment or cure for HIV. But he questions whether a therapy using CRISPR \u2014 which would require genetically modifying a substantial number of a patients\u2019 T cells \u2014 is suited for tackling the virus; especially since it is increasingly possible to manage most HIV infections with cocktails of antiretroviral drugs. \u201cTo me, it\u2019s pie in the sky,\u201d he says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                 \n                   Gene-editing method tackles HIV in first clinical test 2014-Mar-05 \n                 \n                   Hopes of HIV cure in 'Boston patients' dashed 2013-Dec-06 \n                 \n                   Stem-cell transplants may purge HIV 2013-Jul-03 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19720", "url": "https://www.nature.com/articles/nature.2016.19720", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA engineers work to recover the telescope on the eve of a new type of planet search. \n             Update (11 April): The Kepler spacecraft has been recovered from its emergency state, NASA announced today. Engineers expect to spend the rest of the week  \n             assessing the health \n              of the spacecraft before commanding it to begin the microlensing planet search. \n           NASA\u2019s Kepler space telescope has unexpectedly gone into an emergency operations mode, halting the start of a much-anticipated phase of its planet hunt. Engineers are working to try to get the probe working normally. Kepler apparently entered the mode on 6 April, according to  an 8 April update  from Charlie Sobeck, the mission manager at NASA\u2019s Ames Research Center in Moffett Field, California. In emergency mode, Kepler burns more of its dwindling supply of fuel, which is needed to ignite its thrusters and orient the spacecraft to communicate with Earth. The spacecraft had not yet executed the turning manoeuvre that would have started the new planet hunt. Until now, Kepler has discovered planets by watching for the slight dimming of starlight caused by an orbiting planet passing in front of a star. The probe has been  wildly successful at this task , finding more than 1,040 confirmed planets and more than 4,700 planet candidates since its 2009 launch. The new campaign was to have run from 7 April to 1 July. It would have looked for the temporary brightening of stars caused by a different effect, known as gravitational microlensing. In microlensing, the gravity of an intervening object \u2014 such as a planet \u2014 focuses and intensifies the light from a background star, causing it to brighten. Unlike Kepler\u2019s other discoveries, which tend to be smaller planets relatively close to their host stars, microlensing targets big planets at large distances from their stars, or even  lonely planets wandering on their own  through the depths of space. Ground-based telescopes have discovered 46 planets through microlensing, and astronomers were hoping that Kepler would uncover 10 or more during its campaign. (The space telescope would have upped its chances by turning to look at the star-spangled heart of the Milky Way.) Such discoveries could help to narrow the statistics on how common free-floating planets might be throughout the Galaxy. \n             Ground game \n           Astronomers have coordinated an elaborate plan in which some two dozen ground-based telescopes, spread across six continents, would gaze at the same part of the sky at the same time as Kepler. They include the Optical Gravitational Lensing Experiment (OGLE) survey, which hunts for microlensing events from the Las Campanas Observatory in Chile. OGLE was to have shifted its observing strategy slightly in order to overlap with the same fields that Kepler was looking at. In late June, NASA\u2019s Spitzer Space Telescope was to have joined the hunt as well. It would have been the first microlensing survey conducted simultaneously from the ground and from space. Those different vantage points would have allowed astronomers to study potential microlensing planets more easily than using just one or two ground-based telescopes. \u201cThere's a strong feeling like it's Christmas morning; we were all set to unwrap a shiny new toy, and then we had to put everything on hold due to a power outage or something,\u201d says Andrew Cole, an astronomer at the University of Tasmania in Hobart, Australia. His team had planned to use a 1.3-metre telescope in Tasmania to follow up on microlensing alerts from Kepler. For now, the start of Kepler's microlensing campaign is on hold until engineers can get the telescope working again. It is currently about 120 million kilometres from Earth, meaning each message takes 13 minutes to get to Kepler and back. Days lost from the microlensing campaign cannot be made up later. On 2 July, the day after the observations were due to end, Kepler will no longer be in the proper orbital position, relative to the Sun, to be able to hunt for microlensing planets. Paul Hertz, NASA\u2019s director of astrophysics, has touted the Kepler microlensing survey as a step towards the agency\u2019s next big space telescope, the Wide-Field Infrared Survey Telescope, which is meant to do microlensing searches after it launches in the 2020s. The latest glitch is not Kepler\u2019s first problem. Issues with its reaction wheels, which allow the spacecraft to orient itself, caused the main mission to end in May 2013 after four years of observing. It has been operating since then in a more limited 'K2' mode, which uses pressure from sunlight to compensate for the loss of the reaction wheels. Even that, however, has yielded  a bonanza of exoplanets. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Rebooted Kepler spacecraft hauls in the planets 2016-Jan-07 \n                 \n                   The exoplanet files 2015-Nov-18 \n                 \n                   Sun\u2019s stroke keeps Kepler online 2014-Oct-21 \n                 \n                   NASA ponders Kepler\u2019s future 2013-Sep-04 \n                 \n                   So many lonely planets with no star to guide them 2011-May-18 \n                 \n                   Kepler & K2 science center \n                 \n                   OGLE microlensing survey \n                 Reprints and Permissions"},
{"file_id": "532018a", "url": "https://www.nature.com/articles/532018a", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Nations debate how to protect biodiversity in the high seas. They might host habitats of huge ecological importance, but two-thirds of the world\u2019s oceans lie beyond the authority of national governments. On 28\u00a0March, members of the United Nations began negotiating the first global treaty to impose conservation and sustainability on the high seas. As well as vastly increasing the areas that could be set aside to protect endangered species, a legally binding treaty could usher in laws on the use of marine organisms in the search for drugs and cosmetics. \u201cThis is something that could change the future of how we manage our oceans,\u201d says Elizabeth Wilson, director of international ocean policy at the Pew Charitable Trusts in Washington DC, which has advocated for such a treaty. Currently, nations can claim waters up to 200\u00a0nautical miles (370 kilometres) from their shorelines as \u2018exclusive economic zones\u2019; everything beyond these is designated the high seas (see \u2018Sea change\u2019). There are treaties that govern specific high-seas activities, such as mining the sea bed for minerals or laying cables, and agreements that regulate some kinds of fishing in various areas. But there is no comprehensive set of regulations on biodiversity and conservation. The ongoing treaty discussions, which are at the UN headquarters in New York, are the first talks of a preparatory committee, known as  Prep Com  \u2014 and the result of years of wrangling between member nations. If they, and three more meetings before the end of 2017, are successful, a text could be voted on by UN members as soon as 2018, Wilson says. One goal of the UN negotiations is a mechanism for the creation of marine protected areas (MPAs) on the high seas. As part of the UN Convention on Biological Diversity, most governments are now committed to designating at least 10% of the oceans as protected areas by 2020 \u2014 currently, around 2% lies in MPAs. But legally, they can create MPAs only in their own waters, so some of the most ecologically important areas remain out of reach. Moreover, in a study published last month, marine scientists Callum Roberts, Bethan O\u2019Leary and their colleagues at the University of York, UK, conclude that the 10% target is much too low. On the basis of a review of 144\u00a0studies that assessed the adequacy of the UN target, they estimate that more than 30% of the ocean must be protected to achieve goals such as protecting biodiversity and minimizing the risk that fish populations will collapse ( B.\u00a0C.\u00a0O\u2019Learyetal.Conserv.Lett.http://doi.org/bdxw;2016 ). But it would be near impossible to set aside this much-larger portion without being able to create MPAs in the high seas, notes Roberts. \u201cThese negotiations over the next two years are going to be vitally important,\u201d he says. \n               Broad approach \n             Others say that MPAs aren\u2019t necessarily the best way to protect the oceans, because they can lead to problems such as overfishing in non-protected areas. Rather than setting aside large areas for protection, a better approach would be to manage activities properly across the ocean, says oceanographer James Cowan at Louisiana State University in Baton Rouge. Another issue being discussed during the negotiations is how to govern the search for genetic resources \u2014 plants and animals that could yield products such as drugs or cosmetics. Bioprospecting is on the rise in the oceans, particularly in the high seas, says Glen Wright, a marine-policy researcher at the Institute for Sustainable Development and International Relations in Paris. The G77 group of developing nations argues that genetic resources from the high seas are part of the \u2018common heritage of mankind\u2019, so any profits from them should be shared among all nations. Other groups, including the European Union would rather avoid such a formal status, says Wright, and focus instead on a practical mechanism for sharing the benefits. But at this stage, say Wright and Wilson, it is unclear what rules might be brought in, and what mechanisms might be used to enforce them. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Green List promotes best conservation areas 2014-Nov-14 \n                   \n                     Conservation: A to-do list for the world's parks 2014-Nov-05 \n                   \n                     Marine reserves planned around commercial interests 2014-Feb-28 \n                   \n                     Marine protection goes large 2011-May-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19718", "url": "https://www.nature.com/articles/nature.2016.19718", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Study used CRISPR technology to introduce HIV-resistance mutation into embryos. Researchers in China have reported editing the genes of human embryos to try to make them resistant to HIV infection. Their paper 1  \u2014 which used CRISPR-editing tools in non-viable embryos that were destroyed after three days \u2014 is only the second published claim of gene editing in human embryos. In April 2015, a different China-based team announced that  they had modified a gene linked to a blood disease in human embryos  (which were also not viable, and so could not have resulted in a live birth) 2 . That report \u2014 a world first \u2014 fuelled global deliberations over the  ethics of modifying embryos  and human reproductive cells, and led to calls for a moratorium on even such proof-of-principle research. At the time, rumours swirled that other teams had conducted similar experiments. Sources in China told  Nature \u2019s news team that a handful of papers had been submitted for publication. The latest paper, which appeared in the  Journal of Assisted Reproduction and Genetics  on 6 April, might be one of these.  Nature \u2019s news team has asked the paper\u2019s corresponding author, stem-cell scientist Yong Fan, for comment, but had not heard from him by the time of this report. \n             HIV resistance \n           In the paper, Fan, who works at Guangzhou Medical University in China, and his team say that they collected a total of 213 fertilized human eggs between April and September 2014. The fertilized eggs, donated by 87 patients, were unsuitable for implantation as part of  in vitro  fertility therapy, because they contained an extra set of chromosomes. Fan\u2019s team used CRISPR\u2013Cas9 genome editing to introduce into some of the embryos a mutation that cripples an immune-cell gene called  CCR5 . Some humans naturally carry this mutation (known as  CCR5 \u039432) and they are resistant to HIV, because the mutation alters the CCR5 protein in a way that prevents the virus from entering the T cells it tries to infect. Genetic analysis showed that 4 of 26 human embryos targeted were successfully modified. But not all the embryos\u2019 chromosomes harboured the  CCR5 \u039432 mutation \u2014 some contained unmodified  CCR5 , whereas others had acquired different mutations. George Daley, a stem-cell biologist at Children\u2019s Hospital Boston in Massachusetts, says that the paper\u2019s main advance is the use of CRISPR to introduce a precise genetic modification successfully. \u201cThis paper doesn\u2019t look like it offers much more than anecdotal evidence that it works in human embryos, which we already knew,\u201d he says. \u201cIt\u2019s certainly a long way from realizing the intended potential\u201d \u2014 a human embryo with all its copies of  CCR5  inactivated. \u201cIt just emphasizes that there are still a lot of technical difficulties to doing precision editing in human embryo cells,\u201d says Xiao-Jiang Li, a neuroscientist at Emory University in Atlanta, Georgia. He thinks that researchers should work out these kinks in non-human primates, for example, before continuing to modify the genomes of human embryos using techniques such as CRISPR. \n             Ethics of experiments \n           Tetsuya Ishii, a bioethicist at Hokkaido University in Sapporo, Japan, sees no problem with how the experiments were conducted \u2014 a local ethics committee approved them, and the egg donors gave their informed consent \u2014 but he questions their necessity. \u201cIntroducing  CCR5 \u039432 and trying repair, even in\u00a0non-viable embryos, is just playing with human\u00a0embryos,\u201d Ishii says. Fan's team writes in the paper that proof-of-principle experiments for human-embryo editing such as theirs are important to conduct while the ethical and legal issues of germline modification are being hashed out. \u201cWe believe that any attempt to generate genetically modified humans through the modification of early embryos needs to be strictly prohibited until we can resolve both ethical and scientific issues,\u201d they write. Daley sees a stark contrast between Fan\u2019s work and  research approved in February by UK fertility regulators  that will allow CRISPR genome editing of human embryos. Those experiments, led by developmental biologist Kathy Niakan at the Francis Crick Institute in London, will inactivate genes involved in very early embryo development, in hopes of understanding why some pregnancies terminate. (The work will be done in viable embryos, but the researchers' licence requires that experiments be stopped within 14 days.) Earlier this year, developmental biologist Robin Lovell-Badge, also at the Francis Crick Institute, told  Nature  that he thought that the carefully considered UK approval might embolden other researchers who are interested in pursuing embryo-editing research. \u201cIf they've been doing it in China, we may see several manuscripts begin to appear,\u201d he said. Whereas Niakan's work is answering questions intrinsic to embryology, Fan's work is establishing proof of principle for what would need to be done to generate an individual with resistance to HIV, Daley adds. \u201cThat means the science is going forward before there\u2019s been the general consensus after deliberation that such an approach is medically warranted,\" he says. Additional reporting by David Cyranoski \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                 \n                   Where in the world could the first CRISPR baby be born? 2015-Oct-13 \n                 \n                   UK scientists apply for licence to edit genes in human embryos 2015-Sep-18 \n                 \n                   Chinese scientists genetically modify human embryos 2015-Apr-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19714", "url": "https://www.nature.com/articles/nature.2016.19714", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "A British scientist successfully appealed against an unfavourable grant review \u2014 but the road to victory can be paved with challenges. Faced with a rejected grant application, scientists experience a range of emotions \u2014 shock, sadness, anger \u2014 before usually accepting the verdict and moving on. But when\u00a0the European Commission rejected a \u20ac5-million (US$5.7-million) grant application from computational scientist Peter Coveney, he hired a lawyer and challenged the decision. The successful appeal, made public on 29 March, highlights an aspect of the research-funding process that scientists rarely act on and almost never succeed at. \u201cI\u2019ve been told by colleagues that you don\u2019t challenge the commission on anything,\u201d says Coveney, of University College London (UCL). \u201cBut if your research is in jeopardy as a part of poor decisions, then people should be prepared to challenge them.\u201d Coveney believes that his rare victory should encourage more researchers to appeal decisions made by funders. But funding-agency administrators warn that the chances of success are low \u2014 and that fruitless appeals can waste time and resources. \u201cIf you\u2019re going to play the odds here, your chance of getting funded is substantially higher if you submit a revised proposal than if you go down the route of submitting an appeal,\u201d says Michael Lauer, director of the Office of Extramural Research at the US National Institutes of Health (NIH), the world\u2019s largest biomedical funder. Appeals are uncommon in both Europe and the United States. Between 2007 and 2013, the European Commission's Framework Programme 7 received more than 106,000 grant applications, but although\u00a0around 80%\u00a0were rejected, only\u00a03,683 decisions were appealed. Of these, 101 were re-evaluated and fewer than 10 succeeded in gaining funding. The\u00a0US National Science Foundation, meanwhile, received just 388 appeals between 2001 and 2014, 17 of which led to funding. Appeals at the NIH are similarly rare, says Lauer. Although the agency does not track them centrally, in eight years of overseeing cardiology-research grants, he saw just one successful challenge. \n               Surprise decision \n             When the European Commission rejected the Coveney team\u2019s proposal to create a hub for applying computer modelling to biomedical and clinical data in May 2015, he was surprised. The 3-year project would involve 15 industrial and academic partners across Europe and employ a consulting firm as project manager. Those elements fitted with a requirement for professional management, says Coveney, as outlined in the commission\u2019s funding call (part of a  7-year \u20ac78.6-billion programme called Horizon 2020 ). But he says that the reviews indicated that the team had brought in unnecessary partners by including the consulting firm, resulting in a poor score on that aspect. Like some other funders, including the NIH, the commission has a formal \u2018redress\u2019 process that allows spurned scientists to ask for their grant applications to be re-reviewed. UCL advised Coveney that the odds of success were low. But he hired a law firm, Bindmans in London, to mount a challenge; his team spent around \u00a310,000 (US$14,000) in legal fees. He learned that his grant would be reconsidered in October 2015, and later that it had scored well enough on this subsequent review to be funded in February this year. He got official word of its approval last month. A representative of the commission confirmed that the grant\u2019s initial evaluation report contained incorrect information, leading to a new evaluation. \u201cIt is the only time I\u2019ve challenged a grant decision so far in my life. I\u2019ve seen a few dubious things happen in the past, but this one was so black and white,\u201d says Coveney. \u201cIt should send the message to people that they should think carefully and not just assume it\u2019s not worth it.\u201d Not everyone agrees. \u201cLawyering up to get money is not something that strikes me as the way I\u2019d do it,\u201d says Adrian Liston, an immunologist at the University of Leuven in Belgium. \"I\u2019d just take the grant to another agency.\" Some researchers see Coveney\u2019s victory as an exception that proves the rule \u2014 science\u2019s version of \u201cYou can\u2019t fight city hall\u201d. Liston's own attempt to appeal a funding decision last year was foiled by a Kafkaesque process. When a funder he declined to name denied a fellowship renewal for a postdoc in his lab, Liston was told that he first needed to request the reviews. They arrived two months later, and were positive. But the funder then told him that appeals had to be filed within a month of a rejection. \u201cIt\u2019s an appeals process on paper, but they make it so it can\u2019t ever be used,\u201d he says. \n               Differing opinions \n             A lack of expertise on the review panel is one of the few grounds on which the NIH says that it will grant an appeal, in addition to factual errors, bias or conflicts of interest on the part of reviewers. But Lauer says that such complaints often boil down to differences of opinion, which can\u2019t be appealed. Researchers are personally invested in their grant proposals, making rejection that much harder to handle, says Sally Rockey, Lauer\u2019s predecessor at the NIH, who is now executive director of the Foundation for Food and Agriculture Research in Washington DC. \u201cPeople have a tough time separating their emotions from the actual review itself.\u201d There may now be more motivation than ever to appeal grant rejections because the success rates of grant applications are in decline at many funding agencies, notes Bj\u00f6rn Brembs, a neurobiologist at the University of Regensburg in Germany who still bemoans the denial of a grant extension he requested in 2003. \u201cAt a certain threshold of desperation and lack of alternatives, then an appeal doesn\u2019t seem as much of a cost anymore,\u201d he says.\u00a0 Appeals could waste the time of overworked agencies already faced with far too many strong applications to fund, warns Douglas Kell, a biologist at the University of Manchester, UK, and former head of the Biotechnology and Biological Sciences Research Council, which, like the DFG and the UK\u2019s other government funders, does not have a formal appeals process. \u201cThere are lots of things I would say we could do to improve funding procedures,\u201d says Kell. \u201cBut letting people bitch about the ones that go down isn\u2019t one of them.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Racial bias continues to haunt NIH grants 2015-Nov-17 \n                   \n                     Grant application rejected over choice of font 2015-Oct-29 \n                   \n                     US astronomers stuck in grant-rejection cycle 2015-Oct-23 \n                   \n                     High-scoring grant applications yield more highly cited papers 2015-Apr-23 \n                   \n                     Biochemist questions peer review at UK funding agency 2015-Jan-06 \n                   \n                     Fixing a grant system in crisis 2010-Mar-24 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19590", "url": "https://www.nature.com/articles/nature.2016.19590", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Oceanography, brain science and stem cells among research fields that look set to grow. From a slowing economy to geopolitical tensions in the South China Sea, it is a testing time for China\u2019s ruling Communist party. But its science aspirations seem unbridled. On 16 March, China approved its 13th Five-Year Plan. A draft version, as well as statements by key politicians, make it clear that innovation through science and technology is a priority. China also intends for its research expenditure to rise to 2.5% of gross domestic product by 2020, from less than 2.2% over the past five years. Reductions in energy use and the development of low-carbon energy sources feature in the latest five-year plan. For some of the other themes that are set to shape Chinese research over the next five years,  Nature  spoke to a range of scientists. \n               The ocean deep \n             In 2012, \u2018oceanauts\u2019 aboard the research submersible  Jiaolong   descended more than 7,000 metres beneath the waves , marking China\u2019s entry into an elite club of nations capable of reaching the hadal zone \u2014 the deepest part of the ocean, which begins at 6,000 metres below sea level. Over the next five years, Chinese scientists will build one crewed and one uncrewed submersible, according to a plan released by the science ministry in February, each of which can reach depths of 11,000 metres \u2014 the very bottom of the hadal zone. \"For deep-sea technology, this five years will be a golden period,\u201d says Cui Weicheng of the Hadal Science and Technology Research Center at Shanghai Ocean University. The uncrewed vessel will be similar to Nereus, the advanced US submersible that  imploded in 2014  and  will not be replaced . The crewed vessel will hold at least two people,  more than the  Deepsea Challenger  , which  took film director James Cameron on a solo dive to the deepest point of the Mariana Trench in 2012 . The hadal zone is one of the most poorly studied habitats on Earth, and is home to mysterious tube worms, sea cucumbers and jellyfish. Researchers are also interested in its role in the carbon cycle, because the microbes there digest a surprising amount of organic matter. Chinese scientists hope to use both submersibles to explore the zone in more detail than ever before. Independently of the latest five-year plan, Cui has also developed a 'movable laboratory' ( W. Cui\u00a0 et al.\u00a0Meth. Oceanogr. \u00a0 10, \u00a0178\u2013193; 2014 ) composed of three landers, a robotic submersible and a crewed vehicle.The robotic submersible and first lander were tested down to 4,000 metres last October. A mother ship that controls the robot and landers is due to be launched on 24 March, and the first scientific expedition is planned for August, in the New Britain Trench off Papua New Guinea. Together these projects \u201ccould help shorten the gap\" between Chinese ocean science and technology and the most advanced capabilities elsewhere, says Cui. \n               China brain project \n             The  United States ,  Europe  and  Japan  have each announced their own massive projects to map the brain, and China has had one in the works for several years. The latest five-year plan calls for brain science to be a priority \u2014 and most of the resources are expected to be channelled through the China project, which is due to be officially announced shortly, say Chinese researchers. The brain project is expected to focus on brain disease, in particular through studying animal models, as well as artificial intelligence. Scientists in China acknowledge that they are far behind the rest of the world in terms of top-level talent in brain science, but several factors could enable them to catch up. China\u2019s neuroscience community is growing \u2014 the Chinese Neuroscience Society now has 6,000 members, compared to just 1,500 ten years ago; the country has tens of millions of patients with psychiatric or degenerative brain disease that will facilitate clinical studies; and it has hundreds of thousands of research monkeys. This last factor has already allowed Chinese researchers to  take the lead in using gene-editing technologies to produce models of autism  and other conditions. The bounty of research animals is also starting to draw interest from abroad \u2014 a new primate research centre in Shenzhen is being jointly established with the Cambridge-based Massachusetts Institute of Technology. \n               Conservation corridors \n             With actor Jackie Chan and basketball star Yao Ming involved in campaigns attacking the trade in protected animals such as bears, which are milked for their bile, and elephants,  targeted for their ivory , conservation has become a high profile issue in China. The latest five-year plan will launch efforts to protect the giant panda, tiger and Asian elephant in the wild, says Zhang Li, a conservation biologist at Beijing Normal University. \"There will be a big budget to restore habitat for these species,\u201d says Zhang. The projects will focus on corridors between protected areas that greatly increase the habitats by letting the animals move from one reserve to another.\u00a0 A biodiversity hotspot between Laos, Myanmar and the southwestern Chinese province of Yunnan requires protection in particular, says Stuart Pimm, a biodiversity specialist at Duke University in Durham, North Carolina. Forest there has been converted into rubber plantations, he says, \u201cand the level of hunting is worse than any place I\u2019ve ever been\u201d. But a focus on protecting pandas, elephants and tigers could leave other animals at risk, he pointed out in November ( B. V. Li and S. L. Pimm  Conserv. Biol.   30,  329\u2013339; 2016 ). \n               Stem-cell boom \n             In the wake of the five-year plan, China will gain a new funding initiative called 'Stem Cell and Translational Research', according to stem cell researchers Pei Gang, president of Tongji University, and Pei Duanqing, director of the Guangzhou Institutes of Biomedicine and Health. The grants will be awarded under a new competitive review and evaluation process, replacing a system that critics said rewarded scientific and political connections rather than merit. Following the last five year plan, China invested roughly 3 billion yuan (about US$460 million) in  stem-cell research . The pair say that there will be a big increase over the next five years but did not give exact figures. \u201cGiven the size of its population and the wide spectrum of unmet medical needs, China recognizes the promise of stem-cell and regenerative medicine as one of the key thrusts for modernizing its medical service system,\u201d says Pei Gang. \n               Pollution laboratory \n             In a country that places great value on social harmony, air and water pollution are the trigger for an increasing number of protests. Under a plan that began in 2012, the government is already trying to reduce the levels of airborne parti\u00adculate matter measuring less than 2.5\u00a0micrometres across (PM 2.5 ), which are small enough to penetrate deep into the respiratory system. By 2017, it  wants to achieve reductions of 25% in the Beijing area, 20% in the Yangtze River Delta and greater Shanghai area, and 15% in the Pearl River Delta . Major nationwide environmental initiatives outlined in the latest five-year plan will tackle transportation, clean energy and environmental protection, says Wei-xian Zhang, director of the State Key Lab for Pollution Control at Tongji University in Shanghai. The government will also target pollution black spots, such as smog in Beijing and  fertilizer pollution in Lake Tai  near Shanghai. Funding to control air pollution alone will increase by at least four times, says Zhang, and several new national laboratories focusing on clean energy and environmental research have also been funded for the next five years. \u201cChina is and will continue to be the largest market in air-, soil- and water-pollution control technologies,\u201d says Zhang. \u201cTo some degree, the whole country will be a huge laboratory for environmental research, such as smog mitigation.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               Reprints and Permissions"},
{"file_id": "nature.2016.19595", "url": "https://www.nature.com/articles/nature.2016.19595", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "Historic win by Google DeepMind's Go-playing program has South Korean government playing catch-up on artificial intelligence. Scrambling to respond to the  success of Google DeepMind\u2019s world-beating Go program AlphaGo , South Korea announced on 17 March that it would invest $863 million (1 trillion won) in artificial-intelligence (AI) research over the next five years. The commitment includes an already-budgeted 138.8 billion won for 2016; if the rest is spread evenly over the following four years, it represents a 55% increase in annual funding for AI. The windfall includes money for the founding of a high-profile, public\u2013private research centre with participation from several Korean conglomerates, including Samsung, LG Electronics and Hyundai Motor, as well as the technology firm Naver, based near Seoul. The timing of the announcement indicates the impact in South Korea of AlphaGo, which two days earlier  wrapped up a 4\u20131 victory  over grandmaster Lee Sedol in an exhibition match in Seoul. The feat was hailed as a milestone for AI research. But it also shocked the Korean public, stoking widespread concern over the capabilities of AI, as well as a spate of newspaper headlines worrying that South Korea was falling behind in a crucial growth industry. South Korean President Park Geun-hye has also announced the formation of a council that will provide recommendations to overhaul the nation\u2019s research and development process to enhance productivity. In her 17 March speech, she emphasized that \u201cartificial intelligence can be a blessing for human society\u201d and called it \u201cthe fourth industrial revolution\u201d. She added, \u201cAbove all, Korean society is ironically lucky, that thanks to the \u2018AlphaGo shock\u2019, we have learned the importance of AI before it is too late.\u201d \n             Quick reaction \n           Korean scientists told  Nature  that the AI research institute was already in the planning stages, and was originally intended to open in 2017. The science ministry, however, says it was on track to open by this June. However, AlphaGo\u2019s success has prompted the government to accelerate plans for the institute. Science ministry official Kim Yong-soo said that they hope it will open as soon as possible, but that the exact date depends on the companies involved. The institute is likely to be located in Pangyo, a technology city just south of Seoul. Korean AI researchers who spoke to  Nature  expressed concern that the new initiative is short-sighted, and a knee-jerk reaction. \u201cIt will help, but more consistent support is required,\u201d said Kwon Hyuk-chul, an AI researcher at Pusan National University in Busan. \u201cI\u2019m very sorry to hear that the government is interested in investing a lot of money in mostly industry, not universities,\u201d said one machine-learning professor at a leading Korean university, who requested anonymity in order to talk openly about the policy. \u201cIndustry will probably get some useful applications for making some product, but they are basically not interested in the research itself.\u201d South Korea already funds two high-profile AI projects:  Exobrain , which is intended to compete with IBM\u2019s Watson computer, and Deep View, a computer vision project. The combined 80 billion won had already been allocated to these projects over the next five years is included in the 1 trillion won figure, science ministry official Lee Jae-beom told  Nature . \n             Ready, steady, Go \n           The international Go community has probably not seen the last Go showdown between a human and a machine. Two days before the AlphaGo match began, deep-learning start-up firm NovuMind challenged the Chinese professional Go player Ke Jie to a computer match. Based in California's Silicon Valley, NovuMind was founded in 2015 by Ren Wu, a former deep-learning researcher at Baidu, the Chinese web-services giant. The terms of the match have yet to be formalized, says Wu, but he is confident that they will be signed soon. The 18-year-old Ke Jie defeated Lee Sedol in an international tournament held in China in January, and is currently the world\u2019s top-ranked player at  GoRatings.org  \u2014 just ahead of AlphaGo. The developers of two other Go-playing programs, called Zen and CrazyStone, are also working on enhanced deep-learning versions. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   What Google\u2019s winning Go algorithm will do next 2016-Mar-15 \n                 \n                   The Go Files: AI computer wraps up 4-1 victory against human champion 2016-Mar-15 \n                 \n                   The Go Files: AI computer wins first match against master Go player 2016-Mar-09 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19555", "url": "https://www.nature.com/articles/nature.2016.19555", "year": 2016, "authors": [{"name": "Adam Levy"}], "parsed_as_year": "2006_or_before", "body": "Tyrannosaurs evolved sophisticated senses before later growth spurt. Fragments of a newly identified dinosaur fossil from Uzbekistan have shed more light on how  Tyrannosaurus rex  and other fearsome carnivores evolved from their diminutive forebears \u2014 by getting smart before they got big. The tyrannosaurs of the late Cretaceous period (80 million to 66 million years ago) are among the biggest carnivores to have walked the Earth. But their predecessors \u2014 who lived as far back as 170 million years ago, in the Jurassic period \u2014 were much smaller; they were generally no bigger than a horse. They also had proportionally smaller heads and longer arms, and lacked the sense of smell and ability to hear low-frequency sound of later tyrannosaurs. A 20-million-year gap in the fossil record, from 100 million years ago to the time of the giant tyrannosaurs' appearance, has made it  difficult to trace how the keen-sensed giant carnivores evolved . But fossil fragments found in the Kyzylkum desert belong to a newly described horse-sized dinosaur that lived 92 million to 90 million years ago, slotting neatly into this gap, palaeontologists report 1 . \u201cThis is what we\u2019d been waiting for,\u201d says Stephen Brusatte, a palaeontologist at the University of Edinburgh, UK, who led the team that announced the find in the  Proceedings of the National Academy of Sciences  on 14 March. \n             Good listener \n           The dinosaur has been christened  Timurlengia euotica , meaning \u2018well-eared Timurleng\u2019 \u2014 in reference to the fourteenth-century central Asian ruler Timurleng, or Tamerlane, and to the specimen\u2019s large inner ear. It \u201ccaptures tyrannosaurs at a key point in their evolutionary transformation\u201d, says Lawrence Witmer, who studies the soft tissues of dinosaur heads at Ohio University in Athens. Although around 25 fragments of  Timurlengia  were found between 1997 and 2006, Brusatte was shown only the most significant of them \u2014 the braincase \u2014 in 2014, because of how long it took to process the huge number of finds excavated from the same area. The braincase, which is kept at the Russian Academy of Sciences in Saint Petersburg, suggests that despite the dinosaur\u2019s small size, weighing around 170\u2013270 kilograms,  Timurlengia  already housed a relatively long, tubular brain, similar to that of  T. rex.  The size and thickness of its head, compared with the rest of its body, also resembles that of later tyrannosaurs. Timurlengia \u2019s long cochlear duct \u2014 the part of the inner ear that controls hearing \u2014 also resembles that of its successors, which suggests that it would have shared their ability to hear low-frequency sounds, enabling it to hear prey from great distances. It is not known, however, whether the dinosaur possessed later tyrannosaurs\u2019 keen sense of smell. \n             Affirming evolution \n           The find suggests that the tyrannosaur \u201choned its sensory toolbox before it gained massive size\u201d, says Christopher Brochu, who studies the evolutionary history of dinosaurs at the University of Iowa in Iowa City. That might have enabled tyrannosaurs to reach the top of the predatory food chain when earlier large allosaurs \u2014 a separate group of dinosaurs to the tyrannosaurs \u2014 went extinct. Timurlengia  \u201cis a wonderful affirmation of evolution\u201d, says Witmer, \u201cin that it\u2019s an evolutionary intermediate that slots right in place in terms of both time and its anatomy\u201d. Still, the new find is only a single data point in a 20-million-year evolutionary period;  Timurlengia  might not be typical of other tyrannosaurs that were alive at the time. And tyrannosaurs come in a huge variety of shapes and sizes. Even as far back as 100 million years ago, there were large tyrannosaurs \u2014 \u201cweird off-shoots\u201d, says Brusatte, that were not ancestors of the enormous tyrannosaurs of the late Cretaceous \u2014 such as the  long-snouted  Xiongguanlong baimoensis , and the  9-metre long  Yutyrannus huali . \u201cSome elements of this story could be proven wrong by future discoveries,\u201d says Brusatte. \u201cI hope they are, because that means we\u2019ll have more and better middle Cretaceous fossils\u201d. \n                   Long-snouted tyrannosaur unearthed 2014-May-07 \n                 \n                   Diminutive dinosaur stalked the Arctic 2014-Mar-12 \n                 \n                   Palaeontology: The truth about T. rex 2013-Oct-23 \n                 \n                   How to eat a Triceratops 2012-Oct-24 \n                 Reprints and Permissions"},
{"file_id": "531425a", "url": "https://www.nature.com/articles/531425a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Country's 13th Five-Year Plan advances a broad goal to phase down coal and expand renewable energy. The world\u2019s largest greenhouse-gas emitter is turning a corner on climate change. China\u2019s 13th Five-Year Plan reinforces the country\u2019s seismic shift away from dirty coal, and many specialists now think that Chinese emissions  are already nearing their peak , or perhaps have even levelled off \u2014 well ahead of schedule. Approved on 16 March , the plan establishes an overarching strategy for economic development up to 2020, while setting basic goals and requirements for areas such as energy and the environment. In particular, the document extends and strengthens mandatory targets put in place over the past decade to reduce energy use,  curb air pollution  and promote the development of low-carbon sources such as wind, solar and nuclear. These efforts are already having an impact: China\u2019s coal consumption declined by an estimated 3.7% in 2015, according to statistics released in February by the Chinese government. Such a decrease is unprecedented, says Barbara Finamore, Asia director for the Natural Resources Defense Council, an environmental-advocacy group headquartered in New York City. \u201cI think it's catching everyone by surprise.\u201d The new plan calls for an 18% reduction in carbon intensity, which is a measure of how much carbon dioxide is emitted per unit of gross domestic product. That is slightly more aggressive than the 17% target in the previous five-year plan, made in 2011. And for the first time, the latest plan includes a goal to limit the country\u2019s total energy consumption. China consumed energy equivalent to 4.3 billion tonnes of coal in 2015, and the plan would seek to cap that figure at the equivalent of 5 billion tonnes by 2020. \n               On target \n             Nonetheless, the document does not specify how China will achieve its targets. \u201cThe point of this is to set the tone and direction,\u201d says Ranping Song, who handles climate policy in developing countries for the World Resources Institute (WRI), an environmental think tank in Washington DC. Song expects China to release detailed plans in coming months about how various sectors of its economy will meet the new commitments. As it stands, China is on track to achieve \u2014 and probably exceed \u2014 its previous targets. For instance, China announced in 2014 that it would halt its dramatic rise in coal use by 2020, and the latest data suggest that the country may have already accomplished that goal. China also leads the world in the deployment of renewable energy; in 2015, the country invested some US$110 billion \u2014 twice as much as the United States, according to the WRI. At the  United Nations climate summit in Paris  last year, China committed to  halting the growth in greenhouse-gas emissions by 2030 , but consensus is building that a peak could come by 2025 \u2014 if not substantially sooner. In addition to energy trends, the latest forecasts account for slower economic growth, as well as a shift away from heavy manufacturing and the production of steel and other commodities. \n               Growth debate \n             Some fear that coal consumption could once again spike, along with carbon emissions, if China\u2019s slowing economy revives, but a London School of Economics study published on 16 March 1  suggests that this is unlikely. \u201cIf emissions do grow, that growth is likely to be slow,\u201d says Fergus Green, a policy analyst who co-authored the study with economist Nicholas Stern. Green says that the Chinese government\u2019s latest energy statistics suggest that emissions may have dropped in 2015 \u2014 which leaves open the possibility that China\u2019s emissions have already peaked. With coal on the wane, Finamore says that one major question is whether China can rein in oil use in the growing transportation sector \u2014 an area in which the government has been less aggressive to date. Nonetheless, she says, strict new requirements on air pollution, driven by rising anger among Chinese citizens, are pushing China in the right direction. \u201cI\u2019m of the opinion that this is a trend that will continue,\u201d Finamore says. \u201cThis is the new normal.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     What China\u2019s latest five-year plan means for science 2016-Mar-18 \n                   \n                     Paris climate deal hinges on better carbon accountancy 2016-Jan-26 \n                   \n                     Nations approve historic global climate accord 2015-Dec-12 \n                   \n                     Global greenhouse-gas emissions set to fall in 2015 2015-Dec-07 \n                   \n                     Global carbon emissions nearly stalled in 2014 2015-Nov-25 \n                   \n                     China to launch cap-and-trade system 2015-Sep-25 \n                   \n                     China\u2019s carbon emissions overestimated 2015-Aug-19 \n                   \n                     What does the US\u2013China climate deal mean? 2014-Nov-12 \n                   \n                     White House: US-China deal on climate change \n                   \n                     UN Framework Convention on Climate Change \n                   Reprints and Permissions"},
{"file_id": "531422a", "url": "https://www.nature.com/articles/531422a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Smartphone programs allow researchers to recruit large numbers of participants and monitor them in real time. Last summer, physician Yvonne Chan wondered how the wildfires raging through Washington state were affecting people with asthma \u2014 for whom smoke and heat can trigger breathing difficulties. So she tapped into data collected through the Asthma Health iPhone app, which 8,700\u00a0people with asthma use each day to record their symptoms and triggers. Chan found that when fires flared up, so did asthma symptoms and reports of environmental triggers among users living near the blazes. \u201cIn the past, stuff like this was just logistically impossible to do,\u201d says Chan, director of digital health at the Icahn Institute for Genomics and Multiscale Biology at Mount Sinai in New York City. \u201cIt opens up a brand-new area of research.\u201d Smartphone apps developed by academics, pharmaceutical companies and technology giants are making possible large studies that collect real-time data on people\u2019s location, environment and health. Last March, for example, Apple debuted its  ResearchKit developer tools . Scientists and companies have used these tools to make iPhone apps targeted to specific conditions. Researchers are only now gaining access to these mobile-collected data sets, but the scope of such programs is expanding: on 21\u00a0March, Apple announced that ResearchKit apps can now import a user\u2019s genetic data from the consumer testing service 23andMe, based in Mountain View, California. Chan\u2019s asthma app and MyHeartCounts, a cardiovascular-disease app developed by Stanford University in California, will be the first to be able to easily incorporate  users\u2019 23andMe data , if participants allow it. \u201cThe biggest thing we\u2019re likely to get with these apps is scale,\u201d says neuroscientist James Beck, vice-president for scientific affairs at the Parkinson\u2019s Disease Foundation in New York City. mPower, a ResearchKit app that is aimed at people with Parkinson\u2019s disease, has enrolled more than 6,800 participants \u2014 3 times the number in the largest previous Parkinson\u2019s study. Collecting health data through an app also makes it easy to share them with other researchers. The mPower and asthma apps ask users whether they would like to make their data available for further analyses. So far, most have agreed \u2014 75% with mPower and 90% in the asthma study. On 3\u00a0March, roughly one year after mPower launched, it released a data set from its users \u2014 a huge departure from the past, when it would have taken years to collect and distribute such a large amount of data. \u201cOne of the things I like about these new digital ways of gathering information is that it\u2019s an opportunity to have data-sharing enabled by the trial itself,\u201d says Stephen Friend, president of Sage Bionetworks, a non-profit organization in Seattle, Washington, that developed mPower. Still, many researchers are taking a wait-and-see approach to the new technology. ResearchKit launched last year with 5\u00a0apps; there are now 25, tracking conditions including autism, breast cancer and multiple sclerosis. Some are surprised that more scientists haven\u2019t developed their own apps: \u201cI\u2019m shocked to see that we\u2019re a year into this and there\u2019s so few apps in there,\u201d says Atul Butte, director of the Institute for Computational Health Sciences at the University of California, San Francisco.  We\u2019re just at the edge of this wave.  Some may be wary about the quality of the data collected by mobile apps; in many of the ResearchKit studies, study personnel do not meet participants, raising questions about the quality of the data that these participants provide. With this in mind, researchers are working to spot-check their app data. Chan\u2019s team has examined whether the height and gender of the asthma-app users correlate as expected with peak flow, a measurement of breathing ability that is usually higher for men and for taller people. So far, that relationship has held up. \u201cWe don\u2019t have participants randomly entering bad data,\u201d Chan says. And Euan Ashley, a Stanford cardiologist who is the principal investigator for MyHeartCounts, is trying different strategies to recruit a diverse user base, since app users can skew male. The MyHeartCounts team is linking advertising for its study \u2014 which has roughly 50,000 participants \u2014 to specific Internet search terms and partnering with the Women's Health Initiative, a longrunning US study. But whether research apps can keep users engaged over the long term is an open question. For instance, mPower uses the iPhone\u2019s accelerometer and microphone to measure the steadiness of participants\u2019 gait and speech, respectively. But only about 1,000 mPower participants have elected to fill out a survey that assesses cognitive function. \u201cThere\u2019s a drop-off in interest as things get more difficult to do,\u201d Beck says. \u201cThere needs to be some value to the user, so that people don\u2019t pick it up and play with it for the first hour and never go back to it.\u201d Friend agrees. His company is working on making the mPower app more user-friendly. \u201cWhen we look back on it, we\u2019ll probably go, \u2018Wow, this is clunky\u2019,\u201d he says of the current app. And researchers are still working out how best to use the data from such programs. Because participants\u2019 data are collected in real time and much more often than usual \u2014 for example, daily, as opposed to during a quarterly visit to a physician\u2019s surgery \u2014 one logical application is in clinical trials of therapeutics. Pharmaceutical company Roche, based in Basel, Switzerland, has developed a Parkinson\u2019s app that it is using in a study of a new drug. Others suggest that mobile-enabled research may eventually lead to wearable devices that automatically collect information about participants in real time \u2014 such as those being developed by  Verily in Mountain View . Its Baseline Study will use wearable devices to collect user data, with the aim of gaining insights into how to detect and prevent disease. Says Beck: \u201cWe\u2019re just at the edge of this wave.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Why biomedical superstars are signing on with Google 2015-Oct-21 \n                   \n                     What could derail the wearables revolution? 2015-Sep-01 \n                   \n                     Smartphones set to boost large-scale health studies 2015-Mar-10 \n                   \n                     Wireless monitor frees patients to roam 2004-Mar-22 \n                   \n                     mPOWER: Mobile Parkinson's disease study \n                   \n                     ResearchKit \n                   \n                     Asthma Health App \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19599", "url": "https://www.nature.com/articles/nature.2016.19599", "year": 2016, "authors": [{"name": "Anna Nowogrodzki"}], "parsed_as_year": "2006_or_before", "body": "Decision by US National Science Foundation could hamper research on conservation biology, climate change and invasive species. The cabinets of the Field Museum in Chicago hold a collection of eggs that led to one of the most famous conservation discoveries of the twentieth century: that the pesticide DDT was causing widespread nesting failures in birds of prey. But such specimen troves \u2014 which are used  to identify species, track diseases and study climate change  \u2014 have lost a valuable means of support. Last week, the US National Science Foundation (NSF) announced that it would indefinitely suspend a programme that provides funding to maintain biological research collections. The agency will honour current grants, but it is not accepting new proposals. \u201cIt\u2019s surprising and disheartening,\u201d says Christian Sidor, a palaeontologist at the University of Washington in Seattle and curator of vertebrate palaeontology at the Burke Museum of Natural History and Culture, also in Seattle. \u201cIt rattled through the entire museum yesterday.\u201d He and other researchers are worried because the NSF is  one of the only public providers  of funds to maintain specimen collections. It awards between US$3 million and $5 million a year in grants for such collections, equivalent to roughly 0.06% of the agency\u2019s $7.5-billion budget for fiscal year 2016. (Individual grants are capped at $500,000.) And although the phrase 'biological collections' might call to mind images of dusty museum drawers, these resources are as likely to include jars of fish larvae collected last week as they are pressed plants from 100 years ago. \u201cOur fish collection, for example, is the repository for NOAA for the North Pacific,\u201d said Sidor. NOAA \u2014 the US National Oceanic and Atmospheric Administration \u2014 uses the specimens collected each year to assess fish abundance and set fishing quotas. \n               Learning from the past \n             The NSF says that it is evaluating the collections grant programme, and is thus unable to say whether the funding hiatus is temporary or permanent. \u201cThat depends on the results of the evaluation,\u201d says Muriel Poston, director of NSF\u2019s Division of Biological Infrastructure. The programme \u201ccould be reinstated, but potentially with a new focus\u201d, she adds. (In the meantime, the NSF Division of Biological Infrastructure is  soliciting feedback on the programme .) That doesn\u2019t satisfy scientists, many of whom took to Twitter to express their dismay. Felisa Smith, an ecologist at the University of New Mexico in Albuquerque,  wrote : \u201cWhat gives? Biological collections are the bedrock of a lot of contemporary science!\u201d Comparing modern plants or animals to preserved specimens can help scientists to understand how the climate is changing, how species have responded to past changes and how they are likely to behave in the future. Museum collections can also help scientists to determine a species\u2019 historic range, which can illuminate whether a modern population is endangered or threatened. Other researchers use collections to map and study invasive or otherwise harmful species, to identify insect pests, and to track species that carry human diseases. Rodent collections, for instance, helped researchers to determine the factors that led to an outbreak of hantavirus in the southwestern United States in 1993. The virus is spread by rodent droppings and can cause a fatal lung disease in humans. \u201cWithout natural history collections, we are blind to the arrival of new pest species,\u201d  tweeted  Alex Wild, curator of entomology at the University of Texas at Austin. \u201cWithout natural history collections, we are blind to both new species and species extinctions. Someone is going to have to produce funding for research collections, or we will lose the biology that lets us identify species.\u201d As technology improves, Sidor says, scientists could use specimens for purposes that the original collectors could never have anticipated. For example, DNA sequencing of museum specimens has helped to identify previously unknown species \u2014 some collected before DNA was discovered. Many museums are pushing to digitize their collections, which improves global access to information \u2014 indeed, the NSF's programme to support digitizing collections remains unchanged. But \u201cthere\u2019s no point digitizing if we don\u2019t take care of the collections themselves\u201d, says Barbara Thiers, director of the William and Lynda Steere Herbarium at the New York Botanical Garden. \u201cYou certainly can\u2019t get any DNA out of an image.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Smithsonian sets up frozen-plant repository 2015-Jul-08 \n                   \n                     Plant collections left in the cold by cuts 2015-Jul-01 \n                   \n                     Museums: The endangered dead 2015-Feb-18 \n                   \n                     Chicago's Field Museum cuts back on science 2012-Dec-20 \n                   \n                     Superstars of botany: Rare specimens 2012-Apr-25 \n                   \n                     US National Science Foundation: Collections in Support of Biological Research \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19615", "url": "https://www.nature.com/articles/nature.2016.19615", "year": 2016, "authors": [{"name": "Adam Levy"}], "parsed_as_year": "2006_or_before", "body": "Fluorescent proteins used to track individual skin cells in real time. Researchers have created a transgenic zebrafish with skin that fluoresces in thousands of colours \u2014 enabling them to track the behaviour of hundreds of individual cells in real time and to see what happens to skin when it is wounded. \u201cIt\u2019s a spectacular-looking fish,\u201d says Kenneth Poss, who studies tissue regeneration at Duke University in Durham, North Carolina, and who led the research, published in  Developmental Cell 1 . The idea is based on the \u2018 brainbow \u2019 \u2014 a technique published in 2007 2  in which neurons were engineered to express mixtures of fluorescent proteins, producing a random combination of different colours in different cells. In a zebrafish engineered to express the proteins in its skin cells, the same concept is called the \u2018skinbow\u2019. The fluorescent cells are limited to the fish\u2019s outer layer of skin, and cover the entire surface of its body \u2014 even the cornea.\u00a0 \n             Reading the rainbow \n           Based on the number of combinations of red, green and blue proteins they can express, individual cells could be expected to shine in any one of around 5,000 different colour combinations. In fact, only around 70 colours can be distinguished clearly through a microscope. Still, that is enough for most cells to be \u2018barcoded\u2019 distinctly from their neighbours. By tracking hundreds of individual skin cells over time, the researchers were able to study in real time how the skin recovered from injury, such as a scrape or a fin amputation. The scientists found that when a fin is amputated, for example, the cells employ three distinct processes to keep regenerating tissue covered with skin. Skin cells from neighbouring regions migrate in to cover the new tissue; new skin cells are created and some cells also grow substantially. \u201cThe interesting thing about this kind of study,\u201d says Poss, \u201cis you don\u2019t know what to expect, but you have a great way to visualize it.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Flashing fish brains filmed in action 2013-Mar-18 \n                 \n                   Mapping brain networks: Fish-bowl neuroscience 2013-Jan-23 \n                 \n                   Custom gene editing rewrites zebrafish DNA 2012-Sep-23 \n                 \n                   Colours light up brain structure 2007-Oct-31 \n                 Reprints and Permissions"},
{"file_id": "531426a", "url": "https://www.nature.com/articles/531426a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Two conflicting studies are at centre of row. In a decision hailed by animal-rights groups, the US marine-park company SeaWorld Entertainment announced last week that it will no longer breed killer whales. But whether captivity harms the planet\u2019s biggest predator is an area of active scientific debate. The latest arguments centre on two 2015 studies that drew dramatically different conclusions about the lifespans of captive killer whales ( Orcinus orca ), relative to those of wild populations. Although many factors affect well-being, an apparent discrepancy between the survival of captive and wild animals has long been cited by activists as evidence of the poor welfare of captive killer whales. One of the studies 1  is authored by a team largely made up of researchers at SeaWorld, which is headquartered in Orlando, Florida, and owns several animal parks that keep killer whales; the other 2  is by two former killer-whale trainers at the company who feature in the 2013 documentary film  Blackfish , which is critical of SeaWorld. In letters published last week 3 , 4 , authors from each paper accuse the others of cherry-picking data to support positions on whether the animals should be captive\u00a0\u2014\u00a0charges that each team in turn rejects. Although SeaWorld\u2019s captive-killer-whale programme now has an expiration date, the company\u2019s existing 23\u00a0animals will remain in parks for the rest of their lives, and its pregnant female Takara will give birth in captivity. Another 33 animals are held in other marine parks around the world. Robust studies of killer whales\u2019 longevity are needed to improve the well-being of the remaining captive animals, says Douglas DeMaster, science director at the US National Oceanic and Atmospheric Administration\u2019s Alaska Fisheries Science Center in Seattle, Washington. But the annals of research on captive killer whales are slim. Before 2015, the last major published study 5  dates to 1995, when US government scientists calculated that the annual survival rate of captive killer whales was several per cent lower than that of a wild population off the coast of Washington state called southern resident killer whales. In one of the 2015 studies 2 , the former trainers\u00a0\u2014\u00a0John Jett, a biologist at Stetson University in DeLand, Florida, and Jeffrey Ventre, a physician at Lakeview Campus Medical Facility in Yakima, Washington\u00a0\u2014\u00a0attempted to measure how captive whales have fared since conditions were improved in the 1980s. They pooled data from between 1961 and 2013 on 201\u00a0captive killer whales in institutions around the world, including SeaWorld. They concluded that survival rates in captivity have improved since 1985, but that even the most recent survival rates are below those of animals in the wild. In the other 2015 study 1 , researchers led by SeaWorld veterinary surgeon Todd Robeck came to a very different conclusion: that animals now in captivity at SeaWorld\u2019s US\u00a0parks live just as long as wild populations. The researchers looked only at animals held at those parks after 2000, and produced a survival rate that is higher than a rate that they calculated for southern resident killer whales\u00a0\u2014\u00a0and equivalent to that of another wild population that lives in the waters off British Columbia, Canada. Now, each lead author has taken aim at the work of the other. In a letter published in  Marine Mammal Science 3 , Robeck and three colleagues note that Jett and Ventre included in their 2015 study stranded animals, which might have arrived in captivity in poor health, and newborns, which are at particularly high risk of death. This pushes down the apparent survival rate of captive animals, say the researchers.  People started looking at killer whales in the early 1970s and they weren\u2019t immediately experts.  In the same journal, Jett responds 4  to that critique, and accuses Robeck\u2019s 2015 study of bias because, for instance, it compares captive whales to the southern resident population, which is endangered and exposed to pollutants and shipping traffic, and whose numbers have waxed and waned over the past four decades. Jett says that his and Ventre\u2019s study was intended to take a wide look at captive-killer-whale survival, so they included as many data as possible. But Robeck stands by his critique. \u201cThey can include all the animals they want,\u201d he says. \u201cThe conclusions they made were not based on the evidence they showed.\u201d DeMaster notes that the comparison that Robeck and his colleagues made between captive killer whales and a disturbed wild population is not useful. He adds that it is also difficult to compare the approaches taken by the two teams, because they analyse different animals over different periods. On 8\u00a0March, a further group of researchers entered the fray, criticizing the 2015 Robeck study on another front. In the  Journal of Mammalogy 6 , the group charges that Robeck\u2019s study implied that evidence for a long post-reproductive life\u00adspan in killer whales is an artefact stemming from over\u00adestimated ages of adults in the early days of research on captive killer whales. \u201cPeople started looking at killer whales in the early 1970s and they weren\u2019t immediately experts,\u201d says Robeck, who has also published a response 7  to that critique. The authors of the critique say that the evidence for the post-reproductive lifespan, a rare evolutionary adaptation otherwise seen only in humans and in pilot whales, is robust. \u201cThere are whales still alive now that were around in the 70s that haven\u2019t had a calf,\u201d says one of the authors, Darren Croft, a behavioural ecologist at the University of Exeter, UK. It will take more observation time to put firm numbers on the post-reproductive lifespan of killer whales, says Andrew Foote, an evolutionary ecologist at the University of Bern and another of the co-authors. The only way to resolve the dispute over the longevity of captive killer whales is for different teams to analyse the same data in the same manner, says DeMaster. Such studies could improve the well-being of captive animals by, for instance, identifying the facilities and husbandry practices that most benefit them. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     The whale that talked 2012-Oct-22 \n                   \n                     Orcas find shark diet a real grind 2011-Jan-20 \n                   \n                     Unique orca hunting technique documented 2007-Dec-14 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19611", "url": "https://www.nature.com/articles/nature.2016.19611", "year": 2016, "authors": [{"name": "Bianca Nogrady"}], "parsed_as_year": "2006_or_before", "body": "Other scientists also say the need to get a permit for applied \u2018dual-use\u2019 research may constrain academic freedom. Researchers in Australia are worried that an unusually restrictive 'export controls' law that comes into force in April could constrain their academic freedom. The law, called the Defence Trade Controls Act, will require academics who are working on applied research that is classified as \u2018dual-use\u2019 \u2014 that which may have both military and non-military applications \u2014 to apply for a permit from Australia\u2019s Department of Defence before they can write to colleagues overseas about their work. The dual-use list includes fields from electronics to microorganisms research. By 2 April, which marks the end of a one-year grace period since the act was passed, affected academics risk jail terms or fines if they communicate their research outside Australia without seeking a permit. Researchers working in cryptology, artificial intelligence and microbiology have all said they are worried about the impacts of the legislation. \u201cI think we\u2019re all concerned that because it appears to be a very blunt instrument, there is the potential for it to be used clumsily with potentially serious effects,\u201d says Jon Iredell, a microbiologist at the University of Sydney.\u00a0 The  United States  has long had similar laws, but they contain exemptions for academics working on basic and applied research. Australia's version exempts only basic research. As a result, says Vanessa Teague, a cryptologist at the University of Melbourne, much university-based applied research in cryptology in the United States is free from restriction \u2014 but in Australia, communicating the same type of research overseas may soon require a permit, and even then collaboration would be limited to an approved list of researchers or institutions. Another permit could be needed for new research relationships; the law seems to allow Australia\u2019s Department of Defence free rein to restrict communication around any technology it deems to have potential military applications. Just the time taken to process permit applications could disadvantage Australian researchers, Teague says. \n             Unclear legislation \n           Cryptologists have been particularly vocal with their concerns, in part because their field has historically had an uneasy relationship with defence and national security bodies. In July 2015, Teague was one of 229 Australian and international members to sign an online petition from the International Association for Cryptologic Research, claiming that the legislation would cut Australia off from the international cryptologic research community by imposing \u201cunclear, potentially severe, export controls\u201d. The situation is worrying academics in part because no one is clear on how the law will work in practice, Teague adds \u2014 for example, which kinds of research will actually require permits, and how swiftly the Department of Defence will grant them. The legislation also allows the defence minister to veto communication of dual-use research if the minister believes that it would prejudice Australia\u2019s security or international obligations, notes Jen Tsen Kwok, a policy specialist at the National Tertiary Education Union in Melbourne, which represents people working in higher education in Australia. \u201cThe Minister for Defence can come up with an excuse to stop research which may damage or constrain or compromise diplomatic relations with another country,\u201d he says. \u201cThe potential scope in the way the legislation is written is arbitrarily wide.\u201d The legislation is reminiscent of a mistake the United States made in the 1990s, says Anna Lysyanskaya, a cryptography researcher at Brown University in Providence, Rhode Island. At that time, cryptography was classified as military technology and subject to the US Arms Export Control Act. But the restrictions were challenged both by academic researchers and corporate investors (who wanted to export encryption technology for use in e-commerce). After several years of searching for ways to control the export of encryption technology, the government of then-President Bill Clinton relented and moved oversight of encryption to the US Department of Commerce. \n             Inappropriate application \n           Radar researcher Bill Moran at RMIT University in Melbourne says that he was baffled to discover that at least two of his current research projects were designated as \u2018controlled\u2019 by an online defence-department questionnaire designed to give researchers a quick \u2018yes\u2019 or \u2018no\u2019 about whether their research falls under the legislation.\u00a0He subsequently was told that the research in question didn\u2019t need a permit after all. \u201cI have done classified work in the past and I appreciate that some work has to be secret,\u201d says Moran, who is a former director of the Defence Science Institute at the University of Melbourne. But he says that the incoming legislation is being inappropriately applied to non-military academic work. A spokesperson for the Department of Defence did not elaborate on the full reach of the legislation, but stated in an e-mail to  Nature  that for any technology to be assessed as \u2018controlled\u2019 under the new law, it would have to meet specific and high thresholds. \u201cThese mean the technology is not readily available, would usually require specific skills to develop, produce or use, and has application in a military context or a weapon of mass destruction program,\u201d the spokesperson said. Others say that the law will cause academics few problems. It has already been amended from a 2012 version (which was never implemented), making it much more workable for researchers, points out Les Field, the secretary for science policy at the Australian Academy of Science in Canberra. Those amendments, introduced in April 2015, mean that affected academics won\u2019t need permits for verbal communications (such as talking on the phone or speaking about research at overseas conferences) or for e-mailing data or draft papers to overseas journals before publication, says Field, who was involved in the negotiations led by Australia's then-chief scientist Ian Chubb. Despite the amendments, Teague says she\u2019s still concerned about the vague but heavy-handed threat of the legislation. \u201cOn the one hand, these are very heavy penalties \u2014 at least in theory \u2014 and on the other hand, the kind of activities we\u2019re talking about are sharing new cryptology ideas with researchers overseas,\u201d she says. \u201cIt\u2019s hard to see dramatic prosecutions but it's much more plausible to see a chilling effect on research.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   US \u2018export rules\u2019 threaten research 2015-Jun-16 \n                 \n                   University tightens oversight of sensitive research 2009-Oct-26 \n                 \n                   Export-control laws worry academics 2009-Sep-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19614", "url": "https://www.nature.com/articles/nature.2016.19614", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Transgender people are the most affected. More than one in five physicists\u00a0from sexual and gender minorities in the United States report having been excluded, intimidated or harassed at work in the past year because of their gender or sexual identity or expression, a survey has found. According to the American Physical Society (APS) report  LGBT Climate in Physics , published on 15 March, transgender physicists and physics students faced the most hostile working environment, with almost half of the 37 surveyed reporting having experienced exclusionary and harassing treatment in the past year. Problems faced by transgender physicists included colleagues who failed to respect their gender identity \u2014 for example, by using the wrong name or pronoun to refer to them \u2014 and a lack of toilet facilities that they felt comfortable and safe in using. The findings come from a survey that asked 324 staff and students \u2014 most of whom were in academia \u2014 who self-identify as lesbian, gay, bisexual, transgender, queer, questioning or intersex or another sexual or gender minority (LGBT), about their experiences. The report suggests that  even though a survey published last year  suggested that scientists are more open about their sexual and gender identities than are others in the US workforce, some LGBT academics continue to face sexual harassment, homophobic comments, exclusion, stereotyping and expectations of incompetence. Experiences were tougher for women, the report suggests: they experienced harassment, intimidation and exclusionary behaviour at three times the rate of men. And although the survey was too small to find statistically significant differences on the basis of racial background, follow-up interviews revealed that non-white LGBT physicists experienced additional problems because of their race that were not faced by their white colleagues. Even greater numbers of LGBT physicists \u2014 60% of transgender respondents and around one-third of non-transgender (cisgender) respondents \u2014 reported observing such activities. More one-third of the respondents (36%) also reported that they had considered leaving their institution, which the authors say is correlated strongly with both experiencing and observing such behaviour. The survey comes at a time when one of the world\u2019s most prominent physics institutions \u2014 the European particle-physics laboratory, CERN, near Geneva, Switzerland \u2014 is in the limelight over the experiences of its LGBT community.  Physics World  reported in depth  on 3 March on the long-running attempts of the lab\u2019s LGBT group to gain official status, as well as about how posters raising awareness about the group had been defaced, torn down and, in one case, adorned with biblical scripture \u2014 reports that were later picked up widely by newspapers including the UK's  Sunday Times . Aidan Randle-Conde, a CERN physicist based at the Free University of Brussels who founded CERN's LGBT group in 2010, says that the issue with posters being removed or defaced remains a problem today; around a third of posters are taken down in a typical two week period. Defacing is rarer, he says, happening a few times each year. But CERN authorities \u2013 as well as staff \u2013 have been supportive, he adds. \u201cPeople inside and outside of the lab have responded with surprise, dismay, and outrage that a minority of people at the lab can spread their hate and intolerance like this.\" Ahead of the media reports, CERN had already taken disciplinary action against the homophobic behaviour and strongly condemned the actions. A spokesman for the laboratory said: \u201cCERN is fully committed to promoting diversity and equality, at all levels. It is one of CERN\u2019s core values as clearly reflected in our Code of Conduct as\u00a0well as in several organizational policies. Homophobic behaviour at CERN will not be tolerated.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Most gay and lesbian researchers are out in the lab 2015-Aug-14 \n                 \n                   African academics challenge homophobic laws 2015-Jun-10 \n                 \n                   Diversity: Pride in science 2014-Sep-16 \n                 \n                   Equality: Standing out 2014-Jan-08 \n                 \n                   Nature and Scientific American special: Diversity \n                 Reprints and Permissions"},
{"file_id": "531421a", "url": "https://www.nature.com/articles/531421a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Initiatives aim to measure global warming\u2019s impact on high seas and deep currents. The Southern Ocean guards its secrets well. Strong winds and punishing waves have kept all except the hardiest sailors at bay. But a new generation of robotic explorers is helping scientists to document the region\u2019s influence on the global climate. These devices are leading a technological wave that could soon give researchers unprecedented access to oceans worldwide. Oceanographers are already using data from the more than 3,900 floats in the international Argo array.  These automated probes  periodically dive to depths of 2,000\u00a0metres, measuring temperature and salinity before resurfacing to transmit their observations to a satellite (see \u2018Diving deeper\u2019). The US$21-million Southern Ocean Carbon and Climate Observations and Modeling Project (SOCCOM) is going a step further, deploying around 200 advanced probes to monitor several indicators of seawater chemistry and biological activity in the waters around Antarctica. A primary aim is to track the prodigious amount of carbon dioxide that  flows into the Southern Ocean . \u201cThe Southern Ocean is very important, and it\u2019s also very poorly known because it\u2019s just so incredibly miserable to work down there,\u201d says Joellen Russell, an oceanographer at the University of Arizona in Tucson and leader of SOCCOM\u2019s modelling team. Scientists estimate that the oceans have taken up roughly 93% of the extra heat generated by global warming, and around 26% of humanity\u2019s CO 2  emissions, but it is unclear precisely where in the seas  the heat and carbon go . A better understanding of the processes involved could improve projections of future climate change. SOCCOM, which launched in 2014, has funding from the US National Science Foundation to operate in the Southern Ocean for six years. Project scientists\u2019 ultimate goal is to expand to all the world\u2019s oceans. That would require roughly 1,000 floats, and would cost an estimated $25 million per year. Interest in this global array, dubbed the Biogeochemical Argo, is growing. The Japanese government has put a proposal to expand use of SOCCOM probes on the agenda for the meetings of the Group of 7 leading industrialized nations in Japan in May. And the project is gaining high-level attention as a result: the SOCCOM team has briefed John Holdren, science adviser to US President Barack Obama. Project scientists are rushing to develop a plan to expand use of the next-generation probes. \u201cIt\u2019s like, \u2018Oh, couldn\u2019t they wait a year?\u2019\u201d jokes SOCCOM associate director Ken Johnson, an ocean chemist at the Monterey Bay Aquarium Research Institute in Moss Landing, California. His team is drafting a proposal to present to the inter\u00adnational Argo steering committee at a meeting that begins on 22\u00a0March. Meanwhile, another set of researchers hopes to extend the existing Argo array beyond its current 2,000-metre limit. The US National Oceanic and Atmospheric Admini\u00adstration (NOAA) is spending about $1\u00a0million annually on a Deep Argo project to monitor ocean temperature and salinity down to 6,000\u00a0metres. The agency deployed nine Deep Argo floats south of New Zealand in January, and is planning similar pilot arrays in the Indian Ocean and the North Atlantic. The deep-ocean data will be particularly useful in improving how models simulate ocean circulation, says Alicia Karspeck, an ocean modeller at the National Center for Atmospheric Research in Boulder, Colorado. \u201cFrom a scientific perspective, it\u2019s a no-brainer,\u201d she says \u2014 noting that the new floats are a low-risk investment compared with spending money on developing models without additional oceanographic data. NOAA is using two different models of float, both designed to withstand the crushing pressures at the bottom of the sea. And Argo teams in Japan and Europe are already using upgraded floats that can reach down to 4,000\u00a0metres. The goal is to establish a new international array of some 1,250 deep-ocean floats\u00a0\u2014 most of which would need to dive to 6,000\u00a0metres. Doing so would provide basic data on 99% of the world\u2019s seawater. \u201cWe are really still working the bugs out of the equipment and trying to show that we can do this,\u201d says Gregory Johnson, a NOAA oceanographer in Seattle, Washington, and one of the principal investigators for Deep Argo. Even if scientists succeed in expanding next-generation ocean probes around the globe, he says, the data that they provide will not supplant detailed measurements of carbon, water chemistry, salinity and temperature that are currently made by ship-based surveys. Deep Argo measures only temperature and salinity, and the technology used in Biogeochemical Argo is not yet sensitive enough to measure subtle changes in the deep ocean. Still, ship surveys \u2014 which are done on average every ten years \u2014 cannot follow how heat is taken up by the deep ocean. By contrast, Deep Argo would allow researchers to continually watch heat move through the oceans. That could lead to a better understanding of how the oceans respond to global warming \u2014 and how the climate responds to the oceans. \u201cThis has all kinds of ramifications for ecosystems and climate,\u201d says Johnson of NOAA. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Epic El Ni\u00f1o yields massive data trove 2016-Mar-02 \n                   \n                     El Ni\u00f1o monitoring system in failure mode 2014-Jan-23 \n                   \n                     MERMAIDs detect distant earthquakes 2011-Oct-07 \n                   \n                     Southern Ocean Carbon and Climate Observations and Modeling \n                   \n                     Argo array \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19629", "url": "https://www.nature.com/articles/nature.2016.19629", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Paolo Macchiarini says that he does not accept disciplinary-board findings. The prestigious Karolinska Institute (KI) in Stockholm has ended its contract with the controversial surgeon Paolo Macchiarini after a series of allegations about his clinical and research practices. Macchiarini, formerly a visiting professor at the medical institute, had been internationally f\u00eated for his pioneering operations to implant artificial windpipes \u2014 until allegations of scientific and ethical misconduct  began to emerge almost two years ago . The KI, which selects winners of the Nobel Prize in Physiology or Medicine, has subsequently  come under criticism for its handling of the affair . In February, the KI  announced that it had \u201clost confidence\u201d in Macchiarini ; that his lab there should phase out its research; and that his contract would not be renewed in November. Now, the Staff Disciplinary Board at the institute says that he has been dismissed. Macchiarini \u201cengaged in conduct and research that is incompatible with a position of employment\u201d, alleged the board in a statement released on 23 March. \u201cIt\u2019s impossible for KI to have any kind of collaboration with Paolo Macchiarini any longer,\u201d said KI human-resources manager Mats Engelbrektson in the same statement. Following the announcement, Macchiarini told  Nature : \u201cI do not accept any of the findings of the Disciplinary Board. I have instructed lawyers and will be taking immediate steps to restore my reputation.\u201d \n             Russian procedures \n           Macchiarini carried out three artificial trachea operations, in which the synthetic tracheas were seeded with the patients' own stem cells, at the Karolinska University Hospital between 2011 and 2012. Two of those patients have since died, and one remains in hospital. In 2013, the KI said that it would not extend his contract as a surgeon, but kept him on as a basic researcher in regenerative medicine and approved his 'extra-mural occupation' as a surgeon at the Kuban State Medical University in Krasnodar, Russia. Allegations of misconduct against Macchiarini began to emerge in June 2014, including that he had exaggerated the success of his artificial-trachea implants in several scientific papers describing experiments in rats and in people. In August 2015, the KI  cleared him of scientific misconduct, but said that his research failed to meet its required standards of quality .\u00a0 A television documentary about Macchiarini\u2019s work, aired in January,  brought fresh, public attention to his work . The programme suggested that in an operation in Russia, Macchiarini implanted one of his plastic tracheas into a woman who was not in a life-threatening condition. Previously, the surgeon had said he attempted the risky procedures only on people who were life-threateningly ill. \n             External investigation \n           After the documentary, leading Karolinska figures resigned, including the vice-chancellor, the dean of research and the  secretary-general of the Nobel Assembly . The KI has also commissioned an ongoing, external investigation into its hiring of Macchiarini and the handling of its previous investigations into his work. In its latest statement, the Karolinska Staff Disciplinary Board says that it found that Macchiarini\u2019s activities in Krasnodar \u201care in breach of the KI\u2019s fundamental values and have damaged KI\u2019s reputation\u201d and that he had failed to \u201ctruthfully and fully\u201d report his activities there. It also says that Macchiarini \u201csupplied false or misleading information in the CV he submitted to KI\u201d, and had \u201cdemonstrated scientific negligence\u201d. Engelbrektson added: \u201cHe has acted in a way that has had very tragic consequences for the people affected and their families. His conduct has seriously damaged confidence in Karolinska Institute and for research in general.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             Reprints and Permissions"},
{"file_id": "531557a", "url": "https://www.nature.com/articles/531557a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Craig Venter\u2019s creation comes as CRISPR gene-editing methods provide alternative ways to tinker with life\u2019s building blocks. Genomics entrepreneur  Craig Venter  has created a synthetic cell that contains the smallest genome of any known, independent organism. Functioning with 473\u00a0genes, the cell is a milestone in his team\u2019s 20-year quest to reduce life to its bare essentials and, by extension, to design life from scratch. Venter, who has co-founded a company that seeks to harness synthetic cells for making industrial products, says that the feat heralds the creation of customized cells to make drugs, fuels and other products. But an explosion in powerful \u2018gene-editing\u2019 techniques, which enable relatively easy and selective tinkering with genomes, raises a niggling question: why go to the trouble of making new life forms when you can simply tweak what already exists? Unlike the  first synthetic cells  made in 2010 1 , in which Venter\u2019s team at the J. Craig Venter Institute in La Jolla, California, copied an existing bacterial genome and transplanted it into another cell, the genome of the minimal cells is like nothing in nature. Venter says that the cell, which is described in a paper released on 24\u00a0March in  Science 2 , constitutes a brand new, artificial species. \u201cThe idea of building whole genomes is one of the dreams and promises of  synthetic biology ,\u201d says Paul Freemont, a synthetic biologist at Imperial College London, who is not involved in the work. The design and synthesis of genomes from scratch remains a niche pursuit, and is technically demanding. By contrast, the  use of genome editing is soaring  \u2014 and its most famous tool,  CRISPR\u2013Cas9 , has already gained traction in industry, agriculture and medicine, notes George Church, a genome scientist at Harvard Medical School in Boston, Massachusetts, who  works with CRISPR . \u201cWith much less effort, CRISPR came around and suddenly there are 30,000 people practising CRISPR, if not more.\u201d Microbiologists were just starting to characterize the bacterial immune system that scientists would eventually co-opt and name CRISPR when Venter\u2019s team began its effort to whittle life down to its bare essentials. In a 1995  Science  paper, Venter\u2019s team sequenced the genome of  Mycoplasma genitalium , a sexually transmitted microbe with the smallest genome of any known free-living organism 3 , and mapped its 470 genes. By inactivating genes one by one and testing to see whether the bacterium could still function, the group slimmed this list down to 375 genes that seemed essential. One way to test this hypothesis is to make an organism that contains just those genes. So Venter, together with his close colleagues Clyde Hutchison and Hamilton Smith and their team, set out to build a minimal genome from scratch, by joining together chemically synthesized DNA segments. The effort required the development of new technologies, but by 2008, they had used this method to make what was essentially an  exact copy of the  M.\u00a0genitalium  genome  that also included dozens of non-functional snippets of DNA \u2018watermarks\u2019 4 . But the sluggish growth of natural  M.\u00a0genitalium  cells prompted them to switch to the more prolific  Mycoplasma mycoides . This time, they not only synthesized its genome and watermarked it with their names and with famous quotes, but also implanted it into another bacterium that had been emptied of its own genome. The  resulting \u2018JCVI-syn1.0\u2019 cells  were unveiled 1  in 2010 and  hailed  \u2014 hyperbolically, many say \u2014 as the  dawn of synthetic life . (The feat prompted US President Barack Obama to launch a bioethics review, and the Vatican to question Venter\u2019s claim that he had created life.) However, the organism\u2019s genome was built by copying an existing plan and not through design \u2014 and its bloated genome of more than 1\u00a0million\u00a0DNA bases was anything but minimal. In an attempt to complete its long-standing goal of designing a minimal genome, Venter\u2019s team designed and synthesized a 483,000-base, 471-gene  M.\u00a0mycoides  chromosome from which it had removed genes responsible for the production of nutrients that could be provided externally, and other genetic \u2018flotsam\u2019. But this did not produce a viable organism. So, in a further move, the team developed a \u2018design-build-and-test\u2019 cycle. It broke the  M.\u00a0mycoides  genome into eight DNA segments and mixed and matched these to see which combinations produced viable cells; lessons learned from each cycle informed which genes were included in the next design. This process highlighted DNA sequences that do not encode proteins but that are still needed because they direct the expression of essential genes, as well as pairs of genes that perform the same essential task \u2014 when such genes are deleted one at a time, both mistakenly seem to be dispensable. Eventually, the team hit on the 531,000-base, 473-gene design that became known as JCVI-syn3.0 (syn2.0 was a less streamlined intermediary). Syn3.0 has a respectable doubling time of 3 hours, compared with, for instance, 1\u00a0hour for  M. mycoides  and 18 hours for  M.\u00a0genitalium . \u201cThis old Richard Feynman quote, \u2018what I cannot create, I do not understand\u2019, this principle is now served,\u201d says Martin Fussenegger, a synthetic biologist at the Swiss Federal Institute of Technology (ETH) in Zurich, Switzerland. \u201cYou can add in genes and see what happens.\u201d With nearly all of its nutrients supplied through growth media, syn3.0\u2019s essential genes tend to be those involved in cellular chores such as making proteins, copying DNA and building cellular membranes. Astoundingly, Venter says that his team could not identify the function of 149 of the genes in syn3.0\u2019s genome, many of which are found in other life forms, including humans. \u201cWe don\u2019t know about a third of essential life, and we\u2019re trying to sort that out now,\u201d he says. This has blown Fussenegger away. \u201cWe\u2019ve sequenced everything on this planet, and we still don\u2019t know 149 genes that are most essential for life!\u201d he says. \u201cThis is the coolest thing I want to know.\u201d Syn3.0\u2019s lasting impact on synthetic biology is an open question. \u201cI think it\u2019s kind of a George Mallory moment,\u201d says Church, referring to the English mountaineer who died in 1924 trying to become the first person to climb Mount Everest. \u201c\u2018Because it\u2019s there\u2019 was the excuse he gave for climbing Everest.\u201d Church says that genome-editing techniques will remain the go-to choice for most applications that require a small number of genetic alterations, whereas genome design will be useful for specialized applications, such as recoding an entire genome to incorporate new amino acids. Fussenegger thinks that genome editing will be the favoured approach for therapies, but that writing genomes from scratch will appeal to scientists interested in fundamental questions about how genomes evolve, for instance. Even Venter acknowledges that syn3.0\u2019s genome, although new, was designed by trial and error, rather than being based on a fundamental understanding of how to build a functioning genome. But he expects fast improvements, and thinks that genome synthesis from scratch will become the preferred approach for manipulating life. \u201cIf you want to make a few changes, CRISPRs are a great tool,\u201d he says. \u201cBut if you\u2019re really making something new and you\u2019re trying to design life, CRISPRs aren\u2019t going to get you there.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Genomics: DNA's master craftsmen 2010-Nov-03 \n                   \n                     Researchers start up cell with synthetic genome 2010-May-20 \n                   \n                     Sizing up the 'synthetic cell' 2010-May-20 \n                   \n                     Scientists devise new way to modify organisms 2009-Aug-20 \n                   \n                     Genome stitched together by hand 2008-Jan-24 \n                   \n                     Genome transplant makes species switch 2007-Jun-28 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19642", "url": "https://www.nature.com/articles/nature.2016.19642", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Future of the major astronomy probe remains unclear as pieces of space debris are reported. The Japan Aerospace Exploration Agency (JAXA) lost contact with its flagship X-ray astronomical satellite, Hitomi, on 26 March. The observatory, launched on 17 February, had been going through initial check-outs and calibrations. Hitomi's status remains unknown as JAXA engineers work to re-establish communication. Ominously, the US Joint Space Operations Center, which tracks space debris, reported spotting five objects in the vicinity of the spacecraft around the time that it went silent. The centre characterized the objects as pieces of a \u201cbreak-up\u201d. The space debris could consist of minor pieces that were blown off Hitomi, as opposed to indicating complete destruction, says Jonathan McDowell, an astronomer and space analyst at the Harvard\u2013Smithsonian Center for Astrophysics in Cambridge, Massachusetts. Hitomi, which was  known before launch as ASTRO-H , is designed to study X-rays streaming from cosmic phenomena such as black holes, galaxy clusters and dark matter. It carries a high-resolution spectrometer to measure X-ray wavelengths in exquisite detail. Earlier versions of the same instrument have twice met a grim fate on JAXA missions: in 2000, the ASTRO-E telescope crashed on launch, and in 2005, a helium leak aboard the Suzaku satellite crippled its spectrometer within weeks of launch. \n             Hope for recovery \n           JAXA lost contact with Hitomi at 4:40 p.m. Japan time on 26 March. \u201cThe cause of the communication failure is under investigation,\u201d the agency said. It has, however, received at least one short signal from the satellite since then, and is working on possible ways to start talking to it again. Agency engineers have pulled off spaceflight recoveries before. In December, JAXA  placed the Akatsuki spacecraft into Venus orbit , five years after a failed engine burn seemed to doom the mission. And in 1993, a US X-ray mission named Alexis made it into orbit, but was not heard from for three months. Spacecraft engineers eventually recovered it, and it went on to do its planned X-ray science. International partners on the Hitomi project include NASA, the European Space Agency, the Netherlands Institute for Space Research and the Canadian Space Agency. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   High stakes as Japanese space observatory prepares for launch 2016-Feb-09 \n                 \n                   Satellites watch stellar death throes 2012-Aug-02 \n                 \n                   Spacecraft aims to expose violent hearts of galaxies 2012-Mar-13 \n                 \n                   JAXA's Hitomi site \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19634", "url": "https://www.nature.com/articles/nature.2016.19634", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Officials hope to avoid repeat of delayed response to Ebola epidemic. Public-health officials say that the first human trials of a Zika vaccine could begin this year. But they caution that it will take until at least next year, and possibly much longer, to determine whether a vaccine works. In the meantime, they are trying to avoid a repeat of their experience with the Ebola epidemic, during which most vaccine trials began  too late  \u2014 just as the rate of infection began to taper off. As a result, scientists missed out on the chance to prove that the vaccines prevent people from becoming infected. \u201cI really don\u2019t think that\u2019s going to be the case with Zika,\u201d says Anthony Fauci, director of the US National Institute of Allergy and Infectious Diseases in Bethesda, Maryland. \u201cI seriously doubt that the vaccine trials are going to be completely impeded by a lack of cases.\u201d Fauci is among the scientists, government officials and representatives of the private sector who are  meeting today  in Bethesda, Maryland, to discuss how to speed up the development of vaccines, diagnostics and treatments against the Zika virus, which is spreading through the Americas and may be linked to debilitating birth defects.\u00a0 The rate of Zika infections may drop off over time, because most people who are infected will probably develop immunity to Zika and thus cannot become reinfected. But even then, \u201cwe\u2019ll probably need a routine vaccination to control the infection\u201d, says Alexander Precioso, director of the clinical trials and pharmacovigilance division of the Butantan Institute in S\u00e3o Paulo, Brazil. That\u2019s because mosquito-borne infections \u2014 such as Zika, dengue and yellow fever \u2014 tend to recur in waves, waxing and waning as the virus hits new populations of susceptible people, such as children. \n             Vaccine variations \n           The Butantan Institute is one of 18 agencies and companies around the world that are developing Zika vaccines. Its experimental product is an \u201cinactivated\u201d vaccine, based on killed, purified Zika virus, that could be tested in people by 2018 or 2019. At least four other groups are pursuing this strategy. Inactivated vaccines are thought to be the safest type of inoculation for pregnant women, who are thought to be especially vulnerable to Zika. Babies born to mothers infected with Zika may be at greater risk of certain  birth defects,  such as microcephaly \u2014 an abnormally small head. On 9 March, a group of experts convened by the World Health Organization said that the development of an inactivated Zika vaccine for use in women who might become pregnant is a top  research priority . But other types of vaccine are further along in development. The US National Institutes of Health (NIH), for instance, is developing a DNA-based vaccine in which genetic material from the Zika virus would be used to induce an immune response. The agency has already used that technology in an investigational vaccine against West Nile virus. The NIH will soon begin to manufacture the vaccine and could start to test it in healthy volunteers in the United States as early as December, Fauci says. If that goes smoothly, the NIH would then test the vaccine in a larger study in countries where Zika is spreading: \u201cWe\u2019re going to do that where there are the most cases,\u201d Fauci says. In the long term, a vaccine made from a weakened Zika virus \u2014 a \u201clive attenuated\u201d vaccine \u2014 might be the most effective, Precioso says, because it mimics the natural course of infection more closely than other types. The NIH and several other agencies, as well as private companies, are developing live attenuated vaccines \u2014 including one that targets both Zika and dengue. But because such vaccines are complex to develop, they will probably not enter safety trials until next year. In the meantime, says Precioso, his institute and others will press ahead with other strategies: \u201cWe\u2019re trying to see what we can do right now to control these widespread cases.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                 \n                   Proving Zika link to birth defects poses huge challenge 2016-Feb-09 \n                 \n                   Ebola teaches tough lessons about rapid research 2015-May-27 \n                 Reprints and Permissions"},
{"file_id": "531560a", "url": "https://www.nature.com/articles/531560a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Scientists will track psychological and medical outcomes of controversial treatments to help transgender adolescents transition. For transgender children who think their bodies are the wrong sex, puberty can be terrifying. To alleviate this psychological trauma, physicians are increasingly giving transgender adolescents drugs to block puberty until their bodies \u2014 and decision-making abilities \u2014 are mature enough to begin cross-sex hormone treatment, typically at age 16. But the side effects of such therapy are largely unknown, and researchers and clinicians are still trying to determine how to treat children who question the gender they were assigned at birth. A US study set to begin recruiting participants in May could offer some clarity. Funded by the US National Institutes of Health (NIH), the US$5.7-million project will be not only the largest-ever study of transgender youth, but also only the second to track the psychological effects of delaying puberty \u2014 and the first to track its medical impacts. It comes as the NIH and others have begun to spend heavily on research related to the health of transgender people, says Robert Garofalo, a paediatrician at Ann and Robert H. Lurie Children\u2019s Hospital of Chicago, Illinois, and a leader of the study. \u201cWe seem to really be at a tipping point,\u201d he adds. Garofalo and his colleagues aim to recruit 280 adolescents who identify as transgender, and to follow them for at least five years. One group will receive puberty blockers at the beginning of adolescence, and another, older group will receive cross-sex hormones. Their findings could help clinicians to judge how best to help adolescents who are seeking a transition. About 75% of children who question their gender identify as the gender assigned at birth by puberty. But those who identify as transgender in adolescence almost always do so permanently. Denying them the ability to\u00a0transition is unethical, says bioethicist Simona Giordano of the University of Manchester, UK. \u201cNot treating adolescents is not being neutral,\u201d she says. \u201cIt means exposing children to a lot of harm.\u201d \n               Age of consent \n             Still, there is no clear age at which children can consent to irreversible treatments, including to hormones. To allow more time to decide and to let their bodies mature, transgender children on the cusp of adolescence are often given drugs called GnRH agonists that block the effects of sex hormones. This is \u201cthe safest way to relieve transgender adolescents at the worst time of their life\u201d, says Wylie Hembree, an endocrinologist at Columbia University in New York City. Only one study, published in 2014, has examined the psychological effects of such treatment. Child psychiatrist Annelou de Vries and her colleagues at VU University Medical Center in Amsterdam monitored a group of 55 trans\u00adgender adolescents who received puberty blockers at around age 13, cross-sex hormones at about 16 and gender-reassignment surgery at around age 20. They found study participants \u2014 now in their 20s \u2014 to be as mentally healthy as their non-transgender peers ( A.\u00a0L.\u00a0de Vries  et\u00a0al.    Pediatrics    134,  696\u2013704; 2014 ). Less is known about how postponing puberty affects physical health. GnRH agonists have been used for decades to treat children who start to mature too early. But some scientists worry that putting off puberty in older children may disrupt bone and brain development, reducing bone density and leading to cognitive problems. Later this year, the Endocrine Society will update its guidelines for treating transgender youth. Stephen Rosenthal, a paediatric endocrinologist at the University of California, San Francisco (UCSF), and a leader of the new study, anticipates two major changes. One is to discontinue blanket advice to withhold cross-sex hormone therapy until age 16, to allow flexibility on the basis of when a child enters puberty. The other change addresses a more controversial topic: whether to allow prepubescent children to live as the gender they identify with. Because most children who question their gender do not do so past adolescence, many psychologists discourage \u201csocially transitioning\u201d until the teenage years. Other clinicians use a \u201cwait and see\u201d approach. But encouraging children to live as the gender they identify with is an increasingly popular choice. \u201cThere\u2019s been a real sea change,\u201d says Diane Ehrensaft, a psychologist at UCSF. She reports seeing more prepubescent patients recently who have already transitioned socially. Many transgender-rights activists support this model, and liken any other approach to gay-conversion therapy. \u201cYou\u2019re telling a kid, \u2018I don\u2019t believe you\u2019,\u201d says Asaf Orr, staff attorney at the National Center for Lesbian Rights in San Francisco. The best strategy, he says, is \u201cto affirm a child\u2019s gender exploration, regardless of what the end result is going to be\u201d. The debate is so heated \u2014 and evidence so sparse \u2014 that the authors of the American Psychiatric Association\u2019s 2013  Diagnostic and Statistical Manual of Mental Disorders  ( DSM-5 ) were unable to reach a consensus. \u201cPeople are making declarations of knowledge that are their belief systems, that aren\u2019t also backed up by empirical research,\u201d says Jack Drescher, a psychiatrist at the William Alanson White Institute in New York City. Nevertheless, several US states and Ontario, Canada, have banned transgender-conversion therapy, which may include any practices that do not actively help children to live as the gender they identify with. No matter the approach, Giordano says, clinicians and families should help children to understand what they are experiencing. \u201cGoing through the social and physical transition is a long journey,\u201d she says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Excluded, intimidated and harassed: LGBT physicists face discrimination 2016-Mar-22 \n                   \n                     Most gay and lesbian researchers are out in the lab 2015-Aug-14 \n                   \n                     African academics challenge homophobic laws 2015-Jun-10 \n                   \n                     Sex redefined 2015-Feb-18 \n                   \n                     Diversity: Pride in science 2014-Sep-16 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19589", "url": "https://www.nature.com/articles/nature.2016.19589", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}, {"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "One fresh analysis keeps alive physicists\u2019 hope for a breakthrough, but another is disappointing. Hints of a mysterious new particle at the world\u2019s largest particle accelerator just got a little stronger. The excess of photons produced by particle collisions at the Large Hadron Collider (LHC) has  kept physicists abuzz since it was discovered three months ago . Now the use of fresh data by one LHC experiment has made the signal slightly more statistically significant \u2014 but it still falls well short of the certainty needed to claim a discovery. In December, physicists announced that they had seen an excess of  pairs of \u03b3-ray photons  with a combined energy of around 750 gigaelectronvolts. The data came from ATLAS and CMS, the two largest detectors at the 27-kilometre-circumference LHC at CERN, the European particle-physics laboratory near Geneva, Switzerland. The excess seen by the CMS experiment has now become slightly more significant, owing to a fresh analysis reported on 17 March at a conference in La Thuile, Italy. But to the disappointment of many, the analysis presented by ATLAS on the same day, which did not contain new data, did little to change the status of the mysterious excess. In fact, the significance seen by ATLAS went down a bit as a result of the analysis, which was a more conservative interpretation of the data-set than previously, says Marco Delmastro, the physicist at the CNRS Theoretical Physics Laboratory in Annecy-le-Vieux, France who presented the ATLAS results. The data set used in the latest CMS analysis is 22% larger than the one that the experiment reported in December, because it includes collisions from early in the LHC\u2019s 2015 run, when the detector\u2019s magnet was switched off owing to a problem in its cooling system. The magnetic field affects detector electronics, so data taken without the field needed careful and separate calibration. \u201cThe good news is, we now we have almost as much data as ATLAS,\u201d says James Olsen, physics coordinator for CMS and a physicist at Princeton University in New Jersey. \n             Bumps in the road \n           The CMS team has also recalibrated the full data set \u2014 something that researchers do at the end of each run to account for how radiation affects their measurements. With the additional data and the tweaked calibration, the statistical significance of the CMS bump has now gone up from 1.2 to 1.6 sigma, said Pasquale Musella, a physicist at the Swiss Federal Institute of Technology in Zurich, at the La Thuile conference on Thursday. \u201cThe fact that their excess has gone up is a hopeful sign,\u201d says Delmastro, referring to the CMS results. \u201cBut caution is necessary. Statistics is a harsh mistress,\u201d he adds, paraphrasing the title of a science-fiction novel by Robert Heinlein. The significance reported by CMS is still far below physicists\u2019 threshold for a discovery: 5 sigma, or a chance of around 3 in 10 million that the signal is a statistical fluke. Moreover, although the calculation takes into account the \u2018look elsewhere\u2019 effect \u2014 in which deviations from the expected are more likely when scouring a wide range of energies than when looking at a specific, pre-established window \u2014 it does not consider that photons are just one of many end products that LHC physicists test, warns Marumi Kado, the physics coordinator of ATLAS and a physicist at the Linear Accelerator Laboratory at the University of Paris-Sud. Yet conducting many searches increases the odds that at least one such \u2018channel\u2019 will contain some statistical fluctuations.\u00a0 \n             Empty search \n           Further hints about the excess could emerge as soon as next week, from more talks at the La Thuile meeting: bumps could have appeared in other searches, as the particle decays into something other than two photons. So far, such searches, including  one presented earlier this week at CERN , have found nothing, but physicists say that the 2015 data sets may be too small to show bumps in those other modes of decay. If the excess is a genuine sign of a particle, it would most probably be a boson \u2014 a type of particle typically associated with one of the fundamental forces \u2014 that no one had predicted. Physicists at the LHC and elsewhere say that such a discovery would be the most important in particle physics since at least 1975, when the unexpected \u03c4 lepton was discovered. By contrast, the Higgs boson,  discovered in 2012 , was predicted by the standard model of particle physics. \u201cIt would be the first detected in a collider experiment beyond the standard model,\u201d Olsen says. \u201cIf it\u2019s truly a new signal, it\u2019s incredibly interesting,\u201d says Kado. \"It would open up so many possibilities, so many questions. Studying it would be wonderful.\u201d But statistical bumps often go away after more data are collected, so Kado and others still urge caution. \u201cOur job is to doubt \u2014 to always check for possible problems,\u201d he says. \n             Theoretical frenzy \n           Even so, theoretical physicists have been in a frenzy. \u201cIn the Theory Division, it\u2019s all we talk about,\u201d says CERN theorist Gian Francesco Giudice. \u201cTheorists are more emotional,\u201d he says. \u201cExperimentalists are by nature more cautious, especially in their official statements.\u201d Since the December announcements, theoretical physicists have posted 285 (according to  a count kept by a CMS physicist ) papers in the arXiv online repository  purporting to explain the excess , but no consensus has yet emerged on what such a particle could be. Especially interesting is that the particle would probably not be a \u201clone wolf\u201d, Giudice says, but would be one of many related particles yet to be discovered. \u201cIt\u2019s reasonable to think that it\u2019s just an animal that strayed away from its pack, but that there is a pack somewhere to be found.\u201d The LHC\u2019s beams were shut down over winter for maintenance, but in the next few weeks they will be colliding particles again. New high-energy collisions will begin in April. Physicists say that by June, or August at the latest, CMS and ATLAS should have enough data to either make a statistical fluctuation go away \u2014 if that\u2019s what the excess is \u2014 or confirm a discovery. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Who ordered that? 2016-Mar-08 \n                 \n                   Hint of new boson at LHC sparks flood of papers 2015-Dec-24 \n                 \n                   CERN\u2019s next director-general on the LHC and her hopes for international particle physics 2015-Dec-22 \n                 \n                   LHC sees hint of boson heavier than Higgs 2015-Dec-15 \n                 \n                   LHC signal hints at cracks in physics' standard model 2015-Sep-03 \n                 \n                   LHC 2.0: A new view of the Universe 2015-Mar-11 \n                 \n                   Gian Francesco Giudice \n                 \n                   James Olsen \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19654", "url": "https://www.nature.com/articles/nature.2016.19654", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "US president pushed world to secure radioactive materials, but the threat of nuclear warfare \u2014 and terrorism \u2014 remains. US President Barack Obama has  downsized his country\u2019s nuclear arsenal , helped to negotiate a deal  to halt Iran\u2019s nuclear-weapons programme  and led a global initiative to secure radioactive materials. But Obama\u2019s legacy on nuclear issues remains uncertain as he prepares for a major global summit this week on nuclear terrorism. The meeting, which begins in Washington DC on 31 March, has taken on new significance in light of revelations that operatives of the Islamist extremist group ISIS may have been targeting nuclear facilities in Belgium. Obama began a series of biennial summits on nuclear security in 2010, after calling on the world  to secure all nuclear materials  within four years. But progress has been slow, and it is already clear that this week\u2019s summit \u2014 probably the last in the series \u2014 will come up short. \u201cIt\u2019s great that Obama has made this an issue,\u201d says Miles Pomper, who tracks nuclear issues at the James Martin Center for Nonproliferation Studies in Washington DC. \u201cBut he didn\u2019t quite drive it home.\u201d Obama has encountered significant headwinds on nuclear policy. Russia, whose relationship with the West has soured, declined an invitation to this week\u2019s summit. And Republicans in the US Congress have attacked the July 2015 deal with Iran as too lenient; even supporters acknowledge that it will take time to verify the impact of the accord. North Korea\u2019s nuclear programme remains in place, and the spectre of nuclear warfare hovers over India and Pakistan. Although Obama struck a deal in 2010 with Russian President Vladimir Putin to curb each country's trove of nuclear warheads from 2,200 to 1,550, Putin has declined to discuss further reductions. Meanwhile, the US Department of Energy is advancing expensive plans to refurbish and upgrade the country\u2019s existing arsenal. \u201cThe administration has largely failed on the promise it came to office with \u2014 of trying to end cold-war thinking,\u201d says Stephen Young, who follows nuclear-weapons issues for the Union of Concerned Scientists, an advocacy group in Cambridge, Massachusetts. \n             Terrorist threat \n           The news that ISIS, which carried out the recent  terrorist attacks in Paris  and Brussels, may have been targeting nuclear facilities has renewed many experts\u2019 anxiety about the nature and urgency of the terrorism threat. \u201cIt\u2019s dispiriting,\u201d says David Albright, a physicist and founder of the Institute for Science and International Security, an arms-control group in Washington DC. \u201cThe threat of annihilation has gone way down, but the fear of being killed by something nuclear through terrorism is just becoming more prevalent.\u201d Obama-administration officials say that the summit process has facilitated discussion on the full range of nuclear threats, and this year\u2019s summit will touch on everything from ISIS to Iran and North Korea. But the summits are mainly designed to encourage countries to bolster security at both civilian and military nuclear facilities. \u201cWe want to be essentially raising the global norm related to nuclear security,\u201d says Laura Holgate, senior director for weapons of mass destruction terrorism and threat reduction on the US National Security Council. Since 2010, 12 countries \u2014 including Ukraine, Turkey and Libya \u2014 have eliminated their stockpiles of highly enriched uranium, which can be used in weapons. Countries have converted research reactors to use low-enriched uranium, upgraded security at nuclear facilities and installed radiation detectors at border crossings. Much of the world\u2019s focus has been on preventing the smuggling of nuclear materials from former Soviet-bloc countries and other developing nations. But the ongoing investigation into terrorist activities in Belgium suggests that nuclear facilities in developed countries are not just at risk of theft, but also sabotage and outright attack. \n             After Obama \n           The United States has fallen short on its own nuclear commitments. In particular, an agreement between the United States and Russia to dispose of 34 tonnes of plutonium each, signed in 2000, is on hold\u00a0owing to ongoing questions about disposal methods. Citing budget problems, the Department of Energy is trying to halt construction of a facility in South Carolina that would convert the plutonium into mixed-oxide fuel (a mixture of a plutonium and uranium oxides) for nuclear reactors. Instead, the department wants  to dilute and dispose of the material  in a permanent geological repository. \u201cIt will definitely be cheaper and faster and safer, but Congress has not given any signs that it will support that approach,\u201d Young says. Delegates from more than 50 countries, including heads of state, are expected to present a new round of pledges this week, and probably a plan for what comes next. Few expect the summits to continue once Obama leaves office in January 2017, which means that it will be up to existing multilateral institutions such as the International Atomic Energy Agency and Interpol to pick up the pieces. \u201cThere\u2019s no question that these summits have made a difference, but momentum has clearly slowed,\u201d says Page Stoutland, vice-president for scientific and technical affairs at the Nuclear Threat Initiative, an advocacy group in Washington DC. \u201cThe challenge is to figure out how to carry this forward in some way.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Iranian researchers welcome nuclear deal 2015-Jul-15 \n                 \n                   US government seeks sites for nuclear-waste storage 2015-Mar-24 \n                 \n                   US warheads to get a facelift 2013-May-07 \n                 \n                   Weapons labs to thrive as Obama trims nukes 2010-Mar-02 \n                 \n                   Obama's nuclear-weapons-free vision 2009-Apr-08 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19655", "url": "https://www.nature.com/articles/nature.2016.19655", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Fetal tissue may prove crucial to probing link between virus and birth defects. A protein that helps Zika virus infect adult skin cells might also give the virus access to stem cells that make brain cells, suggests a study carried out on donated human fetal tissue. The result \u2014 published today in  Cell Stem Cell 1  \u2014 is part of a growing body of research that seeks to determine how Zika  might cause birth defects , but that requires a type of tissue that is increasingly controversial for researchers in the United States. Recent advances in neuroscience and cell technology have given hints as to why some babies born to Zika-infected mothers  have abnormally small heads  \u2014 a condition called microcephaly \u2014 and other problems, such as eye damage. But to fully understand what is happening in the womb, some scientists say that they need to study tissue from fetuses, which can be donated by couples who terminate pregnancies. Researchers already knew that a protein called AXL enabled Zika to enter human skin cells. Now, Arnold Kriegstein, a neuroscientist at the University of California, San Francisco, and his colleagues show that the protein is also made by cells in the fetus that form the eye and the brain. AXL could provide a means for Zika virus to infect these cells. Two other studies published this month 2 , 3  showed that Zika specifically targets and kills neural cells in organoids \u2014 brain-like structures derived from reprogrammed human skin cells. These studies suggest that Zika causes microcephaly by damaging fetal cells that make the brain, says neuroscientist Patricia Pestana Garcez of the Federal University of Rio de Janeiro, Brazil, who led one of the organoid studies. \u201cWe can say for sure that Zika has the ability to infect neural progenitors, and this is a good explanation for why Zika is correlated with microcephaly,\u201d she says. \n               Under the microscope \n             Kriegstein says that the fetal tissue used in his study was donated by patients treated at UCSF medical facilities. But such tissue may be harder to come by, as the collection and use of fetal cells is under renewed scrutiny in the United States. Last July, an anti-abortion group called the Center for Medical Progress in Irvine, California, released video of employees from the non-profit health-care provider Planned Parenthood  discussing the sale of fetal tissue  from abortions for research. Members of the US House of Representatives are now investigating the use of fetal tissue in research. US scientists worry that the controversy is affecting the availability of donated fetal tissue, and could thus hamper crucial research on the Zika virus. \u201cMany fewer people are willing to donate, and it\u2019s slowing us down,\u201d says Susan Fisher, a stem-cell and developmental biologist at the University of California, San Francisco. Fisher is studying how Zika virus is transmitted from mother to baby through the placenta, which carries blood and nutrients to the fetus during pregnancy. She has found AXL in fetal cells called trophoblasts that anchor the placenta to the mother's uterus. These cells are known to transmit infections such as cytomegalovirus from mother to baby. \u201cThis suggests that the placenta is extremely capable of transmitting Zika,\u201d says Fisher, whose studies rely on fetal tissue donated from terminated and full-term pregnancies. Carolyn Coyne, a virologist at the University of Pittsburgh in Pennsylvania, is also probing Zika transmission between mother and baby \u2014 but using cell lines and placentas donated after full-term pregnancies. She says that fetal tissue is particularly critical for studies of Zika because the virus appears to be able to harm a fetus throughout pregnancy 4 . \u201cIt is absolutely essential to study Zika infection in human fetal tissue,\u201d says Coyne. \u201cThese types of studies need to extend to all stages of pregnancy.\u201d Because abortion is illegal or highly restricted in many Latin American countries, laboratory research on neural development in the regions hit hardest by Zika relies mainly on other types of human tissue, such as organoids. Researchers in Brazil, for example, are studying the lethality of different Zika viruses in neurons and organoids derived from cord blood. \n               Looking ahead \n             Fisher used donated fetal tissue in part because an embryonic stem-cell line that she developed is ineligible for federal grant funding. Fisher derived this stem-cell line, which is capable of making trophoblast cells like those found in the placenta, from an eight-cell embryo. But current federal guidelines restrict funding for embryonic stem-cell research to cells derived from a blastocyst \u2014 an embryo about three days older than that which gave rise to Fisher's cell line. Both Fisher and Kriegstein are planning further studies to test how Zika infects developing brain and placental cells. They argue that such studies are crucial to establish why the virus damages babies' brains, and whether this can be prevented. The scientists will also use organoids and animal models, but they note that neither of these is a perfect substitute for human fetal tissue. For instance, researchers aren't sure how faithfully the growth of brain organoids replicates human brain development. \u201cIt\u2019ll be important to demonstrate in human tissue exactly how the virus is creating the pattern of damage that is emerging,\u201d Kriegstein says. \u201cIn situations like this, where there\u2019s considerable time pressure to try to unravel what\u2019s going on and to protect the developing human brain, it\u2019s especially important.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     The race is on to develop Zika vaccine 2016-Mar-28 \n                   \n                     Zika and birth defects: what we know and what we don\u2019t 2016-Mar-21 \n                   \n                     Proving Zika link to birth defects poses huge challenge 2016-Feb-09 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19651", "url": "https://www.nature.com/articles/nature.2016.19651", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Latest excavations show  Homo floresiensis  to be tens of thousands of years older than thought. Homo floresiensis , the mysterious and diminutive species found in Indonesia in 2003, is tens of thousands of years older than originally thought \u2014 and may have been driven to extinction by modern humans. After researchers discovered  H. floresiensis , which they nicknamed the hobbit,  in Liang Bua cave on\u00a0the island of Flores , they concluded that its skeletal remains were as young as 11,000 years old. But later excavations that have dated more rock and sediment around the remains now suggest that hobbits were gone from the cave by 50,000 years ago, according to a study published in  Nature  on 30 March 1 . That is around the time that modern humans moved through southeast Asia and Australia. \u201cI can\u2019t believe that it is purely coincidence, based on what else we know happens when modern humans enter a new area,\u201d says Richard Roberts, a geochronologist at the University of Wollongong, Australia. He notes that  Neanderthals vanished soon after early modern humans arrived in Europe from Africa . Roberts co-led the study with archaeologist colleague Thomas Sutikna (who also helped coordinate the 2003 dig), and Matthew Tocheri, a paleoanthropologist at Lakehead University in Thunder Bay, Canada. \n             Dating game \n           The first hobbit fossil, known as LB1, was found in 2003 2  beneath about 6 metres of dirt and rock. Its fragile bones were too precious for radiocarbon dating, so the team collected nearby charcoal, on the assumption that it had accrued at the same time as the bones. That charcoal was as young as 11,000 years old, researchers reported at the time 3 , 4 . \u201cSomehow these tiny people had survived on this island 30,000 years after modern humans arrived,\u201d says Roberts. \u201cWe were scratching our heads. It couldn\u2019t add up.\u201d The hobbit team has continued excavating Liang Bua \u2014 mainly  in search of more hominin remains , but also to better understand the geology of the enormous cave. And the more recent excavations have indicated that the charcoal lay in a section where older sediments had eroded away and been replaced with much younger rock. Using several methods, the team dated newly excavated rock and dirt that had accumulated in the same sediment layer as the hominin remains, and discovered that they are between 100,000 and 60,000 years old. Previously excavated stone tools, which researchers think were made by  H. floresiensis , were dated to between 190,000 and 50,000 years old. The older dates resolve the mystery of how hobbits co-existed with humans for tens of thousands of years: they didn\u2019t. But other questions linger. Researchers have little clue about  H. floresiensis \u2019 evolutionary relationship to other ancient-human relatives, and whether they mated with humans or other species is an open question. \n             Human error \n           Roberts says that the peculiar geology of Liang Bua would have been hard to notice when the first hobbit bones were found on the final days of the 2003 field season. \u201cDo I think we could have done a better job? Not with what we knew at the time,\u201d he says. \u201cWe\u2019re 10 years down the road, and we know a lot more and we\u2019ve excavated a lot more.\u201d Tom Higham, an archaeological scientist at the University of Oxford, UK, says that the latest dating work is compelling. \u201cThese results are tantalizingly close to the earliest evidence for modern humans in the region, which might suggest a causal link to the subsequent disappearance of  H. floresiensis ,\u201d Higham adds. Roberts, too, suspects that humans had a hand in the species' demise, perhaps by competing for scant resources. \u201cIt\u2019s a smoking gun for modern human interaction, but we haven\u2019t yet found the bullet,\u201d he says. Now the team hopes to find the remains of modern humans that may have encountered the last hobbits. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The discovery of Homo floresiensis: Tales of the hobbit 2014-Oct-22 \n                 \n                   Human evolution: Small remains still pose big problems 2014-Oct-22 \n                 \n                   'Hobbit' was a dwarf with large feet 2009-May-06 \n                 \n                   Will the hobbit argument ever be resolved? 2006-Aug-25 \n                 \n                   Critics silenced by scans of hobbit skull 2005-Mar-03 \n                 \n                   Fossil finders in tug of war over analysis of hobbit bones 2005-Mar-02 \n                 \n                   Little lady of Flores forces rethink of human evolution 2004-Oct-27 \n                 Reprints and Permissions"},
{"file_id": "531559a", "url": "https://www.nature.com/articles/531559a", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Most polled researchers in Britain and the wider EU think that the union benefits science. The charged question of whether the United Kingdom should stay in the European Union\u00a0\u2014\u00a0to be put to a national referendum on 23 June\u00a0\u2014\u00a0splits the general population almost evenly. But most scientists want the country to stay in, suggests a  Nature  poll of nearly 2,000 researchers living in the EU, both inside and outside the United Kingdom (see \u2018Scientists speak on a Brexit\u2019). Most of the polled researchers also think that a British exit, or \u2018Brexit\u2019, would harm science in the nation and in the EU at large. Responses to the poll were solicited by e-mail from people who had registered their addresses with  Nature;  through a pop-up on its website; and on social media.  Of the 907 researchers working in the United Kingdom who were polled, 83% said that they wanted Britain to stay in, whereas 12% were in favour of a Brexit. When only the 666 UK researchers who plan to vote in the referendum were included, these figures shifted slightly \u2014 to 80% and 14%. Sentiment was similar among polled researchers living outside the United Kingdom but inside the EU, who don\u2019t have a vote. Of these 954 individuals, 77% wanted Britain to stay in the EU, whereas 17% wanted it to leave. These proportions differ markedly from those of the general UK population, which is divided roughly evenly between the \u2018leave\u2019 and \u2018remain\u2019 camps, according to other surveys. Of those who intend to vote in the referendum, 78% said that a Brexit would harm UK science; 9% said that it would be beneficial. Both UK and EU researchers thought that an exit would harm the rest of EU science although to a lesser extent than it harmed UK science. Political debate concerning a Brexit has revolved heavily around immigration, the economy and infighting in the country\u2019s ruling Conservative Party. Prime Minister David Cameron supports the \u2018in\u2019 camp, but several high-profile members of his party want out. However, science is making inroads into the discussion. \u201cResearch and innovation are actually coming more into the debate,\u201d says Mike Galsworthy, co-founder of the advocacy group Scientists for EU. \u201cIt\u2019s going to get more heated around that issue.\u201d On 10 March,  The Times  newspaper published a letter extolling the benefits to science of EU membership, signed by more than 150\u00a0researchers at the University of Cambridge who are fellows of the Royal Society. \u201cI think in the sciences, it\u2019s clearly overwhelmingly in favour of staying in,\u201d says lead signatory Alan Fersht, a Cambridge chemist. Scientists in favour of staying note that UK universities receive around 16% of their total research funding directly from the EU, and that membership allows researchers to move freely between member states and to work with no restrictions (see  Nature 530, 15, 2016 ). But pro-Brexit Conservative justice minister Michael Gove has suggested that money that the United Kingdom currently gives to the EU as part of its membership could be invested in science if the country leaves. And cancer researcher Angus Dalgleish\u00a0\u2014\u00a0who is campaigning for the United Kingdom to leave the union\u00a0\u2014\u00a0 complained about EU regulation of science  on the television programme  Newsnight  on 10\u00a0March. The campaign to leave is making science a major point of its activities, says Jamie Martin, an advocate for the leave side and a former special adviser to Gove. The full results of  Nature 's poll are available to download here:  Full survey results  . The raw data from the poll can be  downloaded from figshare . \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Better together 2016-Feb-03 \n                   \n                     Academics across Europe join \u2018Brexit\u2019 debate 2016-Feb-03 \n                   \n                     European medical research escapes stifling privacy laws 2015-Dec-16 \n                   \n                     European Commission names seven researchers as its top science advisers 2015-Nov-10 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19719", "url": "https://www.nature.com/articles/nature.2016.19719", "year": 2016, "authors": [{"name": "Bethany Augliere"}], "parsed_as_year": "2006_or_before", "body": "Massive genomic study picks up disease-linked mutations in otherwise healthy people. By analysing genetic data gathered from more than half a million people, researchers have discovered a handful of individuals who are resilient to severe childhood diseases. The finding, published on 11 April in  Nature Biotechnology 1 , demonstrates an important proof of concept: by sharing massive genomic data sets, scientists can find healthy individuals who harbour mutations that normally cause disease. Studying these people can help scientists to identify factors that protect against sickness, says Stephen Friend, a co-author of the study and director of Sage Bionetworks in Seattle, Washington. Mendelian disorders, such as  cystic fibrosis  and Tay-Sachs disease, manifest in childhood and are generally caused by  mutations in a single gene . Many studies have sought to identify the genes involved in these disorders, but naturally occurring protective factors are unknown, and few effective therapies exist to treat symptoms. Researchers have known for years that patients with mutations that should cause death or disabling conditions can go on to lead extended healthy lives. For example, women with a mutation in  BRCA1  have a high risk of developing breast cancer. Yet many women who carry that mutation do not develop the disease. The new study's approach is notable in that it combines data from disparate sources to find these protected individuals, says Daniel MacArthur, a geneticist at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts. \u201cIt\u2019s an enormously impressive effort,\u201d he adds. \n             Gene by gene \n           Friend and his colleagues accumulated data from 12 studies that together examined the genetic sequences of 589,306 people. The team looked for mutations in 874 genes linked to nearly 600 childhood diseases. The scientists whittled down the sample to 15,597 individuals who had at least one mutation associated with the 163 Mendelian diseases included in the study. After performing a series of quality-control tests, including manual review of clinical trials and more genetic sequencing of stored samples, the researchers found 13 seemingly healthy individuals who survived to adulthood without showing any symptoms, despite carrying a genetic mutation linked to one of eight Mendelian diseases. \u201cI actually think there are probably more than 13, but they took a very restrictive threshold for making the call,\u201d says Eric Topol, a professor of genomics at the Scripps Research Institute in La Jolla, California. But the study was limited in some important ways. Its retroactive nature meant that the scientists did not have consent to re-contact patients and seek permission to sequence their full genomes. To find protective factors in these healthy individuals, the team would need to follow up and confirm their conditions before fully analysing the genomes of the patients and their family members. \n             Sharing for a cure \n           \u201cIt was both an exciting and a really frustrating project,\u201d says Friend. \u201cThis was entirely a proof of concept and to guide us for a prospective study.\u201d This work paves the way for future genotype-sequencing studies, in which sharing data at a national scale, and across international boundaries, will become increasingly important, says MacArthur. Large sample sizes will be required to identify common protective factors among resilient individuals. \u201cIt\u2019s all about data sharing and collaboration,\u201d he says. Friend and his colleagues argue that finding mutations that act as protective factors against disease is a better starting point for designing therapies than starting with the disease itself. Topol describes this new direction as uncharted but important territory. \u201cWhat we need to do in the future is get thousands of these people of a diverse protection, and understand what gave them this Teflon coating, this bullet-proof genome,\u201d he says.  \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Funds dedicated to personalized genetics 2011-Dec-06 \n                 \n                   Selective sequencing solves a genetic mystery 2009-Nov-13 \n                 \n                   Genomics shifts focus to rare diseases 2009-Sep-22 \n                 \n                   Time for bed, says DNA 1999-Aug-31 \n                 \n                   Stephen Friend \n                 \n                   Daniel MacArthur \n                 \n                   Eric Topol \n                 \n                   The Resilience Project \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19715", "url": "https://www.nature.com/articles/nature.2016.19715", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Discrepancy between observations could point to new physics. The most precise measurement ever made of the current rate of expansion of the Universe has produced a value that appears incompatible with measurements of radiation left over from the Big Bang 1 . If the findings are confirmed by independent techniques, the laws of cosmology might have to be rewritten. This might even mean that dark energy \u2014 the unknown force that is thought to be responsible for the observed acceleration of the expansion of the Universe \u2014 has increased in strength since the dawn of time. \u201cI think that there is something in the standard cosmological model that we don't understand,\u201d says astrophysicist Adam Riess, a physicist at Johns Hopkins University in Baltimore, Maryland, who  co-discovered dark energy in 1998  and led the latest study. Kevork Abazajian, a cosmologist at the University of California, Irvine, who was not involved in the study, says that the results have the potential of \u201cbecoming transformational in cosmology\u201d. \n             Uncertainty limits \n           In the accepted model of cosmology, the Universe evolves mostly through the competing action of dark matter and dark energy. Dark matter\u2019s gravity tends to slow cosmic expansion, while dark energy pushes in the opposite direction and makes it accelerate. Earlier observations made by Riess and others suggest that dark energy\u2019s strength has been constant throughout the history of the Universe. Much of what scientists know about the relative contributions of dark matter and dark energy comes from the relic radiation left behind from the Big Bang, called the cosmic microwave background. The most exhaustive study of it\u00a0\u2014 essentially a  portrait of the young Universe  at about 400,000 years of age\u00a0\u2014\u00a0was done in recent years by the European Space Agency\u2019s  Planck observatory . Based on Planck\u2019s measurements, cosmologists can predict how that young Universe will evolve, including how fast it expands at any point in its history. For years, those predictions have disagreed with direct measurements of the current rate of cosmic expansion \u2014 also known as the Hubble constant. But until now the error margins in this constant were large enough that the disagreement could be ignored. The Hubble constant is calculated by observing how rapidly galaxies in the relatively nearby Universe move away from the Milky Way, using stars of known intrinsic brightness called ' standard candles '. For their latest paper, Riess's team studied two types of standard candles in 18 galaxies using hundreds of hours of observing time on the Hubble Space Telescope. \u201cWe\u2019ve been going gangbusters with this,\u201d says Riess. Their paper 1 , which has been submitted to a journal and posted on the arXiv online repository on 6 April, reports that they measured the constant with an uncertainty of 2.4%, down from a previous best result 2 \u00a0of 3.3%. They find the speed of expansion to be about 8% faster than that predicted based on Planck data, says Riess.\u00a0 \n             Dark matter mystery \n           If both the new measurement of the Hubble constant and the earlier measurements by the Planck team are accurate, then something in the standard model has to change, Riess says. One possibility is that the elementary particles that constitute dark matter have properties that are different than currently thought, which would affect the evolution of the early Universe. Another option is that dark energy is not constant but has become stronger in recent eons. Planck researcher Fran\u00e7ois Bouchet of the Institute of Astrophysics in Paris says he doubts that the problem is in his team\u2019s measurement, but that the new findings are \u201cexciting\u201d regardless of what the solution turns out to be. Another possibility is that standard candles themselves that are not reliable when it comes to precision measurements, says Wendy Freedman, an astronomer at the University of Chicago in Illinois who in 2001 led the first precision measurement of the Hubble constant 3 . She and her team are working on an alternative method based on a different class of stars. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Siren call 2016-Mar-23 \n                 \n                   European probe shoots down dark-matter claims 2014-Dec-02 \n                 \n                   Cosmologists at odds over mysterious anomalies in data from early Universe 2013-Dec-13 \n                 \n                   Planck snaps infant Universe 2013-Mar-26 \n                 \n                   Stellar performance nets physics prize 2011-Oct-04 \n                 \n                   SH0ES \n                 \n                   Planck \n                 \n                   Adam Riess \n                 \n                   Kevork Abazajian \n                 \n                   Wendy Freedman \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19576", "url": "https://www.nature.com/articles/nature.2016.19576", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Protection against virus raises hopes of vaccine development for dengue and even Zika. Scientists have found what may be the strongest evidence yet that a vaccine can prevent dengue, by deliberately infecting volunteers with a weakened form of the disease-causing virus. This method of testing vaccines, known as \u2018human challenge\u2019, fell out of favour during the last century, but could be crucial for combating certain diseases, including Zika. \u201cThis is a tremendous step forward, and something that has been desperately needed for 30 years,\u201d says Duane Gubler, a disease researcher at the Duke NUS Medical School in Singapore who was not involved in the new study. The lack of human challenge studies, he said, has \u201cactually been one of the things that has made the development of dengue vaccines very difficult.\u201d Concerns about the safety of deliberately infecting people have limited the use of human challenge studies. Researchers now generally test whether most vaccines work by vaccinating large numbers of people who were already at risk of contracting the disease concerned, and observing whether or not they were protected. But deliberate infection has been used in some cases, for instance to develop\u00a0 vaccines against malaria . Anna Durbin, a vaccine researcher at the Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland, and her colleagues explain in  Science Translational Medicine  how they used the strategy to test a dengue vaccine 1 . First, they injected 21 volunteers with the experimental vaccine, and 20 other volunteers with a dummy vaccine. Six months later, they injected all 41 volunteers with a weakened, \u2018challenge\u2019 version of the dengue virus \u2014 which usually causes symptoms similar to a mild dengue infection, such as a rash. None of those vaccinated became sick from the challenge virus or showed the virus in their blood. By contrast, dengue virus was found in the blood of all of the volunteers who had received the dummy vaccine; 80% of them also developed a rash. Current dengue vaccines only protect a proportion of volunteers, so if these results hold up in larger populations the vaccine could be one of the most promising dengue vaccines developed. \u201cThis is an incredible paper that shows what is absolutely necessary to develop a vaccine against the dengue virus,\u201d says Scott Halstead, a virologist and vaccinologist at the Uniformed Services University of the Health Sciences in Bethesda, Maryland. \u201cIt\u2019s a really important demonstration of the kind of proof that you really need to have before you spend US$1.5 or 2 billion on a phase III [efficacy] trial,\u201d he says.\u2028 \n             From dengue to Zika \n           The dengue virus has proved a difficult vaccine target because it comes in four versions, or serotypes. The study published today tested only whether the vaccine prevented infection with dengue serotype 2 \u2014 the most difficult to protect against. Investigators have already begun a second human-challenge study to test whether the vaccine protects against dengue serotype 3, and they hope to go on to test it against serotypes 1 and 2. The scientists who ran the study also hope to use the human-challenge strategy to speed the development of a vaccine against Zika virus, which is related to dengue. Several groups are working on potential Zika vaccines. But it is unclear whether the vaccines can be developed in time to prevent the severe consequences of the outbreak that has now infected as many as 1 million people, and that  may be causing birth defects , such as microcephaly, an abnormally small head. \u201cWe are looking at strategies to accelerate that timeline, and we think that a Zika human-challenge model could be very useful in that endeavour,\u201d says Durbin. In the meantime, the Butantan Institute, a Brazilian research organization in S\u00e4o Paulo, began a large clinical trial of the dengue vaccine candidate on 22 February. The institute hopes to enrol 17,000 people over the next year to test the efficacy of the vaccine, which could be licensed by 2018. The Japanese pharmaceutical company Takeda, headquartered in Osaka, has also begun large efficacy studies of its own dengue vaccine candidate. This gives veterans of the field, such as Gubler, hope: \u201cFor the first time in 50 years, I\u2019m really enthusiastic and confident that we will have a vaccine, and we\u2019ll be able to use the vaccine in the next few years.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The global distribution and burden of dengue 2013-Apr-07 \n                 \n                   Dengue: a continuing global threat 2010-Dec-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19535", "url": "https://www.nature.com/articles/nature.2016.19535", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Cells grown both inside and outside the body show promise in fixing lenses and corneas. Discs made of multiple types of eye tissue have been grown from human stem cells \u2014 and that tissue has been used to restore sight in rabbits. The work, reported today in Nature 1 , suggests that induced pluripotent stem (iPS) cells \u2014 stem cells generated from adult cells \u2014 could one day be harnessed to provide replacement corneal or lens tissue for human eyes. The discs also could be used to study how eye tissue and congenital eye diseases develop. \u201cThe potential of this technique is mind-boggling,\u201d says Mark Daniell, head of corneal research at the Centre for Eye Research Australia in Melbourne, who was not involved in the research. \u201cIt\u2019s almost like an eye in a dish.\u201d A second, unrelated paper in  Nature 2  describes a surgical procedure that activates the body\u2019s own stem cells to regenerate a clear, functioning lens in the eyes of babies born with cataracts. The two studies are \u201camazing, almost like science fiction\u201d, Daniell says. In the first study, a team led by Kohji Nishida, an ophthalmologist at Osaka University Graduate School of Medicine in Japan, cultivated human iPS cells to produce discs that contained several types of eye tissue. The cells grew in distinct regions so that researchers could extract and purify specific types, including those found in the cornea, retina and lens. Nishida\u2019s team was able to remove cells from one region of a disc to grow sheets of corneal epithelium that the researchers then successfully transplanted into rabbits with defective corneas. Previous studies have generated  retinal or corneal tissue  using iPS cells, but none has produced such different types of eye cell in a single experiment. And Daniell says that cells made from the recipient\u2019s own cells using the disc method could one day supply tissue to repair damaged eyes without the threat of rejection by the immune system. But much remains to be done before any such therapy could be tested in humans, and if a treatment is developed, it could cost tens or hundreds of thousands of dollars. \n             Parting the clouds \n           By contrast, the cataract paper could have an almost immediate impact on treatment, says James Funderburgh, a cell biologist at the University of Pittsburgh School of Medicine in Pennsylvania. The technique described does not involve culturing cells outside the body or transplanting material that would require regulatory approval. \u201cThis is just a change in a surgical procedure,\u201d says Funderburgh. \u201cThey are not putting in an artificial lens: they are just letting the lens regrow.\u201d The research was inspired by a typical side effect of implanting artificial lenses to treat cataracts: the new lenses often become cloudy as the recipient\u2019s own cells grow over them. A team led by ophthalmologists Khang Zhang of the University of California, San Diego, and Yizhi Liu of Sun Yat-sen University in Guangzhou, China, decided to find out whether this regrowth signalled that the body is capable of regenerating an entire lens. The scientists began a series of animal studies to assess whether lens epithelial stem/progenitor cells (LECs) that exist naturally in a fully formed mammalian eye can produce a new lens. Encouraged by the results, the team developed a surgical technique and tested it in rabbits, macaque monkeys and, finally, 12 human infants. \n             Next steps \n           The standard surgical treatment for cataracts in children involves cutting a 6-millimetre slit in the centre of the lens capsule. This opening allows the surgeon to remove a patient\u2019s diseased lens and replace it with an artificial one, but it also results in the loss of many LECs. In the new method, surgeons slice a 1.5-millimetre opening in the side of the lens capsule to remove the diseased lens, prompting the eye\u2019s LECs to grow a new one. In initial tests, this approach produced a much lower rate of complications \u2014 17% \u2014 than the 92% seen after typical cataract surgery. And the lenses generated did not grow opaque as artificial lenses tend to do. The first infant treated using the method underwent surgery two years ago and still has good vision, says Zhang. He says that the regenerated lens should grow as the child grows, which could reduce later complications. But there are still difficulties to be worked out. Babies born with cataracts often have genetic mutations that will cause a new lens to become cloudy again. And surgery alone may not work for elderly adults \u2014 the people most likely to suffer from cataracts \u2014 because their cells regenerate relatively slowly. (Even in babies treated with the method, growing a new lens takes three months.) Still, Funderburgh is enthusiastic about the technique. \u201cEven if it\u2019s only for kids, it\u2019s fantastic,\u201d he says. Read the related  News & Views .  Tweet   Follow @NatureNews \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Stem cells pass safety test in vision-loss trial 2015-Apr-30 \n                 \n                   Japanese woman is first recipient of next-generation stem cells 2014-Sep-12 \n                 \n                   Curing blindness: Vision quest 2014-Sep-10 \n                 \n                   Biologists grow human-eye precursor from stem cells 2012-Jun-15 \n                 Reprints and Permissions"},
{"file_id": "531150a", "url": "https://www.nature.com/articles/531150a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "The pressure is on to choose between several proposals for space-based detectors. In the wake of last month\u2019s historic detection of gravitational waves by a US-led collaboration, a range of Chinese proposals to take studies of these ripples in space-time to the next level are attracting fresh attention. The suggestions, from two separate teams, are for space-based observatories that would pick up a wider range of gravitational radiation than ground-based observatories can. The most ambitious plan could give China an edge over the leading European proposal to detect gravitational waves from space, but whether a single country can achieve that on its own is unclear. Also under consideration are a possible collaboration between Chinese researchers and the European effort, and a cheaper Chinese plan. Although an Earth-based detector \u2014 the US Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) \u2014  was the first to confirm a prediction made by Albert Einstein  a century ago,  launching the field of gravitational-wave astronomy , such detectors can pick up only limited frequencies. Advanced LIGO compares laser light beamed along two perpendicular detector arms to reveal whether one beam has been compressed or stretched by gravitational waves. Each LIGO arm measures 4\u00a0kilo\u00admetres, but picking up the frequencies that are richest in gravitational waves requires distances of hundreds of thousands of kilometres or more. This can be achieved only in space, where spacecraft equipped with lasers can be positioned at these distances. Space-based detectors also avoid fluctuations in Earth\u2019s gravitational field, which can obscure signals. With such considerations in mind, the European Space Agency (ESA) is pursuing a  space-based gravitational-wave detector . One of the Chinese proposals, Taiji, meaning \u2018supreme ultimate\u2019, is to create a more ambitious version of the leading proposal for the European project, which is called eLISA (Evolved Laser Interferometer Space Antenna). Like eLISA, Taiji would consist of a triangle of three spacecraft in orbit around the Sun, which bounce lasers between each other (see \u2018China\u2019s choices\u2019). The distance between eLISA\u2019s components is still under discussion, but current plans suggest it could be 2\u00a0million kilometres, says eLISA member Karsten Danzmann of the Max Planck Institute for Gravitational Physics in Hanover, Germany. Taiji\u2019s spacecraft would be separated by 3\u00a0million kilometres, giving the detector access to different frequencies. Taiji would launch in 2033, slipping in a year ahead of eLISA\u2019s current schedule. \u201cIf Taiji produces a Chinese version of eLISA, then it will bring China to the frontier,\u201d says Yanbei Chen, a gravitational-wave physicist at the California Institute of Technology in Pasadena, who works on LIGO. Gerhard Heinzel, an eLISA physicist also at the Max Planck Institute in Hanover, cautions against a single country going it alone on such a large project. It \u201cis definitely too big \u2014 mainly in terms of cost but also resources in terms of scientists and experts in the presence of competing science projects\u201d, he says. Taiji project leader Wu Yue-Liang, a particle physicist at the Chinese Academy of Sciences\u2019 Institute of Theoretical Physics in Beijing, estimates that the project will cost 14\u00a0billion yuan (US$2\u00a0billion), roughly twice as much as ESA is budgeting for its gravitational-wave detector. \n               Second string \n             A second Chinese proposal, led by Luo Jun, a physicist at the Sun Yat-Sen University campus in Zhuhai, would lower the bar in terms of cost and resources. Called TianQin, a name that refers to the metaphor of nature playing a stringed instrument (a zither) in space, the project has three satellites that orbit Earth at a distance of about 150,000 kilometres from each other. It would cost 2\u00a0billion yuan, says Luo. TianQin would be more limited than Taiji in terms of what it could detect: rather than acting as an observatory for the waves emitted by myriad objects including black holes and neutron stars, it would mainly target a particular pair of orbiting white dwarf stars, called HM\u00a0Cancri. TianQin\u2019s simplicity makes it cheaper and more certain of success, Luo says. The spacecraft could launch in 15\u201320\u00a0years, he adds, around the same time as the Taiji group says that it could launch. Luo thinks that a simpler project is more realistic now, but says that TianQin could lay the groundwork for a Taiji-like project in the future. Wu Ji, director-general of the Chinese Academy of Sciences\u2019 National Space Science Center, says that the TianQin and Taiji teams should merge. \u201cIf China decides to have a space gravitational mission, there should be an integrated one, with a new name probably. There is no way to support two missions at the same time.\u201d Both Wu Yue-Liang and Luo are confident that their proposals will move forward to the concrete design phase in the next five years. Taiji currently receives money from the Chinese Academy of Sciences and TianQin from the city of Zhuhai \u2014 but both need much more cash. The LIGO discovery could increase their chances of success. The \u201cgovernment will know more the importance of fundamental research\u201d in gravitational waves, says Wu Ji. \u201cChina should catch up in this area,\u201d he adds. On 5\u00a0March, the Chinese central govern\u00adment released a draft list of 100\u00a0strategic projects that will be emphasized in the country\u2019s next five-year plan, which includes \u201ca new generation of heavy launch vehicles, satellites, space platforms and new payload\u201d and a \u201cdeep-space station\u201d. Chinese researchers could also end up collaborating with Europe. As well as its main project, the Taiji group has outlined the possibility of a direct collaboration with eLISA: it would either contribute 1.5\u00a0billion yuan directly or develop its own scaled-down, 8-billion-yuan version of eLISA that would coordinate closely with the European effort, sharing data. Heinzel recommends that a united Chinese group work on one of these less ambitious options. The direct contribution from China in particular could be a boon for eLISA. Originally, NASA collaborated with ESA on a planned space-based gravitational-wave observatory, named LISA. But  the United States pulled out of LISA five years ago  and ESA had to pare down the mission, resulting in the eLISA proposal. China\u2019s entry into the project could fill that hole, says Rainer Weiss, a physicist at the Massachusetts Institute of Technology in Cambridge, who is credited as the chief inventor of LIGO. This would perhaps allow Europe to pursue a design closer to that of LISA, which was better equipped than the eLISA proposal and would have had a longer mission lifetime. A decision is needed soon if China is to achieve a launch date around 2030, cautions Heinzel. \u201cNow is the time to do very serious technology development,\u201d he says. \u201cIt is time to start making decisions.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Successful test drive for space-based gravitational-wave detector 2016-Feb-25 \n                   \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     Freefall space cubes are test for gravitational wave spotter 2015-Nov-17 \n                   \n                     eLISA \n                   \n                     TianQin \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19545", "url": "https://www.nature.com/articles/nature.2016.19545", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Instrument problems prevented Martian lander from launching in March 2016 as planned. NASA has rescheduled the launch of its Mars InSight spacecraft for May 2018 \u2014  delaying its send-off by 26 months . InSight was originally set to launch this month, but NASA called off those plans in December 2015 because of  leaks in the spacecraft's primary scientific instrument , a seismometer. The space agency said then that it was considering whether to cancel the mission outright. The seismometer, built by the French space agency CNES, will be repaired in time to make the 2018 launch window, said Jim Green, head of NASA's planetary sciences division in Washington DC. \u201cThat's terrific news,\u201d he told a planetary sciences advisory panel on 9 March. The Jet Propulsion Laboratory in Pasadena, California, will assume responsibility for building a new vacuum enclosure for the seismometer, to address the problems that prevented InSight from launching this month. NASA did not say how much the delay might cost. Green said that the money needed to continue the mission would come from NASA's planetary sciences budget, but did not specify how it might affect other missions under development in the Discovery class, to which the US$425-million InSight belongs. \n             Bumper crop? \n           NASA is currently considering  five Discovery ideas  \u2014 including missions to Venus and asteroids \u2014 and will choose at least one later this year to develop towards flight, probably in the early 2020s. Because the agency has not been flying Discovery missions as frequently as it would like, Green has been considering whether to pick two proposed missions from the current crop. All five are currently working through \u2018Phase A\u2019 studies, which include detailed engineering analyses in order to develop cost estimates. \u201c We can only know if we can select more than one based on the Phase A studies,\u201d Green said. \u201cAt that point we will have the information necessary.\u201d Those numbers are expected later this year. InSight \u2014 which stands for Interior Exploration using Seismic Investigations, Geodesy and Heat Transport \u2014 is currently in storage at Lockheed Martin Space Systems in Denver, Colorado, which built the spacecraft. The mission is meant to study the Martian interior by using the seismometer to monitor marsquakes ringing through the planet. If the spacecraft launches in May 2018, it would arrive at Mars in November of that year. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   NASA cancels March launch to Mars 2015-Dec-22 \n                 \n                   NASA Mars mission suffers problem with key instrument 2015-Dec-03 \n                 \n                   NASA narrows its list of planetary targets 2015-Sep-30 \n                 \n                   InSight home page \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19543", "url": "https://www.nature.com/articles/nature.2016.19543", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Genetic study deals blow to the idea that high levels of HDL cholesterol reduce heart risk. For decades, guidance on cholesterol levels has come as a tidy dichotomy: LDL cholesterol is \u2018bad\u2019 for heart health; HDL cholesterol is \u2018good\u2019. But a genetic study adds to mounting evidence that the truth is not so simple \u2014 and that having high levels of HDL cholesterol may not protect against heart disease. The study, published on 10 March in  Science 1 , pitted the genomes of 852 people with high levels of HDL (high-density lipoprotein) cholesterol in their blood against those of a control group of 1,156 people with low HDL cholesterol. The approach unearthed mutations in a protein called SR-BI that binds to HDL cholesterol and triggers its movement from the blood into the liver. Those who carried the mutations tended to have high HDL cholesterol levels in the blood, as expected. But they were also, paradoxically, at higher risk for coronary heart disease. \u201cWhen I started medical school in 1992, I was taught that anything that raised HDL cholesterol must be good for you,\u201d says Sekar Kathiresan, a preventative cardiologist at the Massachusetts General Hospital in Boston, and a co-author of the study. \u201cWe can now safely disregard that notion.\u201d \n             Cause versus effect \n           LDL cholesterol is believed to collect in the walls of blood vessels, ultimately blocking the flow of blood and leading to heart attacks and strokes. A large body of  genetic and molecular studies , and the rampant success of  some drugs that lower LDL cholesterol , back up this idea. The role of HDL, however, has been less clear. Although higher HDL cholesterol levels are correlated with better heart health, efforts to show that HDL cholesterol has a protective effect in humans have come up empty-handed. Pharmaceutical companies have poured millions of dollars into the pursuit of drugs that would raise HDL cholesterol. So far, none has been shown to protect the heart. One promising compound,  called anacetrapib  and developed by Merck of Kenilworth, New Jersey, is in late-stage clinical trials. But the drug also lowers LDL cholesterol, making it difficult to infer whether its effects on heart health are truly related to HDL cholesterol, cautions Monty Krieger, a molecular cell biologist at the Massachusetts Institute of Technology in Cambridge. Krieger\u2019s team has shown that mice that lacked SR-BI had high levels of HDL cholesterol in their blood 2 . But despite HDL cholesterol's 'good' reputation, the mice also had high rates of plaque build-up in their arteries, a condition known as atherosclerosis. It was important to find out whether the same would be true in humans, notes Krieger, because of key differences in mouse and human physiology. Mice, for example, tend to have less LDL than humans. Kathiresan and his colleagues found 19 people with at least one copy of the mutation in SR-BI. Sixteen of those participants also had high HDL cholesterol levels. One woman was the first person found to have two copies of the mutation. \n             A cleaner study \n           That represents a breakthrough, says Jay Heinecke, an endocrinologist at the University of Washington in Seattle. Previous genetic analyses in humans were confounded by a focus on genes that could affect physiology in other ways, for example by altering the levels of other fatty molecules called triglycerides. \u201cThis is a cleaner study,\u201d he says. \u201cThis will force us to re-evaluate how we\u2019ve been thinking about HDL cholesterol from the beginning.\u201d But Krieger, who agrees that the study is important, notes that SR-BI could have other functions that have not yet been characterized, and that many animal studies have suggested a role for HDL cholesterol in protecting against heart disease. Kathiresan\u2019s study also raises an important question: why are higher levels of HDL cholesterol in the blood associated with reduced heart risk? Some have argued that other functions of HDL cholesterol \u2014 not fully reflected by its concentration in the blood \u2014 could be important. Kathiresan suspects that people with high HDL cholesterol levels may also be better at clearing triglycerides from the blood. For now, Kathiresan thinks there is evidence that physicians should change how they discuss HDL-cholesterol with their patients. \u201cWe probably should stop using the term good cholesterol,\u201d he says. Explaining the difference between correlation and causation makes for a more complicated conversation, he adds. \u201cThe analogy I use is grey hair: if you have grey hair, you are at higher risk of heart disease on average,\u201d Kathiresan says. \u201cBut that\u2019s not because of the grey hair.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Drug trial supports importance of low cholesterol to treat heart disease 2014-Nov-17 \n                 \n                   Genetics: A gene of rare effect 2013-Apr-09 \n                 \n                   Cholesterol limits lose their lustre 2013-Feb-26 \n                 \n                   Good news for 'good' cholesterol 2010-Nov-17 \n                 \n                   Blogpost: New cholesterol drugs make strides in clinical trials \n                 \n                   Blogpost: Cholesterol guidelines back away from high-dose statin regimens \n                 \n                   US Centers for Disease Control and Prevention: \u201cBad\u201d and \u201cGood\u201d Cholesterol \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19534", "url": "https://www.nature.com/articles/nature.2016.19534", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Electrical stimulation seems to boost endurance in preliminary studies. Elite ski jumpers rely on extreme balance and power to descend the steep slopes that allow them to reach up to 100 kilometres per hour. But the US Ski and Snowboard Association (USSA) is seeking to give its elite athletes an edge by training a different muscle: the mind. Working with Halo Neuroscience in San Francisco, California, the sports group is testing whether stimulating the brain with electricity can improve the performance of ski jumpers by making it easier for them to hone their skills. Other research suggests that targeted brain stimulation can reduce an athlete\u2019s ability to perceive fatigue 1 . Such technologies could aid recovery from injury or let athletes try 'brain doping' to gain a competitive advantage. Yet many scientists question whether brain stimulation is as effective as its proponents claim, pointing out that studies have looked at only small groups of people. \u201cThey\u2019re cool findings, but who knows what they mean,\u201d says cognitive psychologist Jared Horvath at the University of Melbourne in Australia. The USSA is working with Halo to judge the efficacy of a device that delivers electricity to the motor cortex, an area of the brain that controls physical skills. The company claims that the stimulation helps the brain to build new connections\u00a0as it learns a skill. It tested its device in an unpublished study of seven elite Nordic ski jumpers, including Olympic athletes. Four times per week, for two weeks, the skiers practised jumping onto an unstable platform. Four athletes received transcranial direct-current stimulation (tDCS) as they trained; the other three received a sham procedure. The stimulation ultimately improved the athletes' jumping force by 70% and their coordination by 80%, compared with the sham group, Halo announced in February. Troy Taylor, high-performance director for the USSA, is encouraged by the results \u2014 but concedes that they are preliminary. \n               Pushing the limits of endurance \n             Another study, presented on 7 March at the Biomedical Basis of Elite Performance meeting in Nottingham, UK, suggests that tDCS may reduce the perception of fatigue. Sports scientist Lex Mauger of the University of Kent in Canterbury, UK, and his colleagues found that stimulating the motor-cortex region that controls leg function allows cyclists to pedal longer without feeling tired. The researchers stimulated the brains of 12 untrained volunteers before directing the athletes to pedal stationary bicycles until they were exhausted. Every minute, they asked the cyclists to rate their level of effort. Volunteers who received tDCS were able to pedal two minutes longer, on average, than were those who were given a sham treatment. They also rated themselves as less tired. But there was no difference in heart rate or the lactate level in the muscles between the treatment and control groups. This suggests that changes in brain perception, rather than muscle pain or other body feedback, drove the improved performance. Alexandre Okano, a biological engineer at Federal University of Rio Grande do Norte in Brazil, found similar increases in cyclists\u2019 performance when he stimulated the brain\u2019s temporal cortex, which is involved in body awareness and in automatic functions such as breathing 2 . This suggests that the temporal and motor cortices are connected in ways that are not understood, or that tDCS does not target locations in the brain precisely, Okano says. These results support the notion that the brain manages exertion by collating feedback from the body and then slowing muscles to prevent fatigue, says Dylan Edwards, a neurophysiologist at Burke Medical Research Institute in White Plains, New York 3 . \u201cEven when you think you\u2019re exercising as hard as you can, there is always some reserve of ability,\u201d he says. \n               Tricky tests \n             But Horvath cautions that little is known about the long-term effects of stimulating the brain. And others are sceptical of the technique\u2019s potential to increase performance. Vincent Walsh, a neuroscientist at University College London, notes that the methods used in tDCS studies often differ between research groups \u2014 and might not always be optimized. For instance, the fairly intense amount of electricity that Mauger's team used has been shown to sometimes have complex and unintended effects on the brain's activity 4 . Replicating such experiments is difficult because of variations in how people respond to brain stimulation. Some people do not respond at all; others might respond only when stimulated in a certain way. And even an individual\u2019s response can differ from day to day. Edwards says that it is important to map these differences if tDCS is to be used therapeutically or for other purposes. \u201cWe\u2019re moving toward customized prescription of brain stimulation,\u201d he says. Nonetheless, the use of tDCS in sports is only likely to increase. Stimulating the motor cortex, for instance, seems to increase dexterity, so videogamers have been quick to take up the technique. And it is increasingly easy to acquire stimulation devices; Halo has begun to market its equipment for the express purpose of increasing athletic performance. Taylor compares the use of brain stimulation by athletes to eating carbohydrates ahead of an athletic event, in the hopes of boosting endurance. \u201cIt piggybacks on the ability to learn,\u201d he says. \u201cIt's not introducing something artificial into the body.\u201d But Edwards worries that the availability of tDCS devices will tempt athletes to try \u201cbrain doping\u201d, in part because there is no way to detect its use. \u201cIf this is real,\u201d he says, \u201cthen absolutely the Olympics should be concerned about it.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Brain power 2016-Mar-02 \n                   \n                     Brain stimulation in children spurs hope \u2014 and concern 2015-Sep-23 \n                   \n                     Performance enhancement: Superhuman athletes 2012-Jul-18 \n                   \n                     Biomedical Basis of Elite Performance 2016 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19549", "url": "https://www.nature.com/articles/nature.2016.19549", "year": 2016, "authors": [{"name": "Devin Powell"}], "parsed_as_year": "2006_or_before", "body": "Plan to postpone launch of InSight probe will cost agency an extra US$150 million. Cracks in an instrument designed to detect earthquakes on Mars will add roughly US$150 million to the price tag of InSight, NASA\u2019s next mission to the red planet. But the agency said on 9 March that it still intends to fly the spacecraft, raising questions about how the unexpected expense will affect other planetary missions in development. And although InSight\u2019s launch \u2014  originally scheduled  for this month \u2014 is now slated for May 2018, it is not clear whether  the spacecraft's faulty seismometer  will be ready in time. InSight seeks  to investigate Mars\u2019s interior  by measuring seismic activity, the heat that is escaping from the planet and the movement of its surface. \u201cWe\u2019re really grateful that NASA has recognized the value of science we\u2019re going to do and agreed to give us a chance to try it again,\u201d says InSight\u2019s principal investigator, Bruce Banerdt of NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California. The spacecraft was developed as part of NASA\u2019s Discovery Program, which funds small, quick-turnaround missions whose cost is capped at $450 million.  Five proposed missions  are currently vying for a chance to launch in the early 2020s. These include a trip to Jupiter\u2019s Trojan asteroids, two missions to Venus and a camera to detect near-Earth objects. \u201cNASA has been trying to choose two missions out of this round instead of one, and the community\u2019s concern is that the likelihood of that happening might be falling,\u201d says Linda Elkins-Tanton, a planetary scientist at Arizona State University in Tempe and the principal investigator of a proposed mission to the asteroid Psyche. Jim Green, director of NASA\u2019s planetary-science division in Washington DC, says that budget details and consequences to other planetary missions will be worked out by August. \u201cOur ability to select at least one Discovery mission in December is expected to be unaffected,\u201d he says. \n               Sealing the deal \n             Then there is the matter of whether Insight's troubled seismometer, which was developed by a global collaboration led by the Institut de Physique du Globe in Paris, can be repaired. Banerdt says that Sodern, the French company subcontracted to build a vacuum container to enclose the seismometer\u2019s sensors, did not detect problems with connectors that are supposed to seal wires leading out of the vacuum housing. Only when the instrument was tested in frigid, Mars-like temperatures in December did cracks in those seals become apparent. The project team tried to patch the problem, but persistent leaks remained. \u201cIt\u2019s very frustrating,\u201d says Banerdt. \u201cI\u2019ve been working on getting this kind of mission for more than 25 years, and everything else on the project was going really well.\u201d NASA has asked the JPL to craft a new, hardier vacuum chamber. The agency\u2019s French collaborators will test the chamber on their own dime. \u201cPersonally, I am relieved to know that JPL will be taking responsibility for the vacuum chamber,\u201d says Lisa Pratt, a biogeochemist at Indiana University Bloomington. The Mars InSight team is now re-running landing simulations and recalculating orbits to account for the updated launch date. Some wonder if the mistake may cause NASA to tighten the reins on future projects. The most recent call for Discovery proposals, made before the problem with InSight occurred, mandated that no more than one-third of instrument costs could be spent on foreign sources. \u201cThe word on the street is that NASA\u2019s a little more wary of collaborating with groups that they don\u2019t know so well or don\u2019t control directly,\u201d says Elkins-Tanton. But Green argues that any nation trying to build a new instrument could have made this mistake.\"This is the first time this type of instrument has been built to withstand harsh environmental conditions on another planet,\" he says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     NASA reschedules troubled Mars InSight mission to 2018 2016-Mar-09 \n                   \n                     NASA cancels March launch to Mars 2015-Dec-22 \n                   \n                     NASA Mars mission suffers problem with key instrument 2015-Dec-03 \n                   \n                     NASA narrows its list of planetary targets 2015-Sep-30 \n                   \n                     Blog: NASA selects mission to explore interior of Mars \n                   \n                     NASA Mars InSight mission website \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19547", "url": "https://www.nature.com/articles/nature.2016.19547", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Joint ExoMars mission\u00a0launches\u00a0lander and orbiter \u2014 a rover\u00a0is planned for\u00a02018. Neither Europe nor Russia has ever successfully operated a mission on Mars\u2019s surface. Now the European Space Agency (ESA) and its Russian counterpart Roscosmos hope to mark a first for both organizations, with a joint mission that launched from the Baikonur Cosmodrome in Kazakhstan on 14 March. Known as ExoMars 2016, it consists of a lander that will study the planet\u2019s dust storms, and an orbiter that will analyse its atmosphere, including looking for methane. The orbiter will also act as a relay for a follow-up Mars rover, due to be launched in 2018. Each phase of the mission will be a test of the growing collaboration between the two space agencies, which have hinted at future joint missions, including teaming up for  uncrewed and crewed Moon trips . ESA designed the orbiter and lander projects but a Russian rocket launched them and they carry Russian instruments. \u201cThe launch is crucial because it\u2019s symbolic,\u201d says Oleg Korablev of the Space Research Institute, Moscow, who is principal investigator for the Atmospheric Chemistry Suite on the orbiter. \"It's psychologically very important.\" ESA project scientist Jorge Vago adds: \u201cHopefully this will cement a way of doing things that becomes the modus operandi for when we do missions together.\u201d Based at the European Space Research and Technology Centre in Noordwijk, the Netherlands, Vago also works on the ExoMars 2018 mission, which will be a joint operation that integrates the teams more tightly. \n               Two-stage mission \n             ESA approved the ExoMars concept in 2005; a subsequent merry-go-round of collaborators eventually resulted in the Europe\u2013Russia collaboration and ExoMars\u2019s unusual two-stage format (see 'Mission merry-go-round'). A Russian Proton rocket launched the ExoMars 2016 craft \u2014 at 4,332 kilograms, the heaviest Mars mission ever to take to the skies. There will now be four rocket burns over 10 hours before the spacecraft begins its trajectory towards Mars. A favourable alignment between Earth and the red planet means that ExoMars should reach its Martian orbit after 7 months; the orbiter and landing module, known as Schiaparelli, will separate three days before reaching the Martian atmosphere.  The landing won\u2019t involve anything as complex as NASA\u2019s sky crane,  which delivered the Curiosity rover to Mars in 2012  during the Mars Science Laboratory (MSL) mission. But it is ambitious, says Vago, and designed to show that Europe has the know-how to make a controlled landing on Mars. Taking into account  lessons learned from Beagle 2  (Britain's failed 2003 Mars lander that was operated by ESA), the module will first use drag from the Martian atmosphere to brake, then open a parachute and eventually fire its thrusters. During the last 2 metres of its descent, travelling at a relatively sedate 10 kilometres an hour, Schiaparelli will deploy a honeycomb-like crash pad and come to rest on the surface. The first lander to set down during dust-storm season, Schiaparelli will monitor pressure and temperature and image the approaching landing site during its descent. On the ground, the conical lander has just 2\u20134 days of battery power to perform experiments. Its tiny meteorological station DREAMS (Dust Characterisation, Risk Assessment, and Environment Analyser on the Martian Surface) will measure pressure, humidity, temperature, wind speed and direction. This represents a unique chance to study dust circulation and hopefully unravel the mystery of why some storms on Mars go planet-wide, says Francesca Esposito at the INAF Astronomical Observatory of Capdiomonte in Naples, Italy, and the principal investigator for DREAMS. The Schiaparelli lander will also be the first to examine the planet\u2019s electric field. Those data will feed into Martian climate models and could allow scientists to better predict future disturbances to communications on the planet, she says. \n               Biological studies \n             The higher-profile science \u2014 including investigating hints of Martian biology \u2014 will take place in the sky on board ExoMars\u2019 Trace Gas Orbiter (TGO). That phase will begin at the end of 2017, once the craft has manoeuvred into a circular, 400-kilometre-high orbit. While studying Mars\u2019s atmosphere, the TGO\u2019s major task will be to follow up on evidence that the red planet contains methane, which has been associated with active geological processes, as well as biological ones. \u201cIs there a seasonality to the methane, or are the concentrations associated with particular types of terrain, for instance?\u201d asks John Bridges, a planetary scientist at the University of Leicester, UK, who works on the TGO\u2019s stereo camera. The camera will use 3D images to chart geological features, and a hydrogen detector will map the planet\u2019s subsurface water. The orbiter will also serve as a communications platform, including for  ExoMars\u2019s future rove r, which will break new ground \u2014 literally. Armed with a drill, the rover will bore up to 2 metres into the planetary surface, where scientists hope that organic matter, which can be destroyed by surface radiation, may lie preserved. The rover will require the European and Russian teams to work together to an extent unprecedented for ESA, says Vago. In the 2016 mission, the responsibilities of the two teams are relatively separate, but in the 2018 mission, he says, \u201cthere is no clean line between them\u201d. As a result, each design tweak ripples through the work of both teams. \n               Slow progress \n             It is a new experience for Russia too, says Korablev, even though the country has long contributed scientific instruments to foreign space missions. \u201cThere are many problems, but there are always problems on national projects too,\u201d he says. \u201cSo I would say it was fine \u2014 slower, but not that much slower.\u201d This complexity, coupled with late-running instruments, delays in testing and a lack of cash, means that the 2018 rover mission could be delayed until 2020, says Vago. ESA\u2019s director-general,  Johann-Dietrich W\u00f6rner , said in January that the 2018 mission needed more funding to meet its launch target, and the agency is expected to ask member states for the missing few hundred million euros at a meeting in December. Success with ExoMars 2016 could help to persuade European leaders to contribute, but Bridges says that most scientists will accept a delay as long as it means that all the instruments are on the craft and working. For now, the teams are focused on the complex launch and on the rocket\u2019s separation from the spacecraft. \u201cWe will be biting our nails all day on the 14th until we have successful separation,\u201d says Vago. Korablev\u2019s involvement with Mars missions has been an emotional rollercoaster. He spent 10 years working on Russia\u2019s Mars 96 orbiter, which in 1996  failed to leave near-Earth orbit . He faced disappointment again when a sample-return mission to the Martian moon Phobos  ran into problems , eventually  crashing in the Pacific Ocean in 2012 . \u201cWe put a great effort into ExoMars,\u201d he says. \u201cI almost don\u2019t dare to say any words.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Europe sets modest goals for space 2012-Nov-23 \n                   \n                     Europe looks to Russia after NASA falls short on ExoMars 2011-Oct-14 \n                   \n                     Joint Mars plans come together 2009-Aug-05 \n                   \n                     ExoMars \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19553", "url": "https://www.nature.com/articles/nature.2016.19553", "year": 2016, "authors": [{"name": "Tanguy Chouard"}], "parsed_as_year": "2006_or_before", "body": "Nature  reports from AlphaGo's triumph in Seoul. Seoul, South Korea Tanguy Chouard, an editor with  Nature , saw Google-DeepMind\u2019s AI system AlphaGo defeat a human professional for the first time last year at the ancient board game Go. This week, he is watching top professional Lee Sedol take on AlphaGo, in Seoul, for a $1 million prize. So that\u2019s it \u2014 this morning Google DeepMind\u2019s AI machine AlphaGo claimed a decisive victory against Lee Sedol by winning its third game in a row, meaning that the computer has now triumphed in the best-of-five tournament in Seoul. For me, the drama that was set up at the start of this matchup \u2014 man vs machine in humanity\u2019s most complex board game! \u2013 has faded away. The surprise now will be if Lee, who is one of the world\u2019s top players of Go over the past decade, manages to win a single game against the AI system. Everyone wants Lee to win \u2013 but the cliche is going around here that his only chance is to pull out AlphaGo\u2019s power plug. \n             Comprehensively outplayed \n           At the press conference after this deciding match in the series, the Google DeepMind team were polite and respectful \u2014 praising Lee for his \u201camazing genius and creative skills\u201d, while official commentator Michael Redmond added that the South Korean professional had \u201cplayed his best\u201d. Lee himself couldn\u2019t disagree more. Speaking through a translator, he apologized for his play in this third game. Not that he had given up before the contest. He spent Thursday night studying the two first games with a group of fellow Korean professional players, and then kept playing more relaxed baduk on his resting day, I was told by Lee Hajin, Secretary General of the International Go Federation. But at the press conference, Lee Sedol said that he\u2019d never felt as much pressure as he did in game 3. And while he had identified missed opportunities in game 2, he felt he could not win game 1 even if he replayed it today. Independent commentators agreed that the machine had comprehensively outplayed the human. Andy Jackson, the vice president of the American Go Association (AGA), told me that Lee had lost the third game very early, by move 35. (A DeepMind scientist who was passing at the time said that this was in agreement with AlphaGo\u2019s internal evaluation of its winning chances). Lee is clearly trying to probe AlphaGo\u2019s weaknesses. Today he engaged the computer in a series of \u2018 ko fights \u2019 \u2013 sharp strategic battles \u2014 but failed to get the upper hand. The blogosphere had been buzzing over the possibility that AlphaGo might be \u2018afraid\u2019 of this kind of play. \u201cWell, we\u2019ve settled that one,\u201d said Thore Graepel, one of the system\u2019s developers. \n             Unknowable wisdom \n           Go commentators are thrilled by the way the machine plays. \u201cI love AlphaGo! I want to study it and learn from it!\u201d said Cho Hyeyeon, one of the strongest female Go players in Korea, who was commentating on the  AGA live-feed of the match . \u201cAlphaGo seems like it knows everything!\u201d Cho \u2014 and everybody else \u2014 wants to know just what AlphaGo is thinking. It seems to have a different vision of how to play the game. Alas, I\u2019m afraid its understanding is simply unknowable \u2013 and not just because the computer has no voice to express its evaluations. As DeepMind scientist David Silver explained to the press this January, even though AlphaGo has effectively rediscovered the most subtle concepts of Go (such as  sente ,  moyo ,  aji  or, now we know,  ko fights ), its knowledge of these is implicit. The computer doesn't explicitly parse out these concepts \u2013 they simply emerge from its statistical comparisons of types of winning board positions at Go. In effect, AlphaGo has a kind of  digital intuition . I actually feel that, even though we are reaching the end of this week of top-level testing, we have only seen the beginning of the system\u2019s mastery. To reveal the full potential of the machine, top professional players may soon have to receive handicap advantages to play it. \n             Computerized hustler \n           The algorithm seems to be holding back its power. Sometimes it plays moves that lose material because it is seeking simply to maximise its probability of reaching winning positions, rather than \u2014 as human players tend to do \u2014 maximise territorial gains. Jackson thinks that some of these odd-looking moves may have fooled Lee into underestimating the machine\u2019s skills at the beginning of game 1 \u2014 which, I suppose, makes AlphaGo a kind of computerized hustler. Towards the end of today\u2019s press conference, Lee insisted that the clinching defeat was \u201cLee Sedol\u2019s defeat, not the defeat of mankind.\u201d That would seem to imply that he wasn\u2019t best placed to represent humanity this week \u2014 a suggestion that\u2019s been rather rudely made by the world\u2019s current top-ranked go player, Ke Jie, who said that \u201c AlphaGo can\u2019t beat me \u201d. Most commentators I\u2019ve talked to would disagree. AlphaGo is likely to start \u201ca new revolution\u201d in the way we play Go, says Redmond. He said at the press conference that the Google DeepMind team had \u201ccreated a work of art.\u201d Says Cho: \u201cwe have to admit that we\u2019re faced with the best player \u2026 of the past two thousand years.\" One can only imagine what this kind of AI system will be capable of when applied to other problems. As Hassabis  has said , one could easily conceive of translating AlphaGo\u2019s qualities of pattern recognition, decision-making and long-term planning to, for example, a system that digests clinical data to make diagnoses or treatment plans. One caution though: AlphaGo has proved itself supremely capable of reaching winning positions in the black and white game of Go \u2014 where the board game\u2019s rules define what these positions are. But if we are to delegate decision-making in the more complex, nuanced real world to AI systems, we had better be careful to define what \u2018winning positions\u2019 we want them to reach. And that will be a political, not an engineering, issue. \n             Previous entry:  \n             AI computer wins first match against master Go player \n              | Next entry:  \n             AI computer wraps up 4-1 victory \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The Go Files: \u2018Humanity-packed\u2019 AI prepares to take on world champion 2016-Mar-07 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Digital intuition 2016-Jan-27 \n                 \n                   Go players react to computer defeat 2016-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19550", "url": "https://www.nature.com/articles/nature.2016.19550", "year": 2016, "authors": [{"name": "Evelyn Lamb"}], "parsed_as_year": "2006_or_before", "body": "Last digits of nearby primes have \u2018anti-sameness\u2019 bias. Two mathematicians have found a strange pattern in prime numbers \u2014 showing that the numbers are not distributed as randomly as theorists often assume. \u201cEvery single person we\u2019ve told this ends up writing their own computer program to check it for themselves,\u201d says Kannan Soundararajan, a mathematician at Stanford University in California, who reported the discovery with his colleague Robert Lemke Oliver in a  paper submitted to the arXiv preprint server  on 11 March 1 . \u201cIt is really a surprise,\u201d he says. Prime numbers near to each other tend to avoid repeating their last digits, the mathematicians say: that is, a prime that ends in 1 is less likely to be followed by another ending in 1 than one might expect from a random sequence. \u201cAs soon as I saw the numbers, I could see it was true,\u201d says mathematician James Maynard of the University of Oxford, UK. \u201cIt\u2019s a really nice result.\u201d Although prime numbers are used in a number of applications, such as cryptography, this \u2018anti-sameness\u2019 bias has no practical use or even any wider implication for number theory, as far as Soundararajan and Lemke Oliver know. But, for mathematicians, it\u2019s both strange and fascinating. \n             Not so random \n           A clear rule determines exactly what makes a prime: it\u2019s a whole number that can\u2019t be exactly divided by anything except 1 and itself. But there\u2019s no discernable pattern in the occurrence of the primes. Beyond the obvious \u2014 after the numbers 2 and 5, primes can\u2019t be even or end in 5 \u2014 there seems to be little structure that can help to predict where the next prime will occur. As a result, number theorists find it useful to treat the primes as a \u2018pseudorandom\u2019 sequence, as if it were created by a random-number generator. But if the sequence were truly random, then a prime with 1 as its last digit should be followed by another prime ending in 1 one-quarter of the time. That\u2019s because after the number 5, there are only four possibilities \u2014 1, 3, 7 and 9 \u2014 for prime last digits. And these are, on average, equally represented among all primes, according to a theorem proved around the end of the nineteenth century, one of the results that underpin much of our understanding of the distribution of prime numbers. (Another is the prime number theorem, which quantifies how much rarer the primes become as numbers get larger.) Instead, Lemke Oliver and Soundararajan saw that in the first billion primes, a 1 is followed by a 1 about 18% of the time, by a 3 or a 7 each 30% of the time, and by a 9 22% of the time. They found similar results when they started with primes that ended in 3, 7 or 9: variation, but with repeated last digits the least common. The bias persists but slowly decreases as numbers get larger. \n             The k-tuple conjecture \n           The mathematicians were able to show that the pattern they saw holds true for all primes, if a widely accepted but unproven statement called the Hardy\u2013Littlewood  k -tuple conjecture is correct. This describes the distributions of pairs, triples and larger prime clusters more precisely than the basic assumption that the primes are evenly distributed. The idea behind it is that there are some configurations of primes that can\u2019t occur, and that this makes other clusters more likely. For example, consecutive numbers cannot both be prime \u2014 one of them is always an even number. So if the number  n  is prime, it is slightly more likely that  n  + 2 will be prime than random chance would suggest. The  k -tuple conjecture quantifies this observation in a general statement that applies to all kinds of prime clusters. And by playing with the conjecture, the researchers show how it implies that repeated final digits are rarer than chance would suggest. At first glance, it would seem that this is because gaps between primes of multiples of 10 (20, 30, 100 and so on) are disfavoured. But the finding gets much more general \u2014 and even more peculiar. A prime\u2019s last digit is its remainder when it is divided by 10. But the mathematicians found that the anti-sameness bias holds for any divisor. Take 6, for example. All primes have a remainder of 1 or 5 when divided by 6 (otherwise, they would be divisible by 2 or 3) and the two remainders are on average equally represented among all primes. But the researchers found that a prime that has a remainder of 1 when divided by 6 is more likely to be followed by one that has a remainder of 5 than by another that has a remainder of 1. From a 6-centric point of view, then, gaps of multiples of 6 seem to be disfavoured. Paradoxically, checking every possible divisor makes it appear that almost all gaps are disfavoured, suggesting that a subtler explanation than a simple accounting of favoured and disfavoured gaps must be at work. \u201cIt\u2019s a completely weird thing,\u201d says Soundararajan. \n             Mystifying phenomenon \n           The researchers have checked primes up to a few trillion, but they think that they have to invoke the  k -tuple conjecture to show that the pattern persists. \u201cI have no idea how you would possibly formulate the right conjecture without assuming it,\u201d says Lemke Oliver. Without assuming unproven statements such as the  k -tuple conjecture and the much-studied Riemann hypothesis, mathematicians\u2019 understanding of the distribution of primes dries up. \u201cWhat we know is embarrassingly little,\u201d says Lemke Oliver. For example, without assuming the  k -tuple conjecture, mathematicians have proved that the last-digit pairs 1\u20131, 3\u20133, 7\u20137 and 9\u20139 occur infinitely often, but they cannot prove that the other pairs do. \u201cPerversely, given our work, the other pairs should be more common,\u201d says Lemke Oliver. He and Soundararajan feel that they have a long way to go before they understand the phenomenon on a deep level. Each has a pet theory, but none of them is really satisfying. \u201cIt still mystifies us,\u201d says Soundararajan. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Maths whizz solves a master\u2019s riddle 2015-Sep-25 \n                 \n                   Maths world abuzz with prime proof 2003-Apr-09 \n                 \n                   Prime numbers not so random? 2003-Mar-24 \n                 Reprints and Permissions"},
{"file_id": "531286a", "url": "https://www.nature.com/articles/531286a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Sequence of 430,000-year-old DNA pushes back divergence of humans and Neanderthals. Matthias Meyer has just published the results of what may be the world\u2019s most wasteful genome-sequencing project. In decoding just 0.1% of the genome of the oldest DNA ever recovered from an ancient human, the molecular biologist at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, threw out enough raw data to map the modern human genome dozens of times over. But the excess was necessary, because the DNA in the 430,000-year-old bones was degraded and contaminated. Meyer\u2019s feat of recovery has revealed that the remains, from a cavern in northern Spain, represent early Neanderthals \u2014 and has pushed back estimates of the time at which the ancient predecessors of humans must have split from those of Neanderthals (M.\u00a0Meyer  et al. Nature  http://dx.doi.org/10.1038/nature17405 ; 2016). \u201cStarting such a thing is already very ambitious, and managing it is even more impressive,\u201d says Ludovic Orlando, an ancient-DNA researcher at the Natural History Museum of Denmark in Copenhagen. \u201cWe are really reaching the limits of what is possible.\u201d The analysis addresses confusion over which species the remains belong to. A  report published in 2013 sequenced a femur\u2019s mitochondrial genome  \u2014 which is made up of DNA from the cell\u2019s energy-producing structures that is more abundant in cells than is nuclear DNA. It suggested that at least one individual identified from the remains was more closely related to a group called Denisovans \u2014 known from remains found thousands of kilometres away in Siberia \u2014 than it was to European Neanderthals ( M. Meyer et al. Nature 505, 403\u2013406; 2014 ). \u201cIt\u2019s wonderful news to have mitochondrial and nuclear DNA from something that is 430,000\u00a0years old. It\u2019s like science fiction. It\u2019s an amazing opportunity,\u201d says Maria Martin\u00f3n-Torres, a palaeoanthropologist at University College London. The remains are known as the Sima hominins because they were found in Sima de los Huesos (Spanish for \u2018pit of bones\u2019), a 13-metre-deep shaft in Spain\u2019s Atapuerca mountains. Few ancient sites are as important or intriguing as Sima, which holds the remains of at least 28\u00a0individuals, along with those of dozens of cave bears and other animals. The hominins might have plummeted to their death, but some researchers think they were deliberately buried there. The Sima hominin skulls have the beginnings of a prominent brow ridge, as well as  other traits typical of Neanderthals . But other features, and uncertainties around their age \u2014 some studies put them at 600,000 years old, others closer to 400,000 \u2014 convinced many researchers that they might instead belong to an older species known as  Homo heidelbergensis. Confusion peaked when Meyer, his colleague Svante P\u00e4\u00e4bo and their team revealed the mitochondrial connection to the Denisovans. But they hoped that retrieving the skeletons\u2019 nuclear DNA \u2014 which represents many more lines of ancestry than does mitochondrial DNA, which is inherited solely from the maternal line \u2014 would clear things up. \n               Nuclear recovery \n             Meyer\u2019s team managed to glean nuclear and mitochondrial DNA from five Sima samples, probably representing different individuals. A key factor in their success, says Meyer, was that since 2006, archaeologists had carefully refrigerated teeth and shoulder-blade tissue from the pit to preserve the ancient DNA \u2014 awaiting advanced molecular-analysis techniques. The nuclear DNA, Meyer\u2019s team reports in  Nature  on 14\u00a0March, shows that the Sima hominins are in fact early Neanderthals. And its age suggests that the early predecessors of humans diverged from those of Neanderthals between 550,000 and 765,000 years ago \u2014 too far back for the common ancestors of both to have been  Homo heidelbergensis , as some had posited. Researchers should now be looking for a population that lived around 700,000 to 900,000\u00a0years ago, says Martin\u00f3n-Torres. She thinks that  Homo antecessor , known from  900,000-year-old remains from Spain , is the strongest candidate for the common ancestor, if such specimens can be found in Africa or the Middle East. The team\u2019s latest mitochondrial sequences, meanwhile, again confirm the puzzling link between the Sima hominins and the Denisovans. Meyer suggests that the ancestors of the two groups carried mitochondrial DNA that is reflected in both \u2014 but which is not present in later Neanderthals. This elimination could have happened by chance, but Meyer now favours the hypothesis that an as yet unknown species from Africa migrated to Eurasia and bred with Neanderthals, replacing the mitochondrial DNA lineages. (Supporting this idea, stone-tool technologies spread from Africa to Eurasia around half a million years ago, and again 250,000\u00a0years ago). It is hard to rule out these or other ideas without new data, says Meyer. The full or nearly full genome of a Sima hominin, or genetic data from other early Neanderthals, would be necessary. \u201cIt\u2019s fascinating and keeps us all on our toes trying to make sense of it all,\u201d says Chris Stringer, a palaeoanthropologist at the Natural History Museum in London. Stringer says that the recovery of such old nuclear DNA gives him hope that researchers will be able to analyse ancient DNA that stretches even further back in time. \u201cInstead of just being stuck with trying to resolve the last 100,000 years,\u201d he says, \u201cwe can really start to put some dates from DNA further down the human tree.\u201d\n \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Evidence mounts for interbreeding bonanza in ancient human species 2016-Feb-17 \n                   \n                     Human evolution: The Neanderthal in the family 2014-Mar-26 \n                   \n                     Hominin DNA baffles experts 2013-Dec-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19556", "url": "https://www.nature.com/articles/nature.2016.19556", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Study in mice suggests that behaviour of parents influences health of children through 'epigenetic' inheritance. The health effects of a bad diet can carry over to offspring through eggs and sperm cells without DNA mutations, researchers have found. The mouse study, published in  Nature Genetics 1 , provides some of the strongest evidence yet for the non-genetic inheritance of traits acquired during an organism\u2019s lifetime. And although previous work has suggested that sperm cells can carry 'epigenetic' factors, this is the first time that such an effect has been observed with egg cells. Researchers have suspected for some time that parents' lifestyle and behaviour choices can affect their children's health through epigenetics. These are chemical modifications to DNA or the proteins in chromosomes that affect how genes are expressed, but that do not alter the gene sequences themselves. Whether those changes can be inherited is still controversial. In particular, there have been suggestions that parental eating habits might shape the offspring's risk of obesity and diabetes. However, it has been difficult to disentangle the possibility that the parents\u2019 behaviour during pregnancy or during the offspring's early childhood was to blame, rather than epigenetic changes that had occurred before conception. To get around this issue, endocrinologist Peter Huypens at the German Research Center for Environmental Health in Neuherberg, Germany, and his colleagues gave genetically identical mice one of three diets \u2014 high fat, low fat or standard laboratory chow \u2014 for six weeks. As expected, those fed the high-fat diet became obese and had impaired tolerance to glucose, an early sign of type 2 diabetes. The team then took eggs and sperm cells from each of the three groups and performed  in vitro  fertilization (IVF), implanting the resulting embryos into healthy surrogate mothers. The idea was that if a physical trait or behaviour was observed in the offspring, it could only have been transmitted through the egg or sperm cells. (Previous studies that did not include IVF had offered evidence for epigenetic transmission from the fathers, but could not exclude mothers' effects through development or nursing.) \u201cTheir design means that previous possible confounders like maternal bonding, feeding and the microbiome are ruled out,\u201d says Tim Spector, a genetic epidemiologist at King\u2019s College London, who was not involved in the study. When the adult offspring were subsequently fed a high-fat diet, those with obese parents seemed more prone to gaining weight and developing glucose intolerance, particularly if both parents were obese. The offspring of two lean parents gained the least weight. \u201cIt nicely shows that metabolic alterations in the offspring are more important if both eggs and sperm have been collected from high-fat-diet fed animals, suggesting the effect of maternal and paternal diet are additive,\u201d says Romain Barr\u00e8s, a molecular biologist at the University of Copenhagen, who was also not involved in the study. \n             Sex differences \n           Curiously, the authors reported differences between male and female offspring: daughters seemed more prone to gaining weight if their parents had been obese, whereas sons were only more prone to developing glucose intolerance. The mother\u2019s diet also seemed to have a greater influence on the offspring\u2019s metabolism than the father\u2019s did. This is interesting, because a similar pattern has been seen in some human epidemiological studies, says Huypens. However, Isabelle Mansuy, a neuroepigeneticist at the University of Zurich in Switzerland, finds the sex differences troubling. The IVF procedure involves stimulating the females with hormones, she points out, which \u201calters metabolism in eggs, raising the concern that this may differently affect eggs from obese females and result \u2014 at least in part \u2014 in the effects\u201d. She also notes that the offspring of obese parents gained weight when they were fed a high-fat diet, but the authors did not test if the offspring gained weight under normal conditions. The idea of epigenetic inheritance is that the effects of parents\u2019 exposure to a risk factor should appear even when the offspring are not exposed to it, she says. Assuming that the results can be replicated, the next question is how traits are being passed from parent to offspring. Two major mechanisms that affect gene expression have been proposed for epigenetic inheritance. One is that it occurs through chemical modifications of DNA called methylations, and another is that short RNA chains called microRNAs are inherited in the sperm or egg cell along with the DNA. So far, the German team has found differences in methylation patterns and in the RNA transcripts in egg and sperm cells from both obese and healthy animals, but it\u2019s not yet clear whether these are bringing about the changes in the offspring. Another question is whether any period of obesity in a parent would affect the offspring\u2019s metabolism, or whether just overeating during certain phases of life has an effect. In the current study, the effects were only seen if the mice were overfed after they reached adulthood. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Starvation in pregnant mice marks offspring DNA 2014-Jul-10 \n                 \n                   Epigenetics: The sins of the father 2014-Mar-05 \n                 \n                   Fearful memories haunt mouse descendants 2013-Dec-01 \n                 \n                   Fat fathers affect daughters' health 2010-Oct-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19552", "url": "https://www.nature.com/articles/nature.2016.19552", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Mathematician receives coveted award for solving three-century-old problem in number theory. British number theorist Andrew Wiles has received the 2016 Abel Prize for his solution to Fermat\u2019s last theorem \u2014 a problem that stumped some of the world\u2019s greatest minds for three and a half centuries. The Norwegian Academy of Science and Letters announced the award \u2014 considered by some to be the 'Nobel of mathematics' \u2014 on 15 March. Wiles, who is 62 and now at the University of Oxford, UK, will receive 6 million kroner (US$700,000) for his 1994 proof of the theorem, which states that there cannot be any positive whole numbers  x ,  y  and  z  such that  x n  +  y n  =  z n , if  n  is greater than 2. Soon after receiving the news on the morning of 15 March, Wiles told  Nature  that the award came to him as a \u201ctotal surprise\u201d. That he solved a problem considered too hard by so many \u2014 and yet a problem relatively simple to state \u2014 has made Wiles arguably \u201cthe most celebrated mathematician of the twentieth century\u201d, says Martin Bridson, director of Oxford's Mathematical Institute \u2014 which is housed in a building named after Wiles. Although his achievement is now two decades old, he continues to inspire young minds, something that is apparent when school children show up at his public lectures. \u201cThey treat him like a rock star,\u201d Bridson says. \u201cThey line up to have their photos taken with him.\u201d \n               Lifelong quest \n             Wiles's story has become a classic tale of tenacity and resilience. While a faculty member at Princeton University in New Jersey in the 1980s, he embarked on a solitary, seven-year quest to solve the problem, working in his attic without telling anyone except for his wife. He went on to make a historic announcement at a conference in his hometown of Cambridge, UK, in June 1993, only to hear from a colleague two months later that his proof contained a serious mistake. But after another frantic year of work \u2014 and with the help of one of his former students, Richard Taylor, who is now at the Institute for Advanced Study in Princeton \u2014 he was able to patch up the proof. When the resulting two papers were published in 1995, they made up an entire issue of the  Annals of Mathematics 1 , 2 . But after Wiles's original claim had already made front-page news around the world, the pressure on the shy mathematician to save his work almost crippled him. \u201cDoing mathematics in that kind of overexposed way is certainly not my style, and I have no wish to repeat it,\u201d he said in a BBC documentary in 1996, still visibly shaken by the experience. \u201cIt\u2019s almost unbelievable that he was able to get something done\u201d at that point, says John Rognes, a mathematician at the University of Oslo and chair of the Abel Committee. \u201cIt was very, very intense,\u201d says Wiles. \u201cUnfortunately as human beings we succeed by trial and error. It\u2019s the people who overcome the setbacks who succeed.\u201d Wiles first learnt about French mathematician Pierre de Fermat as a child growing up in Cambridge. As he was told, Fermat formulated his eponymous theorem in a handwritten note in the margins of a book in 1637: \u201cI have a truly marvellous demonstration of this proposition which this margin is too narrow to contain,\u201d he wrote (in Latin). \u201cI think it has a very romantic story,\u201d Wiles says of Fermat's idea. \u201cThe kind of story that catches people\u2019s imagination when they\u2019re young and thinking of entering mathematics.\u201d But although he may have thought he had a proof at the time, only a proof for one special case has survived him, for exponent  n  = 4. A century later, Leonhard Euler proved it for  n  = 3, and Sophie Germain's work led to a proof for infinitely many exponents, but still not for all. Experts now tend to concur that the most general form of the statement would have been impossible to crack without mathematical tools that became available only in the twentieth century. In 1983, German mathematician Gerd Faltings, now at the Max Planck Institute for Mathematics in Bonn, took a huge leap forward by proving that Fermat's statement had, at most, a finite number of solutions, although he could not show that the number should be zero. (In fact, he proved a result viewed by specialists as deeper and more interesting than Fermat's last theorem itself; it demonstrated that a broader class of equations has, at most, a finite number of solutions.) \n               The winning number \n             To narrow it to zero, Wiles took a different approach: he proved the Shimura-Taniyama conjecture, a 1950s proposal that describes how two very different branches of mathematics, called elliptic curves and modular forms, are conceptually equivalent. Others had shown that proof of this equivalence would imply proof of Fermat \u2014 and, like Faltings' result, most mathematicians regard this as much more profound than Fermat\u2019s last theorem itself. (The full citation for the Abel Prize states that it was awarded to Wiles \u201cfor his stunning proof of Fermat\u2019s Last Theorem by way of the modularity conjecture for semistable elliptic curves, opening a new era in number theory.\u201d) The link between the Shimura\u2013Taniyama conjecture and Fermat's theorum was first proposed in 1984 by number theorist Gerhard Frey, now at the University of Duisburg-Essen in Germany. He claimed that any counterexample to Fermat's last theorem would also lead to a counterexample to the Shimura\u2013Taniyama conjecture. Kenneth Ribet, a mathematician at the University of California, Berkeley, soon proved that Frey was right, and therefore that anyone who proved the more recent conjecture would also bag Fermat's. Still, that did not seem to make the task any easier. \u201cAndrew Wiles is probably one of the few people on Earth who had the audacity to dream that he can actually go and prove this conjecture,\u201d Ribet told the BBC in the 1996 documentary. Fermat's last theorem is also connected to another deep question in number theory called the  abc  conjecture, Rognes points out. Mathematician  Shinichi Mochizuki  of Kyoto University's Research Institute for Mathematical Sciences in Japan  claimed to have proved that conjecture in 2012 , although his roughly 500-page proof is still being vetted by his peers. Some mathematicians say that Mochizuki's work could provide, as an extra perk, an alternative way of proving Fermat, although Wiles says that sees those hopes with scepticism. Wiles helped to arrange  an Oxford workshop on Mochizuki's work  last December, although his research interests are somewhat different. Lately, he has focused his efforts on  another major, unsolved conjecture in number theory , which has been listed as one of seven Millennium Prize problems posed by the Clay Mathematics Institute in Oxford, UK. He still works very hard and thinks about mathematics for most of his waking hours, including as he walks to the office in the morning. \u201cHe doesn\u2019t want to cycle,\u201d Bridson says. \u201cHe thinks it would be a bit dangerous for him to do it while thinking about mathematics.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Biggest mystery in mathematics in limbo after cryptic meeting 2015-Dec-16 \n                   \n                     The biggest mystery in mathematics: Shinichi Mochizuki and the impenetrable proof 2015-Oct-07 \n                   \n                     'Beautiful mind' John Nash adds Abel Prize to his Nobel 2015-Mar-25 \n                   \n                     Chaos-theory pioneer nabs Abel Prize 2014-Mar-26 \n                   \n                     Mathematician wins award for shaping algebra 2013-Mar-20 \n                   \n                     Fermat's theorem proves elusive to the last \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19575", "url": "https://www.nature.com/articles/nature.2016.19575", "year": 2016, "authors": [{"name": "Tanguy  Chouard"}], "parsed_as_year": "2006_or_before", "body": "Nature  reports from AlphaGo's victory in Seoul. Seoul, South Korea Tanguy Chouard, an editor with  Nature , saw Google-DeepMind\u2019s AI system AlphaGo defeat a human professional for the first time last year at the ancient board game Go. This week, he is watching top professional Lee Sedol take on AlphaGo, in Seoul, for a $1 million prize. It\u2019s all over at the Four Seasons Hotel in Seoul, where this morning AlphaGo  wrapped up a 4-1 victory  over Lee Sedol \u2014 incidentally, earning itself and its creators an honorary '9-dan professional' degree from the Korean Baduk Association. After winning the first three games, Google-DeepMind's computer looked impregnable. But the last two games may have revealed some weaknesses in its makeup. Game four totally changed the Go world\u2019s view on AlphaGo\u2019s dominance because it made it clear that the computer can 'bug' \u2014 or at least play very poor moves when on the losing side. It was obvious that Lee felt under much less pressure than in game three. And he adopted a different style, one based on taking large amounts of territory early on rather than immediately going for \u2018street fighting\u2019 such as making threats to capture stones. This style \u2013 called \u2018amashi\u2019 \u2013 seems to have paid off, because on move 78, Lee produced a play that somehow slipped under AlphaGo\u2019s rada r.  David Silver, a scientist at DeepMind who's been leading the development of AlphaGo, said the program estimated its probability as 1 in 10,000. It\u2019s highly debatable whether this actually was a genius move  \u2014  or even \"God's move\" as suggested by some commentators. A couple of professionals watching on the live stream of the American Go Association brought it up as a possible move while Lee was still thinking about it. And the American professional Michael Redmond, who was the official commentator on the game for the public, suggested  in post-match analysis  that the play doesn\u2019t really work. But in any case, Lee\u2019s play revealed some glaring weaknesses in AlphaGo. On its following move the computer made a decisive mistake (as the DeepMind team acknowledged afterwards), but it still estimated its winning chances at 70%. Only by move 87 did its internal assessment of its position take a dive. In the endgame, the system seemed rather confused \u2013 perhaps because it was clearly losing. So it seems that AlphaGo  can  bug \u2013 although it\u2019s hard to know why and how. This obviously poses a serious problem when considering future real-world applications for AI. Confronted about the issue in the post-game press conference, DeepMind's CEO Demis Hassabis replied that AlphaGo was still only a prototype \u2014 \"I'd like to call it a beta, but it's not even an alpha\" \u2014 and that finding such weaknesses was precisely the main technical reason the team was so keen to test the system at the highest level. On to game five, and it was pretty obvious from the nervous looks on the DeepMind support team that today\u2019s game was particularly tense in the control room. Again, Lee took the amashi style, and four hours into the game, neither the go experts nor the computer scientists could call it. It was that close. Ultimately, despite an early mistake, noted by Hassabis in a tweet during the game, the computer caught up and pulled off the victory, but this was far from the comprehensive routing of the first three games. Without taking anything away from the DeepMind team\u2019s achievement, the exposure of cracks in AlphaGo's armour by Lee raises hopes that he and other players might, in the near future, be able to fare better against AlphaGo. It seems that Lee, with advice from his Korean baduk pro colleagues, realised what his best chance might be \u2013 which is amazing after just a few games. The computer plays a million games a day, versus 1,000 games a year for a practising professional, but \u2013 compared to humans \u2013 it\u2019s quite stupid. Neural networks need enormous amounts of data to be trained on, whereas we humans are very efficient at learning and generalizing from very few examples. Humans are also capable of transferring knowledge across very different domains and, of course, of formalizing their learning through explicit concepts, which can be further enriched through education or culture. Combining all such skills in one single machine, to achieve what is known as 'general' AI, remains an outstanding challenge for the future. As Oren Etzioni, chief executive of the non-profit Allen Institute for Artificial Intelligence in Seattle, Washington, says: \" We are a long, long way from general artificial intelligence .\" \n             Previous entry:  \n             AI computer clinches victory against Go champion \n           \n                   What Google\u2019s winning Go algorithm will do next 2016-Mar-15 \n                 \n                   The Go Files: AI computer clinches victory against Go champion 2016-Mar-12 \n                 \n                   The Go Files: \u2018Humanity-packed\u2019 AI prepares to take on world champion 2016-Mar-07 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Digital intuition 2016-Jan-27 \n                 \n                   Go players react to computer defeat 2016-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "531284a", "url": "https://www.nature.com/articles/531284a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "AlphaGo\u2019s techniques could have broad uses, but moving beyond games is a challenge. Following the defeat of one of its finest human players, the ancient game of Go has joined the growing list of tasks at which computers perform better than humans. In a 6-day tournament in Seoul, watched by a reported 100\u00a0million people around the world, the computer algorithm AlphaGo, created by the Google-owned company DeepMind, beat Go professional Lee Sedol by 4 games to 1. The complexity and intuitive nature of the ancient board game had established Go as one the greatest challenges in artificial intelligence (AI). Now the big question is what the DeepMind team will turn to next. AlphaGo\u2019s general-purpose approach \u2014 which was mainly learned, with a few elements crafted specifically for the game \u2014 could be applied to problems that involve pattern recognition, decision-making and planning. But the approach is also limited. \u201cIt\u2019s really impressive, but at the same time, there are still a lot of challenges,\u201d says Yoshua Bengio, a computer scientist at the University of Montreal in Canada. Lee, who had predicted that he would win the Google tournament in a landslide, was shocked by his loss. In October,  AlphaGo beat European champion Fan Hui . But the version of the program that won in Seoul is significantly stronger, says Jonathan Schaeffer, a computer scientist at the University of Alberta in Edmonton, Canada, whose Chinook software mastered draughts in 2007: \u201cI expected them to use more computational resources and do a lot more learning, but I still didn\u2019t expect to see this amazing level of performance.\u201d The improvement was largely down to the fact that the more AlphaGo plays, the better it gets, says Miles Brundage, a social scientist at Arizona State University in Tempe, who studies trends in AI. AlphaGo uses a  brain-inspired architecture  known as a neural network, in which connections between layers of simulated neurons strengthen on the basis of experience. It learned by first studying 30\u00a0million Go positions from human games and then improving by playing itself over and over again, a technique known as reinforcement learning. Then, DeepMind combined AlphaGo\u2019s ability to recognize successful board configurations with a \u2018look-ahead search\u2019, in which it explores the consequences of playing promising moves and uses that to decide which one to pick. Next, DeepMind could tackle more games. Most board games, in which players tend to have access to all information about play, are now solved. But machines still cannot beat humans at multiplayer poker, say, in which each player sees only their own cards. The DeepMind team has expressed an interest in tackling Starcraft, a science-fiction strategy game, and Schaeffer suggests that DeepMind devise a program that can learn to play different types of game from scratch. Such programs already compete annually at the International General Game Playing Competition, which is geared towards creating a more general type of AI. Schaeffer suspects that DeepMind would excel at the contest. \u201cIt\u2019s so obvious, that I\u2019m positive they must be looking at it,\u201d he says. DeepMind\u2019s founder and chief executive Demis Hassabis mentioned the possibility of training a version of AlphaGo using self-play alone, omitting the knowledge from human-expert games, at a conference last month. The firm created a program that  l earned to play  less complex arcade games in this manner in 2015 . Without a head start, AlphaGo would probably take much longer to learn, says Bengio\u00a0\u2014 and might never beat the best human. But it\u2019s an important step, he says, because humans learn with such little guidance. DeepMind, based in London, also plans to venture beyond games. In February the company founded DeepMind Health and launched a collaboration with the UK National Health Service: its algorithms could eventually be applied to clinical data to improve diagnoses or treatment plans. Such applications pose different challenges from games, says Oren Etzioni, chief executive of the non-profit Allen Institute for Artificial Intelligence in Seattle, Washington. \u201cThe universal thing about games is that you can collect an arbitrary amount of data,\u201d he says\u00a0\u2014 and that the program is constantly getting feedback on what\u2019s a good or bad move by playing many games. But, in the messy real world, data\u00a0\u2014 on rare diseases, say\u00a0\u2014 might be scarcer, and even with common diseases, labelling the consequences of a decision as \u2018good\u2019 or \u2018bad\u2019 may not be straightforward.\u00a0 Hassabis has said that DeepMind\u2019s algorithms could give smartphone personal assistants a deeper understanding of users\u2019 requests. And AI researchers see parallels between human dialogue and games: \u201cEach person is making a play, and we have a sequence of turns, and each of us has an objective,\u201d says Bengio. But they also caution that language and human interaction involve a lot more uncertainty. DeepMind is fuelled by a \u201cvery powerful cocktail\u201d of the freedoms usually reserved for academic researchers, and by the vast staff and computing resources that come with being a Google-backed firm, says Joelle Pineau, a computer scientist at McGill University in Montreal. Its achievement with Go has prompted speculation about when an AI will have a versatile, general intelligence. \u201cPeople\u2019s minds race forward and say, if it can beat a world champion it can do anything,\u201d says Etzioni. But deep reinforcement learning remains applicable only in certain domains, he says: \u201cWe are a long, long way from general artificial intelligence.\u201d DeepMind\u2019s approach is not the only way to push the boundaries of AI. Gary Marcus, a neuroscientist at New York University in New York City, has co-founded a start-up company, Geometric Intelligence, to explore learning techniques that extrapolate from a small number of examples, inspired by how children learn. In its short life, AlphaGo probably played hundreds of\u00a0millions of games\u00a0\u2014\u00a0many more than Lee, who still won one of the five games against AlphaGo. \u201cIt\u2019s impressive that a human can use a much smaller quantity of data to pick up a pattern,\u201d says Marcus. \u201cProbably, humans are much faster learners than computers.\u201d\n \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     The Go Files: AI computer clinches victory against Go champion 2016-Mar-12 \n                   \n                     Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                   \n                     Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                   \n                     Game theorists crack poker 2015-Jan-08 \n                   \n                     Computer science: The learning machines 2014-Jan-08 \n                   \n                     Nature  Special: The Go Files \n                   \n                     Google DeepMind \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19586", "url": "https://www.nature.com/articles/nature.2016.19586", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Arrests could be the first of many after peace petition led to 30 academics being fired. Three Turkish academics in Istanbul have been arrested and are being held in prison on suspicion of \u2018making terrorist propaganda\u2019, after they signed a petition in January calling for an end to violence between government forces and Kurdish separatists in Turkey\u2019s southeast. A British computer scientist working in Istanbul who protested against their arrests was himself detained and is now leaving the country. Psychologist Esra Mungan at Bo\u011fazi\u00e7i University, mathematician K\u0131van\u00e7 Ersoy from Mimar Sinan University and political scientist Muzaffer Kaya from Ni\u015fanta\u015f\u0131 University were taken in for questioning on 14 March and have now been formally arrested and held without bail. Four days earlier, the three had held a press conference affirming their commitment to the \u2018 academics for peace \u2019 declaration, which was launched more than two months ago and was quickly signed by more than 1,100 Turkish academics and several hundred Western intellectuals, including linguist Noam Chomsky. \u201cThe three jailed academics have committed no crime and should be immediately released,\u201d says Emma Sinclair-Webb, senior Turkey researcher at the civil-rights group Human Rights Watch, which issued a  press statement  about the arrests. Most Turkish researchers who signed the petition have since come under investigation by their universities \u2014 and in January some were  brought in for police questioning and subsequently released  \u2014 after Turkey\u2019s president Recep Tayyip Erdo\u011fan accused signatories of spreading Kurdish terrorist propaganda and undermining the country\u2019s national security. Erdo\u011fan said that the failure of the declaration\u2019s text to refer to violence carried out by the Kurdish groups, particularly the militant Kurdistan Workers\u2019 Party (PKK), constituted support for terrorists.\u00a0 At least 30 academics, including Kaya, have already been fired from their posts, and 27 others suspended, according to Human Rights Watch. \u201cThese first arrests are likely to be the tip of the iceberg,\u201d says Gareth Jenkins, a political analyst based in Istanbul. \u201cThe next weeks could see a wave of them in jail.\u201d Turkey\u2019s government has a history of  imprisoning scientists on charges associated with terrorism offences . Chris Stephenson, a British computer scientist at Bilgi University who protested against the arrests at the Istanbul police station, was himself detained on 15 March. He is now leaving the country before waiting to find out if he whether he will be formally deported, according to Turkish media. Police were reported as having found him in possession of leaflets supporting the PKK, but other reports say that his bag contained only invitations to Kurdish New Year celebrations on 21 March. (Erdo\u011fan has banned all such celebrations). Other signatories at Turkish universities are feeling nervous, according to Cem Say, a computer scientist at Bo\u011fazi\u00e7i University. The day before Stephenson\u2019s arrest, Erdo\u011fan said \u2014 in the wake of a bomb attack in the Turkish capital Ankara \u2014 that he wanted to widen the definition of the word terrorist. He said: \u201cIt might be the terrorist who pulls the trigger and detonates the bomb, but it is these supporters and accomplices who allow that attack to achieve its goal. The fact their title is politician, academic, writer, journalist or head of a civil society group doesn\u2019t change the fact that individual is a terrorist.\u201d Say did not sign the \u2018academics for peace\u2019 declaration himself because, he says, he felt it to be unbalanced and unhelpful. But he says that he \u201cwouldn\u2019t have guessed that something like this would happen \u2014 it is extremely disturbing\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Turkish scientists rocked by accusations of supporting terrorism 2016-Jan-18 \n                 \n                   Scientists swept up in terrorism trials 2013-Aug-06 \n                 \n                   Turkey cracks down on academic freedom 2012-Jul-03 \n                 \n                   Academics for Peace Petition \n                 \n                   Human Rights Watch \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19839", "url": "https://www.nature.com/articles/nature.2016.19839", "year": 2016, "authors": [{"name": "Rachel Becker"}], "parsed_as_year": "2006_or_before", "body": "Modelling study paints bleak picture for Europe\u2019s bird populations. A veterinary drug blamed for driving vultures to the brink of extinction on the Indian subcontinent could cause thousands of bird deaths now that it is being used in Spain. Researchers  have expressed concern  over use of the anti-inflammatory drug diclofenac in cattle\u00a0since it was approved for veterinary use\u00a0in Spain in 2013, as the drug is toxic to vultures who may consume it via dead cows. Now, modelling by Rhys Green, a conservation scientist at the University of Cambridge, UK, and his colleagues suggests that the drug could cause populations of that country\u2019s Eurasian griffon vultures ( Gyps fulvus ) to decline by between 1\u20138% each year. Their work was published on 25 April in the  Journal of Applied Ecology 1 . \u201cYou can almost liken it to the rather macabre game of Russian roulette,\u201d he says. \u201cVultures eat about every three days on average, so that\u2019s 120 days a year \u2014 and so that\u2019s like 120 pulls of the trigger.\u201d Widespread use of diclofenac in south Asian cattle was  linked to the deaths  of millions of vultures that ate carcasses containing the drug, causing some populations to decline by more than 99% since the 1990s. Although diclofenac does not yet seem to have caused population declines for Europe\u2019s vultures, scientists suspect that it might only be a matter of time. Because vultures congregate to feed, Green says that even a few carcasses containing the drug could seriously damage a population. Along with Antoni Margalida from the University of Lleida in Spain, and other colleagues, he is calling for a ban of the veterinary drug in favour of an alternative called meloxicam that is less toxic to vultures. \n             Toxic roulette \n           Diclofenac is toxic to vultures even in small doses, causing kidney failure. That results in uric acid accumulating in the birds' blood and crystallizing around their internal organs\u2014a condition called visceral gout 2 . Countries on the Indian subcontinent began banning diclofenac in 2006 and since then, vulture populations in the region seem to have halted their precipitous declines 3 . In Europe, diclofenac has been approved for veterinary use since 1993. In 2014, the European Medicines Agency acknowledged that vultures are at risk of consuming residues of the drug in dead livestock, but  did not recommend banning it . In 2015 the European Commission decided to follow the EMA\u2019s recommendation,  leaving it up to EU member states  to prevent diclofenac-laced carcasses from entering the food chain. But in 2012, a dead vulture discovered in Spain was found to contain high levels of a similar drug called flunixin 4 , indicating \u201cthat another non-steroidal anti-inflammatory drug in veterinary use in Spain \u2014 which shouldn\u2019t have gotten into the vulture\u2019s food chain \u2014 did, in this case\u201d, says Green. Since then, toxicologist Rafael Mateo Soria at the University of Castilla-La Mancha says there have been at least two more vulture poisonings in Spain with flunixin. So when it comes to diclofenac and vultures, \u201cyou\u2019re playing with fire\u201d, he says. \n             Model behaviour \n           Spain's medicines agency, AEMPS, and its agriculture ministry, MAGRAMA, had previously modelled annual vulture mortality from diclofenac poisoning, and estimated that 15\u201339 birds might die from it each year. The population declines calculated by Green\u2019s team \u2014 715 to 6,389 bird deaths per year \u2014 are significantly more worrying. They used the same numbers of medicated carcasses that MAGRAMA and AEMPS proposed vultures might eat, but allowed for a little more uncertainty about the lethal dose of diclofenac. Such a die-off could drive populations to extinction. \u201cThe reality is, I am 100% sure is that there is no way that any one model can predict perfectly,\u201d says Todd Katzner, a wildlife biologist with the US Geological Survey. \u201cAt the same time, I think this model is very useful in terms of understanding the biology of the situation.\u201d The European Commission and the manufacturers of diclofenac drugs in Europe did not reply to  Nature \u2019s requests for comment. \n                   Microbes help vultures eat rotting meat 2014-Nov-26 \n                 \n                   Toxic influence 2014-Oct-21 \n                 \n                   Poisoned vulture could herald European bird crisis 2014-Oct-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19574", "url": "https://www.nature.com/articles/nature.2016.19574", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Study suggests that patients with Alzheimer's disease can still form memories, raising hopes of new treatments. People with Alzheimer's disease may forget faces or where they left familiar objects because their brains cannot find where they put those memories, a study in mice suggests. The study, reported in  Nature 1 , contradicts the notion that Alzheimer\u2019s prevents the brain from making new memories. It also suggests that brain stimulation might temporarily improve the memories of patients in the early stages of the disease. The research builds on earlier work by lead author Susumu Tonegawa, a neuroscientist, and his colleagues at Massachusetts Institute of Technology in Cambridge. Last year, they showed that in certain types of amnesia, memories were stored but could not be retrieved 2 . It is difficult to detect the difference between a stored and a retrieved memory in humans, as the only way to test memory is to ask patients to recall information. But memories can be manipulated in mice, so Tonegawa and his colleagues tested their theory using two strains of mice with mutations in genes linked to Alzheimer\u2019s disease. These mice develop amyloid protein clusters, or plaques, in their brains and eventually lose their memories \u2014 just as humans with Alzheimer's disease do. The researchers demonstrated this memory loss by placing the mice in a box in which they received an electric shock. Normal mice learned to fear the box, but the mutant mice did not, because they did not remember being shocked. \n             Thinking inside the box \n           The researchers engineered the mutant mice to make a light-sensitive protein in neurons in the hippocampus, the part of the brain that encodes short-term memories. Then the scientists placed the mice back into the box, shining a light onto the animals' brains to force the modified neurons to fire. This caused the mice to recall the memory of being shocked, and the animals froze \u2014 suggesting that the memory had been encoded in the first place. But the next day, the mice had again forgotten their fear of the box. Next, the scientists pulsed the light, mimicking a process that occurs naturally as a memory is accessed repeatedly over time. This strengthened the connections between the hippocampus and another brain region called the entorhinal cortex, a connection that serves as long-term memory storage. With the memories now firmly embedded, the mice remembered to be afraid of the box, even when the light was off. When the researchers dissected the animals\u2019 brains, they found that the pulsing stimulation had created more connections between the hippocampus and the entorhinal cortex \u2014 connections that are lost as Alzheimer's disease progresses. But the researchers expect that the technique would only work for a few months in mice, or two to three years in humans, before the disease advances enough to erase any gains.  This theory about how Alzheimer's affects the brain agrees with symptoms seen in patients. For unknown reasons, the hippocampus is particularly vulnerable to the ravages of Alzheimer's, which is why a person with the disease first forgets new memories, such as where he left his car. As the disease worsens, other parts of the brain are destroyed, causing patients to forget long-term information such as family members\u2019 names. \n             Stimulating memories \n           \u201cIt\u2019s a beautifully executed study,\u201d says Itzhak Fried, a neurosurgeon at the University of California Los Angeles. But he cautions that the findings may not translate to human brains, because mice do not develop amyloid plaques in the same way as humans do. And it is impossible to test whether the memory-retrieval hypothesis holds true in humans, because researchers have not worked out how to stimulate human brains using light. Christine Denny, a neurobiologist at Columbia University in New York City, says that electrical stimulation may succeed where optogenetics has not. Early trials suggest that deep-brain stimulation of the hippocampus prompts the creation of neurons and improves memory in some Alzheimer's patients. But no one knows how it works 3 . Tonegawa's findings may allow more targeted stimulation, especially once researchers understand what happens to memories after they leave the hippocampus. Several groups, including Fried\u2019s, are already implanting such fine-tuned micro-stimulation devices  into the entorhinal cortices of epilepsy patients  with brain injuries in the hope of restoring memory abilities. Fried says that it might soon be time to test microstimulation in very small groups of people with Alzheimer's disease. Although he acknowledges that it is important to do more animal work, especially in primates, \u201cat the same time we\u2019re crying for relief of clinical symptoms in patients who are really suffering\u201d.  Read the related News and Views article: ' Alzheimer's disease: Lost memories found '. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Memory-boosting devices tested in humans 2015-Nov-03 \n                 \n                   Memory-saving devices snag US research funds 2014-Jul-10 \n                 \n                   Electrodes spark neuron growth 2009-May-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19584", "url": "https://www.nature.com/articles/nature.2016.19584", "year": 2016, "authors": [{"name": "Heidi Ledford"}, {"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Join us on Reddit where we'll be talking about all things CRISPR. CRISPR\u2013Cas9 technology has already revolutionized biology and shows no sign of slowing. From  GM crops  to  customized pets ,  patent disputes  to  CRISPR babies , we\u2019ll be answering your questions about the powerful gene-editing tool at our CRISPR AMA on Thursday 17 March at 1:00 p.m. EDT / 5:00 p.m. GMT. Join Heidi Ledford and Sara Reardon at  www.reddit.com/r/science . The AMA opens at 8:00 a.m. EDT / 12:00 p.m. GMT for you to submit your questions. To take part, you will need a Reddit account.  Register here . \n             Meet the team \n            I\u2019m Heidi Ledford, a senior reporter in Cambridge, Massachusetts. I write about various biomedical topics: cancer research, drug development, biotechnology and, of course, CRISPR. A lot of CRISPR.  CRISPR editing ,  CRISPR epigenetics ,  CRISPR gene drives ,  CRISPR patents ,  CRISPR babies  (hypothetical only),  CRISPR therapies  (also still hypothetical) and  DIY CRISPR  (that one's real already). Once upon a time, I earned a PhD in plant biology at the University of California in Berkeley. But don't come to me for gardening advice. I used molecular biology to study photosynthesis in algae.  I'm Sara Reardon, a\u00a0reporter based in Washington DC. I write about US science policy and biomedical research, especially neuroscience and microbiology. I'm a recovering scientist (clean for five years) and studied neurodevelopment for my master's degree in molecular biology, which was much harder pre-CRISPR. It is an exciting time to be writing about genome editing, especially as it brings to life wild ideas like  pigs with human-like organs for transplantation  and  \u201cde-extincted\u201d woolly mammoths made by CRISPRing extra-hairy elephants . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19585", "url": "https://www.nature.com/articles/nature.2016.19585", "year": 2016, "authors": [{"name": "Jeff Hecht"}], "parsed_as_year": "2006_or_before", "body": "Data from NASA\u2019s New Horizons mission begin to reveal the stories behind the dwarf planet's complex geology. The plains of Pluto\u2019s Sputnik Planum look smooth and fresh after 4 billion years in the deep freeze of the outer Solar System. Yet nearby highlands are saturated with impact craters. Welcome to  weird and wonderful Pluto , as revealed by NASA\u2019s New Horizons spacecraft. Eight months after the probe  buzzed past the dwarf planet , mission scientists have published the most detailed studies yet of Pluto\u2019s  unexpectedly varied terrain  and its  motley moons . \u201cIt\u2019s truly amazing how many different geological processes have operated\u201d on Pluto, says Jeffrey Moore, a planetary scientist at NASA\u2019s Ames Research Center in Moffett Field, California, and the lead author of one of five New Horizons papers published today in  Science 1 , 2 , 3 , 4 , 5 . On Sputnik Planum, nitrogen, methane and carbon monoxide continually cycle between ice and gas at temperatures of \u2212243 to \u2212223 \u00baC. Sputnik Planum's elevation, 3\u20134 kilometres below the surrounding uplands, may create conditions that collect these volatile chemicals from Pluto's thin atmosphere. The result is  soft glaciers , composed largely of nitrogen ice, that cover a bedrock of much harder water ice and help to keep the plains smooth. Yet this water ice is less dense than the nitrogen, so in some places, chunks of the bedrock float on the glaciers. Other areas remain in an almost primordial state. The eastern part of the dark area called Cthulhu Regio seems to be saturated with craters. Moore suspects that they were created during the Late Heavy Bombardment 4 billion years ago, when comets and asteroids pummelled the Solar System. \n             Going with the flow \n           The combination of light, strong water-ice bedrock and softer, flowing glaciers made of about 90% nitrogen creates some strange interactions. Scientists did not think that soft volatile ices could build water ice into mountains several kilometres high \u2014 until they saw Pluto up close. \u201cWhen you lay out all these materials in a large sandbox, weird and wonderful things can happen,\u201d says New Horizons team member Will Grundy, of Lowell Observatory in Flagstaff, Arizona, the lead author of a study describing the surfaces of Pluto and Charon 3 . Other geological oddities arise at the boundaries between different types of terrain. Some highlands near Sputnik Planum are marked by valleys about a kilometre deep, and up to 25 kilometres wide, where glaciers seem to run down to the plains below. The networks of valleys resemble those found on Mars and Saturn\u2019s moon Titan. This surprises Moore, because conditions on Pluto prevent nitrogen from existing as a fluid that could carve such valleys. Scientists aren't sure whether heavy nitrogen ice eroded the lighter water ice to create the depressions. Then there is Pluto\u2019s  largest moon, Charon . Mordor Macula, a large, reddish region near the moon\u2019s north pole, does not resemble anything found on the other known icy satellites in the Solar System. Grundy and his colleagues suggest that its striking colour is produced by methane and other volatile chemicals that freeze out of the atmosphere during Charon's long winters \u2014 when temperatures can dip below \u2212253 \u00baC \u2014 and are then converted by sunlight into darker compounds that do not evaporate. The source of the methane is unknown; it may escape from Pluto's atmosphere and flow toward Charon, or come from Charon's interior. Taken together, the findings constitute \u201ca magnificent reconnaissance\u201d of Pluto and its satellites, says Ralph Lorenz, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, who is not involved in the New Horizons mission. \u201cThe iceberg mountains floating in a frozen sea of nitrogen and the bladed terrain are just examples of a quite amazing range of novel features.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Icy volcanoes may dot Pluto's surface 2015-Nov-09 \n                 \n                   Pluto\u2019s geology is unlike any other 2015-Oct-15 \n                 \n                   Vibrant Pluto stuns scientists 2015-Jul-21 \n                 \n                   Nature  special: Pluto and Ceres \n                 Reprints and Permissions"},
{"file_id": "533020a", "url": "https://www.nature.com/articles/533020a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Ambitious effort depends on transformation of rhino tissue into sperm and egg cells. The northern white rhinoceros is a species waiting for extinction. Its three remaining individuals, kept in a well-guarded Kenyan conservation park, cannot breed naturally. A 15-year-old female named Fatu could be the last of a creature that once roamed central African savannahs by the thousands. In a last-gasp effort to avert that scenario, researchers this week unveiled the details of an audacious plan to save the northern white rhino ( Ceratotherium simum cottoni ), by transforming cells from living rhinos and from frozen storage into sperm and egg cells, and then using  in vitro  fertilization (IVF) to create embryos and revitalize the population. Teams led by San Diego Zoo Global in California and the Leibniz Institute for Zoo and Wildlife Research in Berlin have already started work on the idea.They say that it could guide the rescue of other animals that are on the brink of extinction, and even the resurrection of those already gone. But critics call the plan, which is likely to require millions of dollars, fanciful and worry that it could distract from broader conservation efforts. \u201cThe northern white rhinoceros will go extinct if we don\u2019t do this,\u201d says Oliver Ryder, a conservation geneticist at San Diego Zoo Global and a leading architect of the rescue plan, published on 3 May in  Zoo Biology  ( J.Saragustyetal.ZooBiol.http://dx.doi.org/10.1002/zoo.21284;2016 ). The strategy was drawn up last December in Vienna at a meeting that was attended by teams from both zoos, as well as specialists in stem-cell and reproductive biology. \u201cIt\u2019s really a strategic road map \u2014 one which has a lot of obstacles,\u201d says reproductive biologist Thomas Hildebrandt, who leads the Leibniz team. \n               On the brink \n             Poaching has slashed the rhinos\u2019 numbers from around 2,300 in the 1960s. For the remaining three animals, natural reproduction is not an option. Sudan, a 42-year-old male, has a low sperm count; his 26-year-old daughter Najin has leg injuries that mean she cannot bear the weight either of a mounting male or of pregnancy; and her daughter Fatu has a uterine disorder that would prevent an embryo from implanting. But sperm and other cells from another ten individuals are in frozen storage. To begin with, researchers will try to create embryos from existing sperm and egg cells; Hildebrandt says that this year he will go to the Ol Pejeta Conservancy, where the animals live, to collect egg cells from Fatu and Najin. These could then be fertilized with some frozen sperm and implanted into a surrogate mother, a southern white rhino ( Ceratotherium simum simum ). But no one has ever made a viable rhino embryo using IVF, let alone implanted one into a surrogate, so the San Diego and Leibniz teams are each working to develop the technique in southern white rhinos, which number around 20,000. Hildebrandt is confident that obstacles such as implanting an embryo in a surrogate will be overcome in a matter of years. \u201cNajin or Fatu will see another northern white rhino before they die. That I can guarantee,\u201d he says. Najin and Fatu are currently the only source of egg cells for use in IVF. That limited gene pool means that it will not be possible to create a northern white rhino population that is sufficiently diverse to thrive in the wild. So in stage two, the researchers would try to reprogram frozen rhino cells into stem cells that have the capacity to develop into any type of tissue, including eggs and sperm (see \u2018Saving the northern white rhino\u2019). In 2011, a team led by stem-cell scientist Jeanne Loring at the Scripps Research Institute in La Jolla, California,  created such cells , known as induced pluripotent stem (iPS) cells from Fatu\u2019s skin cells ( I. F. Ben-Nun  et al. Nature Meth.    8,  829\u2013831; 2011 ). But generating sperm and eggs from iPS cells will not be simple, and could require rhino stem cells to be cultured alongside the reproductive tissue of other animals, such as mice. \u201cAll the technologies have been done but in other species,\u201d says Loring. \u201cIt\u2019s not certain these things are going to translate directly to rhinos.\u201d Conservationists have tried to bring species back from the brink using reproductive technologies before. In the 2000s, for instance, researchers attempted to use cloning to resurrect the Pyrenean ibex ( Capra pyrenaica ) and a species of wild ox ( Bos gaurus ). The cell reprogramming elements of the rhino plan are even more ambitious. \u201cI don\u2019t see any technical deal-breakers,\u201d says George Church, a genome scientist at Harvard Medical School in Boston, Massachusetts. He hopes to use some of the same approaches to resurrect woolly mammoths, or at least  engineer Asian elephants that can flourish in the Siberian steppe . Funding could prove the greatest barrier. San Diego Zoo has raised around US$2 million for the project since its last northern white rhino, Nola, died last year; it declined to give an estimate of the project\u2019s total cost. Hildebrandt says that his team has had much less luck raising funds \u2014 and would need several million dollars to create a rhino through IVF. Ryder says that the significant costs of rescuing and protecting northern white rhinos will be worth it \u2014 not only to save the species, but also to demonstrate what conservationists can do to rescue other animals. That precedent is what most worries Stuart Pimm, a conservation biologist at Duke University in Durham, North Carolina. \u201cThis says we can let species go to the very brink of extinction and modern technology can bring them back,\u201d he says. \u201cThere is a very substantial moral hazard in that.\u201d \u201cIt\u2019s  Star Trek -type science,\u201d says Michael Knight, chair of the International Union for Conservation of Nature\u2019s African Rhino Specialist Group. He worries that the effort could take away money from other rhino conservation efforts\u00a0\u2014\u00a0including those directed at southern white rhinos, whose numbers are swelling thanks to good management, Knight says. \u201cThey should not be pushing this idea that they\u2019re saving a species. If you want to save a [rhino] species, put your money into southern white conservation.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Worst year ever for rhino poaching in Africa 2016-Jan-25 \n                   \n                     Mammoth genomes provide recipe for creating Arctic elephants 2015-May-01 \n                   \n                     Synthetic biologists and conservationists open talks 2013-Apr-16 \n                   \n                     Endangered species: Sex and the single rhinoceros 2012-May-30 \n                   \n                     Could stem cells rescue an endangered species? 2011-Sep-04 \n                   \n                     Ol Pejeta Conservancy \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19505", "url": "https://www.nature.com/articles/nature.2016.19505", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Einstein@home project will target neutron stars, some of the most mysterious objects in astrophysics. The next discovery of gravitational waves could come from citizen scientists. The Einstein@home project, which uses the idle time on the computers of volunteers who have downloaded a screen saver, is about to start analysing the data from the recently-upgraded Laser Interferometer Gravitational-Wave Observatory (LIGO), a US-led experiment that made history last month with its announcement that it had detected ripples in spacetime. Since  Einstein@home  began in 2005, the network has analysed previous data collected by LIGO and its Franco-Italian-led counterpart Virgo near Pisa, Italy, but has so far seen nothing. On 9 March, the project is due to start analysing data that the upgraded observatory, known as Advanced LIGO, collected between September and January, says Maria Alessandra Papa, a LIGO astrophysicist at the Max Planck Institute for Gravitational Physics in Hannover, Germany. The upgrade  vastly increased the volume of sky that LIGO could scan for signals , and led to the  discovery of gravitational waves , which was  announced on 11 February . The Einstein@home screen saver automatically downloads and searches chunks of LIGO data, and then sends its results back to the central server, a model inherited from the  SETI@home project , which searches radio-astronomy data for messages sent by alien civilizations. \n             Slow-burn signals \n           Rather than looking for dramatic sources of gravitational waves, such as the black-hole merger that LIGO detected on 14 September, Einstein@home looks for quieter, slow-burn signals that might be emitted by fast-spinning objects such as some neutron stars. These remnants of supernova explosions are some of the least well understood objects in astrophysics: such searches could help to reveal their nature. Because they produce a weaker signal than mergers, rotating sources require more computational power to detect. This makes them well-suited to a distributed search. \u201cEinstein@home is used for the deepest searches, the ones that are computationally most demanding,\u201d Papa says. The hope is to extract the weak signals from the background noise by observing for long stretches of time. \u201cThe beauty of a continuous signal is that the signal is always there,\u201d she says. Albert Einstein\u2019s  general theory of relativity  predicts that a rotating object will produce gravitational waves as long as it is not perfectly symmetrical around its axis of rotation. Neutron stars are thought to be highly symmetrical because their gravity is very intense. But some researchers have theorized that they could have regions of different densities or bumpy surfaces, causing them to emit gravitational waves and slow down their rotation in the process. Observations that some pulsars, a type of neutron star that emits radio-frequency blips, have shown that the stars do slow down, although effects other than gravitational waves are known to contribute to this. If Einstein@home spots gravitational waves from a neutron star, it would suggest that the objects can be asymmetrical. \n             Mysterious structure \n           The magnitude of the waves would also allow physicists to determine how hilly or inhomogeneous the neutron star is, which in turn would provide clues about their internal structure. Although neutron stars get their name because their high density means that any protons and electrons present may have been crunched together to form neutrons, astrophysicists don\u2019t know for sure what they are made of, nor how the known laws of physics apply to them. \u201cWe call them neutron stars, but we don\u2019t even have overwhelming evidence that they\u2019re made of neutrons. They could be made of more exotic materials,\u201d says Graham Woan, a LIGO astrophysicist at the University of Glasgow, UK. As it scans its first tranche of data, Einstein@home will look for neutron stars that are emitting waves with frequencies of between 20 hertz and 100 hertz (corresponding to rotation rates of between 10 hertz and 50 hertz), a range where LIGO's sensitivity has improved dramatically following the US$200 million upgrade. The professionals aren't leaving all the work to citizen-scientists, though. Whereas Einstein@home will look for signals that could be coming from anywhere in the Milky Way, scientists at LIGO and Virgo are planning to target known pulsars. Such targeted searches are computationally less intensive than the Einstein@home scans, so can run on a lab\u2019s computer. But they can also be very powerful. \u201cThey are probably the most sensitive observations which LIGO makes,\u201d Woan says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                 \n                   Young scientists poised to ride the gravitational wave 2016-Feb-16 \n                 \n                   Home computer finds rare pulsar 2010-Aug-12 \n                 \n                   Home computers search for gravity waves 2005-Feb-01 \n                 \n                   Nature Special: Gravitational waves \n                 \n                   Nature Special: General relativity at 100 \n                 \n                   Einstein@home \n                 \n                   SETI@home \n                 \n                   Maria Alessandra Papa \n                 \n                   Graham Woan \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19840", "url": "https://www.nature.com/articles/nature.2016.19840", "year": 2016, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "Concerns about the University of Manchester\u2019s National Graphene Institute reflect a broader decline in industrial research and development. The \u00a361-million (US$89-million)  National Graphene Institute (NGI ) at the University of Manchester, UK, has been open for little more than a year. But a  parliamentary inquiry  into the United Kingdom\u2019s efforts to capitalize on graphene is already putting the institute's progress under scrutiny. The inquiry, which heard evidence from key players in the graphene field last week, was prompted in part by allegations in the  Sunday Times  newspaper in March. These included concerns that the NGI was not doing enough to protect valuable intellectual property around graphene. The university has denied all these allegations. But senior research leaders say that hand-wringing about progress at the NGI typifies broader worries about the United Kingdom\u2019s approach to industrial research and development. \n             Commercial break \n           The NGI\u2019s host city styles itself the \u2018home of graphene\u2019: physicists Andre Geim and Kostya Novoselov first described their successful isolation of graphene 1  at the University of Manchester in a paper published in 2004, and they  shared the 2010 Nobel Prize in Physics for their work . The institute aims to bring academics and industry researchers together to develop applications for the atom-thin carbon material. It would put the United Kingdom \u201cin pole position to lead the world in graphene technology\u201d, said UK chancellor George Osborne when he officially opened the NGI in March 2015. But any impression that the NGI could churn out commercial products was unrealistic, researchers say. The institute does not have adequate funding to enable it to take applications from the lab bench to market, Geim told the UK House of Commons Science and Technology Select Committee on 26 April. Manchester received \u00a338 million in UK government funding to establish the NGI, but the university was expected to support ongoing operations; essentially, it was \u201cheld responsible for commercialization\u201d, he said. \u201cAll of it was done from the university's coffers,\u201d Geim added. \u201cThere was an initial building and equipment for the university, but there are no running costs.\u201d That makes the institute a perfect example, Geim said, of how UK universities have been expected to fill a void of industrial research and development (R&D) spending in some science sectors. Over the past 30 years, UK business R&D spending has dropped from 1.5% to 1.1% of gross domestic product, whereas in other leading economies, it has grown. In a statement to the inquiry, the University of Manchester said that the NGI has a goal of bringing graphene technology to a proof-of-concept stage. It stressed that although the NGI only has two \u2018strategic partners\u2019 for its graphene activities \u2014 companies that have the product engineering and design expertise needed to commercialize the material \u2014 it has almost 50 graphene-project partnerships with firms including BP and Airbus, and has raised \u00a37.4 million from those partnerships over the past 2 years. But those involved in the institute say that they are frustrated by the lack of UK commercial interest in graphene. \u201cIt's a big problem, trying to find the investment to take some of this innovation to market,\u201d says Colin Bailey, deputy president and deputy vice-chancellor of the University of Manchester. He had to look abroad to find a first strategic partner for the NGI \u2014 and even then, he had to become closely involved in guiding the firm's commercial plans (see 'A graphene case study'). \n             Business blues \n           The underlying problem is that the United Kingdom does not have many firms that are well placed to exploit graphene in commercial applications, says Richard Jones, pro-vice-chancellor for research and innovation at the University of Sheffield, UK. For graphene, which is renowned for its electrical conductivity, transparency and strength, the right kind of businesses might include battery manufacturers or electronic-display companies \u2014 not Britain\u2019s forte. That may illuminate another long-term nagging worry for the UK: the nation holds less than 1% of the world\u2019s graphene patents. (China holds about half; the world\u2019s single-largest graphene patent holder is South Korea\u2019s Samsung.) \u201cThere was never going to be an industrial base to exploit graphene in the UK, because we don't have the industries to do that,\u201d says David Price, vice-provost for research at University College London, who co-authored a written submission to the inquiry. Price questions whether the NGI offers the best model for translating research into applications. Nonetheless, the University of Manchester is about to start building a second graphene centre, aimed at helping new technologies to move through the later stages of commercial development. The Graphene Engineering Innovation Centre (GEIC) is expected to be completed next year, with its \u00a360-million price tag split between government funders and Masdar, a renewable-energy company based in Abu Dhabi. But if it wants to boost innovation, the UK government has to do more than create centres that supply new technologies, says Jones. \u201cThere\u2019s not enough focus on where the demand for new inventions is coming from, and how you promote that demand,\u201d he says \u2014 spin-outs and small enterprises cannot achieve a graphene revolution on their own. \n             boxed-text \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   UK scientists celebrate slight rise in research budget 2015-Nov-25 \n                 \n                   Andre Geim: Graphene\u2019s buzz has spread 2015-Jun-26 \n                 \n                   Graphene booms in factories but lacks a killer app 2015-Jun-17 \n                 \n                   The super materials that could trump graphene 2015-Jun-17 \n                 \n                   Britain\u2019s big bet on graphene 2012-Aug-06 \n                 \n                   House of Commons Science and Technology Committee graphene inquiry \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19502", "url": "https://www.nature.com/articles/nature.2016.19502", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Cases may signal start of anticipated wave of birth defects in country hit hard by Zika virus. Researchers have found Colombia's first cases of birth defects linked to the Zika virus,  Nature  has learned \u2014 which are likely forerunners of a widely anticipated wave of Zika-related birth defects in the country. The discovery is perhaps no surprise: the virus arrived in Colombia last September, and the country is second only to Brazil in terms of the number of people infected with Zika. But Colombian researchers hope that plans put in place to closely monitor pregnant women can help to better establish the magnitude of the threat posed to fetuses by Zika. That is a crucial question that scientists have  not so far been able to answer with the data from Brazil . Researchers have diagnosed one newborn with microcephaly \u2014 an abnormally small head \u2014 and two others with congenital brain abnormalities, says Alfonso Rodriguez-Morales, who chairs the Colombian Collaborative Network on Zika (RECOLZIKA), which made the diagnoses. All three tested positive for the presence of Zika virus. The researchers have submitted a report of their detections to a scientific journal. Rodriguez-Morales, an infectious-diseases epidemiologist at the Technological University of Pereira in western Colombia, says that he expects to see a rise in cases of Zika-linked birth defects starting in two or three months' time. The RECOLZIKA group \u2014 a network of researchers and public-health institutions across Colombia \u2014 are already investigating a handful of other suspected cases of microcephaly, which have a possible link to Zika. \n               The next wave? \n             Brazil is the only country so far to report a large surge in newborns with microcephaly that coincides with outbreaks of Zika virus. By the time the alarm over a possible microcephaly link was raised there (in October 2015), Zika infections had already peaked in many parts of the country, because the virus first reached Brazil at the beginning of last year. In Colombia, by contrast, researchers detected the first Zika cases in September, and by December had set up national tracking programmes to monitor pregnant women for signs of infection, and to spot early signs of birth defects in fetuses. Since then, researchers have been waiting attentively to see whether their country might experience a similar rise in birth defects. The true size of Brazil's surge in microcephaly cases is unknown. The country's health ministry says that 5,909 suspected microcephaly cases have been registered since early November, but only 1,687 of them have been investigated so far. Of those, 1,046 have been discarded as false positives, and 641 have been confirmed. (A link with the Zika virus has been confirmed by molecular-lab tests in 82 cases.) Given that Brazil reported only 147 cases of microcephaly in 2014, the reported increase in cases since November suggests a marked rise in the number of babies born with the condition. But the 2014 figure is a \u201chuge underestimate\u201d, says Lavinia Sch\u00fcler-Faccini, a geneticist who specialises in birth defects at the Federal University of Rio Grande do Sul, Brazil, and president of the Brazilian Society of Genetic Medicine. She says that according to the frequency of microcephaly typically observed in regions around the world, one would expect to see 300\u2013600 cases of severe microcephaly in any given year in Brazil, and around 1,500 less-severe ones. The search for cases of microcephaly in Brazil since October is probably turning up many mild cases that previously went unnoticed \u2014  so that the reported surge looks higher than it really is . Still, Sch\u00fcler-Faccini and other clinicians say there is a real problem. They have observed first-hand a marked increase in the number of unusually severe cases of microcephaly, they say. To be prepared to better interpret any imminent peak in birth defects in Colombia, RECOLZIKA plans to look at historical cases to establish a baseline for the annual numbers of birth defects in different regions. It is also setting up a study to analyse patterns in the distribution of head-circumference measurements recorded in obstetrics units regionally throughout the country, to get a better idea of the local range of normal values. \n               Zika's link to microcephaly \n             It has also not been possible so far from Brazilian data to quantify the extent to which Zika virus is linked to the rise in microcephaly. The latest data from Brazil's ministry of health show that increased cases of microcephaly and/or congenital malformations of the central nervous system are still concentrated in the northeast \u2014 raising questions as to whether other factors, perhaps specific to this region, might also be in play. Clinical evidence leaves little doubt that a link between Zika and microcephaly exists: the virus has been detected in amniotic fluid, in the cerebrospinal fluid of affected babies and in the brains of stillborn fetuses and those aborted after the detection of severe malformations during pregnancy. But there are also many other possible causes of microcephaly, including a group of infections that are collectively called STORCH (syphilis, toxoplasmosis, other infections, rubella, cytomegalovirus infection and herpes simplex), which are known to cause birth defects. Exposure to toxic chemicals and the consumption of alcohol during pregnancy can also cause the condition. \u201cThere is a clear need for a full assessment of other detailed causes of microcephaly, such as STORCH, and even non-infectious causes,\u201d says Rodriguez-Morales. Brazil\u2019s health ministry has stated that it is carrying out tests for such causes, but it has not made public how many of the confirmed microcephaly cases are attributable to these. \n               Healthy comparisons \n             A key question in assessing the scale of the threat that Zika may pose to fetuses is how many pregnant women infected with Zika \u2014 in particular during the first trimester, when the fetus is most vulnerable \u2014 nonetheless give birth to healthy babies. RECOLZIKA researchers hope to help to answer this through their monitoring programme. The risk posed by Zika may well be lower than that of other diseases that are known to cause microcephaly such as toxoplasmosis and rubella, says Rodriguez-Morales. That is a preliminary estimate, he says, based on back-of-the-envelope calculations of the reported numbers of confirmed cases of microcephaly and congenital disorders, compared to the number of pregnant women in regions experiencing Zika epidemics. But even if its risk does turn out to be low, Zika could still lead to many cases because a large number of pregnant women in the Americas are likely to become infected with the virus. The biggest risk to pregnant women is right now, rather than in the long term. The epidemic is sweeping so quickly through the Americas that much of the population, including young women, will become naturally vaccinated by their exposure to the virus. As population immunity increases, the Zika epidemic is likely to fade quickly, and it will become endemic with only occasional flare ups. In a modelling study posted to the preprint server bioRxiv 1  on 29 February, US researchers noted that the risk of prenatal Zika virus exposure \u201cshould decrease dramatically following the initial wave of disease, reaching almost undetectable levels\u201d. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Spectre of Ebola haunts Zika response 2016-Mar-02 \n                   \n                     Zika researchers release real-time data on viral infection study in monkeys 2016-Feb-23 \n                   \n                     Proving Zika link to birth defects poses huge challenge 2016-Feb-09 \n                   \n                     The next steps on Zika 2016-Feb-02 \n                   \n                     Zika virus: Brazil's surge in small-headed babies questioned by report 2016-Jan-28 \n                   Reprints and Permissions"},
{"file_id": "531015a", "url": "https://www.nature.com/articles/531015a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Scientists push for better monitoring of what remains. Following a record winter in many ways, Arctic sea-ice cover seems poised to reach one of its smallest winter maxima ever. As of 28\u00a0February, ice covered 14.525\u00a0million\u00a0square\u00a0kilometres, or 938,000\u00a0square\u00a0kilometres less than the 1981\u20132010 average. And researchers are using a new technique to capture crucial information about the thinning ice pack in near real time, to better forecast future changes. Short-term weather patterns and long-term climate trends have conspired to create an extraordinary couple of months, even by Arctic standards. \u201cThis winter will be the topic of research for many years to come,\u201d says Jennifer Francis, a climate scientist at Rutgers University in New Brunswick, New Jersey. \u201cThere\u2019s such an unusual cast of characters on the stage that have never played together before.\u201d The characters include the El Ni\u00f1o weather pattern that is pumping heat and moisture across the globe, and the Arctic Oscillation, a large-scale climate pattern whose shifts in recent months have pushed warm air northward. Together, they are exacerbating the  long-term decline of Arctic sea ice , which has shrunk by an average of 3% each February since satellite records began in 1979. A persistent ridge of high-pressure air perched off the US West Coast has steered weather systems around drought-stricken California, funnelling warmth northward. As a consequence, sea ice is particularly scarce this year in the Bering Sea. \u201cThe ice would normally be extensive and cold, but we have open water instead,\u201d says Francis. A storm last December compounded the situation by pushing warm air \u2014 more than 20\u2009\u00b0C above average \u2014 to the North Pole. In January, an Arctic Oscillation-driven warm spell heated the air above most of the Arctic Ocean. By February, ice had begun to circulate clockwise around the Arctic basin and out through the Fram Strait, says Julienne Stroeve, a researcher at the US National Snow and Ice Data Center (NSIDC) in Boulder, Colorado. Given the Arctic\u2019s  notoriously unpredictable weather , the low maximum doesn\u2019t necessarily foretell record-low melting this summer, when sea ice will reach its annual minimum. (The biggest summer melt on record  happened in 2012 , a year without an El Ni\u00f1o.) But researchers have one new tool with which to track the changes as they happen this year \u2014 the first detailed, near-real-time estimates of ice thickness, from the European Space Agency\u2019s CryoSat-2 satellite. Three research groups currently calculate Arctic ice thickness from satellite data, but with a lag time of at least a month. Faster estimates would allow shipping companies to better plot routes through the Arctic, and scientists to improve their longer-term forecasts of ice behaviour. \u201cThe quicker you have these estimates of sea-ice thickness, the quicker you can start assimilating them into models and make more timely predictions of what\u2019s going to happen,\u201d says Rachel Tilling, a sea-ice researcher at University College London. She and her colleagues have developed a faster way to get information on ice thickness from  CryoSat-2  (see \u2018Measuring stick\u2019). The satellite measures thickness by comparing the time that it takes for radar signals to bounce off the ice, as opposed to open water. Normally, it takes several months for satellite operators to calculate Cryo-Sat-2\u2019s precise orbit (and therefore the exact location of the ice and water that it flew over). But Tilling\u2019s group instead runs a quick-and-dirty analysis of orbital data, then combines it with near-real-time information on ice concentration from the NSIDC and ice type from the Norwegian Meteorological Service ( R.\u00a0L.\u00a0Tillingetal.CryosphereDiscuss.http://doi.org/bcw5;2016 ). The result is ice-thickness measurements that are ready in just 3 days, and accurate to within 1.5% of those produced months later. The current winter cycle is the first complete season for the near-real-time data. (The measurements cannot be done in the summer, when melt ponds on the ice confuse the satellite.) Tilling has begun to speak to shipping companies, among others, that are interested in using the data as fast as they are produced. \u201cIt really is a new era for CryoSat-2,\u201d she says. More-accurate ice-thickness data would improve climate models and give better forecasts for the possible impacts of thick or thin sea ice, says Nathan Kurtz, a cryosphere scientist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland. Kurtz helps to lead NASA\u2019s IceBridge project, which will begin flying aeroplanes north of Greenland later this month to measure ice thickness using lasers and an infrared camera that can detect heat from the underlying water. Thickness measurements are more crucial than ever, given the changing Arctic, says David Barber, a sea-ice specialist at the University of Manitoba in Winnipeg, Canada. He and his colleagues reported last year that there is increased open water all around the edge of the Arctic ice pack every month of the year ( D.\u00a0G.\u00a0Barber  et\u00a0al.   Prog. Oceanogr.   139 , 122\u2013150; 2015 ). \u201cWe\u2019re getting more open water in the winter than we were expecting,\u201d Barber says. \u201cThese changes are happening very quickly, and I don\u2019t think people are fully aware of how dramatic they are.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     US cold snap fuels climate debate 2014-Jan-08 \n                   \n                     Summer storms bolster Arctic ice 2013-Aug-28 \n                   \n                     Special issue on the Arctic: After the ice 2011-Oct-12 \n                   \n                     Blog post: Arctic sea ice declines to record low \n                   \n                     Arctic Sea Ice News \n                   \n                     Near-real-time Arctic ice thickness, from University College London \n                   \n                     Cryosphere Today \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19484", "url": "https://www.nature.com/articles/nature.2016.19484", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Study suggests stem-cell stimulation is behind obesity\u2019s contribution to cancer risk. Obese mice \u2014 like obese humans \u2014 are at increased risk of colon cancer, and a study published today in  Nature  finally suggests why. Overweight mice fed a high-fat diet showed an increase in intestinal stem cells due to activation of a protein called PPAR-\u03b4 that regulates metabolism 1 . If the results hold true in humans, they could explain a phenomenon seen in epidemiological studies. \u201cFor quite some time there\u2019s been an understanding that obesity leads to an increase in cancer in many tissues,\u201d says \u00d6mer Yilmaz, a cancer biologist at the Koch Institute for Integrative Cancer Research at the Massachusetts Institute of Technology (MIT) in Cambridge, and one of the leaders of the study. \u201cWe really wanted to understand the mechanism behind this.\u201d Those molecular details could be important, says cell biologist P. Kay Lund who works at the University of North Carolina in Chapel Hill and the National Institutes of Health in Bethesda, Maryland. Tissue samples from people who have undergone colonoscopies could be tested to see if the same patterns hold true. Ultimately, the increase in PPAR-\u03b4 activity could yield a useful indicator of cancer risk. \u201cIt could provide an opportunity to give those patients an earlier intervention,\u201d says Lund, who was not involved in the obesity work. \n             Model behaviour \n           Yilmaz teamed up with David Sabatini, who studies metabolism at MIT and the Whitehead Institute, also in Cambridge, to learn more about the link between cancer and obesity. Their teams fed mice high-fat, high-calorie chow for about a year, and then tested the effects of the diet on the number and function of stem cells in their intestines. They found that the diet, which was 60% fat, not only led the mice to overeat and become overweight, it also activated PPAR-\u03b4 and stimulated the proliferation of intestinal stem cells. Treating the mice with a drug that activates PPAR-\u03b4 yielded similar cellular regeneration. Stem cells are thought to be more likely to give rise to tumours than other cell types. For now, it is not clear whether the changes in the mice are due to weight gain \u2014 and the metabolic changes that come with it \u2014 or to fatty food. The team also tested the response of intestinal cells grown in three-dimensional cultures called \u2018organoids\u2019, to fatty acids found in the high-fat chow. Those cells also activated PPAR-\u03b4, suggesting that the fatty acids may have been acting directly on its expression. If so, it could be \u201ca mechanism in search of a relation that doesn\u2019t exist in humans\u201d, cautions Walter Willett, who studies nutrition at the Harvard T.H. Chan School of Public Health in Boston, Massachusetts. Greater body fat in humans has been linked to increased cancer risk, he says, but there is no firm evidence of a relationship between a fatty diet and cancer in humans, despite intensive study. But Yilmaz notes that epidemiological studies can be muddled by  confounding variables . \u201dThe data linking fat intake to cancer incidence is a mixed bag,\u201d he says. Yilmaz's team hopes to pick apart the role of fatty acids in cancer risk by conducting follow-up studies in normal-weight mice fed high-fat chow. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                 \n                   Low-fat diets have low impact 2015-Oct-30 \n                 \n                   Food preservatives linked to obesity and gut disease 2015-Feb-25 \n                 \n                   Gut microbes spur liver cancer in obese mice 2013-Jun-26 \n                 \n                   National Cancer Institute: Obesity and cancer \n                 Reprints and Permissions"},
{"file_id": "531019a", "url": "https://www.nature.com/articles/531019a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Agencies rush to show that outbreak tactics have improved. Public-health workers are still struggling to stamp out the Ebola epidemic in West Africa. But the lessons learned from that outbreak \u2014 which exposed major flaws in the global public-health system \u2014 are shaping the escalating international response to the spread of Zika virus in the Americas. \u201cEbola is the gorilla in the room,\u201d says Lawrence Gostin, a health-law and policy specialist at Georgetown University in Washington\u00a0DC. \u201cIt\u2019s driving everything.\u201d He and others say that governments and international public-health agencies seem determined not to repeat the main mistake that they made with Ebola:  waiting for much too long  to respond to a brewing outbreak. The delay allowed Ebola to grow so out of control in West Africa that the epidemic there persists after more than 2 years and 11,000 deaths. By contrast, the global health community has moved aggressively against Zika, beginning with a declaration from the World Health Organization (WHO) on 1 February that the clusters of microcephaly and other neurological disorders that have appeared in Brazil coincident with outbreak of the virus, and previously in French Polynesia, constitute an inter-national public-health emergency. The WHO has never yet made such a declaration before knowing the cause of the condition of concern. The August 2014 declaration that Ebola was a public-health emergency came after the disease had been spreading in West Africa for 8 months and had killed 932\u00a0people. But although Zika has probably infected as many as 1 million people in the latest outbreak, the vast majority have recovered. And scientists  have not proved a link between Zika and microcephaly , a condition in which infants are born with abnormally small heads and brains. \u201cThe WHO has perhaps gotten out ahead of its usual position of gathering and verifying all the evidence before taking a clear position,\u201d says Adam Kamradt-Scott, a health-security specialist at the University of Sydney in Australia. \u201cThe WHO couldn\u2019t afford to be seen to be asleep at the wheel a second time.\u201d Other authorities have taken similarly bold action. On 3 February, the US Centers for Disease Control and Prevention (CDC) moved its emergency-response operations centre to its highest activation level, jump-starting US government research into, and surveillance of, the Zika virus. On the same day, the United Kingdom announced the creation of a Zika research fund with an initial budget of up to \u00a31\u00a0million (US$1.4-million). And on 8 February, US President Barack Obama requested $1.8\u00a0billion from lawmakers for Zika-response activities. (By comparison, Obama\u2019s $6.18-billion request for Ebola-response funding came 3\u00a0months after that virus was declared a global emergency.) The ongoing mobilization against Zika is not an over-reaction, says Suerie Moon, a global-health researcher at the Harvard T.\u00a0H.\u00a0Chan School of Public Health in Boston, Massachusetts. Although Zika \u2014 unlike Ebola \u2014 is not usually fatal, it has the potential to cause suffering and social and economic havoc. \u201cIt\u2019s encouraging to see leadership and mobilization from WHO, CDC and other public-health institutions,\u201d Moon says. \u201cIt shows that some of the lessons from Ebola have been digested.\u201d WHO director-general Margaret Chan has acknowledged the agency\u2019s failings on Ebola, citing \u201cinadequacies and shortcomings in this organization\u2019s administrative, managerial and technical infrastructures\u201d in a speech last year. The Zika response also highlights persistent flaws of the global public-health system. Zika was first discovered in Africa in 1947, and caused a major outbreak in 2013 in the Pacific islands, but there is still no vaccine, treatment or common diagnostic test for the virus. Kamradt-Scott wonders if the world would be tracking Zika\u2019s spread so closely if the virus had not emerged in Brazil, where hundreds of thousands of tourists are scheduled to attend the Olympic Games in August. \u201cMy own perception is that the international community hasn\u2019t responded particularly swiftly to Zika,\u201d he says. Moon notes that although the WHO is trying to ensure that researchers in government, academia and industry  share data  on the outbreak, drug companies developing Zika vaccines have not publicly agreed to participate. The WHO has long struggled to modulate its response to global-health crises, Gostin says. After it was criticized for reacting too strongly to the 2009 H1N1 influenza epidemic \u2014 declaring a full-scale pandemic, when the virus itself did not prove as deadly as was initially feared \u2014 it dialled back its response to the Ebola outbreak. Now the WHO is mounting an urgent response to Zika, in light of criticism of its reaction to Ebola. To Gostin, this inconsistency reinforces a perception that the WHO acts mainly on the basis of political, not medical, factors. \u201cWe need to stop fighting the last war,\u201d he says. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Zika researchers release real-time data on viral infection study in monkeys 2016-Feb-23 \n                   \n                     Zika-microcephaly paper sparks data-sharing confusion 2016-Feb-12 \n                   \n                     Proving Zika link to birth defects poses huge challenge 2016-Feb-09 \n                   \n                     The next steps on Zika 2016-Feb-02 \n                   \n                     Spread of Ebola ends: 7 lessons from a devastating epidemic 2016-Jan-14 \n                   \n                     World Health Organization on Zika virus \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19439", "url": "https://www.nature.com/articles/nature.2016.19439", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Astronomers propose hunting for civilizations on worlds that can see our planet cross the Sun. By watching how the light dims as a planet orbits in front of its parent star, NASA\u2019s Kepler spacecraft has discovered  more than 1,000 worlds  since its launch in 2009. Now, astronomers are flipping that idea on its head in the hope of finding and talking to alien civilizations. Scientists searching for extraterrestrial intelligence should target exoplanets from which Earth can be seen passing in front of the Sun, says Ren\u00e9 Heller, an astronomer at the Max Planck Institute for Solar System Research in G\u00f6ttingen, Germany. By studying these eclipses, known as transits, civilizations on those planets could see that Earth has  an atmosphere that has been chemically altered by life . \u201cThey have a higher motivation to contact us, because they have a better means to identify us as an inhabited planet,\u201d Heller says. About 10,000 stars that could harbour such planets\u00a0should exist within about 1,000 parsecs (3,260 light years) of Earth, Heller and Ralph Pudritz, an astronomer at McMaster University in Hamilton, Canada,  report in the April issue of  Astrobiology 1 . They argue that future searches for signals from aliens, such as the  US$100-million Breakthrough Listen project , should focus on these stars, which fall in a band of space formed by projecting the plane of the Solar System out into the cosmos. Breakthrough Listen currently has no plans to search this region; it is targeting both the centre and the plane of our galaxy, which is not the same as the plane of the Solar System, as well as stars and galaxies across other parts of the sky. The idea of searching for worlds whose inhabitants could see Earth transits dates back to at least the 1980s. But astronomers can now update and revise their ideas thanks to what they have learned from Kepler, Heller says.\u00a0 \n             In the zone \n           The zone of space in which Earth transits would be visible is a relatively narrow strip. It gets even narrower if restricted to geometries in which the Earth passes less than half a solar radius from the Sun\u2019s centre \u2014 which gives a transit that should be easily visible, if aliens have a tool similar to Kepler. Heller and Pudritz went through a catalogue of stars compiled using data from the Hipparcos satellite and found 82 Sun-like stars in this zone that are\u00a0within 1,000 parsecs of Earth. Because not all of the stars in this region of space have been discovered, Heller and Pudritz extrapolated the number of known stars to the number that probably exists and came up with roughly 10,000 candidate stars. If these stars have planets, and if the planets have intelligent life forms, they could have long ago spotted the blink of an Earth transit and begun beaming signals towards us, Heller says. One of the closest known stars in the zone is Van Maanen\u2019s Star, only 4 parsecs away. It is a white dwarf star, the remains of a stellar explosion, and may or may not have planets orbiting it. But if they did exist, they would provide a ringside seat for watching Earth. \u201cIf any civilization survived the death of their star, they could see us transiting our own Sun,\u201d says Heller. For four days in 2010, the\u00a0 Allen Telescope Array \u00a0in northern California looked for signals coming from the region of space directly opposite the Sun, says Seth Shostak, an astronomer at the SETI (search for extraterrestrial intelligence) Institute in Mountain View, California. The goal was to test whether extraterrestrials might be timing any transmissions to reach Earth just as they see it transiting the Sun. No signs of aliens were found, and no follow-up is planned. \u201c Unfortunately, there are more good ideas for SETI experiments than there are SETI experimenters to act on them,\u201d says Andrew Siemion, an astronomer at the University of California, Berkeley. In the next five or so years, the  European Space Agency's Gaia satellite  is likely to discover most of the nearby stars in the Earth transit zone, Heller says. Until then, he and Pudritz plan to use data from  K2, the Kepler follow-on mission , to hunt directly for planets in the zone \u2014 and to look for aliens who might be looking for us. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The truth about exoplanets 2016-Feb-17 \n                 \n                   Search for extraterrestrial intelligence gets a $100-million boost 2015-Jul-20 \n                 \n                   Small stars host droves of life-friendly worlds 2013-Jan-09 \n                 \n                   The search for alien intelligence: SETI is dead \u2014 long live SETI 2011-Jul-27 \n                 \n                   Breakthrough Listen \n                 \n                   Kepler mission \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19494", "url": "https://www.nature.com/articles/nature.2016.19494", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "One paper suggests that fast radio bursts can repeat, but a finding on the origin of another burst is in doubt. Three reports within a week have astronomers aflutter about the puzzling origins of short, bright pulses of radio waves called fast radio bursts (FRBs). Shamini Bundell joins the search for the cosmic origin of mysterious fast radio bursts Last week, astronomers said that they had 1  identified the origins of an FRB for the first time \u2014 pinpointing the signal to a distant galaxy. And a paper published today 3  offers a different clue to the origins of FRBs, which have baffled astronomers since they were first observed nine years ago. It reports the discovery of a repeating signal: a surprise because all 17 known bursts so far have been one-off blips. But sceptics have questioned the first work, recording telescope observations within days of the announcement that cast doubt on the finding 2 . \n             Origin story \n           On 24 February, astronomers  announced that they had identified the origin of an FRB in a galaxy 1.9 billion parsecs (6 billion light years) away , probably produced by a collision between two neutron stars 1 . A network of telescopes had scanned the area of sky in which an FRB had been picked up by the Parkes radio telescope in New South Wales, Australia, and had discovered a fading afterglow of radio waves in an elliptical galaxy. The odds of finding such a radio signal by chance were just one or two in a thousand, wrote the team led by Evan Keane of the Square Kilometre Array Organisation, which is headquartered at the Jodrell Bank Observatory outside Manchester, UK. But two days later, astronomers Edo Berger and Peter Williams  argued in a paper posted on the preprint server arXiv 2  that the afterglow could, in theory, have come from a periodic radio-wave flare-up at the galaxy\u2019s core, where matter spirals into a supermassive black hole. The duo, of the Harvard\u2013Smithsonian Center for Astrophysics in Cambridge, Massachusetts, already had plans to test their hypothesis: they had submitted a proposal on the morning of Thursday 25 February to use the telescopes of the Very Large Array in New Mexico. They received approval the same night and their data arrived over the weekend. By the evening of Sunday 28 February, they  reported  on the Astronomer\u2019s Telegram \u2014 an online bulletin service \u2014 that they had re-measured radio signals from the elliptical galaxy\u2019s core. They found the signals had become brighter than the levels seen in Keane's last set of observations, which implies that the galaxy has flared up again and is indeed naturally variable. \n             \"Weak grounds\" \n           \u201cI think that puts the paper overall on pretty weak grounds,\u201d says Kiyoshi Masui of the University of British Columbia in Vancouver, Canada, who was not involved in either study. He gives Keane\u2019s result a \u201csignificantly worse\u201d than 50% chance of holding up. Williams estimates the odds that a galaxy producing its own radio-wave flare-ups could appear in that area of sky at roughly 10%, not the one in a thousand quoted by Keane\u2019s team. \u201cI don\u2019t know why the referees didn\u2019t make them do more work to reject the hypothesis,\u201d he says. On Twitter, he  added that  he was \u201cdisappointed\u201d with the referees,  and that  \u201csomething has failed badly when it takes a half-day of work to raise serious questions about a result launched with fanfare\u201d. Leslie Sage, a physical sciences editor for  Nature , says that the journal cannot comment on the peer-review process for the paper. ( Nature \u2019s news team is editorially independent of its research team.) Keane says that he and his colleagues are considering the latest analysis and are continuing their own studies. They will report their findings in the peer-reviewed scientific literature, \u201cwhich is where scientific debate happens\u201d, Keane says. \u201cWe really can\u2019t rush the scientific process,\u201d he adds. \n             Play it again \n           In a separate paper published today in  Nature 3 , astronomers report that an FRB first found in 2013 by combing the data archive of Arecibo Observatory in Puerto Rico was spotted again on follow-up observations with the ultra-sensitive radio dish in May and June 2015. The signal was seen ten times last year, with some bursts less than a minute apart. These encore appearances came as a surprise \u2014 and will change how researchers think about the bursts\u2019 origins, says astronomer Laura Spitler of the Max Planck Institute for Radio Astronomy in Bonn, Germany, the first author of the study. An FRB that repeats cannot be caused by a single cataclysmic collision between objects such as neutron stars, for example. Also striking is that some of the pulses are stronger at higher radio frequencies than at lower ones \u2014 the opposite of most astronomical radio signals. Spitler thinks this means that the FRB comes from a neutron star with a strong magnetic field. Some researchers have proposed that a class of such objects called magnetars could be responsible for the bursts 4 . But Spitler favours a different strongly magnetic species: a type of pulsar that spins more rapidly than magnetars but is capable of intermittent giant pulses of radiation. The most famous example is the Crab Pulsar. Taken with Keane\u2019s finding, Spitler\u2019s results would suggest that FRBs have at least two possible sources, notes Masui. \u201cBut now I\u2019d argue that since there\u2019s a lot of doubt cast on last week\u2019s result, there\u2019s no evidence that there are two classes,\u201d he says. If FRBs are the result of giant pulses, they might not be from the distant cosmos at all \u2014 they would only be strong enough to be detected from galaxies in the neighbourhood of the Milky Way. That would be a disappointment to cosmologists, who hoped that Keane\u2019s study meant that FRBs could be used as  beacons to map the broad structure of the Universe , because the radio pulses would be shaped by the matter they pass through. The fog of confusion may soon lift. Three telescopes that will be able to detect several FRBs each day are set to begin operations or ramp up this year \u2014 meaning that astronomers could soon be \u201coverwhelmed\u201d by the signals, as astronomer Duncan Lorimer of West Virginia University in Morgantown  told  Nature  last week . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Mysterious radio burst pinpointed in distant galaxy 2016-Feb-24 \n                 \n                   Mysterious radiowave blast may have come from starquake 2015-Dec-02 \n                 \n                   Mystery extra-galactic radio bursts could solve cosmic puzzle 2013-Jul-04 \n                 Reprints and Permissions"},
{"file_id": "531018a", "url": "https://www.nature.com/articles/531018a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Country\u2019s austerity budget stands in way of law to modernize Soviet-era academy. As political turmoil and conflict rock Ukraine, the country\u2019s main scientific organization is in a bind. In January, Parliament passed a law to modernize the ailing National Academy of Sciences of Ukraine (NASU). Yet an austerity budget imposed around the same time makes this impossible to achieve \u2014 at least this year. The resulting cuts to science funding threaten the jobs of young researchers in particular, who are best poised to revitalize the country\u2019s failing economy. \u201cWe have an extraordinarily high number of potential young scientists who are ready to work for the welfare of the country,\u201d says Liliya Hrynevych, who chairs the Ukrainian Parliament\u2019s Committee on Science and Education and voted in favour of the modernizing law. \u201cBut without setting priorities for science and research, it will be impossible for Ukraine to become a strong and wealthy European nation.\u201d The academy employs some 20,000 scientists across 120 research institutes. On 26 November, Parliament began to debate a \u201claw of Ukraine on scientific and technical activity\u201d, in an attempt to streamline and strengthen the organization, which was founded in the Soviet era. Long deemed outdated and resistant to modernization, the academy uses an opaque system to award funding, and many of its members are elderly, not least the 97-year-old metallurgist Boris Paton, who has run the NASU for decades. The law stipulates the creation of a science advisory council that includes foreign specialists, and an independent grant-giving agency. All NASU institutes will undergo an external evaluation to examine their productivity and efficiency, and overall, government science spending must increase from a current 0.3% of gross domestic product to at least 1.7% by fiscal year 2017 \u2014 near the European Union average. But before the law took effect, Ukraine passed its 2016 austerity budget, in the wake of widespread closure of mines and factories, inflation, debt and currency devaluation. The budget allocates a meagre 2.05 billion hryvnia (US$76 million) to the NASU \u2014 about 12% less than in 2015, continuing a trend of decline (see \u2018Ailing academy\u2019). The cutbacks are irreconcilable with the science law, says Hrynevych, who is campaigning in Parliament for a budget revision after the first quarter of 2016. The budget will leave the academy with scarcely enough to cover the scant salaries (about US$200 per month on average) paid to its administrative staff and scientists. \u201cWe won\u2019t be able to buy any new equipment this year, and purchase of consumables will need to be reduced to a minimum,\u201d says Anatoly Zagorodny, director of the Bogolyubov Institute for Theoretical Physics in Kiev and a vice-president of the academy. The fresh cuts, he says, will also force institutes to reduce staff \u2014 in some circumstances, by more than one-third \u2014 and to discontinue many areas of research, even though science is crucial to economic recovery, he adds. Young scientists are the least protected by existing labour laws and so will feel the brunt of the job cuts, says Irina Yehorchenko, a research fellow at the NASU\u2019s Institute of Mathematics in Kiev. She and some of her colleagues launched a petition in December calling on the country\u2019s president, Petro Poroshenko, to save Ukrainian science. \n               Youthful potential \n             \u201cI, for one, might be able to find a postdoc position abroad,\u201d says Oleksandr Skorokhod, a cell biologist at the NASU Institute of Molecular Biology and Genetics in Kiev who is chair of the academy\u2019s Council of Young Scientists. \u201cBut I\u2019d much rather stay and try to change the bad state of affairs in my country.\u201d Ukrainian science has struggled to recover from Russia\u2019s annexation of the Crimea peninsula in 2014. General consensus in the international community is that Crimea is still part of the Ukraine \u2014 the United Nations General Assembly declared invalid a March 2014 referendum in which voters in Crimea approved the peninsula\u2019s secession from Ukraine. But all 22 Crimean institutes formerly run by the NASU are now under Russian control, and only a few of their 1,320 staff members have relocated to Ukraine-controlled territory. The academy lost access to its only research ship, the RV  Professor Vodianytsky , three astronomical observatories in Nauchny, Katsiveli and Yevpatoria and the 204-year-old Nikitsky Botanical Garden near Yalta, on the Black Sea shore. The Ukrainian government, moreover, expects scientists in Ukraine to cut all ties with colleagues who stayed on the peninsula, says Hrynevych, because any collaboration would be viewed as legitimizing the Russian occupation. The armed conflict with pro-Russian militants in eastern Ukraine is also causing problems for scientists, especially in the country\u2019s Donbas region. Some 12,000 scientists and university lecturers there \u2014 about 60% of the former staff of 26 research institutes and universities in the province \u2014 have moved to safe institutions in Kiev and elsewhere. But many evacuating scientists left behind equipment or lost irreplaceable research material. Marine, environmental and climate studies in the Black Sea region, mining-related geology and a variety of archaeological and historical research have all been hit hard, says Zagorodny. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Ukraine joins flagship European research programme 2015-Mar-20 \n                   \n                     Putin\u2019s Russia divides and enrages scientists 2014-Dec-16 \n                   \n                     Ukraine\u2019s science in turmoil 2014-Apr-01 \n                   \n                     Ukrainian scientists in forefront of protest 2014-Jan-28 \n                   \n                     Ukranian science: DIY, Kiev style 2002-Apr-18 \n                   \n                     National Academy of Sciences of Ukraine \n                   \n                     Petition \u2018Save Ukrainian science\u2019 \n                   \n                     Horizon 2020 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19498", "url": "https://www.nature.com/articles/nature.2016.19498", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Reanalysis of last year's enormous replication study argues that there is no need to be so pessimistic. Is psychology facing a \u2018replication crisis\u2019? Last year, a crowdsourced effort that was able to validate fewer than half of 98 published findings 1   rang alarm bells about the reliability of psychology papers . Now a team of psychologists has reassessed the study and say that it provides no evidence for a crisis. \u201cOur analysis completely invalidates the pessimistic conclusions that many have drawn from this landmark study,\u201d says Daniel Gilbert, a psychologist at Harvard University in Cambridge, Massachusetts, and a co-author of the reanalysis, published on 2 March in  Science 2 . But a response 3  in the same issue of  Science  counters that the reanalysis itself depends on selective assumptions. And others say that psychology still urgently needs to improve its research practices. \n             Statistical criticism \n           In August 2015, a team of 270 researchers reported the largest ever single-study audit of the scientific literature. Led by Brian Nosek, executive director of the Center for Open Science in Charlottesville, Virginia, the Reproducibility Project attempted to replicate studies in 100 psychology papers. (It ended up with 100 replication attempts for 98 papers because of problems assigning teams to two papers.) According to one of several measures of reproducibility,  just 36% could be confirmed ; by another statistical measure, 47% could 1 . Either way, the results looked worryingly feeble. Not so fast, says Gilbert. Because of the way the Reproducibility Project was conducted, its results say little about the overall reliability of the psychology papers it tried to validate, he argues. \u201cThe number of studies that actually did fail to replicate is about the number you would expect to fail to replicate by chance alone \u2014 even if all the original studies had shown true effects.\" Gilbert's team tries to calculate an expected replication rate based on the Reproduciblity Project's protocol. Some replication attempts weren't faithful copies of the original paper, for instance \u2014 making a replication less likely, Gilbert says. And each replication study was attempted just once, giving the project limited statistical power to confirm the original findings. To make his point, Gilbert refers to an earlier work by Nosek, called the Many Labs Replication Project,  in which 36 separate laboratories tried to replicate 13 findings . That project validated 10 findings, but looking at any one lab\u2019s replication effort might have suggested failure. Overall, Gilbert\u2019s team concludes, the Reproducibility Project failed to account for important sources of uncertainty in its analysis. \u201cWhile no study is perfect, it is clear that the reproducibility of psychological studies is not as bad as the original  Science  article characterized,\u201d says Kosuke Imai, a statistician at Princeton University in New Jersey. \n             Neither good nor bad \n           But the reanalysis does not show that psychology\u2019s reproducibility rate is high, says Uri Simonsohn, a social psychologist at the University of Pennsylvania in Philadelphia. He notes that other statistical reassessments of the project (one of which was published in  PLoS ONE  last week 4 , and another of which Simonsohn has reported  on the blog Data Colada ) both suggest that about one-third of the replications are inconclusive, in that they neither strongly confirm nor refute the original results. In general, replication efforts are likely to be more-reliable guides to the existence (and magnitude) of effects in psychology experiments than are the original studies, says Andrew Gelman, a statistician at Columbia University in New York. That\u2019s in part because what is published in the original studies tends to be the statistical \u2018flukes\u2019 that are left standing after the researchers have cast around to find publishable, positive results. In contrast, for replication projects analysis plans are put in place before a study begins. Nosek says that he is glad to see other researchers poring over the data. But he and his co-authors respond in  Science  that Gilbert\u2019s \u201coptimistic assessment is limited by statistical misconceptions\u201d. Although some of the Reproducibility Project's replications didn't faithfully copy the methods of the papers they were testing, in many cases the original authors endorsed the methods used, Nosek says. The Many Labs project is a misleading comparison, he and his co-authors say. And the Reproducibility Project used five measures of reproducibility that coalesced around similar values, which together suggest that most effects -- even if they do exist -- are likely to be much smaller than the original results suggested. Nosek tells  Nature  that the Gilbert team has crafted an exploratory hypothesis that is very optimistic but cannot be seen as definitive. \u201cBoth optimistic and pessimistic conclusions about reproducibility are possible, and neither are yet warranted,\u201d he and his co-authors conclude in their response. \n             Economics versus psychology \n           Another paper published today in  Science  reports results from a project to replicate economics studies 5 . It found that at least 11 of 18 studies could be reproduced, increasing to 14 when using different criteria to assess reproducibility. But Nosek, who was not involved in the study, says that it is hard to conclude from this that economics has a higher replication rate than psychology. Not only was the number of studies replicated small, he says, but the studies focused on simple relationships. Nonetheless, the size of effects found in the replication and original studies are closer in the economics study than in the psychology one, says study author, Colin Camerer, a behavioural economist at the California Institute of Technology in Pasadena. \u201cIt is like a grade of B+ for psychology versus A\u2013 for economics,\u201d he says.\u201c\u00a0There is room for improvement in both fields.\u201d Overall, knowing the exact replication rate for any discipline is not essential for knowing what needs to happen next, says Steve Lindsay, a psychologist at the University of Victoria in Canada and interim editor of the journal  Psychological Science . \u201cWe have a lot of reasons to believe that a lot of psychologists have for a long time tended to systematically exaggerate the effects of what they publish,\u201d he says; the real urgency is to improve bad practices. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Over half of psychology studies fail reproducibility test 2015-Aug-27 \n                 \n                   First results from psychology\u2019s largest reproducibility test 2015-Apr-30 \n                 \n                   Scientific method: Statistical errors 2014-Feb-12 \n                 \n                   Replication studies: Bad copy 2012-May-16 \n                 Reprints and Permissions"},
{"file_id": "531020a", "url": "https://www.nature.com/articles/531020a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Waning warming event studied in unprecedented detail. Floods have ravaged parts of South America. Crops are drying up in Africa. Corals are bleaching around the world. The epic El\u00a0Ni\u00f1o warming event in the tropical Pacific Ocean has boosted temperatures and affected people and ecosystems around the globe. And thanks to a combination of luck and determination, scientists have been  better placed than ever  to record its evolution. \u201cWhen you have an event this big, you really want to squeeze as much out of it as you can,\u201d says Michael McPhaden, an oceanographer at the US National Oceanic and Atmospheric Administration (NOAA) in Seattle, Washington, who helps to manage an array of buoys that is used to monitor El\u00a0Ni\u00f1o conditions. \u201cAnd we were well positioned at the beginning of 2015 to watch this thing unfold.\u201d Had the El\u00a0Ni\u00f1o occurred a year earlier\u00a0\u2014 as originally predicted\u00a0\u2014 McPhaden\u2019s team would not have been ready. In early 2014, the Tropical Atmosphere Ocean (TAO) array was on the verge of collapse. NOAA eventually  restored the array  after oceanographers raised concerns that they\u00a0\u2014 as well as weather forecasters\u00a0\u2014 would be deprived of crucial data if a major El\u00a0Ni\u00f1o arrived. El\u00a0Ni\u00f1o and its counterpart, La\u00a0Ni\u00f1a\u00a0\u2014 which is defined by a cooling of the equatorial Pacific\u00a0\u2014 have powerful knock-on effects around the globe. This oscillation forms the basis of most seasonal weather predictions, and scientists are mining the data for clues that will improve those predictions. NOAA has spent roughly US$3\u00a0million to deploy aircraft, a research ship and hundreds of weather balloons to  capture as much data  as possible before the El\u00a0Ni\u00f1o fades in the next few months. And the US National Science Foundation (NSF) has awarded 19 \u2018rapid response\u2019 research grants, totalling $2.3\u00a0million, to researchers studying the event. Many of the NSF projects focus on the effects of warm seawater on coral reefs; if water is too hot, corals bleach, expelling the colourful algae that feed them. The current bleaching event began in Guam in 2014 and has since spread to the Atlantic and Indian oceans as El\u00a0Ni\u00f1o has warmed the seas (see \u2018Selected El\u00a0Ni\u00f1o impacts\u2019). More than 60% of the world\u2019s corals could be affected in the next few months, and with NOAA predicting that bleaching will continue into 2017, that number could rise. \n               Selected El Ni\u00f1o impacts \n               Scientists and policymakers often focus on the long-term risk posed by carbon dioxide emissions and ocean acidification. The  current bleaching event\u00a0 \u2014 already the longest on record\u00a0\u2014 has shone a spotlight on the immediate danger posed by rising ocean temperatures. \u201cOcean acidification may be much less of a problem than we feared, but that\u2019s only because many of the corals will be dead before we get there,\u201d says Mark Eakin, who heads NOAA\u2019s Coral Reef Watch. In other cases, scientists were lucky to be able to watch El Ni\u00f1o unfold. Daniel Rudnick, an oceanographer at the University of California, San Diego, and his colleagues received grants from the NSF and NOAA in 2012 and 2013 to deploy a trio of underwater gliders in the tropical Pacific from 2013\u201316. The team also released 41 new Argo floats\u00a0\u2014 roughly double the previous number\u00a0\u2014 along the Equator to collect temperature and salinity data down to 2,000 metres. In November 2013, the gliders began to collect high-resolution measurements of the subsurface ocean current\u2019s eastward flow. The monitoring will continue this year. \u201cIt\u2019s been shown that the undercurrent strengthens during El\u00a0Ni\u00f1o, but what we have, I think, is a more finely resolved picture of its size,\u201d Rudnick says. \u201cIt was serendipity with a capital \u2018S\u2019.\u201d Rudnick presented preliminary data on 23\u00a0February at an American Geophysical Union conference in New Orleans, Louisiana. The observations document the under-current\u2019s evolution in 2014, when the forecasted El\u00a0Ni\u00f1o fizzled, and in 2015, when it roared back. By comparing the oceanic and atmospheric conditions in both years, scientists hope to gain insights that will improve future weather forecasts. The focus is often on the trade winds, which usually blow to the west across the Equator. Alexey Fedorov, an oceanographer at Yale University in New Haven, Connecticut, says that 2014 and 2015 both saw significant bursts of eastward winds in June, which began to push warm surface waters towards South America. In 2014, a burst of westward winds in August, driven by atmospheric patterns in the Southern Hemisphere, cut that process short\u00a0\u2014 but helped to set the stage for the massive El\u00a0Ni\u00f1o in 2015. Fedorov says that there is no evidence that those winds could have been forecast, even by the most advanced climate models. \u201cSometimes we are right, sometimes we are wrong,\u201d he says. \u201cThere was no chance to predict this.\u201d Although temperatures in the tropical Pacific are near their peak, McPhaden says that El\u00a0Ni\u00f1o\u2019s energy is quickly dissipating below the surface. \u201cIt\u2019s very clear that this El\u00a0Ni\u00f1o is losing its steam,\u201d he says. And that poses another crucial question for oceanographers and climate scientists: whether this El\u00a0Ni\u00f1o will transition into a major La\u00a0Ni\u00f1a, as happened after the last big El\u00a0Ni\u00f1o in 1997\u201398. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Monster El Ni\u00f1o probed by meteorologists 2016-Jan-20 \n                   \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   \n                     Corals worldwide hit by bleaching 2015-Oct-08 \n                   \n                     Climate change: The case of the missing heat 2014-Jan-15 \n                   \n                     NOAA El Ni\u00f1o Campaign \n                   \n                     Coral Reef Watch \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19500", "url": "https://www.nature.com/articles/nature.2016.19500", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Text-mining analysis finds that studies fall short of best practice \u2014 despite guidelines introduced in 2010. The largest-ever analysis of the quality of mouse studies reveals that as recently as 2014, only around 50% of research papers recorded both the sex and age of the animals used \u2014 key details needed for others to assess and reproduce the research 1 . The analysis, which used software to trawl through the text of more than 15,000 open-access papers published between 1994 and 2014, also reveals the preferences of different research fields. Cardiovascular research tends to use male mice, whereas research on infectious diseases such as HIV and tuberculosis favours female mice, for example. The study is \u201cthe strongest evidence about sex and age bias through biomedical research to date\u201d, say its authors. \n             Sex matters \n           Many researchers have pointed out that male and female mice \u2014 like men and women \u2014 can have different responses to drugs or different behaviours in laboratory experiments. One study last year, for instance, found 2  that although inhibiting the function of immune cells called microglia helps to relieve pain in male mice, it  doesn\u2019t do so in female mice . The difference might explain why some clinical trials of pain drugs have failed. Recognizing the problem, the US National Institutes of Health  said in 2014  that it would require researchers to report their plans for the balance of male and female animals in preclinical studies. But even before that, scientists had been  urged to report in more detail  the strains, sexes and ages of the mice they experimented on. \u201cIt\u2019s useful to see what\u2019s happening in a large-scale study \u2014 which has thrown up some things we weren\u2019t expecting,\u201d says Andrew Brass, a bioinformatician at the University of Manchester, UK, and a co-author of the study, which is  published in  eLife 1 . One surprise was that although recording of animal studies improved through the 1990s and 2000s, standards seem to have plateaued after 2010 \u2014 despite the introduction that year of a voluntary checklist to improve reporting, called the  ARRIVE guidelines 3 . \n             Text-mining power \n           The study shows the power of being able to mine the full text of research papers, says Malcolm Macleod, a stroke researcher and specialist in trial design at the University of Edinburgh, UK. But he notes that the fully open papers that can be mined may not be representative of the entire scientific literature: scientists who want to make their papers open may be \u201camong the more enlightened\u201d, he suggests. Previous research has consistently suggested that researchers tend to use male mice in studies \u2014 but the  eLife  paper reports that, where the sex of animals is recorded, the mice are more likely to be female. That surprises Caroline Zeiss, a veterinary neuropathologist at Yale University in New Haven, Connecticut. The discrepancy might result from biases in the specific fields of research that the  eLife  paper examined, she says. The sex bias varied according to the type of biomedical study, and even between studies of the same disease. Diabetes research, for example, was found to be male-biased overall \u2014 but studies on the immunology of the condition tended to use female mice. There was no correlation between reporting standards and the impact factor of the journal in which the studies were published, the researchers found. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   A mouse\u2019s house may ruin experiments 2016-Feb-12 \n                 \n                   Poorly designed animal experiments in the spotlight 2015-Oct-13 \n                 \n                   Sex divide seen in mechanism that produces persistent pain 2015-Jun-29 \n                 \n                   Policy: NIH to balance sex in cell and animal studies 2014-May-14 \n                 \n                   Sex bias blights drug studies 2010-Mar-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19495", "url": "https://www.nature.com/articles/nature.2016.19495", "year": 2016, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "Invention could help the microelectronics industry to connect circuit-board components without risking heat damage. Put away that hot iron, and stow the solder: you can now forge a connection between two bits of metal at room temperature. Soldering is a mainstay of the microelectronics industry, which uses hot molten metal to connect components on printed circuit boards. But conventional hot soldering techniques can sometimes damage the materials used in flexible electronic devices, or the ever-smaller parts on today\u2019s microchips. Martin Thuo at Iowa State University in Ames has now developed a clever way of soldering that requires no heat, using an alloy of bismuth, indium and tin called Field\u2019s metal. At room temperature, this mixture is normally a solid \u2014 it melts at 62 \u00b0C. But if tiny droplets of the molten metal are encapsulated in a protective shell, they remain liquid when the shell cools and solidifies. This effect, known as undercooling or supercooling, arises because the liquid metal is prevented from coming into contact with anything that triggers solidification \u2014 a speck of dust, say. The effect has been widely studied, but until now there was no way to make stable undercooled metal particles in a readily usable form. \u201cThey\u2019re almost like water balloons of liquid metal,\u201d explains Michael Dickey, a materials scientist at North Carolina State University in Raleigh. Crushing the particles releases the liquid metal, which quickly solidifies to form a neat, conductive solder joint. \u201cI haven\u2019t seen this before, I think it\u2019s quite unique,\u201d says Johan Liu, a materials scientist at Chalmers University of Technology in Gothenburg, Sweden, who develops techniques for electronics manufacturing. In one demonstration, Thuo\u2019s team put the liquid-metal particles on a thin film of gold, and placed a thin gold wire on top. They rolled a glass rod over the assembly to squish the particles, and within seconds the wire was firmly stuck to the film (see video, Heat-free soldering). The particles could also repair a hole in a thin film of silver, or stick foils of gold and aluminium together. For precision work, the particles can be punctured with the tungsten probe of a scanning electron microscope (see video, Puncturing a liquid metal 'balloon' using a microprobe), or a beam of ions. The work is published in  Scientific Reports 1 .  \n             Metal soup \n           Thuo\u2019s team made the particles by adding molten Field\u2019s metal to a solution of acetic acid in a common solvent called diethylene glycol, and whizzing it up with a power tool running at 17,000 r.p.m. to break the metal into tiny droplets. (\u201cA heated soup maker also gives really good particles,\u201d notes Thuo.) The droplets first react with air to form a thin oxide shell that is less than a nanometre thick, and then further react with acetic acid to form a second nanolayer. This adds flexibility so that the shell doesn\u2019t crumble once it cools. Changing the details of the recipe, such as the viscosity of the liquid or the blending speed, can produce particles ranging in size from 4 nanometres to 5 micrometres in diameter. Once the particles have been filtered from solution, they can be stored for months without breaking down. Thuo has recently set up a company called Safi-Tech to commercialize the technology, and hopes to sell the particles to the microelectronics industry. Liu reckons that the manufacturing method looks scalable, and that the research offers a useful proof of concept. But he adds that the microelectronics industry would certainly want to know more about the reliability of the joint, and whether it has any long-term corrosion issues. Thuo is now testing other alloys that have higher melting points, which could be used as solders in microelectronic applications that must withstand temperatures above 62 \u00b0C (when the Field\u2019s metal solder would melt). His team has already found that a mixture of bismuth and tin, which normally melts at 139 \u00b0C, can be encapsulated in liquid form at room temperature just like Field\u2019s metal. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Liquid-metal batteries get boost from molten lead 2014-Sep-21 \n                 \n                   Super-material shrugs off molten metal 2013-Nov-20 \n                 \n                   Nanotechnology solders on 2001-Jun-22 \n                 \n                   Turning on the nanoworld 2000-Nov-02 \n                 \n                   Martin Thuo \n                 \n                   Safi-Tech \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19503", "url": "https://www.nature.com/articles/nature.2016.19503", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Policy statement aims to halt missteps in the quest for certainty. Misuse of the  P  value \u2014 a common test for judging the strength of scientific evidence \u2014 is contributing to the number of research findings that  cannot be reproduced , the American Statistical Association (ASA) warns in a  statement  released today 1 . The group has taken the unusual step of issuing principles to guide use of the  P  value, which it says cannot determine whether a hypothesis is true or whether results are important. This is the first time that the 177-year-old ASA has made explicit recommendations on such a foundational matter in statistics, says executive director Ron Wasserstein. The society\u2019s members had become increasingly concerned that the  P  value was  being misapplied  in ways that cast doubt on statistics generally, he adds. In its statement, the ASA advises researchers to avoid drawing scientific conclusions or making policy decisions based on  P  values alone. Researchers should describe not only the data analyses that produced statistically significant results, the society says, but all statistical tests and choices made in calculations. Otherwise, results may seem falsely robust. V\u00e9ronique Kiermer, executive editor of the Public Library of Science journals, says that the ASA\u2019s statement lends weight and visibility to longstanding concerns over undue reliance on the  P  value. \u201cIt is also very important in that it shows statisticians, as a profession, engaging with the problems in the literature outside of their field,\u201d she adds. \n               Weighing the evidence \n             P  values are commonly used to test (and dismiss) a \u2018null hypothesis\u2019, which generally states that there is no difference between two groups, or that there is no correlation between a pair of characteristics. The smaller the  P  value, the less likely an observed set of values would occur by chance \u2014 assuming that the null hypothesis is true. A  P  value of 0.05 or less is generally taken to mean that a finding is statistically significant and warrants publication. But  that is not necessarily true , the ASA statement notes. A  P  value of 0.05 does not mean that there is a 95% chance that a given hypothesis is correct. Instead, it signifies that if the null hypothesis is true, and all other assumptions made are valid, there is a 5% chance of obtaining a result at least as extreme as the one observed. And a  P  value cannot indicate the importance of a finding; for instance, a drug can have a statistically significant effect on patients\u2019 blood glucose levels without having a therapeutic effect. Giovanni Parmigiani, a biostatistician at the Dana Farber Cancer Institute in Boston, Massachusetts, says that misunderstandings about what information a  P  value provides often crop up in textbooks and practice manuals. A course correction is long overdue, he adds. \u201cSurely if this happened twenty years ago, biomedical research could be in a better place now.\u201d \n               Frustration abounds \n             Criticism of the  P  value  is nothing new . In 2011, researchers trying to raise awareness about false positives gamed an analysis to reach a statistically significant finding: that listening to music by the Beatles makes undergraduates younger 2 . More controversially, in 2015, a set of documentary filmmakers published conclusions from a purposely shoddy clinical trial \u2014 supported by a robust  P  value \u2014 to show that eating chocolate helps people to lose weight. (The article has since  been retracted .) But Simine Vazire, a psychologist at the University of California, Davis, and editor of the journal  Social Psychological and Personality Science , thinks that the ASA statement could help to convince authors to disclose all of the statistical analyses that they run. \u201cTo the extent that people might be sceptical, it helps to have statisticians saying, \u2018No, you can't interpret  P  values without this information,\u201d she says. More drastic steps, such as  the ban on publishing papers that contain  P  values  instituted by at least one journal, could be counter-productive, says Andrew Vickers, a biostatistician at Memorial Sloan Kettering Cancer Center in New York City. He compares attempts to bar the use of  P  values to addressing the risk of automobile accidents by warning people not to drive \u2014 a message that many in the target audience would probably ignore. Instead, Vickers says that researchers should be instructed to \u201ctreat statistics as a science, and not a recipe\u201d. But a better understanding of the  P  value will not take away the human impulse to use statistics to create an impossible level of confidence, warns Andrew Gelman, a statistician at Columbia University in New York City. \u201cPeople want something that they can't really get,\u201d he says. \u201cThey want certainty.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Smart software spots statistical errors in psychology papers 2015-Oct-28 \n                   \n                     How scientists fool themselves \u2013 and how they can stop 2015-Oct-07 \n                   \n                     Statistics: P values are just the tip of the iceberg 2015-Apr-28 \n                   \n                     Psychology journal bans P values 2015-Feb-26 \n                   \n                     Number crunch 2014-Feb-12 \n                   \n                     Scientific method: Statistical errors 2014-Feb-12 \n                   \n                     Weak statistical standards implicated in scientific irreproducibility 2013-Nov-11 \n                   \n                     Nature  special: Challenges in irreproducible research \n                   \n                     American Statistical Association \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19541", "url": "https://www.nature.com/articles/nature.2016.19541", "year": 2016, "authors": [{"name": "Tanguy Chouard"}], "parsed_as_year": "2006_or_before", "body": "Nature  reports from a battle of man vs computer over the Go board. Seoul, South Korea Tanguy Chouard, an editor with  Nature , saw Google-DeepMind\u2019s AI system AlphaGo defeat a human professional for the first time last year at the ancient board game Go. This week, he is watching top professional Lee Sedol take on AlphaGo, in Seoul, for a $1 million prize. I\u2019m at the Four Seasons hotel in Seoul, where tomorrow Lee Sedol, one of the strongest players in the world at the board game Go, will take on the AI computing system AlphaGo. (You can watch the first match on 9 March from 13:00 KST/04:00 GMT, or 23:00 ET on 8 March, at the livestream below). Media excitement is high: hundreds of journalists were bursting with detailed questions and flash cameras at the  press conference  this morning. Although some of the fervour may be manufactured for the television cameras \u2013 if you believe the interviews we\u2019ve been shown, every man, woman and child on Seoul\u2019s streets is rooting for Lee \u2013 it\u2019s still amazing for me to see that the game will be screened live on television throughout Asia. I\u2019ve been told by Fan Hui \u2013 the professional Go player whom AlphaGo  historically defeated last October  \u2013 that in China, 14 television channels plan on covering the match, and each has hired its own professional player to provide commentary. Lee himself seems remarkably relaxed about the whole occasion. At tonight\u2019s hotel dinner he was all smiles, sitting with his wife and daughter, and sipping wine and coffee. But that\u2019s probably a deliberate strategy. Playing good Go is all about managing one\u2019s stress, Fan says. Lee told journalists this morning that, with no way of analysing the mood or sentiment of his opponent as he\u2019d normally do ahead of a match, he\u2019s instead preparing by playing through long games in his mind each day. He and AlphaGo will be given two hours to play their moves at any pace before they receive time-controls that restrict them to only one minute per move (Hui\u2019s games last October were shorter: one hour each before time-controls). \n             Who will win? \n           A few weeks ago, Lee was saying that he expects to beat the computer 5-0 \u2013 or perhaps 4-1. But at this morning\u2019s  hour-long press conference , he said that after seeing Demis Hassabis \u2013 the CEO of Google-owned company DeepMind that created AlphaGo \u2013 presenting how the AlphaGo system worked,\u00a0he felt a little more nervous. \u201cI could be in danger now,\u201d  he said , speaking through a translator. Top Go players, such as Kim Myung-wan from South Korea, seem confident that Lee can win. Kim has  analysed last October\u2019s games  in which AlphaGo defeated Fan Hui 5-0, and says that that AlphaGo imitates the pattern-obsessed style of older professional players \u2013 which may betray the AI system\u2019s reliance on a bank of human moves. \u201cAlphaGo is not creative,\u201d Kim says. He and other 9-dan professionals say the new, young and vibrant Korean school has brought a huge amount of new creativity to the game. Lee has undoubtedly benefited from the social dimension of Korea\u2019s schools for \u2018baduk\u2019 (as Go is known in South Korea), in which players analyse games together as a group. Although AlphaGo is continually playing against itself, Kim doesn\u2019t feel it can improve enough to overcome that advantage. But David Silver, a computer scientist with DeepMind who\u2019s led on their development of AlphaGo, thinks the AI system is creative. The more it plays against itself, the further it drifts away from moves that resemble those in the database of games it was originally trained on, he told me at dinner tonight. Silver thinks professional commentators don\u2019t realise how creative the system has become. And while Kim and others have spotted mistakes in Fan Hui\u2019s play, Silver suggests that AlphaGo pushes its opponents into such errors. But Silver is definitely not hoping that AlphaGo wins because of mistakes. Everyone here from DeepMind and Google just wants to see a great game against Lee. \u201cI sincerely hope that he plays really, really well,\u201d Silver says. I can\u2019t wait for tomorrow: come back here for my thoughts on the first game.  \n             Previous entry:  \n             'Humanity-packed' AI prepares to take on world champion  \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The Go Files: \u2018Humanity-packed\u2019 AI prepares to take on world champion 2016-Mar-07 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Digital intuition 2016-Jan-27 \n                 \n                   Go players react to computer defeat 2016-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19512", "url": "https://www.nature.com/articles/nature.2016.19512", "year": 2016, "authors": [{"name": "Tanguy Chouard"}], "parsed_as_year": "2006_or_before", "body": "Nature  reports from a battle of man vs machine over the Go board. Tanguy Chouard, an editor with  Nature , saw Google-DeepMind\u2019s AI system AlphaGo defeat a human professional for the first time last year at the ancient board game Go. This week, he is watching top professional Lee Sedol take on AlphaGo, in Seoul, for a $1 million prize. Welcome everyone. I\u2019m Tanguy, an editor for the journal  Nature  in London. This week I will be in Seoul to watch the AI matchup of the century so far: it\u2019s computer versus human champion at the ancient Chinese board game Go. The AI algorithm AlphaGo will be taking on  Lee Sedol , the most successful player of the past decade. The formidable complexity of Go has been considered a fundamental challenge for computer science, something that AI wouldn\u2019t crack for another decade. Then last October, AlphaGo  became the first machine to defeat a human professional  at the game (without a handicap) \u2013 it thrashed European champion Fan Hui 5-0. As the  Nature  editor in charge of the peer-review process for the scientific paper 1  that described the system and the feat, I was at that match, held behind closed doors at the London headquarters of DeepMind, Google\u2019s AI company which built AlphaGo. It was one of the most gripping moments in my career. In a room upstairs, where the game was shown on a big screen, DeepMind\u2019s engineering team were cheering for the machine, occasionally scribbling technical notes on white boards that lined the walls. But in the quiet room downstairs, where the black and white stones were actually being plunked on the goban (game board), one couldn\u2019t help but root for Fan Hui, the poor human getting humbled by a machine. \"Mixed feelings, I know\", whispered Demis Hassabis \u2013 the CEO of DeepMind \u2013 who was seated next to me: \"I'm a player myself, so I can feel the pain for him\". I felt even worse. Fan Hui is a hero for kids playing Go in France, where my family lives. I used his books to teach my two sons and their school friends in Marseille about the game. How would I tell them the news? \n             Human-like AI \n           After the elation of an AI success like this one, I usually feel a moment of despair. It makes me suppose that human brains could be little more than machines \u2013 and that algorithms might eventually, outstrip their feats. A computer just defeated a human at the world\u2019s most sophisticated board game? A bot just composed \u2018perfect Bach\u2019? How disgusting is that? But this time is different. AlphaGo is a computing system packed with humanity \u2013 deliberately built on imitation of human brains in its structure, knowledge and experience. The  deep learning neural networks  it is based on mimic the way the brain processes information. It gained cultural knowledge by being trained on millions of moves made by professional Go players: a small, biased, very human sample of the total space of conceivable moves in the game. And it gained experience by playing itself endlessly \u2013 but even these experiments are constrained by moves randomly sampled from a human-biased database. If we draw a parallel from computing machines to flying machines, then AlphaGo is closer to a biomimetic version of a bird, than to a jet airplane. As Fan Hui  told journalists , its play is uncannily human. That deep humanity is at the root of AlphaGo\u2019s power but might also be its fatal limitation going into this week's world match. While the system's 'intuitive' play has shocked everyone on planet Go, its style is still deeply rooted in human moves from the past. Many top professional players (those that have reached the level of  9 dan pro  or '9p') feel that it may lack creativity \u2014 which is why they think Lee Sedol will win. But then, DeepMind\u2019s engineers seem just as confident that AlphaGo has improved so much over the past five months that it will be able to match \u2014 and indeed surpass \u2014\u00a0human 9-dan pro level.  More on that in my next post, when I\u2019ll bring you the atmosphere from Seoul. Ultimately, we\u2019ll see the clash of human vs AI styles on 9 March, when Sedol takes on AlphaGo in the first of five planned games over seven days. Whoever wins \u2014 human or human mimic \u2014 may the game be  divine ! \n             Next entry:  \n             Champion preps for $1 million machine match  \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Digital intuition 2016-Jan-27 \n                 \n                   Go players react to computer defeat 2016-Jan-27 \n                 \n                   Robotics: Ethics of artificial intelligence 2015-May-27 \n                 \n                   Nature  special: Alan Turing at 100 \n                 \n                   Nature   Insight : Machine Intelligence \n                 Reprints and Permissions"},
{"file_id": "531147a", "url": "https://www.nature.com/articles/531147a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Conference aims to raise awareness of shared resources for building lab equipment. Few scientists know that, instead of buying their lab equipment, they can often build it much more cheaply \u2014 and customize their creations \u2014 by following \u2018open-hardware\u2019 instructions that are freely available online. Fifty enthusiasts who gathered last week at CERN, Europe\u2019s particle-physics laboratory near Geneva, Switzerland, are hoping to remedy researchers\u2019 lack of awareness about open science hardware. At  the first conference dedicated to the field , they met to compare creations \u2014 and to thrash out a road map to promote the widespread manufacturing and sharing of labware. \u201cWe want open hardware to become a normal part of the scientific process,\u201d says Shannon Dosemagen, a co-organizer of the conference who is executive director of the non-profit citizen-science community  Public Lab . Proponents of  open hardware  \u2014 named by analogy to \u2018open software\u2019 in computer science \u2014 have already created free online designs for dozens of pieces of labware, taking advantage of manufacturing technologies such as 3D printers and laser-cutting machines. They argue that sharing designs for others to adapt can vastly accelerate the progress of science. But this share-all do-it-yourself (DIY) philosophy is yet to become mainstream. \u201cThe majority of scientists are still waiting to get involved,\u201d says Joshua Pearce, an engineer at Michigan Technological University in Houghton, who two years ago published a book for scientists on  how to create a low-cost lab . \n               Low-cost lab kit \n             The open-hardware movement can already point to much success in science, says conference co-organizer Jenny Molloy, who coordinates  OpenPlant , a synthetic-biology centre at the University of Cambridge, UK. Citizen-science projects, schools and researchers who lack money to buy expensive equipment have been particularly quick to adopt it. In 2009, for example, Irfan Prijambada, a microbiologist at Gadjah Mada University in Yogyakarta, Indonesia, was able to equip his lab with tissue-culture hoods and microscopes for less than 10% of their commercial price, using designs posted by a life-sciences-community platform called  Hackteria . Online designs have been created for  a wide range of labware , from DNA-amplifying PCR machines to fluorescence imaging microscopes (see ). (Molloy says that the basic principles behind a lot of labware are not patented, so intellectual-property conflicts are rare.) For some kit \u2014 such as scanning tunnelling microscopes \u2014 the fabrication process is too complex to take place in the lab, but Pearce thinks that these, too, will eventually become open source. And because these blueprints are openly shared \u2014 allowing anyone to critique and improve them \u2014 the quality of equipment is often at least as good as or even better than what is available commercially, he says. For researchers, this ability to tinker with equipment is the main advantage of open-source sharing. \u201cIf it\u2019s open source, I can adapt it and fix it. That\u2019s most important to me,\u201d says Tobias Wenzel, a biophysics PhD student at the University of Cambridge. \n               Quality assurance \n             But other scientists\u2019 reluctance to dive into DIY may stem from doubts about whether open hardware can faithfully produce the validated, standardized performance of commercial equipment. Too often, the documentation that accompanies designs \u2014 intended to calibrate the equipment\u2019s performance against known standards and describe its use \u2014 is unclear or incomplete, conference attendees heard. A community-standard or best-practice guide could use a checklist to ensure that designers cover all the necessary bases, says Wenzel. \u201cIt needs to be something that says: \u2018if you follow this procedure, this will work and you\u2019ll be able to get high precision, high accuracy and low error\u2019,\u201d says Pearce. The problem is that sharing work in enough detail for anyone else to follow takes time and effort, but provides little formal scientific credit. \u201cIt\u2019s one thing to build something for one\u2019s own research, but to make it so it\u2019s easy for others to replicate is much more difficult,\u201d says Ryan Fobel, an engineer at the University of Toronto, Canada, who helped to develop an open-source platform for doing biology and chemistry on a chip, known as  DropBot . To this end, at the Geneva conference researchers debated ways to assign credit to the designers of open hardware. Some would like to see a citation system for designs, or want journals to publish more research papers that outline designs. A central repository for open science hardware might help: CERN hosts a  repository for electronics open hardware , and the US National Institutes of Health has  a 3D-printing repository  with a labware section. But no single repository collates everything. Because many scientists won\u2019t want to build devices themselves, taking open hardware mainstream will need to involve non-profit organizations and companies that can supply the kit, notes Francois Grey, a physicist at the University of Geneva and conference co-organizer. Firms such as  OpenTrons  in Brooklyn, New York, which makes automated pipetting systems, already both design open-source lab equipment and sell ready-made kit built from open-source designs. But because such companies give away their designs, figuring out a solid business model is a challenge, adds Javier Serrano, an engineer at CERN who helped to pioneer the lab\u2019s  Open Hardware Licence , which allows developers to ensure that all future modifications are documented and shared. Companies might make money by pro\u00adviding support for open hardware, or by conducting quality-assurance checks and validation tests that allow them to offer warranty-like guarantees on products, Pearce suggests. And a collection of success stories might also help scientists to convince their institutions \u2014 which may be accustomed to patenting in-house inventions \u2014 of the value of forming open-hardware spin-offs, adds Molloy. Pearce says that he dreams of a day when every published scientific article will instruct its readers not just on experimental methods, but also on how to build the equipment that the study requires. It\u2019s something that will need the cooperation of funders to become a reality. Existing large-scale equipment grants tend to pay for single instruments, but Pearce would like to see the money spent on open-source hardware, which he says could bring down prices and \u2014 over time \u2014 improve designs. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Environmental science: Pollution patrol 2015-Jan-07 \n                   \n                     Mobile science 2014-Oct-01 \n                   \n                     Laboratory equipment: Cut costs with open-source hardware 2014-Jan-29 \n                   \n                     Homegrown labware made with 3D printer 2012-Apr-16 \n                   \n                     Blog post: Promoting shared hardware design \n                   \n                     Gathering for Open Science Hardware 2016 \n                   \n                     Open Labware \n                   \n                     Teaching and Research in Natural Sciences for Development in Africa \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19538", "url": "https://www.nature.com/articles/nature.2016.19538", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Nature 's favourite winners in the 2016 competition run by the biomedical charity in London. Nature  editors present their pick of the winning scientific images in the  awards run by the Wellcome Trust . The London biomedical charity will announce the overall winner on 15 March. Swallowtail butterflies are part of a colourful family of butterflies that includes hundreds of species and live all over the world. This individual was photographed in Connecticut. Here, the insect's feeding tube is curled up, but the organ can spring open to form a straw, allowing the animal to slurp up flower nectar. The curled-up leaves of a maize (corn) plant are made up of several layers of individual cells. The cells' nuclei are depicted in orange. Now being bathed in ultraviolet light to treat jaundice, this infant was born prematurely at a London hospital. Jaundice is a common condition in newborns and is caused by a build-up of cellular waste when the liver has not developed sufficiently to remove it. Not the roots of some hearty weed, these tendrils are blood vessels in a human eye. The picture was taken with the aid of a technique called fluorescein angiography, which gauges blood circulation in the eye. Fluorescent dye was injected into a person\u2019s arm; it then migrated along veins to the eye. Human liver cells, glowing red, grow and divide within the damaged liver of a lab mouse. The human graft has its own blood vessels, in green. Such implants could help to treat liver diseases, including cirrhosis and cancer. Mesenchymal stem cells reside in bone marrow and can differentiate into bone, cartilage, muscle and fat cells. But they have also been used to treat immune reactions that can happen after patients receive bone-marrow transplants. This cell, which was frozen and then photographed with a scanning electron microscope, was donated by a healthy person for that use. This adult-cow heart has spent years floating in a formalin-filled jar at the Royal Veterinary College in London. As in other four-chamber hearts, blood enters through the two upper chambers and exits through the lower two. Nerve fibres snake through the brain of a young adult. The differently coloured fibres connect distant brain regions: the red tracts allow the left and right hemispheres to communicate; the blue ones link spinal cord and brain. The picture was constructed using a variation on magnetic resonance imaging called diffusion imaging and was taken from the back of the brain. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             Reprints and Permissions"},
{"file_id": "531152a", "url": "https://www.nature.com/articles/531152a", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Project Baseline will monitor effects of climate change on plant evolution. In a vault kept at \u221218\u2009\u00b0C in Fort Collins, Colorado, more than 5 million seeds now lie frozen in time \u2014 destined to wait for up to 50\u00a0years until evolutionary scientists earn permission to experiment with them. Unlike most seed banks, which aim to protect biological diversity, Project Baseline is designed to enable precise, controlled studies of how plants are evolving in response to climate change and environmental degradation. Taken from around 250 locations across the continental United States and stored at a US Department of Agriculture facility, the seeds represent some 60 species. Scientists began collecting the seeds in earnest in 2012, backed by a US$1.3-million grant from the US National Science Foundation (NSF). They took care to gather specimens in a wide variety of environ\u00adments and to cover a multitude of plant types, from the humble radish ( Raphanus sativus ) to the iconic Joshua tree ( Yucca brevifolia ). The collection phase is now complete, says project lead investigator Julie Etterson, a plant biologist at the University of Minnesota Duluth. Earlier this year, she and her colleagues published a paper in the  American Journal of Botany  introducing Project Baseline to the community ( J.\u00a0R.\u00a0Etterson  et\u00a0al. Am. J. Bot.    103, 164\u2013173; 2016 ). To find out whether species are evolving in response to human pressures such as climate change, scientists have previously observed differences in similar species living at various sites or studied one site over time, charting how plants change along with the site. But it can be difficult to distinguish between changes that are the result of evolution \u2014 the selection of traits over generations owing to the survival of certain individuals \u2014 and those that are due to the ability of individual plants to react to a changing environ\u00adment, called plasticity. Project Baseline will allow scientists to grow stored seeds side by side with those from plants that were left to evolve, in identical conditions: any differences can then be attributed to evolution. \u201cI think it\u2019s terrific,\u201d says Richard Lenski, who studies evolution in bacteria at Michigan State University in East Lansing. \u201cTo some extent, museum specimens and even natural seed banks allow scientists to make these comparisons today, but not in the in-depth, systematic and well-thought-out way that this project will allow.\u201d Questions that could be explored include whether the early flowering observed in some plants in conjunction with global warming is attributable to evolution or plasticity, and how rates of evolution vary between different populations of the same species. Genetic sequencing will help researchers to discover which genes are linked to traits that have been selected for. It could also test predictions, such as that low genetic variation increases extinction rates, and that evolution occurs through many small genetic changes rather than a few large ones. \u201cThe list of hypotheses is really only limited by the imagination,\u201d says Etterson. \n               Back to life \n             Project Baseline breathes new life into a field known as resurrection ecology. Its best-known experiments hatched invertebrate eggs that had been naturally preserved in lake sediments, and compared the offspring with those of recently laid eggs. A now-classic example, from the lab of environmental scientist Nelson Hairston at Cornell University in Ithaca, New York, used sediments from Lake Constance in central Europe to prove that water fleas ( Daphnia galeata ) had rapidly evolved tolerance for toxic cyano\u00adbacteria ( N.\u00a0G.\u00a0Hairston  et\u00a0al .  Nature   401,  446; 1999 ). Because Project Baseline actively lays the foundation for future research, rather than relying on what nature has sequestered in the past, it is a \u201ckind of visionary project\u201d, says Hairston. It does assume that there will be observable environmental changes at the sites from which the seeds were collected, notes Charles Kerfoot, a biologist at Michigan Technological University in Houghton and another pioneer in resurrection ecology. But such differences are guaranteed because of climate change, he says: \u201cThis is a group that\u2019s not in denial.\u201d Exactly when the scientists will wake the seeds in the vault from stasis is less clear. Project Baseline\u2019s first call for proposals to work with the specimens is planned for 2018, and Etterson says that the first seeds could be planted as soon as 2020. She hopes to get at least one use out of the project herself before she retires. The timescales are long compared with both the average evolution study and the average NSF grant, say researchers, but that makes Project Baseline special. \u201cThis is really different,\u201d says Samuel Scheiner, the director of the NSF programme that funded the project, \u201cbut exactly what we need to do if we\u2019re going to study global change.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Turning point: Heather Schneider 2015-Jul-29 \n                   \n                     Wild flower blooms again after 30,000 years on ice 2012-Feb-21 \n                   \n                     Seed banks susceptible to sham samples 2011-Mar-11 \n                   \n                     Project Baseline \n                   Reprints and Permissions"},
{"file_id": "531149a", "url": "https://www.nature.com/articles/531149a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Decision could determine who profits from the gene-editing technique in future. There is no shortage of optimism about  the scientific potential  of CRISPR\u2013Cas9, a technique that can precisely alter the genomes of everything from wheat to elephants. But there is a great deal of confusion over who will benefit financially from its use. On 10 March, the US Patent and Trademark Office (USPTO) will  begin an investigation  into who deserves the patent on using CRISPR\u2013Cas9 to edit genes. This \u2018patent interference\u2019 could determine who profits from CRISPR in coming years. Already, companies have sprung up to take advantage of the technique in agriculture, industrial biotechnology and the treatment of human diseases. One firm, Editas Medicine in Cambridge, Massachusetts, raised US$94\u00a0million when it went public on 2\u00a0February, even though it does not expect to enter clinical trials until 2017. Nature  takes a look at what the interference proceeding entails and what it could mean for the fate of CRISPR\u2013Cas9. \n               Who\u2019s who in the patent interference? \n             One patent claim comes from a team led by molecular biologist  Jennifer Doudna  at the University of California, Berkeley, and microbiologist Emmanuelle Charpentier, now at Ume\u00e5 University in Sweden and the Max Planck Institute for Infection Biology in Berlin. They published a 2012 paper demonstrating that the Cas9 enzyme can be directed to cut specific sites in isolated DNA ( M.\u00a0Jinek  et\u00a0al. Science   337 , 816\u2013821; 2012 ), and initiated their patent application on 25 May 2012. Another team, led by  Feng Zhang  at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, published a 2013 paper demonstrating the application of CRISPR\u2013Cas9 in mammalian cells ( L.\u00a0Cong  et\u00a0al. Science    339,  819\u2013823; 2013 ). Zhang\u2019s team began a patent application on 12 December 2012. Although the Berkeley team filed first, the Broad team submitted its application to an expedited review programme, and was awarded the patent in April 2014. The Berkeley team then requested a patent interference against the initial Broad patent plus 11 related Broad patents. On 11 January, the USPTO granted Berkeley\u2019s request. \n               What is a patent interference? \n             A relic from the past. Until a few years ago, the United States awarded patents to those who could show that they were the first to invent, rather than simply the first to file the patent. Under that system, when competing inventors claimed to have created the same invention first, the USPTO declared an interference proceeding to determine which deserved the patent. The United States switched to a first-to-file system in March 2013. But several key CRISPR\u2013Cas9 patents were filed before the change. \n               What will happen during the patent-interference hearing? \n             A panel of three USPTO patent judges will hear evidence from both sides to establish which team invented the application of CRISPR\u2013Cas9 for gene editing. Much of the action will be carried out over the telephone or through written documents. But there will probably be some oral arguments, and these could include testimony from the academic inventors. Patent interferences can be highly technical, says John Conley, a legal scholar at the University of North Carolina in Chapel Hill. \u201cIt\u2019s hard for me to cite anything more convoluted in the law than this,\u201d he says. \u201cIt\u2019s mind-boggling.\u201d The USPTO panel will probably try to determine not only which team was the first to use CRISPR\u2013Cas9 for gene editing, but which conceived of the invention first. The process could be messy. During the era of \u2018first-to-invent\u2019 patents, some companies kept \u2018inventor\u2019s notebooks\u2019: when someone at the firm thought of a new invention, they were to write it down in the notebook and have the entry notarized in case it came into play during future patent disputes. Few academic labs go to such lengths. \n               When will we find out who has won? \n             The law that did away with the United States\u2019 first-to-file policy also introduced changes intended to expedite interferences. But a verdict on the CRISPR patents could still be months, or even years, away. And given the high financial stakes, many expect the losing party to appeal against the USPTO interference decision, further dragging out the process. \n               Will this be the only CRISPR patent interference? \n             Not necessarily. In its filings to the Securities and Exchange Commission, Editas Medicine highlighted a potential interference claim by a Seoul company called ToolGen. Having multiple interferences over the same patent is rare, says Conley, but possible. \n               Is the patent landscape any clearer in Europe? \n             No. The Broad and MIT team also fast-tracked several of its applications at the European Patent Office (EPO), and has been awarded several patents so far. Doudna\u2019s single application is pending. Although the EPO does not have an interference process, outside parties can formally object to a patent. By 11\u00a0November 2015, the deadline for objections to the Broad\u2019s first European CRISPR\u2013Cas9 patent, nine parties had come forward\u00a0\u2014 launching an opposition procedure that can take years to resolve. Once that process is finished, participants can appeal. This adds another four or five years to the clock, says Michael Roberts, a partner at the intellectual-property law firm Reddie & Grose in Cambridge, UK. For this reason, Roberts believes that it will be several years before there is clarity on the earliest CRISPR\u2013Cas9 patents in Europe. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Bitter fight over CRISPR patent heats up 2016-Jan-12 \n                   \n                     CRISPR, the disruptor 2015-Jun-03 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   \n                     CRISPR technology leaps from lab to industry 2013-Dec-03 \n                   \n                     Nature  special: CRISPR \n                   \n                     US Patent and Trademark Office \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19544", "url": "https://www.nature.com/articles/nature.2016.19544", "year": 2016, "authors": [{"name": "Tanguy Chouard"}], "parsed_as_year": "2006_or_before", "body": "Nature  reports from a battle of man vs machine over the Go board. Tanguy Chouard, an editor with  Nature , saw Google-DeepMind\u2019s AI system AlphaGo defeat a human professional for the first time last year at the ancient board game Go. This week, he is watching top professional Lee Sedol take on AlphaGo, in Seoul, for a $1 million prize. As I\u2019m sure you\u2019ve heard, one of humanity\u2019s best Go players, Lee Sedol, just  lost his first game  (replay below) in a best-of-five series against AlphaGo, the artificial intelligence system created by Google DeepMind. \u201cI\u2019m in shock,\u201d Lee said at the post-match press conference. I was surprised too by my emotional reaction to the result. Before I saw the game, which I watched alongside DeepMind\u2019s CEO Demis Hassabis, and David Silver, one of the lead researchers on AlphaGo, I didn\u2019t know who I wanted to win. Now \u2013 to my surprise \u2013 I find myself rooting for the very personable and human Lee Sedol. For me, the key moment came when I saw Hassabis passing his iPhone to other Google executives in our VIP room, some three hours into the game. From their smiles, you knew straight away that they were pretty sure they were winning \u2013 although the experts providing the live public commentary on the match that was broadcast to our room weren\u2019t clear on the matter, and remained confused up to the end of the game just before Lee resigned. (I'm told that other high-level commentators did see the writing on the wall, however). Hassabis\u2019s certainty came from Google\u2019s technical team, who pore over AlphaGo\u2019s evaluation of its position, information that isn\u2019t publicly available. I\u2019d been asking Silver how AlphaGo saw the game going, and he\u2019d already whispered back: \u201cIt\u2019s looking good\u201d. And I realised I had a lump in my throat. From that point on, it was crushing for me to watch Lee\u2019s struggle. Towards the end of the match, Michael Redmond, an American commentator who is the only westerner to reach the top rank of 9 dan pro, said the game was still \u201cvery close\u201d. But Hassabis was frowning and shaking his head \u2013 he knew that AlphaGo was definitely winning. And then Lee resigned, three and a half hours in.  At the post-game press conference, Lee said he felt he\u2019d made a mistake early in the game, and had to drag that burden throughout the match. We\u2019d certainly seen Lee looking tense early on: Redmond had already told us \u2013 and the hundreds of journalists watching in two overflow rooms \u2013 that AlphaGo was playing more aggressively, in contrast to its relatively peaceful games last year against Fan Hui.\u00a0 \"AlphaGo played like a human professional player, but with the emotional element carved out,\u201d said one Korean commentator, Kim Sung-ryong. He said that all top-level pro players were in shock. Silver said that \u2013 judging from the statistics he\u2019d seen when sitting in Google\u2019s technical room \u2013 \u201cLee Sedol pushed AlphaGo to its limits\u201d. Does this mean that AI has finally defeated humanity at what may be the most complex board game we've ever invented? Not quite. There are still four games to go; tomorrow (10 March, livestream below) we may see a different kind of match, as AlphaGo will play first, with the black stones, rather than second, with the white ones. Lee said he wouldn\u2019t be affected psychologically by the loss. \u201cThis game is not going to affect how I play in the next games,\u201d he said. As Redmond told me after the game: \"he's a very tough guy\". Can't wait to see him fight back! \n             Previous entry:  \n             Champion preps for $1 million machine match  \n           \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The Go Files: \u2018Humanity-packed\u2019 AI prepares to take on world champion 2016-Mar-07 \n                 \n                   Google AI algorithm masters ancient game of Go 2016-Jan-27 \n                 \n                   Digital intuition 2016-Jan-27 \n                 \n                   Go players react to computer defeat 2016-Jan-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19950", "url": "https://www.nature.com/articles/nature.2016.19950", "year": 2016, "authors": [{"name": "Helen Shen"}], "parsed_as_year": "2006_or_before", "body": "Study of 1,200 US graduates suggests family and choice of doctoral field dents women's earnings. Women earn nearly one-third less than men within a year of completing a PhD in a science, technology, engineering or mathematics (STEM) field, suggests an analysis of roughly 1,200 US graduates. Much of the pay gap, the study found, came down to a tendency for women to graduate in less-lucrative academic fields \u2014 such as biology and chemistry, which are  known to lead to lower post-PhD earnings than comparatively industry-friendly fields, such as engineering and mathematics . But after controlling for differences in academic field, the researchers found that women still lagged men by 11% in first-year earnings. That difference, they say, was explained entirely by the finding that married women with children earned less than men. Married men with children, on the other hand, saw no disadvantage in earnings. Many studies have reported similar gender pay gaps and have identified similar contributing factors \u2014 but few have systematically broken down the relative contributions of different variables, says Bruce Weinberg, an economist at the Ohio State University in Columbus who led the study, published in the May issue of\u00a0 American Economic Review 1 . \u201cI was quite surprised that we could explain the wage gap using just field of study and family structure,\u201d he says. \n             The offspring effect \n           An unmarried, childless woman earned \u2014 on average \u2014 the same annual salary after receiving her doctorate as a man with a PhD in the same field, the researchers found. The study examined the employment and earnings of 867 men and 370 women who graduated between 2007 and 2010 from 4 different universities. Weinberg says that the data cannot identify or tease apart factors that might explain why married women with children earn less \u2014 among the possibilities, whether employers assign different responsibilities and salaries to these women, or whether the women spend less time or energy on their careers. But, he says, \u201cour data suggest that these positions, as they are currently structured and operate, are not fully family-friendly for women\u201d. The findings support earlier research that suggests that parental and household responsibilities often affect women disproportionately, particularly in environments without adequate work\u2013life and family policies, says Heather Metcalf, director of research and analysis for the US Association for Women in Science (AWIS) in Alexandria, Virginia. The analysis is part of the UMETRICS project, based at the University of Michigan in Ann Arbor, which links anonymized census data on employment and income to student information from a consortium of universities, mainly in the midwestern United States. \n             Holes to fill \n           Mary Ann Mason, a law professor at the University of California, Berkeley, says that the work is a \u201cgood, careful study\u201d, albeit limited in that it cannot yet provide information on what happened in later postdoc years. Research by Mason and others suggests that women who have young children within 5\u201310 years after earning their PhDs are less likely to have tenure-track jobs or to hold tenured faculty positions than men or women without children 2 , 3 , for instance. An important missing piece, says economist Shulamit Kahn at Boston University in Massachusetts, is whether the women and men in the study worked equal numbers of hours. Kahn\u2019s research suggests that, outside of academia, female scientists tend to work slightly fewer hours than do their male counterparts 4 . (That paper did not examine scientists' family status.) Weinberg says that the team is working to expand and extend the project, first by securing participation from more universities. He hopes, eventually, to be able to track doctoral recipients over the first 5\u201310 years of their post-PhD careers. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Biologists lose out in post-PhD earnings analysis 2015-Dec-10 \n                 \n                   How to build a better PhD 2015-Dec-02 \n                 \n                   Make the most of PhDs 2015-Dec-02 \n                 \n                   Graduate survey: Uncertain futures 2015-Oct-21 \n                 \n                   What is a PhD really worth? 2011-Apr-20 \n                 \n                   Science economics: What science is really worth 2010-Jun-09 \n                 \n                   UMETRICS project \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20027", "url": "https://www.nature.com/articles/nature.2016.20027", "year": 2016, "authors": [{"name": "Bethany Augliere"}], "parsed_as_year": "2006_or_before", "body": "Man's best friend may have been domesticated twice \u2014 at different sites. Wolves gave rise to dogs not once, but twice, suggests a study published today in  Science 1 . The findings, based on genetic analyses of ancient and modern dogs and wolves, add a new twist to the long-standing debate over the domestic canine\u2019s origins. Previous studies of dog DNA suggested that the animals were domesticated once, at least 10,000 years ago, and  perhaps as long as 40,000 years ago  \u2014 but they disagree over whether that happened in central or East Asia or in Europe 2 , 3 , 4 , 5 . The latest study is the most comprehensive analysis yet of ancient dog genomes. \u201cThe motivation of this study was to understand when and where dogs came first,\u201d says co-author Laurent Frantz, an evolutionary geneticist at the University of Oxford, UK. Frantz and his colleagues decoded the mitochondrial DNA sequences of 59 ancient European dogs that lived between 3,000 and 14,000 years ago. The team also sequenced the complete genome of a 4,800-year-old dog found in the graves of a human settlement called Newgrange in Ireland. Then the scientists compared these ancient genomes with those of hundreds of wolves and modern dogs \u2014 including mutts and 48 breeds from Samoyeds to Shar Peis \u2014 in Western Eurasia and East Asia. \n             Dual split \n           The researchers' phylogenetic analysis \u2014 an attempt to reconstruct the dog's family tree \u2014 revealed two splits in the dog sequences. As the researchers expected, the most recent separated the modern Saarloos wolfdog from other breeds. The Saarloos was created in the Netherlands in the 1930s by breeding German Shepherds with captive wolves. More intruiging was an earlier split that separated dogs from East Asia and Western Eurasia, roughly 14,000 to 6,400 years ago. This divergence is several millennia after the first known appearance of dogs in Europe and East Asia, the authors say. Modern breeds such as huskies and Greenland sledge dogs have ancestors from both regions. The scientists hypothesize that this split is due to two cases of domestication from distinct wolf populations. \u201cIt\u2019s not conclusive yet, we need some more information,\u201d says Frantz. \u201cBut the combination of genetics and archaeology is pointing toward a dual origin of domestic dogs.\u201d One argument to bolster the team\u2019s hypothesis is a lack of archaeological evidence for ancient dogs in between Western Eurasia and East Asia. It\u2019s possible that dogs came with people from Asia to Europe, and that those dogs outcompeted and partially replaced the more ancient species, says Frantz. \n             Dog data \n           Adam Boyko, a geneticist at Cornell University College of Veterinary Medicine in Ithaca, New York, is not convinced that the dog is an example of dual domestication, but says that it is \u201can intriguing hypothesis\u201d. To test the theory, he says that scientists would need to gather and sequence more DNA from early dogs, such as the Newgrange specimen. As scientists continue to sequence ancient genomes, they hope to resolve the origin of dogs. The Newgrange specimen provides another data point for future genetic studies, says Pontus Skoglund, a geneticist at Harvard Medical School in Boston, Massachusetts. \u201cIt\u2019s going to be an exciting time going forward,\u201d he adds. He notes that learning more about the evolution of the modern dog also provides a window into humans' past. Before they had farms and settled agriculture, people had dogs. \u201cIt\u2019s interesting because it\u2019s one of the first major human cultural innovations,\u201d says Skoglund. \u201cIt tells us something about the cultural capacity of early humans.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Ancient wolf genome pushes back dawn of the dog 2015-May-21 \n                 \n                   Prehistoric genomes reveal European origins of dogs 2013-Nov-14 \n                 \n                   Dog genetics spur scientific spat 2013-Jun-18 \n                 \n                   Dog's dinner was key to domestication 2013-Jan-23 \n                 \n                   Rise of the coyote: The new top dog 2012-May-16 \n                 \n                   Laurent Frantz \n                 \n                   Pontus Skoglund \n                 \n                   Adam Boyko \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19953", "url": "https://www.nature.com/articles/nature.2016.19953", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Complaint to US government alleges that diagnostics company violated individuals' right to access health information. Genetic-testing firm Myriad Genetics is facing a legal challenge from people who say the company refused to give them access to their own genomic data, in violation of a US government rule on medical records. Although Myriad has now agreed to release the data to those individuals, the patients are pressing ahead with their complaint to the US government. The skirmish is the latest in a long-running war between Myriad and data-sharing advocates, and it could ultimately force the company to provide genetic information that patients could then share with scientists. The patients, who are represented by the American Civil Liberties Union (ACLU), filed the complaint on 19 May with the US government alleging that Myriad, of Salt Lake City, Utah, had declined to release complete results of tests for the genes  BRCA1  and  BRCA2.  Some variants of these genes  are linked to higher risk of cancer ; for others, the link to disease is unclear or the variants are considered to be harmless. Myriad refused to report \u2018benign\u2019  BRCA  variants back to patients when they requested this information in February. The ACLU says that the company\u2019s denial violates a  rule  released by the US government in January that gives patients the right to obtain their full lab test results under the Health Insurance Portability and Accountability Act. Breast-cancer survivor AnneMarie Ciccarella, one of the people who filed the complaint, said that she wants access to her complete data so that she can  share it with scientists  who are trying to understand the genetic contributions to cancer. \u201cI want to see that the research community has access to every bit of data that has been generated from my body,\u201d she said.On 18 May, after the ACLU announced a press conference to discuss the complaint, Myriad released the data that Ciccarella and her three co-complainants had requested. \u201cWe believe the complaint lacks merit and should not be accepted,\u201d the company said in a 19 May statement. \n               Seeking certainty \n             Ciccarella and the others who brought the complaint are pressing ahead with their case, in part to set the precedent that companies must legally provide the full results of genetic tests \u2014 not release it on a voluntary basis.Observers say that makes sense, especially given Myriad\u2019s history. The company had previously tried to block rivals from providing  BRCA  tests, asserting that it held patents that gave it the exclusive right to perform such diagnostics. That changed in June 2013, when the  US Supreme Court invalidated Myriad's patents  after the ACLU mounted a legal challenge. Myriad has not shared its large database on thousands of BRCA variants, despite requests from researchers studying the genetics of breast cancer. But it may now be forced to provide individual results on a patient-by-patient basis if the government decides to accept the latest complaint.\u201cIf I were the plaintiffs, I\u2019d want to make sure the government said that Myriad had to do what it did,\u201d says lawyer and bioethicist Hank Greely at Stanford University in California. \u201cIf you\u2019re a consumer advocate in the health-care space, Myriad may not be a company you trust.\u201dHeidi Rehm, a geneticist at the non-profit company Partners Healthcare Personalized Medicine in Cambridge, Massachusetts, drafted a statement of support for the complaint against Myriad. She says that as researchers learn more about genetic risks of cancer, they\u2019re finding that variants once considered benign might actually contribute to cancer risk. Rehm and other researchers are pushing for companies and individuals to  share their genetic test data  with open databases such as ClinVar, and she says that the push for data sharing is gathering increasing momentum. US insurance company Aetna, for instance, has said that it will favour testing companies that deposit data in ClinVar. And the US Food and Drug Administration is considering whether to give companies incentives to deposit their tests results in the database. Additional reporting by Heidi Ledford. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Gene counsellors expect resurgence of 'Jolie effect' 2015-Mar-26 \n                   \n                     Genetic rights and wrongs 2014-Sep-09 \n                   \n                     Biotech reels over patent ruling 2014-Jul-08 \n                   \n                     Cancer-gene data sharing boosted 2014-Jun-10 \n                   \n                     365 days: Nature's 10 2013-Dec-18 \n                   \n                     Myriad ruling causes confusion 2013-Jun-18 \n                   \n                     American Civil Liberties Union \n                   \n                     Myriad Genetics \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20023", "url": "https://www.nature.com/articles/nature.2016.20023", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Chamber accumulates off the main volcanic zone, raising questions about volcano hazards. New Zealand geologists have discovered a magma chamber being born in a surprising place \u2014 not under the country\u2019s most active volcanoes, but off to one side. The finding suggests that molten rock can accumulate underground in complex and unexpected patterns. No eruption is imminent, however. \u201cThere\u2019s no need to panic, but chances are there are lots of bodies of magma dotted throughout the crust,\u201d says Ian Hamling, a geophysicist at GNS Science in Lower Hutt, New Zealand. He and his colleagues describe the discovery on 3 June in  Science Advances 1 . His team uses radar data from satellites, such as the European Space Agency\u2019s now-defunct Envisat, to study ground motions in the Taupo volcanic zone. This region, in the central part of New Zealand\u2019s North Island, has seen 25 enormous eruptions in the past 1.6 million years. Today it is home to some of the country\u2019s most spectacular volcanic features, from the bubbling hot pots of Rotorua to eruptions at White Island, most recently in April. A 2015 study found that much of the main Taupo volcanic zone was subsiding, or sinking, as expected when magma erupts from underground 2 . But one blob , along the north and west coasts of the Bay of Plenty , appeared to be rising. \u201cI just discounted it at the time, because we were so focused on looking at the more volcanic part,\u201d says Hamling. Later the team took a closer look , including data from ground-positioning stations as well as geodetic surveys dating back to the 1950s. They found the ground rising about 5 to 6 millimeters a year at first , but that rate doubled to about 12 millimeters a year starting in the mid-2000s. It has since dropped back to the lower rate. Calculations suggest that about 9 million cubic metres of magma \u2014 about 3,600 Olympic swimming pools\u2019 worth \u2014 pushed into the crust each year during peak growth. It would have gathered in a mushy chamber about 10 kilometres deep. \u201cWhen you compare it to other places, like Yellowstone, we\u2019re smaller than that,\u201d Hamling says. \u201cBut it\u2019s still pretty significant.\u201d The city of Tauranga, with more than 100,000 residents, lies about 50 kilometres west of the uplift. Elaine Smid, a volcanologist at the University of Auckland, notes that people in the area are already at risk of volcanic hazards, especially ashfall from the neighbouring Taupo volcanoes. The new work underscores the need for people to stay on top of the latest science, she says.  The New Zealand discovery adds to other examples around the world, including in the central Andes and in Africa, where magma seems to be pushing into the crust in places other than active volcanoes, says Matthew Pritchard, a geophysicist at Cornell University in Ithaca, New York. He calls them \u201czombie volcanoes,\u201d showing signs of life when they should be dead. \u201cNot to be too glib, but we are not undergoing a zombie volcano invasion,\u201d he says. Rather, researchers can see more ground movements than they ever could before, thanks to the sharp vision of radar satellites.  Hamling\u2019s team wants to do a more detailed study of the area, using different techniques to probe the size and shape of the newfound magma chamber. \n                   World's deadliest volcanoes identified 2015-Mar-03 \n                 \n                   Project drills deep into coming quake 2014-Jul-29 \n                 \n                   Dissecting New Zealand's deadly quake 2011-Feb-22 \n                 \n                   GNS Science page on New Zealand volcanoes \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20022", "url": "https://www.nature.com/articles/nature.2016.20022", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Government can't say how many policy studies it paid for or published, report reveals. The UK government doesn't know how much policy-linked research it has commissioned, or how much of it has been published. That is the stark conclusion of  an independent inquiry , published on 2 June, which details the delays and confusion affecting the status of research produced for government departments in areas ranging from social policy to climate change. The inquiry was carried out by Stephen Sedley, a judge, law professor, and a trustee of Sense About Science, a London-based science-advocacy group which commissioned the inquiry and published the report. He spoke to government advisers, civil servants and researchers, and used multiple freedom-of-information requests to ask how much research commissioned by the government gets published. According to official estimates, the government spends around \u00a32.5 billion (US$3.6 billion) a year commissioning research linked to policy issues \u2014 some of which is done in house, and some by outside researchers, Sedley notes. But, he says, it has \u201cno comprehensive account\u201d of how much is commissioned or published. \n               Scattered studies \n             Just 4 out of 24 government departments told Sedley that they kept a centralised database of commissioned research. Others \u2014 including the Department of Energy and Climate Change and the Department for Business, Innovation and Skills \u2014 could not provide a list of the studies that they carried out or commissioned. Many departments said that it would be too costly to provide the information, because it was held in many different files and locations. Civil servants told Sedley that they often waste time trying to find past studies that their own departments paid for. The report also notes several cases in which the publication of reports has been delayed owing to \u201cpolitical concerns about the implications of the research\u201d \u2014 including work on drug policy and immigration. \u201cThe fact that a few departments do maintain a research register, handle awkward findings and publish promptly exposes the excuses of those that don\u2019t,\u201d said Tracey Brown, director of Sense about Science, in a statement. \u201cSir Stephen has revealed that we don\u2019t know what has become of millions of pounds worth of government-commissioned research because government itself doesn\u2019t know whether it was published, or where it all is now.\u201d The report calls for a central register of all government-commissioned research, a commitment to prompt publication, and routine publication of any work that has been used to inform government policy. \u201cI never encountered this as a particular problem when I was chief scientific adviser. However the proposal to maintain a database that is searchable makes eminent sense,\" says John Beddington, a population biologist now at the Oxford Martin School, and formerly the United Kingdom's chief scientific adviser. In a statement sent to media ahead of the report's publication, the UK government said: \"While the publication of individual pieces of research is a decision for individual government departments, we are clear that access to research is fundamental to effective policy development and wider scientific inquiry across government. We are committed to ensuring that transparency, openness and accountability are embedded in everything we do, and we note today\u2019s report which is a useful contribution to work in this area.\" \u201cWith significant pressures on research budgets across the government and its agencies it is ridiculous that well-grounded research is not accessible to the wider research community as well as to subsequent generations of officials and politicians,\" says Iain Gillespie, pro-vice-chancellor at the University of Leicester, in a statement issued by the London-based Science Media Centre. \"The current system ties up scarce research effort often with little outcome to show for it \u2014 not for any good reason, simply because the research is not shared,\" he says. \n                     Winners and losers emerge in UK funding shake-up 2016-May-19 \n                   \n                     UK government pulls back from rule \u2018gagging\u2019 researchers 2016-Apr-19 \n                   \n                     Sense About Science \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20030", "url": "https://www.nature.com/articles/nature.2016.20030", "year": 2016, "authors": [{"name": "Karen Weintraub"}], "parsed_as_year": "2006_or_before", "body": "Cutting tool could be used to study RNA's role in disease. An article from    Scientific American . Researchers who discovered a molecular \u201cscissors\u201d for snipping genes have now developed a similar approach for targeting and cutting RNA. The new cutting tool should help researchers better understand RNA\u2019s role in cells and diseases, and some believe it could one day be useful in treatments for illnesses from Huntington\u2019s to heart disease. To develop the \u201cblades\u201d for the process, researchers led by Feng Zhang at the Broad Institute used CRISPR (clustered regularly interspaced short palindromic repeats)\u2014a system that bacteria evolved to fight off pathogens. CRISPR has previously been used to edit DNA but had been theorized to work on RNA as well. The new findings, reported Thursday in  Science 1 , came from systematically exploring different aspects of that natural defense system that protects bacteria\u2014and may eventually be put to use helping people. \u201cNature has already invented all these really interesting mechanisms,\u201d Zhang says, comparing himself with a treasure hunter. \u201cWe\u2019re just trying to play with that and learn how they work\u2026then turn them into tools that will be useful to us.\u201d Zhang says the new paper will not affect an  ongoing patent dispute  over who owns rights to the gene-editing approach known as CRISPR\u2013Cas9. His team was the first to use CRISPR\u2013Cas9 in mammalian cells. Another team\u2014led by Jennifer Doudna, at the University of California, Berkeley, and French researcher Emmanuelle Charpentier\u2014was first to publish on CRISPR\u2013Cas9, showing its activity in bacteria. Ironically, Doudna was a co-author on a March paper in  Cell  that used CRISPR\u2013Cas9 to cut RNA in mammalian cells whereas Zhang\u2019s new paper focuses on bacteria 2 . The two RNA manipulation methods may be complementary ways to approach the same ends or one may turn out to be more efficient than the other. In interviews this week each group praised the other\u2019s work while touting the advantages of their own respective approaches. Zhang says his new method\u2014using the enzyme C2c2 to target RNA\u2014relies on an existing natural system and therefore may be more effective than an approach that requires more manipulation. Gene Yeo, senior author on the  Cell  paper, says he has collaborated with both Doudna and Zhang, and described the new paper as a continuation of the kind of \u201cfriendly competition\u201d that drives science. \u201cThere\u2019s always a bit of a race between a lot of the groups, including mine,\u201d he says. \u201cI think scientific competition is good. People tend to push the boundaries more.\u201d Although Yeo pointed out that the C2c2 system has not yet been shown to work in mammalian cells, Zhang says unpublished results make him optimistic that it will. Both RNA-targeting approaches have a long way to go before they could be tested in people\u2014but the promise is there, says Yeo, a professor of cellular and molecular medicine at the University of California, San Diego. Targeting RNA may also offer new insights into how changes in RNA lead to changes in biology and the development of disease. \u201cI think we\u2019ll see an avalanche of these tools that will enable us to monitor and study RNA,\u201d Yeo says. \u201cThis helps us think about RNA as not just an intermediate molecule between DNA and protein,\u201d but as a therapeutic tool for treating diseases and problems of development. Genes consist of double-stranded DNA, which makes single-stranded RNA\u2014which in turn makes the proteins needed for life. Many diseases result from too much or too little protein. Theoretically, acting on the RNA could push those protein levels up or down, thereby offering treatments. Manipulating RNA poses fewer ethical concerns than tinkering with the underlying DNA, although gene editing will remain a better approach for treating some diseases. \u201cThe problem with DNA editing is that it\u2019s permanent,\u201d Yeo says. \u201cThat could be good, but what if you make a mistake?\u201d In some cases, such as with brain cells, DNA repair mechanisms are so strong that it may be more effective to act on the RNA rather than cutting the DNA, says Yeo, who has started a company that\u2019s still in stealth mode to begin looking at treating diseases with this approach. The  Science  paper reports that C2c2 could also be used to add fluorescent tags to RNA as a way to track and better understand its activities. Zhang says he has long been interested in developing systems to target RNA. His team decided to survey the different kinds of CRISPR systems to figure out their functions. C2c2 turned out to be an RNA-targeting system, according to the new study, which includes researchers from the National Institutes of Health, Rutgers University and the Skolkovo Institute of Science and Technology in Russia, in addition to Harvard University and Massachusetts Institute of Technology. Like the Cas9 system that targets specific DNA, C2c2 can be aimed directly at desired RNA sequences, with seemingly few off-target effects. \u201cThe reason that it has evolved is to be able to use RNA guides to target RNA,\u201d Zhang says. His colleague, Eugene Koonin, a co-author on the new paper, puts it more poetically: \u201cEvolution of life to a very large extent is a story of host\u2013parasite interactions,\u201d says Koonin, an expert in evolutionary genomics at the National Center for Biotechnology Information. \u201cAs we explore this arms race between host and parasite, we discover more and more intricate, novel ways in which cellular organisms cope with parasites and parasites counteract.\u201d \n                   Gene-editing hack yields pinpoint precision 2016-Apr-20 \n                 \n                   CRISPR: Pursuit of profit poisons collaboration 2016-Apr-13 \n                 \n                   CRISPR: gene editing is just the beginning 2016-Mar-07 \n                 \n                   Biologists create more precise molecular scissors for genome editing 2015-Dec-01 \n                 \n                   Alternative CRISPR system could improve genome editing 2015-Sep-25 \n                 \n                   Nature  special: CRISPR gene editing \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20096", "url": "https://www.nature.com/articles/nature.2016.20096", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Florida repository of marine sediments dates back to early days of US polar exploration. Free to a good home: more than 23 kilometres of skinny tubes of dirt. With them comes a half-century of Antarctic geological history. The US National Science Foundation (NSF) is looking for a new place to store its Antarctic marine-sediment cores, the world's biggest collection of environmental records from the Southern Ocean. The cores have lain on shelves at Florida State University in Tallahassee since 1963. But last year, the university told the NSF that it no longer wanted to host the collection. Ideas for where the  Antarctic Marine Geology Research Facility  might move to are due by 3 August. \u201cThis area of research is not a priority for the current faculty,\u201d says Gary Ostrander, vice-president for research at Florida State. \u201cIt doesn\u2019t make sense to continue to support that size facility.\u201d The NSF contributes roughly US$280,000 per year, but the university has to pay for overhead costs such as air conditioning for the 930-square-metre building. The invaluable collection includes cores that were taken half a century ago by the USS  Eltanin  \u2014 the first ice-strengthened US research vessel in Antarctic waters \u2014 as well as material gathered in the 2000s by the international ANDRILL programme,  which revealed the history of the West Antarctic Ice Sheet  over the past 17 million years. \n               Freezer burn \n             The transfer is a blow for Sherwood Wise, a geologist at Florida State and the facility's principal investigator. \u201cIt\u2019ll be a sad day for me,\u201d he says. \u201cThis has been a marvellous resource for the university.\u201d In the early 1960s, a Florida State geologist who was also a naval officer volunteered to host the first deep-sea cores coming back from the fledgling US Antarctic programme. The university built a one-storey building for them on its palm-tree-lined campus. The cores are split in half, labelled, sampled and preserved in perpetuity. Dozens of researchers from around the world visit the collection every year to study palaeoclimate and other clues buried within the sediments. (Ice cores from the US Antarctic programme are stored elsewhere, in a freezer in Denver, Colorado.) Over the years, more and more cores have accumulated, from more than 90 research cruises. Studies of the samples have triggered hundreds of publications on all aspects of Southern Ocean and Antarctic history. Some of them have inspired follow-up cruises by other deep-sea drilling expeditions. Curating these older materials is vital because Antarctic samples are  so expensive and difficult  to gather, says Philip Bart, a marine geologist at Louisiana State University in Baton Rouge. \u201cThe facility is critical to ongoing research,\u201d he says. \n               Core concern \n             In the late 2000s, the building began to run out of space for all the cores. Wise applied for and got an NSF grant to install mobile shelving to accommodate more samples. But he is retiring this year, and university administrators have told the NSF that the facility will have to move elsewhere. The transfer is part of a natural evolution of core curation, says Frank Rack, a marine geologist at the University of Nebraska\u2013Lincoln who is executive director for the ANDRILL programme. For instance, the various generations of ocean-drilling research programmes have consolidated their collections over the years and established international centres for long-term storage. \u201cMany people care deeply about these cores and samples,\u201d he says. Wherever and whenever the Florida cores move, Wise estimates that it will take around $2 million just to pack them up and ship them. There are no major drilling projects planned in the next few years for the US Antarctic programme, which means that there is no big influx of cores expected in the near future. Even once the cores are gone, Florida State will still have one big NSF-funded crown jewel. A few kilometres away from the Antarctic core facility is the National High Magnetic Field Laboratory, for which Florida State beat out the Massachusetts Institute of Technology during a national competition in 1990. \n                     Sediment cores reveal Antarctica's warmer past 2008-Apr-24 \n                   \n                     Drillers get into Antarctic seabed 2006-Nov-07 \n                   \n                     Antarctic journal: Life on the ice \n                   \n                     Antarctic Marine Geology Research Facility \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19438", "url": "https://www.nature.com/articles/nature.2016.19438", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Raw data from macaque experiment published daily online. Researchers in the United States who have infected monkeys with Zika virus made their first data public last week. But instead of publishing them in a journal, they have  released them online  for anyone to view \u2014 and are updating their results day by day. The team is posting raw data on the amount of virus detected in the blood, saliva and urine of three Indian rhesus macaques, which they injected with Zika on 15 February. \u201cThis is the first time that our group has made data available in real time,\u201d says David O\u2019Connor, a virologist at the University of Wisconsin\u2013Madison and a leader of the project, whose scientists have dubbed themselves  ZEST (the Zika experimental-science team ). He hopes that releasing the data will help to speed up research into the nature of the virus that has spread across the Americas. Although a few teams have  begun to share genomic data online  during disease outbreaks, instant open-data release remains the exception rather than the rule, particularly in clinical research. O\u2019Connor says that he was inspired by researchers during the Ebola epidemic who  rapidly published genomic-sequencing data online  and encouraged others to re-analyse them. At the time, O'Connor's group downloaded raw data shared by a team led by Pardis Sabeti, a computational geneticist at the Broad Institute and Harvard University in Cambridge, Massachusetts; it immediately helped to advance their own Ebola research, he says, and led to a collaboration with Sabeti's group. \"O'Connor's team is to be lauded for their efforts to make their Zika virus data publicly available as soon as possible,\" says Nathan Yozwiak, a senior scientist in Sabeti's laboratory. \"Distributing up-to-date information \u2014 in this case, animal model data \u2014 as widely and openly as possible is critical during emergencies such as Zika, where relatively little is known about its pathogenesis, yet public concerns and attention are so high.\" \u201cThis is exemplary for research,\u201d agrees Koen Van Rompay, a specialist in non-human primate models of HIV infection at the California National Primate Research Center at the University of California, Davis. Van Rompay is part of a consortium that plans to inject pregnant macaques with Zika. He says that his team will also share data openly in real time. O\u2019Connor\u2019s team seems to be the first to have detailed information from macaques infected with Zika virus, so the rapid data release will enable other researchers planning similar experiments to take the work into account, saving time and resources, Van Rompay adds. \u201cThis is such an urgent public-health emergency that this should not be a race of scientists competing against each other. We\u2019re in a race against the Zika virus, a race against time,\u201d he says. \n             Animal models \n           Like other researchers, the ZEST team wants to understand  when a developing fetus might be at risk of birth defects from Zika . Typically, the virus gives rise to no or mild symptoms \u2014 but scientists are urgently working to estimate the strength of any association between Zika infection and an apparent rise in the number of babies born with microcephaly (abnormally small heads and brains) in northeastern Brazil. If the virus behaves the same way in macaques that it does in humans, O\u2019Connor says, researchers will be able to glean information by infecting monkeys with varying doses of Zika \u2014 data that would be impossible to gain rapidly or ethically from people. Scientists could repeatedly sample amniotic fluid in pregnant macaques, for example, to determine whether, and how quickly, the virus can infect a fetus. The team is starting with male monkeys to get information on how the virus behaves in macaques and determine which dose would be most suitable for later experiments. They have already shown that Zika can infect macaques and that it is detectable not only in blood, but also in cerebrospinal fluid and urine. They will follow up their work with experiments in macaques at different stages of pregnancy, checking for the virus's presence in a wide range of tissues and organs. Even if a link to birth defects is proven, it may still be that very few Zika infections during pregnancy lead to microcephaly, O'Connor says. But he thinks that even with a small number of animals, the team can assess important questions such as whether fetuses become infected with Zika virus and whether they develop abnormalities as a result. Pregnant rhesus macaques have been used in past to study congenital birth defects, O\u2019Connor adds. Research on the effects of cytomegalovirus or  Listeria , for example, have revealed that the diseases produce similar effects in macaques and in humans. The team also hopes to carry out Zika studies in marmosets, which are native to northeastern Brazil and smaller than macaques, making them easier to work with in the lab. If it is possible for the virus to infect marmosets, this might also suggest that the animals are involved in Zika transmission in Brazil, O'Connor says. \n             Open data \n           It was easy for the ZEST members to make their online lab notebook open to all, O\u2019Connor says. The team uses the biomedical-research collaboration system LabKey Server, as does the Wisconsin National Primate Research Center in Madison, which is where many of the ZEST collaborators work and which (along with the US National Institutes of Health) is supporting the research. Researchers created a study to store and update their data, and simply had to switch permissions to allow anyone to view it. Meanwhile, regulatory agencies at the University of Wisconsin\u2013Madison understood that the work was time-sensitive and expedited approvals for animal care and biosafety (without reducing scrutiny, O\u2019Connor adds). On 10 February, dozens of major funders, government agencies and journals released a  statement  supporting open-data sharing \u2014 even before publication \u2014 during public-health emergencies such as the Zika and Ebola epidemic. \u201cIn the context of a public-health emergency of international concern, there is an imperative on all parties to make any information available that might have value in combatting the crisis,\u201d it concluded. Jeremy Farrar, director of the Wellcome Trust in London \u2013 one of the research funders that signed the statement \u2013 says he welcomes the \u201cincreasing commitment\u201d of scientists to sharing information during public health emergencies. \u201cThe world is changing and all of us involved need to encourage, facilitate and give thanks and credit to these teams and the approach they are taking,\u201d he says. \u201cI hope that even those who disagree in principle with animals in research realize that making data available publicly works towards a common goal,\" O'Connor adds. \"Fewer animals will be used in research if groups know what others are doing, and the information that is gained from each animal is maximized.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Zika-microcephaly paper sparks data-sharing confusion 2016-Feb-12 \n                 \n                   Benefits of sharing 2016-Feb-10 \n                 \n                   Proving Zika link to birth defects poses huge challenge 2016-Feb-09 \n                 \n                   Zika virus: Brazil's surge in small-headed babies questioned by report 2016-Jan-28 \n                 Reprints and Permissions"},
{"file_id": "530394a", "url": "https://www.nature.com/articles/530394a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Researchers suspect motives for a planned increase in felling are commercial, but forest administration cites pest control. A Polish proposal to increase logging in the ancient Bia\u0142owie\u017ca Forest is drawing fresh criticism from scientists. They suspect that the motives are partly commercial, and dispute claims that an outbreak of bark beetle threatens the forest. The Polish Ministry of the Environment says that there is no commercial benefit to the proposed logging and insists that it is needed for pest control. The  1,500-square-kilometre forest , which straddles the Poland\u2013Belarus border, has remained largely unchanged for centuries, making it a matchless stomping ground for researchers tracing the behaviour and ecology of insects, birds and mammals, including the largest population of European bison ( Bison bonasus ). It is also a source of ecological measurements, for example on regeneration after disturbances, that inform forest management elsewhere, says Rafa\u0142 Kowalczyk, director of the Polish Academy of Sciences\u2019 Mammal Research Institute in the village of Bia\u0142owie\u017ca. A Bia\u0142owie\u017ca management plan limits logging in the forest to 48,000\u00a0cubic metres of wood per year \u2014 enough to allow locals to gather firewood. But on 10 November, the local forest administration proposed an amendment that would allow large-scale logging in sections outside the central 17% of the forest that is a national park. They cited an outbreak of the bark beetle pest ( Ips typographus ) in Bia\u0142owie\u017ca\u2019s Norway spruce ( Picea abies ). In one forest district where logging is currently limited to 6,000\u2009m 3  per year, the allowable yearly volume would increase to 53,000\u2009m 3 . On 18\u00a0November, scientists with Poland\u2019s State Council for Nature Conservation condemned the proposal; public protests have followed. This week in  Nature , Polish biologists express other concerns in two Correspondence articles ( P. Chylarecki and N. Selva Nature 530, 419; 2016 ;  P. Michalak Nature 530, 419; 2016 ). Conservation council member and Correspondence author Przemys\u0142aw Chylarecki, who is an ornithologist at the Museum and Institute of Zoology in Warsaw, suspects that commercial considerations, not just pest control, are behind the plan. Poland\u2019s government was elected in October \u2014 and the environment minister referred to the wasted commercial potential of unlogged trees in his election campaign, notes Chylarecki. But an environment ministry spokesman, Jacek Krzemi\u0144ski, says that there is no commercial incentive because the wood is only good for firewood, and the costs of logging and transport make it unprofitable to sell the wood on. Kowalczyk, who also opposes the logging proposal, says that the pest-control argument is misguided. Recurring bark-beetle outbreaks do not endanger the forest at large because more-resilient tree species spread and replace spruce, he says. \u201cThat\u2019s a perfectly natural process and endlessly preferable to cutting down trees.\u201d But Jaros\u0142aw Krawczyk, spokesman for the regional state forest directorate in Bia\u0142ystok, says that the current outbreak is unprecedented in scale and has already begun to attack other tree species. A detailed assessment of forest health is under way, says Krzemi\u0144ski. Earlier this month, a regional environment agency suggested that the amount of extra logging be reduced to half of the volume proposed in the new management plan, whereas Poland\u2019s national forest authority has yet to weigh in. Depending on its opinion, the ministry will decide on the amendment later this year, Krzemi\u0144ski told  Nature . \n                 Tweet \n                 Follow @NatureNews \n               \n                     Forests not equal when it comes to climate 2016-Feb-04 \n                   \n                     Conservation: A to-do list for the world's parks 2014-Nov-05 \n                   \n                     Rethinking predators: Legend of the wolf 2014-Mar-07 \n                   \n                     Ecology: The heart of the wood 2008-Sep-17 \n                   \n                     Bia\u0142owie\u017ca Forest UNESCO World Heritage site \n                   \n                     Polish Academy of Sciences Mammal Research Institute \n                   Reprints and Permissions"},
{"file_id": "530392a", "url": "https://www.nature.com/articles/530392a", "year": 2016, "authors": [{"name": "Gabriel Popkin"}], "parsed_as_year": "2006_or_before", "body": "System uses Landsat data to issue warnings just hours after tree loss is detected. A satellite-based alert system could prove a potent weapon in the fight against deforestation. As few as eight hours after it detects that trees are being cut down, the system will send out e-mails warning that an area is endangered. That rapid response could enable environmental managers to catch illegal loggers before they damage large swathes of forest. \u201cIt\u2019s going to be very, very helpful,\u201d says Brian Zutta Salazar, a remote-sensing scientist at the Peruvian Ministry of the Environment in Lima. Satellites are already valuable tools for monitoring deforestation; in recent decades, they have delivered consistent data on forest change over large and often remote areas. One such effort, the Real Time System for Detection of Deforestation, or DETER, has helped Brazil\u2019s government to reduce its deforestation rate  by almost 80% since 2004 , by alerting the country\u2019s environmental police to large-scale forest clearing. But DETER and other existing alert systems can be relatively slow to yield useful information. They use data from the Moderate Resolution Imaging Spectroradiometer (MODIS) on NASA\u2019s Terra satellite, which at its top resolution produces images with pixels covering an area 250 metres on each side, roughly equivalent to 10 football pitches. This is too big to spot small changes in land cover, so it can take computer programs that process MODIS data weeks or even months to detect that a forest is being cleared. \u201cBy the time MODIS picks up on it, it\u2019s almost too late,\u201d says Peter Ellis, a forest-carbon scientist at the Nature Conservancy, a conservation group in Arlington, Virginia. Seeking to provide a sharper view, geographer Matthew Hansen of the University of Maryland in College Park and his colleagues published maps showing year-to-year changes in global forest cover from 2000 to 2012 ( M.\u00a0C.\u00a0Hansen  et al .  Science    342,  850\u2013853; 2013 ). The researchers relied on data from NASA\u2019s  two active Landsat satellites , which together photograph every spot on Earth every eight days. Each pixel in a Landsat image is 30\u00a0metres on each side \u2014 roughly the size of a baseball diamond. This means that an area covered by just one MODIS pixel is captured in roughly 70 smaller Landsat pixels. Hansen and his team wrote data-processing software that can use these higher-resolution images to recognize a disturbance as small as a road snaking its way through a previously untouched forest, something that  often appears before clear-cutting  begins. \u201cIt\u2019s much more advantageous to detect a smaller clearing first, and to figure out what that is, compared to finding something large,\u201d says Salazar. Using this system, Hansen and his colleagues plan to start updating the forest-change maps on their website more frequently \u2014 just hours after new deforestation is detected. A paper detailing the team\u2019s methodology has been accepted for publication in  Environmental Research Letters . The World Resources Institute, an environ\u00admental group in Washington DC,  will provide access  to the deforestation alerts on its Global Forest Watch website, beginning in early March. When trees disappear between successive Landsat passes, a pixel representing that location on an online map will turn red. Users will also be able to sign up to receive e-mails when land cover changes in a specific area, such as a park, an indigenous territory or a privately owned forest, which could facilitate rapid responses to small-scale deforestation. But the alert system is limited in some important ways. Landsat detects only visible light and short-wave infrared, so it cannot see through clouds. This means that in the planet\u2019s cloudiest areas \u2014 such as many tropical rainforests \u2014 the satellites could go months without collecting images of the underlying land. Nor can the probes reliably detect damage from activities that leave the forest canopy intact, such as selective logging and the gathering of wood for fuel. Because such forest degradation can yield carbon emissions that approach half those from all-out deforestation, tracking this damage is important in understanding the role of forests in climate change, says Alessandro Baccini, a remote-sensing expert at the Woods Hole Research Center in Falmouth, Massachusetts. And then there is the difficulty of ensuring that deforestation alerts reach not only govern\u00adment officials, but also people who live in or near affected forests. \u201cWe will have faster detection, but OK, so what, what do you do next?\u201d says Carlos Souza, a research scientist at Imazon, an environmental research institute in Bel\u00e9m, Brazil. He would like to see residents of remote forests trained to check the veracity of satellite-driven alerts on the ground. That could also help countries to improve their estimates of greenhouse-gas emissions from tree loss. In the meantime, the Landsat-based alerts represent a significant step forward for the fight against deforestation, says Frances Seymour, a senior fellow at the Center for Global Development, a think tank in Washington DC. \u201cIn the context of law enforcement, timeliness is every\u00adthing,\u201d she says. \u201cA couple weeks later, not only is the forest gone, but so is the equipment and all the evidence you might be able to use for a successful prosecution.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Paris climate deal hinges on better carbon accountancy 2016-Jan-26 \n                   \n                     Forests in spotlight at Paris climate talks 2015-Dec-01 \n                   \n                     Stopping deforestation: Battle for the Amazon 2015-Apr-01 \n                   \n                     Global Forest Watch \n                   \n                     University of Maryland Global Forest Change \n                   \n                     SilvaCarbon \n                   \n                     Landsat (USGS) \n                   \n                     Landsat (NASA) \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19441", "url": "https://www.nature.com/articles/nature.2016.19441", "year": 2016, "authors": [{"name": "Mark Zastrow"}], "parsed_as_year": "2006_or_before", "body": "For the first time, astronomers have traced an enigmatic blast of radio waves to its source. Since 2007, astronomers have detected curious bright blasts of radio waves from the cosmos, each lasting no more than a few milliseconds. Now scientists have been able to pinpoint the source of one of these pulses: a galaxy 1.9 billion parsecs (6 billion light years) away. It probably came from two colliding neutron stars, says astronomer Evan Keane, a project scientist for the Square Kilometre Array (SKA). Keane, who works at the SKA Organization's headquarters at Jodrell Bank Observatory outside Manchester, UK, led the team that reports the detection in  Nature 1 . The discovery is the \u201cmeasurement the field has been waiting for\u201d, says astronomer Kiyoshi Masui of the University of British Columbia in Vancouver, Canada. By finding more such fast radio bursts (FRBs) and measuring the distance to their source, astronomers hope to use the signals as beacons to shed light on the evolution of the Universe. \n             Eyes on the skies \n           All but one of the 16 previously reported FRBs were found long after the signals reached Earth, by trawling through archives of telescope data. But today, supercomputers can process these signals in real time and detect them as they arrive, says Keane. On 18 April 2015, the Parkes radio telescope in Australia detected a burst lasting less than 1\u00a0millisecond, one of the shortest yet. Parkes\u2019 resolution isn\u2019t fine enough to pinpoint the location of signals, but Keane, who saw the news when he checked emails buzzing into his phone, alerted a network of higher-resolution ground- and space-based telescopes. Two hours after the initial burst, the Australia Telescope Compact Array in New South Wales caught what appeared to be a fading radio afterglow in the same area. This narrowed the search field enough for the 8.2-metre Subaru Telescope on Mauna Kea, Hawaii, to home in on a lone elliptical galaxy, which Keane and his team say is almost certainly the source of the burst. The galaxy is relatively old, and so makes new stars very rarely. Because of that, Keane\u2019s team thinks that the burst came from two colliding neutron stars, which orbited each other in a death spiral until they merged. The brevity of the burst is consistent with the expected timescale for such an event, rather than a collision between larger objects such as white dwarves, or a massive supernova. (If the event was a neutron-star merger, it would also have emitted gravitational waves \u2014 the ripples in space-time that the  US Laser Interferometer Gravitational-Wave Observatory reported detecting two weeks ago .) Not all FRBs fit the scenario for a neutron-star collision. Last December 2 , Masui and his colleagues reported a detection by the Green Bank Telescope in West Virginia that  seems to originate from a young neutron star  with a strong magnetic field emitting intense flares. This suggests that there are multiple kinds of bursts, from different origins. \u201cThe implications for the origins of FRBs are still a bit unclear,\u201d says Victoria Kaspi, an astronomer at McGill University in Montreal, Canada. \n             Imprints of the Universe \n           As a radio pulse from an FRB ploughs through space, its staccato blast is  smeared out by free-floating electrons in its path , so that radio telescopes detect the signal as more like a falling note. Now that Keane and his team know the distance to the new FRB, they can use the length of the signal to reveal how much material it passed through. This could solve a longstanding mystery: precise measurements of the cosmic microwave background \u2014 the afterglow of the Big Bang \u2014 suggest that around 4% of the observable Universe today should be composed of ordinary matter (not dark energy or dark matter). But after totting up what they can see, researchers say around half that matter remains unaccounted for. The amount of signal smearing from the team\u2019s FRB indicates that the \u2018missing\u2019 matter is indeed there, Keane's team now report. Future bursts detected all around the sky could be used as probes to map that matter in detail. A similar approach could yield a map of the magnetic fields between galaxies, as they alter the bursts\u2019 polarization signature in detectable ways. Three instruments that will be able to detect several FRBs per day are either ramping up or set to begin operations this year: the  Canadian Hydrogen Intensity Mapping Experiment  in British Columbia, the upgraded Molonglo Observatory Synthesis Telescope near Canberra and the Five-hundred-meter Aperture Spherical Radio Telescope in Guizhou province, China. \u201cThe field is about to transition from being kind of a fringe, astrophysical-curiosity freak show to potentially a mainstream research area,\u201d says astronomer Duncan Lorimer of West Virginia University in Morgantown, who led the team that  found the first FRB back in 2007 3 , and wrote a News & Views 4  to accompany the latest report. \u201cWe\u2019ll have the potential to soon be overwhelmed by these things,\u201d he says. Read the accompanying  News & Views . \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Mysterious radiowave blast may have come from starquake 2015-Dec-02 \n                 \n                   Search for extraterrestrial intelligence gets a $100-million boost 2015-Jul-20 \n                 \n                   Mystery extra-galactic radio bursts could solve cosmic puzzle 2013-Jul-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19410", "url": "https://www.nature.com/articles/nature.2016.19410", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Field experiment finds that rising carbon dioxide emissions have reduced coral-reef growth by 7% since the Industrial Revolution. Scientists have provided the first experimental evidence that rising carbon dioxide emissions are harming coral reefs in the wild. A team led by Ken Caldeira, a climate scientist at the Carnegie Institution for Science in Stanford, California, used an antacid to alter the chemistry of seawater at a small atoll in the Great Barrier Reef off Australia's west coast. The antacid made the seawater less acidic, mimicking pre-industrial ocean conditions. As a result, the rate at which coral reefs in the atoll grew increased by nearly 7% \u2014 suggesting that present-day CO 2  emissions have slowed down coral growth by making seawater more acidic. \u201cWe\u2019ve provided evidence, for the first time in a natural ecosystem, that ocean acidification is already affecting coral reefs,\u201d says Caldeira. The results agree with with  laboratory studies  indicating that corals \u2014 and other organisms that build their shells out of chalky calcium carbonate \u2014 suffer as seawater becomes acidic. The chemical shift can slow the growth of calcium carbonate shells and skeletons, or even dissolve them 1 . Today\u2019s oceans are already  30% more acidic  than they were before the Industrial Revolution. If current trends continue, Caldeira says that ocean acidification could shift corals into a permanent state of decline by mid-century. \n             Sea change \n           \u201cThe significance of this study is that it wasn\u2019t done in a laboratory, so you are actually seeing the response in the field,\u201d Richard Feely, a chemical oceanographer at the National Oceanic and Atmospheric Administration in Seattle, Washington. Feely was part of a team that ran a series of similar experiments beginning in 2008 in oyster hatcheries on the  US Pacific northwest coast . By manipulating the chemistry of the seawater piped into the indoor hatcheries, the scientists were able to counteract acidification and boost oyster production. The experiment by Caldeira and his colleagues is the first to isolate the effect of acidification in a natural reef environment, although a prior study altered pH in semi-enclosed seawater flumes on the Great Barrier Reef 2 . Researchers have documented damage to reefs in the field before 3 , but determining the factors at work can be tricky. In many cases, corals face harm from a combination of warming seas, coastal pollution and overfishing. This has pushed most researchers studying ocean acidification to work in labs, where they can control and isolate various confounding factors \u2014 but those studies necessarily focus on individual coral species rather than entire reef ecosystems.\u00a0 For Caldeira's team, designing and running an experiment on a natural reef proved exceedingly difficult. But they were aided by the geography of their study site, One Tree Island, a shallow atoll on the southern end of the Great Barrier Reef. A pair of lagoons on the island are submerged during high tide but exposed \u2014 and separated from the ocean \u2014 at low tide. For an hour each day, seawater drains from one lagoon to the other across a reef. \n             Turning back the clock \n           For 15 days, Caldeira\u2019s team boosted the alkalinity in the upper lagoon by releasing sodium hydroxide, or lye, as well as a non-reactive dye. During another seven-day period, they released only dye. By measuring the concentrations of both additives upstream and downstream, the scientists were able to calculate the overall increase in calcification across the reef\u00a0when the seawater chemistry was altered.\u00a0 Caldeira says that his team's first two expeditions to the atoll failed to deliver clear data, because the team was measuring tiny differences in lye concentrations \u2014 equivalent to a couple of tablespoons of lye spread across 30-40 metres of reef. On its third and final expedition, the team added sampling stations and used more precise instruments to analyse the water chemistry. \u201cWe were pushing up against the limits of detectability on these time scales,\u201d he says. In principle, the experiment supports the idea that humans may one day be able to artificially counteract ocean acidification and protect some reefs from the effects of ocean acidification. \u201cThis is a ray of light showing that if we actually do something politically about climate change, the reefs can respond,\u201d says David Kline, a marine ecologist at the Scripps Institution of Oceanography in La Jolla, California. But Caldeira says it would be impossible to pursue this strategy at any significant scale \u2014 and far wiser to reduce CO2 emissions. In September, his team is planning a second experiment that will take a peak into the future. Rather than adding an antacid, the researchers will add carbon dioxide in order to boost the seawater acidity to levels that would be expected in 2100 if emissions continue to rise. \n                   Crucial ocean-acidification models come up short 2015-Aug-05 \n                 \n                   Rising ocean acidity will exacerbate global warming 2013-Aug-25 \n                 \n                   US state declares war on acid waters 2012-Nov-27 \n                 \n                   Global network will track acidifying oceans 2012-Jun-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19414", "url": "https://www.nature.com/articles/nature.2016.19414", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Researchers now argue that slowdown in warming was real. The latest salvo in an ongoing row over global-warming trends claims that warming has indeed slowed down this century. An apparent slowing in the rise of global temperatures at the beginning of the twenty-first century, which is not explained by climate models, was referred to as a \u201chiatus\u201d or a \u201cpause\u201d when first observed several years ago. Climate-change sceptics have used this as evidence that global warming has stopped. But in June last year, a study in  Science   claimed that the hiatus was just an artefact \u00a0which vanishes when biases in temperature data are corrected 1 . Now a prominent group of researchers is countering that claim, arguing in  Nature Climate Change  that even after correcting these biases the slowdown was real 2 . \u201cThere is this mismatch between what the climate models are producing and what the observations are showing,\u201d says lead author John Fyfe, a climate modeller at the Canadian Centre for Climate Modelling and Analysis in Victoria, British Columbia. \u201cWe can\u2019t ignore it.\u201dFyfe uses the term \u201cslowdown\u201d rather than \u201chiatus\u201d and stresses that it does not in any way undermine global-warming theory. \n             Ups and downs \n           The debate revolves in part around statistics on temperature trends. The study 1  that questioned the existence of the slowdown corrected known biases in the surface temperature record maintained by the US National Oceanic and Atmospheric Administration (NOAA), such as differences in temperature readings from ships and buoys. This effectively increased the warming recorded, and the researchers also extended the record to include 2014, which set a new record high for average temperatures. That work, led by Thomas\u00a0Karl, director of NOAA\u2019s National Centers for Environmental Information in Asheville, North Carolina, calculated the rate of global warming between 1950 and 1999 as being 0.113 \u00b0C per decade, similar to the 0.116 \u00b0C a decade calculated for 2000\u201314. This, Karl said, meant that an assessment done by the influential Intergovernmental Panel on Climate Change in 2013 3  showing that warming had slowed was no longer valid. Fyfe and his colleagues argue 2  that Karl\u2019s approach was biased by a period of relatively flat temperatures that extended from the 1950s into the early 1970s. Greenhouse-gas emissions were lower then, and emissions of industrial pollutants such as sulphate aerosols\u00a0were cooling the planet by reflecting sunlight back into space. Fyfe says that his calculations show that the planet warmed at 0.170 \u00b0C per decade from 1972 to 2001, which is significantly higher than the warming of 0.113 \u00b0C per decade he calculates for 2000\u201314. Fyfe says that the advantage of this approach is that it takes account of events that affect decadal temperature trends. For instance, researchers have found that climate models underestimated the cooling effect of volcanic eruption and overestimated the heating from solar radiation at the beginning of the twenty-first century 4 . Other researchers are investigating variability in the Pacific Ocean, including a measure of sea surface temperatures known as the Pacific Decadal Oscillation (PDO) 5 . All these things can affect the climate, and mask the longer-term warming trend. \n             Bumps and wiggles \n           Susan Solomon, a climatologist at the Massachusetts Institute of Technology in Cambridge, says that Fyfe\u2019s framework helps to put twenty-first-century trends into perspective, and clearly indicates that the rate of warming slowed down at a time when greenhouse-gas emissions were rising dramatically. \u201cIt\u2019s important to explain that,\u201d Solomon says. \u201cAs scientists, we are curious about every bump and wiggle in that curve.\u201d For his part, Karl acknowledges that it is important to investigate how short-term effects might impact decadal trends, but says that these short term trends do not necessarily elucidate the long-term effects of rising greenhouse-gas concentrations in the atmosphere. \u201cWhat gets obfuscated is the goal of uncovering the warming due to persistent greenhouse forcing [by human emissions],\u201d Karl says. \u201cIt is simply not possible to gain insight on that underlying trend from short, segmented 10- to 20-year periods.\u201d Gavin Schmidt, director of NASA\u2019s Goddard Institute for Space Studies in New York, is tired of the entire discussion, which he says comes down to definitions and academic bickering. There is no evidence for a change in the long-term warming trend, he says, and there are always a host of reasons why a short-term trend might diverge \u2014 and why the climate models might not capture that divergence. \u201cA little bit of turf-protecting and self-promotion I think is the most parsimonious explanation,\u201d Schmidt says. \u201cNot that there's anything wrong with that.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   2015 declared the hottest year on record 2016-Jan-20 \n                 \n                   Climate-change \u2018hiatus\u2019 disappears with new data 2015-Jun-04 \n                 \n                   Atlantic Ocean key to global-warming pause 2014-Aug-21 \n                 \n                   Climate change: The case of the missing heat 2014-Jan-15 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19453", "url": "https://www.nature.com/articles/nature.2016.19453", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "But some scientists are not convinced by the report. Researchers in China say that they have discovered a way to make rudimentary mouse sperm in a dish, and used them to produce offspring. If the claim stands up to scrutiny, it could point the way to making human sperm in the lab for fertility treatments. But some scientists are not convinced by the report, which is published today in  Cell Stem Cell 1 . \u201cThe results are super-exciting and important,\u201d says Jacob Hanna, a stem-cell scientist at the Weizmann Institute of Science in Rehovot, Israel. But Takashi Shinohara, a reproductive biologist at Kyoto University in Japan, is among researchers who have doubts about the work: he notes that scientists have struggled to replicate several previous claims that sperm can be made in a dish. In 2011, molecular biologists led by Mitinori Saitou at Kyoto University reported that they had managed to recreate the first stages of sperm development in a dish 2 . They coaxed mouse embryonic stem cells to become cells that resembled primordial germ cells (PGCs) \u2014 an important stage in the development of both eggs and sperm. Saitou's team then implanted the artificial PGCs into a mouse: when implanted in testes, they grew to become sperm; in ovaries, they matured into eggs.  Now, Xiao-Yang Zhao, a development biologist at the Southern Medical University in Guangzhou, and Qi Zhou, a cloning specialist and stem-cell biologist at the Institute of Zoology in Beijing, along with colleagues from Nanjing Medical University, say that they have trumped Saitou\u2019s work by carrying out more of the process in a dish. \n             Recipe for sperm \n           The team first made mouse PGCs, and then added cells taken from the testicular tissue of newborn mice, as well as other biological molecules. After 14 days, they report, spermatid-like cells developed. Spermatids are not mature sperm: they are round, rather than having sperm\u2019s elongated shape, and cannot swim. But they do have only one set of chromosomes, showing that (unlike PGCs) they have passed the critical developmental stage of meiosis, in which a cell\u2019s chromosome pairs split up. The researchers injected the spermatids directly into mouse eggs; this led to offspring which, at 15 months, appear healthy, says Zhao. The animals were able to give birth to a next generation of mice. \u201cThe fact that the resulting cell could be injected into an egg and produce a viable animal is a stringent test,\u201d says Allan Spradling, a reproductive biologist at the Carnegie Institution for Science in Baltimore, Maryland. But the mice that were produced \u201cmight still contain defects or problems that do not manifest themselves until later\u201d, he adds. Azim Surani, a developmental biologist at the University of Cambridge, UK, says that the results are \u201cencouraging\u201d, although he cautions that it is hard to know whether the artificial spermatids do behave exactly like their natural counterparts. \n             Cautious reception \n           Other scientists raise specific concerns that mainly relate to the timing of the processes that lead to the sperm cells. For example, Zhou and Zhao report that, on the basis of a genetic analysis, their artificial PGCs were similar to mouse cells at 12.5 days of development. But Saitou and others say that artificial PGCs should look more like 9.5-day-old cell. And other stages of germ-cell development occurred unexpectedly quickly: in a real mouse, it takes more than 4 weeks for the PGC to become a spermatid, for example, but the Chinese team reports a 14-day interval between artificial PGC and spermatid. \u201cYou have to be very cautious about the implications of this paper,\u201d says Saitou. Shinohara says that the researchers\u2019 scenario is \u201cpractically impossible\u201d, and Takehiko Ogawa, a reproductive biologist at Yokohama City University in Japan, says that the results are so surprising he \u201ccannot yet believe it\u201d. He plans to try to reproduce the results. Zhou says that the researchers are \u201cvery confident\u201d that their protocol can be repeated in other laboratories \u2014 and that it would be normal for there to be variations between creating sperm in a dish and the process in live mice. He says that part of the acceleration could be because the cells seemed to have skipped an \u2018arrested\u2019 state that PGCs normally pass through. But Saitou counters that this state is crucial for PGCs to develop properly; at this accelerated pace, he says, the spermatids might not be normal. \n             From mice to men? \n           Applying the same concept to try to make human sperm is the next step, says Zhao. A year ago, Hanna and Surani  reported making human PGCs in a dish  from reprogrammed skin cells. But for ethical reasons, they didn\u2019t try to reintroduce them into humans 3 . Zhao says that his team is already trying to make human PGCs mature in a dish, using human testicular tissue from patients. And Hanna, who says that such tissue is hard to come by, has been using cells from testicular tissue of mice, pigs and monkeys to attempt the same thing. Still, there are important differences between the way in which sperm develop in mice and in humans, warns Yi Zhang, a geneticist at Harvard Medical School in Boston, Massachusetts. \u201cIt may not be as straightforward as people hope,\u201d he says. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Rudimentary egg and sperm cells made from stem cells 2014-Dec-24 \n                 \n                   Stem cells: Egg engineers 2013-Aug-21 \n                 \n                   Mouse stem cells lay eggs 2012-Oct-04 \n                 Reprints and Permissions"},
{"file_id": "530390a", "url": "https://www.nature.com/articles/530390a", "year": 2016, "authors": [{"name": "Mark Peplow"}], "parsed_as_year": "2006_or_before", "body": "Commercial use of genetically engineered yeast to make medicine has modest impact. When Paris-based pharmaceutical giant Sanofi started to sell  malaria drugs made with the help of genetically engineered yeast  in 2014, the move was hailed as a triumph for synthetic biology. The yeast was fermented in a vat to produce a chemical that Sanofi converted into artemisinin, which is used to make leading malaria treatments called artemisinin-based combination therapies (ACTs). Many hoped that the process would offer  a cheap and plentiful supply of drugs  to tackle a disease that claims almost half a million lives worldwide every year. Yet Sanofi produced no \u2018semi-synthetic\u2019 artemisinin (SSA) at all in 2015,  Nature  has learned. And the company is now selling the manufacturing site in Garessio, Italy, where it made its SSA. That such celebrated drugmaking technology \u2014 developed with the help of US$64 million from the Bill & Melinda Gates Foundation \u2014 stands idle illustrates the complicated web of economic forces that affects the market for malaria drugs. \u201cThis is a perfect example of how a new manufacturing process becomes extremely hard to scale up when there is a complex ecosystem of players,\u201d says Prashant Yadav, a health-policy researcher at the William Davidson Institute at the University of Michigan, Ann Arbor, who studies the ACT market. Before the advent of SSA, the only source of artemisinin was the sweet wormwood plant ( Artemisia annua ), the discovery of which  won Chinese scientist Youyou Tu a share of the 2015 Nobel Prize in Physiology or Medicine . But the  agricultural supply has been erratic . Shortages of  A. annua  send prices soaring, which attracts more farmers to plant it; their produce then swamps the market, depressing prices and triggering fresh shortages (see \u2018A stable artemisinin market?\u2019). \n               Supplement or saviour? \n             The synthetic-biology route promised to end this rollercoaster by providing a stable and reliable source of artemisinin. Sanofi developed the capacity to produce almost 60 tonnes of the chemical per year \u2014 about one-third of global need \u2014 and the company hoped to supply other ACT manufacturers with the raw materials. \u201cIn reality, that has not happened,\u201d says Yadav. Sanofi has so far used its SSA to make more than 39 million treatments of its own version of ACT \u2014 representing about 10% of global ACT demand \u2014 but has not sold the chemical to other drugmakers. That is partly because of a glut in agricultural artemisinin. For the past two years, the naturally derived chemical has sold for less than $250 per kilogram \u2014 below Sanofi\u2019s \u2018no profit\u2013no loss\u2019 margin of around $350\u2013400 per kilogram. \u201cIf that price is already very low and there\u2019s a bumper crop, there\u2019s no reason to fire up a fermenter,\u201d says Jay Keasling of the University of California, Berkeley, who led the team that first developed the yeast strain. But ACT manufacturers such as China\u2019s Guilin Pharma and India\u2019s Cipla are also reluctant to buy their drug ingredients from Sanofi, says Yadav, because the company is a direct competitor in the ACT market. And Sanofi has not found it worthwhile to increase production of its own ACT because demand has plateaued. This is in part the result of growing efforts to diagnose malaria before doling out medicine: malaria treatments are often taken by people with fevers who do not actually have malaria, so more-accurate diagnoses help to reduce the number of treatments needed. Whether demand will rise again will depend on how international efforts to tackle malaria develop in the future, and how much funding will be available to purchase ACTs. By July, Sanofi will complete the sale of its Garessio manufacturing plant to Bulgarian company Huvepharma, a contract manufacturer responsible for fermenting the engineered yeast in vats to make artemisinic acid \u2014 the precursor to artemisinin \u2014 for Sanofi. Nicola de Risi, a manager for Huvepharma in Rome who will head the firm\u2019s Italian division, hopes that by gaining control of the entire SSA production process (from yeast to final product), the company will be able to lower costs and make sales to other ACT manufacturers. But Huvepharma will switch to using plant-derived artemisinin if it cannot make SSA cost-competitive, de Risi says. PATH, a global-health organization based in Seattle, Washington, which coordinated the development of SSA, says that it still considers the project a success. \u201cSince SSA entered the market, we have observed better price stability, and there has been adequate supply of artemisinin,\u201d it said in a statement. \u201cThere is merit to the argument that SSA has contributed somewhat to stabilizing prices,\u201d says Yadav. But the main causes of price stability, he adds, are the recent steady demand for ACTs and long-term purchasing contracts with ACT manufacturers, set up by the Global Fund to Fight AIDS, Tuberculosis and Malaria. PATH and Keasling say that SSA was always intended to be a supplemental source to fill gaps in agricultural production, or to cope with spikes in demand. But Claire Marris, a sociologist of science at City University London who previously worked at the Centre for Synthetic Biology and Innovation at Imperial College London, says that in her experience, SSA is often portrayed by those working in the field as simply a low-cost, high-volume substitute for agricultural artemisinin. \u201cIt was constantly talked about,\u201d she says. Now, Marris worries that unrealistic expectations for SSA\u2019s achievements could damage public trust in synthetic biology. When the Gates Foundation awarded the first of its grants for the SSA project in 2004, it explicitly aimed to lower the cost of each ACT treatment from $2.40 to \u201cwell under a dollar\u201d. But the median price of Sanofi\u2019s ACT had already dipped to $0.92 per adult treatment by 2012, well before the introduction of SSA, and it has changed little since then. De Risi says that SSA production will restart later this year so that Sanofi can produce its own ACT treatment. \u201cI think it\u2019s good for synthetic artemisinin,\u201d says Yadav, who points out that other ACT producers may be more willing to buy artemisinin from Huvepharma because it is not an ACT producer itself \u2014 and therefore not a direct competitor. Meanwhile, Guilin Pharma and Cipla are making plans to develop their own SSA, and Keasling hopes that more research and develop\u00adment work could make the synthetic process cheaper in the long term. \u201cI\u2019d like to see SSA take over as the dominant form, and some day I think it will,\u201d says Keasling. \u201cBut we have to be patient.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Anti-parasite drugs sweep Nobel prize in medicine 2015 2015-Oct-05 \n                   \n                     Engineered yeast paves way for home-brew heroin 2015-May-18 \n                   \n                     Synthetic biology: Cultural divide 2014-May-07 \n                   \n                     Malaria drug made in yeast causes market ferment 2013-Feb-13 \n                   \n                     Demand for malaria drug soars 2010-Aug-03 \n                   \n                     Sanofi \n                   \n                     PATH \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19451", "url": "https://www.nature.com/articles/nature.2016.19451", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Market leader Illumina sues rival firm Oxford Nanopore Technologies. Biomedical researchers are dismayed over a patent dispute that could threaten an innovative method for sequencing genomes. Sequencing giant Illumina said on 23 February that it has filed a lawsuit against UK-based Oxford Nanopore Technologies, the first company to commercialize nanopore sequencing. The technology reads single bases of genetic material as they pass through a nanoscale pore. The suit, by Illumina of San Diego, California, alleges that Oxford Nanopore has infringed on Illumina patents that describe aspects of using pores to read DNA. Oxford Nanopore has its own suite of patents related to nanopore sequencing. The two firms  have sparred before . Illumina was once an investor in Oxford Nanopore, but that relationship ended in 2013, after the smaller company switched its focus to develop a nanopore technology that was not covered by their agreement. Illumina does not market a nanopore-based sequencing system. Its machines use a different approach, called sequencing-by-synthesis, in which short stretches of genetic material are read, then computationally stitched together. But the company says that it is working on a nanopore system and \u201chas made substantial investments to obtain licenses and develop the nanopore sequencing technology\u201d. It says that Oxford Nanopore\u2019s technology infringes on its patents. \n             Sparring partners \n           Researchers have reacted to the lawsuit with disappointment.  https://twitter.com/richardmleggett/status/702492373939589120 \u201cSad to see this. We need both of them concentrating on producing great tech,\u201d tweeted computational biologist Richard Leggett of the Genome Analysis Centre in Norwich, UK. Oxford Nanopore\u2019s MinION sequencer, which became commercially available last year, is a palm-sized device that has  created a buzz among users  for its speed, portability and low cost relative to competing machines. Unlike Illumina\u2019s sequencers, the MinION can also read data in real time. Because it is not yet practical to use the device to process human genomes, the MinION does not pose a serious threat to Illumina\u2019s market dominance in high-throughput human genomics. But Oxford Nanopore is planning to debut a higher-throughput system, the PromethION, this year \u2014 and to issue an initial public offering. \u201cThe timing of this [lawsuit] really stinks,\u201d wrote computational biologist Mick Watson of the University of Edinburgh, UK, on his blog,  Opiniomics . \u201cGiven ONT are set to float on the stock market, it\u2019s hard not to see this as a deliberate attempt to scupper that.\u201d\u00a0 Calling himself a fan of both technologies, Watson says he is disappointed by the tussle: \u201cIt\u2019s like having two of your friends fighting.\u201d The major question now is whether the lawsuit will derail Oxford Nanopore\u2019s plans by diverting resources away from developing its technology. Biotechnology venture capitalist Vishal Gulati  calls the fight  a \u201cone sided battle\u201d, saying that Illumina has deeper pockets and a track record of suing competitors successfully. Oxford Nanopore has attempted to allay those concerns. \u201cIt is gratifying to have the commercial relevance of Oxford Nanopore products so publicly acknowledged by the market monopolist\u201d for next-generation sequencing, said company chief executive Gordon Sanghera in a statement on 24 February. \u201cWe do not anticipate any disruption to our ongoing commercial progress as a result of Illumina\u2019s action, which we believe is without merit.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Pint-sized DNA sequencer impresses first users 2015-May-05 \n                 \n                   Data from pocket-sized genome sequencer unveiled 2014-Feb-14 \n                 \n                   Nanopore genome sequencer makes its debut 2012-Feb-17 \n                 \n                   Personal genomes: Standard and pores 2008-Nov-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19452", "url": "https://www.nature.com/articles/nature.2016.19452", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Mission paves the way for planned \u20ac1-billion space observatory. Scientists have long dreamed of launching a constellation of detectors into space to observe gravitational waves \u2014 the ripples in space-time predicted by Albert Einstein and  observed for the first time earlier this  month. That dream is now a step closer to reality. Researchers working on a \u20ac400-million (US$440-million) mission to try out the necessary technology in space for the first time \u2014 involving firing lasers between metal cubes in free fall \u2014 have told  Nature  that the initial test drive is performing just as well as they had hoped. \u201cI think we can now say that the principle has worked,\u201d says Paul McNamara, project scientist for the LISA Pathfinder mission, which  launched last December . \u201cWe believe that we now are in a good shape to look to the future and look to the next generation.\u201d \u201cEverything works as we designed it. It\u2019s sort of magical, and you rarely see that in your career as an experimentalist,\u201d says Stefano Vitale, a physicist at the University of Trento in Italy, and a principal investigator for the Pathfinder mission. The European Space Agency (ESA) financed the test, and  hopes ultimately to launch a \u20ac1-billion observatory to hunt for gravitational waves . For that mission, lasers would be bounced between three spacecraft set millions of kilometres apart. Each craft would contain a test mass (a metal cube) that would be placed in free fall, protected from any forces except that of gravity. Because gravitational waves stretch and compress space-time, the observatory hopes to be able to see passing waves by using the lasers to detect minute changes in the distance between the free-falling cubes. Because of its enormous scale, a space-based observatory could detect lower-frequency gravitational waves than can Earth-based experiments \u2014 such as the US Advanced Laser Interferometer Gravitational-Wave Observatory, which  announced a first successful detection on 11 February . Lower-frequency waves can be triggered by more-powerful events, which scientists hope to study, such as collisions between galaxies and supermassive black holes. The Pathfinder mission aimed to show \u2014 on a much smaller scale \u2014 that the basic design works, and to chart its limitations. It uses two test masses (each a 2-kilogram cube of gold and platinum) set 38 centimetres apart, floats them in isolation from everything except the influence of gravity, and tests to see whether changes in their relative movement can be measured with an accuracy of a picometre, 100,000th of the width of a human hair. To keep the cubes in free fall, the spacecraft monitors their motions and uses tiny thrusters to keep itself centred on the masses. The complexity of such an experiment, carried out millions of kilometres from Earth, meant that sceptics doubted whether it could ever work in space, says Vitale. But data that have been streamed back since 23 February, when Pathfinder began to use the lasers to track its released cubes, show that it not only fulfils its requirements but exceeds them, he says. For now, the team is keeping under wraps details on exactly how well the instruments are performing. Proving that the basic technology works is only the mission\u2019s first step. Its main science goal, which the Pathfinder team will work on over the coming months, is to understand where 'noise' in the system is coming from. That knowledge will be essential in designing the space-based observatory, which is scheduled for launch in 2034. \u201cThe main goal of the mission is not so much to  measure  how well we\u2019re doing, but to  understand  how well we\u2019re doing,\u201d says McNamara. Success of Pathfinder was seen as a prerequisite for building the observatory, which  ESA agreed to fund in 2013 . But before launching such an ambitious experiment, scientists also considered it desirable that gravitational waves should already have been seen on Earth-based detectors. \u201cIt looks like these two conditions have been fulfilled in the same month. So it\u2019s really our month,\u201d adds Vitale. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                   \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                   \n                     Freefall space cubes are test for gravitational wave spotter 2015-Nov-17 \n                   \n                     LISA Pathfinder \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19440", "url": "https://www.nature.com/articles/nature.2016.19440", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Antibody from man who survived infection from 1995 outbreak shows potent effect against deadly virus. The blood of a man who survived an Ebola outbreak nearly 20 years ago is helping scientists to develop a treatment against the disease. The survivor produced some of the strongest protective proteins, or antibodies, against Ebola found so far, researchers report in two papers published today in the journal  Science 1 , 2 . One of these antibodies, dubbed mAb114, is capable of saving monkeys infected with Ebola. \u201cIt\u2019s really stunning that a single antibody can protect against Ebola,\u201d says Nancy Sullivan, a viral immunologist at the US National Institute of Allergy and Infectious Diseases in Bethesda, Maryland, who led the research identifying the antibody. The antibody donor, identified only as \u201csubject 1\u201d, became severely ill with Ebola in 1995, during an outbreak of the virus in Kikwit, Democratic Republic of the Congo. After weeks battling the disease, subject 1 recovered and went back to the Ebola wards to help care for other patients. Eleven years later, scientists drew his blood and isolated the mAb114 antibody. In subsequent tests, the purified antibody saved the lives in of six infected monkeys. Some of the animals recovered despite not receiving treatment until five days after infection. Only one other potential Ebola treatment has proved as powerful in animal studies: the  antibody cocktail known as ZMapp . \n             Search for treatments \n           ZMapp and other similar drugs have been given to more than 80 patients during the Ebola outbreak. On 23 February, researchers reported the results of a clinical trial involving 71 of those patients. Thirty-six people were given ZMapp and 78% of them survived, compared with 63% of patients who did not receive the drug. But that result is not statistically significant. And Mapp Biopharmaceutical of San Diego, California, which developed ZMapp, was forced to end the clinical trial in January without achieving its goal of enrolling 200 patients because of the  waning of the Ebola outbreak . It is not clear whether the new antibody could overcome some of the drawbacks to treating patients with ZMapp. For instance, patients must be infused with relatively large amounts of the drug, and researchers suspect that this may be one reason why so many of those treated develop side effects. Six of 13 patients evacuated from West Africa and treated with ZMapp or closely related drugs in the current Ebola outbreak, for instance, developed side effects including fever, rashes and welts, rapid heart rate and low blood pressure 3 . The National Institutes of Allergy and Infectious Disease, which ran the ZMapp clinical trial with the Liberian ministry of health, said that 25% of patients experienced side effects to the first infusion of the drug, mostly fevers, but that side effects tapered off with each subsequent dose; 10% of patients had side effects after the third infusion. \u201cThe fact that you have to pump people full of antibody for it to work is one of the biggest problems with these therapies,\u201d says infectious-disease researcher Kristian Andersen at the Scripps Research Institute in La Jolla, California. \u201cThat\u2019s going to be a very important question to address.\u201d One of the studies 1  released today tested mAb114 at similar doses to ZMapp, but Sullivan says that further work will explore whether lower doses are effective. \n             Viral trick bested \n           From examining the structure of mAb114, Sullivan and her colleagues conclude that its potency probably arises from its ability to stop the Ebola virus from hijacking the body\u2019s immune defences 2 . Ebola docks to receptor proteins inside cells, which allows the virus to reproduce itself. Ebola hides the protein that it uses to bind to these receptors \u2014 revealing it only after gaining access to the cell's deep interior, where the receptor is found. Normally, this also prevents an antibody from binding to Ebola until it has already reproduced But Sullivan and her colleagues found that mAb114 binds to Ebola viruses, follows them into cells, and blocks the viruses from releasing their deadly payload inside the cell. Sullivan says that her team now plans further work to test whether mAb114 is safe in humans. She says that even though ZMapp looks promising, researchers would prefer to have several possible candidate drugs to choose from in case, for instance, some work better than others or are easier to make. \u201cIt\u2019s sensible to not put all your eggs in one basket,\u201d Sullivan says. \n                   Ebola teaches tough lessons about rapid research 2015-May-27 \n                 \n                   Ethical dilemma for Ebola drug trials 2014-Nov-11 \n                 \n                   Ebola drug saves infected monkeys 2014-Aug-29 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19463", "url": "https://www.nature.com/articles/nature.2016.19463", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "House of Representatives committee expands investigation of a National Oceanic and Atmospheric Administration analysis that refuted global-warming 'hiatus'. Republicans in the US House of Representatives are expanding their request for documents related to a major climate study by the US National Oceanic and Atmospheric Administration (NOAA). Agency researchers \u2014 led by Thomas Karl, director of NOAA\u2019s National Centers for Environmental Information in Asheville, North Carolina \u2014 published the analysis last June in  Science 1 . After updating and correcting problems with the temperature record, the team  found no sign of an apparent pause in global warming  that had been described in previous studies. In October, Congressman Lamar Smith, the Texas Republican who leads the House science committee,  issued a subpoena  for documents related to the NOAA research. The agency has since provided more than 300 pages of e-mails and other documents produced by political appointees and by NOAA's director of communications, Ciaran Clayton. But NOAA has refused to hand over records of its internal scientific deliberations. Now Smith is casting his net wider. In a 22 February letter to NOAA, he expressed disappointment with the \u201cslow pace and limited scope\u201d of NOAA's response to his initial request. \u201cThe speed with which NOAA has conducted these searches and produced documents creates the perception that the Agency is deliberately attempting to impede and hinder the Committee\u2019s oversight,\u201d he wrote. Smith is now asking that NOAA provide his committee with documents from other agency officials and offices, including chief scientist Richard Spinrad. In his letter, Smith also demands that the search terms be expanded to include a host of new words, including \u201ctemperature\u201d, \u201cclimate\u201d, \u201cchange\u201d, \u201cObama\u201d and \u201cParis\u201d. Smith has asked the agency to deliver all documents by 29 February. Clayton says that NOAA is still reviewing the lawmaker's letter. The e-mails that the agency has released to Smith so far discuss NOAA's communications strategy for the release of Karl's study, which NOAA expected to receive intense scrutiny. \u201cThere is nothing in these materials that would support the notion that substance or timing of the paper was politically motivated,\u201d Clayton said. \u201cScience at NOAA is conducted independently and rigorously, and is protected by a robust scientific integrity policy.\u201d The Union of Concerned Scientists, an advocacy group in Cambridge, Massachusetts, which obtained the committee\u2019s letter and released it on 26 February, called the move \u201cunprecedented and unjustified\u201d. \u201cIt\u2019s perfectly reasonable for the committee to have oversight over any sort of political influence over the science,\u201d says Michael Halpern, programme manager for the UCS Center for Science and Democracy. \u201cWhat we are looking for is to stop the kind of ham-handed and broad subpoenas that compromise the ability of scientists to communicate frankly with each other.\u201d As it happens, a prominent group of researchers  published a commentary this week  in  Nature Climate Change 2  that challenges the analysis by Karl and his colleagues. The commentary argues that the rate of warming really has slowed in recent decades. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Global warming \u2018hiatus\u2019 debate flares up again 2016-Feb-24 \n                 \n                   US science agency refuses request for climate records 2015-Oct-28 \n                 \n                   Climate-change \u2018hiatus\u2019 disappears with new data 2015-Jun-04 \n                 \n                   National Oceanic and Atmospheric Administration \n                 \n                   House Committee on Science, Space and Technology \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19456", "url": "https://www.nature.com/articles/nature.2016.19456", "year": 2016, "authors": [{"name": "Natasha Gilbert"}], "parsed_as_year": "2006_or_before", "body": "First assessment from intergovernmental body set up to track world's ecosystems suggests curbing pesticide use to save bees. An international science body tasked with tracking the ecological health of the planet has announced the findings of its first report. The review warns that the ongoing decline in the number of pollinating insects and animals threatens global crop production. The Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services ( IPBES ) was  established in 2012 , and is roughly modelled on the Intergovernmental Panel on Climate Change (IPCC). The reponse to the pollinator report, announced on 26 February at a  meeting in Kuala Lumpur , may be an early sign of whether the body's influence will one day match the IPCC's political and scientific clout. Robert Watson, an environmental scientist at the Tyndall Centre for Climate Change at the University of East Anglia in Norwich, UK, who is vice-chairman of the IPBES, says that he is confident that the assessment will have an impact. The IPBES has 124 member governments, and its pollinator assessment went through two rounds of external peer review. And just as with the IPCC\u2019s climate reports, the assessment was debated word for word, Watson says. \u201cThe fact that all governments requested this document really bodes well that they will use the results,\u201d he says. But Dave Goulson, a bee researcher at the University of Sussex in Brighton, UK, says: \u201cI would question whether any practical on-the-ground action to help pollinators will happen as a result of this document. We are in the midst of the sixth global mass-extinction event, and we sit around spending thousands of hours writing documents about biodiversity, but we do not take action to address the fundamental issues that are causing this ecological catastrophe.\u201d \n             Pollinator warning \n           The report offers a sober assessment of  the\u00a0decline in populations of pollinating insects and animals , affected by factors including climate change, disease and pesticide use. The global production of crops that depend on pollinators is an industry worth up to US$577 billion annually, the report says. \u201cIf we get further declines in wild and managed pollinators, it would be a serious risk to foods that rely on those pollinators, especially food of high nutritional quality such as seeds and fruits,\u201d says\u00a0Watson. It is \u201cbecoming very clear\u201d that pesticides have \u201cdefinite harmful effects\u201d on wild bees, says Simon Potts, a biodiversity scientist at the University of Reading, UK, and co-chair of the report.\u00a0\u201cThere needs to be less application and smart application\u201d of such chemicals, he adds. Studies have  yielded mixed results  on the link between pesticides and declining bee health, the IPBES assessment notes. Critics have questioned some studies for using doses that are much higher than those typically found in pesticide residues on farmers\u2019 fields, and also ask whether sub-lethal effects seen in individual insects are relevant to whole populations. The review acknowledges these limitations, but it says that some lab studies do use realistic doses. The harmful effects seen on individual bees in  one recent field-based study 1  are \u00a0\u201c so huge and so strong\u201d, adds Potts, that it indicates that effects on populations and colonies will likely be negative. The next step is to get direct evidence of long-term population effects, he says. \u201cExposure of pollinators to pesticides can be decreased by reducing the use of pesticides,\u201d the report says, and by using other forms of pest control. It also suggests that farmers could adopt ecologically friendly farming techniques, such as planting strips of flowers to boost pollinating insect numbers. In 2013, the European Commission imposed a temporary ban on the use of three controversial \u2018neonicotinoid\u2019 insecticides \u2014 clothianidin, thiamethoxam and imidacloprid. The European Food Safety Authority (EFSA) in Parma, Italy, is reviewing their safety and expects to complete its analysis by January 2017. \n             IPBES controversy \n           The IPBES assessment attracted controversy before its release: some scientists  complained of a lack of transparency  in the appointment of two agrochemical scientists among 40 lead authors involved in the review. Axel Hochkirch, a biodiversity scientist at the University of Trier, Germany, says that he is still concerned about how the scientists from industry were selected, even though the IPBES requires all lead authors to complete conflict-of-interest statements. Watson told\u00a0 Nature \u00a0that the IPBES conflict-of-interest committee \u201clooked carefully\u201d at the industry scientists\u2019 CVs and \u201cconcluded there is no conflict\u201d. In addition, Watson says that the IPBES has \u201cchecks and balances\u201d in place \u2014 such as planned independent reviews of its procedures in 2017 and 2018 \u2014 to ensure that everything is above board. \u201cThe independent review will be critical,\u201d says Thomas Brooks, head of science at the International Union for Conservation of Nature (IUCN) in Gland, Switzerland. The IPBES has proposed to hand over the leadership of the review to the International Council for Science, a non-governmental organization representing scientific bodies and unions, but Brooks says that the IPBES should select a consultancy company through a competitive and open process. Anne Larigauderie, executive secretary of the IPBES, says that the body will decide how to conduct the reviews at the end of its Kuala Lumpur meeting, on 28 February. The meeting will also set the IPBES budget for the next two years and decide whether it should conduct a global assessment of sustainable biodiversity use, as well as a separate review on invasive species. The IPBES is currently working on four regional biodiversity assessments including in Africa and the Americas, and a separate assessment of land degradation, all of which it hopes to complete by 2018. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Entomology: The bee-all and end-all 2015-May-20 \n                 \n                   Bee studies stir up pesticide debate 2015-Apr-22 \n                 \n                   Major biodiversity initiative needs support 2015-Feb-03 \n                 \n                   Pollinator assessment: IPBES responds on conflicts of interest 2015-Jan-14 \n                 \n                   \u2018Life on Earth\u2019 project gets under\u00a0way 2014-Jun-25 \n                 \n                   IPBES: Biodiversity panel should play by rules 2014-Feb-12 \n                 \n                   World governments establish biodiversity panel 2012-Apr-23 \n                 \n                   IPBES \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19454", "url": "https://www.nature.com/articles/nature.2016.19454", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "No clarity on whether anti-lobbying rule will apply to university funding and science grants. UK scientists may be prevented from arguing for changes in national legislation or policy \u2014 if research grants are not exempted from a government ban on the use of public funds for political lobbying. But days after scientists  raised the alarm  about the government\u2019s anti-lobbying move, the situation is mired in confusion. The UK government Department for Business, Innovation and Skills (BIS), which is responsible for most of the public cash that is channelled to British researchers and universities, could not confirm to  Nature  whether the lobbying ban \u2014 which will apply to government grants from May \u2014 will affect science funding. Major UK research funders say that they do not know whether they will have to implement the rule. On 6 February, the government  announced  that any groups in receipt of public money will be banned from using those funds to attempt to influence either the government or Parliament. A clause inserted into all government grants starting in May will state that they cannot be used for \u201cactivity intended to influence or attempt to influence Parliament, government or political parties ... or attempting to influence legislative or regulatory action\u201d. In theory, this could mean that scientists at UK universities are not allowed to tell ministers what the policy implications of their work are, or respond to consultations that touch on their area of interest \u2014 potentially removing their ability to comment on everything from climate change to medical regulation. \n             Accidental crackdown? \n           \u201cIt\u2019s clear this has simply come about by accident,\u201d says Bob Ward, policy and communications director at the Grantham Research Institute on Climate Change and the Environment in London. The rule does not seem to be designed to target academics, he says. Rather, scientists have been caught in a move to stop charities and other groups from using public grants to lobby for more money, which one minister has called \u201cthe farce of government lobbying government\". But unless an exception is given to researchers, Ward adds, they will face having to use their own funds to do anything that could be considered lobbying or influencing policy. \u201cIf you take it to the letter of the law, it means you couldn\u2019t respond to government consultations or inquiries,\u201d says Ward. Removing academics from debates over policy would leave such discussions dominated by privately funded lobby groups. \u201cWhat about government-funded scientists who advocated a change to the law to allow for research on human-animal hybrid embryos or to legalize mitochondrial DNA transfer? What about new research that finds compelling evidence in one direction or another on the  badger cull  or the European Union ban on  bees and pesticides ?\u201d says Fiona Fox, chief executive of the London-based  Science Media Centre  (which receives some funding from government and some from  Nature 's publisher). \u201cIt\u2019s important that we don\u2019t exaggerate the impact of this ruling or ascribe intent, but I am wary of complacency, too,\u201d Fox adds. \u201cThis can only have a further chilling effect on scientists already fearful of speaking out about where the weight of evidence lies on contentious issues.\u201d \n             Gaps in guidance \n           Organizations that award funding on behalf of the government will have to include the clause in the terms and conditions of their grants, according to  guidance  on how to implement the change. For scientists, those could be the UK\u2019s seven research-funding bodies, which together give out around \u00a33 billion (US$4.2 billion) each year to researchers. A spokesman for Research Councils UK \u2014 the umbrella group for the seven bodies \u2014 told  Nature : \u201cWe are currently working with BIS colleagues to seek clarification on this issue as a matter of urgency. We hope to be able to share guidance with our grant holders soon.\u201d Another UK funding body \u2014 the Higher Education Funding Council for England (HEFCE), which doles out nearly \u00a34 billion per year to universities \u2014 also told  Nature  that it was in discussion with the BIS. Government ministers could remove the clause from some grants, in cases of \u201cexceptional circumstances where applying the clause at all would have unintended consequences that would not benefit the taxpayer\u201d, according to the published guidance. It is also possible to add a \u201cqualification\u201d that would modify the clause. The guidance suggests that a qualification could apply when a grant is being used to fund \u201cresearch that could result in recommendations that challenge existing government policy\u201d. But it adds that \u201cthis grant recipient would not be permitted to use this same grant funding to run any activities that involve lobbying government\u201d. The BIS, which is responsible for the research councils and HEFCE, could not confirm to  Nature  whether or not an exception would be granted for science funding. \u201cThe government is taking steps through this clause to ensure taxpayer funds are not misused. Guidance published by the Cabinet Office outlines how departments are able to make qualifications to the clause, and we are working with stakeholders to determine how this might apply to the research base,\u201d a spokesperson said. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Communication breakdown 2015-Apr-01 \n                 \n                   Science & politics: Speaking out about science 2010-Oct-13 \n                 \n                   Canada must free scientists to talk to journalists 2010-Sep-29 \n                 \n                   UK government announcement: new clause to be inserted into grant agreements \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19455", "url": "https://www.nature.com/articles/nature.2016.19455", "year": 2016, "authors": [{"name": "Devin Powell"}], "parsed_as_year": "2006_or_before", "body": "Reversal could change timeline of heat and carbon storage in the seas. In the deep abysses of the ocean, small swirls of water can wield great power. Like the proverbial butterfly flap that stirs up a hurricane, this chaotic turbulence has long been thought to lift up water in the ocean\u2019s interior to  drive currents that stretch across the globe . Now, some researchers are rethinking the role of this turbulence \u2014 turning it upside down. Using computer simulations fed with measurements from the field, they argue that small-scale turbulence drives circulation by pushing water in the ocean\u2019s interior down, not up. \u201cWe\u2019ve shown that it\u2019s the other way around,\u201d says MIT oceanographer Raffaele Ferrari, who presented this new portrait of the abyss this week at the ocean-sciences meeting of the American Geophysical Union in New Orleans. Ferrari hopes that the work will improve our understanding of how the deep oceans  regulate climate . \u201cIt has big implications for how long carbon and heat absorbed from the atmosphere  sit at the bottom of the ocean ,\u201d he says. Water thought to take a millennium to circulate \u2014 sinking at the chilly poles and rising elsewhere to warm \u2014 instead could be doing so in centuries. Understanding that process is important for getting climate models right. \u201cClimate models currently take a simplistic view which does not represent the role of ocean turbulence in deep circulation accurately,\u201d says MIT oceanographer Ali Mashayek, who collaborated with Ferrari on the project. \n             The missing mixing \n           The idea that mere turbulence can power the ocean owes much to oceanographer Walter Munk. Currents flowing through the deep ocean often start with cold, dense water sinking at high latitudes. But that water has to rise and warm to stimulate circulation. What caused this upwelling was a mystery. In 1966, Munk suggested that turbulence drove this process, and calculated how much of it the oceans would need to power their great conveyor belts of water 1 . Over the years, his calculation went from controversial heresy to established wisdom. At first, expedition after expedition probing the upper reaches of the seas failed to find the intense mixing that he predicted, which was thought to be more-or-less uniform at different depths. \u201cThe community called this the \u2018missing mixing\u2019 problem,\u201d says turbulence researcher William Smyth of Oregon State University in Corvallis. It would be decades before technologies capable of pushing deeper began to find that mixing. \u201cEven when turbulence is strong, it\u2019s extremely difficult to measure,\u201d says Matthew Alford, an oceanographer at the Scripps Institution of Oceanography in La Jolla, California. \u201cIt\u2019s one of the hardest things to measure in the oceans.\u201d Patches of violently churning water ultimately started turning up close to the sea floor, usually near underwater mountains and other rough terrain. Investigations have since uncovered evidence that underwater waves create the abyssal chaos 2 . These waves form between layers of deep water with different densities, just as surface waves form between the surface water and air. Waves inside the ocean crash violently when they break; Alford measured some particularly spectacular examples, slow-moving waves the size of skyscrapers, while probing a 5,500-metre-deep passage near Samoa 3 . \n             Rolling in the deep \n           This rolling in the deep inverts the effect of turbulence, the MIT group argues. It causes upper, less-dense layers of water to mix into lower, denser layers \u2014 pulling massive flows down in the middle of oceans. Abyssal water does not rise everywhere in the ocean, as Munk had envisioned. Instead, it creeps across the bottom, coming up only at the edges of the oceans, at continental margins. This proposal doesn\u2019t entirely surprise Jim Ledwell, an oceanographer at the Woods Hole Oceanographic Institution in Massachusetts. In the 1990s, Ledwell was part of an expedition to the Mid-Atlantic Ridge,\u00a0the longest mountain chain on Earth. Instruments that measure turbulence as well as tracer chemicals released into the water showed flows there descending into an area called the Brazil basin and rising at its edges 4 . The MIT modelling incorporated data from that expedition, as well as from more-recent observations of a similar thing happening in the Drake Passage, between Cape Horn in Chile and the South Shetland Islands in Antarctica. \u201cThey have taken the idea from the Brazil basin and extended it to the whole ocean,\u201d says Ledwell. \u201cWhen their paper on this comes out, it\u2019s going to stimulate a lot of thinking.\u201d When asked what he thinks of the challenge to his idea, Munk, now 98 years old, replies: \u201cI don\u2019t know if I\u2019m wrong yet.\u201d \u201cBut I\u2019m not bothered if I\u2019m wrong,\u201d he says. \u201cI think the important thing is that I got people working on an important problem that had previously been ignored.\u201d  \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Indian Ocean may be key to global warming 'hiatus' 2015-May-18 \n                 \n                   Atlantic current strength declines 2014-May-13 \n                 \n                   Oceans under surveillance 2013-May-07 \n                 \n                   An oceanic 'fast-lane' for climate change 2010-Apr-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19367", "url": "https://www.nature.com/articles/nature.2016.19367", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Virus study used data released online without adequate acknowledgement, researcher complains. When researchers in Brazil posted four Zika virus genome sequences in the  online repository GenBank  on\u00a026 January, they were complying with a call for scientists to openly release their data during public-health emergencies. By 10 February, the information had been used by Slovenian researchers for their own Zika paper in the  New England Journal of Medicine (NEJM) 1  \u2014 apparently, a textbook example of the power of rapid, open data-sharing. But the process didn\u2019t go entirely smoothly. Oliver Pybus, an evolutionary and infectious-disease biologist at the University of Oxford, UK, who works with the Brazilian group, has complained that the  NEJM  paper did not adequately credit the original data-providers when it only included the GenBank accession number for the data. And Pybus says that he is concerned that this lack of formal recognition could dissuade others from rapidly sharing data during an outbreak. \u201cThe very first big Zika virus paper in the  New England Journal of Medicine  has just created exactly the opposite incentive for groups in Brazil that we want to create. We want them to feel confident they can put their data immediately online without any possible disadvantage to them,\u201d Pybus says. The authors of the  NEJM  paper waited to release their own data until their paper was published, he notes. Tatjana Av\u0161i\u010d \u017dupanc, a microbiologist at\u00a0the University of Ljubljana and senior author of the  NEJM  paper, says that her team meant no slight by not contacting Pybus and his colleagues. \u201cIf you deposit something in an open domain like GenBank before you publish it, you would expect that people will just use it,\u201d she says. And Pybus says that he received an apology from the authors on 11 February, after he contacted them with his concerns. (A representative for the  NEJM  told  Nature  that the scientists should resolve the dispute among themselves.) But the credit dispute suggests that scientists haven\u2019t yet adjusted to the etiquette needed for acknowledging others\u2019 public, but not yet formally published, data, researchers say. \n             Microcephaly link \n           \u017dupanc\u2019s team reported a case study of a Slovenian woman who had been living in Brazil and terminated her pregnancy after an ultrasound scan at 29 weeks' gestation revealed that the fetus had microcephaly \u2014 an abnormally small head. Zika virus genetic material was discovered in fetal brain tissue and the researchers generated a complete genome sequence. The team compared their sequence to other Zika sequences in public databases, including the four generated by Pybus's colleague Mario Nunes at the Evandro Chagas Institute in Ananindeua, Brazil, and his team. (In fact, Pybus says, this analysis was not needed to link Zika virus to the case of microcephaly; Av\u0161i\u010d\u00a0\u017dupanc says that the analysis was added during the review process at the recommendation of  NEJM  editors). Pybus and Nunes\u2019 team had earlier, on 1 February, posted an online analysis of the data\u00a0at the website\u00a0 virological.org , in which they tracked the importation of Zika to the Americas and its subsequent spread. Pybus thinks that data generated during the Zika virus outbreak is likely to come from a large number of researchers and institutions, which underscores the importance of rapid data sharing. \u201cI hope it won\u2019t discourage people from sharing data pre-publication. It might make researchers more aware that sharing data needs to be a reciprocal exercise,\u201d says Andrew Rambaut, an evolutionary geneticist at the University of Edinburgh, UK. \u201cOn the other hand, there is no point in advocating the rapid release of data if you then don\u2019t allow people to analyse it. The more eyes that look at it, the more likely that an important finding will be made.\u201d \n             Difficult situation \n           Kristian Andersen, an infectious-disease genomicist at the Scripps Research Institute in La Jolla, California, says that the incident highlights \u201ca failure in the system\u201d of using public data that has not yet made it into a publication. \u201cIt\u2019s a difficult situation, and our field needs to figure out a way to give better credit to the data producers so data can be shared freely and without limitations,\u201d he says.  Andersen and his colleagues made Ebola virus genome data public during the epidemic in West Africa, and included a note asking scientists who wish to use the data for publication to contact them first. Most scientists who used their data got in touch with them as a result. Av\u0161i\u010d \u017dupanc says that there should be clearer standards on how to use another team's unpublished but public data, especially for researchers in fields with different expectations over data sharing. The incident comes immediately after dozens of funders, government agencies and journals \u2014 including the  NEJM  \u2014  released a statement on 10 February  supporting open\u00a0data sharing during public-health emergencies such as the Zika and Ebola epidemics. Journals that signed the statement agreed to make Zika content freely available, and affirmed that early release of data or analysis online will not jeopardize researchers' chances of publication in those journals later on. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19361", "url": "https://www.nature.com/articles/nature.2016.19361", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}, {"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "LIGO 'hears' space-time ripples produced by black-hole collision. One hundred years after Albert Einstein predicted the existence of gravitational waves, scientists have finally spotted these elusive ripples in space-time. In a highly anticipated announcement, physicists with the Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) revealed on\u00a011 February\u00a0that their twin detectors have heard the gravitational 'ringing' produced by the collision of two black holes about 400 megaparsecs (1.3 billion light-years) from Earth 1 , 2 . \u201c Ladies and gentlemen, we have detected gravitational waves,\u201d David Reitze, the executive director of the LIGO Laboratory,  said at a Washington DC press conference . \u201cWe did it!\u201d One black hole was about 36 times the mass of the Sun, and the other was about 29 solar masses. As they spiralled inexorably into one another, they merged into a single, more-massive gravitational sink in space-time that weighed 62 solar masses, the LIGO team estimates. \u201c These amazing observations are the confirmation of a lot of theoretical work, including Einstein's  general theory of relativity , which predicts gravitational waves,\u201d says physicist Stephen Hawking of the University of Cambridge, UK. Hawking noted that Einstein himself never believed in black holes. This is the first black-hole merger that scientists have observed. The violent event temporarily radiated more energy \u2014 in the form of gravitational waves \u2014 than all the stars in the observable Universe emitted as light in the same amount of time. When played as an audible sound, the waves make an unmistakeable  \u2018chirp\u2019  \u2014 a rapidly rising tone \u2014 followed by a \u2018ringdown\u2019, the radiation pattern from the merged black hole. The 'loudness' of the recorded signal also provides a rough measure of when the merger occurred: between 600 million and 1.8 billion years ago. The work will be published in a series of papers in  Physical Review Letters 1  and the\u00a0 Astrophysical Journal. The historic discovery \u2014 which physicists say will probably lead shortly to a Nobel prize \u2014 opens up  the new field of gravitational-wave astronomy , in which scientists will listen to the waves to learn more about the objects that can produce them, including black holes, neutron stars and supernovae. \u201cThis is just the first step in a much larger and more exciting development,\u201d says Ilya Mandel, a theoretical physicist at the University of Birmingham, UK. Gravitational waves will join \u03b3-rays, X-rays and radio waves as \"part of the toolkit that we have for understanding the universe\", he says. It is also a long-sought victory for the LIGO experiment, which had  spent a decade searching for the signal  in the 2000s before a US$200-million upgrade  improved the sensitivity of its twin detectors , one in Livingston, Louisiana, and the other in Hanford, Washington. \n             Wave of discovery \n           The discovery itself was made before the upgraded version, Advanced LIGO, had officially begun to take scientific data. At 11:50 a.m. Central European Time on 14 September, during the experiment's first observing run, LIGO physicist Marco Drago at the Max Planck Institute for Gravitational Physics in Hannover, Germany, saw a strange signal on his computer.\u00a0 Software that analyses data in real time was indicating that both interferometers had seen a wave resembling the chirp of a bird with a rapidly increasing pitch. Within an hour, the news had reached Drago's boss, physicist Bruce Allen. The recording looked too good to be true. \u201cWhen I first saw it I said, 'Oh, it's an injection, obviously,'\u201d Allen says. It was an oscillation that began at 35 cycles per second (hertz) and rapidly increased to 250 hertz. It then became chaotic and rapidly died down; the whole thing was over within one-fourth of a second. Crucially, both detectors saw it at roughly the same time \u2014 Livingston first and Hanford 7 milliseconds later. That delay is an indication of how the waves swept through the Earth. Other gravitational-wave detectors \u2014 the Virgo interferometer near Pisa, Italy, and the GEO600 interferometer near Hannover \u2014 were not operating at the time and so could not confirm the signal. Had Advanced Virgo been on, it would have probably detected the event as well, says its spokesperson, Fulvio Ricci, a physicist at the University of Rome La Sapienza. LIGO scientists have run a series of careful checks to ensure that the signal is real and means what they think it does. In the past, a few senior members of the LIGO team have tested the group's ability to validate a potential discovery by secretly inserting \u2018blind injections\u2019 of fake gravitational waves into the data stream to test whether the research team can differentiate between real and fake signals. But the September detection happened before blind injections were being made, so it is thought to be a signal from a real astrophysical phenomenon in the Universe. To pinpoint the source of gravitational waves, researchers have to triangulate a signal spotted by different machines spread around Earth. When both LIGO detectors are operating along with Virgo or GEO600, scientists expect to be better able to locate future gravitational-wave sources. Another interferometer in Japan is under development, and a third LIGO site in India has been proposed. A greater geographic spread of detectors would strengthen confidence in any signals. \n             Direct detection \n           Einstein\u2019s general theory of relativity predicts that any cosmic event that disturbs the fabric of space-time with sufficient force should produce gravitational ripples that propagate through the Universe. Earth should be awash with such waves \u2014 but by the time they reach us, the disturbances that they produce are minute. In 1974, physicists Joseph Taylor and Russell Hulse at the University of Massachusetts Amherst indirectly confirmed the existence of gravitational waves by watching radio flashes emitted by a pair of neutron stars whirling around one another; the shifts in the flashes\u2019 timing matched Einstein\u2019s predictions of how gravitational waves would carry energy away from the event. That discovery won them the 1993 Nobel Prize in Physics (see: \u2018 The hundred-year quest for gravitational waves \u2014 in pictures \u2019). But direct detection of the waves had to await the sensitivity achieved by Advanced LIGO, which can detect stretches and compressions of space-time that are as small as one part in 10 22 \u00a0\u2014 comparable to a hair\u2019s-width change in the distance from the Sun to Alpha Centauri, the nearest star to the Solar System. LIGO\u2019s twin interferometers bounce laser beams between mirrors at the opposite ends of 4-kilometre-long vacuum pipes that are set perpendicularly to each other. A gravitational wave passing through will alter the length of one of the arms, causing the laser beams to shift slightly out of sync. Paid for by the US National Science Foundation, the machines were designed and built by teams at the California Institute of Technology (Caltech) in Pasadena and the Massachusetts Institute of Technology (MIT) in Cambridge. Caltech\u2019s Kip Thorne and Ronald Drever, along with MIT\u2019s Rainer Weiss, were the original founders. More than 1,000 scientists now belong to the LIGO collaboration. By studying gravitational waves, this next generation of researchers expects to probe entirely new realms of physics, including strong-field gravity, the very early Universe and how matter behaves at extremely high densities. Hawking says that he would like to use gravitational waves to test his area theorem: that \u201cthe area of the final black hole is greater than the sum of the areas of the internal black holes.\u201d He adds: \u201cThis is satisfied by the observations.\u201d \u201cIt\u2019s the very real dawn of a new era,\u201d says Mansi Kasliwal, an astronomer at Caltech. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19368", "url": "https://www.nature.com/articles/nature.2016.19368", "year": 2016, "authors": [{"name": "Chris Maddaloni"}, {"name": "Lauren Morello"}], "parsed_as_year": "2006_or_before", "body": "Scenes from the historic announcement in Washington DC. The rumours were true. After more than a decade of searching and months of speculation, researchers with the Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) revealed that they had discovered evidence of gravitational waves. The signal they observed came from the collision of two black holes about 400 megaparsecs (1.3 billion light years) from Earth. \u201cThis was a scientific moonshot \u2014 and we did it, we landed on the Moon,\u201d said physicist David Reitze, executive director of the LIGO Laboratory. Nature  was at the Washington DC press conference where the LIGO team  announced its big find . \n             Packed house \n           Hundreds of people gathered at the National Press Club to learn whether LIGO really had found gravitational waves. Anticipation was high thanks to the  tantalizing rumours that had been swirling  over the past few months. \n             A founding father \n           Physicist Kip Thorne (pictured above)  helped to found LIGO , together with Ronald Drever from the California Institute of Technology in Pasadena and Rainer Weiss of the Massachusetts Institute of Technology in Cambridge. \u201cEinstein comes out being a success,\u201d he said of LIGO's discovery of ripples in space-time, which help to\u00a0confirm\u00a0 Einstein's general theory of relativity . \n             A long wait \n           \u201c It's the beginning of a new era,\u201d says LIGO spokesperson Gabriela Gonz\u00e1lez (pictured above), a physicist at Louisiana State University in Baton Rouge. More than 1,000 scientists are part of the LIGO team, which operates facilities  in Hanford, Washington, and Livingston, Louisiana . \n             Chirp, chirp \n           Just before noon on 14 September 2015, LIGO scientists at the Max Planck Institute for Gravitational Physics in Hannover, Germany, noticed a strange signal:  a wave that resembled the chirp of a bird  with a rapidly increasing pitch. The diagram above contrasts the signal detected by LIGO's facilities in Washington and Louisiana with scientists' predictions of how such a signal would appear. \n             Precision instrument \n           Weiss demonstrates how the mirrors within each LIGO facility's tunnels are suspended to dampen vibrations that could interfere with the detection of gravitational waves. (For more on how LIGO works, see ' Hunt for gravitational waves to resume after massive upgrade '.) \n             Rippling through the Universe \n           Here, Weiss uses a prop to demonstrate  how gravitational waves stretch and compress  the fabric of space-time. \n             Jubilation \n           Gonz\u00e1lez and other LIGO scientists celebrated their discovery with press conferences at multiple sites around the world. But their work is only beginning. Efforts are under way at the two LIGO facilities to improve the detectors' performance before observations restart, probably sometime this summer. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19335", "url": "https://www.nature.com/articles/nature.2016.19335", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Environmental factors lie behind many irreproducible rodent experiments. It\u2019s no secret that therapies that look promising in mice  rarely work in people . But too often, experimental treatments that succeed in one mouse population  do not even work in other mice , suggesting that many rodent studies may be flawed from the start. \u201cWe say mice are simpler, but I think the problem is deeper than that,\u201d says Caroline Zeiss, a veterinary neuropathologist at Yale University in New Haven, Connecticut. Researchers  rarely report on subtle environmental factors  such as their mice\u2019s food, bedding or exposure to light; as a result, conditions vary widely across labs despite an enormous body of research showing that these factors can significantly affect the animals\u2019 biology. \u201cIt\u2019s sort of surprising how many people are surprised by the extent of the variation\u201d between mice that receive different care, says Cory Brayton, a pathologist at Johns Hopkins University in Baltimore, Maryland. At a meeting on mouse models at the Wellcome Genome Campus in Hinxton, UK, on 9\u201311 February, she and others explored the many biological factors that prevent mouse studies from being reproduced. \n               Confounding factors \n             Christopher Colwell, a neuroscientist at the University of California, Los Angeles, has first-hand experience with these issues. He and a colleague studied autism in the same genetically modified mouse line, but obtained different results on the same behaviour tests. Eventually they worked out why: Colwell, who studies circadian rhythms, keeps his mice dark in the daytime to trick their body clocks into thinking day is night, so that the nocturnal animals are more alert when tested during the day. His colleague does not. Colwell notes that disregarding mouse circadian rhythms could bias many behaviour experiments. Most humans would not perform well on social and cognitive tests either if made to do them in the middle of the night, he adds. \n               You are what you eat \n             Nutrition can also determine whether a mouse study succeeds or fails, yet Brayton says that many researchers cannot even say where their animals\u2019 feed comes from. Some mouse foods contain oestrogens and endocrine-disrupting chemicals that can affect research on cancer, among other diseases 1 . And the high-fat, high-sugar food used in obesity studies goes rancid quickly; when it does, mice may stop eating and lose weight without researchers realizing why. Food choices can also alter a mouse\u2019s gut microbiome. Catherine Hagan Gillespie, a veterinary pathologist at the Jackson Laboratory in Sacramento, California, has found that species of bacteria in the gut vary widely between mice from different vendors 2 . In another, unpublished, study, she found that mice with different assortments of gut bacteria showed different anxiety levels in behavioural tests. But few behavioural scientists think about running microbiology assessments, says Hagan Gillespie. Even when they do, the extra work involved can increase the complexity and cost of the study. Yet the mouse microbiome is sensitive to a wide array of factors, such as air quality, maternal stress and immune function. Differences in the gut microbiome may explain why mice with the same genetic mutation can have different characteristics, or phenotypes, says George Weinstock, associate director for microbial genomics at the Jackson Lab\u2019s site in Farmington, Connecticut. Jackson Lab, which breeds and supplies mice for use in studies around the world, tightly controls factors such as the type and quantity of food and the pH of water that animals receive. Even so, it finds differences between the mice at its three sites. Weinstock says that the company has begun researching ways to standardize its customers' experiments by providing special food and care instructions for the mice that it provides. But even when improved mice and food are available, some researchers resist using them out of concern that it will affect their results, says Graham Tobin, former technical director of the mouse-diet vendor Teklad in Alconbury, UK. Yet he argues that standardizing results across labs is worth this inconvenience to individual scientists. Tobin also notes that researchers rarely resist adopting other new technologies \u2014 such as improved DNA sequencers \u2014 that can throw older data into question. \n               Time pressure \n             Zeiss says that the competitive nature of science might increase researchers\u2019 resistance to changing how they consider animals in research design. If scientists have to treat their animals at the right point in the experiment, analyse both clinical and biomarker changes, include old mice and both sexes to ensure that results are representative of broad populations, and control environmental variables, each experiment will take much longer and they\u2019re probably not going to be able to publish as much, she says. The US National Institutes of Health (NIH) has taken steps to address some of these problems. Some of its institutes require certain animal trials to be replicated before a therapy can move into clinical trials, but the NIH says that it has no plans to require this agency-wide. And in 2014, the NIH began requiring researchers to include female animals in studies, and started to give out supplementary grants to researchers who complained about the cost. But the agency has not issued any specific grants or supplements to study other confounding factors. That is disappointing to those who would like to see researchers control \u2014 or at least report \u2014 factors such as the strain of mice used and the type of environment they are raised in. This would allow researchers to perform metanalyses of published literature that could identify any confounding factors. \u201cThe information and the wisdom is out there,\u201d says Zeiss, \u201cbut studies get funded without necessarily a lot of attention to that.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Male researchers stress out rodents 2014-Apr-28 \n                   \n                     Misleading mouse studies waste medical resources 2014-Mar-26 \n                   \n                     Curious mice need room to run 2004-Feb-11 \n                   \n                     Nature  special: Challenges in irreproducible research \n                   \n                     Mouse Models of Disease: Improving Reproducibility of Pathology Endpoints in Challenge Models \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19366", "url": "https://www.nature.com/articles/nature.2016.19366", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Nature Video  explains how scientists are searching for ripples in space-time. Almost exactly a century after Einstein first predicted the existence of  gravitational waves , physicists at the  recently upgraded Laser Interferometer Gravitational-Wave Observatory  are widely expected to announce that they have detected these cosmic ripples in spacetime. In this  Nature Video,  reporter  Davide Castelvecchi  explains what gravitational waves are, and how scientists are searching for them in an attempt to prove Einstein right. Follow the announcement live with  Nature 's reporters at our  \"LIGO live\"  page. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19370", "url": "https://www.nature.com/articles/nature.2016.19370", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Global map charts locations that use more water than is available in at least one month each year. In the western United States, disputes over the management of the Klamath River, which wends its way from southern Oregon to the Pacific Ocean through northern California, have made blood boil for generations. Cattle ranchers and potato farmers want to take the water out for irrigation; Native American tribes, environmentalists, hunters and anglers want to leave it in to support fish and waterfowl populations. Every summer, tempers flare as the rain dries up and water levels begin to fall. But until now, most global analyses would not have categorized the basin as experiencing \u201cwater scarcity\u201d \u2014 a condition defined by the withdrawal of more water than is sustainably available. That\u2019s because the analyses have been done on an annual basis, and it is only for three months of the year, in July, August and September, that water from the Klamath River is in short supply. Now, two water researchers have created maps that show global water scarcity on a monthly timescale 1 . They identify areas, including the Klamath Basin, where more water is withdrawn than the region can sustainably support for at least one month per year. More than four billion people, more than half the world\u2019s population, live in such areas, say Mesfin Mekonnen and Arjen Hoekstra at the University of Twente in the Netherlands. And slightly under four billion live in areas of \"severe water scarcity\", where twice as much water is withdrawn as is sustainably available for at least one month per year. That compares with between 1.7 and 3.1 billion people identified in global assessments that were accounted on annual bases. The analysis is published on 12 February in  Science Advances . \n             Water balance \n           For each location, Hoekstra and Mekonnen estimated the monthly withdrawal of water by combining data on crop types, population density and water evaporation, then compared the results to the amount of water available in rivers and lakes. The researchers assumed that 80% of the water would need to stay in the rivers and lakes to support ecosystems; if people dipped into this reserve, then Mekonnen and Hoekstra judged the location as \u201cwater scarce\u201d for that month. Along with well-known dry places such as Australia and the Middle East, the map identifies parts of Africa and Mexico, southern Europe, Turkey, Central Asia and northern China as places where periods of water scarcity may cause local hardship \u2014 but might also trigger problems that extend beyond the places and times where fresh water is in short supply. For example, many of Europe\u2019s imports of food and other goods rely on reliable water in China, Hoekstra notes. The map can be seen as a guide for international environmental and development institutions that work with water, says Jacob Schewe, a water researcher at Potsdam Institute for Climate Impact Research in Germany. Schewe has devised  maps of water scarcity that attempt to predict how climate change will affect the pattern  and says that northern China, for example, looks likely to get more arid as the century progresses 2 . At the local scale, Hoekstra and Mekonnen's analysis begins to define how much water a given place can safely withdraw each month, data that policymakers can use to set limits and prices. \n             Guide for policy \n           Dipping into water reserves has environmental consequences. \u201cYou can still get water from somewhere, but it might mean you get it from a really important ecosystem that dries out and dies while you are swimming in your swimming pool,\u201d explains Schewe. According to Matt Baun, Klamath Basin coordinator for the Fish and Wildlife Service in Yreka, California, overuse of the water from the Klamath River in recent years has led to the deaths of juvenile salmon and has reduced the amount of food and open water that is available for migratory birds at wildlife refuges, resulting in crowding-related outbreaks of avian cholera and botulism.\u00a0 Those who live in places that show up as water scarce on the map should think about how to adapt and change, Hoekstra says. In the Klamath Basin, this has meant negotiation between former enemies, who are all agreeing to take less water than they want. US film-maker Jason Atkinson has chronicled this process of rancour and compromise in the 2015 documentary  A River Between Us . \u201cIf you heal people, they would heal the river,\u201d he says. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19374", "url": "https://www.nature.com/articles/nature.2016.19374", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Swedish institute reopens misconduct investigation into Paolo Macchiarini. The vice-chancellor of the Karolinska Institute (KI) in Stockholm, Anders Hamsten, has resigned after acknowledging that he mishandled the prestigious Swedish institute\u2019s investigation into controversial surgeon Paolo Macchiarini. The institute will also reopen its misconduct inquiry into Macchiarini, it announced in a  press release  on 13 February, which accompanied an  open letter  by Hamsten in the Swedish daily newspaper  Dagens Nyheter . The KI had already decided  not to renew Macchiarini\u2019s contract  when it runs out in November. Last August, Hamsten  cleared Macchiarini  after  an external investigation found the surgeon had committed misconduct  in seven research papers. But in his letter, Hamsten wrote that he had \u201ccompletely misjudged\u201d Macchiarini, who has been accused of research misconduct and ethical breaches in his work implanting artificial windpipes into patients. \u201cI failed to see the warning signs,\u201d he wrote, adding that new information the KI had recently received meant that last year\u2019s investigation should now be reopened. \u201cThere is much to indicate that the judgement reached by KI last summer should be amended to scientific misconduct, which in plain language means research fraud.\u201d Asked for comment by  Nature , Macchiarini wrote that he could not respond to specific allegations at present, but that\u00a0he is \"trying to collect all the evidence that is required to demonstrate that all the allegations made against me \u2014 in a number of spheres \u2014 are false\". While the Macchiarini reinvestigation is going on, Hamsten and three other KI scientists have also decided to \u201crefrain from participating\u201d in any activities in the Nobel Assembly, a group of 50 Karolinska-based professors that decides who wins the Nobel Prize in Physiology or Medicine. Their decision was taken \u201cout of respect for the integrity of the Nobel Prize work\u201d, wrote the assembly's chairman, Rune Toftg\u00e5rd, who is a biologist at the KI. One of the four, geneticist Urban Lendahl, last week  resigned from his position as secretary-general  of the Nobel Assembly. \n             Public pressure \n           The announcements follow mounting pressure in Sweden for resignations at the KI over the way it has handled the case of Macchiarini, whom the institute hired as a visiting professor in 2010. In 2011, the surgeon reported in  The Lancet  his implantation of an artificial windpipe (trachea) into a patient at the Karolinska, using the patient\u2019s own stem cells \u2014 an operation hailed as a landmark in regenerative medicine. He followed up with implants of tracheas into seven more people. (Six of the eight later died, for reasons unrelated to the surgery, Macchiarini says.) In 2014, physicians at the KI argued that Macchiarini had misrepresented the success of his work in seven papers \u2014 six articles on his transplants in humans, and one reporting a proof-of-principle experiment implanting artificial oesophagi into rats. An independent report  found the surgeon guilty , but Hamsten  cleared  Macchiarini of misconduct. Last month, a television documentary aired by Sweden\u2019s national broadcaster SVT made  new accusations of ethical wrongdoings  by Macchiarini. It alleged that he had conducted operations in Krasnodar, Russia, on at least one patient who was not life-threateningly ill \u2014 contrary to the surgeon\u2019s previous statements \u2014 and that he had misrepresented the success of his prosthetic grafts in scientific publications. That documentary drew fresh attention to the controversy and ultimately led the KI to  dismiss the surgeon  on 4 February, saying it had \u201clost confidence\u201d in him. But Swedish scientists wondered why Hamsten had not paid more heed to the earlier independent investigation. \u201cEven before the\u00a0horrifying\u00a0TV\u00a0broadcasts on this matter, many of us were stunned by the fact that the institute dismissed the well-argued conclusions put forward by their own external reviewer,\u201d Elias Eriksson, a neuroscientist at the University of Gothenburg, Sweden, told  Nature . In his letter in  Dagens Nyheter , Hamsten said that the KI did not have complete information when it first investigated the surgeon. He and the KI said \u2014 without providing further details \u2014 that in the past few days they had received new information about what happened to Macchiarini's first patient after his surgery, based in part on images shown in the Swedish documentary. In its press release accompanying Hamsten\u2019s letter, the KI says that an additional two papers concerning research on rats will be investigated, based on a new report of scientific misconduct. The articles contain images that are very similar and lead to suspicions \"that data published in those publications are incorrect\u201d, says Jan Carlstedt-Duke, an endocrinologist at the KI who also acts as an adviser to its vice-chancellor. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Nobel official resigns over Karolinska surgeon controversy 2016-Feb-08 \n                 \n                   Artificial-windpipe pioneer under scrutiny again 2016-Feb-01 \n                 \n                   Artificial-windpipe pioneer cleared of misconduct 2015-Aug-28 \n                 Reprints and Permissions"},
{"file_id": "women-under-represented-in-world-s-science-academies-1.19465", "url": "https://www.nature.com/news/women-under-represented-in-world-s-science-academies-1.19465", "year": 2016, "authors": [], "parsed_as_year": "2011_2015", "body": "TREND WATCH  The first global survey of women\u2019s representation at the highest level of academia shows that less than one-eighth of the members of science academies around the world are women. Women made up just 12% of members among 69 academies that were surveyed in 2013\u201314, the Academy of Science of South Africa (ASSAf) and the InterAcademy Partnership (IAP)  reported on 29 February . The Cuban Academy of Sciences had the highest proportion of women, at 27%, while the Tanzania Academy of Sciences and the Polish Academy of Sciences had the lowest levels, at 4%. Women\u2019s under-representation in academies matters because the organizations act as sources of both role models and science-policy advice, says Dorothy Ngila, who coordinated the study at ASSAf. \u201cThey should make sure their panels and reports are reflective of the diversity of our world,\u201d she says. \u201cYou cannot provide advice to government using only half the team.\u201d The survey of members of the IAP, a global network of science academies, is the most comprehensive of its kind. Yet\u00a0 not all academies collect data on women's participation, says Ngila. \"One of the glaring results is that academies are not consciously collecting this data,\" she says. In order to act on women's low representation within academies, the organisations must first report and analyse the relevant figures, she says. Nonetheless, the existing data provides some important insight, says Ngila. Academies in Central and South America, for example, boasted the largest proportion of women, accounting for 6 of the top 10 national academies by share of women members. These high numbers could, in part, be attributed to the fact that each of these academies has a member who is dedicated to gender issues, as part of the Women for Science programme of their parent body, the InterAmerican Network of Academies of Science. \u201cThere is an expectation that each academy reports on its trajectory, and this puts pressure on each to do more,\u201d says Ngila. An academy will only make progress if, like the Royal Society, it has a clear and stated intent to encourage more women nominations into the potential pool of candidates, says Athene Donald, a physicist at the University of Cambridge, UK, with an interest in gender diversity. Without such measures, \"numbers won't go up fast\", she says. Being a member of a national academy would be expected to confer prestige, so if women are systematically less likely to be elected, they are also less likely to be asked to take on other important roles in policy and education, says Donald. \u201cSo the consequences reach far beyond the individual academies,\u201d she adds. Because figures in the survey refer to the makeup of an academy\u2019s overall membership rather than its latest intake, the data might not reflect recent efforts to boost women\u2019s representation, admits Ngila. In the United Kingdom, for example, only 6% of the Royal Society's members are women \u2014 but 20% of the 2015 intake were female. Overall, the report found that only 40% of the academies surveyed had policies or strategies in place that explicitly mention the need for increased participation of women in the academy\u2019s activities \u2014 a figure that Donald calls \u201cdisappointingly low\u201d. Only one-third, meanwhile, had a committee that addressed gender or diversity issues, although this was a recommendation of a 2006 report by the InterAcademy Council, a consortium of national science academies that advises international bodies such as the United Nations. The problem of under-representation also lies earlier in the system, says Donald, given that female representation becomes scarcer at each successive stage of academic seniority. The report\u2019s authors compared women\u2019s representation in academies with the proportion of female researchers in each country, and found only a weak positive correlation. Inconsistencies in how the data were collected worldwide mean that it was not possible to compare the figures against the proportion of women professors in each country, says Ngila. This information could give a better idea of how many suitably qualified female candidates exist in each country. When  Nature  compiled these figures for European countries for which the data were available, however, there was little correlation between the percentage of women in a country\u2019s professoriate and in its academy (results not shown). Only one academy surveyed \u2014 the Science Council of Japan \u2014 had a higher proportion of women among its members than in the overall pool of researchers within the country. By appointing more women members, academies can increase the visibility of women scientists and play a positive role in increasing their recruitment to science, says Curt Rice, the rector of the Oslo and Akershus University College of Applied Sciences, who is head of Norway's Committee on Gender Balance and Diversity in Research. Academies should not only do better in terms of reflecting women\u2019s representation in science, but also paint a picture of how it should be, he adds. \u201dI would like to see them taking responsibility for being catalysts for change rather than agents of conservatism.\u201d"},
{"file_id": "nature.2016.19364", "url": "https://www.nature.com/articles/nature.2016.19364", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Veteran cells to be retired in favour of fresh tumour samples grown in mice. After more than 25 years of heavy use by researchers around the world, the US National Cancer Institute (NCI) has decided to retire the NCI-60, its panel of 60 human cancer cell lines grown in culture, from its drug-screening programme. In late spring of this year, the institute will launch a rejuvenated repository of cancer models that are derived from fresh patient samples and tagged with details about their clinical past. The NCI action responds to a widespread push for cancer models with a closer link to the patients they are intended to help. On 11 February, cancer researchers gathered in New Orleans, Louisiana, for a meeting hosted by the American Association for Cancer Research that focused on the creation of new cancer models from clinical samples. Since 1990, industry and academic have screened more than 100,000 compounds using the NCI-60, in order to study the molecular details of cancers and find drugs to treat them.  When the NCI-60 was established, researchers had a very different conception of cancer, says James Doroshow, director of the Division of Cancer Treatment and Diagnosis at the NCI in Bethesda, Maryland. \u201cThirty years ago, the idea was that if you found a drug that worked on six breast cancer cell lines, then you could use it to treat breast cancer,\u201d he says. \u201cWell, it doesn\u2019t work that way.\u201d Since then, breast cancer has been broken into subcategories that are  based on genetic mutations  \u2014 and each category  may respond differently to treatment . \n               Mix and match \n             Many pathologists would be hard pressed to guess what kind of tissue the cells in an NCI-60 cell line came from, says Antonio Jimeno, a cancer researcher at the University of Colorado School of Medicine in Aurora. Like most other cancer cell lines, the NCI-60 have lived for thousands of generations in culture, an environment that differs radically from their native one. Over time, the cells have adapted to life in plastic petri dishes,  altering their genetic make-up and behaviour . The NCI will continue to supply the NCI-60 cell lines to researchers, but will eventually refocus its drug screening on newer models. It is developing hundreds of \u2018patient-derived xenografts\u2019 (PDXs), which are created by implanting small chunks of human tumours into mice. There, the tumours grow in an environment that, although not human, better mimics their native environment. The tumours can be harvested and reimplanted in other mice, allowing researchers to study a given tumour in multiple animals. The NCI will distribute cells from those PDXs, as well as data regarding each tumour\u2019s genetic make-up and gene expression patterns, and the donor\u2019s treatment history. In addition, the institute will make cell lines from the samples for use in more detailed biochemical studies and drug screening. For some cell lines, the repository will also contain cultures of associated, non-cancerous cells called fibroblasts, to allow researchers to learn more about how these cells can influence a tumour\u2019s response to treatment. The institute is also developing cell cultures and xenografts from tumour cells circulating in the blood, an approach that will allow researchers to model tumours in locations that are difficult for surgeons to biopsy. Doroshow estimates that his team is about a third of the way to its initial goal of producing 1,000 models, but will probably only have about 75 models ready for distribution when the repository opens. The NCI effort reflects a wider trend: several institutions have begun to develop repositories of PDX models. Sixteen European institutions have banded together to form EurOPDX, a consortium that boasts 1,500 PDXs. The Jackson Laboratory, a non-profit company in Bar Harbor, Maine, has 450 PDXs, and another 100 in development. Many more reside in pharmaceutical companies: last year, the Swiss pharma giant Novartis published a drug screen using 1,000 PDXs 1 . \n               Treatment guides \n             PDXs have also garnered media attention as possible models to guide treatment of individual patients: mice bearing PDXs could serve as \u2018avatars\u2019 to allow physicians to screen for the most-effective treatment regimen. But the process of generating a PDX is often too slow to benefit the donor, says Edison Liu, chief executive of the Jackson Laboratory. Instead, Liu sees Novartis\u2019s approach \u2014 studying large collections of PDXs for ways to help future patients \u2014 as more promising. Such models promise to capture the genetic complexity of human cancers better than can old cell cultures or genetically engineered mice, but PDXs also have shortcomings. Most are generated in mice that lack normal immune responses, to prevent the human cells from being rejected. The recent success of  cancer therapies that harness the immune system  to fight tumours has researchers clamouring for models that can better incorporate immune responses, says Liu. Efforts are under way to engineer mice with aspects of the human immune system, but no mouse has been made that fully reflects that complexity. Despite their limitations, some researchers say they have already translated PDX results into clinical gains. Livio Trusolino, a cancer researcher at the University of Turin in Italy, and his colleagues mined their collection of 600 colorectal cancer PDXs. At the meeting in New Orleans, Trusolino discussed data showing that PDXs from these tumours respond better to a combination of drugs already available for the treatment of breast cancer \u2014 a result that was then borne out in a small clinical trial. \u201dFor the first time in my life, my results have been translated into a benefit for patients,\u201d he says. \u201cIt is very rewarding.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Obama proposes cancer \u201cmoonshot\u201d in State of the Union address 2016-Jan-13 \n                   \n                     Cancer studies clash over mechanisms of malignancy 2015-Dec-16 \n                   \n                     Cancer screen yields drug clues 2012-Mar-28 \n                   \n                     Nature Special: Cancer genomics \n                   \n                     National Cancer Institute: NCI-60 \n                   \n                     EurOPDX \n                   Reprints and Permissions"},
{"file_id": "530265a", "url": "https://www.nature.com/articles/530265a", "year": 2016, "authors": [{"name": "Ewen Callaway"}, {"name": "Kendall Powell"}], "parsed_as_year": "2006_or_before", "body": "ASAPbio meeting discusses the ins and outs of posting work online before peer review. Physicists do it; computer scientists, mathematicians and economists do it. And this week, a who\u2019s who of biomedical researchers and publishers is asking what it will take to convince life scientists to do it, too\u00a0\u2014 release their work online before peer review and formal journal publication. The impetus for the gathering, called ASAPbio ( asapbio.org ), is the growing frustration of some researchers at the  slow pace of publishing in biology journals . The delay can take years, notes Ron Vale, a cell biologist at the University of California, San Francisco. That can seriously affect scientists\u2019 careers because they don\u2019t receive recognition for their work until it is published. The solution, argues Vale, a co-organizer of ASAPbio, is for biologists to embrace preprints: pre-publication manuscripts posted online. These speed up dissemination, give students and postdocs tangible ways to cite their contributions to the literature, and stimulate discussion and ideas, he says \u2014 accelerating and improving life-sciences research. There are signs that some biologists are ready to follow the lead of their colleagues in the physical sciences, where it is now routine for research to be submitted to the arXiv preprint server \u2014 founded 25\u00a0years ago \u2014 before publication. A life-sciences-only preprint server called  bioRxiv started in 2013  and is rapidly growing in popularity (see \u2018The growth of bioRxiv\u2019), especially in data-intensive fields such as computational biology and genomics. It has now seen more than 3,100 posted preprints, says John Inglis, the site\u2019s co-founder and the executive editor of Cold Spring Harbor Laboratory Press in New York. Other journals, such as the online  F1000Research , also  encourage the posting of life-sciences manuscripts before peer review . But preprints are still unfamiliar ground for biologists, Vale says. Leslie Vosshall, a neuro\u00adbiologist at the Rockefeller University in New York City, says that if such sites are to become popular in the life sciences, researchers will have to overcome common concerns\u00a0\u2014 for example, that preprints could lead to scientists being scooped by competitors and missing out on credit for ideas. Vale and Vosshall say that such worries are misplaced. \u201cI think most biologists don\u2019t know about preprints, or if they do, they\u2019ve heard of them at a very superficial level, to the point that they don\u2019t really understand them very well,\u201d Vale says. \u201cThere\u2019s no doubt that preprints are happening,\u201d says Harold Varmus, a cancer biologist at Weill Cornell Medical College in New York City and another co-organizer of ASAPbio, held on 16\u201317\u00a0February at the Howard Hughes Medical Institute in Chevy Chase, Maryland. \u201cBut I don\u2019t think we\u2019ve ever had a conversation among all the constituents about what the effects will be.\u201d Both Vale and Vosshall think that preprints will become widely accepted only if the life-sciences community develops a consensus that preprint publication establishes a priority for any discovery. A discussion about that is at the top of ASAPbio\u2019s agenda, and Vale co-authored an article on it, posted to the conference\u2019s website last week. He has also tasked meeting attendees with considering how funding agencies and academic committees should view preprints when deciding whom to fund and hire. Another concern is that quality might dip if life scientists flood preprint servers with non-peer-reviewed work. But supporters of preprint publication say that, if anything, researchers are more careful when their reputation rides on early work made public for all to critique. The issue of whether a preprint could jeopardize the chances of a manuscript subsequently appearing in a peer-reviewed journal is also being resolved, says Inglis. Since bioRxiv launched, several journal publishers have changed their policies to expressly allow the publication of research previously posted to preprint servers. Some scientists would like to see more- radical changes. Many make new data sets and hypotheses instantly and freely available online at repositories such as GitHub, figshare and Zenodo, and hope for crowdsourced peer review of their work. \u201cThat\u2019s my utopian fantasy. It would be amazing to live in a world with all radically free data,\u201d says Jessica Polka, a postdoctoral fellow at Harvard Medical School in Boston, Massachusetts, and co-organizer of the ASAPbio meeting. She says that preprints are \u201cthe most practical of all the transformative things that could be implemented\u201d. All of Vosshall\u2019s preprint articles have also been published in conventional journals \u201cthrough the excruciatingly slow process of peer review\u201d, she notes. \u201cMost of them don\u2019t look any different. Which begs the question, why do we need journals any more?\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Does it take too long to publish research? 2016-Feb-10 \n                   \n                     Preprints come to life 2013-Nov-12 \n                   \n                     Geneticists eye the potential of arXiv 2012-Jul-31 \n                   \n                     Nature  special: The future of publishing \n                   \n                     ASAPbio \n                   \n                     bioaR\u03c7iv \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19393", "url": "https://www.nature.com/articles/nature.2016.19393", "year": 2016, "authors": [{"name": "Melinda Wenner Moyer"}], "parsed_as_year": "2006_or_before", "body": "Scientists claim a novel bacterium can cause the tick-borne disease and may trigger more serious symptoms. An article by    Scientific American .  Tick-borne Lyme disease in the U.S. has long been thought to be caused by a single microbe, a spiral-shaped bacterium called  Borrelia burgdorferi . Last week this notion was challenged when a team led by scientists at the Mayo Clinic discovered that Lyme could be caused, albeit rarely, by a different bacterial species that may incite more serious symptoms ranging from vomiting to neurological issues. Scientists working in the contentious field of Lyme disagree, however, as to what this information means for public health and if these findings are truly the first of their kind. For years, they say, research has pointed to the notion that the spirochete that causes Lyme disease in the U.S. is more heterogeneous than many have acknowledged. In the new\u00a0 study , recently published in\u00a0The Lancet Infectious Diseases, Mayo Clinic pathologist and laboratory doctor Bobbi Pritt and her colleagues tested more than 100,500 clinical specimens, such as blood, cerebrospinal fluid and tissue, collected from U.S. patients with suspected Lyme disease between 2003 and 2014. Using a special molecular biology technique called PCR that can identify genetic differences among bacterial strains, they found that six of the samples\u2014collected from patients between 2012 and 2014 in Wisconsin, Minnesota and North Dakota\u2014contained DNA suggestive of a new species. They isolated some of these live bacteria and analyzed parts of their genetic sequence, confirming that the microbe has, in fact, never been documented before. The researchers propose to name the new species\u00a0Borrelia mayonii. Whereas these findings have been touted as the first evidence that bacteria other than\u00a0B. burgdorferi\u00a0can cause Lyme in the U.S., \u201cother Borrelia\u00a0species have [in the past] been implicated,\u201d says Richard Ostfeld, a disease ecologist at the Cary Institute of Ecosystem Studies. For example, in 2011 researchers led by Yvette Girard, a medical entomologist at the University of California, Berkeley,\u00a0 found \u00a0DNA close in sequence to a spirochete called\u00a0Borrelia bissettii,\u00a0which has\u00a0 been implicated \u00a0in Lyme disease in Europe, in three California individuals. Kerry Clark, a tick-borne disease ecologist and epidemiologist at the University of North Florida, and his colleagues also\u00a0 found \u00a0B. bissettii DNA in an individual from the U.S. Southeast, and they\u00a0 identified \u00a0the DNA of two other\u00a0Borrelia\u00a0species in a handful of Florida and Georgia individuals with Lyme-like symptoms. Clark, for one, is troubled that the new paper did not mention any of these previous findings. \u201cI find it unprofessional, and unethical, to not give proper scientific credit to these other researchers,\u201d he says. According to Pritt, the previous work that linked Lyme disease to the bacterial DNA of other\u00a0Borrelia\u00a0species does not prove that theseBorrelia\u00a0caused infections: One has to show that the bacteria are \u201calive or responsible for the patient\u2019s symptoms,\u201d she says. It\u2019s theoretically possible, she notes, for ticks to insert parts of bacteria into their hosts, which may not cause any problems. (Clark and his team have, however,  just published \u00a0a paper in which they grew live\u00a0B. bissettii\u00a0isolated from a patient who had been treated for Lyme.) Pritt\u2019s team did show that the bacteria they found were whole and alive but they have not yet proved that they caused the observed symptoms. \u201cThose definitive studies have not yet been done,\u201d she says. Yet many scientists argue that it is next to impossible to isolate and grow\u00a0B. burgdorferi\u00a0from blood because they do not tend to linger there and they grow slowly. \u201cWe can very rarely culture them in untreated people with acute Lyme disease, where you should be able to culture them,\u201d explains infectious disease physician and researcher John Aucott, who directs the Johns Hopkins Lyme Disease Clinical Research Center. The spirochete that causes syphilis, which is similar, was discovered in 1905 and is still virtually impossible to grow in the lab. (One exception to this culturing problem seems to be\u00a0B. mayonii, which proliferates in blood for as yet unknown reasons and could in part explain why the Mayo Clinic researchers were able to isolate and grow them so easily.) Lyme-causing bacteria are complex for another reason: Even within a single species of\u00a0Borrelia,\u00a0diversity flourishes. Contrary to what has  long been believed ,\u00a0B. burgdorferi\u00a0can\u00a0 genetically recombine \u00a0to create different strains that behave dissimilarly inside the human body. Some strains seem\u00a0 more likely \u00a0to remain in the skin whereas\u00a0 others \u00a0are more likely to invade the nervous system or heart. Some strains are also more commonly found in certain parts of the country. \u201cWhen I started out and we identified a tick as having\u00a0Borrelia burgdorferi,\u00a0we thought that was the gold standard\u2014aha!\u2014but now we are not thinking that way,\u201d says Robert Lane, a medical entomologist at the University of California at Berkeley. \u201cWe have to go within the species itself and break it down further, according to strains or genotypes or alleles. As we learn more, it gets more complicated over time to disentangle the transmission cycles in nature and also what\u2019s going on in the human body after exposure to a given spirochete.\u201d Could some of these differences explain why Lyme patients report diverse symptoms and treatment outcomes? Weigang Qiu, a biologist who studies\u00a0Borrelia\u00a0genetics at Hunter College in New York City, says no one yet knows. \u201cThis is the most important question, but we haven\u2019t found a definitive answer yet,\u201d he says.\u00a0B. mayonii, though, seems to cause strange and serious symptoms: Some patients experienced nausea and vomiting and had diffuse and spotty rashes that were drastically different from the typical Lyme bulls-eye rash. Half displayed neurological problems and one third were hospitalized. All these scientific challenges could help explain why there are so many rifts within the Lyme research community. The organism is difficult to study and genetically diverse, and its ecology\u2014the complicated and intricate dance that takes place between the ticks, their spirochetes and their numerous animal and human hosts\u2014is immensely difficult to track and understand. \u201cTo me, the underlying biology that paves the way for controversy and vastly different perspectives is all a function of the amazing complexity and sophistication of\u00a0Borrelia,\u201d Ostfeld says. Adding to the problem, scientists bring to the field different backgrounds, methodologies, standards of evidence and preconceptions. The new bacterium could complicate the diagnosis of Lyme, too, which has long been a contentious issue. Even with\u00a0B. burgdorferi\u2013caused Lyme, government-recommended diagnostic tests do not typically work in the first four weeks of infection; blood antibody levels are too low. (Three of the six patients who had B. mayonii\u00a0in the Mayo Clinic study would have failed the standard Lyme tests based on their antibody results.) Because of these difficulties, physicians diagnosing Lyme in its early stages are supposed to rely entirely on clinical cues such as the characteristic bulls-eye rash, fever, aches and fatigue. But what if a patient is vomiting and has a spotty rash? \u201cPeople may not think of a tick-borne disease with that,\u201d Aucott says, so cases of\u00a0B. mayonii\u00a0may go undiagnosed and untreated. (B. burgdorferi\u2013caused Lyme disease, he adds, does not always cause a bulls-eye rash either.) Pritt and her colleagues recommend that physicians use their PCR (polymerase chain reaction) test to diagnose\u00a0B. mayonii\u00a0early on, as these bacteria, unlike B. burgdorferi, proliferate readily in blood. But Aucott points out that these tests require physicians to send samples to the Mayo Clinic, and \u201cthat just may not happen.\u201d According to the study, only six Americans since 2012 have been infected with\u00a0B. mayonii. Looking at its evolutionary tree, the spirochete is probably not a new organism, Qiu and Ostfeld say; it has likely been lurking in small numbers in the environment for a long time, and may stay that way. Or it may become more common and spread geographically as other tick-borne diseases have done in recent years, thanks to various ecological factors. Although many questions remain, one thing does seem clear about the new finding: It is yet another paper to add to the pile suggesting that Lyme is not always a simple or straightforward beast. \u201cIt\u2019s really not,\u201d Lane says. \u201cI can state that unequivocally.\u201d \n               This article was originally published by  \n               Scientific American \n                on 16 February 2016. \n             \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   The growing global battle against blood-sucking ticks 2015-Aug-25 \n                 \n                   Lyme bacterium's possible ancestor found in ancient tick 2014-Jun-06 \n                 \n                   Lyme bacteria show that evolvability is evolvable 2013-Nov-14 \n                 \n                   Antibodies linked to long-term Lyme symptoms 2011-Aug-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19394", "url": "https://www.nature.com/articles/nature.2016.19394", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Nature  tallies the trysts among Neanderthals, humans and other relatives. The discovery of  yet another period of interbreeding between early humans and Neanderthals  is adding to the growing sense that sexual encounters among different ancient human species were commonplace throughout their history.\u00a0 \u201cAs more early modern humans and archaic humans are found and sequenced, we\u2019re going to see many more instances of interbreeding,\u201d says Sergi Castellano, a population geneticist at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. His team discovered the latest example, which they believe occurred around 100,000 years ago, by analysing traces of  Homo sapiens  DNA in a Neanderthal genome extracted from a toe bone found in a cave in Siberia. \u201cThere is this joke in the population genetics community \u2014 there\u2019s always one more interbreeding event,\" Castellano says. So before researchers discover the next one, here\u2019s a rundown of the interbreeding episodes that they have already deduced from studies of ancient DNA. \n             1. Early modern humans and Neanderthals \n           The latest discovery has emerged from a re-analysis of the genome of a female Neanderthal. Her genome sequence \u2014 which is much more accurate and complete than those obtained from other Neanderthal samples \u2014 contains stretches of  Homo sapien s DNA, owing to encounters that may have happened in the Middle East. Reporting their work in  Nature 1 , Castellano and his team propose that around 100,000 years ago, her ancestors \u2014 a small population of Neanderthals migrating from Europe to Asia \u2014 encountered a very early wave of  Homo sapiens  leaving Africa. The identity of these early modern humans is a mystery. But roughly 100,000-year-old remains of  Homo sapiens  have been found in the Skhul and Qafzeh caves in Israel, and  similarly ancient human teeth have been found in a cave in southern China . Either set of remains could represent the humans who made an early trek out of Africa; it is not clear whether this population has living descendants today. \n             2. Humans and Neanderthals \n           The  first conclusive evidence that humans and Neanderthals mated  came from analysing a draft Neanderthal genome, which was gleaned largely from remains found in Croatia. As a result of these encounters, humans from outside Africa carry traces of Neanderthal DNA \u2014  about 1\u20132% of their genomes . The two populations  may have met in the Middle East 50,000 to 60,000 years ago , as humans leaving Africa encountered resident Neanderthals. They may have also  interbred more recently in Eastern Europe : DNA from a 40,000-year-old human skeleton from Romania suggests the individual may have had a Neanderthal great-great grandparent. Meanwhile, some researchers contend that the ancestors of East Asians had a second Neanderthal affair, leaving them with slightly more Neanderthal heritage than Europeans have. \n             3. Humans and Denisovans \n           Neanderthals weren\u2019t the only ancient group to interbreed with humans. Denisovans, a group discovered from remains in a cave near southern Siberia\u2019s Altai Mountains,  may have once lived all across Asia , giving them ample opportunity to interbreed with humans there.  People from Papua New Guinea and elsewhere in Oceania carry fragments of Denisovan DNA , as do East Asians. Some of these sequences have proved helpful to humans: gene variants that help Tibetans to cope with altitude may have been  inherited from Denisovans . \n             4. Neanderthals and Denisovans \n           Neanderthals and Denisovans \u2014 both of which lived in Denisova Cave at various points \u2014 also interbred, probably in Asia more than 50,000 years ago. Scientists know little about this encounter, but it may have endowed Denisovans with immune-system genes from Neanderthals. \n             5. Denisovans and a 'ghost' population of hominins \n           The most mysterious interbreeding episode of all involves  Denisovans and a ghost population of hominins that may have left Africa some million years ago . The mystery species could be an Asian offshoot of  Homo erectus , which lived in Indonesia, perhaps as recently as 100,000 years ago, or possibly even relatives of  Homo floresiensis ,  the 'hobbit' species discovered more than a decade ago on an Indonesian island . \u201cWe\u2019re looking at a\u00a0 Lord of the Rings -type world \u2014 that there were many hominid populations,\u201d one evolutionary geneticist told  Nature  when the findings were presented at a conference in 2013.\u00a0 \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Human evolution: The Neanderthal in the family 2014-Mar-26 \n                 \n                   Hominin DNA baffles experts 2013-Dec-04 \n                 \n                   Ancient DNA reveals secrets of human history 2011-Aug-09 \n                 Reprints and Permissions"},
{"file_id": "530263a", "url": "https://www.nature.com/articles/530263a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Detection of ripples in space-time kicks off new era in physics. The  first direct detection of gravitational waves  has opened a new window in physics and astronomy \u2014 rewarding a cohort of young researchers who gambled on finding evidence of a phenomenon that had long eluded physicists. Conceived in the 1970s and built in the 1990s, the Laser Interferometer Gravitational-Wave Observatory (LIGO) has been  promising results for decades . On 11\u00a0February,  it finally delivered , when project scientists reported finding signals of the space-time ripples known as gravitational waves. Its observations are now  poised to reshape  ideas about high-gravity environ\u00adments \u2014 such as colliding black holes, exploding stars and the earliest moments of the Universe. \u201cThe big game-changer for me is, we really do have data and we can finally test our theories,\u201d says Samaya Nissanke, an astrophysicist at Radboud University in Nijmegen, the Netherlands. Nissanke is among the legions of early-career researchers who got into gravitational physics hoping to use data from LIGO and similar detectors. \u201cYou have this unique probe into extreme gravity and extreme space-time in a way that really holds your imagination,\u201d she says. \u201cI was hooked.\u201d LIGO\u2019s first phase ran for years without detecting any gravitational waves, but after a  major upgrade in September  last year, it took just days to find a signal. That strengthens the belief that it will catch many future waves. Physicists expect each additional discovery to bring fresh insight. \u201cThe fact that this happened right away has really given us a boost,\u201d says Laura Cadonati, a physicist at the Georgia Institute of Technology in Atlanta who oversees LIGO data analysis. But the field did not look nearly so rosy 15\u00a0years ago, when Vicky Kalogera, an astrophysicist at Northwestern University in Evanston, Illinois, was calculating how often astrophysical objects such as black holes or neutron stars \u2014 the ultra-dense leftovers of exploded stars \u2014 merge. Such collisions are thought to be the source of most of the gravitational waves that LIGO was designed to detect. Kalogera led some of the early calculations to explore how often two neutron stars might collide close enough to Earth for LIGO to spot the ensuing gravitational waves ( V.\u00a0Kalogera  et\u00a0al. Astrophys.\u00a0J.   601,  L179\u2013L182; 2004 ). Estimates from different groups varied widely, and included some pessimistic scenarios in which LIGO had little chance of ever catching any waves. Kalogera faced a tough decision: whether to stick with gravitational-wave astrophysics or switch to topics that might be more likely to yield actual data. \u201cI went with my guts when everybody told me it was the wrong career choice,\u201d she says. \u201cNow, it is stunning to actually be in the detection era.\u201d Surprisingly, LIGO\u2019s first detection did not come from a binary neutron-star system \u2014 which are thought to be relatively common, with six known pairs in our Galaxy alone \u2014 but from two large black holes. Both were of the order of 30 times the mass of the Sun. \u201cYou can start to think of these not just as gravitational-wave sources,\u201d says Nissanke. \u201cThey are real astronomical beasts.\u201d Still, many physicists hold out hope that LIGO and similar detectors will soon catch gravitational waves from merging neutron stars. These incredibly dense stars are impenetrable to ordinary astronomical tele\u00adscopes, which cannot probe beneath their blazingly bright surfaces; researchers must rely on models to extrapolate what is going on inside. Gravitational waves could change that, yielding information such as the precise sizes of neutron stars and how neutrons pack themselves together so tightly. These answers would come from the details of how the neutron stars spiral towards one another in the last moments before their final merger. \u201cThere\u2019s this potential to learn about the densest stable matter in the Universe, in a way that we\u2019ve been blind to before,\u201d says Jocelyn Read, a physicist at California State University, Fullerton. When neutron stars merge, they are thought to fuse light chemical elements into heavier ones, which they then spew into the surrounding environment. Such cosmic collisions are the source of many of the heavy metals in the cosmos, including much of the gold that has ever been created, says Mansi Kasliwal, an astrophysicist at the California Institute of Technology in Pasadena. \u201cWe haven\u2019t actually seen explosions that are powerful enough to synthesize these elements,\u201d she says. But when LIGO detects gravitational waves, astronomers will be able to command their telescopes to sweep the part of sky where the waves come from \u2014 and, with any luck, will capture a flash of these gold mines in the sky. Kasliwal is already searching with a wide-field camera on a 1.2-metre telescope at Palomar Observatory in California. Next year, this effort will upgrade to a much bigger camera that can survey the sky 12 times faster. A similar survey in Chile is also expected to come online next year, giving both the Northern and Southern hemispheres a dedicated telescope for following the tantalizing traces of gravitational-wave detections. Astronomers hope eventually to piece together a more complete picture of how gravitational waves and conventional astronomy come together. It\u2019s like seeing a film in which the combination of images (electromagnetic waves) and sound (gravitational waves) provides a much fuller picture than either could alone, says Alessandra Corsi, an astrophysicist at Texas Tech University in Lubbock. \u201cIt feels incredibly exciting to be right at the start of a new era.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Gravitational waves: How LIGO forged the path to victory 2016-Feb-16 \n                   \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                   \n                     Hunt for gravitational waves to resume after massive upgrade 2015-Sep-15 \n                   \n                     LIGO \n                   \n                     Virgo \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19375", "url": "https://www.nature.com/articles/nature.2016.19375", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Online poll suggests 10% have had a paper held for at least 3 years. TREND WATCH : A poll answered by more than 3,600  Nature  readers suggests that some 10% have waited at least 3 years for one or more of their papers to be published in a journal. But more than one-third have never waited longer than a year. The online poll accompanied a feature article on  scientists' frustrations with the time it takes to publish papers . Nature  also asked readers what they thought was the best way to speed up publication of scientific papers. Of nearly 3,000 responses, more than 40% suggested that peer reviewers should stop asking for unnecessary revisions in manuscripts, and another 22% asked journal editors to make quicker and clearer decisions. Only 15% suggested that authors should publish preprints and make their work available online before formal peer review. A meeting about how to encourage biologists to do just that,  ASAPbio , is being held this week at the Howard Hughes Medical Institute in Chevy Chase, Maryland. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Does it take too long to publish research? 2016-Feb-10 \n                 Reprints and Permissions"},
{"file_id": "530261a", "url": "https://www.nature.com/articles/530261a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Historic discovery of ripples in space-time meant ruling out the possibility of a fake signal. At 11:53 a.m. local time on 14\u00a0September 2015, an automated e-mail appeared in the inbox of Marco Drago, a physicist at the Max Planck Institute for Gravitational Physics in Hannover, Germany. It contained links to two plots, each showing a wave shaped like a bird\u2019s chirp that emerged suddenly from a noisy background and ended in a crash. It was a signal that Drago had been trained to spot and that the US-led Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) that he works on was built to detect: the signature ripples in space-time produced when two black holes collide to form a single gravitational sink. No one had ever directly detected gravitational waves before, nor a black-hole merger. The plots, one from each of LIGO\u2019s twin detectors in Washington state and Louisiana,  would go on to make history . On 11\u00a0February, the LIGO collaboration announced that it had made the  first detection of gravitational waves  from a black-hole merger that occurred about 400 million parsecs (1.3 billion light years) from Earth. It was just over 100\u00a0years after Albert Einstein predicted such waves as part of his general theory of relativity. \u201cWe did it!\u201d David Reitze, the executive director of the LIGO Laboratory, said  at a press conference in Washington DC . As well as being expected to lead to a Nobel prize, LIGO\u2019s discovery  launches the field of gravitational-wave astronomy , in which scientists will  \u2018listen\u2019 to the waves to learn more about the Universe . On that September morning, Drago could not take it for granted that he was looking at the chirp of a black-hole merger. \u201cIt was clear that it was something extraordinary,\u201d he says. But the plots were also something that the LIGO researchers had expected to see injected artificially by their colleagues to test the detectors. \u201cI went down to the office of my colleague Andrew Lundgren to ask him if he was aware of an injection,\u201d says Drago. Lundgren quickly checked the data logs and found no traces of a drill. Next, Drago sent an e-mail to the entire LIGO collaboration\u00a0\u2014 1,000 researchers spread around the world \u2014 to see what they thought. \u201cWhen I first saw it, I said \u2018Oh, it\u2019s an injection, obviously\u2019,\u201d says physicist Bruce Allen, Drago and Lundgren\u2019s boss. Allen, who was in a meeting at the time, did not bother to enquire until after his lunch break. Within a few hours, collaborators on the other side of the Atlantic woke up to Drago\u2019s e-mail\u00a0\u2014 including experimental physicist Rainer Weiss at the Massachusetts Institute of Technology (MIT) in Cambridge, who is credited as the chief inventor of LIGO. \u201cWhen I started looking at these waveforms, they were something spectacular,\u201d he says. To many, the timing of the signal seemed too good to be true: the collaboration had completed a five-year upgrade to its instruments (see \u2018LIGO\u2019s growing universe\u2019). Moreover, the LIGO collaboration had also given a small number of its members the power to inject fake signals and to hide whether they were real or simulated in order to test the team\u2019s responses. But even such a \u2018blind injection\u2019 ought to have left some traces in the data, says LIGO spokeswoman Gabriela Gonz\u00e1lez, a physicist at Louisiana State University in Baton Rouge. After a long day of calls and e-mails, she determined that no blind injection had occurred and told the entire collaboration. Only then did Kip Thorne, a theoretical physicist at the California Institute of Technology (Caltech) in Pasadena who co-founded LIGO with Weiss and Caltech colleague Ronald Drever, realize that a 40-year-old dream had come true. But it was not yet time to pop the champagne. The collaboration needed to do more before announcing a discovery to the world. \u201cThat night at home, I celebrated by just smiling to myself, because I could not tell my wife yet,\u201d Thorne says. Gonz\u00e1lez and her team decided to take data for another month before beginning a full analysis: the researchers needed to record the natural noise present in their detectors to have something to compare with the chirp. They concluded that the odds of noise producing that loud pattern\u00a0\u2014 and the very same pattern in both Louisiana and Washington at about the same time\u00a0\u2014 were so low that it should only occur by chance less than once every 203,000 years. To extract as much information as possible, the researchers then performed lengthy supercomputer simulations, Allen says. These confirmed that the data beautifully matched the predictions of Einstein\u2019s general theory of relativity in 1915, and the theoretical work that in the past few decades has led physicists to understand the theory\u2019s implications in fine detail. From the waveforms, the researchers were able to deduce that one black hole was about 36 times the mass of the Sun, and the other was about 29 solar masses. As the two objects orbited each other, they warped the fabric of space and time around them in a fluctuating pattern. Those fluctuations then  travelled across the Universe as gravitational waves  for an estimated 1.3 billion years, stretching and squeezing space as they moved. LIGO\u2019s twin interferometers bounce laser beams between mirrors at the opposite ends of perpendicular, 4-kilometre-long vacuum pipes. A gravitational wave passing through will alter the length of the pipes in different ways, causing the laser beams to shift slightly out of sync. By the time the waves from the black-hole merger arrived on 14\u00a0September, they had become tiny ripples, changing the length of the pipes on the order of just 1\u00a0part in 1 billion trillion (10 21 ). Although the two black holes had probably been orbiting each other for millions of years, LIGO began to pick up their waves only when they reached a frequency of 35 cycles per second (hertz). The frequency rapidly increased to 250\u00a0hertz. The signal became chaotic and then rapidly died down; the whole thing was over within a quarter of a second. Crucially, both detectors saw it at roughly the same time\u00a0\u2014 Livingston, in Louisiana, first and Hanford, in Washington, 7\u00a0milli\u00adseconds later. The delay is an indication of how the waves swept through Earth. Then came writing the paper. This involved getting 1,000 researchers to agree on every detail, and took some 5,000 e-mails, says LIGO\u2019s chief detector scientist Peter Fritschel at MIT. On 21 January, the team submitted the paper, which  Physical Review Letters  published on 11\u00a0February ( B. P. Abbott  et al. Phys. Rev. Lett.    116,  061102; 2016 ), the same day that LIGO held multiple press conferences around the world. \u201cThese amazing observations are the confirmation of a lot of theoretical work, including Einstein\u2019s general theory of relativity, which predicts gravitational waves,\u201d says physicist Stephen Hawking at the University of Cambridge, UK. LIGO\u2019s triumph is a fitting end to the tale that Einstein began. He never believed that black holes existed. But although astronomers had accumulated compelling evidence for black holes by observing their surroundings, notes Thibault Damour, a theoretical physicist at the Institute of Advanced Scientific Studies near Paris, the LIGO signal is \u201cthe first real direct proof of their existence\u201d. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Einstein's gravitational waves found at last 2016-Feb-11 \n                   \n                     LIGO announces gravitational-wave detection \u2014 in pictures 2016-Feb-11 \n                   \n                     Gravitational waves: 6 cosmic questions they can tackle 2016-Feb-09 \n                   \n                     Nature  special: Gravitational waves \n                   \n                     Nature  special: General relativity at 100 \n                   \n                     The LIGO papers \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19408", "url": "https://www.nature.com/articles/nature.2016.19408", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "People obeying commands feel less responsibility for their actions. More than 50 years after a controversial psychologist shocked the world with studies that revealed people\u2019s willingness to harm others on order, a team of cognitive scientists has carried out an updated version of the iconic \u2018Milgram experiments\u2019. Their findings may offer some explanation for Stanley Milgram's uncomfortable revelations: when following commands, they say, people genuinely feel less responsibility for their actions \u2014 whether they are told to do something evil or benign. \u201cIf others can replicate this, then it is giving us a big message,\u201d says neuroethicist Walter Sinnot-Armstrong of Duke University in Durham, North Carolina, who was not involved in the work. \u201cIt may be the beginning of an insight into why people can harm others if coerced: they don\u2019t see it as their own action.\u201d The study may feed into a long-running legal debate about the balance of personal responsibility between someone acting under instruction and their instructor, says Patrick Haggard, a cognitive neuroscientist at University College London, who led the work, published on 18 February in  Current Biology 1 . Milgram\u2019s original experiments were motivated by the trial of Nazi Adolf Eichmann, who famously argued that he was \u2018just following orders\u2019 when he sent Jews to their deaths. The new findings don\u2019t legitimize harmful actions, Haggard emphasizes, but they do suggest that the \u2018only obeying orders\u2019 excuse betrays a deeper truth about how a person feels when acting under command. \n               Ordered to shock \n             In a series of experiments at Yale University in New Haven, Connecticut, in the 1960s, Milgram told his participants that a man was being trained to learn word pairs in a neighbouring room. The participants had to press a button to deliver an electric shock of escalating strength to the learner when he made an error; when they did so, they heard his cries of pain. In reality, the learner was an actor, and no shock was ever delivered. Milgram\u2019s aim was to see how far people would go when they were ordered to step up the voltage. Routinely, an alarming two-thirds of participants continued to step up shocks, even after the learner was apparently rendered unconscious. But Milgram did not assess his participants\u2019 subjective feelings as they were coerced into doing something unpleasant. And his experiments have been criticized for the deception that they involved \u2014 not just because participants may have been traumatized, but also because some may have guessed that the pain wasn\u2019t real. Modern teams have conducted partial and less ethically complicated replications of Milgram\u2019s work. But Haggard and his colleagues wanted to find out what participants were feeling. They designed a study in which volunteers knowingly inflicted real pain on each other, and were completely aware of the experiment\u2019s aims. Because Milgram\u2019s experiments were so controversial, Haggard says that he took \u201cquite a deep breath before deciding to do the study\u201d. But he says that the question of who bears personal responsibility is so important to the rule of law that he thought it was \u201cworth trying to do some good experiments to get to the heart of the matter.\u201d \n               Sense of agency \n             In his experiments, the volunteers (all were female, as were the experimenters, to avoid gender effects) were given \u00a320 (US$29). In pairs, they sat facing each other across a table, with a keyboard between them. A participant designated the \u2018agent\u2019 could press one of two keys; one did nothing. But for some pairs, the other key would transfer 5p to the agent from the other participant, designated the \u2018victim\u2019; for others, the key would also deliver a painful but bearable electric shock to the victim\u2019s arm. (Because people have different tolerances to pain, the level of the electric shock was determined for each individual before the experiment began.) In one experiment, an experimenter stood next to the agent and told her which key to press. In another, the experimenter looked away and gave the agent a free choice about which key to press. To examine the participants\u2019 \u2018sense of agency\u2019 \u2014 the unconscious feeling that they were in control of their own actions \u2014 Haggard and his colleagues designed the experiment so that pressing either key caused a tone to sound after a few hundred milliseconds, and both volunteers were asked to judge the length of this interval. Psychologists have established that people perceive the interval between an action and its outcome as shorter when they carry out an intentional action of their own free will, such as moving their arm, than when the action is passive, such as having their arm moved by someone else. When they were ordered to press a key, the participants seemed to judge their action as more passive than when they had free choice \u2014 they perceived the time to the tone as longer. In a separate experiment, volunteers followed similar protocols while electrodes on their heads recorded their neural activity through EEG (electroencephalography). When ordered to press a key, their EEG recordings were quieter \u2014 suggesting, says Haggard, that their brains were not processing the outcome of their action. Some participants later reported feeling reduced responsibility for their action. Unexpectedly, giving the order to press the key was enough to cause the effects, even when the keystroke led to no physical or financial harm. \u201cIt seems like your sense of responsibility is reduced whenever someone orders you to do something \u2014 whatever it is they are telling you to do,\u201d says Haggard. The study might inform legal debate, but it also has wider relevance to other domains of society, says Sinnot-Armstrong. For example, companies that want to create \u2014 or avoid \u2014 a feeling of personal responsibility among their employees could take its lessons on board. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Experimental psychology: The anatomy of obedience 2015-Jul-22 \n                   \n                     Virtual reality shocker 2006-Dec-22 \n                   \n                     UCL Institute of Cognitive Neuroscience \n                   Reprints and Permissions"},
{"file_id": "530266a", "url": "https://www.nature.com/articles/530266a", "year": 2016, "authors": [{"name": "Meera Subramanian"}], "parsed_as_year": "2006_or_before", "body": "Scramble by researchers to monitor driving restrictions in Indian capital pays off. New Delhi may be the world\u2019s most polluted city, but it\u2019s making an effort to relinquish that title. With pollution from particulate matter at potentially lethal levels early last December, city officials took a drastic step: they announced that they would temporarily restrict the use of private vehicles by allowing owners to drive only on alternate days, based on the sequence of their number plates. The initial results of that 15-day trial, which began on 1\u00a0January, are now in. Although traffic actually increased in the first week of the ban, the levels of PM 2.5  \u2014 parti\u00adculate matter measuring less than 2.5\u00a0micrometres across \u2014 fell by roughly 10%. That is a victory not just for New Delhi officials, but also for the scientists who sprang into action to collect the data necessary to determine whether the test had achieved its goal. \u201cThis experiment with \u2018live research\u2019 has been really quite exciting,\u201d says Santosh Harish, assistant director of the India centre of the Energy Policy Institute at the University of Chicago (EPIC-India). EPIC-India and the New Delhi-based Council on Energy, Environment and Water (CEEW), an independent think tank, used video monitors around the city to document the types and numbers of vehicles on the roads. The groups had less than a month to collect baseline data before the driving restrictions began. But they weren\u2019t the only researchers interested in Delhi\u2019s living lab. Economist Gabriel Kreindler of the Massachusetts Institute of Technology in Cambridge scrambled to secure human-study approval and funding for a survey of driver behaviour during the traffic restrictions. Within 18\u00a0days of the announcement of the driving ban, he had arrived in New Delhi to oversee a surveying team from the Abdul Latif Jameel Poverty Action Lab\u2019s office there. Kreindler\u2019s work eventually found that the alternate-day restrictions were well received by most drivers, who, in spite of the disruption, were willing to comply and alter their behaviour for short periods of time. Other researchers built on work already under way. The Centre for Science and Environ\u00adment (CSE), a non-profit research and advocacy group in New Delhi, had been closely analysing government air-quality data since last October. By December, government monitors were recording daily levels of noxious PM 2.5  in the range of 400\u2013600\u00a0micrograms per cubic metre. This is much higher than the Indian legal standard of 60\u00a0micrograms (which itself is more than double the 25-microgram target threshold set by the World Health Organization). PM 2.5  particles cause more than 600,000 premature deaths in India each year, from lung cancer, asthma, and cardiovascular and respiratory diseases. There is no known safe level for this pernicious pollutant. The CSE\u2019s analysis found that, despite unfavourable weather conditions, the peak pollution during the driving scheme was lower than it would have been without the restrictions in place. \u201cThe region is geographically disadvantaged,\u201d says M. P. George, a scientist with the government\u2019s Delhi Pollution Control Committee. In winter, particulate levels can be twice as high as during the summer, because \u2018inversion layers\u2019 of warm air trap cold air close to the ground. This prevents pollution from dissipating into the atmosphere. Emissions from vehicles and construction dust also combine with raised levels of black carbon generated from winter sources \u2014 fires for warmth, brick kilns that are lit in the autumn, and widespread field burning in neighbouring states. \u201cIt\u2019s a very simple math,\u201d says Sarath Guttikunda, director of the independent research group Urban Emissions, which is registered in New Delhi. \u201cIn winter, your air volume is going down and your emissions are going up.\u201d Because atmospheric conditions such as wind and temperature can greatly affect particulate-matter measurements, researchers from EPIC-India and the Evidence for Policy Design initiative at Harvard University in Cambridge, Massachusetts, gathered data from air-quality monitors in New Delhi and placed monitors in three adjacent cities as a control. They found that the daily level of PM 2.5  pollution in Delhi dropped by 10\u201313% during the vehicle restrictions. Hourly comparisons showed an even greater improvement, at times an 18% fall. The question now is whether New Delhi, the capital of a nation with dozens of growing cities choked by pollution, can build on the experiment for long-term gains in air quality. \u201cDelhi has to get it right,\u201d says Namit Arora, a member of the pollution task force of the Delhi Dialogue Commission, a government initiative. This will require long-term strategies and coordination between local, regional and national efforts, he says, as well as a reduction in all sources of air pollution. Other researchers stress the need for more open-access data from a wide range of well-calibrated instruments. But the driving-restriction experiment has given researchers a tantalizing glimpse of one possible future. \u201cWe need to re-imagine the way we think about cities,\u201d says Hem Himanshu Dholakia, a research associate at the CEEW. \u201cThat\u2019s the real opportunity.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Sustainable mobility: Six research routes to steer transport policy 2015-Jul-01 \n                   \n                     Environmental science: Pollution patrol 2015-Jan-07 \n                   \n                     India races through environmental approvals 2014-Jul-08 \n                   \n                     Global health: Deadly dinners 2014-May-28 \n                   \n                     Development: Mobilize citizens to track sustainability 2014-Mar-30 \n                   \n                     EPIC-India \n                   \n                     Council on Energy, Environment and Water \n                   \n                     J-PAL South Asia \n                   \n                     Centre for Science and Environment \n                   \n                     Delhi Pollution Control Committee \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19422", "url": "https://www.nature.com/articles/nature.2016.19422", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Only one-third of trials at US medical centres are reported within two years of completion. TREND WATCH:  The results of clinical trials need to be published speedily if the studies are to be useful to physicians. But only 35.9% of clinical trials at leading US academic medical centres have their results reported within two years of trial completion, US researchers revealed in the  BMJ  on 17 February 1 . The team examined more than 4,300 trials across 51 institutions registered at the website ClinicalTrials.gov as having been completed between 2007 and 2010. Only 29% of the trials had their results published in scientific journals two years after they had been completed, the researchers found, and just 13% were reported on ClinicalTrials.gov in the same time frame. The results show the wide variance of reporting among US institutions. The University of Minnesota was the most efficient, reporting 55.3% of its clinical trial results within two years; the University of Nebraska was the least, with just 16.2% reported in that time (see 'The trial publishing problem'). \u201cThe lack of timely reporting and publication fundamentally impairs the research enterprise, violates the commitment made by investigators to patients and funders, squanders precious time and resources, and threatens to compromise evidence based clinical decision making,\u201d says the team behind the work, led by Harlan Krumholz at Yale University in New Haven, Connecticut. Overall, by July 2014, two-thirds of the results of trials completed between 2007 and 2010 had been published or reported online. Previous research has found similar problems with clinical-trial reporting, the team says; studies have variously reported that 25\u201350% of clinical-trial results remain unpublished several years after the trials' completion. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Make journals report clinical trials properly 2016-Feb-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19419", "url": "https://www.nature.com/articles/nature.2016.19419", "year": 2016, "authors": [{"name": "Bianca Nogrady"}], "parsed_as_year": "2006_or_before", "body": "Australian bill provokes rush of protests ahead of parliamentary deadline. Nicholas Price works to understand the brain's fundamental functions, with a view towards developing a bionic eye. The neuroscientist uses marmosets and macaques in his experiments at Monash University\u2019s Biomedicine Discovery Institute in Melbourne. In late January, he was shocked to discover a bill before the Australian Parliament that calls for a ban on the import of non-human primates for medical research. Australia\u2019s three main breeding colonies of research primates consist of several hundred macaques, marmosets and baboons. Regular imports of the animals are vital to maintain the genetic diversity of these colonies, says Price. Senator Lee Rhiannon, a member of the Greens party, introduced  the bill  on 17 September last year as an amendment to Australia\u2019s federal Environment Protection and Biodiversity Conservation Act. But because the Senate committee that deals with this piece of legislation is not usually of interest to those in the medical research community, the amendment almost slipped under the community's radar, says Price. By the time he heard about the proposed ban, from another researcher, the window for public comment was days away from closing, though it was later extended. \n               Submissions rush \n             As soon as they found out, Price and his Monash colleagues James Bourne and Marcello Rosa began e-mailing researchers around the world. Several institutions rushed to submit statements opposing the bill, including the Federation of European Neuroscience Societies (FENS), the Society for Neuroscience, headquartered in Washington DC, and the Basel Declaration Society, which promotes the open, transparent and ethical use of animals in research. Australia\u2019s National Health and Medical Research Council and the Australasian Neuroscience Society also sent statements of opposition to the Senate committee. Animal research, including that on non-human primates, \u201ccontinues to be the basis for medical advances that have extended our life expectancy\u201d, says the  FENS statement , submitted on 4 February. The  Society for Neuroscience's statement , dated the same day, says that the proposed legislation would lead to \"the loss of critical research resources that will be devastating for Australian science\". The committee is now in the process of considering the bill, and will report on it on 1 March, as a prelude to an eventual Senate vote. Rhiannon, who trained as a zoologist, told  Nature  that the Greens are not calling for a ban on non-human primates being used in research. \u201cThere\u2019s certainly a live debate but it\u2019s not the party position,\u201d she says. She calls the bill a \u201cmodest\u201d way to improve the welfare of research animals, and, when she launched the bill last year, spoke at length about the \"the cruelty during their capture, confinement and transportation\". Price and Bourne say that cutting off access to the genetic diversity required to maintain the monkey colonies would eventually spell the end of Australian research on non-human primates. \u201cAfter a while you\u2019ll get genetic inbreeding,\u201d says Price, \u201cand that can lead to exacerbation of health problems that you may not be able to see until you\u2019re a few generations down the track.\u201d He regards non-human primate research as one of the country\u2019s major sources of scientific innovation. \n               Wild primates \n             In introducing the bill, Rhiannon also said that it would ensure that Australia \u201cdoes not participate in the unethical trade of wild-caught primates for use in experimentation for the research industry\u201d. But Australian regulations already prohibit the use of wild-caught primates in medical research, says Bourne, who is chairman of the National Non-human Primate Breeding and Research Facility Board. \u201cThey have to be certified from a registered and accredited breeding facility in another country.\" Rhiannon introduced a similar bill in 2012 that never made it to a Senate vote before Parliament was dissolved ahead of a federal election. The latest bill may face a similar challenge with an election required by January 2017 at the latest. But Rhiannon says that even if it doesn\u2019t get passed into legislation anytime soon, the bill is a way to highlight that there is a problem with the use of non-human primates, without going so far as to call for banning such research entirely. Price says that the events have convinced him of a need to be more public about the importance of his work. \u201cIf we can demonstrate the value and outcomes, especially in medical research, then we feel that the majority of the public would be very supportive.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     NIH to retire all research chimpanzees 2015-Nov-18 \n                   \n                     Animal farm 2014-Feb-05 \n                   \n                     Biomedicine: The changing face of primate research 2014-Feb-05 \n                   \n                     A Bill for an Act to amend the Environment Protection and Biodiversity Conservation Act \n                   \n                     Society for Neuroscience statement \n                   \n                     FENS statement \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19411", "url": "https://www.nature.com/articles/nature.2016.19411", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Santa Cruz Biotechnology is one of the world\u2019s largest antibody providers \u2014 and the subject of a US government animal-welfare investigation. In July 2015, the major antibody provider Santa Cruz Biotechnology owned 2,471 rabbits and 3,202 goats. Now the animals have vanished, according to the US Department of Agriculture (USDA). The company, which is headquartered in Dallas, Texas, is one of the world\u2019s largest providers of antibodies \u2014 extracting them from animals such as goats and rabbits by injecting the animals with proteins to stimulate antibody production. Biomedical researchers can then use these antibodies to detect and label the same protein in cell or tissue samples. But Santa Cruz Biotech is also the subject of three animal-welfare complaints filed by the USDA after its inspectors found evidence that the firm mistreated goats at its facility in California. Santa Cruz Biotech has contested the complaints, prompting a hearing in August before a USDA administrative law judge in Washington DC. Four days into the hearing, both parties asked to suspend the proceedings in order to negotiate a settlement. But those negotiations fell through in September. The USDA hearing is set to resume on 5 April. If Santa Cruz Biotech is found to have violated the US Animal Welfare Act, it could be fined or lose its licence to keep animals for commercial use. The USDA says that the company could face a maximum fine of US$10,000 per violation for each day that a given violation persists. The agency has reported 31 alleged violations by the company. \n             Disappearing act \n           In the meantime, the company seems to have done away with its entire animal inventory. When the USDA inspected the firm's California facility on 12 January, it found no animal-welfare violations, and listed \u201cno animals present or none inspected\u201d. USDA spokesman Ed Curlett says that no animals were present during the inspection. The fate of the goats and rabbits is unclear. The company did not respond to questions about the matter, and David Schaefer, director of public relations for the law firm Covington & Burling in Washington DC, which is representing Santa Cruz Biotechnology, declined to comment on the animals\u2019 fate. As research animals, the goats and rabbits could not be sold for meat, although they could be sold to another business or research entity. Cathy Liss, president of the Animal Welfare Institute, an advocacy group in Washington DC, suspects that the animals were killed. She says that it is unlikely that such a large number of animals bred for such a specific purpose would find a buyer. David Favre, an expert in animal-welfare law at Michigan State University in East Lansing, argues that the disappearance of the animals should not sway the legal proceedings over whether the company violated the Animal Welfare Act, because the USDA complaints refer to past events. But he says that the court could still take this latest development into account. Favre is also unhappy with the USDA\u2019s decision to delay action on the complaints. The department\u2019s \u201cwhole attitude is \u2018we\u2019ll give them time to fix it rather than impose punishment\u2019,\u201d Favre says. \u201cThere\u2019s no excuse for a company that size not to be able to comply with the Animal Welfare Act.\u201d \n             Welfare complaints \n           The USDA\u2019s complaints about Santa Cruz Biotech\u2019s operations detail alleged violations of the law since 2007 \u2014 among them accounts of goats with untreated coyote bites and massive tumours, and rabbits being housed in cruel conditions. A sick goat died in front of a USDA inspector during one 2012 inspection. The company also angered the USDA by  keeping 841 goats in an unreported facility , which concealed the animals and their living conditions from regulatory scrutiny until 2012. During the August 2015 USDA hearing, former Santa Cruz Biotech veterinarian Robin Parker testified that company president John Stephenson had decided not to tell the USDA inspectors about the second site. She said that she had been told that the regulators tended to \u201cnitpick\u201d the company's operations. After leaving Santa Cruz Biotech in 2012, Parker notified the USDA about the unreported facility. When inspectors visited the site, they found animals housed in poor living conditions. \u201cSo much of what was cited involves great animal suffering,\u201d says Liss, whose advocacy group has campaigned for the USDA to take action against the company. \u201cWe are hoping that USDA holds out and if there is going to be a settlement, that it includes them permanently losing their licence as a dealer.\u201d Favre says that the USDA and Santa Cruz Biotech may have already reached some sort of agreement that requires the company to cease keeping animals for commercial use in advance of the 5 April court hearing; that could explain why the company no longer keeps goats or rabbits. But the USDA administrative-law court says that the company has not submitted any exhibits related to animal removal for the upcoming hearing, although its attorneys could petition to add more evidence before the hearing begins. \n             Antibody alternatives \n           Were Santa Cruz Biotech to stop producing antibodies, there would still be hundreds of other providers supplying the materials to researchers, says David Rimm, a pathologist at Yale University in New Haven, Connecticut. \u201cI think people might notice, but I don\u2019t think it would impact science at all,\u201d says Rimm. He speculates that the company may be moving towards making \u2018recombinant\u2019 antibodies. These are produced in cells cultured in the lab that are genetically engineered to make specific antibodies. Many companies have switched to this method instead of producing antibodies using animals, Rimm says. Alice Ra\u2019anan, director of government relations and science policy at the American Physiological Society in Bethesda, Maryland, hopes that the allegations against Santa Cruz Biotechnology will prompt a cultural change among those involved in animal research. The ideal outcome, she says, is \u201cthat people will give animal welfare the level of consideration it deserves\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Discovery of goat facility adds to antibody provider's woes 2013-Jan-14 \n                 \n                   NIH retires research chimps at troubled facility 2012-Sep-21 \n                 \n                   Antibody provider investigated over treatment of goats \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19418", "url": "https://www.nature.com/articles/nature.2016.19418", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Clinical-trials expert Robert Califf expected to win approval after months of political delay. \n             Update: On 24 February, the US Senate confirmed Califf as the next FDA commissioner. \n           After a five-month delay, the US Senate is finally poised to vote on the nominee to head the US Food and Drug Administration (FDA): cardiologist and clinical-trials expert Robert Califf. On 22 February, lawmakers voted to limit debate on Califf\u2019s nomination. That procedural tactic sets the stage for a final vote this week that would determine whether he will lead the FDA. President Barack Obama  nominated Califf last September , but a handful of lawmakers has delayed consideration of the nomination over concerns about the FDA\u2019s approval last November of  genetically engineered salmon  for use as food and the agency\u2019s policies on opioid painkillers. Another lawmaker, Senator Bernie Sanders \u2014 a Democrat from Vermont who is running for president \u2014 has objected to Califf himself. Sanders finds fault with Califf's many connections to the pharmaceutical industry, which he forged over years of heading a major clinical-trials centre at Duke University in Durham, North Carolina, before joining the FDA last January. In an article this month in the  New England Journal of Medicine,  Califf listed more than a dozen pharmaceutical companies in his conflict-of-interest disclosure[1]. No previous FDA commissioner has been so closely tied to the pharmaceutical industry, says Michael Carome, director of the health-research group at Public Citizen, a consumer activist group in Washington DC. \u201cIt would be dangerously naive to think he has not developed deeply ingrained attitudes that tilt in favour of the medical-device and drug industries,\u201d says Carome. But Califf\u2019s supporters say that he has maintained his independence. \u201cI\u2019ve never experienced a situation where I thought he was not reporting the results of the studies in a fair, open and honest way,\u201d says cardiologist Steven Nissen at the Cleveland Clinic in Ohio, who has been critical of the influence that the pharmaceutical industry wields over the FDA. \n             Smooth sailing? \n           After today\u2019s procedural vote, the Senate is expected to confirm Califf in a matter of days. Daniel Carpenter, a social scientist at Harvard University in Cambridge, Massachusetts, says that Califf's nomination will probably not be the last to spark debate over potential industry influence in government. \u201cThe fact that [Califf] was officially at Duke but had all of these ties with industry shows how intertwined the biomedical complex has become with universities,\u201d Carpenter says. \u201cFuture appointments from universities to the FDA and other agencies are increasingly going to be appointments from people who have these conflicts of interest.\u201d In 2013 and 2014, Califf received roughly US$52,000 from industry partners, primarily for travel and consulting, according to the government\u2019s Open Payments database. About 55% of all full professors at US medical centres have received money from industry, often as payment for consulting, notes Eric Campbell, a sociologist at Harvard Medical School in Cambridge. \u201cClose relationships in academia and industry are essential to moving science forward,\u201d Campbell says. \u201cBut the question is: is that same level of closeness necessary and appropriate regarding a government regulatory agency and the industry it is trying to regulate?\u201d The key, he says, will be how the FDA manages Califf's potential conflicts. Nissen points to one incident that gives him confidence in Califf's independence. In 2008, Nissen told an FDA advisory committee that the agency should require diabetes drugs to be tested for their effects on cardiovascular health, in addition to their ability to lower blood sugar. It was a controversial opinion, and some experts \u2014 particularly in industry \u2014 said that it would discourage the development of new diabetes drugs by making the required clinical trials prohibitively expensive. Nissen thought that he had little chance of convincing the FDA panel of his argument. But after Nissen\u2019s talk, Califf gave his own presentation in which he voiced support for Nissen\u2019s proposal. Later that summer, the FDA announced that it would require the extra trials for full approval of the drugs. \u201cI could never have gotten that initiative done if there weren\u2019t some people like Califf who would stand up and say, \u2018I agree\u2019,\u201d says Nissen. \u201cI\u2019m sure he took some heat from industry.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Clinical-trial specialist could be next FDA chief 2015-Feb-12 \n                 \n                   Policy reform: Strengthen and stabilize the FDA 2012-May-09 \n                 \n                   The FDA: A tough tonic 2009-Nov-25 \n                 \n                   FDA: Robert Califf \n                 \n                   Open Payments database \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19462", "url": "https://www.nature.com/articles/nature.2016.19462", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Mimivirus defence system might lead to new genome-editing tools Gigantic mimiviruses fend off invaders using defences similar to the CRISPR system deployed by bacteria and other microorganisms, French researchers report 1 . They say that the discovery of a working immune system in a mimivirus bolsters their claim that the giant virus represents a new branch in the tree of life. Mimiviruses are so large that they are visible under a light microscope. Around half a micrometre across, and first found infecting amoebae living in a water tower, they boast genomes that are larger than those of some bacteria. They are distantly related to viruses that include smallpox, but unlike most viruses, they have genes to make amino acids, DNA letters and complex proteins. That means that they blur the line between non-living viruses and living microbes, says Didier Raoult, a microbiologist at Aix-Marseille University in France, who co-led the study with microbiologist colleague Bernard La Scola. Raoult says that he doesn\u2019t consider the mimivirus to be a typical virus; instead, it is more like a prokaryote \u2014 microbes, including bacteria, that lack nuclei. Like prokaryotes, mimiviruses are  plagued by viruses known as virophages , Raoult, La Scola and their colleagues reported in 2008 2 . Six years later, in 2014, they found a virophage \u2014 named Zamilon \u2014 that infects some kinds of mimivirus but not others 3 . Raoult hypothesized that these infections, which sap a mimivirus\u2019s capacity to copy itself, could have led to the evolution of a defence system much like CRISPR. \n             Immune defence \n           In bacteria and another kind of prokaryote, called archaea, CRISPR systems store a library of short DNA sequences that match those of phages and other invading DNA. When a foreign DNA sequence with matching sequences in this library attacks a cell, specialized \u2018Cas\u2019 enzymes unwind the intruder DNA and chop it into pieces, stopping an infection.\u00a0Biologists have now  repurposed CRISPR as a technology to edit genomes . To determine whether mimiviruses have a similar defence system, Raoult\u2019s team analysed the genomes of 60 mimivirus strains and looked for sequences that match those of the Zamilon virophage. Mimiviruses that were resistant to Zamilon also harboured a short stretch of DNA that matched that of the phage. Adjacent to these sequences, Raoult\u2019s team found genes encoding enzymes that can degrade and unwind DNA. In CRISPR immunity, too, the genes encoding the Cas enzymes sit beside the sequences that recognize the virus. Blocking activity of different components of the system made the mimiviruses susceptible to Zamilon virophage attack. The findings were published on 29 February in  Nature 1 . It makes sense for mimiviruses to have an immune system because they must compete for resources against against other microbes and viruses, says Raoult. \u201cThey are facing the same kind of challenge that prokaryotes have when they live in communities: they need to fight against viruses and prokaryotes. I even suspect they secrete antibiotic compounds.\u201d Raoult has argued,  somewhat controversially, that mimiviruses constitute a fourth domain of life  \u2014 alongside bacteria, archaea and eukaryotes. He sees their defence system, which he has named MIMIVIRE, as a very ancient adaptation that further supports them having their own branch on the tree of life. Francisco M\u00f3jica, a microbiologist at the University of Alicante in Spain, who identified CRISPR sequences in prokaryotes in the 1990s, notes that CRISPR components have been found in other viruses, but it is not clear whether the systems function. He suspects that an ancestor of mimiviruses picked up MIMIVIRE from another microbe. \u201cIt will certainly be of great interest to identify the mechanism involved in MIMIVIRE immunity,\u201d says M\u00f3jica; he expects that it will be very different from CRISPR. Luciano Marraffini, a bacteriologist at the Rockefeller University in New York, says that Raoult\u2019s team makes a good case that MIMIVIRE is a viral defence system, but agrees that it will be important to work out how it stops virophage infections. Just as unravelling how CRISPR immunity works led to its repurposing as a genome-editing tool, studying mimiviruses could hold surprises, Marraffini says. \u201cThe giant viruses most likely\u00a0enclose a whole lot of new biology, some of which, including the MIMIVIRE, could find novel application. Maybe\u00a0in genome editing, maybe in other fields.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Guts of giant virus imaged in 3D 2015-Mar-02 \n                 \n                   Giant virus resurrected from 30,000-year-old ice 2014-Mar-03 \n                 \n                   Giant viruses open Pandora's box 2013-Jul-18 \n                 \n                   The challenge of microbial diversity: Out on a limb 2011-Aug-03 \n                 \n                   'Virophage' suggests viruses are alive 2008-Aug-06 \n                 Reprints and Permissions"},
{"file_id": "531016a", "url": "https://www.nature.com/articles/531016a", "year": 2016, "authors": [{"name": "T. V. Padma"}], "parsed_as_year": "2006_or_before", "body": "Biotechnology agency wants to upgrade capabilities to kick-start economic growth. An ambitious plan to turn India into a world-class centre for genomics research and commercialization received a modest boost on 29\u00a0February when the government announced its annual budget. A big winner in the budget was India\u2019s main science funding agency, the Department of Science and Technology, which received 44.7\u00a0billion rupees (US$650\u00a0million), a 17% hike on last year\u2019s allocation. The Department of Biotechnology (DBT), meanwhile, received 18.2\u00a0billion\u00a0rupees, a 12% rise on the previous year \u2014 an indication of how the National Biotechnology Development Strategy, which the department unveiled last December, is likely to evolve. The budget brought mixed news for other departments engaged in scientific research (see \u2018Budget allocations\u2019). The Department of Health Research\u2019s budget represented a 12% rise in funding compared with the money pledged in 2015\u201316, for instance, whereas the Department of Space got an increase of less than 2%.  \n               Budget allocations (millions of rupees) \n               The DBT\u2019s allocation is roughly half of what  Krishnaswamy VijayRaghavan , the department\u2019s secretary, estimated was needed when the strategy was released \u2014 but he is confident that the remainder can be made up from other sources. The allocation is \u201cvery good\u201d in terms of implementing the strategy, he told  Nature . The DBT\u2019s strategy aims to ramp up India\u2019s total biotech revenues by more than tenfold since the industry started up two decades ago, to $100\u00a0billion by 2025. The idea is to kick-start the economy by replicating the success of the information-technology boom that has fuelled economic growth for more than 20 years. \u201cBiotechnology can be another vibrant model for growth that India can offer,\u201d said the science minister, Harsh Vardhan, back in December. India\u2019s pharmaceutical industry is largely confined to the  production of \u2018generic\u2019 copies of existing drugs , and to contract research organizations, which conduct clinical trials of drugs and vaccines on behalf of pharmaceutical companies. Both have grown into successful industries, says VijayRaghavan, but the nation \u201cis now ready to upgrade its biotech capabilities\u201d. The DBT received an encouraging sign last year, when its budget allocation for 2015 was not subsequently slashed during mid-term budget revisions, as often happens. The latest 12% increase builds on that good news, says VijayRaghavan. Ahead of this year\u2019s budget, however, VijayRaghavan said that this figure would need to rise to 25\u201330% annually over the next five years to implement the strategy. He now says that the DBT could make up the difference with funds from elsewhere, including a national innovation mission launched in January, which identified biotechnology as a key area \u2014 in particular, to bolster the parts of the strategy aimed at nurturing biotech start-ups and supporting entrepreneurs. The DBT could also tap into the science department\u2019s budget. Department secretary Ashutosh Sharma, who described the increase as \u201cfantastic\u201d, says that his department\u2019s plans include a rise in the number and quality of start-ups and business incubators, support for scientists undertaking high-risk research, the promotion of industry-relevant research at academic institutes and new research programmes on, among other things, biomedical devices. Some of these plans overlap with the DBT\u2019s strategy. Ahead of the budget announcement, VijayRaghavan told  Nature  that the strategy revolves around three core activities. The first is the creation of new infrastructure. India already hosts several genomics research institutes, such as the Institute of Genomics and Integrative Biology (IGIB) and the National Institute of Plant Genome Research, both in New Delhi, and the National Institute of Biomedical Genomics near Kolkata. The DBT\u2019s strategy aims to create five more centres, each dedicated to a different field, including drug discovery, marine biology and infection, as well as several centres of excellence based on narrower, high-priority areas such as genetically modified organisms, vaccines and marine bioproducts. The second activity is the provision of training in the analysis of big data. Indian geneticists have previously discovered mutations in breast-cancer genes that are unique to the Indian population ( M.\u00a0T.\u00a0Valarmathi  et al.    Hum. Mutat.   23,  205; 2004 ) and sequenced the genomes of several crops, including chickpea ( R.\u00a0K.\u00a0Varshney et\u00a0al. Nature Biotechnol. 31, 240\u2013246; 2013 ). The DBT\u2019s strategy aims to train researchers in the scanning and analysis of large numbers of genomes. VijayRaghavan notes that the country\u2019s existing expertise in computing and biology will help this. \u201cWe need to bring the two skill sets together,\u201d he says. The strategy also aims to create 150\u00a0technology-transfer organizations to help to commercialize discoveries made in publicly funded research laboratories, together with 40\u00a0technology and business incubators, which will provide equipment and guidance for new firms, and facilitate networking opportunities. Together, these all comprise the third core activity, says VijayRaghavan, and will build on the activities of the DBT\u2019s Biotechnology Industry Research Assistance Council, which was set up in 2012. Lipi Thukral, a computational structural biologist at the IGIB, sees the DBT\u2019s goal of creating a genomics hub as an opportunity for India to enter the emerging field of  precision medicine , which uses genomic, physiological and other data to tailor treatments to the individual. Achieving that will require clinicians to gather extensive data and to interact better with academics to analyse the data, says Thukral. To succeed, the strategy will also need a feedback mechanism between the biotech corporate sector and academic institutions, policies to protect scientists undertaking high-risk, high-reward research and a reorientation of academia towards more industry-relevant research, she adds. Others have reservations about the scale of the DBT\u2019s ambitions. \u201cThe strategy seems overwhelming, overburdened, and implementation would be a Herculean task,\u201d says Nalini Vemuri, vice-president for research and development at the Gurgaon-based company Lifecare Innovations. The strategy spans four major areas \u2014 health care, food and nutrition, energy and education. But although these represent an \u201cimpressive vision\u201d, says Vemuri, a more narrowly focused goal, for example to improve the country\u2019s research in malaria and tuberculosis, would have a better chance of success. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n               \n                     Indian bioscience: The anti-bureaucrat 2015-May-13 \n                   \n                     India: The fight to become a science superpower 2015-May-13 \n                   \n                     Case study: India's billion dollar biotech 2010-Aug-01 \n                   \n                     Biotech boom 2005-Jul-27 \n                   \n                     Then and now 2005-Jul-27 \n                   \n                     Department of Biotechnology \n                   \n                     Biotechnology Industry Research Assistance Council \n                   \n                     CSIR Institute of Genomics and Integrative Biology \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19287", "url": "https://www.nature.com/articles/nature.2016.19287", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Elegant experiment confirms that targeting senescent cells could treat age-related diseases. Eliminating worn-out cells extends the healthy lives of lab mice \u2014 an indication that treatments aimed at killing off these cells, or blocking their effects, might also help to combat age-related diseases in humans. As animals age, cells that are no longer able to divide \u2014 called senescent cells \u2014 accrue all over their bodies, releasing molecules that can harm nearby tissues. Senescent cells are linked to diseases of old age, such as kidney failure and type 2 diabetes. Ewen Callaway talks to researcher Darren Baker about senescent cells and prolonging life. To test the cells\u2019 role in ageing, Darren Baker and Jan van Deursen, molecular biologists at the Mayo Clinic in Rochester, Minnesota, and their colleagues engineered mice so that their senescent cells would die off when the rodents were injected with a drug.\u00a0 The work involved sophisticated genetic tinkering and extensive physiological testing, but the concept has an elegant simplicity to it. \u201cWe think these cells are bad when they accumulate. We remove them and see the consequences,\u201d says Baker. \u201cThat\u2019s how I try to explain it to my kids.\u201d \n             Live long and prosper \n           Mice whose senescent cells were killed off over six months were healthier, in several ways, than a control group of transgenic mice in which these cells were allowed to build up. Their kidneys worked better and their hearts were more resilient to stress, they tended to explore their cages more and they developed cancers at a later age. Eliminating senescent cells also extended the lifespans of the mice by 20\u201330%, Baker and van Deursen report in  Nature  on 3 February 1 . The research is a follow-up to a 2011 study, in which their team also found that eliminating senescent cells delayed the onset of diseases of old age in mice, although that work had been done in mice which had a mutation that causes premature ageing 2 . In the hope of discovering therapies for diseases of old age, researchers are already looking for drugs that can directly eliminate senescent cells or stop them from churning out factors that damage neighbouring tissue. They include Baker and van Deursen, who have have licensed patents to develop such drugs to a company van Deursen has co-founded.  The team's experiment \u201cgives you confidence that senescent cells are an important target,\" says Dominic Withers, a clinician-scientist who studies ageing at Imperial College London and who co-wrote a News and Views article for  Nature  that accompanies the Mayo Clinic report 3 .\u00a0\u201cI think that there is every chance this will be a viable therapeutic option.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Read the related News & Views article, \" Out with the old \". \n                   Ageing research: Blood to blood 2015-Jan-21 \n                 \n                   Blood hormone restores youthful hearts to old mice 2013-May-10 \n                 \n                   Telomerase reverses ageing process 2010-Nov-28 \n                 \n                   Cancer-proof mice live longer 2007-Jul-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19308", "url": "https://www.nature.com/articles/nature.2016.19308", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Blazes have encroached on ecosystems that date back more than 180 million years. Bushfires sparked by lightning storms have burned large areas of northwestern Tasmania since mid-January, consuming more than 105,000 hectares \u2014 including almost 2% of the region\u2019s United Nations World Heritage wilderness lands. Large Australian bushfires  have become so common that they hardly seem like news 1 , but these are different. Rather than burning swathes of fire-adapted vegetation such as  Eucalyptus  or  Banksia , many of the recent blazes have raged through ecosystems that are not adapted to fire at all \u2014 relict forests from when Tasmania was a part of the Gondwana supercontinent, more than 180\u00a0million years ago. When fires burn the pencil pines ( Athrotaxis cupressoides ) and King Billy pines ( Athrotaxis selaginoides ) that dominate these high-altitude ecosystems, they kill not only the trees but also their seeds \u2014 and incinerate the peaty soil they grow in. In the hardest-hit areas, natural regeneration of these ancient forests is all but impossible. The trees, many of which are more than 1,000 years old, have been able to survive in Tasmania thus far because its climate is colder and wetter than that of the mainland. But climate change may tip the odds against them. \n               Storm warning \n             The 'dry' lightning strikes that ignited the current fires \u2014 from thunderstorms in which most rain evaporates before reaching the ground \u2014 used to be vanishingly rare in western Tasmania, but climate change is thought to have made such storms more common in recent years. Tasmania saw one of the driest years on record in 2015. Furthermore, logging and dry conditions in the rainforest that surrounds these alpine forests have reduced its ability to act as a firebreak. \u201cThere was no doubt pencil pine was on the mainland, but the fire and climate regime meant it couldn\u2019t persist,\u201d says David Lindenmayer, a forest ecologist at Australian National University in Canberra. \u201cIf Tasmania is going to become more like the mainland, there is a distinct possibility that its time is going to be done. That is a huge loss for the world.\u201d Just a small percentage of the alpine and central-plateau fire-sensitive ecosystems in northwestern Tasmania have been killed by the blazes, of which 69 were still burning on 4\u00a0February. But if fires become more frequent, that may spell the beginning of the end. \u201cIf you have 2% [burning] every 10 or 15 years, it is not long before it is pushed into only the most fire-protected refuges,\u201d says Jamie Kirkpatrick, a geographer and conservation ecologist at the University of Tasmania in Hobart. \n               Preserving the past \n             To the chagrin of ecologists and bushwalkers, the fires have threatened several iconic landscapes, including the Walls of Jerusalem National Park and Mount Anne, the highest peak in southwestern Tasmania. Hobart-based photographer Dan Broun and a colleague hiked up to a burned alpine area last weekend. When they crested the plateau, they were greeted by a dead world. \u201cWe were in shock. What we were seeing was complete and utter devastation,\u201d says Broun. There have already been discussions about reseeding the burnt areas, but experts warn that it may not work; it is not at all clear that the strategy would make sense in a \u201cnew normal\u201d in which fires are predicted to run rampant in the area. Furthermore, grazing by wallabies and wombats keeps many seedlings from ever growing tall enough to reproduce. The existing pines may date from a slender window of time when heavy snows kept grazing animals away for long enough for the trees to grow out of their reach \u2014 a process that takes 50 years. With threats to the region\u2019s iconic forests clear, University of Tasmania ecologist David Bowman has called for an increased effort to collect seeds of fire-sensitive Tasmanian species and conserve them in another location, perhaps even on a sub-Antarctic island that would be safer from fire. That would require a lot of seeds. Luckily, 2015 was a mast year \u2014 a period in which trees produce unusually large crops of cones and seeds \u2014 for many high-altitude conifers in Tasmania. In March and May, government biologists collected 1.57 million viable seeds from pencil and King Billy Pines, as well as the shrub-like Cheshunt pine ( Diselma archeri ) and drooping pine ( Pherosphaera hookeriana ). \u201cWe knew these sorts of [fire] events were likely in the future and the species we were looking at were so vulnerable to fire,\u201d says James Wood, head of the Tasmanian Seed Conservation Centre at the Royal Tasmanian Botanical Gardens in Hobart. \u201cEffectively, we are a Noah\u2019s ark. We are just trying to hold onto material so it is not lost permanently.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     UN World Heritage Area: Tasmanian Wilderness \n                   \n                     Tasmania Fire Service bushfire map \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19269", "url": "https://www.nature.com/articles/nature.2016.19269", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Amgen posts three studies at new online channel for discussing reproducibility. A biotechnology firm is releasing data on three failed efforts to confirm findings in high-profile scientific journals \u2014 details that the industry usually keeps secret. Amgen, headquartered in Thousand Oaks, California, says that it hopes the move will encourage others in industry and academia to describe their own replication attempts, and thus help the scientific community to get to the bottom of work that other labs are having trouble verifying. The data are  posted online  at a newly launched channel dedicated to quickly publishing efforts to confirm scientific findings. The 'Preclinical Reproducibility and Robustness' channel is hosted by  F1000Research , the publishing platform of London-based publishers Faculty of 1000 (F1000). Scientists who are concerned about the  irreproducibility of preclinical research  say that they welcome the initiative \u2014 but are not sure whether it will gain traction. \n               Open to criticism \n             The idea emerged from discussions at a meeting focused on improving scientific integrity, hosted by the US National Academy of Sciences in 2015. Sasha Kamb, who leads research discovery at Amgen, said that his company's scientists have in many instances tried and failed to reproduce academic studies, but that it takes too much time and effort to publish these accounts through conventional peer-review procedures. Bruce Alberts, a former editor-in-chief of  Science  who sits on  F1000Research \u2019s advisory board, suggested that Kamb try the faster F1000 route \u2014 an  open-science publishing model  in which submitted studies are posted online (for a fee that ranges from US$150 to $1000) before undergoing peer review; submissions are subject to checks by F1000 editors to ensure that data are freely available and that methods and reagents are adequately described. \u201cThe idea is to get the data out and get it critically looked at,\u201d Alberts says. The editors then invite open peer review of the studies. If reviewers recommend the work, it is indexed in databases such as PubMed and Scopus. F1000, in turn, has created a designated channel for these studies in the hope that they will garner attention, give credit to researchers doing careful confirmatory experiments and provide a place where the original researchers of a study and other scientists can discuss reasons behind different outcomes. \n               Irreproducible history \n             In 2012, Amgen researchers made headlines when they declared that they had been unable to reproduce the findings in 47 of 53 'landmark' cancer papers 1 . Those papers were never identified \u2014 partly because of confidentiality concerns \u2014 and there are no plans to release details now either, says Kamb, who was not involved with that publication. He says that he prefers to focus on more-recent publications. The three studies that Amgen has posted deliberately do not make a detailed comparison of their results to previous papers, says Kamb. \u201cWe don\u2019t want to make strong conclusions that someone else\u2019s work is wrong with a capital W,\u201d he says. One study adds to  existing criticism  of a  Science  paper that suggested that a cancer drug might be a potential treatment for Alzheimer\u2019s disease 2 ; a second counters earlier findings (including some by Amgen researchers) connecting a gene to insulin sensitivity in mice 3 , 4 ; and a third counters a  Nature  paper reporting that inhibiting one particular protein could enhance degradation of other proteins associated with neurodegenerative diseases 5 . \u201cWe believe that interested scientists can look at our methods and results and draw their own conclusions,\u201d Kamb says. Amgen researchers did not contact the original authors when they conducted their studies, he says, but future postings could be collaborative. \n               Gaining traction \n             Right now, the main way that the scientific community spreads the word about irreproducible research is through innuendo, which is inefficient and unfair to the original researchers, says Ricardo Dolmetsch, global head of neuroscience at Novartis\u2019s Institutes for Biomedical Research in Cambridge, Massachusetts. \u201cAnything we can do to improve the ratio of signal to noise in the literature is very welcome,\u201d he says. The F1000 initiative is useful, but previous efforts have tried and failed to encourage the reporting of replications and negative results, cautions John Ioannidis, who studies scientific robustness at California's Stanford University. That is because, in general, the scientific community undervalues such work, he says. But Kamb says that he has spoken with several industry leaders who have expressed support, and he hopes that they will contribute eventually. Roger Perlmutter, head of research and development at pharmaceutical giant Merck, says his colleagues can participate in the channel \"at their own discretion\". Morgan Sheng, a vice-president at biotechnology company Genentech in South San Francisco, says he can forsee his company's scientists submitting data to the venture too. \"I believe the main risk of a publication venue like the F1000 channel is that it becomes a place for \u201cbashing\" good science, because biological experiments are complex and beset by many variables that are hard to control. Non-replication does not necessarily mean 'not true',\" Sheng adds. He says the site should be careful to emphasize publication of positive replication data as well. Academic researchers are unlikely to risk alienating their peers by publishing disconfirming results, predicts Elizabeth Iorns, head of Science Exchange in Palo Alto, California. Her firm provides an online marketplace where scientists can offer to do others\u2019 experiments, which she used to  launch a reproducibility initiative  in 2012. But providing industry scientists with a low-barrier way to share their attempts might prove a winning strategy, she says. \u201cHopefully, the awareness of the reproducibility issue has been raised such that people are no longer afraid to talk about it.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Nature Reproducibility Special \n                   \n                     F1000Research Preclinical Reproducibility and Robustness Channel \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19294", "url": "https://www.nature.com/articles/nature.2016.19294", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Two studies show how different tree species affect both carbon storage and local temperatures. Simply planting trees will not necessarily slow down climate change, an analysis of Europe's vegetation history shows. Although the continent's forests have expanded by 10% since 1750, timber harvesting and shifts to more commercially valuable tree species have resulted in a net release of carbon to the atmosphere, a  Science  paper published on 4 February concludes 1 . The changes have also had local effects, the analysis finds, raising surface temperatures by 0.12 \u00b0C by increasing the absorption and retention of heat. \u201cThe current assumption is that all forest management and all forests contribute to climate mitigation,\u201d says Kim Naudts, a postdoctoral ecologist at the Max Planck Institute for Meteorology in Hamburg, Germany. \u201cWe cannot say that is true, at least for Europe.\u201d Naudts conducted the analysis with a team of colleagues while at the Laboratory of Climate Science and Environment in Gif-sur-Yvette, France. The paper sounds a warning about potential limitations to the benefits of forest expansion, or afforestation, but does not come as a surprise, says Richard Houghton, an ecologist at the Woods Hole Research Center in Falmouth, Massachusetts. \u201cForest management includes many possibilities,\u201d he says. \u201cIf the point is to store carbon, then afforestation is presumably good, but losing carbon to wood extraction is bad.\u201d From 1750 to 1850, roughly 190,000 square kilometres of Europe's forest were cut down to for fuel and to clear land for agriculture. Forests have since rebounded on an area more than twice that size, but fast-growing conifers have replaced deciduous trees on roughly 633,000 square kilometres of forest owing to interest in timber harvesting. Although European forests continue to take up carbon, the shift in composition means that they now hold 3.1 billion tonnes less than they did in 1750. The modelling analysis also considered the local climate impact of trees, which affect temperatures by releasing water into the atmosphere through evapotranspiration, and by absorbing or reflecting sunlight. The model suggests that the shift toward dark conifers, which absorb more sunlight and emit less water, has contributed to local warming. Unpublished data support the idea that a shift from deciduous to coniferous forests could increase local temperature, says Alessandro Cescatti, an ecologist at the European Commission\u2019s Joint Research Centre in Ispra, Italy. But the conclusion that European forests have produced net warming is questionable, he adds. Cescatti co-authored a paper in the same issue of  Science  that concludes that forests in all climates cool the local atmosphere, particularly during summer months, when heat and fire are a concern 2 . The study used satellite observations to reconstruct changes in air temperature in areas that were cleared of forests from 2003 to 2012. Cescatti says that both studies suggest that policymakers must account for the local biophysical climatic effects of forests rather than focus exclusively on the global effects of carbon dioxide. \u201cForest management, forest transition and forest land cover should be accounted for in climate policies,\u201d he says. \u201cAt the moment they are not.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Forests in spotlight at Paris climate talks 2015-Dec-01 \n                 \n                   Tree cheers 2015-Apr-01 \n                 \n                   Stopping deforestation: Battle for the Amazon 2015-Apr-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19332", "url": "https://www.nature.com/articles/nature.2016.19332", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Geneticist Urban Lendahl steps down because of involvement in Macchiarini investigation. A prominent official has resigned from the committee that awards the Nobel Prize in Physiology or Medicine, because he expects to become involved in  the investigation surrounding controversial surgeon Paolo Macchiarini  at the Karolinska Institute (KI) in Stockholm. Urban Lendahl, a geneticist, was one of the scientists at the Karolinska who recommended hiring Macchiarini as a visiting professor at the institute in 2010. The KI is now  cutting ties with Macchiarini , who is embroiled in a scandal about the ethics of his work implanting artificial windpipes into patients; it has also ordered an external investigation into how it handled his case. Lendahl, who \u201canticipates that he may be involved in this investigation\u201d, resigned his post as secretary-general of the Nobel Assembly, a group of 50 Karolinska-based professors that decides who wins the prize in physiology or medicine, on 6 February. He also resigned as secretary-general on the smaller Nobel Committee, which puts forward nominations for the prize. The decision is \u201ceffective immediately,\u201d according to a  statement  from the chairman of the Nobel Assembly, Rune Toftg\u00e5rd, a biologist at the Karolinska. Lendahl had asked to resign \u201cout of respect for the integrity of the Nobel Prize work,\u201d Toftg\u00e5rd explains. \n             Trachea controversy \n           In 2011, Macchiarini implanted a plastic trachea, seeded with stem cells, into a patient whose own windpipe had been damaged. Following that work \u2014 which was hailed as a game-changer in regenerative medicine \u2014 he implanted artificial tracheas into seven more people, including two more at the Karolinska. Six of the patients have died and another has spent most of their time in intensive care since the procedure. (Macchiarini says the deaths were unrelated to his surgery.) The KI\u2019s decision to hire the surgeon \u2014 and subsequent decisions to extend his contracts \u2014 have been  questioned  following a documentary on SVT, Sweden's public broadcaster, that aired in January. The documentary alleged, among other things, that Macchiarini had performed the surgery on a patient who was not life-threateningly ill, contrary to the surgeon's previous statements. It also showed that Macchiarini claimed in publications that the artificial tracheas had fared better than patient records show. An  article in  Vanity Fair  in January alleged that Macchiarini lied about his past affiliations when he applied for the Karolinska post. The Karolinska has said that it will look into the charges \u2014 all of which Macchiarini denies \u2014 and announced last week that it would not renew the surgeon\u2019s contract, which expires in November, and that it would launch an investigation into the way it handled his case. In 2015, physicians at the Karolinska argued that Macchiarini had conducted research misconduct on seven papers; an independent investigation  found the surgeon guilty , but the Karolinska\u2019s vice-chancellor Anders Hamsten then  cleared him of misconduct . \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "530138a", "url": "https://www.nature.com/articles/530138a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "US science agencies threaten harsh penalties, but many have yet to take action. Fabricating, falsifying or plagiarizing data can get a grant yanked or a researcher blacklisted for breaking the professional code of science. Now, some funders are facing a fresh challenge: what to do with grants given to scientists who commit sexual transgressions. The US government does not classify sexual infractions as research misconduct. Instead, as recent high-profile cases illustrate, the National Science Foundation (NSF), NASA and the National Institutes of Health (NIH) must navigate a relatively new legal landscape when confronted with sexual harassment by grant recipients. What is clear, specialists in research ethics say, is that agencies, institutions and researchers all need to improve their response to such behaviour. \u201cThe public has a right for us to conduct publicly funded work honourably and with integrity,\u201d says C.\u00a0K.\u00a0Gunsalus, director of the National Center for Professional and Research Ethics at the University of Illinois at Urbana\u2013Champaign. The latest scandal broke on 2\u00a0February, when  The New York Times  reported that molecular biologist Jason Lieb had left the University of Chicago in Illinois after an internal investigation found that he had made unwelcome sexual advances to female graduate students, and had engaged in sexual activity with a student who was incapacitated and could not consent. In January, it became public that Christian Ott, a theoretical astrophysicist at the California Institute of Technology in Pasadena,  was on unpaid leave  for violating the institution\u2019s sexual-harassment policy. And last October, astronomer Geoffrey Marcy  announced that he would retire  from the University of California, Berkeley, after a similar verdict. Lieb, Ott and Marcy have each brought millions in government research dollars to their universities, which must now decide how to handle the money. Funding agencies and institutions must comply with Title IX, a federal law that forbids sex discrimination (which, in legal terms, can include harassment or assault) in any educational programme that receives government money. The law has been on the books since 1972, but in 2011, the US Department of Education said that it would step up its enforcement of the sexual-harassment aspects. To comply with Title IX, institutions must have a representative who investigates and resolves allegations of sex discrimination. The inquiries into Lieb, Ott and Marcy all went through the Title IX offices at their respective universities. Once a Title IX investigation is complete, the institution must decide whether to take disciplinary action. A funding agency can open its own inquiry and levy extra penalties if it deems them necessary. NASA and the NSF have both put out statements recently saying that they do not tolerate sexual harassment by grantees; the NSF even threatened to pull funds entirely from institutions that do not comply with Title IX. But it has never banned a grantee, let alone an institution, for violating Title IX. \u201cStatements are good for changing the culture, but they have to be supported by action,\u201d says Katie Hinde, an anthropologist at Arizona State University in Tempe. The process is more complicated than simply yanking existing grants. \u201cPeople come to us and say, why don\u2019t you fix it?\u201d says James Ulvestad, head of the NSF\u2019s astronomy division. \u201cWell, what the funding agencies can do is what federal law allows us to do.\u201d In general, funding awards are made to institutions, not the person who is the principal investigator (PI) for the work. Even if a PI has been found to violate institutional policies, his or her grant money will continue to flow to support graduate students, postdoctoral fellows and other collaborators on an affected project. Lieb is PI or co-PI on more than US$1.2\u00a0million in NIH grants, for which the University of Chicago may nominate someone to replace him. Ott is involved in more than $3.2 million in NSF funds; those grants are under review but their status remains unchanged for now, says NSF spokeswoman Ivy Kupec. Ott still has access to NSF facilities, including the Blue Waters supercomputer in Illinois, on which he runs simulations of supernova explosions. Marcy had many lucrative private grants, including a share of the $100-million Breakthrough Listen  search for extraterrestrial intelligence . Those have been transferred to new PIs. His old employer is now working on designating new PIs for the two NASA grants totalling roughly $1\u00a0million that are in Marcy\u2019s name. It was actually a case of sexual assault that prompted the modern US definition of research misconduct, says Nicholas Steneck, a specialist in research integrity at the University of Michigan in Ann Arbor. In 1989, the NSF received complaints about the actions of a senior researcher while taking undergraduates to a research site in another country. The agency\u2019s inspector-general ultimately found the researcher to have committed \u201c16\u00a0incidents of sexual misfeasance with female graduate and undergraduate students at the research site; on the way to the site; and in his home, car, and office\u201d. Many could be classified as sexual assaults. The agency barred him from receiving federal funding for five years, according to a definition of misconduct that at that time included \u201cserious deviations\u201d from accepted research practices. After a fierce battle over the meaning of the phrase, agencies excised it from their definitions of misconduct in 2000. \u201cSexual harassment shouldn\u2019t be tolerated,\u201d Steneck says. \u201cBut it\u2019s not so easy to say, \u2018It\u2019s research misconduct and that\u2019s the way it ought to be handled\u2019.\u201d US agencies might learn a thing or two from funders in other countries, Steneck adds. Both Canada and Australia (see \u2018Codes of conduct\u2019) require federally funded scientists to meet a minimum ethical standard that specifically describes institutional roles. \u201cYou need to set out a clear code of what to expect,\u201d he says. \n               boxed-text \n             See World View  page 131 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     NSF statement on harassment \n                   \n                     NASA statement on harassment \n                   \n                     US Department of Education page on Title IX \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19337", "url": "https://www.nature.com/articles/nature.2016.19337", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "The discovery of ripples in space-time has vindicated Einstein \u2014 but it can also do so much more. The  first direct detection of gravitational waves was announced on 11 February  by the Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO). Using LIGO's twin giant detectors \u2014 one in Livingston, Louisiana, and the other in Hanford, Washington \u2014 researchers measured ripples in space-time produced by a collision between two black holes. The announcement vindicates Albert Einstein\u2019s prediction of gravitational waves, which he made almost exactly 100 years ago 1  as part of his  general theory of relativity  \u2014 but it also has much further significance. As vibrations in the fabric of space-time, gravitational waves are often compared to sound, and have even been converted into  sound   snippets . In effect, gravitational-wave telescopes allow scientists to \u2018hear\u2019 phenomena at the same time as light-based telescopes \u2018see\u2019 them. (Already, members of LIGO and its smaller counterpart Virgo in Pisa, Italy, have set up a system for alerting communities working on other types of telescope.) When LIGO fought to get US government funding in the early 1990s, its major opponents at congressional hearings were astronomers 2 . \u201cThe general view was that LIGO didn\u2019t have much to do with astronomy,\u201d says Clifford Will, a general-relativity theorist at the University of Florida in Gainesville and an early LIGO supporter. But things have changed now, he says. Welcome to the field of gravitational-wave astronomy 3 : we take a look at the questions and phenomena that it can explore. \n             Do black holes actually exist? \n           One of the important scientific consequences of LIGO\u2019s detection of a black-hole merger is, quite simply, that it confirms that black holes really do exist \u2014 at least as the perfectly round objects made of pure, empty, warped space-time that are predicted by general relativity. Astronomers had plenty of circumstantial evidence for black holes, but until now, that had come from observations of the stars and super-heated gas that orbit black holes, not of black holes themselves. \u201cThe scientific community, including myself, has become very blas\u00e9 about black holes. We have taken them for granted,\u201d Frans Pretorius, a specialist in general-relativity simulations at Princeton University in New Jersey, told  Nature  before the  LIGO announcement . \u201cBut if you think of what an astonishing prediction it is, we really need astonishing evidence.\u201d LIGO\u2019s signal has provided that evidence \u2014 and also confirms that mergers between two black holes proceed as predicted. A merger occurs when two black holes start to spiral towards each other, radiating energy as gravitational waves. LIGO detected  the characteristic sound of these waves, called a chirp,  which allowed scientists to measure the masses of the two objects involved in the event the observatory spotted: one about 36 times the mass of the Sun, and the other 29 solar masses. Next, the black holes fuse. \u201cIt\u2019s as if you get two soap bubbles so close that they form one bubble. Initially, the bigger bubble is deformed,\u201d says Thibault Damour, a gravity theorist at the Institute of Advanced Scientific Studies near Paris. The resulting single black hole will settle into a perfectly spherical shape, but first, as LIGO saw, it radiates gravitational waves in a pattern called a ringdown. \n             Do gravitational waves travel at the speed of light? \n           When scientists start to compare observations from LIGO with those from other types of telescope, one of the first things that they will check is whether the signals arrive at the same time. Physicists hypothesize that gravity is transmitted by particles called gravitons, the gravitational analogue of photons. If, like photons, these particles have no mass, then gravitational waves would travel at the speed of light, matching the prediction of the speed of gravitational waves in classical general relativity. (Their speed can be affected by the accelerating expansion of the Universe, but that should manifest only over distances much greater than LIGO can probe 4 ). But it is  possible that gravitons have a slight mass , which would mean that gravitational waves would travel at less than the speed of light. So if, say, LIGO and Virgo were to detect gravitational waves from a cosmic event, and find that the waves took slightly longer to arrive at Earth than the associated burst of \u03b3-rays detected by a more conventional telescope, that could have momentous consequences for fundamental physics. \n             Is space-time made of cosmic strings? \n           An even weirder discovery would occur if bursts of gravitational waves were detected coming from \u2018 cosmic strings \u2019. These hypothetical defects in the curvature of space-time, which may or may not be related to string theory, would be infinitesimally thin but would stretch across cosmic distances. Researchers have predicted that cosmic strings, if they exist, might occasionally develop kinks; if a string snapped, it would suddenly release a burst of gravitational waves, which detectors such as LIGO and Virgo could measure. \n             Are neutron stars rugged? \n           Neutron stars are the remnants of bigger stars that collapsed under their own weight, becoming so dense that they  pushed their constituent electrons and protons to fuse into neutrons . Their extreme physics is poorly understood, but gravitational waves could provide unique insights. For example, the intense gravity at their surface tends to make neutron stars almost perfectly spherical. But some researchers have theorized that there could still be \u2018mountains\u2019 \u2014 at most a few millimetres high \u2014 that make these dense objects, themselves about 10 kilometres in diameter, slightly asymmetrical. Neutron stars usually spin very rapidly, so the asymmetric distribution of mass would deform space-time and produce a continuous gravitational-wave signal in the shape of a sine wave, which would radiate energy and slow down the star\u2019s spin. Pairs of neutron stars that orbit each other would also produce a continuous signal. Just like black holes, the stars would spiral into each other and eventually merge, sometimes producing an audible chirp. But their final instants would differ dramatically from those of black holes. \u201cYou have a zoo of possibilities, depending on masses and how much pressure neutron-dense matter can exert,\u201d says Pretorius. For example, the resulting merged star could be a huge neutron star, or it could immediately collapse and turn into a black hole. \n             What makes stars explode? \n           Black holes and neutron stars form when massive stars stop shining and collapse in on themselves. Astrophysicists think that this process is what powers a  common type of supernova explosion , known as Type II. Simulations of such supernovae have not yet clearly explained what ignites them, but listening to the gravitational-wave bursts that real supernova are expected to produce could help to provide an answer. Depending on what the bursts\u2019 waveforms look like, how loud the bursts are, how frequent they are and how they correlate with the supernovae as seen with electromagnetic telescopes, the data could help to validate or discard various, existing models.  \n             How fast is the Universe expanding? \n           The  expansion of the Universe  means that distant objects that are receding from our Galaxy look redder than they really are, because the light that they emit stretches as it travels. Cosmologists estimate the rate of the Universe\u2019s expansion by comparing this redshift of galaxies with how far the galaxies are from us. But that distance is usually gauged from the brightness of \u2018Type Ia\u2019 supernovae \u2014 a technique that leaves large uncertainties. If several gravitational-wave detectors across the world detect signals from the same neutron-star merger, together they will be able to provide an estimate of the absolute loudness of the signal, which will reveal how far away the merger occurred. They will also be able to estimate the direction it came from; astronomers could then deduce which galaxy hosted the merger. Comparing that galaxy\u2019s redshift with the distance of the merger as measured by the loudness of the gravitational waves could provide an independent estimate of the rate of cosmic expansion, possibly more accurate than current methods. \n             \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Nature Special: General relativity at 100 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19313", "url": "https://www.nature.com/articles/nature.2016.19313", "year": 2016, "authors": [{"name": "Myles Gough"}], "parsed_as_year": "2006_or_before", "body": "National science agency announces strategic shift away from measuring and modelling climate change. Hundreds of climate researchers at Australia\u2019s national science agency are set to lose their jobs after the organization announced that it would shift its strategy away from basic climate science. The Commonwealth Scientific and Industrial Research Organisation (CSIRO) employs thousands of scientists across Australia, and has been a leader in climate modelling and ocean observation in the Southern Hemisphere for decades. But in an e-mail sent to CSIRO staff members this week, chief executive Larry Marshall wrote that he expected the agency to shed up to 350 jobs over the next two years, of which the burden would fall on climate-science areas, including research divisions in the Oceans and Atmosphere and Land and Water units. Climate models and measurements had now proven the existence of global climate change, Marshall wrote, and the questions for the organization would now be: \u201cWhat do we do about it\u201d and \u201chow can we find solutions for the climate we will be living with?\u201d A spokesperson for CSIRO said that the cuts from climate-research units were a strategic decision. \u201cThe CSIRO is effectively saying \u2018climate science is done and we\u2019re moving on to adaptation and mitigation\u2019,\u201d says John Church, an expert in sea-level rise in the Ocean and Atmosphere unit who has spent 38 years with the organization. \"My view is that there is inaccurate and misleading science in that statement \u2014 climate science is not done,\u201d he says. Another senior scientist from the unit, who spoke to  Nature  on the condition of anonymity, says that 220 jobs will be cut from the two units; the 110 cuts from his unit will draw directly from the roughly 130 scientists (of the unit\u2019s 421 staff) who work on climate science-related activities, he says. \u201cMore than 80% [of our climate scientists] will be cut. This is not about myself, it\u2019s about my people and the capability we spent 40 years to build. It will be going overnight.\u201d\u00a0 \n             \u2018Disastrous move\u2019 \n           Other Australian researchers were quick to condemn the announcement. \u201cThis is a disastrous move that will decimate ocean and climate sciences in Australia,\u201d Matthew England, co-director of the University of New South Wales\u2019 Climate-Change Research Centre in Sydney, told the Australian Science Media Centre (SMC) in Adelaide. Penny Sackett, an astronomer at the Australian National University in Canberra, and a former chief scientist for the country, told the SMC that she was \u201cstunned by reports that CSIRO management no longer thinks measuring and understanding climate change is important, innovative or impactful\u201d. Andrew Holmes, president of the Australian Academy of Science in Canberra, said in a  statement  that the CSIRO job losses followed cuts of more than Aus$20 million (US$19 million) to climate and environmental science in the 2014\u201315 federal budget, and meant that there was \"serious concern\" about the country's ability to conduct research in the area. \"We call on the government to quickly make alternative arrangements to continue a comprehensive national program of climate research,\" he said. Australia\u2019s science and innovation minister, Christopher Pyne, did not respond to  Nature \u2019s requests for comment. The cuts come after a difficult time for CSIRO, which employs more than 5,000 people but dropped 1,300 jobs in the two years up to June 2015, largely because of  a 2014 federal budget that cut CSIRO funding by 16% , or roughly Aus$115 million, over four years. Despite the most recent job losses, a CSIRO spokesperson said, \"we expect that after two years, staff numbers will be at the same levels they are now, or higher.\" But Sam Popovski, the secretary of the CSIRO Staff Association, says that there are doubts that, with flat federal funding for the next three years, CSIRO will be able to keep its staffing levels stable. \n                   Australia's scientists give new prime minister a cautious welcome 2015-Sep-15 \n                 \n                   Australian science-agency staff announce strike 2015-Jun-11 \n                 \n                   Australian cuts rile researchers 2014-Oct-08 \n                 \n                   Australian budget hits science jobs 2014-Jul-01 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19315", "url": "https://www.nature.com/articles/nature.2016.19315", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Swedish institute has \u201clost confidence\u201d in artificial-windpipe pioneer Paolo Macchiarini after allegations of ethical breaches. The Karolinska Institute (KI) in Stockholm is ending its association with acclaimed but controversial surgeon Paolo Macchiarini, who pioneered transplants of artificial windpipes but has been accused of ethical breaches in his work.\u00a0 Macchiarini\u2019s contract will not be renewed when it runs out in November 2016, the Karolinska  announced , and he has been asked to use his remaining time to phase out his research there. Macchiarini's head of department is also responsible for ensuring that \"the work of his research group is dismantled\", the institute says. The 4 February decision comes after  revelations in a Swedish documentary  that Macchiarini conducted operations in Krasnodar, Russia, on at least one patient who was not life-threateningly ill, and that he misrepresented the success of his prosthetic grafts in scientific publications. The programme has created uproar in Sweden, and led the KI to  announce earlier this week  that it was looking into the case. Now, the Karolinska has \u201clost confidence\u201d in Macchiarini, explains Claes Keisu, a press officer for the institute. \u201cHe has overexploited Karolinska's brand in his work in Krasnodar. His activities there has undermined KI\u2019s reputation and damaged the public\u2019s and the scientific community\u2019s trust in KI,\u201d Keisu says.\u00a0 The institute is also looking into discrepancies in the surgeon\u2019s CV, adds Keisu. Those allegations were first made in a  Vanity Fair  article . \n             Ethical questions \n           The surgeon\u2019s work was hailed as a game-changer in regenerative medicine when, in 2011, he implanted a plastic artificial trachea, using bioengineered stem cells, into a patient whose own windpipe had been damaged. Over the next three years, he carried out seven more synthetic trachea implantations \u2014 two more at the Karolinska, one in Illinois and four in Russia, where he heads a tissue engineering project. Six of the eight patients have died (from causes unrelated to the transplants, Macchiarini says), and one has been in intensive care since the procedure. The documentary,  made by SVT, Sweden's national broadcaster , was aired in January. It suggested that in Russia, Macchiarini implanted a trachea into a woman who was not in a life-threatening condition. That was news to the Karolinska\u2019s vice-chancellor Anders Hamsten, who  said in a statement  that the institute would never have approved Macchiarini\u2019s activities in Russia if they were as the documentary describes. Five months ago, Hamsten had  cleared Macchiarini  of allegations of misconduct in research papers \u2014 after an independent investigation had  found the surgeon guilty . The institute has not yet decided whether to reopen that investigation. But on 4 February it said it would open an external investigation into its own handling of the Macchiarini case, to be led by a lawyer and medical researchers who have not yet been appointed. Swedish prosecutors are also investigating the three procedures carried out at Karolinska, but have not made any charges. Macchiarini, a visiting professor at the KI since 2010, has not yet responded to  Nature \u2019s requests for comment after the latest Karolinska announcement. After the documentary, he said that he was \u201cin the process of presenting all the multidisciplinary conference discussions that were had around each patient's case \u2014 along with the ethical committee decisions that approved them \u2014 to the Karolinska Institute\u201d. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Artificial-windpipe pioneer under scrutiny again 2016-Feb-01 \n                 \n                   Artificial-windpipe pioneer cleared of misconduct 2015-Aug-28 \n                 \n                   Investigations launched into artificial tracheas 2014-Nov-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19336", "url": "https://www.nature.com/articles/nature.2016.19336", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Plan aims to decrease carbon dioxide produced by new aeroplanes. A United Nations panel has proposed the first global greenhouse-gas emissions standard for aircraft. The draft rule, released by the International Civil Aviation Organization (ICAO) on 8 February, applies to most commercial and business aircraft, including designs already in production. It would require minimal changes to aviation design over the next 12 years, and many environmentalists say that the proposal is inadequate to combat climate change. The plan \u2014 which would take full effect in 2028 \u2014 could decrease fuel consumption by new aircraft at cruising speed by an average of 4% compared with the current level, according to the International Council on Clean Transportation (ICCT), a non-profit research group based in Washington DC. The ICAO is expected to adopt the CO 2  standard later this year. But many environmental groups found the UN panel\u2019s action wanting. \u201dWe think that this is just woefully insufficient,\u201d says Vera Pardee, a lawyer with the Center for Biological Diversity in Oakland, California. She calls the requirements for new aircraft weak, and notes that the plan would not require any changes to aircraft that are already flying. \u201cICAO is not proposing to do anything about the existing fleet, and it could,\u201d she says. Daniel Rutherford, programme director for marine and aviation at the ICCT in San Francisco, California, agrees that the ICAO could have been much more aggressive. An ICCT study released last December found that manufacturers could reduce fuel consumption in new aircraft by 25% in 2024 and by 40% in 2034 in a cost-effective manner. These efficiency gains would come from improvements in engine technologies and aerodynamics, as well as reductions in aircraft weight. Nonetheless, Rutherford says, the new ICAO standard is a step forward. \u201cThese standards do tend to matter over time as you update them and make them more stringent,\u201d he adds. \n               Looking ahead \n             The ICAO process was designed to plug a gap in the  UN climate agreement  signed in Paris last December. That agreement did not address  growing emissions from international aviation  or  shipping , which together account for more than 3% of humanity\u2019s CO 2  output. In addition to the CO 2  standard, ICAO is working on a market-based offset mechanism that would levy a fee on international flights. In the meantime, individual countries are free to implement more-stringent standards for aircraft emissions, and environmentalists are gearing up for a fight. For instance, lawsuits from environmental groups helped to push the US Environmental Protection Agency (EPA) to begin developing its own greenhouse-gas standards for aircraft. Although the EPA has said that it is waiting to see what the ICAO\u2019s final rule looks like, Pardee notes that the United States did push for a stricter standard when the UN panel met this week in Montreal. That could be a sign that the US agency will pursue regulations that are tougher than the ICAO plan. If it fails to do so, environmentalists could sue the agency once again.\u00a0 Meanwhile, the ICAO is also developing a market-based offset mechanism to cap international aviation emissions by raising money to reduce emissions in other sectors, beginning in 2021. The discussions build on the European Union\u2019s decision in 2012 to include domestic aviation emissions in its Emissions Trading System. The EU plan  initially included international flights , too, but officials backed off to give the ICAO time to develop its own offset scheme. International aviation produced more than 492 million tonnes of CO 2  in 2014, making its output larger than that of the United Kingdom. And that figure is projected to skyrocket in the coming years, with more than 56,000 new aircraft projected to hit the skies by 2040, according to the Environmental Defense Fund (EDF), an environmental group based in New York City. The EDF says that CO 2  emissions from air travel and transport could triple or even quadruple over that period. With that in mind, EDF lawyer Annie Petsonk argues that the ICAO\u2019s proposed emissions standard sets an important precedent \u2014 and could create momentum for the panel\u2019s nascent market-based emissions measure, which could achieve larger reductions in greenhouse-gas output. \u201cIt\u2019s going to be a tough negotiation, but the global spotlight is now on ICAO to deliver,\u201d Petsonk says.\u00a0 \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Paris climate deal hinges on better carbon accountancy 2016-Jan-26 \n                   \n                     Talks in the city of light generate more heat 2015-Dec-21 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19339", "url": "https://www.nature.com/articles/nature.2016.19339", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Dark-fly project looks for changes that helped fruit flies to thrive without light. On 11 November 1954, Japanese ecologist Syuiti Mori placed a dark cloth over a captive colony of fruit flies and began one of evolutionary biology's longest-running lab experiments. Sixty-one years and some 1,500 generations later, researchers have now identified dozens of genetic variations that may help the flies\u2019 descendants to cope with life in total darkness 1 . The dark flies look just like normal fruit flies ( Drosophila melanogaster ), except for their slightly longer head bristles, which are used as sensory organs. They also seem to have a keener sense of smell, and a superior ability to find a mate in the dark, compared with normal flies. But despite a life shrouded in darkness, the dark flies are drawn to light and retain their circadian cycles, says Naoyuki Fuse, a geneticist at Kyoto University who became the steward of Mori's \u2018dark-fly\u2019 project in 2008; Mori himself died in 2007. In 2012, Fuse and his colleagues sequenced the dark-fly genome, identifying 220,000 single-letter differences in its DNA and several thousand larger DNA insertions or deletions, compared with a normal fruit-fly strain 2 . (Mori had started a control colony from the same fly population that was kept in normal lighting conditions, but this was lost after an incubator malfunctioned.) To determine which of the genetic variations might be helping the flies to adapt to total darkness, Fuse\u2019s team bred the dark flies with normal flies and followed how this hybrid population evolved over 49 generations, using genome sequencing. They reasoned that, if the hybrids were reared in the dark over many generations, genetic variants that helped the flies to adapt would become more common over time. \n             Super sniffers \n           Fuse\u2019s team came up with a list of 84 candidate genes, including several that are involved in sensing odours and chemicals in the environment, as well as producing pheromones. The results were published this month in the journal  Genes Genomes Genetics 1 . The authors speculate that alterations to these genes could help flies to detect pheromones better, explaining their increased ability to mate in the dark. Fuse hopes to test this hypothesis by inserting the dark-fly gene variations in normal flies using genome-editing technologies. \u201cIt's a really interesting study,\u201d says Richard Lenski, an evolutionary biologist at Michigan State University in East Lansing, whose team has been propagating a strain of  Escherichia coli  bacteria since 1988, over  more than 50,000 generations . Lenski\u2019s team has tracked how the bacteria adapt to new food sources by freezing samples every few months, and analyzing these records. \u201cIt's too bad that they don't have, as far as I know, frozen samples of the ancestral population's DNA and samples from all along the way,\u201d he adds. \u201cI think these types of long-term evolution system are very interesting, and there aren\u2019t that many of them,\u201d says Leonid Kruglyak, a geneticist at the University of California, Los Angeles. It should be possible to identify gene variants that have helped flies to adapt to the dark, but he says that the variants Fuse\u2019s team identified may have changed in frequency because of random \u2018genetic drift\u2019, not natural selection. \u201cBottom line: cool system, they\u2019re asking interesting questions, not clear they\u2019re getting the answers yet,\" Kruglyak says. Fuse says that the dark-fly project is important scientific heritage. But because his position at Kyoto University is not permanent, he is uncertain of the project\u2019s future. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19333", "url": "https://www.nature.com/articles/nature.2016.19333", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Asian powerhouse invests more of its economy into research than anyone else. TREND WATCH:  South Korea has opened up a clear lead as the world\u2019s most research-intensive economy, according to figures released last week by the Paris-based Organisation for Economic Co-operation and Development (OECD). In 2014, South Korea invested 4.29% of its gross domestic product (GDP) in research and development (R&D) \u2014 stretching ahead of Israel, which is ranked second with a 4.11% investment. The increase in South Korea is largely due to rising industrial investment, and the country is aiming to spend 5% of its GDP on research by 2017. China also continues to pour more into research. By 2014, the proportion of its GDP devoted to R&D had reached 2.05%, pulling away from the European Union, which invested 1.94%. In absolute terms, China\u2019s R&D spending is about one-third lower than that of Europe's. But the OECD says that when China\u2019s lower wages are taken into account, the nation\u2019s R&D purchasing power has \u2014 for the first time \u2014 surpassed that of the European Union. With a similar adjustment for purchasing power, China's 2014 spending on research is already 80% of that of the United States' in 2013, the latest year for which figures are available.  Forecasters suggest  that China will surpass the United States in R&D spending by the end of this decade. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   OECD Science and Technology Indicators \n                 Reprints and Permissions"},
{"file_id": "530142a", "url": "https://www.nature.com/articles/530142a", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Obtaining conclusive evidence either way could take years, say researchers. Public-health authorities are investigating whether the Zika virus has caused an apparent surge in the number of infants born with microcephaly, or abnormally small heads, in Brazil. But conclusively determining whether the mosquito-borne virus is to blame could take months to years, researchers say. Concerns rose after Brazil declared a national public-health emergency in November. As of 2\u00a0February, officials there had investigated 1,113 of 4,783 suspected cases of microcephaly reported since late last year, and confirmed 404 of them \u2014 17 of which have so far been linked to Zika. On 1\u00a0February, a committee convened by the World Health Organization said that a causal link between Zika and microcephaly is \u201cstrongly suspected, though not yet scientifically proven\u201d. That is not for a lack of effort. Work now under way includes case-control studies to compare rates of Zika infection in babies who are born with microcephaly and in those without it, as well as genetic sequencing of the virus and efforts to develop a molecular diagnostic test for Zika infection. Making progress has been difficult because scientists know relatively little about Zika; there is no easy-to-use test to diagnose infections; and physicians disagree about how to define microcephaly, says Bruno Andrade, an immunologist at the Fiocruz research institute in Bahia, Brazil. \u201cAll of this started less than two months ago \u2014 that\u2019s when everything stepped up,\u201d he says. \u201cWe are in the middle of this nightmare here.\u201d So far, two lines of evidence support a link between the virus and microcephaly. Microcephaly cases in Brazil started to rise around 6\u00a0months after authorities confirmed Zika transmission there, hinting that the defect might have been caused by  in utero  exposure to the virus. And researchers in Brazil have found traces of the virus, or antibodies to it, in the amniotic fluid, brains or spinal fluid of 15 fetuses and babies diagnosed with microcephaly. This is suggestive, but not conclusive. \u201cMost of us believe it\u2019s highly plausible that Zika is the cause of this epidemic of microcephaly, but we need additional evidence,\u201d says Albert Ko, an infectious-disease physician and epidemiologist at the Yale School of Public Health in New Haven, Connecticut. In the hope of producing more-definitive data, the Brazilian ministry of health is now setting up large studies. In one, researchers will follow up 6,000 pregnant women in northeastern Brazil to investigate the effects of Zika and of microcephaly. \n               Knowledge gaps \n             Epidemiological studies are often complex because Zika causes a relatively mild illness in adults and there is no widely deployed test for the virus. This means that most of the mothers who have participated in previous studies were never diagnosed with Zika, even if they had it. To address this problem, the Brazilian health ministry is now asking mothers whether they had Zika symptoms instead of whether they were diagnosed with Zika. But many researchers say that epidemiological data alone will not convince them of a link between Zika and microcephaly; they would like to see evidence of how and why the virus causes the condition. With this in mind, scientists are developing animal models to investigate Zika\u2019s effects on the body, such as which tissues it infects, and why fetal brains might be especially vulnerable. \u201cThere\u2019s a lot of basic work and research that we need to do,\u201d says Anthony Fauci, director of the US National Institute of Allergy and Infectious Diseases in Bethesda, Maryland. It\u2019s plausible, for instance, that Zika crosses from mother to baby through the placenta, as do some related viruses, such as West Nile virus. But these other viruses don\u2019t often cause infant brain damage, so it\u2019s not clear why \u2014 or how \u2014 Zika might, says David Morens, a senior adviser to Fauci. The virus may be toxic only while a fetus\u2019s brain is still developing its major structures, in the first two months of pregnancy. Or it may persist in the body for a long period, which would explain why Zika is seen in stillborn babies with microcephaly. \u201cIf the insult happened early on, then why is the virus present at seven months when the miscarriage occurs?\u201d Morens says. \u201cThere must be a combination of things going on.\u201d Another conundrum is what it is that makes these women and babies so vulnerable: the vast majority of women infected with Zika go on to have healthy babies. But whatever scientists ultimately discover about Zika, another major challenge remains: supporting the children born with microcephaly. Many are living in what Ko calls a \u201cvegetative state\u201d, and may go on to have seizures. That could be difficult for their families\u00a0\u2014\u00a0many of which are impoverished\u00a0\u2014\u00a0to bear. \u201cWe have to start settling down and think about how we\u2019re going to take care of these kids,\u201d Ko says. If there is a link between Zika and microcephaly, the number of babies affected by the condition could soar as the virus spreads, he cautions. \u201cWe have no idea how big it\u2019s going to get.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     The next steps on Zika 2016-Feb-02 \n                   \n                     Zika virus: Brazil's surge in small-headed babies questioned by report 2016-Jan-28 \n                   \n                     WHO Zika site \n                   \n                     CDC Zika site \n                   Reprints and Permissions"},
{"file_id": "530140a", "url": "https://www.nature.com/articles/530140a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "ASTRO-H will carry a technology that two earlier, ill-fated space telescopes failed to put into action. \n               Update: \n                After launching on 17 February, ASTRO-H has reached its intended orbit, says the \n                Japan Aerospace Exploration Agency \n               . The agency also says that it has  \n               renamed the craft Hitomi, the Japanese word for the pupil of the eye. Hitomi will remain in a \u2018critical operation phase\u2019 until 28 February; this will include tests of onboard navigation systems and of the deployment of its solar panels.  \n             Astronomers around the world are hoping that the third time will be the charm as Japan prepares to launch its largest space observatory ever. The telescope will use X-rays to study phenomena from black holes to dark matter and carries cryogenic imaging technology that flew on two previous missions \u2014 but met disaster both times. Weather permitting, a Japanese-built H-IIA rocket is scheduled to launch the probe, provisionally named ASTRO-H, from Tanegashima Space Center at 17:45 local time on 12\u00a0February. Once in orbit, the 2.7-tonne probe will stretch out to its maximum length of 14\u00a0metres, including a 6.4-metre boom that will host an imager capable of collecting high-energy, or \u2018hard\u2019 X-ray photons (see \u2018Spectra in space\u2019). The Japan Aerospace Exploration Agency (JAXA) leads the mission with an investment of \u00a531 billion (US$265 million), but there is also major participation from NASA, as well as institutions in six other nations and the European Space Agency (ESA). Studying X-ray emissions is the best way to observe a wide range of cosmic phenomena, from galaxy clusters to the super-heated accretion disks around black holes. But Earth\u2019s atmosphere is mostly opaque to radiation outside the visible spectrum, and particularly to X-rays and \u03b3-rays, meaning that most X-ray astronomy requires a satellite. The major existing X-ray satellites are NASA\u2019s Chandra X-ray Observatory and ESA\u2019s XMM-Newton, which both launched in 1999. These can analyse the constituent wavelengths of X-rays \u2014 the spectra \u2014 emitted by point-like objects such as stars. But ASTRO-H will be the first to provide high-resolution spectra for much more spread-out X-ray sources such as galaxy clusters, says Norbert Schartel, project scientist for XMM-Newton at ESA\u2019s European Space Astronomy Centre outside Madrid, who is also a member of ASTRO-H\u2019s ESA team. Spectra carry information about the velocity and turbulence of the plasma that pervades galaxy clusters, which in turn can reveal whether, and how, a cluster resulted from a merger of two smaller ones, says Christine Forman, a high-energy astrophysicist at Harvard University in Cambridge, Massachusetts. X-ray pictures of clusters, when combined with visible-light images, have also previously provided striking \u2014 although indirect \u2014 evidence for the existence of dark matter. ASTRO\u2011H should be able to help settle whether a 3.5-kiloelectronvolt X-ray signal seen in certain galaxies is a signature of dark matter decaying into photons \u2014 or something else, says Alexey Boyarsky, an astrophysicist at Leiden University in the Netherlands who  co-discovered the signal . ASTRO-H will also cover a broader range of wavelengths than most other missions, from \u2018soft\u2019, low-energy photons starting at 300\u00a0eV, through hard X-rays and right up to soft \u03b3-rays of 600\u00a0keV. But only the soft X-rays will have their spectra imaged to high resolution. At the heart of the instrument responsible for this \u2014 the Soft X-ray Spectrometer (SXS) \u2014 is an array of 36-pixel elements that must be kept at 0.05\u00a0degrees above absolute zero, well inside the main body of the craft. When a photon strikes one of the sensors, the temperature of the sensor rises slightly, causing its electrical conductivity to increase. The resulting change in voltage can be used to measure the energy of the original photon \u2014 and therefore its wavelength \u2014 with a precision of nearly one part in 1,000. The technology first took shape in 1984, when Richard Kelley, an astrophysicist at NASA\u2019s Goddard Space Flight Center in Greenbelt, Maryland, started designing sensors for Chandra. After NASA scaled back its ambitions for the observatory and scrapped that plan, Kelley and his team provided the spectrometer for a Japanese X-ray telescope called ASTRO\u2011E. But in 2000, the rocket that was supposed to put it into orbit crashed shortly after take-off. JAXA prepared a replacement mission, Suzaku, which reached orbit in July 2005 \u2014 only for disaster to strike again. The liquid helium used to keep a spectrometer\u2019s sensors cold has to be slowly released, or outgassed. But in Suzaku, a tiny amount of that helium accumulated inside the craft. This was enough to ruin the vacuum that was supposed to insulate the helium tank from the rest of the craft. The tank heated up faster than expected, causing the helium to boil off and vent into space within four weeks of launch. Unable to stay super-chilled, the spectrometer was crippled before it could start making observations, although Suzaku\u2019s other instruments continued to operate until the craft was decommissioned in 2015. For ASTRO-H, JAXA redesigned the tank with plumbing to outgas the helium straight into space. And to further guard against glitches, ASTRO-H project manager Tadayuki Takahashi, an astrophysicist at the University of Tokyo and ASTRO-H\u2019s project manager, pushed his collaboration to work without borders. \u201cUsually, international co\u00adalitions have clearly defined interfaces,\u201d with different laboratories providing isolated components of a spacecraft and its payload, says Takahashi. But ASTRO-H researchers regularly visited each other\u2019s labs, sometimes for months at a time. Kelley says that Takahashi forged a very open collaboration. \u201cTad understands that if you want to maximize the chances of success, you have to have no barriers,\u201d he says. \u201cEverybody has access to everything.\u201d Astronomers around the world will be allowed to request observing time with ASTRO-H. Each team will have exclusive access to the resulting data for one year, after which JAXA will make them publicly available \u2014 a model long adopted by NASA. ASTRO-H will be renamed after launch, although what it will be called is yet to be determined. A larger, higher-resolution version of the SXS is due to fly aboard Athena, an ESA-led X-ray astronomy mission planned for the late 2020s. Additional reporting by David Cyranoski \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Indian ASTROSAT telescope set for global stardom 2015-Sep-22 \n                   \n                     Crunch time for pet theory on dark matter 2015-Jan-21 \n                   \n                     Astrophysics: The heart of darkness 2014-Jan-15 \n                   \n                     Spacecraft aims to expose violent hearts of galaxies 2012-Mar-13 \n                   \n                     ASTRO-H \n                   \n                     ATHENA \n                   \n                     Suzaku status report \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19340", "url": "https://www.nature.com/articles/nature.2016.19340", "year": 2016, "authors": [{"name": "M. Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "On LIGO\u2019s big day,  Nature  chronicles the search for Einstein's predicted ripples in space-time. Scientists at the Laser Interferometer Gravitational-Wave Observatory (LIGO)  announced on 11 February  that they have detected gravitational waves: ripples in space-time that Albert Einstein predicted a century ago. LIGO, which is US-led, has sites in Hanford, Washington and Livingston, Louisiana.\u00a0 Nature  takes a pictorial look at the quest to track down of one of the most elusive quarries in physics. \n             June 1916: Einstein predicts ripples in the firmament \n           After formulating his  general theory of relativity , which holds that gravity is a distortion in space and time around massive objects, Albert Einstein ( pictured ) pondered what would happen when a mass is shaken. His answer, published a year after the theory, was that space-time would ripple and produce \u2018gravitational waves\u2019 moving outward from the mass at the speed of light 1 . He and other physicists immediately began arguing about whether the predicted waves were real, or just artefacts of the new mathematics involved. Einstein himself changed his mind several times. \n             June 1969: a detection is claimed \n           Joseph Weber ( pictured ), a physicist at the University of Maryland in College Park, believed that gravitational waves were real. In 1969, he announced that he had found them with a detector of his own invention: an aluminium cylinder, about 2 metres long and 1 metre in diameter, that \u2018rang\u2019 when it was struck by such a wave 2 . His result was never replicated, and was eventually rejected by nearly everyone except Weber himself. Nonetheless, his work drew many other researchers into the gravitational wave field. \n             1974: neutron stars provide a step forward \n           A more widely believed finding came from Joseph Taylor and his graduate student Russell Hulse. Working at the University of Massachusetts Amherst, they discovered 3 \u00a0the first known binary pulsar, dubbed PSR B1913+16 (artist's impression,  pictured ),\u00a0in 1974. It consisted of two neutron stars whipping around one another in a close orbit, and also spiralling inwards at exactly the rate predicted by Einstein\u2019s theory \u2014 if gravitational waves were carrying away their energy. Viewed as an indirect observation of gravitational waves, the find won Hulse and Taylor the 1993 Nobel Prize in Physics, with the citation: \u201cfor the discovery of a new type of pulsar, a discovery that has opened up new possibilities for the study of gravitation\u201d. \n             1990: enter LIGO \n           When scientists at the Massachusetts Institute of Technology and the California Institute of Technology submitted plans for huge detectors to find gravitational waves using a technique known as  laser interferometry , many researchers were strongly opposed to the project. They feared that it would divert huge amounts of money from other research and \u2014 moreover \u2014 never find anything. But the US National Science Foundation (NSF) approved the construction of LIGO in 1990, and in 1992 selected sites for the experiment\u2019s twin detectors: Hanford, Washington ( pictured ), and Livingston, Louisiana. The facilities were completed in 1999 and started collecting data in 2001. In 2010, the detectors were  shut down for upgrades , having found nothing. \n             March 2014: primordial wave claim \n           In 2014, a different type of evidence for gravitational waves was claimed, by the collaboration behind a South Pole-based instrument called BICEP2 (facility,  pictured ). The BICEP2 researchers said that they had  found \u2018B modes\u2019  \u2014 subtle microwave signals that they believed to be produced by \u2018primordial\u2019 gravitational waves generated by the Big Bang. But their analysis was subsequently revealed to be a mistake: the signal was  the result of interstellar dust particles  in our own Galaxy. \n             September 2015: Advanced LIGO \n           A hugely upgraded LIGO began its first observing run last September, with the ability to search for gravitational waves in a  much greater volume of space than its predecessor could . Advanced LIGO finished its first period of operation in January 2016. ( Pictured : an inspection at the Livingston detector.) \n             February 2016: LIGO claims success \n           At a packed press conference in Washington DC ( pictured , Gabriela Gonzalez, Rainer Weiss and Kip Thorne) on 11 February, scientists from the LIGO team announced that they had made the  first direct detection of gravitational waves . \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   General Relativity at 100 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19290", "url": "https://www.nature.com/articles/nature.2016.19290", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "But federal law prevents regulators from approving the technique. The US Food and Drug Administration (FDA) should approve clinical trials of a gene-therapy technique to create embryos with genetic material from three people, the US National Academies of Sciences, Engineering and Medicine said on 3 February. The goal would be to prevent mothers from passing down disabling or fatal genetic disorders. The controversial gene-therapy technique involves  replacing the faulty energy-producing mitochondria  in a mother's egg with healthy mitochondria from the egg of a second woman who does not carry the disease. The aim is to prevent the transmission of diseases caused by mutations in mitochondrial DNA. But concerns about the safety of mitochondrial replacement, and the psychological and social implications of children with three genetic parents,  have given US regulators pause . And a federal law approved late last year prevents the FDA from allowing any such trials in humans. In its report, the academy panel suggests limiting the tests of mitochondrial replacement to male embryos as a safety precaution. Male offspring would not be able to pass their modified mitochondria to future generations, because a child inherits its mitochondria from its mother. The report also outlines several extra steps to monitor the safety of mitochondrial replacement. These include making every attempt to follow the children born as a result of the technique for years and sharing the resulting data with scientists and the public. If mitochondrial replacement is proven safe in male offspring, it could be expanded to female embryos, the advisory panel said. The approach stands in contrast to that of the United Kingdom, which  last year approved mitochondrial replacement  with no restrictions on the sex of a modified embryo. Some ethicists who advised the UK government on the implications of mitochondrial replacement argued that the risks of the technique are poorly understood, so there is no justification for using one sex to quantify those risks. \n               Barriers to research \n             For Shoukhrat Mitalipov, a reproductive-biology specialist at the Oregon Health and Science University in Portland, the advisory panel\u2019s recommendation is a hollow victory. The FDA commissioned the US$1.1 million academy review in 2014 after Mitalipov applied to perform a clinical trial of mitochondrial replacement therapy with human embryos. But the fiscal year 2016 government spending bill enacted in December includes  language preventing the FDA  from approving any applications to implant modified human embryos into women. The FDA says that it cannot comment on any individual application, but confirms that the law covers mitochondrial transfer, even if the resulting genetic modifications cannot be passed to a third generation. \u201cThe future seems very hazy compared to a few months ago,\u201d Mitalipov says, given the restrictions included in the spending bill. Still, his lab is beginning to breed monkeys treated with mitochondrial replacement, with the hope of understanding how this genetic modification could affect subsequent generations of offspring. In an unusual move, the 2016 spending legislation also directs the FDA to appoint an independent committee \u2014 including experts from \u201cfaith-based institutions\u201d \u2014 to review the academy report and report back to Congress. The FDA says that it is reviewing the report and cannot comment on its future plans.\u00a0 Jeffrey Kahn, a bioethicist at Johns Hopkins University in Baltimore, Maryland, who led the academy panel, notes that it included a religious expert. As for the resulting report, he says, \u201dI feel like it's had a fairly rigorous review for all issues.\u201d Others disagree with the panel\u2019s conclusions. The new report \u201crealized all the concerns and leapt to the conclusion that things should go forward despite all the concerns,\u201d says Marcy Darnovsky, executive director of the non-profit Center for Genetics and Society in Berkeley, California, who has opposed mitochondrial replacement in humans on both safety and ethical grounds. Darnovsky says that she would like to see an international agreement and legislation to ban techniques that edit embryos\u2019 nuclear genomes. \u201cI would have more faith in the argument if allowing this technology isn\u2019t going to pave the way for more concerning forms of germline editing,\u201d she says.  \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     UK scientists gain licence to edit genes in human embryos 2016-Feb-01 \n                   \n                     US Congress moves to block human-embryo editing 2015-Jun-25 \n                   \n                     World hails UK vote on three-person embryos 2015-Feb-10 \n                   \n                     Scientists cheer vote to allow three-person embryos 2015-Feb-03 \n                   \n                     Reproductive medicine: The power of three 2014-May-21 \n                   \n                     Regulators weigh benefits of \u2018three-parent\u2019 fertilization 2013-Oct-15 \n                   Reprints and Permissions"},
{"file_id": "530018a", "url": "https://www.nature.com/articles/530018a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Research clusters emerge as the big success of Germany\u2019s Excellence Initiative \u2014 despite its focus on elite institutes. For many, Munich\u2019s fame rests on the Oktoberfest beer festival. But for astrophysicist Stephan Paul, what makes the Bavarian capital so charming is its universities\u2019 rise to stardom in studies on the origin and structure of the Universe. The region has long been a national hub for physics, but its appeal to theorists and particle physicists has soared in recent years thanks to a well-funded research programme that brings together the city\u2019s two large universities \u2014 the Technical University of Munich (TUM) and Ludwig Maximilian University (LMU) \u2014 and several Max Planck institutes in nearby Garching. \u201cThe research infrastructure here is top-notch and the concentration of expertise is quite unique,\u201d says Paul, a physicist at the TUM who coordinates the programme. The programme is one of  43 \u2018clusters of excellence\u2019  launched in 2011 as part of Germany\u2019s \u20ac4.6-billion (US$5-billion) Excellence Initiative. The clusters are among the ten-year-old initiative\u2019s most tangible successes, according to a major report released on 29\u00a0January by an independent, international panel (see  go.nature.com/qxo768 ). The hubs bring together research groups \u2014 either within a university or across different institutes in the same region \u2014 that previously had little contact, so that they can pool their facilities and build on each other\u2019s successes. \u201cWe were surprised to find out how much good science there was just around the corner,\u201d says Paul. The report, commissioned by Germany\u2019s federal government and its 16\u00a0state governments, strongly recommends that they continue the excellence initiative, in particular the highly successful clusters. The report is less conclusive on the initiative\u2019s success in achieving its much higher-profile goal: to produce a top-ranked research powerhouse akin to Harvard University or the universities of Oxford or Cambridge. \u201cThe high quality of science produced at the clusters of excellence is particularly impressive,\u201d says Dieter Imboden, a Swiss environmental physicist and long-time science manager who chaired the evaluation panel. \u201cBut we are only at the beginning of a long road towards the group of global top universities.\u201d Since it began, the initiative has designated a few universities as \u2018elite\u2019 \u2014 the latest assignment gave the status to 11\u00a0universities, including the TUM and the LMU \u2014 and rewarded them with an extra \u20ac10\u00a0million to \u20ac14\u00a0million per year. A report published last September by Germany\u2019s main research-funding agency, the DFG, noted that these 11 universities have markedly increased their scientific output. A  further analysis done last year by  Nature  found that at elite institutions, the proportion of publications that feature in the top 10% of the world\u2019s most highly cited papers had almost doubled since 2002 (although  Nature  also found that the same was true on average of five good, but not elite, German universities). But the new elite universities still lag far behind the likes of Oxford and Harvard in terms of world rankings, appeal to top scientists and funding. Critics of the initiative say that it has created a two-tier research system and an excessive administrative burden. Even scientists at the \u2018elite\u2019 universities agree that the jury is still out on the success of the concept (see \u2018Germany\u2019s elite?\u2019). \u201cThe initiative has created a palpable \u2018we can do it\u2019 spirit,\u201d says Stephan Leibfried, a social scientist and research-policy specialist at the University of Bremen, which has elite status. But reaching the top of international university rankings \u201cwill require decades of hard work\u201d. \u201cNo matter how often you might try, a Harvard can\u2019t be pulled, like a rabbit, out of the hat,\u201d agrees Stefan Hornbostel, a science-policy researcher at the Humboldt University of Berlin, another of the latest 11 universities to be labelled elite. The report recommends a two-year extension of the current programme, which ends in 2017, followed by a new programme starting in 2019. It suggests that no more than 10\u00a0institutions should receive the elite bonus in the future, and that prolonged support of promising research clusters should be at the core of a renewed excellence programme. The report also says that in the follow-up regime, \u201csmaller disciplines\u201d deserve proportionally more funding than in the past and that research clusters could span geographically distant universities. The recommendations are non-binding but are sure to feed into the decision of federal and state governments on whether to continue the initiative, which is due by June. For Paul and his team, who have received some \u20ac70\u00a0million from the programme so far, the prospect of renewed support comes at the right time. Since 2006, some 150 physicists have moved from leading institutes in Europe and overseas to Munich. Researchers there have started to operate a newly built ultracold neutron facility and an underground laboratory largely shielded from background radiation, both financed in part with money from the initiative. Key experiments at these new facilities, says Paul, might shed light on the properties of neutrino particles, the design of the early Universe and the elusive nature of dark matter. The collaborations enabled by the Excellence Initiative have produced some \u201cgood friction\u201d, he says. \u201cNow we need to start using the heat.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Germany claims success for elite universities drive 2015-Sep-04 \n                   \n                     Germany's researchers welcome \u20ac5-billion funding boost 2015-Apr-17 \n                   \n                     Federal boost for German science 2014-Jun-04 \n                   \n                     Germany hits science high 2013-Sep-18 \n                   \n                     Germany: Excellence revisited 2012-Jul-25 \n                   \n                     Excellence Initiative \n                   \n                     Evaluation of the Excellence Initiative (PDF) \n                   \n                     Excellence Cluster Origin and Structure of the Universe \n                   Reprints and Permissions"},
{"file_id": "530017a", "url": "https://www.nature.com/articles/530017a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Industry and researchers push for ways to assess memory and concentration deficits. In the past quarter of a century, a wave of drugs has transformed the treatment of depression. But the advances have struggled to come to grips with symptoms that often linger long after people start to feel better: cognitive problems such as memory loss and trouble concentrating. On 3 February, the US Food and Drug Administration (FDA) will convene a meeting of its scientific advisers to discuss whether such cognitive impairments are components of the disorder that drugs might be able to target\u00a0\u2014\u00a0or just a result of depressed mood. The discussion will help the agency to decide whether two companies that sell the antidepressant vortioxetine should be allowed to label it as a treatment for the cognitive effects. A \u2018yes\u2019 could spur drug developers to invest in ways to test cognitive function during their antidepressant trials. Psychiatrists have long noted that some people with depression also struggle to concentrate and to make decisions. The question has been whether such difficulties are merely an offshoot of altered mood and would thus clear up without specific treatment, says Diego Pizzagalli, a neuroscientist at McLean Hospital, an affiliate of Harvard Medical School in Belmont, Massachusetts. But some patients who report improved mood after treatment still struggle with cognitive deficits\u00a0\u2014\u00a0so psychiatrists sometimes prescribe concentration-enhancing drugs that are approved to treat attention deficit hyperactivity disorder to people with depression. The scenario is a familiar one for those who treat schizophrenia: antipsychotic drugs may drive away hallucinations, but the cognitive deficits persist. And the deficits make it difficult for people with schizophrenia to keep jobs or to live independently, says Michael Green, a neuropsychologist at the University of California, Los Angeles. \n               Long lead time \n             More than a decade ago, companies waged a campaign to encourage drug regulators to recognize cognitive impairment in schizophrenia. But the FDA refused to do so until drugmakers came up with uniform criteria to measure the impairments. As a result, the schizophrenia community built a consensus around a battery of tests for use in clinical trials. In the case of depression, tests would have to be especially sensitive because the cognitive impairments can be more subtle than those that accompany schizophrenia, says Richard Keefe of the Duke Institute for Brain Sciences in Durham, North Carolina. Researchers and industry representatives discussed the problem of cognitive impairment in depression at a workshop held by the US Institute of Medicine (now the National Academy of Medicine) almost a year ago, but they did not set a course for establishing uniform assays. And even if tests acceptable to the FDA can be established, that is no guarantee that effective drugs will soon follow. Guidelines governing schizophrenia trials were established in 2005, but no cognitive-function drug has yet been approved in such cases. Furthest along is the company Forum Pharmaceuticals in Waltham, Massachusetts, which is conducting late-stage clinical trials of encenicline \u2014 a drug that targets the memory-related nicotinic protein acetylcholine receptor \u03b17. Results are expected in the first half of this year. But interest in cognitive drugs for people with depression is building as more and more antidepressants become available in cheap, generic forms and pharmaceutical companies seek to carve out niches for their newer, more expensive offerings, says psychiatrist Eduard Vieta at Spain\u2019s University of Barcelona. \u201cCompanies are changing strategies, and trying to find indications that are not the typical ones,\u201d he says. \u201cWhen you can speak about an indication that nobody else has \u2014 like cognition in the context of depression \u2014 it\u2019s a huge advantage.\u201d In making the case for vortioxetine, Takeda Pharmaceutical Company in Osaka, Japan, and H. Lundbeck in Valby, Denmark, cite clinical-trial data showing that the drug led to improvements in several cognitive tests, apart from its effect on mood. If the FDA does decide to recognize cognitive dysfunction as a treatable aspect of depression, the effects could also reach beyond the pharmaceutical industry, says Green. \u201cIt\u2019s a matter of respecting an aspect of the illness that we\u2019ve always thought wasn\u2019t getting enough attention,\u201d he says. \u201cThe more visibility there is on these deficits, the better.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               \n                     Dog DNA probed for clues to human psychiatric ills 2016-Jan-26 \n                   \n                     Monkeys genetically modified to show autism symptoms 2016-Jan-25 \n                   \n                     Director of US mental-health institute leaves for Google 2015-Sep-15 \n                   \n                     First robust genetic links to depression emerge 2015-Jul-15 \n                   \n                     Medical research: If depression were cancer 2014-Nov-12 \n                   \n                     Nature  special: Depression \n                   \n                     FDA meeting announcement \n                   \n                     IOM workshop: Cognitive Dysfunction in Depression \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19270", "url": "https://www.nature.com/articles/nature.2016.19270", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Team at Francis Crick Institute permitted to use CRISPR\u2013Cas9 technology in embryos for early-development research. Scientists in London have been granted permission to edit the genomes of human embryos for research, UK fertility regulators  announced . The 1 February approval by the\u00a0UK Human Fertilisation and Embryology Authority (HFEA) represents the world's first endorsement of such research by a national regulatory authority. \"It\u2019s an important first. The HFEA has been a very thoughtful, deliberative body that has provided rational oversight of sensitive research areas, and this establishes a strong precedent for allowing this type of research to go forward,\" says George Daley, a stem-cell biologist at Boston Children's Hospital in Massachusetts. The HFEA has approved an application by developmental biologist Kathy Niakan, at the Francis Crick Institute in London, to use the genome-editing technique CRISPR\u2013Cas9 in healthy human embryos. Niakan\u2019s team is interested in early development, and it plans to alter genes that are active in the first few days after fertilization. The researchers will stop the experiments after seven days, after which the embryos will be destroyed. The genetic modifications could help researchers to develop treatments for infertility, but will not themselves form the basis of a therapy. Robin Lovell-Badge, a developmental\u00a0biologist at the Crick institute, says\u00a0that the\u00a0HFEA\u2019s decision will embolden other researchers who hope to edit the genomes of human embryos. He has heard from other UK scientists\u00a0who are\u00a0interested in pursuing embryo-editing research, he says, and\u00a0expects\u00a0that\u00a0more applications will follow. In other countries, he says, the decision \u201cwill give scientists\u00a0confidence to either apply to their national regulatory bodies, if they have them, or just to go ahead anyway\u201d. \n               Development genes \n             Niakan\u2019s team has already been granted a licence by the HFEA to conduct research using healthy human embryos that are donated by patients who had undergone  in vitro  fertilization (IVF) at fertility clinics. But in September last year, the team announced that it had  applied to conduct genome editing  on these embryos \u2014 five months after researchers in China reported that they had used  CRISPR\u2013Cas9 to edit the genomes of non-viable human embryos , which  sparked a debate  about how or whether to draw the line on gene editing in human embryos. At a press briefing last month, Niakan said that her team could begin experiments within \u201cmonths\u201d of the HFEA approving the application. Its first experiment will involve blocking the activity of a \u2018master regulator\u2019 gene called  OCT4 , also known as  POU5F1 , which is active in cells that go on to form the fetus. (Other cells in the embryo go on to form the placenta.) Her team plans to end its test-tube experiments within a week of fertilization, when the fertilized egg has reached the blastocyst stage of development and contains up to 256 cells. \u201cI am delighted that the HFEA has approved Dr Niakan\u2019s application,\u201d said Crick director Paul Nurse in a statement. \u201cDr Niakan\u2019s proposed research is important for understanding how a healthy human embryo develops and will enhance our understanding of IVF success rates, by looking at the very earliest stage of human development.\u201d A local research ethics board (which is similar to an institutional review board in the United States) will now need to approve the research that Niakan\u2019s team has planned. When approving Niakan's application, the HFEA said that no experiments could begin until such ethics approval was granted. \n               International impact \n             Sarah Chan, a bioethicist at the University of Edinburgh, UK, says\u00a0that\u00a0the decision will reverberate well beyond the\u00a0United Kingdom. \u201cI think this will be a good example to countries who are considering their approach to regulating this technology. We\u00a0can have a well-regulated system that is able to make that distinction between research and reproduction,\u201d she says. It remains illegal to alter the genomes of embryos used to conceive a child in the United Kingdom, but researchers say\u00a0that\u00a0the decision to allow embryo-editing research could inform the debate over deploying gene-editing in embryos for therapeutic uses in the clinic. \u201cThis step in the UK will stimulate debate on legal regulation of germline gene editing in clinical\u00a0settings,\u201d says Tetsuya Ishii, a bioethicist at Hokkaido University in Sapporo, Japan, who notes that some countries do not explicitly prohibit reproductive applications. \u201cThis type of research should prove valuable for understanding the many complex issues around germline editing,\" adds Daley. \"Even though this work isn\u2019t explicitly aiming toward the clinic, it may teach us the potential risks of considering clinical application.\u201d \n                 Tweet \n                 Facebook \n                 weibo \n               \n                     UK scientists apply for licence to edit genes in human embryos 2015-Sep-18 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19316", "url": "https://www.nature.com/articles/nature.2016.19316", "year": 2016, "authors": [{"name": "Heidi Ledford"}, {"name": "Sara Reardon"}, {"name": "Richard Monastersky"}, {"name": "Alexandra Witze"}, {"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "But many research advocates worry that the proposal could backfire in the face of political opposition. With less than a year before he leaves office, US President Barack Obama is making a strong push to increase spending on scientific research. His fiscal year 2017 budget plan, released on 9 February, calls for a 4% bump in research and development funding across the federal government. But science advocates and lawmakers alike say that they\u2019re unhappy with Obama\u2019s decision to boost science by relying on \u2018mandatory\u2019 spending. Normally, research funding is \u2018discretionary\u2019, meaning that Congress decides how much money each agency will receive. But lawmakers have little leeway to adjust mandatory programmes, which must be supported by a dedicated revenue stream \u2014 such as the oil tax that Obama has proposed should go to fund some clean-transportation programmes. That makes them a tough sell to Congress, which must approve the government\u2019s budget. Most major science agencies would receive some mandatory funding under Obama\u2019s proposed 2017 budget. In many cases, those mandatory spending proposals offset a reduced or flat discretionary budget, notes Matt Hourihan, director of the research and development budget and policy programme at the American Association for the Advancement of Science in Washington DC. \u201cThat in and of itself is problematic,\u201d he says. \u201cMandatory spending is often better seen as a supplement \u2014 not a long-term solution.\u201d If Congress does not adopt the mandatory spending proposal for the US National Institutes of Health (NIH), for example, the NIH budget would drop by US$1 billion, based on the president\u2019s budget. The budget of the National Science Foundation (NSF) would increase by roughly 1%. But science agencies may still escape cuts if \u2014 as expected \u2014 Congress rejects the mandatory proposals. \u201cOver the past few years, Congress has done a good job of trying to prioritize science and technology spending as much as they can,\u201d says Hourihan, who notes particularly  strong support in Congress for the NIH and NASA . Lawmakers will not have as much freedom to boost science budgets as they did last year, however. A two-year budget deal struck last December increased discretionary spending by 5.2% in fiscal year 2016, but requires that it remain essentially flat in 2017. Here,  Nature  breaks down how various agencies fare in the White House budget request. \n             National Institutes of Health \n           Obama is requesting $33.1 billion for the NIH \u2014 $825 million, or 2.6%,  over the 2016 level . But this total includes about $1.8 billion in mandatory spending that masks a major cut to the NIH\u2019s discretionary budget. \u201cIt\u2019s an increase in the same way as saying \u2018I\u2019m going to increase my household budget because I bought a Powerball [lottery] ticket,\u201d says Jennifer Zeitzer, director of legislative affairs at the Federation of American Societies for Experimental Biology in Bethesda, Maryland. Yet NIH director Francis Collins is not worried. \u201cIt would be astounding if Congress approves a cut in NIH funding,\u201d he says, noting that lawmakers increased the agency\u2019s budget by 6.6% in 2016, compared with the previous year. Moreover, he adds that Congress has shown some support for the concept of mandatory biomedical spending. In 2015, the House of Representatives passed a bill to reform the Food and Drug Administration (FDA) that also included $1.75 billion per year in mandatory funds for the NIH. Meanwhile, Senate lawmakers are developing seven smaller, related bills that may also include mandatory funding. Within Obama\u2019s request, the National Cancer Institute would receive $680 million for the  cancer \u2018moonshot\u2019 , an effort to cure cancer that will focus on research areas such as genomics and \u2018big-data\u2019 analyses. Collins says that the agency has not yet decided whether the project will parcel its money out in small grants or pursue large initiatives. He says that the NIH will soon appoint an advisory panel to begin discussing the effort\u2019s structure. The Precision Medicine Initiative, a longitudinal study to  track the health of one million Americans , would receive $300 million. The project aims to begin recruiting participants this summer, Collins says. And the NIH\u2019s portion of the  Brain Research through Advancing Innovative Neurotechnologies  (BRAIN) initiative would receive $195 million. \n             National Science Foundation \n           Obama has requested $8.0 billion for the NSF, a healthy 6.7% increase over the 2016 estimate. But the bulk of that jump would come from $400 million in mandatory spending, a more difficult sell to Congress. Much of that extra money would go to support younger researchers, who face greater competition in winning research grants than more established scientists. Without that additional funding, the agency would see an increase of only $101 million, or 1.3%. In a sign of the difficult battles the agency has had this year with Congress  over funding for social sciences and geosciences , the NSF has made it a priority to sell itself as a key component in feeding economic growth and improving national security. \u201cThe money spent on basic resesarch is not optional in a successful economy,\u201d says agency director France C\u00f3rdova. \u201cIt\u2019s a necessary investment that will insure the US remains the birthplace of new ideas and great discoveries.\u201d Among its major priorities, the NSF would spend $512 million on research and education in renewable and alternative energy, and another $142 million on brain research \u2014 about half of which would support the BRAIN Initiative. The agency proposes to spend $176 million on research related to advanced manufacturing and $150 million for its ongoing programme in cybersecurity. A total of $43 million would go to research aimed at improving prediction and resilience in natural and human-caused disasters. Ocean science would benefit from a $106-million request to build  two additional research ships . The $8-billion funding request would provide enough for 10,100 new research grants, about 900 more than the 2016 budget supports. That would increase funding rates from 22% of proposals to 23%. \n             NASA \n           The budget request for NASA is $19 billion \u2014 $300 million less than Congress gave the agency in 2016. Funding for its science division would remain essentially flat, at $5.6 billion. Within that, though, there are some clear winners and losers. Earth sciences would get a $111-million boost to $2 billion, to continue the development of missions such as the IceSAT-2 cryosphere-monitoring satellite and a follow-on to the GRACE gravity satellites  that measure changes in groundwater  and ice. Notably, the request would accelerate plans for the next  Landsat remote-sensing satellite . Landsat 8 suffered a problem with its thermal-infrared imager after its 2013 launch, and some had suggested launching an interim sensor, on a free-flying satellite, as a temporary supplement. Obama has instead bowed to congressional pressure to accelerate the launch of Landsat 9 by several years, to 2021. \u201cCongress loves Landsat,\u201d says Steve Running, a forest ecologist at the University of Montana in Missoula and chair of an Earth sciences panel that advises NASA. Even as Earth sciences rise, planetary science would drop by nearly the same amount, to $1.519 billion. That\u2019s still more than the White House has proposed in recent years, an apparent concession to Congress, which keeps tucking additional monies into the planetary budget. \u201cWe\u2019re misaligned between how the administration wants to move forward and how Congress wants to move forward,\u201d says Casey Dreier, director of space policy at the Planetary Society in Pasadena, California. A perennial sticking point between the White House and Congress, a mission to  Jupiter\u2019s moon Europa , would receive $49.6 million. Last year, the White House requested $30 million for the programme; Congress instead showered it with $175 million and stipulated that it include a lander and be launched on the new heavy-lift Space Launch System (SLS) rocket no later than 2022. NASA has yet to figure out how the mission \u2014 an envisaged multiple fly-by of the icy moon \u2014 could also carry a lander. And the SLS rocket may or may not be ready in time for a 2022 launch. For 2017, Obama proposes to slash SLS funding from $2 billion to $1.3 billion, a move that Congress will almost certainly ignore. \u201cThis administration cannot continue to tout plans to send astronauts to Mars while strangling the programmes that will take us there,\u201d said Representative Lamar Smith (Republican, Texas), chair of the House committee that oversees NASA, in a statement. As for NASA\u2019s idea to  bring an asteroid into lunar space  for astronauts to study, the budget request allocates $217 million. A robotic spacecraft could launch in 2023or earlier to retrieve the asteroid, with astronauts visiting the rock in 2025, said the agency\u2019s chief financial officer, David Radzanowski. But asteroid experts have questioned  the scientific return and technical feasibility  of such a plan. Meanwhile, the NASA astrophysics budget continues development of the James Webb Space Telescope, due to launch in 2018, and the Wide-Field Infrared Survey Telescope, for launch in the following decade. The Stratospheric Observatory for Infrared Astronomy (SOFIA), a telescope-in-a-plane, would be fully funded at $84 million after the Obama administration  attempted to kill it  two years ago. \n             Department of Energy \n           Within the Department of Energy (DOE), the Office of Science would receive $5.7 billion, an increase of 6% over 2016. The largest increases in its portfolio would go to the advanced computing, basic energy sciences, and biological and environmental research programmes. The only significant decrease would be for nuclear fusion, which would see its funding cut by 9%, to $398 million. ITER, an international effort to build a fusion-energy plant, would receive $115 million. The  Advanced Research Projects Agency \u2013 Energy  (ARPA-E) would get $500 million, a 72% increase over 2016 spending; $150 million of that would be new mandatory funds. The White House also proposes to increase the agency\u2019s budget to $1 billion by 2021. This year\u2019s budget includes a multi-agency proposal to double federal spending on clean-energy research and development, from $6.4 billion in 2016 to $12.8 billion in 2021. The fiscal 2017 budget includes $7.7 billion towards this goal. Around 80% of that money would be funnelled through the DOE, although 12 agencies are included in the effort. The DOE contribution to the initiative includes $880 million for research on vehicles and renewable fuels, $804 million for nuclear-energy programmes and $564 million for a range of fossil-energy research, including  technologies to capture and sequester carbon dioxide . Mark Muro, a senior fellow who studies innovation at the Brookings Institution, a think tank in Washington DC, says that the Republican-controlled Congress may not reject the plan outright, despite its general opposition to Obama\u2019s climate policies. Innovation, technology and jobs are issues that have traditionally enjoyed bipartisan support, and they are key components of the clean-energy proposal. But Obama\u2019s proposal for a new tax on oil, which would increase investment in clean-transportation infrastructure by roughly 50%, has already come under Republican attack. Oil companies would pay $10 per barrel of oil, to be phased in over five years. At current consumption rates, such a fee could raise up to $70 billion annually. \n             Coast Guard \n           In a move sure to be welcomed by polar scientists, the Coast Guard would get $150 million to complete the design of a new icebreaker. The US government has only two such vessels, the heavy but ageing  Polar Sta r and the middleweight  Healy  that operates mainly in the Arctic.  This limited fleet  has sometimes forced the government to rent Russian icebreakers to clear a path to its McMurdo Station in Antarctica. \u201cWe\u2019d really like a heavy icebreaker so that, no matter what the season, even in midwinter, we have the capability to go where we need to go,\u201d says Julie Brigham-Grette, a palaeoclimatologist at the University of Massachusetts in Amherst who chairs a national polar research board. In September, Obama said that he would accelerate the push to acquire a heavy-duty icebreaker to 2020 from 2022, at an expected cost of roughly $1 billion. \n             Food and Drug Administration \n           The FDA, which has responsibilities that range from approving new drugs to overseeing aspects of food safety, would receive $5.1 billion in fiscal year 2017 \u2014 an increase of 8% over the 2016 budget. The bulk of that increase, $269 million, would come from user fees collected from industry stakeholders, including food producers and pharmaceutical companies. For Steven Grossman, deputy executive director of the Alliance for a Stronger FDA in Washington DC, the numbers are a disappointment. \"The increase doesn't reflect what the agency does and how much more it's required to do each year,\" he says. Grossman points to increased responsibility in monitoring drug production overseas, evaluating and approving \u2018biosimilar\u2019 versions of complex biological drugs and implementing the 2011 Food Safety Modernization Act as examples of the growing burden on the agency. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   White House Office of Management and Budget: Fiscal year 2017 budget request \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19259", "url": "https://www.nature.com/articles/nature.2016.19259", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Organization says spike might be the result of heightened awareness because of possible link to Zika \u2014 but not everyone agrees. Researchers at the body responsible for monitoring birth defects in Latin America are questioning the size of an apparent surge in the number of Brazilian children born with 'microcephaly' \u2014 abnormally small heads and brains. Alarm is growing about a reported rise in suspected cases of the rare condition, which has been tentatively linked to the rapid spread of the Zika virus through the Americas. But Jorge Lopez-Camelo and Ieda Maria Orioli, from the Latin American Collaborative Study of Congenital Malformations ( ECLAMC ), say that the surge might largely be attributed to the intense search for cases of the birth defect, and misdiagnoses, because of heightened awareness in the wake of the possible link with Zika. This \u2018awareness\u2019 effect is well known and inevitable, they say, and must be revealing cases that would have gone unnoticed under normal circumstances. They also say that a high rate of misdiagnoses among reported cases is likely because the diagnostic criteria being used for microcephaly are broad. Lopez-Camelo and Orioli presented their analysis in  Portuguese-language reports , and, after  Nature \u2019s enquiries, provided an English version of the summary ( ECLAMC Report  ). They say that from the epidemiological data available, it is impossible to establish the true size of the surge in microcephaly, and whether there is any link with the Zika virus. In particular, large 'prospective' studies, in which pregnant women in areas of Brazil experiencing Zika outbreaks are monitored to see how many of their children develop microcephaly are needed, they say. Several research groups in and outside Brazil are already planning such studies, and some have begun. Specialists contacted by\u00a0 Nature \u00a0emphasize that it is prudent for pregnant women to be cautious \u2014 for example, by protecting themselves against mosquito bites \u2014 until more is known. The experts agree that the reported size of the microcephaly increase so far is probably inflated \u2014 and this chimes with the latest figures from the Brazilian government. On 27 January, it said that of 4,180 suspected cases of microcephaly recorded since October, it has so far confirmed 270 and rejected 462 as false diagnoses. But some disagree with the ECLAMC team's conclusion that the reported surge in recent months can mostly be attributed to an increase in the intensity of the search for cases and misdiagnosis. Thomas Jaenisch, a tropical medicine specialist at the Heidelberg University Hospital in Germany, calls this an \u201cextreme\u201d position and says that it \u201cmight also create uncertainty in the media and public discussion in Brazil\u201d. \n               Mild symptoms \n             Previously confined to Africa and Asia, Zika virus reached the Americas in 2015, where it is currently causing an unprecedented epidemic in Brazil (see 'Zika in the Americas'). Most people infected with the virus \u2014 after being bitten by a mosquito \u2014 have no symptoms; the remainder have mild symptoms such as fever, skin rash and headache. But in October, Brazil's health ministry reported an unusual spike in reported cases of microcephaly in the northeastern state of Pernambuco, where the affected children's mothers had been in early pregnancy at around the same time as large Zika outbreaks occurred. The ministry subsequently raised the alarm of a possible link to Zika.  This led the World Health Organization and its regional office, the Pan American Health Organization (PAHO), to issue an epidemiological alert on 17 November last year, which called on member states to look out for any similar increase in microcephaly among their populations. Earlier this month, the US Centers for Diseases Control and Prevention issued a travel notice, \u201cout of an abundance of caution\u201d, that advised pregnant women to consider postponing travel to places that have ongoing Zika outbreaks. To investigate the situation, the researchers at ECLAMC turned to its own databases dating back to 1967, as well as the country's Live Birth Information System (SINASC). According to ECLAMC, the average historical prevalence of microcephaly in Brazil is around 2 cases per 10,000 births, although rates in the country's north have typically been higher. The researchers calculate that the maximum number of cases that would have been expected in the northern state of Pernambuco in 2015 is around 45. Yet Pernambuco reported 26 times that number last year. Even if Zika is causing microcephaly, these huge numbers are simply too high to be credible, says the report. \n               Increased surveillance \n             As well as the increased diagnoses owing to heightened awareness from the media and governments, Lopez-Camelo also highlights that the diagnostic criteria for microcephaly are relatively unspecific https://poly-admin1.nature.com/polopoly/CM#_msocom_2  and are casting too wide a net. Brazilian health authorities are treating all fetuses with head circumferences that are more than two standard deviations below the average, and newborns with a head circumference of less than 32 centimetres, as suspected cases. But these criteria will inevitably capture many healthy children within the normal growth range who do not have microcephaly. But head circumference is only a proxy measure, note Lopez-Camelo and Orioli: confirming microcephaly requires a diagnosis of small brain size, and a decreased rate of brain growth. The pair are not alone in drawing attention to the broad diagnostic criteria \u2014 a risk assessment published on 21 January by the European Centre for Disease Prevention and Control (ECDC) also noted this and said: \u201cIt is expected that many of the suspected cases will be reclassified and discarded.\u201d Helen Dolk, an epidemiologist at the University of Ulster near Belfast, UK, who works on the surveillance of congenital abnormalities, says that the ECLAMC\u2019s conclusion \u2014 that the apparent surge could be largely an artefact \u2014 is possible in principle. But she stresses that it is impossible to confirm until more data becomes available \u2014 and that she is reserving judgement on the portion of the apparent increase that can be attributed to confounding factors. \n               Real concern \n             Lavinia Sch\u00fcler-Faccini, a researcher at the Federal University of Rio Grande do Sul, Brazil, and president of the Brazilian Society of Genetic Medicine, says that she is certain that there has been a substantial increase in microcephaly cases. She notes that physicians began reporting a rise before the increased attention by health authorities, and the media began reporting a spike last November. \u201cMy personal impression is that there is an augmentation of cases of microcephaly in Brazil,\u201d she says. \u201cHowever it is not as huge as the suspected cases referred to the Ministry of Health.\u201d Prospective studies have started and others are planned, she says. And she adds: \u201cAll our efforts now are to establish the real level of increase.\u201d Establishing whether there is a link between microcephaly and Zika is particularly important because people living in the Americas lack immunity to the virus. This, combined with the fact that the  Aedes  mosquitoes that transmit the virus are widespread in the Americas, means that many people will be infected in future, including pregnant women. Zika virus has been found in amniotic fluid, placental or fetal tissues in several cases of nervous system malformations, including microcephaly, in Brazil. Following a World Health Organization press conference on Zika virus on 28 January, the agency said in a statement: \u201cA causal relationship between Zika virus infection and birth defects and neurological syndromes has not been established, but is strongly suspected.\u201d It also said: \u201cThe Organization is supporting the scaling up and strengthening of surveillance systems in countries that have reported cases of Zika and of microcephaly and other neurological conditions that may be associated with the virus.\u201d \n                 Tweet \n                 Facebook \n                 weibo \n               \n                     Global research priorities for infections that affect the nervous system 2015-Nov-18 \n                   \n                     How to beat the next Ebola 2015-Aug-05 \n                   \n                     US assesses virus of the Caribbean 2014-Aug-12 \n                   \n                     The global distribution and burden of dengue 2013-Apr-07 \n                   \n                     Europe on alert for flying invaders 2012-Sep-11 \n                   \n                     ECDC Zika site \n                   \n                     PAHO/WHO Zika site \n                   \n                     CDC Zika site \n                   \n                     ECLAMC  \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19261", "url": "https://www.nature.com/articles/nature.2016.19261", "year": 2016, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "Conceptual leap occurred over a thousand years earlier than historians thought. A reanalysis of markings on Babylonian tablets has revealed that astronomers working between the fourth and first centuries  bc  used geometry to calculate the motions of Jupiter \u2014 a conceptual leap that historians thought had not occurred until fourteenth-century Europe. The discovery was made by science historian Mathieu Ossendrijver at the Humboldt University in Berlin, who translated and interpreted five clay tablets that were marked with the tick-shaped imprints of the ancient cuneiform script 1 . The tablets were excavated in the late nineteenth century and are kept at the British Museum in London. By the seventh century  bc , astronomers in Babylonia \u2014 a state in Mesopotamia, present-day Iraq \u2014 were conducting detailed observations, largely for astrological forecasting. Previous cuneiform records have suggested that the astronomers predicted where planets would be using arithmetic methods. In fact, Ossendrijver\u2019s work suggests, the astronomers sometimes employed more geometric thinking. The inscriptions on the tablets show that they measured the daily apparent velocity of Jupiter (as seen from Earth) at different dates in its orbit. Then they used these velocities and times to deduce the distance that Jupiter must have travelled during the intervening period. That calculation is equivalent to the geometrical notion of plotting velocity against time, and calculating the area under that plot. Ossendrijver knew that four of the tablets described such calculations, and probably had to do with astronomy. But he wasn't sure about what was going on until he found and translated a fifth tablet in 2014, after receiving an old photograph of it from a colleague. That tablet contained a set of instructions for calculating Jupiter's movement using geometric principles \u2014 exactly the procedures laid out in the other tablets. \n             Right on track \n           This method of \u2018area-under-the-graph\u2019 calculation was explained in the fourteenth century by a group of scholars known as the Oxford calculators, working at Merton College in Oxford, UK. Their result was expressed in graphical terms around the same time by the French mathematician, philosopher and bishop Nicholas Oresme. Although the Babylonians never used graphs or geometric figures explicitly, it seems that they had already grasped the same method centuries earlier, Ossendrijver says. In this, they were even more sophisticated than the ancient Greeks, who used aspects of geometry in astronomy \u2014 they conceived of planets travelling in orbits \u2014 but didn\u2019t use the kinds of abstract constructions described by the tablets, which connect velocity, time and distance. Hermann Hunger, a specialist on Babylonian astronomy at the University of Vienna, says that the work marks a new discovery. However, he and Ossendrijver both point out that Babylonian mathematicians were well accustomed to geometry, so it is not entirely surprising that astronomers might have grasped the same points. \u201cThese findings do not so much show a higher degree of sophistication in geometric thinking, but rather a remarkable ability to apply traditional Babylonian geometric thinking to a new problem\u201d, Hunger says. Science historian Jens H\u00f8yrup at Roskilde University in Denmark says, however, that this might not be the first hint of geometric ideas in Babylonian astronomy. The thinking behind the forecasting of certain lunar configurations, he says, \u201calso shows kind of geometric combination of phenomena at the setting and rising positions of the Moon\u201d 2 . \n               Tweet \n               Follow @NatureNews \n             \n                   Archimedes\u2019 legendary sphere brought to life 2015-Sep-25 \n                 \n                   Famed Antikythera wreck yields more treasures 2014-Oct-10 \n                 \n                   Ancient astronomy: Mechanical inspiration 2010-Nov-24 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19255", "url": "https://www.nature.com/articles/nature.2016.19255", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Experts think that world champion Lee Sedol may still beat the AI software in a March contest. For decades, the ancient game of Go has stood out as the one board game that computers couldn\u2019t crack. Played by tens of millions of people across Asia, its complexity and subtlety meant that Go\u2019s top human players reigned supreme against the advance of artificial intelligence (AI). Now, for the first time, a computer has  beaten a human Go professional without the advantage of a handicap . AlphaGo, a program developed by Google\u2019s London-based company DeepMind, bested European champion Fan Hui in five games out of five. Nature  asked Fan what it\u2019s like to be beaten by a machine, and took predictions from other Go and AI aficionados about who will win when AlphaGo faces its ultimate challenge: playing against Lee Sedol, one of the game\u2019s greatest players, in March. \n             Fan Hui \n           \n             European Go champion \n           \"In China, Go is not just a game. It is also a mirror on life. We say if you have a problem with your game, maybe you also have a problem in life. Losing was very hard. Before I played with AlphaGo, I thought I would win. After the first game I changed my strategy and fought more, but I lost. The problem is humans sometimes make very big mistakes, because we are human. Sometimes we are tired, sometimes we so want to win the game, we have this pressure. The programme is not like this. It\u2019s very strong and stable, it seems like a wall. For me this is a big difference. I know AlphaGo is a computer, but if no one told me, maybe I would think the player was a little strange, but a very strong player, a real person. Of course, when I lost the game I was not happy, but all professionals will lose many games. So I lose, I study the game, and maybe I change my game. I think it\u2019s a good thing for the future.\" \n             Toby Manning \n           \n             Treasurer, British Go Association, and referee of Fan versus AlphaGo \n           \"Go players were aware that the game is one of the great unsolved problems in AI, so I think people were expecting that computers would reach professional human level, but the feeling was it was going to take another 10 years or so. In this match, I was expecting Fan Hui to win. The thing that struck me, playing through the games you couldn\u2019t tell who was the human and who was the computer. With a lot of software you find the computer makes a lot of sensible moves and suddenly loses the plot. But here, you couldn\u2019t tell which was which. The one thing that was not human was the way it managed its time. Fan Hui took longer over his moves than AlphaGo. And AlphaGo seemed to be not as aggressive as a human might have been. It would play very calmly rather than start a fight by invading territory or attacking a group of stones. I think the main reaction from the Go community will be, as indeed happened after IBM computer Deep Blue achieved grandmaster status in chess, is that people want to get hold of the software and use it in their own games to work out where they went wrong.\" \n             Hajin Lee \n           \n             Secretary general of the International Go Federation \n           \"When I first heard about this plan for a computer to challenge the top professional, Lee Sedol, I was really shocked. I thought this challenger must have no idea how strong the top player was, but actually it was I who had no idea how strong the computer was. Now I am very excited. Who will win? I don\u2019t know. Lee Sedol himself doubts that the computer is as strong [as he is]. But personally I had a chance to hear more about AlphaGo, and then I was just amazed how strong it was. I also personally know how strong Lee Sedol is, so I would say each has a 50% chance. I think Go still has a lot to offer, and I don\u2019t think the fact that computer AI can be stronger than humans diminishes the game at any level. I think people will accept that computer technology has advanced and find a way to use that to use that to the advantage.\" \n             Jonathan Schaeffer \n           \n             Computer scientist at the University of Alberta, Edmonton, Canada, and designer of Chinook,  \n             the program that solved draughts (checkers) in 2007 \n           \"This is not yet a Deep Blue moment [when the computer beat world champion Garry Kasparov at chess in 1997]. The real achievement will be when the program plays a player in the true top echelon. Deep Blue started regularly beating grandmasters in 1989, but the end result was eight years later. What I see from these numbers is that the gap between where AlphaGo is and where the top humans are has shrunk enormously, and it\u2019s quite possible that with a bit more work and improvements, and more computing power, within a year or two they could do it. [In the March match], no offence to the AlphaGo team, but I would put my money on the human. Think of AlphaGo as a child prodigy. All of a sudden it has learned to play really good Go, very quickly. But it doesn\u2019t have a lot of experience. What we saw in chess and checkers is that experience counts for a lot.\" \n             Demis Hassabis \n           \n             Co-founder of DeepMind, the firm that created AlphaGo \n           \"AlphaGo is now going beyond \u2014 hopefully, eventually \u2014 what even the best humans in this area can do. It\u2019s quite an amazing feeling to see what new things it\u2019s going to invent, within the constraints of the game of Go. I guess we feel a lot of affinity with the system we\u2019ve built, especially because of the way it\u2019s been built \u2014 it has learned, we\u2019ve trained it in some sense, and it\u2019s playing in quite a human-like style. And it\u2019s different from a program you\u2019ve hand-crafted where you know all the nuances of what you can do: here it has picked up things for itself, so it\u2019s amazing to see the kind of capabilities it has learned.\" \n             David Silver \n           \n             DeepMind computer scientist \n           \"I haven\u2019t put any money on AlphaGo winning, but I do think we have a lot of reputation riding on this bet. So let\u2019s just say we\u2019ll be very disappointed if we lose the match in March. But you never know, anything is possible. Humans inevitably have a lot of tricks up their sleeve that we\u2019re not able to train against.\" \n               Tweet \n               Follow @NatureNews \n             \n               weibo \n             \n                   Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                 \n                   Computer science: The learning machines 2014-Jan-08 \n                 Reprints and Permissions"},
{"file_id": "529445a", "url": "https://www.nature.com/articles/529445a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Deep-learning software defeats human professional for first time. March 2016 sees AlphaGo face its next professional opponent, the world's top Go player Lee Sedol.  Follow the match here . A computer has beaten a human professional for the first time at Go \u2014 an ancient board game that has long been viewed as one of the greatest challenges for artificial intelligence (AI). The best human players of chess, draughts and backgammon have all been outplayed by computers. But a hefty handicap was needed for computers to win at Go. Now Google\u2019s London-based AI company, DeepMind, claims that its machine has mastered the game. DeepMind\u2019s program AlphaGo beat Fan Hui, the European Go champion, five times out of five in tournament conditions, the firm reveals in research published in  Nature  on 27\u00a0January 1 . It also defeated its silicon-based rivals, winning 99.8% of games against the current best programs. The program has yet to play the Go equivalent of a world champion, but a match against South Korean professional Lee Sedol, considered by many to be the world\u2019s strongest player, is scheduled for March. \u201cWe\u2019re pretty confident,\u201d says DeepMind co-founder Demis Hassabis. \u201cThis is a really big result, it\u2019s huge,\u201d says R\u00e9mi Coulom, a programmer in Lille, France, who designed a commercial Go program called Crazy Stone. He had thought computer mastery of the game was a decade away. The IBM chess computer Deep Blue, which famously beat grandmaster Garry Kasparov in 1997, was explicitly programmed to win at the game. But AlphaGo was not preprogrammed to play Go: rather, it learned using a general-purpose algorithm that allowed it to interpret the game\u2019s patterns, in a similar way to how a DeepMind program  learned to play 49\u00a0different arcade games 2 . This means that similar techniques could be applied to  other AI domains  that require recognition of complex patterns, long-term planning and decision-making, says Hassabis. \u201cA lot of the things we\u2019re trying to do in the world come under that rubric.\u201d Examples are using medical images to make diagnoses or treatment plans, and improving climate-change models. In China, Japan and South Korea, Go is hugely popular and is even played by celebrity professionals. But the game has long interested AI researchers because of its complexity. The rules are relatively simple: the goal is to gain the most territory by placing and capturing black and white stones on a 19\u2009\u00d7\u200919 grid. But the average 150-move game contains more possible board configurations\u00a0\u2014\u00a010 170  \u2014 than there are atoms in the Universe, so it can\u2019t be solved by algorithms that search exhaustively for the best move. \n               Abstract strategy \n             Chess is less complex than Go, but it still has too many possible configurations to solve by brute force alone. Instead, programs cut down their searches by looking a few turns ahead and judging which player would have the upper hand. In Go, recognizing winning and losing positions is much harder: stones have equal values and can have subtle impacts far across the board. To interpret Go boards and to learn the best possible moves, the AlphaGo program applied  deep learning in neural networks \u00a0\u2014\u00a0brain-inspired programs in which connections between layers of simulated neurons are strengthened through examples and experience. It first studied 30 million positions from expert games, gleaning abstract information on the state of play from board data, much as other programmes categorize images from pixels. Then it played against itself across 50\u00a0computers, improving with each iteration, a technique known as reinforcement learning.  Deep learning is killing every problem in AI.  The software was already competitive with the leading commercial Go programs, which select the best move by scanning a sample of simulated future games. DeepMind then combined this search approach with the ability to pick moves and interpret Go boards\u00a0\u2014\u00a0giving AlphaGo a better idea of which strategies are likely to be successful. The technique is \u201cphenomenal\u201d, says Jonathan Schaeffer, a computer scientist at the University of Alberta in Edmonton, Canada, whose software Chinook solved 3  draughts in 2007. Rather than follow the trend of the past 30 years of trying to crack games using computing power, DeepMind has reverted to mimicking human-like knowledge, albeit by training, rather than by being programmed, he says. The feat also shows  the power of deep learning , which is going from success to success, says Coulom. \u201cDeep learning is killing every problem in AI.\u201d AlphaGo plays in a human way, says Fan. \u201cIf no one told me, maybe I would think the player was a little strange, but a very strong player, a real person.\u201d The program seems to have developed a conservative (rather than aggressive) style, adds Toby Manning, a lifelong Go player who refereed the match. Google\u2019s rival firm Facebook has also been working on software that uses machine learning to play Go. Its program, called  darkforest , is still behind commercial state-of-the-art Go AI systems, according to a November preprint 4 .\u00a0 Hassabis says that many challenges remain in DeepMind\u2019s goal of developing a generalized AI system. In particular, its programs cannot yet usefully transfer their learning about one system\u00a0\u2014 such as Go \u2014 to new tasks; a feat that humans perform seamlessly. \u201cWe\u2019ve no idea how to do that. Not yet,\u201d Hassabis says. Go players will be keen to use the software to improve their game, says Manning, although Hassabis says that DeepMind has yet to decide whether it will make a commercial version. AlphaGo hasn\u2019t killed the joy of the game, Manning adds. Strap lines boasting that Go is a game that computers can\u2019t win will have to be changed, he says. \u201cBut just because some software has got to a strength that I can only dream of, it\u2019s not going to stop me playing.\u201d\n See Editorial  page 437 \n                 Tweet \n                 Facebook \n                 weibo \n               \n                     Game-playing software holds lessons for neuroscience 2015-Feb-25 \n                   \n                     Game theorists crack poker 2015-Jan-08 \n                   \n                     Computer science: The learning machines 2014-Jan-08 \n                   \n                     Chess and GO no-brainers? 2002-Dec-12 \n                   \n                     DeepMind \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19252", "url": "https://www.nature.com/articles/nature.2016.19252", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Clusters of slow-slip events linked to risk of larger ones. Clusters of tiny earthquakes that happen every three years could help to signal when the next big one will hit Japan, researchers report in  Science 1 . Small, subtle quakes happen in many places where a slab of sea floor dives beneath a continent, such as in the US Pacific Northwest or off the coast of Chile. But the study of seismic activity in Japan is the first to show that they happen in regular episodes, and that those events can precede larger earthquakes. If the same patterns hold in other earthquake-prone regions, they could improve seismic risk estimates there, too. \u201cThis is a very important finding,\u201d says Akira Hasegawa, a seismologist at Tohoku University in Sendai, Japan, who was not involved in the research. A team led by Naoki Uchida, who is also a seismologist at Tohoku University, used data from seismometers that blanket most of Japan. The scientists examined 6,126 earthquakes of magnitude 2.5 or larger that came in groups between 1984 and 2011. These repeating earthquakes happen on the geological fault where two crustal plates meet. They show that the plates must be creeping past one another gently, in an almost imperceptible motion  known as slow slip . Every so often, the slow slip gives way and a much larger earthquake occurs. \n             Early warning \n           Geologists had known that slow slip happens off Japan, and that it can precede monster quakes. It may have helped to trigger a magnitude-9 earthquake that  devastated the northeastern Tohoku coast  in 2011, and caused a tsunami that flooded the Fukushima Daiichi nuclear plant 2 . Uchida and his colleagues have now discovered that slow slip happens in cycles every 2.7 to 3 years off the coast of northeastern Japan. \u201cThe results suggest that slow-slip events occur more frequently\u201d than previously realized, says Uchida. In this region, slow slip also happens around the same time as, or just before, a spike in the rate of earthquakes of magnitude 5 and greater. Slow slip may gradually build up stresses along the fault and eventually trigger it to move in the larger quake, Hasegawa says. \n             Stress monitoring \n           Because the 2011 Tohoku earthquake relieved geological stress, Uchida says, that particular section of the fault is not likely to move in a large earthquake any time soon. But by monitoring slow slip to the north and south of Tohoku, seismologists may get a better idea of how much stress is building there and when a large earthquake is likely to strike again. \u201cIt means earthquake probabilities should be raised during times of accelerated [slow] slip,\u201d says Gavin Hayes, a seismologist with the US Geological Survey in Golden, Colorado. Slow slip has happened before other large earthquakes, such as the magnitude-8.1 Iquique earthquake in Chile in 2014 3 . In 2014, off the coast of Guerrero, Mexico, a magnitude-7.2 earthquake occurred about two months after slow slip began, says Mathilde Radiguet, a seismologist at ISTerre Institute of Earth Sciences in Grenoble, France. And slow slip is common along the Pacific Northwest coast, a spot thought to be ripe for a large earthquake in the zone known as Cascadia. For the past five weeks, in a fairly common occurrence, tiny quakes have been marching south from Vancouver Island and into Washington state. \u201cIt is key for us to know as much as possible about unsteady slow slip in Cascadia,\u201d says Heidi Houston, a seismologist at the University of Washington in Seattle. But Japan has a huge advantage over other areas where slow-slip occurs, says Susan Schwartz, a seismologist at the University of California, Santa Cruz. The country\u2019s seismological network is so dense that it can detect faint signals, such as the periodic slow slip, that might never be seen in less-well-instrumented areas. \n                   Killer qualities of Japanese fault revealed 2013-Dec-05 \n                 \n                   Seismic hazards: Seconds count 2013-Oct-02 \n                 \n                   Hurricane may have triggered earthquake aftershocks 2013-Apr-19 \n                 \n                   Earthquake detected from space 2013-Mar-05 \n                 \n                   Typhoons trigger gentler tremors 2009-Jun-10 \n                 \n                   Nature  special: Japan earthquake and nuclear crisis \n                 \n                   Naoki Uchida \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19251", "url": "https://www.nature.com/articles/nature.2016.19251", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "DNA work shows Devils Hole pupfish might have occasionally mingled with relatives. A tiny fish species that is trapped in a hole in the desert in one of the hottest places on Earth might be younger and less isolated than scientists had thought. The Devils Hole pupfish ( Cyprinodon diabolis ) \u2014 whose population dropped as low as 35 individuals in 2013 \u2014 lives in the Mojave desert in Nevada (near California's famous Death Valley National Park) inside an isolated, flooded cavern with just one opening onto the harsh desert landscape. The pupfish has evolved distinct differences from related species that live nearby, including reduced aggression, larger eyes and missing pelvic fins. It is endangered, and conservation biologists are trying to rescue the fish, including with a captive breeding program near Devils Hole. Many researchers thought that the fish species had been isolated in its cavern from around 13,000 years ago \u2014 the last time major flooding occurred in the region. But Christopher Martin, an evolutionary biologist at the University of North Carolina, Chapel Hill, and his colleagues say that genetic sequencing suggests that the pupfish became trapped in Devils Hole somewhere between 105 and 830 years ago \u2014 and since then has continued to exchange genes with neighbouring populations of pupfish species. \u201cThat was the big surprise,\u201d says Martin. \u201cEvery few hundred years there\u2019s a fish or two that\u2019s moving between the desert springs.\u201d The fish either somehow move over land, he says, or are transported as eggs stuck to the feet of water birds. \n             Pupfish families \n           Martin and his colleagues built up a family tree of pupfish species by examining differences in their DNA. To calibrate the dates of splits in this family tree, they relied partly on geological evidence from Lake Chichancanab basin in the Yucatan peninsula in Mexico. That basin now contains several pupfish species, but it was dry 8,000 years ago, so the species there now are likely to have diverged from the common ancestor they share with other pupfish only after that drought. Martin\u2019s analysis, published in the  Proceedings of the Royal Society B 1 , suggests that DNA mutation rates can be much higher in pupfish than previously thought \u2014 and implies that the population of Devils Hole pupfish has not been isolated for long. \u201cThis is a very interesting paper, and it deals with a fascinating study system. The short timeframe of evolution is really remarkable,\u201d says Simon Ho, a computational evolutionary biologist at the University of Sydney, Australia. Ho says that the study adds to a growing body of evidence that some species might be much younger than earlier genetic comparisons had suggested, because DNA mutation rates can be very high over a short period of time 2 . Anthony Echelle, a pupfish researcher at Oklahoma State University in Stillwater, points out that Martin\u2019s analysis assumes that the entire basin in the Yucatan was dry 8,000 years ago. It is possible that pupfish, which are \u201camong the hardiest of animals\u201d, could have survived in patches of surface water in the Yucatan, Echelle says \u2014 meaning that the forming of the basin may not have marked such a definite splitting point in the pupfish family tree. \u201cFurther study of the Lake Chichancanab basin is needed for greater confidence in the startling conclusions of this paper,\u201d he says. Whatever the conclusion about the age of their provenance, the Devils Hole pupfish are incredible fish, Martin says. They live in a hole that gets no direct sunlight for two months of the year and in water that is a near-constant 32 \u00b0C: \u201cIt\u2019s amazing the fish can survive in there for a day.\u201d \n               Tweet \n               Follow @NatureNews \n             Reprints and Permissions"},
{"file_id": "529448a", "url": "https://www.nature.com/articles/529448a", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Some welcome his latest report as a fresh way to solve a black-hole conundrum; others are unsure of its merits. Cambridge, UK Almost a month after Stephen Hawking and his colleagues posted a paper about black holes online 1 , physicists still cannot agree on what it means. Some support the preprint\u2019s claim \u2014 that it provides a promising way to tackle a conundrum known as the black hole information paradox, which Hawking identified more than 40\u00a0years ago. \u201cI think there is a general sense of excitement that we have a new way of looking at things that may get us out of the logjam,\u201d says Andrew Strominger, a physicist at Harvard University in Cambridge, Massachusetts, and a co-author of the latest paper. Strominger presented the results on 18\u00a0January at a crowded talk at the University of Cambridge, UK, where Hawking is based. Others are not so sure that the approach can solve the paradox, although some say that the work illuminates various problems in physics. In the mid-1970s, Hawking discovered that black holes are not truly black, and in fact emit some radiation 2 . According to quantum physics, pairs of particles must appear out of quantum fluctuations just outside the event horizon \u2014 the black hole\u2019s point of no return. Some of these particles escape the pull of the black hole but take a portion of its mass with them, causing the black hole to slowly shrink and eventually disappear. In a paper 3  published in 1976, Hawking pointed out that the outflowing particles \u2014 now known as Hawking radiation \u2014 would have completely random properties. As a result, once the black hole was gone, the information carried by anything that had previously fallen into the hole would be lost to the Universe. But this result clashes with laws of physics that say that information, like energy, is conserved, creating the paradox. \u201cThat paper was responsible for more sleepless nights among theoretical physicists than any paper in history,\u201d Strominger said during his talk. The mistake, Strominger explained, was to ignore the potential for the empty space to carry information. In their paper, he and Hawking, along with their third co-author Malcolm Perry, also at the University of Cambridge, turn to soft particles. These are low-energy versions of photons, hypothetical particles known as gravitons and other particles. Until recently, these were mainly used to make calculations in particle physics. But the authors note that the vacuum in which a black hole sits need not be devoid of particles \u2014 only energy \u2014 and therefore that soft particles are present there in a zero-energy state. It follows, they write, that anything falling into a black hole would leave an imprint on these particles. \u201cIf you\u2019re in one vacuum and you breathe on it \u2014 or do anything to it \u2014 you stir up a lot of soft gravitons,\u201d said Strominger. After this disturbance, the vacuum around the black hole has changed, and the information has been preserved after all. The paper goes on to suggest a mechanism for transferring that information to the black hole \u2014 which would have to happen for the paradox to be solved. The authors do this by calculating how to encode the data in a quantum description of the event horizon, known whimsically as \u2018black hole hair\u2019. \n               Tricky transfer \n             Still, the work is incomplete. Abhay Ashtekar, who studies gravitation at Pennsylvania State University in University Park, says that he finds the way that the authors transfer the information to the black hole \u2014 which they call \u2018soft hair\u2019 \u2014 unconvincing. And the authors acknowledge that they do not yet know how the information would subsequently transfer to the Hawking radiation, a further necessary step. Steven Avery, a theoretical physicist at Brown University in Providence, Rhode Island, is sceptical that the approach will solve the paradox, but is excited by the way it broadens the significance of soft particles. He notes that Strominger has found that soft particles reveal subtle symmetries of the known forces of nature 4 , \u201csome of which we knew and some of which are new\u201d. Other physicists are more optimistic about the method\u2019s prospects for solving the information paradox, including Sabine Hossenfelder of the Frankfurt Institute for Advanced Studies in Germany. She says that the results on soft hair, together with some of her own work, seem to settle a more-recent controversy over black holes, known as  the firewall problem . This is the question of whether the formation of Hawking radiation makes the event horizon a very hot place. That would contradict Albert Einstein\u2019s general theory of relativity, in which an observer falling through the horizon would see no sudden changes in the environment. \u201cIf the vacuum has different states,\u201d Hossenfelder says, \u201cthen you can transfer information into the radiation without having to put any kind of energy at the horizon. Consequently, there\u2019s no firewall.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Quantum bounce could make black holes explode 2014-Jul-17 \n                   \n                     Stephen Hawking: 'There are no black holes' 2014-Jan-24 \n                   \n                     Black holes shrink but endure 2013-Oct-29 \n                   \n                     Astrophysics: Fire in the hole! 2013-Apr-03 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19254", "url": "https://www.nature.com/articles/nature.2016.19254", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Flexible plastic sensor sends molecular test results to a smartphone. Materials scientists have created a small, wearable sensor that can read the molecular composition of sweat and send its results in real time to a smartphone. The flexible plastic patches \u2014 which can be incorporated into wristbands and headbands \u2014 may be able to provide early warning of changes in the body, say their creators. \u201cThe idea is to have this thumbs-up or thumbs-down device that will give real-time information: it could provide an alarm that you need to take some medication, or that you\u2019re getting dehydrated and need to drink some water,\u201d says Ali Javey, at the University of California, Berkeley, who helped to develop the sensors. He and his colleagues report their work in  Nature 1 . Several labs have been developing sensors for sweat, which contains a multitude of electrolytes and metabolites \u2014 the final products of the body\u2019s biological processes (for example, the lactic acid that builds up after exercise). But these sensors have tended to measure only one component of sweat at a time, and generally cannot transmit their measurements in real-time. \u201cUntil now, sweat sensors have typically involved patches that are removed for subsequent chemical analysis by separate, non-wearable machines,\u201d says John Rogers at the University of Illinois at Urbana\u2013Champaign, who is also  developing wearable electronics . \u201cThe current device is wearable, it provides continuous data streams, and it measures multiple biomarkers simultaneously.\u201d \n             Perspiration on your phone \n           Putting together existing advances in wearables technology, Javey\u2019s team made the sensors from a flexible electronics board joined to a flexible printed plastic sensor array, which can detect glucose, lactate, sodium, potassium and body temperature. When the sensors come into contact with sweat they generate electrical signals that are amplified and filtered, and then calibrated using skin temperature. This step is essential, says Javey: \u201cElectrochemical sensors are very sensitive to temperature, and skin temperature can vary quite a bit when we are sweating.\u201d The data are then wirelessly transmitted to a smartphone. It\u2019s an impressive achievement, says Jason Heikenfeld at the University of Cincinnati in Ohio, whose lab has also been developing wearable sweat sensors. \u201cThe sensors typically require electronics that are normally the size of a shoebox; they miniaturized them into something that can wrap around your wrist,\u201d he says. The sensors have to be fabricated from basic chemicals in the laboratory, and cannot be purchased off the shelf like sensors found in today\u2019s wearables, which measure heart rate and detect the body's motion. \n             Challenges ahead \n           Javey says he has applied for patents on the technology. But there are still many challenges to overcome before you can expect to buy a sweat sensor incorporated into a wearable fitness band. For one thing, scientists aren\u2019t used to working with such tiny quantities of fluid, and people aren\u2019t always sweating. \u201cMany applications will be outside athletics, where wearable bands or patches will have to locally stimulate sweat,\u201d says Heikenfeld.\u00a0 Sweat sensors will never be as accurate as blood tests, which are the \u201cgold standard\u201d, says Javey.\u00a0Our bodies closely control the molecular composition of our blood, but the content of our sweat is more variable and is sometimes influenced by microbes on our skin \u2014 so the medical relevance of the information that sweat provides will need to be rigorously tested. However, sweat does have an advantage: taking blood samples with a needle is not a practical means of assessing health on a minute-by-minute basis. In time, the researchers hope to incorporate more sensors that might provide an even deeper picture of what\u2019s happening in the body. \u201cWe want to develop medical applications,\u201d Javey says. He points to research suggesting that certain biomarkers in sweat may correlate with symptoms in people with depression 2 . \u201cBy looking at those other chemicals we may be able to get information about the mental health of an individual,\u201d he says. Read the related News & Views article ' Technological leap for sweat sensing '. \n                   The inside story on wearable electronics 2015-Dec-01 \n                 \n                   What could derail the wearables revolution? 2015-Sep-01 \n                 \n                   'Old person smell' is real, but not necessarily offensive 2012-May-31 \n                 \n                   Radio sweat gland - 90 GHz 2008-Apr-09 \n                 \n                   Ali Javey's research lab \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19267", "url": "https://www.nature.com/articles/nature.2016.19267", "year": 2016, "authors": [{"name": "Zeeya Merali"}], "parsed_as_year": "2006_or_before", "body": "High-profile physicist says his students' papers were wrongly rejected by the preprint server's volunteer moderators. A heated debate about arXiv\u2019s screening policies has flared up after a high-profile physicist said that moderators at the popular preprint server rejected reasonable papers without justification. The site \u2013 where physicists, mathematicians and other researchers routinely post their articles before peer review \u2014 has previously been  accused of bias  for filtering out some of the wilder ideas it receives. But in a December  blogpost  that is now provoking debate, Nicolas Gisin, a quantum physicist at the University of Geneva, Switzerland, suggests that arXiv moderators wrongly blacklisted two of his students from posting their work. Gisin notes that being unable to post to arXiv has a detrimental effect on young researchers\u2019 careers, because it is so influential \u2014 the preprint server holds  more than 1.1 million papers  and receives well over 9,000 submissions each month. He is concerned that the site\u2019s volunteer moderators have too much power. In reply to Gisin\u2019s complaint, arXiv moderators say that they do not blacklist people and cannot comment on this particular case. But other physicists say that the preprint server needs to be more transparent about its screening process. \n             Preprints rebuffed \n           For Gisin, the trouble began when two of his graduate students, Thiago Guerreiro and Fernando Monteiro, fell foul of arXiv\u2019s filter. The two had written a paper that \u2014 startlingly \u2014 calculated that it is impossible to fall into a black hole because it would evaporate before a person came near enough to be swallowed. Gisin, who admits that he is no expert on black holes, felt that it must be wrong, but neither he nor his colleagues could find a mistake, so the result was submitted to arXiv in December 2014. It was placed on hold by the site\u2019s moderators, and rejected three months later. A modified version of the paper later passed peer review and was published last October in the journal  Physics Letters A 1 . Gisin asked for an explanation, and got sent the site\u2019s  publicly stated rules  for moderation \u2014 which include papers with inappropriate formatting or topic, papers in need of \u201csignificant review and revision\u201d, or concerns over copyright, duplicated submissions or multiple postings in quick succession. Those policies are sensible and rarely trouble seasoned users, adds Gisin (who has posted more than 300 papers under the site\u2019s quantum physics category), but the moderators wouldn\u2019t say which rule the students\u2019 paper had violated. Sabine Hossenfelder, an expert on quantum gravity at the Frankfurt Institute for Advanced Studies in Germany, says that the black-hole paper is scientific and clearly argued, but is wrong because it uses an equation in a slightly different regime to that in which it should be applied. She calls this a \u201ccommon and understandable mistake\u201d. Hossenfelder says that if she had been approached by a journal to review the paper, she would have recommended rejection. But despite that, she still believes the version which was published was suitable for posting on the arXiv. The students\u2019 next paper, on black-hole radiation, was less controversial because it used a simplified technique to reproduce an accepted result. However, after its submission in May 2015, it was rejected a week later by arXiv \u2014 after which Gisin aired his thoughts online. Gisin adds that he appreciates that arXiv\u2019s volunteer moderators may well be working with \u201cgoodwill\u201d, but it should not be their responsibility to vet papers, he says. (Guerreiro and Monteiro said they preferred not to comment.) \n             Quality control \n           Asked by  Nature  for a response, Daniel Gottesman, an arXiv moderator and chair of its physics advisory committee, said that moderators are unable to comment on specific cases. He added, however, that \u201cthere is no arXiv blacklist\u201d \u2014 besides measures to ban users who flagrantly attempt to bypass an appeals procedure by resubmitting rejected papers. \u201cIt is often the case that people who submit one paper that does not meet arXiv standards will submit more with similar problems, so future submissions by the same person are likely to get more scrutiny,\u201d says Gottesman, who is based at the Perimeter Institute in Waterloo, Ontario. The grounds for rejection listed on arXiv should not be taken as comprehensive, Gottesman adds. Moderators are also asked to check whether the papers meet a certain minimum quality standard, based on their expert judgement. The standards imposed by arXiv are less stringent than those of a high-quality peer-reviewed journal, he says. \u201cIf a paper is rejected by arXiv and accepted by a journal, that does not mean that arXiv is the one that made a mistake.\u201d ArXiv.org founder Paul Ginsparg, a quantum physicist at Cornell University, in Ithaca, New York, who was not involved in the moderation in this case, adds that arXiv moderators are also now sensitive to the fact that the site is checked daily by the news media. This gives moderators another reason to avoid posting \u201cmanifestly outlandish\u201d claims that might confuse the public, he says. Hossenfelder thinks that the arXiv moderators may have misfired on this occasion, but has sympathy for them, given the volume of papers they sift through. \u201cI hope that this episode will shake up the community and result in more funding for the arXiv, which in turn will help them to provide a better and more transparent moderation,\u201d she says. Ian Durham, a quantum physicist at Saint Anselm College in New Hampshire, agrees that the black-hole paper is wrong but should have been accepted by arXiv, so that the students could be exposed to community feedback. \u201cI do not approve of the way in which the arXiv handled this,\u201d he says. \u201cI understand that they have to protect against crackpots posting truly crazy papers. But in that case the process should be more transparent and the moderation must be more meaningful with some feedback provided.\u201d Previous complaints over arXiv\u2019s moderation policy motivated independent physicist Philip Gibbs to  set up the filter-free repository viXra  in 2009. Although viXra has a reputation for hosting speculative papers from non-academics, Gibbs argues that problems with arXiv have led to a rise in the number and quality of viXra submissions. \u201cWe now seem to be reaching a breakout point where more people from within academia can see the point of what we are doing too,\u201d he says. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   The arXiv preprint server hits 1 million articles 2014-Dec-30 \n                 \n                   Preprints come to life 2013-Nov-12 \n                 \n                   ArXiv at 20 2011-Aug-10 \n                 \n                   Ousted creationist sues over website 2002-Dec-12 \n                 \n                   What's arXiv spelled backwards? A new place to publish \n                 \n                   arXiv.org \n                 \n                   Nicholas Gisin's blogpost \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19258", "url": "https://www.nature.com/articles/nature.2016.19258", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Finding that much of Africa has Eurasian ancestry was mistaken. An error has forced researchers to go back on their claim that  humans across the whole of Africa carry DNA inherited from Eurasian immigrants . This week the authors  issued a note explaining the mistake  in their October 2015  Science  paper on the genome of a 4,500-year-old man from Ethiopia 1  \u2014 the first complete ancient human genome from Africa. The man was named after Mota Cave, where his remains were found. Although the first humans left Africa some 100,000 years ago, a study published in 2013 found that  some came back again around 3,000 years ago ; this reverse migration has left its trace in African genomes. In the  Science  paper, researchers confirmed this finding. The paper also suggested that populations across the continent still harbour significant ancestry from the Middle Eastern farmers who were behind the back-migration. Populations in East Africa, including Ethiopian highlanders who live near Mota Cave, carried the highest levels of Eurasian ancestry. But the team also found vestiges of the \u2018backflow\u2019 migration in West Africans and in a pygmy group in Central Africa, the Mbuti. Andrea Manica, a population geneticist at the University of Cambridge, UK, who co-led the study, says the team made a mistake in its conclusion that the backflow reached western and central Africa. \u201cThe movement 3,000 years ago, or thereabouts, was limited to eastern Africa,\u201d he says. \n             Incompatible software \n           Manica says that the error occurred when his team compared genetic variants in the ancient Ethiopian man with those in the reference human genome. Incompatibility between the two software packages used caused some variants that the Ethiopian man shared with Europeans (whose DNA forms a large chunk of the human reference sequence) to be removed from the analysis. This made Mota man seem less closely related to modern European populations than he actually was \u2014 and in turn made contemporary African populations appear more closely related to Europeans. The researchers did have a script that they could have run to harmonize the two software packages, says Manica, but someone forgot to run it. Pontus Skoglund, a population geneticist at Harvard Medical School in Boston, Massachusetts, says that he was surprised by the claim that as much as 6\u20137% of the ancestry of West and Central African groups came from the Eurasian migrants. But after obtaining the Mota man\u2019s genome from Manica\u2019s team, he and his colleague David Reich carried out their own comparison and found no evidence for that conclusion. They informed Manica\u2019s team, who then discovered the processing error. \u201cAlmost all of us agree there was some back-to-Africa gene flow, and it was a pretty big migration into East Africa,\u201d says Skoglund. \u201cBut it did not reach West and Central Africa, at least not in a detectable way.\u201d The error also undermines the paper\u2019s original conclusion that many Africans carry Neanderthal DNA (inherited from Eurasians whose ancestors had interbred with the group). Skoglund praised the paper \u2014 \u201cthe genome itself is just fantastic,\u201d he says \u2014 and the researchers\u2019 willingness to share their data and issue a speedy note about the error: they  posted it online on 25 January . When asked to confirm whether and when it would publish the researchers' update, a representative for  Science  said the journal couldn't yet comment. Manica is not yet sure if  Science  will change the title of the paper, \u2018Ancient Ethiopian genome reveals extensive Eurasian admixture throughout the African continent\u2019. But if the team had caught the error earlier, he says, \u201cI\u2019m sure we would have phrased things differently\u201d. \n               Tweet \n               Facebook \n               weibo \n             \n                   Ancient DNA from hot climes yields its secrets 2015-Oct-13 \n                 \n                   First ancient African genome reveals vast Eurasian migration 2015-Oct-08 \n                 \n                   Hunter-gatherer genomes a trove of genetic diversity 2012-Jul-26 \n                 \n                   Out of southern Africa 2011-Mar-07 \n                 \n                   Africa yields two full human genomes 2010-Feb-17 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19260", "url": "https://www.nature.com/articles/nature.2016.19260", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Columbia courts philanthropic benefactors to support research in impacts and adaptation. Like most researchers at Columbia University\u2019s Lamont\u2013Doherty Earth Observatory (LDEO), Park Williams is expected to win research grants to cover his salary. But times are tough for climate scientists, who face flat levels of government funding in an ever-expanding pool of competitors. Two years into a post as an assistant research professor, the 34-year-old bioclimatologist had yet to receive a single grant. But on 22 January the Center for Climate and Life, a new research centre at Columbia that is seeking to raise funds from the business community, awarded Williams US$180,000 for his research on historical drought and fire cycles. Michael Puma, an environmental modeller at Columbia and NASA\u2019s Goddard Institute for Space Studies, received $190,000 to investigate the impact of climate change on the global food system. \u201cI was beginning to worry about my future here and wondering if I\u2019d be wise to begin applying for more-traditional professorships,\u201d says Williams. \u201cNow I\u2019ll have time to actually do research.\u201d \n               Business boost \n             With climate-science funding  under perennial threat  in Washington DC, Columbia is engaging\u00a0corporate philanthropists to boost research into the effects of projected environmental changes and how human systems can adapt. Seeded by Columbia with an initial budget of $3.1 million over five years, the Center for Climate and Life hopes to build a $200-million endowment that disburses around $10 million annually. \u201cIt\u2019s a very new way of funding science,\u201d says Peter de Menocal, a palaeoclimatologist at the LDEO in Palisades, New York, who is directing the centre. The centre will supplement salaries and research costs for scientists at Columbia, as well as at NASA\u2019s Goddard Institute for Space Studies, which is located on the Columbia campus in New York City. De Menocal says that the centre will apply the same peer-review procedures used by the US National Science Foundation to ensure that its grants are directed towards the best research proposals. \n               Budget crunch \n             With roughly 85% of scientists at the LDEO reliant on government grants for their salaries, de Menocal says, two decades  of stagnant budgets  for the environmental sciences have taken a toll. And Republicans in the House of Representatives, many of whom deny the reality of global warming, have attempted repeatedly to cut funding for climate-related research. De Menocal says that the funding situation has many young Earth scientists rethinking their career choice because of what he calls \u201ca silly ideological divide\u201d. The new institute should give them needed job security, he says, and allow the community to identify and pursue new research paths without waiting for Washington to come around. Others have also recently turned to private philanthropy to fund climate research. \u201cIt is going to be very hard for the government to undertake a really big increase in federal research,\u201d says Margaret Leinen, director of the Scripps Institution of Oceanography in La Jolla, California. In August, Scripps opened the Center for Climate Change Impacts and Adaptation with a donation of $5 million from energy executive Richard Hertzberg and his wife Carol Dean Hertzberg. And the Grantham Foundation for the Protection of the Environment, founded by investment manager Jeremy Grantham and his wife Hannelore, has helped to establish similar research institutes at multiple universities, including the Grantham Research Institute on Climate Change at the London School of Economics. One of the Columbia centre\u2019s initial partners is the World Surf League (WSL) in Santa Monica, California, which is the governing body of professional surfing. The organization says it seeks to promote environmental awareness among more than 120 million surfing fans around the world. As part of that partnership, Columbia plans to develop an online certificate programme focused on ocean science and conservation. The courses will be open to anybody beginning in 2017 and may evolve into a formal master\u2019s degree programme. \u201cWe\u2019ve got this perfect combination of science and soul,\u201d says Scott Hargrove, chief marketing officer for the WSL, which plans to announce its funding commitment as early as February. \u201cSurfing has the power to move culture,\u201d he says, with Columbia driving the science and education, and surfers serving as public ambassadors. De Menocal is also in talks with French aerospace giant Airbus, which would provide the fuselage for a research aircraft that could be readily equipped with instruments to study everything from the atmosphere to rainforests and polar ice sheets. De Menocal says that the center is currently working on a viability study for the project. \u201cWe want to change the way we do and fund science,\u201d says de Menocal, \u201cand fast track the science we need to understand how climate impacts people.\u201d \n                     Biomedicine wins big in US budget deal 2015-Dec-18 \n                   \n                     US lawmakers approve controversial spending bill 2015-Jun-04 \n                   \n                     Obama budget seeks big boost for science 2015-Feb-03 \n                   \n                     Obama acts alone on climate 2015-Jan-27 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19272", "url": "https://www.nature.com/articles/nature.2016.19272", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Karolinska Institute may reopen investigation into Paolo Macchiarini, whom it cleared of research misconduct last year. \n             Update: On 4 February, the Karolinska Institute announced that  \n             it will not renew Paolo Macchiarini\u2019s contract \n              when it ends in November 2016. Macchiarini has been asked to use the remaining months to phase out his research, according to a statement released by the Karolinska. \n           The Karolinska Institute (KI) in Stockholm says that it is  looking into alleged ethical breaches  by Paolo Macchiarini \u2014 a surgeon who famously pioneered transplants of artificial windpipes \u2014 five months after it  cleared him of separate accusations of scientific misconduct . The Karolinska\u2019s re-examining of Macchiarini\u2019s work was triggered by revelations made in  a documentary made by SVT, Sweden's national television broadcaster , aired in three parts from 13 to 27 January. It suggests that in an operation in Russia, Macchiarini implanted one of his specially designed plastic tracheas into a woman who \u2014 although having had a tracheotomy four years earlier after an accident \u2014was not in a life-threatening condition. Previously, the surgeon had said he attempted the risky procedures only on people who were life-threateningly ill. The documentary also says that Macchiarini misrepresented the success of the prosthetic grafts in publications. \"We need to examine and evaluate the claims made in the documentary, and will be reopening the inquiry if there is reason to do so,\" the Karolinska's vice-chancellor, Anders Hamsten, said in a  statement issued on 28 January  by the institute, where Macchiarini is a visiting professor. Although the operation featured in the film did not take place at the Karolinska, \u201cif the information presented is true, the activities in Russia do not comply with KI rules and what we expect from our employees\u201d, Claes Keisu, a press officer for the Karolinska, told  Nature . If necessary, Keisu confirmed, the institute would reopen the formal investigation that it had concluded in August 2015, when it  determined that Maccharini did not commit scientific misconduct  in seven research papers, following allegations made by four physicians at the Karolinska. The revival of any inquiry could have repercussions for Karolinska management as well as Macchiarini; Hamsten wrote in an e-mail to Karolinska employees on 29 January that decisions would be taken to determine if the institute failed in its handling of the situation. \u201cThis case has brought KI to a crisis of confidence that I take very seriously,\u201d he wrote. \n             Risky research \n           Macchiarini\u2019s research, hailed as a bright spot in the field of regenerative medicine, involves bathing a synthetic polymer shaped like a trachea in stem cells. The cells are intended to help the windpipe to integrate into surrounding tissue. The surgeon has implanted artificial tracheas in eight patients; subsequently, six have died (from causes unrelated to the transplants, Maccharini says) and one has been in intensive care since the procedure. The surgeon has said that his procedure is experimental and risky; he told  Nature  in a November 2014 e-mail that the patients are \u201call extremely ill, with conditions so dire that many have been told they have only months to live\u201d. But the Swedish documentary counters that claim with video footage of Julia Tuulik, a 33-year old patient whom Macchiarini operated on in 2012 in Krasnodar, Russia, where he leads a government-backed regenerative-medicine programme. Tuulik's trachea was damaged in a car accident in 2008. In the documentary, she appears mainly concerned about pain from her resulting tracheotomy, and says she wants Macchiarini's surgery so as to \"live like normal people\". In e-mails to  Nature  in 2014, Macchiarini had described Tuulik as coming to him \u201cin a desperately ill, dire state\u201d. A year after the 2012 surgery, Tuulik\u2019s artificial trachea failed and had to be replaced; she died just over a year after that. \u201cThe three patients on whom Paolo Macchiarini operated at Karolinska University Hospital in 2011 and 2012 were seriously ill and judged to have little time left to live. We assumed that the same was true for the patients operated on in Krasnodar,\u201d said Hamsten in the Karolinska statement.  statement issued on 28 January  by Karolinska. \n             Images raise questions \n           Asked for comment, Macchiarini told  Nature  in an e-mail on 31 January that he was \u201cin the process of presenting all the multidisciplinary conference discussions that were had around each patient's case \u2014 along with the ethical committee decisions that approved them \u2014 to the Karolinska Institute.\u201d He added: \u201cI can assure you that large teams were involved in the decision-making process for every single patient, and that the patients themselves were also fully aware of the decisions they were making.\u201d The Karolinska will also be looking into images, presented in the documentary, of the very first prosthetic trachea, which Macchiarini implanted at the Karolinska hospital in June 2011. The image shows a bronchoscopy (in which a camera is inserted into the airways) a year after the procedure in which the airway appears blocked. But a research  article that Macchiarini co-authored  describes that patient at 12 months after surgery as having \u201can almost normal airway\u201d. Macchiarini told  Nature  that he was \u201cin the process of preparing a manuscript detailing the outcomes of every transplant, with full data\u201d. The Karolinska will also look into allegations made in a  Vanity Fair  article  that Macchiarini misrepresented his research experience and affiliations when applying for the job at the Karolinska in 2010. \u201cI have already provided all the required evidence that I have never misrepresented my professional qualifications to KI,\u201d Macchiarini told  Nature.  \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Artificial-windpipe surgeon committed misconduct 2015-May-21 \n                 \n                   Investigations launched into artificial tracheas 2014-Nov-28 \n                 \n                   Swedish Public Television \n                 \n                   Paolo Macchiarini's Russia project \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19286", "url": "https://www.nature.com/articles/nature.2016.19286", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Plastic litter affects offspring of exposed marine animals. Oysters that consume the small pieces of plastic that are littering the world\u2019s oceans produce fewer and less-healthy offspring, a study suggests \u2014 fuelling concern that the material may be damaging marine life. Millions of tonnes of plastic end up in the world\u2019s oceans every year; one recent calculation suggests that, by around 2050, there will be more plastic than fish, by weight (see  go.nature.com/59rxvt ). But researchers are  increasingly concerned  about the effects of tiny \u2018microplastic\u2019 fragments \u2014 those smaller than 5 millimetres \u2014 which are created when larger objects break apart, or manufactured for industrial products including cosmetics and packaging materials. Arnaud Huvet, a scientist at France's national marine research agency (Ifremer) in Plouzan\u00e9, and his colleagues placed Pacific oysters ( Crassostrea gigas ) in water laced with micrometre-sized spheres of polystyrene. (Although there are no measurements on the actual concentration of tiny microplastics at sea, Huvet says, the researchers chose a density of polystyrene that matched previous estimates of microplastics found at the interface between water and sediment, where wild oysters live). After two months, oysters exposed to the plastic produced fewer and smaller egg cells, less-mobile sperm and fewer offspring than did animals raised in water without the plastic 1 . The offspring themselves grew more slowly, the researchers report. Microplastics have been shown to reduce the fertility of\u00a0other marine animals, including tiny crustaceans such as copepods 2  and daphnia 3 . But the latest study broadens the case file to oysters, says Huvet. The oysters\u2019 digestion might be disrupted when they eat the plastic, he says, and endocrine-disrupting chemicals, which are known to affect reproductive systems, might be released from the plastic particles into the oysters' digestive tracts. \n             Plastic problem \n           Awareness of the biological damage caused by microplastics is still in its infancy, says Tamara Galloway, an ecotoxicologist at the University of Exeter, UK. By contrast, there are well-publicized images of birds and turtles choking on larger pieces of plastic. Galloway says that the oyster study is \u201cextremely comprehensive\u201d and adds to other evidence for the negative effects of microplastics, reinforcing the need to act on the problem of marine litter. \u201cAnthropogenic litter is something we can do something about quite quickly if we want to,\u201d she says \u2014 by using less plastic and being more careful about waste disposal. Wild populations of Pacific oysters are not in decline, says Huvet, but the study suggests that plastic could have long-term effects because oysters are a vital food source for many other animals. What\u2019s still not clear, says Huvet, is whether the microplastics that accumulate in oysters could be harmful to the humans that ultimately eat them. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   In the name of beauty 2015-Sep-22 \n                 \n                   Plastic waste taints the ocean floors 2014-Dec-17 \n                 \n                   Fate of ocean plastic remains a mystery 2014-Dec-10 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19275", "url": "https://www.nature.com/articles/nature.2016.19275", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Newborns were exposed experimentally to vaginal microbes to restore the microbiomes they missed. Researchers have altered the microbiomes of babies born through caesarean section by swabbing them with microbes from their mothers\u2019 vaginas, they report in a first-of-its kind study published on 1 February in  Nature Medicine 1 . The procedure \u2014 tested on just four newborns \u2014 is an attempt to simulate the microbial exposures that babies born through caesarean section (C-section) surgeries lack. C-section babies have a slightly higher risk of developing obesity,  asthma  and other ailments than do children born vaginally. There are also differences between the microbial communities on their skin, in their guts and elsewhere. But no study has established a link between health problems of babies born through C-section and the composition of their microbiomes. \u201cIt\u2019s something that, on first principles, just makes evolutionary sense,\u201d says Rob Knight, a microbiologist at the University of California, San Diego, who was part of the work. \u201cUntil very recently, every surviving mammal that was delivered into the world was essentially coated in its mother\u2019s vaginal community.\u201d Knight himself performed the procedure with his wife after their daughter was born via emergency C-section in 2011, although that was not part of any study. In some countries, especially those in Latin America, C-sections account for more than half of all births. \u201cYou wonder, 'What are we doing with all these babies born without the natural primordial bacteria?\u2019,\u201d says Maria Dominguez-Bello, a microbial ecologist at New York University who led the study. \n             Microbial bath \n           In 2012, Dominguez-Bello began to recruit expectant mothers for the study. The team enrolled 7 women who delivered vaginally and 11 who had a C-section \u2014 4 of whom underwent the microbial transfer. Just before surgery, the researchers sampled the mother\u2019s vaginal microbes with sterile gauze. Within 2 minutes of birth, this gauze was swabbed all over the newborns\u2019 bodies. The four babies who received the swabs harboured skin, gut, anal and oral bacterial communities that were more like those of infants delivered naturally, compared to the C-section-delivered babies who did not go through the procedure. The paper reports on microbial differences seen only in the first month of life, but Dominguez-Bello says that they are long-lasting. Her team is working on a follow-up study that looks at the effects of the procedure in about 75 children after a year. \u201cAfter one year, I can tell you how the baby was born with pretty high precision,\u201d she says. It will be much more difficult to determine whether the transfers have any consequences on health. Dominguez-Bello estimates that her team will need to enrol around 1200 children and follow them for at least 3\u20135 years to explore whether the procedure leads to any differences in body composition or rates of asthma or allergies. \n             Health effects unclear \n           Alexander Khoruts, a gastroenterologist at the University of Minnesota in Minneapolis, says that it will be difficult to work out whether the restorations have any effect on health later in life. Systematic differences between mothers who deliver naturally and those who get C-sections could complicate any interpretation, Khoruts notes. \u201cWhat I fear is that some patients might come to the clinic and start demanding this sort of protocol, which I don\u2019t think is ready for primetime,\u201d Khoruts adds. Mothers who attempt this themselves could unwittingly transfer infections to their children, notes Josef Neu, a neonatologist at the University of Florida College of Medicine in Gainesville. Dominguez-Bello receives regular enquiries about the procedure from mothers, and she shares her team\u2019s protocol, which includes testing for some infections, such as group B  Streptococcus . But \u201cI tell them that I\u2019m not an MD, and this is not a standard procedure, so I\u2019m not in any possession to recommend this,\u201d she says. Some families are not waiting for conclusive research to  try the procedure for themselves . \u201cIn one sense, the science isn\u2019t settled yet,\" says Knight. \"In another sense, compared to other choices you might be making this is a very natural choice. Had you not delivered your baby by C-section there\u2019s no way you could escape coating your baby in these bacteria.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Bacteria found in healthy placentas 2014-May-21 \n                 \n                   Pregnancy alters resident gut microbes 2012-Aug-02 \n                 \n                   Microbes en masse: The sequencing machine 2012-Jul-11 \n                 \n                   Caesarian sections may increase asthma risk 2007-Oct-29 \n                 \n                   Caesarean risks hard to pin down 2006-Mar-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19274", "url": "https://www.nature.com/articles/nature.2016.19274", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Journals throw their weight behind checklist for rigorous animal experiments. TREND WATCH:  More than 600 research journals have now signed up to voluntary guidelines that are designed to improve the reporting of animal experiments. Scientists have  repeatedly pointed out  that many published papers on animal studies suffer from poor study design and sloppy reporting \u2014 leaving the research at a  substantial risk of bias . So in 2010, the  ARRIVE  guidelines  (Animals in Research: Reporting\u00a0 In Vivo \u00a0Experiments)  were introduced by a team led by the UK National Centre for the Replacement, Refinement and Reduction of Animals in Research (NC3Rs) 1 . They provide a detailed checklist of elements that should be included in any reporting of animal research, such as information about animal strain and sex, appropriate statistical calculations and disclosure of adverse events. More than 150 journals endorsed the ARRIVE guidelines in 2015 alone, according to NC3Rs data \u2014 the highest number of signatories in a single year since the checklist's release in 2010. By the end of January 2016, the total number had passed 600. Still, endorsement does not mean enforcement:  a 2014 study suggested that researchers largely ignore the voluntary guidelines . By comparing some papers published before and after the guidelines were issued, it found that there was little difference in the quality of reporting 2 . \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   Missing mice: gaps in data plague animal research 2016-Jan-05 \n                 \n                   Poorly designed animal experiments in the spotlight 2015-Oct-13 \n                 \n                   UK funders demand strong statistics for animal studies 2015-Apr-15 \n                 \n                   Why animal research needs to improve 2011-Sep-28 \n                 Reprints and Permissions"},
{"file_id": "530015a", "url": "https://www.nature.com/articles/530015a", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "If the United Kingdom leaves the EU, researchers throughout the bloc will feel the effects. A UK debate over whether to leave the European Union (EU) is drawing in academics from across the continent. Millions in research funding, collaborations and the employment status of thousands of scientists could be affected by the outcome. The UK government has committed to holding a referendum on a Brexit \u2014 as the possible British exit has been dubbed \u2014 by the end of 2017. Brexit proponents say that a lone United Kingdom would enjoy greater freedom to set policies that affect research. But most researchers who are willing to pick a side publicly are worried about the prospect. \u201cEurope would suffer and the UK would suffer,\u201d says Lesley Wilson, secretary-general of the European University Association in Brussels. \u00a0One big uncertainty is money. UK universities rely on the EU for around 16% of their total research funding. And scientists working in the United Kingdom are disproportionately successful at winning such awards compared to applicants in other member states; under the EU\u2019s last Framework Programme, which ran from 2007 to 2013, they won grants worth \u20ac7 billion (US$7.58 billion), second in value only to Germany. UK institutions also host more researchers with grants from the EU-funded European Research Council (ERC) than those in any other member state. Being outside the EU does not necessarily preclude involvement in EU programmes. Non-members such as Norway, Switzerland and Israel have gained access to various EU research schemes, mainly by paying for inclusion in them and by adopting some general EU rules, such as freedom of movement. Angus Dalgleish, who is part of the \u2018Leave.eu\u2019 campaign, says that the shortfall would be made up if the United Kingdom were to redirect to science even a portion of the sum \u2014 most recently around \u20ac17 billion \u2014 that it must contribute annually to the overall budget of the EU as a member. \u201cWe would have a far bigger budget for funding our own science,\u201d says Dalgleish, a cancer and HIV researcher at St George\u2019s, University of London, who once stood for election as a member of the pro-Brexit UK Independence Party. But opponents of a Brexit counter that the United Kingdom could find it expensive to renegotiate entry into EU funding programmes because of its historically outsized success at winning competitive grants. They also cite the example of Switzerland, which had bought into EU funding schemes but was booted out of many such projects in 2014 after its citizens voted to restrict immigration. Scientists had to scramble to find ways around the official severing of ties after that, and Swiss participation has been restricted ever since. UK researchers could still access major EU research-infrastructure projects after a Brexit. But they would lose the priority given to EU members, putting them at the back of the queue for access to facilities ranging from a laser instrument to a major social-science data set. UK researchers would also have to negotiate for access to international projects where EU funding currently gets them in, such as the  huge experimental fusion reactor , ITER. \n               Bridges burned \n             For Kurt Deketelaere, secretary-general of the League of European Research Universities in Leuven, Belgium, the potential loss of mobility and collaboration is worrying for scientists across Europe. Wilson agrees. \u201cEverybody wants to work with the best,\u201d she says. \u201cIf you\u2019re going to lose strong partners, that\u2019s not going to benefit anybody.\u201d Dalgleish counters that universities already maintain successful collaborations with non-EU members, and says that opting out would have \u201cno negative impact on scientific collaboration whatsoever\u201d. Still, around 15% of academic staff at UK institutions are non-UK EU nationals, a figure that rises to 20% among elite universities. It is unlikely that these people would have to apply for visas or leave in the event of a Brexit, or that grants already awarded would be clawed back. But in future, obtaining funding and securing jobs across UK\u2013EU borders could become more difficult. \u201cIn general, the UK would be less attractive for me,\u201d says Yvonne Peters, a particle physicist originally from Germany who works at the University of Manchester, UK, and is partially funded by a grant from the ERC. Brexit proponents say that if the United Kingdom leaves, it will escape other EU regulations, such as rules governing clinical trials. These have been widely blamed for  hindering UK medical research  \u2014 triggering proposals to overhaul the regulations. The nation might also be able to offer more tax credits for research spending and  adopt a more positive stance  on genetically modified crops. But the EU would also lose a powerful political voice pushing for science, says Vicky Ford, a UK Conservative Party member of the European Parliament who supports EU reform. She says that UK votes have been crucial in parliamentary decisions that have affected the entire bloc, including reductions to red tape in the awarding of funds, and improvements to science-advice mechanisms in EU politics. Without UK votes, Ford says, EU research would have paid a price: \u201cDefinitely there would have been less money.\u201d \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 weibo \n               See Editorial  page 6 \n                     Better together 2016-Feb-03 \n                   \n                     European medical research escapes stifling privacy laws 2015-Dec-16 \n                   \n                     European Commission names seven researchers as its top science advisers 2015-Nov-10 \n                   \n                     Economic divide taking toll on European science 2015-Jan-07 \n                   \n                     Overhaul complete for EU clinical trials 2014-Jun-04 \n                   \n                     House of Lord\u2019s committee inquiry \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19341", "url": "https://www.nature.com/articles/nature.2016.19341", "year": 2016, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Study suggests how dummy pills might reduce drug doses in routine care. The brain cells of people with Parkinson\u2019s disease can be trained to reliably respond to placebo drugs, Italian neuroscientists report. The training wears off after 24 hours but the effect shows it may be possible to reduce the medication needed to treat Parkinson\u2019s by interspersing real drugs with inert injections or pills, says placebo researcher Fabrizio Benedetti at the University of Turin, Italy, who led the work. A few people with Parkinson\u2019s disease do respond dramatically to placebos, but most do not 1 . People with the condition suffer characteristic tremors and stiff muscles because their dopamine-producing brain cells are gradually dying off. They alleviate their symptoms by taking drugs such as apomorphine, which activate receptors for dopamine. For some conditions \u2014 such as pain and immune disorders \u2014 trials have shown 2  that it is possible to train people to respond to placebos, although this practice hasn\u2019t made its way into clinical care. Benedetti and his colleagues wondered whether the same effect might be possible for neurological disorders. They studied 42 people with advanced Parkinson\u2019s disease who were having electrodes implanted into their brains for a therapy called deep brain stimulation, which eases symptoms by stimulating affected brain areas directly. That surgery gave Benedetti\u2019s team a rare opportunity to measure the activity of individual neurons in the thalamus, a brain region known to be inhibited by lack of dopamine in people with Parkinson's. During surgery, participants were given a saline injection that they were told was apomorphine. It produced no response \u2014 unless the patients had been 'pre-conditioned' by having already received 1\u20134 daily injections of the real drug in the days before surgery. Those patients did respond to the saline: after the injection, their neurons showed increased activity, and their muscle rigidity dropped (as assessed by a neurologist who was not told the purpose of the study or which treatment the patients had received). Measuring the response of individual brain cells, Benedetti says, proves that changes in clinical outcome aren\u2019t explained by any bias from patient or experimenter. The larger the number of previous apomorphine injections, the greater the subsequent response to the saline. If patients had received four previous injections, there was \u201cno difference between drug and placebo response\u201d, Benedetti says. (The results cannot be due to residual apomorphine, as the drug is virtually eliminated from the body after a few hours). The findings are published in  The   Journal of Physiology 3 . \n             Short-lived memory \n           The training is short-lived: it wore off after a maximum of a day. But Benedetti hopes that it may be possible to lengthen the placebo 'memory' of patients, by giving them real drugs for longer. The study is important \u201cbecause of its clear demonstration that clinical response and neuronal activation are clearly linked and can be trained\u201d, says Christopher Goetz, a neurologist at Rush University Medical Center in Chicago, Illinois. \u201cThough the group sizes are small, the results seem compelling,\u201d adds Tor Wager, a neuroscientist at the University of Colorado Boulder, who has studied placebo effects in pain relief. Studies of immune responses and pain, including Wager\u2019s work 2 , 4 , have shown \u2014 in small trials \u2014 that learned placebo effects can persist even when people know they are being given a fake drug. Benedetti says that although it is not yet clear that this \u201chonest placebo\u201d approach would work for Parkinson\u2019s, it might still be possible to use placebos in clinical practice without deception by informing a patient that inert doses were being interspersed with real medication. Alberto Espay, a neuroscientist at the University of Cincinnati in Ohio who has studied placebo effects in Parkinson\u2019s disease, says that it will be important to check whether patients actually benefit in the long term. But he predicts that placebos could ultimately be used in clinical practice, reducing the amount and cost of medication. Benedetti suggests that placebos might also help to delay drug tolerance \u2014 where the effect of a real drug wears off in Parkinson\u2019s patients after long-term use. What is unclear is how exactly the effect works. Goetz thinks it may be purely a 'Pavlovian response', in which patients conditioned through experience associate injections with symptom relief. Placebo studies have traditionally focused on a different idea: that a patient responds to a placebo if they have positive expectations that a treatment will work. Wager suggests that Benedetti\u2019s study \u2014 along with others \u2014 shows that learned associations might work together with positive expectations to cause changes in the brain. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19346", "url": "https://www.nature.com/articles/nature.2016.19346", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Rules to limit greenhouse-gas emissions from power plants are key part of US President's fight against global warming. The US Supreme Court on 9 February blocked President Barack Obama's plan to regulate carbon dioxide emissions from power plants, pending the outcome of a legal challenge by more than two dozen states. The emissions rules, known as the Clean Power Plan, are one of  Obama's primary tools  in the battle against climate change.  Finalized in August 2015 by the US Environmental Protection Agency  (EPA), the regulations would require states and electric utilities to reduce emissions by lowering demand, deploying low-carbon energy sources or increasing the efficiency of existing fossil-fuel power plants. By 2030, the regulations would reduce CO 2  emissions from the power sector by an estimated 32% compared with 2005 levels.\u00a0 The Supreme Court overruled a 21 January decision by a federal appeals court that would have allowed the EPA to implement the regulations pending legal review. If the appeals court ultimately sides with the Obama administration and the states appeal against the verdict, the regulations would remain on hold pending a Supreme Court hearing. In that case, the high court could issue a ruling as early as 2017. \u201cMake no mistake \u2014 this is a great victory for West Virginia,\u201d the state's attorney general, Patrick Morrisey, said in a prepared statement. West Virginia is one of the states that has sued to overturn the EPA regulations. Under the rules, each state must craft its own plan to reduce emissions beginning in 2022. Before the Supreme Court ruling, States had until 6 September 2016 to submit those plans to the EPA, although they could also apply for a two-year extension. The Supreme Court\u2019s decision puts that process on hold, although Obama administration officials say that the EPA will continue working with states to prepare for the eventual implementation of the regulations. Jeffrey Holmstead, a lawyer at the firm Bracewell in Washington DC, who worked at the EPA under President George W. Bush, says that this is the first time that the Supreme Court has stepped in to block a major environmental regulation before a lower court ruling. This suggests that the Supreme Court is sympathetic to arguments that the EPA overstepped its authority in crafting power-plant regulations, he says. \u201cI think the likelihood that [the EPA rules] will ever go into effect is pretty low,\u201d Holmstead says. \u201cThere needs to be some sort of congressional action to decide how the United States is going to deal with climate change.\u201d White House officials are disappointed with the Supreme Court\u2019s decision, but say they are confident that the EPA regulations will ultimately be upheld by the court. Officials also say that the ruling will not affect the country's ability to meet the commitment to reduce greenhouse-gas emissions it made  as part of the Paris climate agreement . \u201cThis rule is on sound legal footing,\u201d a senior administration official said during a background briefing late on 9 February. \u201cWe remain completely confident in our ability to meet those commitments, and we will continue making steps to make sure that the United States is doing its part.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             \n                   US Environmental Protection Agency Clean Power Plan \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19344", "url": "https://www.nature.com/articles/nature.2016.19344", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Follow announcements on the search for cosmic ripples as they unfold. On 11 February, the Advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) announced that it had made  the first ever direct detection of gravitational waves , ripples in space-time  predicted by Albert Einstein almost exactly 100 years ago . Nature  live-blogged the news and what it means for science. \n               Tweet \n               Facebook \n               LinkedIn \n               weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19365", "url": "https://www.nature.com/articles/nature.2016.19365", "year": 2016, "authors": [{"name": "Natasha Gilbert"}], "parsed_as_year": "2006_or_before", "body": "Health risks of nearly 10,000 chemicals charted to help predict toxicity of untested substances. A giant database on the health risks of nearly 10,000 chemicals will make it easier to predict the toxicity of tens of thousands of consumer products for which no data exist, say researchers. But a legal disagreement means they haven't yet been able to make the database public, as they had hoped to do. \u201cThis has the potential to save millions of animals and reduce testing costs by hundreds of millions,\u201d says Thomas Hartung, a toxicologist at Johns Hopkins University in Baltimore, Maryland, who led the team that created the database. He describes his work in  papers published  on 11 February in  Alternatives to Animal Experiments 1 . The index is built from a mountain of safety data collected over the past decade by the European Chemicals Agency (ECHA) in Helsinki, under a  2006 law  known as REACH (registration, evaluation, authorization and restriction of chemicals). The information is  already public , but not held in an easy-to-analyse format \u2014 so Hartung\u2019s team developed software that extracted it and converted it into a searchable database. But the ECHA says that it has exclusive rights to the information, and that Hartung did not gain the specific permission he needed from the agency in order to duplicate it. For the moment, Hartung has agreed to hold off making his team's database public. \n             From one chemical to another \n           With the database, Hartung hopes that companies and regulators will find it easier to infer the toxic effects of untested substances by comparing them with structurally or biologically similar chemicals with known effects \u2014 a method called read-across. That concept is already popular among chemical companies that seek  alternatives to safety tests on animals , says Markus Wahl, a regulatory toxicologist at chemicals producer BASF in Ludwigshafen, Germany. The database will provide \u201chelpful supporting evidence\u201d, he says, but he adds that European regulators accept the results of read-across (in place of animal-safety tests) only occasionally. Hartung, a long-time promoter of alternatives to animal-based safety testing, hopes to change that. A spokesperson for the ECHA says that read-across is a \u201cgood approach\u201d for checking relatively simple concerns such as harmful effects to skin and eyes \u2014 but that it \u201cproves to be challenging\u201d for complex issues such as the effects of repeated exposure to chemicals. \u201cCompanies quite often fail to substantiate why the read-across is scientifically justified,\u201d the agency says. Hartung argues that the database will strengthen the scientific case for read-across, because the certainty of the comparison \"increases with the extent and quality of data,\u201d he says. The data might also prove very useful to US regulators, as the country's lawmakers  attempt to tighten legislation governing the safe use of chemicals . Currently, chemicals can go on the US market with little regulatory scrutiny. Analysis of the database has shown that some animal tests are woefully irreproducible, Hartung adds. The Draize eye test, for example, in which chemicals are applied to rabbits\u2019 eyes to check for harmful effects, is a \u201cbig lottery\u201d, he says. The test, in use for decades, has been widely criticized for producing inconsistent results and raising animal-welfare concerns, but the Johns Hopkins team analysed 9,700 Draize results from the ECHA data to quantify the problem. The results, published 2  alongside the description of the database, suggest that substances found to cause serious irreversible eye damage in one test have a 10% chance of being found harmless in a subsequent test. By contrast, substances found to cause reversible irritation to rabbits\u2019 eyes have nearly a 60% chance of being found harmless in a later test. Human error and variation in the interpretation of the effects is a key cause of the inconsistent results, says Hartung. \n             Legal tussle \n           Hartung says that numerous researchers have expressed interest in mining the database, including the US Environmental Protection Agency, the US National Institutes of Health and some academic and industry groups. But the database has already run into legal trouble with the ECHA. Information on the ECHA\u2019s website is \"proprietary\", the agency says, and \"may be subject to intellectual property rights or copyright\" belonging to the chemical companies. \u201cThis is not a parochial or bureaucratic requirement,\u201d a spokesperson added: the ECHA is \u201ckeen\u201d to see the data being used, but says that it also needs to protect the rights of the companies that own the data. Hartung counters that the research \u201cmakes use only of the publicly available data\u201d, and that the agency shouldn't prohibit their use for academic enquiry. He has agreed to delay making the database public until he gets the specific permission he needs from the ECHA, but it is not clear how long that will take.  Reprints and Permissions"},
{"file_id": "nature.2016.19178", "url": "https://www.nature.com/articles/nature.2016.19178", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "In hotels and at sea, from code to cartilaginous fish: a celebration of the responses to  Nature \u2019s #ShowUsYourScience. To celebrate reaching 1 million followers of  @NatureNews  on Twitter,  Nature  asked its audience to send in photos of their work. The response to  #ShowUsYourScience  was overwhelming. Here are the stories behind some of our favourite responses. We wish we could have featured them all. \n             Beetle locomotion \n           Alex Evans is a PhD student at the University of Leeds, UK, where he works to understand flight. Although he works mainly on birds, Evans also investigates beetles such as this flower chafer ( Mecynorrhina ugandensis ). He will dissect out the beetle's muscle fibres and use them to generate data on energy use and power outputs. \u201cHopefully, these results will help us to understand more about why we find such a diverse range of muscle mechanics and flight styles in beetle species and what may drive adaptations towards certain styles,\u201d says Evans. \u201cThe main reason I was taking this beetle for a walk across my hands was mostly just because I find them fascinating to watch!\u201d \n             Ancient Americans \n           By sequencing ancient remains from the Americas, Jennifer Raff hopes to understand the prehistory of the region, and how humans first arrived and peopled it. The ancient-DNA researcher at the University of Kansas in Lawrence generally starts her days in a special laboratory that uses positive-pressure air systems and ultraviolet lights to minimize contamination of ancient DNA, and which restricts access to people whose DNA has been sequenced, so as to identify contamination if it occurs. In the afternoon, she works in a lab that deals with modern genomes, or on a computer, analysing sequences such as the one in this tweet. The move from ancient to modern is deliberate \u2014 it prevents the contamination of older samples with modern ones. \u201cIt can be incredibly frustrating sometimes,\u201d Raff says, \u201cbecause few samples have preserved DNA, and even if DNA is present it will be highly degraded and scarce. But ancient DNA work has transformed our understanding of human history, and I absolutely love my work.\u201d \n             Wild dogs feel the heat \n           Turning dogs into data is the science of Daniella Rabaiotti, a PhD student researching climate and conservation at the Zoological Society of London. Rabaiotti is working on the impact of climate change on African wild dogs ( Lycaon pictus ), a species that many people assumed would not be greatly affected by rising temperatures. She is using a huge data set from radio-collared animals, allied with mathematical models (seen on the right of the picture) to tease out how the dogs will fare with changes in temperature, rainfall and other environmental factors influenced by global warming. Although she spends most of her time in the office, \u201cI go out and collar some wild dogs and cheetahs occasionally\u201d, she told  Nature .\u201cThe take-home from my research is that species you wouldn\u2019t necessarily expect to be affected by climate change probably are,\u201d says Rabaiotti. \n             Science room service \n           Richard Johnston was in Germany last year to test drive a microscope when he found that his only opportunity to prepare a sample of cuttlebone for scanning was in his hotel room. He even had to use the hotel hair dryer on the cuttlefish in question. Things did get \u201cquite smelly\u201d, he says. Johnston, who co-directs the Advanced Imaging of Materials Facility at Swansea University, UK, looks to get \u2018bioinspiration\u2019 for materials science from nature. The microscope was clearly impressive because he is now expecting delivery of his own version of the \u00a31-million (US$1.4-million) Zeiss Xradia 520. \n             Swim free \n           This cute baby southern fiddler ray ( Trygonorrhina dumerilii ) is being released after helping Leonardo Guida to understand the impact of fishing. Guida is a PhD student at Monash University in Melbourne, Australia, with the  @LetsGetPhysEcol  lab, and is studying how capture by fishing stresses sharks and rays (chondrichthyes). He catches pregnant rays by hand and then simulates a capture by trawler in an aquarium. Although it is not sought out by fishermen, this species is often caught as \u2018bycatch\u2019. \u201cThe results of our work generally inform fisheries managers of practices which best ensure the survival of bycatch sharks and rays and ultimately assist in the development of sustainable fishing,\u201d Guida told  Nature . \n             Going underground \n           Pablo D\u00e1vila Harris found himself in this cave last Sunday, collecting water and rock samples and trying to \u201cdecipher the relation between the cave structures and the host rock\u201d, he told  Nature . A geologist at the Institute for Scientific and Technological Research of San Luis Potos\u00ed (IPICYT) in Mexico, he is part of a project looking at the area\u2019s \u2018tuff\u2019 \u2014 a type of rock that forms from volcanic eruptions. In this case, the tuff was the product of a huge eruption in the Pleistocene. \u201cWe want to shed light on several scientific questions: How was the cave formed? How long did it take to form? What are the main processes responsible for the formation of the cave?\u201d he says.  \n               Tweet \n               Follow @NatureNews \n             \n                   Insider\u2019s view of faculty search kicks off discussion online 2016-Jan-13 \n                 \n                   Satirical paper puts evidence-based medicine in the spotlight 2016-Jan-08 \n                 \n                   Nature  Social Selections \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19177", "url": "https://www.nature.com/articles/nature.2016.19177", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "France's iconic Chauvet cave holds mysterious spray-shaped imagery, made around the time when nearby volcanoes were spewing lava. Mysterious paintings in one of the world\u2019s most famous caves could mark the oldest-known depiction of a volcanic eruption. Spray-shaped images in Chauvet cave in France were painted at around the same time as nearby volcanoes spewed lava high into the sky, reports a paper published this month in  PLoS ONE 1 . Chauvet-Pont D'Arc cave, in southern France, is one of the world\u2019s oldest and most impressive cave-art sites. Discovered in 1994 and popularized in the Werner Herzog documentary 'Cave of Forgotten Dreams', Chauvet contains hundreds of paintings that were made as early as 37,000 years ago. Fearsome animals such as woolly rhinoceroses, cave lions and bears dominate Chauvet\u2019s imagery. But one of its innermost galleries \u2014 named after a giant deer species,  Megaloceros , that is depicted there \u2014 also contains a series of mysterious spray-shaped drawings, partly covered by the  Megaloceros  painting. A nearby gallery holds similar spray imagery, as does a wall near the cave\u2019s original entrance, but researchers have not determined what the images represent. The depictions are unique to Chauvet, notes Sebastien Nomade, a geoscientist at the University of Paris-Saclay in Gif-Sur-Yvette, France, who led the study. The Bas-Vivarais volcanic field, a well-known site containing more than a dozen extinct volcanoes, lies just 35 kilometres from the cave, but only eruptions that happened before humans occupied Chauvet had been dated, Nomade says. \n             Lava light show \n           In the hope of calculating the dates of younger eruptions, Nomade visited Bas-Vivarais in 2012 and sampled rock from three volcanic centres. By measuring the levels of different isotopes of radioactive argon gas, his team determined that the region had been lit up by a series of eruptions between about 19,000 years and 43,000 years ago. The events would have been dramatic \u2018strombolian\u2019 eruptions, Nomade says \u2014 named after those typical of the Stromboli volcano in Italy \u2014 with lava spewing 200-plus metres into the sky and flowing down the volcanoes' slopes. Each cone would have erupted once or twice before going extinct. Hunter-gatherers living in the region at the time must have seen the eruptions, Nomade says, noting that the 35 kilometres between the Chauvet cave and Bas-Vivarais would have offered a safe vantage point. \u201cYou just have to climb the small hill on top of Chauvet, and looking north you see the volcanoes. During the night you could see them glowing and you could hear the sound of the volcanic eruption.\u201d Meanwhile, radiocarbon dating suggests that humans occupied the  Megaloceros  gallery between 36,000 and 37,000 years ago, and charcoal used to paint the  Megaloceros  that overlays the spray-like paintings is at least 34,000\u201336,000 years old. \u201cThere\u2019s no way anybody could prove that it is a volcano that they depicted, but for us it\u2019s the hypothesis which is the most probable,\u201d says Nomade, whose team includes two rock-art experts who have previously studied the  Megaloceros  gallery. \n             A matter of record \n           If Nomade and his team are correct, Chauvet\u2019s volcano imagery would represent the earliest record of any eruption. Other, younger examples include a mysterious 8,600-year-old mural found on a wall at the Neolithic site of \u00c7atalh\u00f6y\u00fck in central Turkey, which may be a map depicting a nearby volcano that erupted at around that time 2 . And the poet Pliny the Younger famously documented the  ad  79 eruption of Vesuvius (which took the life of his uncle, Pliny the Elder). Axel Schmitt, a geoscientist at\u00a0Heidelberg University in Germany whose team studied the\u00a0eruption near\u00a0\u00c7atalh\u00f6y\u00fck, says that the dating of the eruptions near Chauvet is solid. But it will be difficult to get more precise dates from the volcanic basalt rock in the\u00a0Bas-Vivarais, he says.\u00a0\u201cYou have to be lucky to find the right sample.\u201d \u201cI think they make a pretty good case that it\u2019s potentially a depiction of the kind of volcano that one sees on the landscape,\u201d says Michael Petraglia, an archaeologist at the University of Oxford, UK. Depictions of natural events in rock art are rare, he notes, but this could be because they are too abstract or because researchers simply haven\u2019t looked. \u201cMaybe there\u2019s more of this out there than we have realized.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   World's oldest art found in Indonesian cave 2014-Oct-08 \n                 \n                   Neanderthal culture: Old masters 2013-May-15 \n                 \n                   Spain claims top spot for world\u2019s oldest cave art 2012-Jun-14 \n                 \n                   Human evolution: Cultural roots 2012-Feb-15 \n                 \n                   French bid to save rock art 2010-Sep-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19180", "url": "https://www.nature.com/articles/nature.2016.19180", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Case announced hours after World Health Organization declares spread of virus stopped in West Africa. When the World Health Organization (WHO)  declared on 14 January that the spread of Ebola had been halted in West Africa , it cautioned that cases of the virus might yet re-emerge. That is exactly what has happened in Sierra Leone, where another death from Ebola was announced hours after the WHO\u2019s statement. Health officials told reporters that a 22-year-old woman had died in Magburaka after falling ill in Baomoi Luma, near the border of Guinea. A test for Ebola was confirmed positive only after her death, which occurred earlier in the week, raising concerns that she may have been in contact with others while contagious. The case is Sierra Leone\u2019s first since it was declared free of Ebola on 7 November 2015, although the country was still in a 90-day period of enhanced surveillance. The WHO and local partners say that they are investigating its origin and identifying the woman\u2019s contacts. \n             Flare-ups expected \n           Although the epidemic phase of Ebola seems to be over, isolated cases were expected. The WHO considers human transmission of the virus to have halted when a country has gone 42 days (twice the virus\u2019s incubation period) with no new cases \u2014 but the  virus can persist in survivors for months in semen , as well as in tissues such as the eye, the central nervous system, the prostate gland and the placenta. It also remains  hidden in animal reservoirs . Liberia, for example, was pronounced Ebola-free in May 2015, but the virus flared up twice before the WHO could declare the country clear of the virus again on 14 January. \u201cWe are now at a critical period in the Ebola epidemic as we move from managing cases and patients to managing the residual risk of new infections,\u201d Bruce Aylward, special representative for the WHO\u2019s Ebola response, noted in the organization's press-released statement at the time. There is a particular focus on  the potential of sexual transmission of Ebola  to cause occasional cases. After a first-known case of sexual transmission of the disease was confirmed in Liberia last October, Armand Sprecher, a public-health specialist with M\u00e9decins Sans Fronti\u00e8res (also known as Doctors without Borders) in Brussels, wrote in an  editorial : \u201cThe challenge with sexual transmission is not that it would be a source of many new Ebola virus disease cases, but that it may be a source of late cases.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   Spread of Ebola ends: 7 lessons from a devastating epidemic 2016-Jan-14 \n                 \n                   Hunt for Ebola\u2019s wild hideout takes off as epidemic wanes 2016-Jan-12 \n                 \n                   What first case of sexually transmitted Ebola means for public health 2015-Oct-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19189", "url": "https://www.nature.com/articles/nature.2016.19189", "year": 2016, "authors": [{"name": "Declan Butler"}, {"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Knowledge about the drug's structure would help researchers understand what happened. One person died, and five others were hospitalized, after a clinical trial of an experimental drug in France went tragically wrong. But days after the first public acknowledgement of the incidents on 15\u00a0January, a lack of official information has left outside experts and the public largely in the dark as to what happened. \u201cThe French authorities have not been very rapid nor transparent in their response,\u201d says Catherine Hill, a specialist in clinical-trial design and a former member of the scientific advisory board of France\u2019s National Agency for Medicines and Health Products Safety (ANSM). She adds that French investigations into other medical accidents have often been opaque. The trial was a \u2018first-in-human\u2019 phase I trial to test the drug\u2019s safety in healthy people (see \u2018Basic facts about the trial\u2019). The Portuguese company Bial produced the drug, which was aimed at treating anxiety and motor disorders associated with Parkinson\u2019s disease, and chronic pain in people with cancer and other conditions. Biotrial, a French contract-research organization, conducted the trial at its facilities in Rennes. \n               boxed-text \n             But many key questions remain unanswered, says Marc Rodwin, a biomedical-law specialist at Suffolk University Law School in Boston, Massachusetts. This includes how the participants\u2019 injuries came about \u2014 magnetic-resonance-imaging scans showed dying and bleeding tissue deep in the brain \u2014 and whether the trials were conducted properly. \n               Brain enzyme \n             In particular, neither the French authorities nor Biotrial has disclosed the identity of the molecule administered in the trials. Bial did say that the drug was an FAAH (fatty acid amide hydrolase) inhibitor; FAAH is an enzyme produced in the brain and elsewhere in the body that breaks down neurotransmitters known as endocannabinoids. By blocking these enzymes, FAAH inhibitors cause endocannabinoids \u2014 which activate the same neural receptors as the active chemical in cannabis, and might have painkilling properties \u2014 to accumulate in the body. Some scientists scrambled over the weekend to try to establish the identity of the drug. Among them were Steve Alexander, a molecular pharmacologist at the University of Nottingham Medical School, UK, who has worked on FAAH for 15\u00a0years, and his colleague Christopher Southan, a curator for the Guide to Pharmacology database at the University of Edinburgh, UK. Together, the pair examined an online list of drugs in Bial\u2019s research pipeline. The search revealed just two molecules in phase\u00a0I trials, one of which fitted the therapeutic profile mentioned by Bial, although it was referred to only by a codename, BIA 10-2474. A French newspaper also published a recruitment form given to a volunteer in the trial that mentioned a drug with the same codename. \u201cAs best as we can make out, this compound has not been described in the [scientific] literature,\u201d says Alexander. \u201cSo we\u2019re working in the dark.\u201d It is common in the pharmaceutical industry not to reveal the structure of a molecule this early in development \u2014 although the practice has been criticized by researchers. \u201cThey declare codenames of candidates in development and hide the structure,\u201d says Southan. \u201cI think it\u2019s time they stopped.\u201d That lack of information left researchers trying to guess the structure from published Bial patents over the weekend, Southan adds. He also says that there seems to be no entry for the trial in clinical-trial registries. Numerous companies have developed FAAH inhibitors. There is none on the market, because most clinical trials have shown them to be ineffective \u2014 but the ones that were previously tested in people proved safe. \n               Off-target action \n             Many researchers believe that BIA 10-2474 is acting \u2018off target\u2019 \u2014 in other words, inhibiting a protein other than an FAAH. To investigate, researchers could radioactively label the compound and test it on brain tissue from cadavers to \u2018fish out\u2019 the proteins it binds to. Knowing the drug\u2019s molecular structure would also enable scientists to run computer predictions of this and other mechanisms that might result in toxicity. \u201cThere\u2019s a whole gamut of sophisticated computation analysis to predict anything you like,\u201d says Southan. Other researchers studying the FAAH pathway will probably look more closely at the potential for inhibitors to strike other proteins, Alexander says. \u201cI think it\u2019s very likely that both private industry and academic institutions will be looking very hard as to what this off-target affect might be.\u201d The lack of transparency is typical of French investigations, which tend to favour secrecy until firm conclusions are established, says a French health-law specialist who requested anonymity. He notes that the country\u2019s rules governing research on human subjects are strong and guarantee substantial protection of trial participants. He adds that safety incidents in clinical trials are almost unheard of in the country, with the price often being delays in the approval of trial applications. \n               Streamlined rules \n             In recent years, there have been two major changes to French laws affecting the approval of drugs in clinical trials. France strengthened its medical-safety laws following the 2009 withdrawal of a diabetes drug that was suspected of causing hundreds of deaths: a 2011 law, in particular, tightened rules on conflicts of interest for people involved in the country\u2019s drug-approval process, as well as giving authorities more power to demand safety tests of medications after they are approved. Then, in 2012, the government passed a separate law intended to streamline the rules for research involving humans, to speed up therapeutic progress and to make France a more attractive place for companies to carry out clinical trials. One possible safety issue in the trial of BIA\u00a010-2474, notes trial-design specialist Hill, is that all six participants seem to have been administered the doses simultaneously, rather than one receiving a test dose and being checked for adverse effects before others were given it. Simultaneous rather than sequential administration was identified as problematic in a  disastrous UK clinical trial in 2006  that caused multiple organ failure in six participants. \u201cFrom the 2006 catastrophe in London, I had concluded that treating several individuals with the same dose on the same day in a phase\u00a0I trial was a big mistake,\u201d says Hill. Jean-Marc Gandon, the president and chief executive of Biotrial, says that he cannot immediately respond to queries from  Nature , that he is focused on trying to save the patients and that the company will respond later. Bial spokeswoman Susana Vasconcelos says that the trial had been conducted \u201cin accordance with all the good international practices guidelines, with the completion of tests and preclinical trials\u201d and that the company \u201cis committed to determine thoroughly and exhaustively the causes which are at the origin of this situation\u201d. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Fresh light thrown on tragic drug trial 2007-Jan-25 \n                   \n                     New test could weed out dangerous drug trials 2006-Dec-07 \n                   \n                     Drug to blame for clinical-trial disaster? 2006-Apr-05 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19183", "url": "https://www.nature.com/articles/nature.2016.19183", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Work that describes harm from crops was cited in Italian Senate hearing. Papers that describe harmful effects to animals fed genetically modified (GM) crops are under scrutiny for alleged data manipulation. The leaked findings of an ongoing investigation at the University of Naples in Italy suggest that images in the papers may have been intentionally altered. The leader of the lab that carried out the work there says that there is no substance to this claim. The papers\u2019 findings run counter to those of numerous safety tests carried out by food and drug agencies around the world, which indicate that there are no dangers associated with eating GM food. But the work has been widely cited on anti-GM websites \u2014 and results of the experiments that the papers describe were referenced in an Italian Senate hearing last July on whether the country should allow cultivation of safety-approved GM crops. \u201cThe case is very important also because these papers have been used politically in the debate on GM crops,\u201d says Italian senator  Elena Cattaneo , a neuroscientist at the University of Milan whose concerns about the work triggered the investigation. Following the Senate hearing, Cattaneo took a closer look at three papers 1 , 2 , 3 , which all emerged from a research lab at the University of Naples, headed by veterinary scientist Federico Infascelli. They describe experiments on goat kids born to mothers fed on GM soya-bean meal and conclude that fragments of the foreign gene in the soya bean can be transported across the gut and secreted in the milk, influencing the biology of the suckling kids. \n               Gel manipulation \n             Cattaneo noted what looked like problems in all three papers: sections of images of electrophoresis gels appeared to have been obliterated, and some of the images in different papers appeared to be identical but with captions describing different experiments. She then commissioned Enrico Bucci, head of the biomedical services and information consultancy firm BioDigitalValley in Aosta, Italy, to carry out a forensic analysis of all three papers. The analysis suggested that the papers did indeed contain manipulated and reused images. Cattaneo contacted the journals concerned in September last year, and in November forwarded the analysis to the University of Naples. The university rector, Gaetano Manfredi, an engineer, immediately launched the university investigation, which is nearly complete. He says that the university will probably announce any resulting actions by the end of February. Ahead of this, however, details of the confidential findings of the investigation committee \u2014 composed of scientists in and outside of Naples \u2014 were leaked to the Italian press. Tommaso Russo, a molecular biologist at the University of Naples who is responsible for coordinating the investigation, told  Nature  that the committee has found that the papers contain intentional data manipulation. But, according to the Italian newspaper  La Repubblica , Infascelli said that there is no substance to these allegations, and that an expert that he\u00a0consulted about the papers had ruled out the possibility of data manipulation. Infascelli declined to discuss the case with  Nature  until the investigation is complete. \n               Retracted paper \n             On 14 January, Bucci  posted online his analysis  of the papers under investigation, as well as of four more papers on GM feed co-authored by Infascelli, and a PhD thesis from Infascelli\u2019s lab. The analysis claims evidence for image manipulation in all eight papers. Bucci has informed the rector and Infascelli of his findings. Since Cattaneo sent her findings to the journals concerned, one of the three papers under investigation has been retracted: last month, the 2013  Food and Nutrition Sciences  paper 2  was retracted, with a citation of \u201cself-plagiarism\u201d. However, the journal noted that the results were still valid and that it considered the issues an \u201chonest error\u201d. Cattaneo is not the only scientist to have raised concerns about papers from Infascelli\u2019s lab. Plant geneticist Wayne Parrott at the University of Georgia in Athens notified the relevant journals of his independent concerns about image manipulation in the three papers under investigation, and in one more from 2006 that claims a metabolic impact of GM food in rabbits 4 . (This paper also appears in Bucci's analysis.) The investigation at the University of Naples is the first to test formal rules on scientific misconduct that Manfredi introduced last July. Two years ago, police took over  an investigation into alleged misconduct in the medical faculty  because the university had no formal misconduct procedures and had failed to take up the case. That case is still ongoing. \n                 Tweet \n                 Follow @NatureNews \n               \n                 weibo \n               \n                     Image search triggers Italian police probe 2013-Dec-04 \n                   \n                     Call the cops 2013-Dec-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19179", "url": "https://www.nature.com/articles/nature.2016.19179", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Peace petition leads to arrests and university investigations. Hundreds of Turkish academics are waiting to find out whether they will be prosecuted or sacked for spreading \u201cterrorist propaganda\u201d, after they signed a petition calling for violence to end in Turkey\u2019s southeast, where government forces have been fighting Kurdish separatists. After the petition provoked a furious response from Turkey's president Recep Tayyip Erdo\u011fan, several universities in the country have begun investigations into signatories among their faculty \u2014 which could lead to their dismissal if accusations of unlawful political agitation hold up. On 15 January, police arrested and later released 27 academics, according to local media reports, including economists, physicians and scientists. \u201cWe are accused of defamation of the state and of terrorist propaganda,\u201d says Zeynep K\u0131v\u0131lc\u0131m, a law professor at Istanbul University, who has signed the petition and said she knew of several arrests. \u201cWe are all waiting for the police,\u201d she told  Nature  on 15 January. Turkey\u2019s government has previously  clamped down on scientists and students who question its policies ,  imprisoned scientists charged with terrorism offenses , and restricted the freedom of funding agencies and scientific academies. But the number of arrests and investigations makes the current episode one of\u00a0the larger Turkish attacks on freedom of expression in recent years, prompting outrage among human-rights advocates. \u201cState and police repression of academics who raise their voice for peace is completely unacceptable and violates Turkish and international human-rights law,\u201d says Metin Bakkalci, the Ankara-based secretary-general of the Human Rights Foundation of Turkey. \u201cUnfortunately, academics in our country have been facing pressure for 'undesired' political activity for many years.\u201d Scientists had hoped for more liberal policies after  parliamentary elections last June  stripped Erdo\u011fan\u2019s increasingly repressive Justice and Development Party (AKP) of an outright majority \u2014 but the president re-established his party\u2019s grip after a second round of elections in November. \n             Peace petition \n           By 15 January, almost 2,000 Turkish academics from 90 or so universities had signed a petition \u2014 launched a week earlier \u2014 that called on the Turkish government to end the fighting against Kurdish militants. Thousands of civilians have been killed in the longstanding conflict, which  flared up again last July  after a ceasefire collapsed. \u201cAs academics and researchers of this country, we will not be a party to this crime,\u201d signatories declared. Several hundred western scientists and intellectuals, including linguist Noam Chomsky and gender theorist Judith Butler, have also publicly supported the petition. In an 12 January speech (made in the wake of terrorist attacks in Istanbul) Erdo\u011fan accused signatories of spreading and supporting Kurdish terrorist propaganda and undermining Turkey\u2019s national security. \u201cI call upon all our institutions: everyone who benefits from this state but is now an enemy of the state must be punished without further delay,\u201d he said. In response, the Turkish Higher Education Board (Y\u00d6K) and public prosecutors in several Turkish university cities launched investigations against academics who signed the petition. And several Turkish universities launched their own investigations into signatories at their institutions; some of them, including Abdullah G\u00fcl University in Kayseri, have asked signatories to resign. The rector of that university, \u0130hsan Sabuncuo\u011flu, has not responded to  Nature 's e-mail requests for comment. \n               Tweet \n               Follow @NatureNews \n             \n                   Turkish biomed hub spurs hope amid political strife 2015-Oct-07 \n                 \n                   Turkey election results delight scientists 2015-Jun-16 \n                 \n                   Scientists swept up in terrorism trials 2013-Aug-06 \n                 \n                   Turkey cracks down on academic freedom 2012-Jul-03 \n                 \n                   Secularist academic jailed in Turkey 2012-Jun-26 \n                 \n                   Turkish Higher Education Council \n                 \n                   Academics for Peace petition \n                 \n                   Human Rights Foundation of Turkey \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19186", "url": "https://www.nature.com/articles/nature.2016.19186", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Drugmaker commits to stockpiling 300,000 doses and beginning approval process. With the Ebola outbreak in West Africa stubbornly hanging on, officials have brokered an agreement to ensure that a vaccine is available to fight future occurrences. On 20 January, Gavi, the Vaccine Alliance, announced that it has paid US$5 million to Merck, the manufacturer of the  first Ebola vaccine shown to protect  against the virus in a human clinical trial. The deal marks the first time that the public-health organization has committed to purchase a vaccine before it has been licensed. In return for the payment from Gavi, Merck promises that it will seek to have the vaccine approved by a regulatory agency by 2017. The company has also asked permission from the World Health Organization (WHO) to use the vaccine if another epidemic arises before the vaccine is licensed, and to make a supply of at least 300,000 doses available by May for such use. \u201cWe wanted to make sure there was vaccine that was prepared and ready to be used if there was a potential outbreak,\u201d says Seth Berkley, chief executive of Gavi in Geneva, Switzerland. The  recurrence of Ebola in Sierra Leone  on 15 January \u2014 just one day after the WHO had declared that  spread of the virus had stopped  in West Africa \u2014 highlights the need for an Ebola vaccine stockpile, Berkley says. \u201cIt basically says we need to have a supply of vaccine available for potential outbreaks going forward, even if we get it completely under control and think we\u2019ve ended the problem,\u201d Berkley explains. Public-health experts fear that as the West Africa epidemic winds down, there is danger that the work of stockpiling, licensing and planning to administer Ebola vaccines will be set aside in favour of more pressing \u2014 and profitable \u2014 pursuits. \u201cWe are in the most tenuous situation with regard to Ebola vaccines that we\u2019ve seen since we started all of this,\u201d says Michael Osterholm, a public-health scientist at the University of Minnesota's Center for Infectious Disease Research and Policy in Minneapolis. A vast store of Ebola vaccines has been manufactured in the past year \u2014 approximately 2 million doses of three candidate vaccines made by Merck, Johnson & Johnson and GlaxoSmithKline. So far, more than 20,000 people have been vaccinated with these products, and thousands more will receive them in the coming months. Before the West Africa outbreak, only a handful of people had ever received a vaccination against Ebola. The existing supply should, at least in theory, be enough to provide crucial protection in a future outbreak for patients, their contacts and health-care workers, says Marie-Paule Kieny, assistant director-general for health systems and innovation at the WHO in Geneva. \n             Licensing barrier \n           But in practice, it remains unclear how those vaccines might be delivered during an outbreak. The biggest barrier is bureaucratic: none of the three vaccines has been submitted for approval by a regulatory body such as the US Food and Drug Administration or the European Medicines Agency. Sierra Leone and Guinea have made arrangements with the relevant companies to use the vaccines in clinical trials. But if Ebola were to arise elsewhere, negotiating similar agreements in new countries could delay the outbreak response. M\u00e9decins Sans Fronti\u00e8res (MSF; also known as Doctors Without Borders), which administered the Merck vaccine trial in West Africa, plans to continue using the vaccines in investigative mode if another outbreak occurs. That means spending extra time and money compared with using a licensed vaccine \u2014 patients in a trial must be informed of the risk of taking an unapproved product, and providers must keep strict records of how well the vaccines work and whether they cause side effects. And if the vaccine is already known to be effective, this approach might also not be the right way to proceed from an ethical standpoint. The Gavi agreement is intended to ease that problem by requiring Merck to seek an 'emergency use assessment and listing' \u2014 permission from the WHO to use the vaccine wherever it is needed without having to organize a clinical trial. Gavi says that Merck has already begun those discussions with the WHO, and that ultimately it might buy other vaccines if they are approved. The deal also addresses a problem facing drug companies: Ebola and other tropical diseases still mainly afflict people in poor countries, so there is little financial incentive to produce vaccines against them. The funding from Gavi to Merck is an 'advance market commitment' \u2014 a guarantee that Gavi will buy the vaccine once it is approved. \u201cIt says the company is not going to be left holding the bag,\u201d Berkley says. \n               Tweet \n               Follow @NatureNews \n             \n                   Ebola re-emerges in Sierra Leone 2016-Jan-15 \n                 \n                   Spread of Ebola ends: 7 lessons from a devastating epidemic 2016-Jan-14 \n                 \n                   Disease specialists identify post-Ebola threats 2015-Dec-07 \n                 \n                   How to beat the next Ebola 2015-Aug-05 \n                 \n                   How Ebola-vaccine success could reshape clinical-trial policy 2015-Aug-04 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19197", "url": "https://www.nature.com/articles/nature.2016.19197", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Huge collaboration raises questions about official reporting. Tens of millions more tonnes of fish have been taken from the seas than are recorded in official statistics, suggests a huge and controversial project aiming to estimate the \u2018true catch\u2019 of the world\u2019s fishing industry. The work is detailed in a paper in  Nature Communications 1  by fisheries researchers Daniel Pauly and Dirk Zeller of the University of British Columbia in Vancouver, and it builds on a decade-long project that has drawn in hundreds of researchers from around the world. According to Pauly and Zeller, global fisheries catches hit a peak of 130 million tonnes a year in 1996, and they have been declining strongly since then. This is substantially higher than the data collected by the Food and Agriculture Organization of the United Nations (FAO), which report that catches reached 86 million tonnes in 1996 and have fallen only slightly. This decline is due at least in part to collapses in some fish stocks, says Pauly. \n             Fishing for data \n           The FAO numbers have long been the only estimate of how many tonnes of fish are caught at a global level. But \u201cthe FAO doesn\u2019t have a mandate to correct the data they get\u201d, Pauly told journalists during a conference call. This leaves the organization reliant mainly on the numbers submitted by member countries, he says, and \u201cthe countries have the bad habit to report only the data they see\u201d. This means that many official statistics do not account for a huge amount of the world\u2019s fisheries catch, such as that by small-scale and subsistence fisheries or fish thrown back as \u2018discards\u2019 \u2014 species other than those being hunted. To fill in the holes in official statistics, Pauly\u2019s team embarked on an epic project to supplement the official baseline data from member nations. This included using results from peer-reviewed research, interviews with local specialists and consumption information from population surveys. The international effort has already produced scores of papers \u2014 many of them co-authored by Pauly \u2014 concerning individual countries. For example, one study has estimated that Senegal's catch is more than twice as large as the official FAO numbers. Some fisheries researchers, however, have  questioned Pauly\u2019s catch-reconstruction methods . He has also engaged in a sometimes-heated debate about whether data from catches can shed light on the state of fish populations remaining in the ocean. Pauly also feels that his team has had to jump through hoops to publish the paper. He notes that the paper has very large uncertainty levels on the graph detailing the key findings of the paper (see figure above). In fact, he says, the team had come up with relatively narrow confidence intervals by using a popular statistical method known as Monte Carlo. But one reviewer objected and, Pauly says, forced the use of a different method that gives \u201cabsurdly large confidence intervals\u201d. \u201cIn reality, given that our country estimates are independent (we made sure of that), some will be too high, some too low and things will cancel out, and thus generate narrow confidence intervals,\u201d Pauly wrote in an e-mail to  Nature . Overall, however, he is happy to point to the simple message of the research: \u201cThe catch of the world is higher than reported.\u201d In a statement, the FAO welcomed the paper, saying that \u201cthe idea of catch reconstructions has merit\u201d and noting that the reconstruction work builds in part on FAO data. The FAO adds that it has some \u201ctechnical reservations\u201d about the trends identified, but \u201cagrees with the basic conclusions of the paper: catch statistics (including estimates of additional sources of removals) can and should be improved, and this requires additional funding and international collaboration and country commitment\u201d. \n               Tweet \n               Follow @NatureNews \n             \n                   Fisheries: Eyes on the ocean 2015-Mar-17 \n                 \n                   Detective work uncovers under-reported overfishing 2013-Apr-02 \n                 \n                   Battling scientists reach consensus on health of global fish stocks 2009-Jul-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19198", "url": "https://www.nature.com/articles/nature.2016.19198", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Big US report documents increases in international collaboration and Chinese science output. China\u2019s share of global science and engineering publications has pulled within a percentage point of those from the United States, according to the latest research statistics published by the US National Science Foundation (NSF). The agency's  report , released on 19 January, also underscores the rising importance of international scientific collaboration. Between 2000 and 2013, the percentage of publications with authors from multiple countries rose from 13.2% to 19.2%. \u201cThe scientific landscape is increasingly multipolar,\u201d says Dan Arvizu, chairman of the National Science Board, which oversees the NSF and produces the biennial publication known as the  Science and Engineering Indicators . The report serves as a resource for lawmakers and federal agencies to understand global trends in research and how the United States fits into those. The past couple of  Indicators   have documented in stark terms  how Asian countries, particularly China,  have risen dramatically  in their production of both students and publications in science and engineering fields. This year\u2019s report reveals some nuances in that overall trend. \n             Foreigner friendly \n           International collaborations are on the rise, with scientists in smaller nations more likely to collaborate with foreign authors than those in larger ones. In 2013, just over one-half of science and engineering articles from institutions in the United Kingdom listed an international co-author; for the US the number was roughly one-third, and China about 15%. Different countries showed different propensities for co-authoring with others. Within the European Union, the United Kingdom, France and Germany had the highest percentages of international collaboration overall. US authors collaborated most frequently with authors from China, compared with other countries. And scientists from both China and Canada co-authored with US scientists at a higher rate than would be expected from their other international partnerships. By discipline, astronomy had the highest percentage of publications \u2014 52.7% \u2014 with international authors. Other areas with more than 20% international collaboration included the geosciences, mathematics, biological sciences and physics. The overall increase in collaboration is reflected in  other analyses , including the most recent scorecard from the Organisation for Economic Co-operation and Development. To discern trends among countries, the NSF report studied nearly 2.2 million peer-reviewed articles published in 2013. Of those, 412,542 (18.8%) came from the United States, and 401,435 (18.2%) came from China. But over the period 2003\u201313, US publications saw an average annual growth of 3.2%, whereas Chinese publications grew 18.9% annually. \n             Measures of growth \n           The increase in Chinese publications \u201cis a meaningful number for sure\u201d, says Richard Suttmeier of the University of Oregon in Eugene, who studies Chinese science policy. \u201cI don\u2019t think it\u2019s too surprising or astounding, but it\u2019s a measure of growing strength.\u201d But China has yet to catch up to the United States by other measures, he says \u2014 such as the extent to which it draws non-Chinese scientists to conduct research there. Viewed as a bloc, EU countries still lead total global publication output, producing 27.5% of all publications in 2013. The 2016  Indicators  report changed the metrics by which it measures publications. Instead of using the Thomson Reuters Science Citation Index and the Social Science Citation Index, the NSF went with Elsevier\u2019s Scopus database. The change was made to try to get a more accurate view of global trends, says Carol Robbins, the NSF senior analyst who oversaw the bibliometrics portion of the report. By using Scopus, the 2016 analysis was able to look at roughly 17,000 journals, compared to the 5,087 included in the previous report two years ago. The changes \u201cshow us a slightly more nuanced view of the world\u201d, Robbins says. \u201cWe see more-rapid growth in China and India in publications,\u201d she says, as well as more information about countries in the developing world. \n               Tweet \n               Follow @NatureNews \n             \n                   China predicted to outspend the US on science by 2020 2014-Nov-12 \n                 \n                   China becomes world\u2019s third-largest producer of research articles 2014-Feb-06 \n                 \n                   China tops Europe in R&D intensity 2014-Jan-08 \n                 \n                   Collaborations: The fourth age of research 2013-May-29 \n                 \n                   Research in Asia heats up 2012-Jan-24 \n                 \n                   Focus on quality, not just quantity 2011-Jul-20 \n                 \n                   Research sans fronti\u00e8res 2011-Mar-28 \n                 \n                   Nature Index 2015 Collaborations \n                 \n                   Science and Engineering Indicators 2016 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19216", "url": "https://www.nature.com/articles/nature.2016.19216", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Warming in the Pacific Ocean helps to shatter past records, and could bring even faster temperature rises. It\u2019s official: 2015 was the hottest year on record. Global data show that a  powerful El Ni\u00f1o  system, marked by warmed waters in the tropical Pacific Ocean, helped to drive atmospheric temperatures well past  2014\u2019s record highs . Some researchers suggest that broader Pacific trends could spell even more dramatic temperature increases in years to come. Released on 20 January, the global temperature data come from three independent records maintained by NASA, the US National Oceanic and Atmospheric Administration (NOAA) and the UK Met Office. All three data sets document unprecedented high temperatures in 2015, pushing the global average to at least 1 \u00baC above pre-industrial levels. Although El Ni\u00f1o boosted temperatures late in the year, US government scientists say that the steady increase in atmospheric concentrations of greenhouse gases continues to drive overall warming. \u201cThe reason why this is such a warm record year is because of the long-term trend,\u201d says Gavin Schmidt, director of NASA\u2019s Goddard Institute for Space Studies in New York City. \u201cAnd there is no evidence that this long-term trend has slowed.\u201d Average global surface temperatures in 2015 were 0.16 \u00b0C higher than in 2014, the next-warmest year on record, says NOAA. Almost all areas of the globe, including both land and sea, experienced above-normal temperatures. Satellite and balloon records of temperatures in the upper atmosphere showed less warming owing to a delayed response to El Ni\u00f1o, but are expected to rise faster in 2016. Overall, global temperatures have increased by 0.1\u20130.2 \u00baC per decade since the 1970s, says Thomas Karl, director of NOAA\u2019s National Centers for Environmental Information in Asheville, North Carolina. \u201cClearly the 2015 data continues the pattern,\u201d Karl says. \u201cThis trend will continue.\u201d \n               Pacific flip-flop \n             The current El Ni\u00f1o is predicted to continue to boost the average global temperature over the next several months. This could translate into another year of record heat. But the question facing scientists is whether the near-record El Ni\u00f1o that  developed in 2015  has helped to flip the Pacific Ocean into a warmer state that will favour the development of such systems in future, and will boost global surface temperatures. The Pacific Decadal Oscillation (PDO) is a 15- to 30-year cycle that increases sea surface temperatures across the eastern Pacific in its positive phase and produces cooler temperatures in its negative phase. Since 1998, after the last major El Ni\u00f1o and a subsequent La Ni\u00f1a cooling system, the PDO has been mostly negative. Some scientists say that the cooling  helped to suppress  the increase in global temperatures in the early part of the millennium. But since early 2014, the PDO has been largely positive. \u201cIt sure looks to me like we\u2019ve changed phases in the PDO,\u201d says Kevin Trenberth, a climate scientist at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado. Some studies have tied the PDO to long-term temperature trends 1 . The PDO was largely negative in the mid-1970s, when global temperature increases slowed. It was mostly positive in the 1980s and 1990s, when temperatures registered faster increases. But scientists debate the climatic links between the PDO and both El Ni\u00f1o and global temperature. \u201cIf you try to look at PDO and global temperatures, you can come up with a variety of relationships,\u201d says Karl, who questions whether the oscillation is an independent phenomenon or merely an extension of El Nino. \n               Climate evolution \n             Trenberth notes that the PDO is related to the El Ni\u00f1o\u2013La Ni\u00f1a cycle in the tropical Pacific. That leaves open the possibility that it could fade with El Ni\u00f1o, which models predict will diminish over the next several months. But he says that the PDO is also a result of longer-term fluctuations in ocean currents that push warm water deep into the ocean or keep it closer to the surface. Jerry Meehl, a climate modeller at the NCAR, has a study under review that suggests that the PDO is likely to remain in a positive state over the coming decade. In that analysis, Meehl and his colleagues plugged actual atmospheric and ocean data from 2013 into a global climate model and then ran the model forward to simulate how the climate might change. The model evolved into a positive PDO and remained there. \u201cOver the next ten years, we see higher rates of warming,\u201d says Meehl. He adds that this does not change the overall assessment that global warming has proceeded apace over the past century. Rather, he says that global temperatures vary and often increase in stepwise fashion over decades. Scientists are now trying to understand how ocean circulation works and how much changes in it can affect global temperatures. \u201cWe are still trying to figure that out,\u201d says Meehl. \u201cIt\u2019s really intriguing. That\u2019s why it\u2019s exciting for climate science.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Monster El Ni\u00f1o probed by meteorologists 2016-Jan-20 \n                   \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   \n                     Climate change: The case of the missing heat 2014-Jan-15 \n                   Reprints and Permissions"},
{"file_id": "529267a", "url": "https://www.nature.com/articles/529267a", "year": 2016, "authors": [{"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "Unprecedented Pacific Ocean campaign aims to improve forecasts for strong storms. Climate scientists this week began a research blitz to study El Ni\u00f1o, the climate trouble-maker that disrupts weather around much of the globe. For the next two months, US researchers will use specially outfitted planes, a research ship and hundreds of weather balloons to monitor the region in the tropical Pacific Ocean where El\u00a0Ni\u00f1o forms. Ultimately, the scientists say, their measurements could help to improve weather forecasts and unlock secrets about how powerful El Ni\u00f1o events evolve. \u201cWe\u2019re seeing an extreme climate state\u00a0\u2014 one that we know tends to produce extreme climate conditions worldwide,\u201d says Randall Dole, lead scientist on the project and a meteorologist with the US National Oceanic and Atmospheric Administration (NOAA) in Boulder, Colorado. \u201cWe\u2019re going right into the heart of that.\u201d The El Ni\u00f1o warming that has bloomed in the equatorial Pacific is one of the strongest on record, with ocean temperatures reaching as much as 3\u2009\u00b0C above normal across the central and eastern parts of the ocean basin. That heat triggers convection in the atmosphere that re-routes major air currents, often sending strong storms towards California while drying out parts of southeast Asia, Australia and eastern South America. But researchers have few data on the atmospheric changes in the core of the El\u00a0Ni\u00f1o region because the remote equatorial Pacific is essentially a meteorological black hole. To begin the campaign, NOAA sent its Gulfstream-IV research jet to Hawaii, its base for about 20 flights south towards the Equator. Using onboard remote-sensing equipment and dropsondes \u2014 packages of instruments released from the plane \u2014 the team will measure winds, temperature, air pressure and moisture from a height of 12\u201314 kilometres down to the ocean surface (see \u2018Hunting Godzilla\u2019). In February, NASA\u2019s unmanned Global Hawk aircraft will join the effort, prowling the eastern part of the Pacific in 4 flights lasting up to 24 hours each. At the same time, NOAA will launch instrument packages on weather balloons from Kiritimati, or Christmas Island, an atoll near the Equator in the heart of the region in which El\u00a0Ni\u00f1o forms. And researchers will also release balloon-borne instruments from the NOAA research ship  Ronald H. Brown  as it conducts a previously planned cruise in the central Pacific. \n               Seizing the moment \n             The idea for the roughly US$3-million campaign developed as the warming gathered strength last year; Dole and his colleagues realized that they had a rare opportunity to collect the first detailed atmospheric measurements of a monster El\u00a0Ni\u00f1o. NOAA scrambled to pull the campaign together in a few months\u00a0\u2014 rather than the usual two to three\u00a0years that it usually takes to mount a major meteorological field project. The agency had some resources to spare: thanks to the way El Ni\u00f1o alters conditions over the Atlantic, there were relatively few tropical storms there last year. That meant that NOAA did not use all of the flying time budgeted for the Gulfstream-IV hurricane hunter, which flies over storms to collect data useful for forecasters. The quiet hurricane season also meant that the Global Hawk did not make as many research flights in the Atlantic as planned last year. \u201cWe\u2019ve done this largely by reallocating,\u201d says Dole. \u201cWe\u2019re working within the existing budget and shifting everything around.\u201d Alexey Fedorov, a climate modeller at Yale University in New Haven, Connecticut, says that because extreme El\u00a0Ni\u00f1o events are so rare, \u201cit is important to use any opportunity to gather as much data as possible\u201d. Fedorov, who is not part of the campaign, says that researchers lack a full understanding of the way that strong El\u00a0Ni\u00f1os evolve and alter global weather patterns. The information gathered over the next few months could yield long-term dividends for El\u00a0Ni\u00f1o researchers, says Dole. \u201cIf we do this well, it will impact our community for the next 10 or 20 years.\u201d But the project\u2019s immediate goal is to help forecasters to understand how the unruly atmosphere will affect weather now. By gathering direct measurements from this data-poor zone, leaders of the NOAA campaign hope to improve weather forecasts and allow researchers to test weather models to better understand the source of errors in those models. Data from the Global Hawk will also aid meteorologists tracking El\u00a0Ni\u00f1o-spawned storms as they barrel down on the western United States, says Dole. Over the past few weeks, coastal California has been pummelled by such storms, and more are expected. As part of the El\u00a0Ni\u00f1o campaign, NOAA has installed a scanning X-band radar south of San Francisco Bay that will measure precipitation in approaching storms. The agency will upload data from the field campaign to the World Meteorological Organization\u2019s Global Telecommunications System, so that forecasters around the globe can access the observations. Peter Bauer, an atmospheric modeller at the European Centre for Medium-Range Weather Forecasts in Reading, UK, says that he plans to feed the data into model experiments with the aim of improving forecasts for Europe. The campaign, he says, \u201chas potentially a very big impact\u201d. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Hunting the Godzilla El Ni\u00f1o 2015-Oct-20 \n                   \n                     Corals worldwide hit by bleaching 2015-Oct-08 \n                   \n                     Developing El Ni\u00f1o could be strongest on record 2015-Aug-14 \n                   \n                     NOAA El Ni\u00f1o Rapid Response Field Campaign \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19221", "url": "https://www.nature.com/articles/nature.2016.19221", "year": 2016, "authors": [{"name": "Ewen Callaway"}, {"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "UK's Royal Statistical Society among those demanding more information after the release of trial's protocol. Scientists are voicing concerns over the design of a  French drug trial that left one participant dead and several others with severe health problems  \u2014 and they are calling for more information to be released. The researchers, including those in the UK\u2019s Royal Statistical Society (RSS), have examined a document that describes how the trial was conducted, and say that major pieces of information are still missing. In particular, the researchers note a lack of information about whether the design included adequate time intervals between the individuals given the multiple-dose regimen of the drug that caused the problems. Such intervals allow investigators to watch for possible side effects in one volunteer before they expose subsequent volunteers to the drug. The incorporation of such delays was identified as important both by an RSS working group and the European Medicines Agency, after a clinical trial went  disastrously wrong in the United Kingdom  in 2006. \u201cA key aspect is a proper interval of time between dosing of successive volunteers,\u201d says biostatistician Sheila Bird of the Medical Research Council Biostatistics Unit at the University of Cambridge, UK, who is a member of the RSS working group, which focuses on 'first-in-human' clinical trials. The RSS is now calling on the Portuguese company Bial, which sponsored the trial (conducted by French contract-research oranization Biotrial in Rennes), to release further information about its design and the tests that preceded it. Bial spokesperson Susana Vasconcelos told  Nature  that the company denounces the release of the protocol, as well as \u201cdiscussion on this subject without knowing the results of the current investigations and all clinical data regarding the volunteers of the clinical trial\u201d. \n             Protocol released \n           In the days after the trial went wrong \u2014 the first public acknowledgement of the incidents came on 15 January \u2014 little information was available,  frustrating those who wanted to understand what had happened . Then, on 22 January, France's National Agency for Medicines and Health Products Safety (ANSM)  released the protocol of the drug trial , after the newspaper  Le Figaro  published a version of the same document. The document identifies, for the first time, the chemical makeup of the drug \u2014 which was aimed at treating anxiety and motor disorders associated with Parkinson\u2019s disease, and chronic pain in people with cancer and other conditions \u2014 and the regimen that the study volunteers followed. But it still leaves many questions unanswered. Such phase I trials are conducted in healthy volunteers to determine the safety and dosing of a drug, before moving on to studies that test the effectiveness of drugs in people with a particular condition. In the study, the first volunteers received either just a single dose of the oral drug, which is known as BIA 10-2474, or a placebo.\u00a0After this, different volunteers were given a single administration of increasingly higher doses of the drug. The six volunteers who were hospitalised \u2014 some with severe symptoms such as bleeding or dying tissue in the brain \u2014 were the first to receive multiple doses of the drug, administered on successive days. (The first patient to fall ill died on 17 January; one other has recovered sufficiently to be discharged from hospital, and  the health of the remaining patients has improved .) \n             boxed-text \n           According to the newly released protocol, the participants in this part of the trial were to receive one dose of the drug each day for ten consecutive days. But Bird says that the protocol does not state whether there was any interval between the individuals who were beginning this regimen, or the dosage that these participants received. \n             Intervals recommended \n           After the 2006 UK trial of the antibody treatment TGN1412, which  led to the hospitalization of six volunteers , Bird's working group recommended that such intervals be included in the design of phase I trials. Guidelines drafted by the EMA after that disaster also underscores the importance of these intervals and says that their length should be justified by previous data collected in humans and animals. According to the timeline detailed by France\u2019s health minister, Marisol Touraine, those who fell ill had begun to take the experimental treatment on the same day, 7 January, and adverse symptoms appeared in the first subject \u2014 who was hospitalized with brain death \u2014 on 10 January. The trial was halted on 11 January, and the five others were hospitalized in the days that followed. Catherine Hill, a biostatistician who previously served on the ANSM's scientific advisory board, says that it was \u201ca big mistake\u201d to begin giving the six volunteers the drug on the same day. She says that the trial should have incorporated a delay between volunteers as they started the multiple-dose regimen. \u201cYou have to do things reasonably, and I think it\u2019s an unreasonable protocol,\u201d she says. Bial's Vasconcelos says: \u201cWe reiterate that the development of this molecule has been conducted since the beginning in accordance with all the good international practices, with the completion of tests and preclinical trials, particularly in the area of toxicology. The results obtained in accordance with international guidelines have permitted the start of the clinical trials in humans.\" In a statement on 22 January, the RSS called for the publication of the \u2018investigator brochure\u2019, which details the preclinical studies that led up to the trial. According to the ANSM, Bial declined to publish the brochure and another document, citing French laws that protect the release of trade secrets. Bird says that the release of such information is important to ensure the safety of participants in other clinical studies. \u201cThere are other studies going on around the world right now, and we want to know what the design problems were.\u201d On the same day, the British Pharmacological Society published a statement calling for improved early access to data from catastrophic clinical trials, following the recent disaster in France. \n               Tweet \n               Follow @NatureNews \n             \n                   Scientists in the dark after French clinical trial proves fatal 2016-Jan-18 \n                 \n                   Fresh light thrown on tragic drug trial 2007-Jan-25 \n                 \n                   New test could weed out dangerous drug trials 2006-Dec-07 \n                 \n                   Drug to blame for clinical-trial disaster? 2006-Apr-05 \n                 Reprints and Permissions"},
{"file_id": "529449a", "url": "https://www.nature.com/articles/529449a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "But it is unclear how well the results match the condition in humans. The laboratory monkeys run obsessively in circles, largely ignore their peers and grunt anxiously when stared at. Engineered to have a gene that is related to autism spectrum disorder in people, the monkeys are the most realistic animal model of the condition yet, say their creators. Researchers hope that the animals will open up new ways to test treatments and investigate the biology of autism. But the jury is still out on how well the monkeys\u2019 condition matches human autism. Autism has a vast array of symptoms and types, and researchers think that at least 100\u00a0genes play a part. The scientists who led the latest work, which is published on 25\u00a0January in  Nature  ( Z.Liuetal.Naturehttp://doi.org/bb3k;2016 ), turned to the autism-related gene  MECP2 : many of the symptoms of autism are found in people who have extra copies of the gene ( MECP2 -duplication syndrome) as well as in people who have certain mutations in this gene (Rett\u2019s syndrome). Researchers have engineered monkeys to have autism-related genes before ( H. Liu  et al. Cell Stem Cell   14,  323\u2013328; 2014 ), but this is the first published demonstration of a link between those genes and the animals\u2019 behaviour. Back in 2010, the team that did the latest work, led by researchers at the Chinese Academy of Sciences\u2019 Institute of Neuroscience in Shanghai, attached human  MECP2  genes to a harmless virus, which they injected into the eggs of crab-eating macaque monkeys ( Macaca fascicularis ). The eggs were then fertilized, and the developing embryos were implanted into female monkeys. The result was eight genetically manipulated newborns, which each had between one and seven extra copies of  MECP2.  Examinations of other, stillborn monkeys revealed that the extra copies were being expressed in the brain. \u201cThat was the first exciting moment,\u201d says Zilong Qiu, a molecular biologist at the Institute of Neuroscience and a co-author of the paper. The next breakthrough came about a year later, when the monkeys showed behaviours that hinted at autism: running around in tight circles in a strange manner. \u201cIf another monkey is in its way, it will either jump over the monkey, or go around it, but then it would return to its original circular path,\u201d says co-author Sun Qiang, a reproductive biologist at the institute. The team launched a battery of behavioural tests, which showed that all of the monkeys had at least one autism-like symptom, such as repetitive or asocial behaviour, and that the symptoms were more severe in males, as seen in people with the  MECP2  duplications. But this still wasn\u2019t enough to be sure that the monkeys were a sound model of autism \u2014 and a paper that the team submitted for publication in 2013 was rejected. Among other things, reviewers wanted to know whether the unusual behaviour was just the result of fiddling around with the genome. \u201cWe needed to show where the gene makes a difference,\u201d says Qiu. That opportunity came with the next generation of macaques, which the team created with unprecedented speed. When the monkeys were 27\u00a0months old and not yet sexually mature, Sun\u2019s team took testes from the males, matured the tissue artificially by  grafting it under the skin on the backs of castrated mice , and used the resulting sperm to fertilize eggs from non-engineered macaques. The offspring showed asocial behaviour at about 11 months. That both gene and symptoms seemed to be passed on to a second generation was finally enough to convince reviewers, says Qiu. The macaque model is \u201csuperior\u201d to existing mouse models of autism because \u201cit actually shows more clearly some of the autism-like behaviours\u201d, says Alysson Muotri, who researches stem cells, autism and Rett\u2019s syndrome at the University of California, San Diego. But he adds that the symptoms in both mice and monkeys still seem less severe than \u201cwhat we actually observe in human patients\u201d. \u201cIt remains to be seen if the model can actually generate novel insights into the human condition,\u201d he says. Huda Zoghbi, a pioneer of  MECP2  studies in mice at Baylor College of Medicine in Houston, Texas, is even more cautious. The monkeys do not mimic some of the human  MECP2 -duplication symptoms, such as seizures and severe cognitive problems, she notes. This could be because the expression of the gene in the monkey model is triggered by a different mechanism from that in humans \u2014 a limitation that the authors recognize \u2014 and she advises caution in using the model to make assumptions about human autism. Qiu, meanwhile, is excited by the prospect of using the model to identify exactly where in the brain the  MECP2  overexpression causes trouble. His team is already using brain-imaging technology on the monkeys to pinpoint such areas. Next, the researchers plan to use the CRISPR gene-editing technique to knock out the extra  MECP2  copies in cells in those regions and then check whether the autisim-like symptoms stop. It is unlikely that such a technique would be approved for use in people any time soon. But the regions identified in the monkey study could be targeted with other, existing treatments \u2014 such as deep brain stimulation, which has had success in treating Parkinson\u2019s disease and depression. Because the structure of the mouse brain is so different from that of the human brain, Qiu says that the monkey imaging will allow more parallels to be drawn with humans than mice studies could. Working with a mental-health hospital, the team is also trying to identify the autism-linked genes that are most common in the Chinese population. If non-human primates prove to be a useful model for psychiatric disorders, China and other countries that are investing heavily in research on monkeys,  such as Japan , could gain an edge in brain research. Muotri says that such studies probably wouldn\u2019t be done in the United States, for example, where research on non-human primates is more expensive and controversial than it is in Japan or China. \u201cChina and Japan have a clear advantage over the US on this area,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                 weibo \n               \n                     China's bold push into genetically customized animals 2015-Nov-18 \n                   \n                     Marmosets are stars of Japan\u2019s ambitious brain project 2014-Oct-08 \n                   \n                     First monkeys with customized mutations born 2014-Jan-30 \n                   \n                     Precision gene editing paves way for transgenic monkeys 2013-Nov-06 \n                   \n                     Bone-marrow transplant reverses Rett syndrome in mice 2012-Mar-18 \n                   \n                     Special issue on neuroscience: The autism enigma 2011-Nov-02 \n                   \n                     Marmoset model takes centre stage 2009-May-27 \n                   \n                     Autism spotlight \n                   \n                     Chinese Academy of Sciences Institute of Neuroscience \n                   \n                     Suzhou Non-human Primate Facility \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19225", "url": "https://www.nature.com/articles/nature.2016.19225", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Illegal killing rises in Zimbabwe and Namibia, even as it dips in South Africa. TREND WATCH:  At least 1,312 rhinoceros were illegally killed in Africa in 2015 \u2014 a record high for the continent, according to figures from TRAFFIC, a wildlife-trade monitoring network based in Cambridge, UK. South Africa, which has the largest share of this poaching, reported a small decrease on 21 January \u2014 from 1,215 rhinos in 2014 to 1,175 in 2015. But that was more than offset by rises in illegal killing in neighbouring countries (see \u2018African rhino poaching on the rise\u2019). \u201cFor Africa as a whole, this is the worst year in decades for rhino poaching,\u201d said Tom Milliken, a rhino expert with TRAFFIC, in a statement released to the media. \u201cThe poaching epicentre has spread to neighbouring Namibia and Zimbabwe, but is nowhere near being extinguished in South Africa: despite some commendable efforts being made, we\u2019re still a very long way from seeing the light at the end of this very dark tunnel.\u201d Rhino conservation measures will be under discussion at the 17th meeting of CITES, the Convention on International Trade in Endangered Species of Wild Fauna and Flora, which  will be held in September  in Johannesburg, South Africa. \n               Tweet \n               Follow @NatureNews \n             \n                   Nations pledge to make poaching a 'serious crime' 2014-Feb-14 \n                 \n                   Tusk tracking will tackle illegal trade 2013-Feb-27 \n                 \n                   Endangered species: Sex and the single rhinoceros 2012-May-30 \n                 \n                   TRAFFIC: protecting rhinos \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19176", "url": "https://www.nature.com/articles/nature.2016.19176", "year": 2016, "authors": [{"name": "Ron Cowen"}], "parsed_as_year": "2006_or_before", "body": "Origin of exploding star that is twice as luminous as any other remains unclear. Seven months after it was  first spotted , a puzzle still hangs over the origin of the brightest supernova ever seen. The exploding star, which was found in June 2015 and blazed brighter than 570 billion Suns at its peak, is one of a class of 'superluminous' supernovae. More than 100 times brighter and 1000 times rarer than ordinary supernovae, they have been spotted thanks to a growing number of automated telescope surveys devoted to spotting ephemeral stellar events over wide patches of sky (see 'The brightest supernovae'). Full details of last year\u2019s explosion, known as ASASSN-15lh, were reported on 15 January in  Science 1 . \u201cIt challenges all our previous theories of explosion mechanisms and power sources of superluminous supernovae,\u201d says Subo Dong, an astronomer at the Kavli Institute for Astronomy and Astrophysics at Peking University in Beijing, whose team discovered the event. \n             Obscure origins \n           As Dong had noted in a  report  posted on the arXiv physics preprint server last July 2 , the blast belongs to a class of superluminous supernovae that are low in hydrogen. These kinds of explosions are thought to be fuelled by magnetars: compact, rapidly rotating, highly magnetized cores that are left behind after a supernova explosion casts off a star\u2019s outer layers. The magnetar\u2019s powerful magnetic field launches a wind that heats gas flying from the supernova. But ASASSN-15lh is hotter and more luminous than other hydrogen-poor supernovae \u2014 so much so that a magnetar would need to be spinning at its maximum possible rate and convert its spin energy into heat at 100% efficiency, says Dong. Because such changes are so extreme, Dong doubts that the magnetar model would work. And whereas other hydrogen-poor supernovae reside in dim dwarf galaxies, ASASSN-15lh seems to originate near the centre of a massive galaxy that is brighter than the Milky Way \u2014 although Dong\u2019s team says that it can\u2019t rule out the possibility that it exploded in a dwarf galaxy that seemed to align with the larger one. There\u2019s a slim chance that ASASSN-15lh is not a supernova at all. Instead, it might be the fireworks associated with a star that has been gravitationally torn apart by a supermassive black hole, says supernova observer Edo Berger at Harvard University in Cambridge, Massachusetts, who was not part of the study. Dong\u2019s team will now use the Hubble Space Telescope to try to figure out more about the blast\u2019s home galaxy. \n               Tweet \n               Follow @NatureNews \n             \n                   Astronomers spy brightest-ever supernova 2015-Jul-13 \n                 \n                   Astrophysics: Super-luminous supernovae on the rise 2013-Oct-16 \n                 \n                   Hydrogen-poor superluminous stellar explosions 2011-Jun-08 \n                 Reprints and Permissions"},
{"file_id": "529266a", "url": "https://www.nature.com/articles/529266a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Gravitational signature hints at massive object that orbits the Sun every 20,000 years. A century after observatory founder Percival Lowell speculated that  a \u2018Planet X\u2019 lurks  at the fringes of the Solar System, astronomers say that they have the best evidence yet for such a world. They call it Planet Nine. Orbital calculations suggest that Planet Nine, if it exists, is about ten times the mass of Earth and swings an elliptical path around the Sun once every 10,000\u201320,000 years. It would never get closer than about 200 times the Earth\u2013Sun distance, or 200 astronomical units ( au ). That range would put it far beyond Pluto, in the realm of icy bodies known as the Kuiper belt. No one has seen Planet Nine, but researchers have inferred its existence from the way several other Kuiper belt objects (KBOs) move. And given the history of speculation about distant planets (see \u2018Solving for X\u2019), Planet Nine may end up in the dustbin of good ideas gone wrong. \n               boxed-text \n             \u201cIf I read this paper out of the blue, my first reaction would be that it was crazy,\u201d says Mike Brown, an astronomer at the California Institute of Technology in Pasadena who was part of the research team. \u201cBut if you look at the evidence and statistics, it\u2019s very hard to come away with any other conclusion.\u201d Brown and his colleague Konstantin Batygin propose Planet Nine in a paper published on 20\u00a0January in the  Astronomical Journal  ( K.\u00a0Batygin and M.\u00a0E.\u00a0Brown  Astronom.\u00a0J.    151,  22; 2016 ). Alessandro Morbidelli, an orbital-dynamics specialist at the University of the C\u00f4te d\u2019Azur in Nice, France, who has reviewed the paper in detail, says he is \u201cquite convinced\u201d that the planet exists. Others are not so sure. \u201cI have seen many, many such claims in my career,\u201d says Hal Levison, a planetary scientist at the Southwest Research Institute in Boulder, Colorado. \u201cAnd all of them have been wrong.\u201d Claims of Planet Nine\u2019s existence recall a period in the nineteenth century when astronomers predicted and then discovered Neptune by studying tiny perturbations in the orbit of Uranus. The gravity of some unseen body must be tugging on Uranus, they said\u00a0\u2014\u00a0and they were right. \u201cIn some sense we\u2019re hoping to relive history a little bit,\u201d says Batygin. The story of Planet Nine began in 2014, when a pair of astronomers reported  finding a KBO called 2012 VP 113 . Its stretched-out orbit never came closer than 80\u2009 au  to the Sun ( C.\u00a0A.\u00a0Trujillo and S.\u00a0S.\u00a0Sheppard  Nature    507,  471\u2013474; 2014 ). (Pluto, at its most distant, is 48\u2009 au  from the Sun.) VP 113  joined  the dwarf planet Sedna  as only the second known object with a very distant orbit. In their report, Chadwick Trujillo at the Gemini Observatory in Hilo, Hawaii, and Scott Sheppard of the Carnegie Institution for Science in Washington DC said that the orbits of these objects suggested that yet another object, a planet bigger than Earth, could exist at around 250\u2009 au  (see \u2018Far afield\u2019). Batygin and Brown picked up the challenge. \u201cOur main goal at that point was to show that this idea is crazy,\u201d says Brown. But Trujillo and Sheppard had noted that Sedna, VP 113 , and several other KBOs all shared a peculiar property: their closest approach to the Sun lay in the plane of the Solar System, and they all moved from south to north when crossing that plane. Batygin and Brown analysed the orbits further and discovered that their long axes were physically aligned, too, as if something had nudged them to occupy the same region of space around the Sun. The team concluded that a massive object must be shepherding the objects. \u201cWe have a gravitational signature of a giant planet in the outer Solar System,\u201d Batygin says. Planet Nine \u2014 informally known as Phattie \u2014 is probably smaller than Neptune and icy with a gassy outer layer. The gravitational effect of Uranus and Neptune would have flung it outward in the first 3 million years of the Solar System\u2019s existence, Batygin says. Actually spotting Planet Nine through a telescope could be difficult because it would spend most of its time very far from the Sun, making it faint and hard to see, notes Meg Schwamb, an astronomer at the Academia Sinica in Taipei. Brown and Batygin have been looking for it using the Subaru telescope in Hawaii, so far without success. The  Large Synoptic Survey Telescope in Chile  will have a good chance of catching it when it starts operating early next decade, Brown says. But he and Batygin say that there are other ways to test the existence of Planet Nine. Its gravitational influence would also produce a population of KBOs with orbits at steeply inclined angles. A few of these have already been spotted, but discovering more would strengthen the statistics of the discovery and help to clarify whether Planet Nine really exists or not, says David Nesvorny, a planetary scientist at the Southwest Research Institute. So it\u2019s back to the telescopes. \u201cIt really points to the fact that more extreme KBOs need to be found,\u201d says Trujillo. \u201cThe location is not known well enough to just point a telescope at it and say, \u2018there it is\u2019.\u201d\n \n                 Tweet \n                 Follow @NatureNews \n               \n                 weibo \n               \n                     Astronomers spy most distant Solar System object ever 2015-Nov-10 \n                   \n                     Dwarf planet stretches Solar System's edge 2014-Mar-26 \n                   \n                     Dwarf planet found to be heftier than Pluto 2007-Jun-14 \n                   \n                     Astronomers spy new 'planet' 2004-Mar-15 \n                   \n                     Nature  special on dwarf planets: Pluto and Ceres \n                   \n                     Extreme outer solar system objects, from Scott Sheppard \n                   \n                     Konstantin Batygin \n                   \n                     Mike Brown \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19226", "url": "https://www.nature.com/articles/nature.2016.19226", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Have you been paying attention to January's science news? Reprints and Permissions"},
{"file_id": "nature.2016.19215", "url": "https://www.nature.com/articles/nature.2016.19215", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "'RNA nanoconstruction' has been the focus of a decade-long controversy. Update, 4 February:  Science  published an ' editorial  retraction'  of the 2004 chemistry paper on 4 February, 2016. It stated that neither Feldheim nor Eaton    agreed to the retraction, and that Gugliotti could not be reached for comment. A  long-running battle  over findings reported in a 2004 chemistry paper in  Science 1  may finally be drawing to a close. On 21 January, Marcia McNutt, the journal\u2019s editor-in-chief, published an \u2018editorial expression of concern\u2019 saying that  Science  would either retract or correct the paper, which described using RNA to assemble nanoparticles made of palladium. The US National Science Foundation (NSF) funded the research, and in 2013 the agency's inspector-general recommended that it make a finding of research misconduct, alleging that the authors had falsified data in the paper. In a final report in 2015, the NSF concluded that the evidence did not support that misconduct charge. The authors are chemists Daniel Feldheim and Bruce Eaton of the University of Colorado Boulder, who were at North Carolina State University (NCSU) in Raleigh at the time of the work, and former NCSU graduate student Lina Gugliotti. All three have been barred from receiving future NSF funding unless they take \u201cspecific actions to correct publications containing the misleading results\u201d. \u201cOf course I am disappointed with  Science \u2019s decision,\u201d Feldheim wrote to  Nature . \u201cSuch measures were not requested by any governing or investigatory body and I do not believe it is in the best interest of the scientific community.\u201d \n             Crystal technique \n           The saga began when the paper described a method for using RNA sequences to grow tiny hexagonal crystals of palladium metal. The work hinted that RNA might have a role in producing inorganic materials in the environment. It has been cited more than 135 times. But Stefan Franzen, another chemist at NCSU, soon raised questions about the work. In a series of publications, he challenged whether the team had really seen RNA-driven action 2  or stable palladium crystals 3 . Franzen filed a formal complaint to NCSU, which kicked off a series of investigations. In the 2013 report, the NSF inspector-general found that the researchers had omitted experimental details and overstated the results, and recommended a finding of research misconduct. In 2015, the agency declined to make such a finding, but did issue a letter of reprimand and ban the authors from funding. Feldheim says that he agrees with the NSF final report that a finding of misconduct was not warranted. McNutt says that  Science  is working with the authors to determine whether to run a retraction or correction. The timeframe for that \u2014 or any final conclusion \u2014 remains unclear, frustrating Franzen. \u201cI am pretty cynical about the system,\u201d he says. \u201cI would like to move on.\u201d \n                   Acrimony over nanoconstruction 2011-Aug-23 \n                 \n                   Daniel Feldheim \n                 \n                   Bruce Eaton \n                 \n                   Stefan Franzen \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19127", "url": "https://www.nature.com/articles/nature.2016.19127", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "\u00d6tzi ice mummy yields oldest complete pathogen genome. Researchers have extracted the oldest complete genome sequence of a pathogen yet, from the body of the 5,300-year-old\u00a0ice mummy \u00d6tzi. According to a 7 January paper 1  in  Science , the \u2018Iceman\u2019 was infected with the bacterium  Helicobacter pylori , which also plagues modern humans. Few corpses have drawn more attention from researchers than \u00d6tzi\u2019s, discovered in 1991 encased in ice at an altitude of more than 3,000 metres, by hikers exploring the Tyrolean Alps in Italy. The cause of his death is believed to have been an arrow in the back, but researchers have shown that \u00d6tzi  suffered from myriad  health problems, including cavities, hardened arteries and possibly Lyme disease. In 2010, researchers examining a computed tomography (CT) scan of \u00d6tzi noticed that his stomach had been preserved. After they opened him up, they discovered that his last meal had contained ibex and wild grains. Then, a team led by biomolecular archaeologist Albert Zink at the Institute for Mummies and the Iceman in Bolzano, Italy, decided to look for  H. pylori . Roughly half of all modern humans carry the stomach bacterium, which causes ulcers in a small percentage of carriers and can lead to  stomach cancer . Using purification techniques similar to those used to extract the DNA of bubonic-plague-causing bacteria  from the teeth of Black Death victims , Zink\u2019s team obtained genetic material from \u00d6tzi\u2019s stomach that matched 92% of the modern pathogen\u2019s 1.6-million-letter genome. The strain that infected the iceman contained genes for a cellular toxin that allows modern  H. pylori  to cause ulcers. Zink\u2019s team also identified protein fragments that are found in the inflamed stomach tissue of people harbouring  H. pylori . This suggests that \u00d6tzi may have been made ill by his infection. The strain found in \u00d6tzi was genetically distinct from the  H. pylori  most common in modern Europe, which is a recombinant hybrid of two strains related to those that circulate in India and North Africa. \u00d6tzi\u2019s  H. pylori  matches only the Indian strain. Humans acquire  H. pylori  through close contact, usually from family members, and researchers have used the bacterium\u2019s DNA to trace past human migrations. Zink\u2019s team suggests that the migration that brought the North African strain to Europe occurred after \u00d6tzi died. It is also possible that other Europeans who lived at the same time as \u00d6tzi harboured recombinant  H. pylori , the authors acknowledge. Study co-author Yoshan Moodley, a geneticist at the University of Venda in Thohoyandou, South Africa, told journalists that the \u00d6tzi bacterium was probably the original strain that lived in the stomachs of the first Europeans. \u201cThis ancient  HP  strain has allowed us what is perhaps a unique opportunity to discover what populations of  Helicobacter pylori  existed in Europe during this copper age,\u201d he told journalists. \u201cThis might never happen again that we find such a wonderfully preserved specimen where  Helicobacter pylori  DNA still can be extracted.\u201d Daniel Falush, a population geneticist at Swansea University, UK, says that the study solves an important question about when the hybrid  H. pylori  strain carried by modern Europeans emerged. A previous study 2  proposed that it may have arisen in the Middle East as long ago as 50,000 years. It is not yet clear how a North African\u00a0 H. pylori  strain got to Europe, Falush says. \"Some of the pharaohs in the Nile Valley may have transmitted it,\" he jokes. \n                   Human\u2013microbe mismatch boosts risk of stomach cancer 2014-Jan-13 \n                 \n                   Iceman's DNA reveals health risks and relations 2012-Feb-28 \n                 \n                   Plague genome: The Black Death decoded 2011-Oct-26 \n                 \n                   Plague genome: The Black Death decoded 2011-Oct-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19162", "url": "https://www.nature.com/articles/nature.2016.19162", "year": 2016, "authors": [{"name": "Traci Watson"}], "parsed_as_year": "2006_or_before", "body": "Researchers tentatively identify an object that fell near Sri Lanka in November. The piece of space junk that made a fiery plunge into the Indian Ocean two months ago was most likely the remains of a rocket motor that propelled a NASA probe to the Moon in 1998, researchers studying the event have concluded. The junk\u2019s identity is by no means certain, but the \u201cleading candidate\u201d is the translunar injection module of Lunar Prospector, says Paul Chodas, an asteroid tracker at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. The module nudged the probe out of Earth orbit and then detached from the main spacecraft, which orbited the Moon for 19 months before it was deliberately slammed into the lunar south pole in July 1999. Speculation about the source of the debris, known as WT1190F, ran rampant even before it plummeted through the atmosphere on 13 November. The only artificial object to make an uncontrolled re-entry at a precisely predicted place and moment, it presented  a unique chance  to witness such an event in real time. Researchers took advantage of the opportunity,  monitoring the debris  from a chartered jet as well as from ground-based observatories. Telescopes had occasionally spotted the object in orbit since 2009, although no one realized until 2015 that the junk would strike Earth. By combining the series of sightings, researchers constructed WT1190F\u2019s elliptical trajectory around Earth and beyond the Moon\u2019s orbit. That path bears the \u201csignature of something launched to the Moon\u201d, Chodas says. \n             Unique characteristics \n           Researchers think that they can eliminate many lunar missions as sources of the debris. Any object travelling on WT1190F\u2019s estimated course for much longer than a decade would probably have hit Earth or swerved into a solar orbit, says independent astronomy-software developer Bill Gray, also part of the re-entry team. So it is unlikely that the debris came from an Apollo mission or one of the other early Moon shots. Many of the rocket segments used in more recent missions can also be ruled out because they ended up in orbit around the Sun rather than the Earth, says astrophysicist Jonathan McDowell of the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, who has done his own analysis of the re-entry object. Other candidates can be ruled out because when observed in orbit, they haven\u2019t matched WT1190F\u2019s furious spin rate of 40 revolutions per minute. Observations collected by the airborne team on 13 November also point to Lunar Prospector. The spectra of one large fragment of WT1190F include signals of titanium oxide and hydrogen, says astronomer Peter Jenniskens of the SETI Institute in Mountain View, California, who presented the observations on 5 January at a meeting of the American Institute of Aeronautics and Astronautics in San Diego, California. So the object could have been a titanium-walled vessel containing residual fuel, he says, although he declines to speculate about its identity. Lunar Prospector\u2019s translunar injection module had a titanium case, whereas a similar module on another leading candidate, Japan\u2019s Nozomi Mars probe, had a case made from carbon fibre. \n             Back in time \n           Additional support for the Lunar Prospector theory could come from archival searches to uncover sightings of WT1190F that pre-date 2009. If the debris\u2019 orbit can be traced back further in time, researchers can compare the junk\u2019s early travels with the path of Lunar Prospector to see how well they match. Getting more data would require good luck, but this re-entry has a charmed track record. The airborne observers monitored two chunks of debris down to an altitude of 33 kilometres before the objects disappeared from sight, which implies that they survived intact all the way to the surface. Orbital-debris specialist Patrick Seitzer of the University of Michigan in Ann Arbor notes that the re-entry site was fortuitous. \u201cWe\u2019re lucky that this went into the ocean and not onto the ground, where it could\u2019ve injured someone \u2014 or worse.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   Researchers rendezvous with falling space debris 2015-Nov-13 \n                 \n                   Incoming space junk a scientific opportunity 2015-Oct-23 \n                 \n                   Private firms spy a market in spotting space junk 2015-Sep-23 \n                 Reprints and Permissions"},
{"file_id": "529138a", "url": "https://www.nature.com/articles/529138a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Researchers aim to prevent recurrences by finding the virus\u2019s natural host. \n               Update, 15 January: The World Health Organization  \n               announced on 14 January \n                that all known chains of Ebola transmission in West Africa had stopped. But shortly afterwards,  \n               a death from Ebola was announced in Sierra Leone \n               , underlining, as health officials have emphasized, the potential for new cases of the virus to emerge.  \n             With the official end of Ebola transmission across West Africa anticipated on 14 January,  an epidemic  that killed more than 11,000 people in 2 years may be starting to fade into history. But that does not mean that Ebola has disappeared. The virus remains hidden in animal reservoirs, and is almost certain to spill over into humans again. \u201cWe\u2019ve got to focus on what could potentially happen next,\u201d says David Pigott, a spatial epidemiologist at the University of Oxford, UK \u2014 and that means uncovering the species that harbour Ebola in the wild to try to prevent deadly outbreaks in the future. It is no easy task. Since the disease first emerged in Zaire (now the Democratic Republic of the Congo) 40 years ago, efforts to trace the origins of the outbreaks, including the most recent one, have come up frustratingly empty.  Wild gorillas and chimpanzees  in central Africa have experienced occasional Ebola outbreaks. But like humans, these species are  too ravaged by the virus  to serve as its natural host. Experts say that a reservoir species is likely to harbour the virus only at low levels, and without becoming sick. The leading candidates are several species of fruit bat from across central and West Africa \u2014 where all known Ebola outbreaks have originated \u2014 that are often hunted for meat. A 2005 study 1  uncovered Ebola genetic material in some fruit bats from Gabon and the Democratic Republic of the Congo, and detected Ebola antibodies in the blood of others. Marburg virus, which is closely related to Ebola, is thought to be transmitted by fruit bats. \u201cI firmly believe fruit bats are the reservoir for Ebola,\u201d says Peter Daszak, a disease ecologist and president of EcoHealth Alliance, a conservation organization in New York City that plans to survey numerous bat species, including fruit bats, in Liberia for signs of Ebola infection. Other researchers believe that focus is too narrow. \u201cThe evidence for fruit bats is the strongest, but it\u2019s still weak,\u201d says Fabian Leendertz, a wildlife epidemiologist at the Robert Koch Institute in Berlin. Leendertz suspects another type of bat. He led a team that searched for the source of the latest West African outbreak in early 2014, a few months after a toddler in southern Guinea became the first human victim. The team captured dozens of bats near the toddler\u2019s village, but none \u2014 fruit-eating or otherwise \u2014 showed any conclusive signs of Ebola infection 2 . Still, circumstantial evidence has led the researchers to suspect that the culprit may have been  small insect-eating bats  living in a tree near the toddler\u2019s home. Although the tree had burned down before researchers arrived, it had been filled with such bats, and villagers told the team that children often played in its hollowed-out trunk. The team is now looking more closely at insectivorous bats, but Leendertz cautions against focusing on any one animal. \n               Unusual suspects \n             Some researchers advise casting the net even wider. \u201cI don\u2019t buy the bat story for Ebola virus, not at all,\u201d says virologist Jens Kuhn of the US National Institute of Allergy and Infectious Diseases at Fort Detrick, Maryland. He thinks that bats are much too abundant and too closely associated with humans to explain an infection that has emerged just two dozen times over the past four decades. \u201cIt\u2019s going to be a strange host,\u201d he says. Even arthropods or fungi could be possibilities, he adds. Others intend to look at more-familiar species. The US Agency for International Development plans a two-year survey of animals ranging from rodents to livestock to domestic dogs and cats. These animals may not be natural reservoirs of Ebola, but they could contribute to spillovers into humans, says Dennis Carroll, director of the agency\u2019s Pandemic Influenza and Other Emerging Threats Unit. But with so many question marks hovering over the identity of Ebola\u2019s reservoirs, some scientists say that it is time to eschew virus hunting in specific creatures and instead pursue more-holistic approaches that examine ecological and anthropological factors common to spillovers. Tony Goldberg, an epidemiologist at the University of Wisconsin\u2013Madison, is one such advocate. He no longer subscribes to the view that \u201cwe have to blanket the continent of Africa with  field-deployable DNA sequencers  and sample everything that crawls, flies or swims and eventually we\u2019ll come across it. I used to think that way,\u201d he says, \u201cbut I\u2019m cooling off to that approach.\u201d His team is studying how bush-meat hunters interact with wild ecosystems to identify factors that might be linked to the spillover of zoonotic infections such as Ebola. In a similar effort, a team led by Pigott and his colleague epidemiologist Simon Hay is looking at past outbreaks for common ecological factors, such as vegetation, elevation and the presence of suspected reservoir species such as fruit bats and carriers such as apes. By modelling these data, the team has created a map of areas at risk of Ebola spillovers 3 . And Barbara Han, a disease ecologist at the Cary Institute of Ecosystem Studies in Millbrook, New York, is using machine-learning techniques to predict which bat species are likely to harbour Ebola and related viruses because they share ecological factors common to suspected reservoir species. Research on Ebola therapies and vaccines saw an infusion of public and private funding during the epidemic, and scientists hunting the virus in the wild hope to capture the same sense of urgency and financial support. But they know that the job won\u2019t be easy. \u201cIt has lit a fire under people\u2019s butts, mine included,\u201d says Goldberg. \u201cThe problem is, we\u2019re not sure what to do with the fire.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Artificial intelligence joins hunt for human\u2013animal diseases 2015-May-18 \n                   \n                     New clues to where the Ebola epidemic started 2014-Dec-31 \n                   \n                     The Ebola questions 2014-Oct-29 \n                   \n                     Cost of human-animal disease greatest for world's poor 2012-Jul-05 \n                   \n                     Ebola outbreak has experts rooting for answers 2009-Jan-21 \n                   \n                     Double threat decimates apes 2003-Apr-07 \n                   \n                     Nature  special: Ebola epidemic \n                   \n                     WHO Ebola virus disease outbreak page \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19152", "url": "https://www.nature.com/articles/nature.2016.19152", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "A major player's entry into DNA-based detection of emerging tumours will test the technology's potential. A leader in genetic sequencing is betting that it can detect cancer at its earliest stages on the basis of minuscule amounts of genetic material circulating in a person's bloodstream. But specialists warn that there are many technical hurdles to such an application. On 10 January, Illumina of San Diego, California, announced that it has formed a venture that will use  genetic-sequencing technology  to detect cancer through a simple blood test. Such a  \u2018liquid biopsy\u2019  would identify tumour-specific DNA or RNA in the blood before a person has begun to show symptoms. Although many companies are working on aspects of this technology, the Illumina announcement made a splash because of its backing \u2014 US$100 million in funding, with  investors  including Bill Gates and Amazon founder Jeff Bezos's investment firm. \u201cIt is great that large companies like Illumina are finally getting involved,\u201d says Victor Velculescu, a cancer geneticist at Johns Hopkins University Kimmel Cancer Center in Baltimore, Maryland. He has founded a company called Personal Genome Diagnostics, which offers genetic screening of tumours in people who have already received a cancer diagnosis to help to guide their treatment. The new company, called GRAIL, will try to extend the technology by looking for genetic signs of cancer in people who are apparently healthy. \n             Daunting quest \n           Researchers have been encouraged in part by the huge success of  non-invasive prenatal screening , in which fetal DNA circulating in the mother\u2019s blood is checked for genetic anomalies. The global market for non-invasive prenatal screening is estimated to be more than $500 million, and it is growing rapidly. \u201cVirtually all of the companies that have developed non-invasive prenatal tests are now realizing that perhaps they can modify their tests and apply them to cancer, which is a much more lucrative market,\u201d says Bert Vogelstein, a cancer geneticist at Johns Hopkins and an adviser to Personal Genome Diagnostics. One company, Pathway Genomics of San Diego, California, said last year that it would market a cancer-detection test directly to consumers. But in September, the US Food and Drug Administration cautioned the company that it had not provided sufficient evidence that its test is valid. Illumina estimates that the market for a cancer-screening test performed once a year on healthy adults could be worth $20 billion to $100 billion, depending on how well it works. The company aims to market a test by 2019 that would check for many types of tumours. Reaching that goal would require a number of technical advances. Although about 10% of the DNA in a mother\u2019s blood is estimated to come from a fetus, as little as 0.01% of circulating DNA in a person with asymptomatic cancer might come from a tumour; detecting that DNA without generating an unacceptable number of false positives will be extremely difficult. It is also not clear how much information free-floating DNA can give about a tumour's location in the body. And it has yet to be demonstrated whether a genetic test would be able to discriminate lethal cancers that need immediate follow-up from non-lethal cancers that can be left alone. The inability of existing screening methods such as mammography to make such distinctions has sparked heated debates among physicians and health-policy specialists. \n             Trials ahead \n           Dennis Lo, a chemical pathologist at the Chinese University of Hong Kong and a co-founder of Cirina, a company that is developing blood tests to detect cancer, says that GRAIL could help to solve some of these problems. In the past four years, researchers have demonstrated that tumour DNA circulating in the blood can be detected through genetic sequencing 1 ; that such DNA has different characteristics from normal DNA, which may make it easier to detect 2 ; and that it may be possible to use this circulating DNA to pinpoint the location of a tumour 3 . Yet it remains to be seen whether those advances and others can be incorporated into a test that provides useful information to apparently healthy people and to their physicians. Richard Klausner, former head of the US National Cancer Institute and a director of GRAIL, says that the company will invest in the large clinical trials that are needed to show that the method is an improvement over currently available screening methods. \u201cGRAIL will undertake the most important and extensive clinical studies ever to answer important questions about the risks and benefits of these tests,\u201d Klausner says. \n               Tweet \n               Follow @NatureNews \n             \n                   Cancer biomarkers: Written in blood 2014-Jul-30 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19125", "url": "https://www.nature.com/articles/nature.2016.19125", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Death rates weren't reduced by transfusing survivors' plasma into Ebola patients. The first clinical trial to transfuse blood plasma from Ebola survivors into virus-infected patients has found that the treatment didn't reduce the risk of death \u2014 but experts say it's too early to rule out the idea as an Ebola therapy. \"The results are disappointing,\" says Ian Lipkin, a virologist and outbreak specialist at Columbia University in New York, who was not involved in the study. From February 2015, an international consortium of researchers collected plasma from the blood of Ebola survivors and gave it to 84 patients at the Donka Ebola treatment centre operated by M\u00e9decins Sans Fronti\u00e8res in Conakry, Guinea\u2019s capital. The researchers hoped that antibodies in the survivors\u2019 plasma might have a protective effect. Administering \u2018convalescent\u2019 plasma is a  long-established therapy  that was widely used in the early twentieth century to treat infectious diseases such as mumps, diphtheria and measles. It fell out of favour following the development of antibiotic and antiviral treatments, although it is still used to treat some diseases (such as Argentine haemorrhagic fever). Although  an Ebola vaccine proved highly successful in trials last year , a therapy is still needed because there are no effective drugs against the virus, says David Heymann, an infectious-disease researcher at the London School of Hygiene and Tropical Medicine. As the number of Ebola survivors increases during an outbreak, using their plasma could be a fast and easily scaled-up way to tackle the infection. \u201cIt was a study that needed to be done,\u201d he says. \n             Lessons learned \n           But the results of the trial, published on 7 January in the  New England Journal of Medicine 1 , show that the death rate of 31% in the plasma-treated group was little different from the 37.8% death rate in a control group of 418 people with Ebola who were cared for at the centre in the 5 months before the trial began. After adjusting the raw data to take into account the ages and viral loads of the patients, researchers estimated that the difference between the two groups was just 2.6%, and not statistically significant. Still, the trial showed that the therapy is safe, that donors were willing to give plasma and that it was possible to organize the medical infrastructure needed to collect the plasma, even during an epidemic, says Stephen Hoffman, an infectious disease expert and chief executive of the malaria-vaccine company Sanaria, in Rockville, Maryland. \"This is an excellent demonstration of what clinical investigators can do in the most difficult circumstances,\" he says. It would be premature to rule out convalescent plasma as a therapy for Ebola, says Hoffman. Infants and pregnant women given plasma in the trial had strikingly high survival rates, he points out. In particular, only one of 5 infants died in the treated group, compared to 15 of 23 in the control group \u2014 but the trial tested too few infants to make this a statistically significant result. And both he and Lipkin suggest that the donated plasma might not have contained sufficient levels of antibodies to protect patients. It wasn\u2019t possible to check this at the time because West Africa has no laboratories with the necessary top grade of biosafety (BSL4) that is needed to conduct such tests \u2014 and shipping samples of the plasma overseas would have delayed the trial. But the scientists have now sent stored plasma samples to a BSL4 lab in Lyon, France, where over the next 6 months they will retrospectively measure whether there was a correlation between antibody levels and patient survival. \"There is still hope that we will get indications of efficacy,\" says Johan van Griensven, a researcher at the Institute of Tropical Medicine in Antwerp, Belgium, which led the trial consortium. \"The likely scenario is still that convalescent plasma works but that you need to give high amounts of antibodies,\" he says. \n             Next steps \n           If this is the case, it might prove more effective to recruit donors with higher levels of antibodies in their blood plasma, administer the plasma in a more concentrated form or give patients more plasma in higher volumes. (In the Guinea trial, patients were given about half a litre of plasma in two doses.) The Ebola epidemic is almost at an end \u2014 if there are no more reported cases, the World Health Organisation will declare West Africa Ebola-free on 14 January \u2014 so scientists will have to wait for another outbreak to test out these ideas. Researchers had hoped also to test plasma from Ebola survivors in separate trials in Liberia and Sierra Leone, but they only managed to recruit nine patients, so the trials never got off the ground. An \u201cobvious next step\u201d, says Heymann, would be to extract and concentrate antibodies from the many plasma samples already collected from survivors, so as to be ready to trial them immediately in future outbreaks. \n               Tweet \n               Follow @NatureNews \n             \n                   How to beat the next Ebola 2015-Aug-05 \n                 \n                   Ebola raises profile of blood-based therapy 2014-Dec-23 \n                 \n                   First trials of blood-based Ebola therapy kick off 2014-Dec-15 \n                 \n                   Blood transfusion named as priority treatment for Ebola 2014-Sep-05 \n                 \n                   Nature Special: the Ebola epidemic \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19126", "url": "https://www.nature.com/articles/nature.2016.19126", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Fresh worlds found by K2 mission push beyond original discoveries. Kissimmee, Florida In the second phase of its life as a planet hunter, NASA\u2019s Kepler spacecraft is raking in exoplanet discoveries that are surprisingly different from those found during its first iteration. Between 2009 and 2013, Kepler became the most successful planet-hunting machine ever, discovering at least 1,030 planets and more than 4,600 possible others in a single patch of sky. When a mechanical failure stripped the spacecraft of its ability to point precisely among the stars, engineers  reinvented it in 2014 as the K2 mission , which looks at different parts of the cosmos for shorter periods of time. In its first year of observing, K2 has netted more than 100 confirmed exoplanets, says astronomer Ian Crossfield at the University of Arizona in Tucson. They include a surprising number of systems in which more than one planet orbits the same star 1 . The K2 planets are also orbiting hotter stars than are many of the Kepler discoveries. \u201cThis is really showing the power and potential of K2,\u201d says Crossfield. \u201cThese are things we never found with four years of Kepler data.\u201d He and other scientists reported the findings this week at a meeting of the American Astronomical Society in Kissimmee, Florida. The original Kepler mission was designed to answer a specific question: what fraction of Sun-like stars have Earth-sized planets around them? Unbound by those constraints \u2014 even if not as good at pointing itself \u2014 K2 has been able to explore wider questions of planetary origin and evolution. \u201cNow we get to look at a much bigger variety,\u201d says Steve Howell, the mission\u2019s project scientist at NASA\u2019s Ames Research Center in Moffett Field, California. And because K2 looks at stars that are generally brighter and closer to Earth than Kepler did, the exoplanets that the mission finds are likely to be the best-studied for the foreseeable future. This is because they are near enough to allow astronomers to explore them with other telescopes on Earth and in space. \n               Unexpected bounty \n             In the past year, K2 has uncovered not just planets \u2014 such as  three super-Earths orbiting a single star  \u2014 but also surprises such as the  disintegrating remains of a planet swirling around a white dwarf star . It has even probed exploding stars \u2014 because K2 stares constantly at a patch of the sky, it is able to catch a supernova as it brightens instead of later in its explosion, as other telescopes typically do. Among the K2 planets confirmed so far, 58 are singletons, 28 come from systems with at least 2 planets and 14 are triples, Crossfield says. In addition, K2 has unearthed more than 200 candidate planets, says Andrew Vanderburg, an astronomer at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts. K2 observes a larger fraction of the cool stars known as M dwarfs \u2014 the most common type of star in the Galaxy \u2014 than Kepler did. But surprisingly, fewer of the K2 planets are orbiting M-dwarf stars. A higher percentage of them, at least so far, circle stars that are hotter and more like the Sun, says Courtney Dressing, an astronomer at the California Institute of Technology (Caltech) in Pasadena. K2 will begin a new type of planet-hunting on 7 April. Normally the spacecraft searches for a temporary dimming of a star caused when a planet crosses in front of it. For just under three months, however, it will look for the temporary brightening of cosmic objects, such as a galaxy, caused when a planet bends light as it crosses the line of sight between the object and the observer. The team expects to catch between 85 and 120 of these \u2018microlensing\u2019 planets during the campaign. The survey will involve other telescopes and be the first automated search to be done simultaneously from the ground and in space, says Calen Henderson, an astronomer at NASA\u2019s Jet Propulsion Laboratory in Pasadena, California. That means much more work ahead for mission scientists. \u201cKepler was one field and it ruined your summer,\u201d says Caltech astronomer David Ciardi. \u201cK2 is ruining our whole year.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     The exoplanet files 2015-Nov-18 \n                   \n                     Dead star spotted eating planetary leftovers 2015-Oct-21 \n                   \n                     Three 'super-Earth' exoplanets seen orbiting nearby star 2015-Jan-16 \n                   \n                     Sun\u2019s stroke keeps Kepler online 2014-Oct-21 \n                   \n                     NASA ponders Kepler\u2019s future 2013-Sep-04 \n                   \n                     Kepler and K2 science centre \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19131", "url": "https://www.nature.com/articles/nature.2016.19131", "year": 2016, "authors": [{"name": "Zach Zorich"}], "parsed_as_year": "2006_or_before", "body": "Syrian civil war inspires creative efforts to document and protect ancient sites and artefacts threatened by fighting and looting. When fighting between Syrian rebels and government forces neared the Ma\u2019arra Mosaic Museum near Aleppo in 2012, archaeologists sprang into action. To save the museum\u2019s Byzantine and Roman tile masterpieces, a team of researchers from Syria and the United States decided to swaddle the artworks in protective sheets of Tyvek fabric and truckloads of sandbags imported from Turkey. The work paid off. In June, a barrel bomb hit the museum\u2019s courtyard, and although it damaged some mosaics stored outdoors, the roughly 150 square metres of mosaics inside \u2014 which date from the third to the sixth centuries \u2014 were largely unharmed. The Ma\u2019arra project was a notable success, but it is just one of roughly 20 efforts under way to protect cultural treasures that are threatened by Syria\u2019s ongoing civil war \u2014 and, perhaps, to learn lessons that can be applied to conflicts elsewhere. \u201cHopefully, when peace does break out, there will be a richer archaeological heritage for people to see and enjoy,\u201d says Robert Bewley, an archaeologist at the University of Oxford, UK. \n             Satellite saviours \n           These preservation efforts have intensified in recent months, as the Islamic State (commonly known as ISIS) has destroyed important Syrian heritage sites such as the ancient city of Dura Europis and  the temples of Palmyra . Although little short of a military intervention can prevent such attacks, archaeologists hope to preserve for future generations records of sites at risk. Researchers are more optimistic, however, about their ability to reduce damage caused by the more commonplace looting and illegal or poorly planned construction. Multiple analyses of satellite images that document archaeological sites over time suggest that more sites are destroyed by looting and construction than by the attacks that have become  a regular feature of ISIS propaganda videos . And it is not just sites in Syria and Iraq that are vulnerable: looting of archaeological treasures is widespread in countries such as Yemen, Tunisia,  Libya  and Egypt. Mindful of this, Bewley is leading a project to document vulnerable sites in places spanning from Mauritania to Iran by using satellite imagery, aerial photographs and other data. The effort began in January 2015 and has already amassed a database of roughly 94,000 archaeological sites that includes basic information on each site\u2019s location and history. Bewley and his colleagues hope to publish their database online soon, for public use. But the government of Jordan is already using data from the trove to protect archaeological sites from being damaged by road construction outside of the country's city of Madaba. \n             Worldwide efforts \n           Another project, the Million Image Database, is using 3D cameras to chronicle threatened sites and objects in conflict zones in the Middle East and Africa. Run by the Institute for Digital Archaeology \u2014 a collaboration between researchers at Oxford, Harvard University in Cambridge, Massachusetts, and the Museum of the Future in Dubai \u2014 the team hopes to distribute roughly 5,000 small, lightweight cameras to volunteer photographers in the coming months. And in Syria, a non-governmental organization called the The Day After is building on the effort to save the Ma\u2019arra Mosaic Museum by raising money to repair the damage from the June barrel-bomb attack. The site's mosaics and other cultural treasures are important symbols to reinforce national identity, says Amr al-Azm, a Syrian archaeologist at Shawnee State University in Portsmouth, Ohio, who is aiding the effort. \u201cDespite the huge divides between the warring factions, this shared common history acts as the glue that holds Syrian society together,\u201d he says. Meanwhile, the initial push to save the Ma\u2019arra museum has already yielded important lessons for researchers, says Brian Daniels, an archaeologist at the University of Pennsylvania in Philadelphia. Foremost, he says, is the idea that heritage preservation should not be separated from the larger humanitarian response to conflict. Archaeologists on the Ma\u2019arra project asked local residents to decide which artworks were most important to preserve \u2014 a simple step that built goodwill and that helped to identify the most culturally significant artefacts, Daniels says. Others see larger lessons from the conflict in Syria. Bassel Kaghadou, a programme coordinator for a United Nations project on the future of Syria, says that archaeologists and other researchers should push for a greater voice in government to protect irreplaceable cultural sites and artefacts. \u201cScientists need to start to learn how to lobby,\u201d he says. \u201cWe are simply losing the world heritage. We are losing part of the human memory.\u201d \n                   Archaeologists ousted by ISIS return to ancient Iraqi cave 2015-Oct-02 \n                 \n                   Heroism in Syria 2015-Aug-25 \n                 \n                   Science in turmoil: After the Arab Spring 2015-Apr-29 \n                 \n                   Experts struggle to confirm archaeological damage in Iraq 2015-Mar-26 \n                 \n                   Conflict resolution: Wars without end 2015-Mar-11 \n                 \n                   Cultural heritage: Save Libyan archaeology 2015-Jan-28 \n                 \n                   Million Image Database project \n                 \n                   Endangered Archaeology in the Middle East and North Africa \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19153", "url": "https://www.nature.com/articles/nature.2016.19153", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Caltech has suspended a faculty member for violating its policy against harassment. Concerns over sexual harassment in astronomy are once again in the spotlight, with new reports of harassment investigations at two US universities. The California Institute of Technology (Caltech) in Pasadena has temporarily suspended a faculty member, without pay, after determining that he had committed gender-based harassment against two graduate students.  Science   reported  on 12 January that the faculty member is theoretical astrophysicist Christian Ott, which  Nature  can also confirm. When asked whether he was the faculty member in question, Ott told  Nature  that he could not comment. \u201cI\u2019ve been instructed not to speak with journalists,\u201d he said. Caltech officials, citing privacy issues, told  Nature  several times that they could not confirm or deny any information about the faculty member\u2019s identity. And on 12 January, US Congresswoman Jackie Speier, a Democrat who represents a district in northern California, read a statement on the floor of the House of Representatives revealing the results of a 2004 harassment investigation at the University of Arizona. The case involved an astronomy educator who has since moved to the University of Wyoming. Speier announced that she would introduce legislation aimed at requiring universities to inform other universities of the outcome of a disciplinary proceeding. \u201cIt's time to stop pretending sexual harassment in science happened a long time ago in a galaxy far, far away,\u201d she said. The new revelations confirm that harassment is a widespread problem in science with only some of the instances now coming to light, says Joan Schmelz, an astronomer at Arecibo Observatory in Puerto Rico and  longtime advocate for women in astronomy . \u201cYou can't just sweep this stuff under the rug, declare it confidential and hope that no one ever knows about it,\" she says. \n             Details emerge on two cases \n           The Caltech case went public on 4 January, when university president Thomas Rosenbaum and provost Edward Stolper  sent a campus-wide message  saying that the institute followed formal procedures to investigate harassment complaints involving two graduate students. \u201cThe faculty committee concluded, and the provost concurred, that there was unambiguous gender-based harassment of both graduate students by the faculty member,\u201d Rosenbaum and Stolper wrote. The suspension of the faculty member \u2014 which includes a ban on accepting any new students \u2014 will extend through the nine months of the 2015\u201316 academic year, and the faculty member is also barred from campus. Contact between the faculty member and his research group is being monitored. He must undergo professional training in mentoring students before being allowed to return. The faculty member appealed the actions, Rosenbaum and Stolper wrote, but the appeal was denied. Caltech officials say that all of the graduate students who worked for the suspended faculty member remain at the institution, and are progressing in their original degree programmes. BuzzFeed News  reported  on 13 January that one of the graduate students who filed a complaint against Ott is finishing her research at the University of California, Berkeley \u2014 but her degree will ultimately come from Caltech. Ott's research topics include determining how massive stars explode in supernovae. He is part of the Laser Interferometer Gravitational-Wave Observatory (LIGO) that is hunting for these elusive waves, which were predicted by Albert Einstein. Ott\u2019s current US National Science Foundation awards total more than US$850,000, and his publications include a  Nature  paper from November on magnetic structures in rapidly rotating supernovae 1 . \n             Harrassment training \n           Meanwhile, Speier's remarks on the House floor focused on another set of allegations, which involved Timothy Slater, an astronomy educator formerly of the University of Arizona. The university opened an investigation in 2004 into reports of \u201csexually charged conduct\u201d linked to Slater, including allegations of sexual jokes and visits to strip clubs. The report concluded that he had violated campus policies on sexual harassment. Slater moved to the University of Wyoming in 2008. A statement on his research group's website said that he underwent management and harassment training at Arizona, and that training had been effective. \u201cDr. Slater has made no attempt to hide his role in, or the lessons learned from these events occurring more than a decade ago,\u201d said the statement, which is signed by Stephanie Slater, who is Timothy Slater's wife and director of the research group. In an e-mail to  Nature , Timothy Slater said that he had nothing to add to the statement and that no further allegations of sexual harassment had been brought against him since the Arizona investigation ended. Stephanie Slater said that Speier's posting of the Arizona report had made witnesses, who are anonymized in the document, more easily identifiable. \u201cIf people think their statements are going to end up in the Congressional record, they're not going to give them,\u201d she said. Speier said that she was speaking publicly about the case because \u201cthese actions are symptoms of a larger problem, of how to effectively deal with sexual harassment in academia.\u201d \n             Community response \n           Concerns about sexual harassment in astronomy came to the fore in October, when the news broke that an investigation at Berkeley determined that  exoplanet hunter Geoffrey Marcy had violated campus harassment policies . The university told Marcy to \u201cabide by clear expectations concerning his future interactions with students\u201d or face harsher terms including suspension or dismissal. He announced his retirement within days of the information becoming public. At the American Astronomical Society meeting in Kissimmee, Florida, in early January, large posters in the registration area displayed the society\u2019s anti-harassment policy. At a town hall meeting during the conference, many astronomers \u2014 ranging from students to university faculty members to high-school teachers \u2014 testified that harassment was a major and long-running problem that hampered professional interactions and many young researchers\u2019 careers. \u201cThere is a problem in our field and we all know it\u2019s there,\u201d said David Silva, director of the National Optical Astronomy Observatory in Tucson, Arizona. Meg Urry, the society\u2019s president and an astronomer at Yale University in New Haven, Connecticut, said that while harassment is not unique to astronomy, the Marcy revelations have brought the problem to wider public consciousness. \u201cFor some of us, over the past six months or so, the most distressing thing has been the readiness of people with power in our profession to try to protect their colleagues who are great scientists,\u201d she added. Universities and institutions have begun campus discussions about harassment. Caltech will hold a colloquium for graduate students and faculty on 11 February, an initiative begun by graduate students. \n               Tweet \n               Follow @NatureNews \n             \n                   Science and gender: Scientists must work harder on equality 2015-Dec-21 \n                 \n                   Berkeley releases report on astronomer sexual-harassment case 2015-Dec-19 \n                 \n                   365 days: Nature\u2019s 10 2015-Dec-17 \n                 \n                   Scientific groups revisit sexual-harassment policies 2015-Nov-16 \n                 \n                   US astronomers rally to end sexual harassment 2015-Oct-21 \n                 \n                   Caltech statement \n                 \n                   Theoretical AstroPhysics Including Relativity and Cosmology (TAPIR) group at Caltech \n                 Reprints and Permissions"},
{"file_id": "529009a", "url": "https://www.nature.com/articles/529009a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Strong genomics record bodes well but a shortage of doctors could pose a hurdle. Formidable capacity in genome sequencing, access to millions of patients and the promise of solid governmental support: those are the assets that China hopes to bring to the  nascent field of precision medicine , which uses genomic, physiological and other data to tailor treatments to individuals. Almost exactly one year after US President  Barack Obama announced the Precision Medicine Initiative , China is finalizing plans for its own, much larger project. But as universities and sequencing companies line up to gather and analyse the data, some observers worry that problems with the nation\u2019s health-care infrastructure \u2014 in particular a dearth of doctors \u2014 threaten the effort\u2019s ultimate goal of improving patient care. Precision medicine harnesses huge amounts of clinical data, from genome sequences to health records, to determine how drugs affect people in different ways. By enabling physicians to target drugs only to those who will benefit, such knowledge can cut waste, improve health outcomes using existing treatments, and inform drug development. For example, it is now clear that individuals with a certain mutation (which is mostly found in Asian people) respond better to the lung-cancer drug Tarceva (erlotinib;  W.\u00a0Pao  et al. Proc. Natl Acad. Sci. USA    101,  13306\u201313311; 2004 ), and the discovery of a mutation that causes 4% of US cystic fibrosis cases led to the development of the drug Kalydeco (ivacaftor). The Chinese government is expected to officially announce the initiative after it approves its next five-year plan in March. Just how much the effort will cost is unclear \u2014 but it will almost certainly be larger and more expensive than the  US$215-million US initiative . Since last spring, Chinese media has been abuzz with estimates of a 60-billion yuan (US$9.2-billion) budget, spread over 15\u00a0years. But this figure is not finalized, cautions Zhan Qimin, director of the State Key Laboratory of Molecular Oncology at Peking Union Medical College in Beijing, who is involved in the initiative. He says that the effort will consist of hundreds of separate projects to sequence genomes and gather clinical data, with support for each ranging from tens of millions of yuan to more than 100\u00a0million yuan. Anticipating the initiative, leading institutes \u2014 including Tsinghua University, Fudan University and the Chinese Academy of Medical Sciences \u2014 are scrambling to set up precision-medicine centres. Sichuan University\u2019s West China Hospital, for instance, plans to sequence 1\u00a0million human genomes itself \u2014 the same goal as the entire US initiative. The hospital will focus on ten diseases, starting with lung cancer. Both the US and the Chinese efforts will focus on genetic links to diseases that are particularly deadly, such as cancer and heart disease. But China will target specific cancers, such as stomach and liver cancer, which are common there. The Chinese initiative is part of a series of research-funding efforts that will replace two major grant programmes, known as 863 and 973, that are due to be phased out by 2017. The new programmes will be \u201cmore organized, more efficient\u201d, says Zhan. Genome-sequencing companies are already vying to provide services to deal with the anticipated demand. For several years, China has boasted high genome-sequencing capacity. In 2010, the genomics institute BGI in Shenzhen was estimated to host more sequencing capacity than the entire United States. This was thanks to its equipment, purchased from Illumina of San Diego, California, which at the time represented state-of-the-art technology. But Illumina has since sold upgraded machines to at least three other genomics firms \u2014 WuXi PharmaTech and Cloud Health, both in Shanghai, and the Beijing-based firm Novogene. Jason Gang Jin, co-founder and chief executive of Cloud Health, says that this trio, rather than BGI, will be the main sequencing support for China\u2019s precision-medicine initiative \u2014 although BGI\u2019s director of research, Xu Xun, disagrees. Xu says that precision medicine is a priority for BGI and that the organization has a diverse portfolio of sequencers that still gives it an edge. \u201cIf you are talking about real data output, BGI is still leading in China, maybe even globally,\u201d he says. BGI has already established a collaboration with the Zhongshan Hospital\u2019s Center for Clinical Precision Medicine in Shanghai, which opened in May 2015 with a budget of 100\u00a0million yuan and is run by Fudan University. \n               Numbers game \n             Regardless of the details, Jin thinks that China will be faster than the United States at sequencing genomes and identifying mutations that are relevant to personalized medicine because China\u2019s larger populations of patients for each disease will make it easier to find sufficient numbers to study. Still, it remains to be seen whether China has the resources to apply these insights to the individualized care of patients. \u201cChina wants to do it, and everybody is very excited,\u201d says Ta Jen Liu, project director at the MD Anderson Cancer Center in Houston, Texas, who helps to establish collaborations in China and is familiar with the precision-medicine scene there. But there are hurdles. He notes that Chinese researchers and pharmaceutical companies have not had much success in developing drugs so far; that the pathologists needed to diagnose specific diseases are scarce in China; and that physicians there are notoriously overworked. \u201cDoctors are always overwhelmed with patients, seeing 60 or 70 a day,\u201d he says. \u201cThey don\u2019t have time to sit down and think about what is best for specific patients.\u201d David Weitz, a physicist at Harvard University who is starting a company in Beijing to develop diagnostic instruments for use in precision medicine, agrees that there will be obstacles, but notes the initiative\u2019s assets. \u201cWe need lots of data to validate ideas, to validate tests,\u201d he says. \u201cThere\u2019s lots of data here.\u201d He thinks that this, combined with the Chinese government\u2019s determination to succeed, will mean that the effort will ultimately win out. \u201cThey really seem devoted to meeting the needs of the society,\u201d he says. \u201cIt\u2019s an exciting thing, to try to help that many people.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                 weibo \n               \n                     Personalized medicine: Time for one-person trials 2015-Apr-29 \n                   \n                     California unveils 'precision-medicine' project 2015-Apr-14 \n                   \n                     Obama to seek $215 million for precision-medicine plan 2015-Jan-30 \n                   \n                     China opens translational medicine centre in Shanghai 2014-Oct-29 \n                   \n                     Chinese bioscience: The sequence factory 2010-Mar-03 \n                   \n                     Nature Insight : Precision medicine \n                   \n                     Novogene \n                   \n                     Cloud Health \n                   \n                     BGI \n                   \n                     West China Hospital \n                   \n                     Illumina on China \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19134", "url": "https://www.nature.com/articles/nature.2016.19134", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Betelgeuse is too cool for current theories to explain how it sheds mass as it approaches death. Kissimmee, Florida New observations of the bright star Betelgeuse, famous as the shoulder in the constellation of Orion the hunter, raise fresh questions about how it blows huge amounts of gas into interstellar space. Betelgeuse is a red giant  near the end of its life , much as the Sun will be billions of years from now. Astronomers study Betelgeuse in hope of understanding  the Sun's ultimate fate . But \u201cwe now have a problem\u201d, says Graham Harper, an astrophysicist at the University of Colorado Boulder. \u201cIf you\u2019re going to eject matter you have to put energy in, and we\u2019re not seeing that.\u201d Harper and his colleagues used the US\u2013German Stratospheric Observatory for Infrared Astronomy (SOFIA), a 2.5-metre  telescope that flies in a modified Boeing 747  aeroplane, to take Betelgeuse\u2019s temperature. They found that the star's upper atmosphere was much cooler than expected \u2014 so cool, in fact, that it doesn\u2019t seem to have enough energy to kick gas out of its gravitational pull and into space. \u201cThis challenges all our theoretical models,\u201d Harper said on 7 January at a meeting of the American Astronomical Society in Kissimmee, Florida. When stars such as the Sun near the end of their lives, they balloon to huge sizes and begin shedding gas. Over the next million years, Betelgeuse will lose about one-quarter of its mass, but astronomers have not been able to explain where it is getting the energy to do that. One idea is that strong magnetic fields within the star drive the outflows. But a 1998  Nature  paper found that Betelgeuse\u2019s temperature, when measured at radio wavelengths, was thousands of degrees cooler than would be expected if magnetic fields were at play, Harper says 1 . \u201cNow we\u2019re looking at being a lot cooler than even that,\u201d he says. \u201cThe fundamental physics is way off.\u201d \n             Cold case \n           In March, Harper\u2019s team used an infrared instrument aboard SOFIA to study the light coming from Betelgeuse. The researchers measured the speed of gas flowing off the star\u2019s surface, and calculated what temperature that corresponded to. Whereas the 1998 radio study found material flowing away at temperatures of 1,500\u20133,500 kelvin, the new SOFIA data found it to be as cool as 540 kelvin. The cold infrared temperature causes problems for theorists trying to explain what is happening in the upper layers of Betelgeuse's atmosphere, Harper says. It not only seems to rule out magnetic fields as the reason for the shedding, it also challenges other possibilities such as radiation pressure from the star\u2019s light, or some type of internal shock wave that drives stellar pulsations 2 . \u201cWe don\u2019t know how the star evolved and we don\u2019t know what it will consequently look like,\u201d Harper says. Other research presented at the meeting underscores how unstable Betelgeuse is. More than four decades of observations from small telescopes on the ground show that its light fluctuates in cycles that range from just over a year to many years, reported a team led by astronomer Ed Guinan at Villanova University in Pennsylvania. At roughly 184 parsecs (600 light years) away, Betelgeuse is one of the closest red giants. When it explodes, perhaps several million years from now, it may shine as brightly as the full Moon. Not understanding the physics of this mysterious star, Harper says, means that researchers will struggle to understand the other red giants in the Universe. \n                   Bizarre star could host a neutron star in its core 2014-Jan-07 \n                 \n                   Kepler\u2019s surprise: The sounds of the stars 2012-Jan-04 \n                 \n                   Early observations identify star at heart of nearby supernova 2011-Dec-14 \n                 \n                   Blog: Betelgeuse about to blow? \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19114", "url": "https://www.nature.com/articles/nature.2016.19114", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Engineered enzyme drives genome-editing errors below detection limit. A powerful technique for editing genomes is now more precise. By tweaking an enzyme, researchers have reduced the error rate for the technique, known as CRISPR\u2013Cas9 \u2014 in some cases to undetectable levels, they report on 6 January in  Nature 1 . Researchers use CRISPR\u2013Cas9 to  make precise changes to genomes  that remove or edit a faulty gene. It has worked on nearly every creature on which they have tested it, including human embryos. The technique relies on an enzyme called Cas9, that uses a 'guide RNA' molecule to home in on its target DNA. Cas9 cuts the DNA at that site, and the cell's natural DNA repair machinery then takes over to mend the cut \u2014 deleting a short fragment of DNA or stitching in a new sequence in the process. But the technology is not infallible: sometimes the Cas9 enzyme creates unwanted mutations. As CRISPR inches out of the laboratory and towards the clinic \u2014 with debates raging over  whether it should be deployed in embryos  \u2014 researchers have  pushed to reduce the error rate . The latest study moves the field closer to that goal, says lead author Keith Joung, a pathologist at Massachusetts General Hospital in Boston. \u201cThis is a significant move forward,\u201d he says. \u201cWe can very much reduce the probability of off-targets.\u201d Some researchers argue that the error rate does not have to be zero for CRISPR to be clinically useful. \u201cAt some point everyone needs to decide how specific is specific enough,\u201d says Charles Gersbach, a bioengineer at Duke University in Durham, North Carolina. \u201cThe idea that you would make a tool that has absolutely no off-target effects is a little too utopian.\u201d \n             Safety first \n           Previous work has shown that using a shorter strand of \u2018guide RNA\u2019 to direct the Cas9 enzyme to the targeted DNA could cut down on some errors 2 . And in December, synthetic biologist Feng Zhang of the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, and his colleagues announced that they had  engineered Cas9 to make it less error-prone 3 . For the latest study, Joung and his colleagues tackled a different region of the Cas9 enzyme, altering the part of the protein that makes contact with the DNA target. The team also used a more sensitive method for detecting errors. They tested their high-fidelity enzyme, called SpCas9-HF1, with eight different guide RNAs. The engineered enzyme cut its target DNA nearly as well as the unaltered form, and made only one mistake with one of the guide RNAs. The unaltered Cas9 enzyme, by contrast, made mistakes when guided by seven of the eight RNAs. Cas9's mistakes have been a focus in many discussions about genome editing \u2014 including in the  debate over using the technique in human embryos . But that focus may be misplaced, says George Church, a geneticist at the Wyss Institute in Boston. With careful design of the guide RNA, Church says that researchers could already avoid most off-target cuts. And although the work is important given the speed with which CRISPR\u2013Cas9 is moving into therapeutics, says Gersbach, the system will need extra safety checks before it is deemed safe for use in humans. \n             Pursuit of perfection \n           In December, Gersbach and his colleagues announced that they had used CRISPR\u2013Cas9 to repair the genetic mutation that causes Duchenne muscular dystrophy in mice 4 . To do so,  his team used a virus to carry Cas9  into muscle cells. That virus can continue to express the enzyme for much longer than it was in Joung\u2019s experiments, leaving more opportunity for off-target cuts. The US Food and Drug Administration has not outlined its requirements for approving a CRISPR\u2013Cas9 clinical trial, but Sangamo BioSciences of Richmond, California, has already used  another genome-editing tool, called zinc finger nucleases , in clinical trials in more than 80 patients. For those trials, regulators wanted safety data on how well the modified cells performed, in addition to information about off-target mutations, says Fyodor Urnov, a senior scientist at the Sangamo. The company was required to show that altered immune cells called T cells still behaved like normal T cells, for example, or that edited liver cells continued to function without showing signs of toxicity. \u201cThis study is a solid advance for the Cas9 field,\u201d says Urnov. \u201cBut when you think about deploying editing in the clinical space, we have a healthy sense of how long the road ahead is.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   Biologists create more precise molecular scissors for genome editing 2015-Dec-01 \n                 \n                   Human-genome editing summit to sample global attitudes 2015-Nov-30 \n                 \n                   Alternative CRISPR system could improve genome editing 2015-Sep-25 \n                 \n                   Mini enzyme moves gene editing closer to the clinic 2015-Apr-01 \n                 \n                   CRISPR: The good, the bad, and the unknown \n                 \n                   YouTube: Genome Editing with CRISPR\u2013Cas9 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19141", "url": "https://www.nature.com/articles/nature.2016.19141", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Satellite measurements track burned gas by country as policymakers seek to reduce emissions. TREND WATCH:  Around 3.5% of the world\u2019s natural-gas supply was wastefully burned, or \u2018flared\u2019, at oil and gas fields in 2012, according to the latest estimates from satellite data 1 . The United States has the greatest number of flares, but Russia leads the world in the total volume of flared natural gas (see chart, 'Top natural-gas-flaring nations'). In 2012, the 143 billion cubic metres of gas flared led to the emission of more than 350 million tonnes of carbon dioxide, around 10% of the annual emissions of European Union member states. Estimates for later years have yet to be published. But a preliminary analysis suggests that the overall volume of gas flared has remained fairly constant, says Christopher Elvidge, a remote-sensing specialist who leads a team at the US National Oceanic and Atmospheric Administration (NOAA) in Washington DC that collects gas-flaring data. Flaring is common in oil and gas fields because producers deem it faster and cheaper to burn natural gas than to capture and use it, typically because they lack pipelines to economically transport the gas to market. But official data on the extent of the practice are scarce. In a 25 December paper, the NOAA researchers report tracking flares using an instrument aboard a NASA weather satellite that takes images of Earth in infrared and visible light 1 . (Previously, the team had used images from a US Air Force defence satellite, but a degradation in the satellite\u2019s orbit made it impossible to collect accurate global data on gas flaring). \u201cFlaring is an unproductive waste of a valuable, non-renewable resource and a significant source of carbon dioxide and methane emissions,\u201d says Bj\u00f8rn H\u00e5ms\u00f8, who manages the Global Gas Flaring Reduction Partnership at the World Bank in Washington DC. The World Bank aims to end routine gas flaring at oil production sites around the world by 2030, in an  initiative  launched last year. Some 45 governments, organizations and oil companies had signed up to the plan by the end of the international climate negotiations in Paris. High-quality national estimates, with detail on how much natural gas is being burned off where, will help governments to implement policies to reduce flaring and track progress, H\u00e5ms\u00f8 says. Estimates for subsequent years are expected to be published in the next few weeks. \n                   Study finds relatively low emissions of methane from major US gas fields 2015-Feb-19 \n                 \n                   Wasted energy 2013-Mar-19 \n                 \n                   Oil boom raises burning issues 2013-Mar-19 \n                 \n                   World Bank's Zero Routine Flaring by 2030 initiative \n                 Reprints and Permissions"},
{"file_id": "nature.2015.17961", "url": "https://www.nature.com/articles/nature.2015.17961", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Unusual battle among academic institutions holds key to gene-editing tool\u2019s future use. A versatile technique for editing genomes has been called the  biggest biotechnology advance  since the polymerase chain reaction (PCR), and the US Patent and Trademark Office (USPTO) is set to determine who will reap the rewards. On 11 January, the USPTO granted a request to review a key patent awarded for the technique, known as CRISPR\u2013Cas9. The outcome of the ensuing proceedings, called a patent interference, could be worth millions to the research institutions that are at war over the relevant patents. It might also influence who is allowed to use the technology \u2014 and under what terms. \u201cThis is an absolutely humungous biotech patent dispute,\u201d says legal scholar Jacob Sherkow of New York Law School. \u201cWe\u2019re all waiting with bated breath.\u201d CRISPR\u2013Cas9 is a bacterial defence system that uses the enzyme Cas9 to snip DNA at sites determined by the sequence of a \u2018guide\u2019 strand of RNA. Scientists can disable, replace or tweak genes by using the technique to rewrite snippets of DNA sequences. Use of the technology in research  has exploded , thanks to CRISPR\u2013Cas9\u2019s relative simplicity and versatility compared to other gene-editing methods. Several companies have sprung up to harness the technique for generating improved crops, research reagents and therapies for human genetic diseases. The roots of the CRISPR\u2013Cas9 dispute date back to 2012, when researchers reported that they had reprogrammed the system to cut strands of isolated DNA at sites of their choosing 1 . The team, led by biologists Jennifer Doudna at the University of California, Berkeley, and Emmanuelle Charpentier, now at the Max Planck Institute for Infection Biology in Berlin and Ume\u00e5 University in Sweden, filed a patent application on 15 March 2013. By then, publications had emerged from other groups showing that the method works in human cells 2 , 3 , 4  and bolstering dreams of CRISPR-based gene therapies \u2014 the basis for several companies that have sprung up to capitalize on the technique. One of those groups, led by synthetic biologist Feng Zhang of the Broad Institute and the Massachusetts Institute of Technology, both in Cambridge, filed a patent application for the CRISPR\u2013Cas9 technique in October 2013. The institutions filed the patent under a special expedited review programme, and it was granted in April 2014. Zhang has since been awarded additional patents on the technology. The original Doudna\u2013Charpentier patent remains under review. \n               A pitched battle \n             In April 2015, the Berkeley team asked the USPTO to begin an interference proceeding to determine which team was the first to invent the technique. The proceedings will be much like a court case, with both sides presenting evidence culled from publications and laboratory notebooks. \u201cOnce the [USPTO] declares an interference, that\u2019s really when the fur is going to fly,\u201d Sherkow predicted in a June interview. The patent interference is also a testament to the high stakes involved: companies aiming to use CRISPR\u2013Cas9 for gene therapy have raised hundreds of millions in venture capital and other funds in under three years. One company, Editas Medicine in Cambridge, Massachusetts, has already filed to go public. Arti Rai, a legal scholar at Duke University in Durham, North Carolina, says that it is unusual for academic research institutions to battle so intensely over a patent. Instead, such institutions usually come to an agreement to share rights to the invention. \u201cThis seems more bitter than disputes I\u2019ve heard of in the past,\u201d she adds. The two patents in question make broad claims to 'foundational' intellectual property thought to be necessary for most lucrative CRISPR\u2013Cas9 applications. But many patents have been filed on CRISPR\u2013Cas9 technologies, and there is still the chance that the winner of the interference will face additional challenges in court. Zhang's group has also reported  another enzyme, called Cpf1 , that could provide an alternative to Cas9. Researchers expect other alternatives to emerge with time.  As for the various CRISPR\u2013Cas9 companies, Zhang remains involved in Editas, which was founded by both Zhang and Doudna, among others, in 2013. Doudna has since severed ties with Editas and thrown her support behind Intellia Therapeutics, also in Cambridge. Charpentier, meanwhile, co-founded CRISPR Therapeutics of Basel, Switzerland. \n               Licensing looms \n             For now, it is unclear how the dispute will affect researchers who use CRISPR\u2013Cas9, if it does so at all. Academics who might use the technology for basic research make unattractive targets for patent lawsuits, says Rodney Sparks, a biotechnology patent counsel at the University of Virginia in Charlottesville. \u201cPatent holders might send out a few cease-and-desist letters, but they probably won\u2019t sue academic researchers,\u201d he says. Doing so would take time and money with little reward: the spoils in a patent lawsuit are typically damages or a share of royalties from a marketed product. That leaves little to gain from suing academics who are not selling anything. But those who intend to use their research as the basis for a start-up company will need to be wary, Sparks says. Some patent holders do ask that even scientists doing basic research take out a licence on a patented technology, typically for a fairly small fee. Such was the case for PCR, says Warren Woessner, a lawyer at Schwegman Lundberg and Woessner in Minneapolis, Minnesota. Woessner recalls how, during his previous career as a scientist, his institution decided to patent a method he developed. Officials at the institution later noticed that someone had published a paper that used the technique without a licence. \u201cThey sent the professor a little note,\u201d recalls Woessner. \u201c\u2018We have a patent on this. Pay up.\u2019\u201d The professor did. The Broad Institute has noted on its website that it will continue to make CRISPR\u2013Cas9 reagents available to the community, and has given no indication that it will pursue licensing fees from academics. But Sherkow warns against assuming that the spirit of academic camaraderie will prevail: licensing revenue has become increasingly important, particularly for major research institutions, he says. \u201cWe\u2019re just living in a brave new world these days.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     CRISPR, the disruptor 2015-Jun-03 \n                   \n                     Chinese scientists genetically modify human embryos 2015-Apr-22 \n                   \n                     365 days: Nature's 10 2013-Dec-18 \n                   \n                     CRISPR technology leaps from lab to industry 2013-Dec-03 \n                   \n                     Nature  special: CRISPR: the good, the bad and the unknown \n                   \n                     Editas Medicine \n                   \n                     Intellia Therapeutics \n                   \n                     CRISPR Therapeutics \n                   \n                     Feng Zhang \n                   \n                     Jennifer Doudna \n                   Reprints and Permissions"},
{"file_id": "529135a", "url": "https://www.nature.com/articles/529135a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "World\u2019s largest systematic identification project will use smart DNA-testing technology. Digging foundations for temples or schools, harvesting rice in paddy fields: these are some of the ways that the decaying remains of Vietnam War victims still turn up, 40\u00a0years after the conflict ended. Now an effort has begun that will use smart DNA technologies to identify the bones of the half a million or more Vietnamese soldiers and civilians who are thought still to be missing. It is the largest ever systematic identification effort; only the identification of more than 20,000\u00a0victims of armed conflicts in Bosnia and Herzegovina during the 1990s comes close. \u201cWhen I was a 21-year-old in the medical corps there, I never imagined that such a project could ever become possible,\u201d says Vietnam veteran and  genomics pioneer Craig Venter , head of the J. Craig Venter Institute in La Jolla, California. \u201cWe thought of body counts as statistics \u2014 now, decades later, it may be possible to put names to them.\u201d Although the United States has repatriated and identified most of its war dead, Vietnam has so far identified just a few hundred people, using outdated techniques. Yet people in Vietnam remain desperate to acquire the remains of family members. A few years ago, the government responded to their plight and asked the Advanced International Joint Stock Company (AIC) in Hanoi to investigate how best to proceed. The AIC consulted medical-diagnostics company Bioglobe in Hamburg, Germany, on how to equip the Vietnamese labs and train their scientists. In 2014, the Vietnamese government announced an investment of 500\u00a0billion dong (US$25\u00a0million) in the project and said that it would upgrade its three existing DNA-testing centres. This was great news, says Truong Nam Hai, head of the Institute of Biotechnology at the Vietnam Academy of Science and Technology, which hosts the first DNA-testing laboratory to be upgraded. In the 1990s, his institute proposed plans for identifying the missing, he says. However, \u201cdue to difficult circumstances at the time\u201d, these did not take off. Last month, the government signed a training and consultancy contract with Bioglobe, which will allow the sequencing effort to start. \u201cThe technical challenges are considerable but tractable,\u201d says Bioglobe\u2019s chief executive, Wolfgang H\u00f6ppner, who crafted the proposal for Vietnam. In the country\u2019s hot and humid climate, DNA in bones that have lain in shallow graves for decades is  likely to have degraded extensively . Moreover, contaminants from soil microbes can inhibit the enzymes that scientists use to amplify what little DNA remains to levels that can be analysed. And because of the large numbers of bones involved, the work needs to be done efficiently, adds H\u00f6ppner. H\u00f6ppner\u2019s proposal makes use of kits from Germany-based biotech company Qiagen, which have been designed to protect and reveal as much DNA as possible when dealing with difficult sources such as old, buried bones, and are also amenable to automated, \u2018high throughput\u2019 processes. The identification process involves powdering bone samples and chemically breaking down their cells. Before amplification, the DNA is extracted in sealed Qiagen cartridges that contain chemicals to wash away substances that could inhibit the process. Another Qiagen kit then checks the amplified DNA against a large set of genomic markers to create a DNA profile of the sample. The kit can also detect whether inhibitors are still present. In cases in which inhibitors prove stubborn, samples will be analysed manually by slower, more complex methods that have been optimized by an experienced forensic laboratory run by the International Commission on Missing Persons (ICMP). That lab, in Bosnia and Herzegovina\u2019s capital Sarajevo, led the  effort to identify people killed during the 1990s conflict , including nearly all of the 8,000 or so who were massacred in 1995 in Srebrenica. \n               Training begins \n             The ICMP will also have a role in training Vietnamese scientists. Truong\u2019s lab will next month send six scientists on a three-month programme. They will spend most of their time in Hamburg focusing on DNA tests, but they will also have a stint at the ICMP to learn other critical aspects of identification: how to avoid jumbling bones from different skeletons when exhuming them from mass graves, or how to look for clues in bones that might aid identification, such as pointers to height or gender. It was possible to extract useful levels of DNA from around 80% of the bones from the Srebrenica victims, says Thomas Parsons, head of the ICMP lab. The Vietnamese bones have been in the ground for longer and in a more damaging climate, but highly optimized methods and careful selection of skeletal samples will help, he says. The Vietnam project will also need reference DNA from family members to compare with the bone DNA from victims. It plans to have an outreach programme calling for people to donate saliva samples to create a reference data bank \u2014 but this will not be easy. Many war victims may have died too young to have had children, and their parents may also be dead, so reference samples will have to come from more distant relatives whose DNA is less similar. \u201cThat is why it is particularly important to do the DNA analysis with a larger than normal set of markers,\u201d says H\u00f6ppner. The outreach programme will also call for people to come forward with information on where bones might be buried. Unlike in Bosnia, where investigators could in some cases use satellite imagery to identify mass graves, the Vietnamese effort will rely on witness reports, as well as on common and military knowledge. Once all three government DNA-testing centres are upgraded, probably by 2017, they will together be able to identify between 8,000 and 10,000 people a year, says Truong. He also anticipates that the DNA project will improve Vietnam\u2019s scientific culture. \n                 Tweet \n                 Follow @NatureNews \n               \n                     Forensic DNA evidence is not infallible 2015-Oct-28 \n                   \n                     Forensic science: Bringing out the dead 2013-Nov-27 \n                   \n                     Body of evidence 2013-Feb-05 \n                   \n                     International Commission on Missing Persons \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19155", "url": "https://www.nature.com/articles/nature.2016.19155", "year": 2016, "authors": [{"name": "Heidi Ledford"}, {"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "US president also touts his climate-policy achievements as he begins his final year in office. US President Barack Obama isn\u2019t going quietly. He began his final year in office by announcing a \u201cmoonshot\u201d to cure cancer in his State of the Union address to Congress on 12 January. The effort will be led by vice-president Joe Biden, whose son Beau died of brain cancer last year. \u201cFor the loved ones we\u2019ve all lost, for the family we can still save, let\u2019s make America the country that cures cancer once and for all,\u201d Obama said in  a soaring speech  that otherwise offered few new proposals. Instead, the president spent most of the address looking back at his accomplishments over roughly seven years in office. The details of the cancer moonshot are still fuzzy. Biden says that he has consulted with nearly 200 physicians, researchers and philanthropists in the past few months and plans to continue to seek such input. Thus far, he has pledged to increase the resources available to combat the disease, and to find ways for the cancer community to work together and share information. The goal is to double the rate of progress against cancer, achieving in five years what otherwise would have taken ten. The vice-president also pointed to what he sees as key problems that must be tackled. Only 5% of people with cancer participate in clinical trials, he noted in  a statement released during the State of the Union  speech, and many community oncologists have limited access to the latest treatment advances. Biden\u2019s commitment to the programme, which he first hinted at three months ago, has been hailed by patient advocates, researchers and the biotechnology industry. Advances in cancer therapy, including treatments that  harness the immune system  and target specific tumour mutations, have brought cancer research to an inflection point, says Jos\u00e9 Baselga, a cancer researcher at the Memorial Sloan Kettering Cancer Center in New York City and president of the American Association for Cancer Research. \u201cNow is the time for a major new initiative in cancer science that supports and builds upon our basic science foundation,\u201d Baselga says. \n             Climate legacy \n           Climate change emerged as another major theme of the speech. Obama urged the United States to pursue new clean-energy technologies to reduce greenhouse-gas emissions. He also showed little patience for those who are sceptical about the idea that human activities are changing the climate. \u201cIf anybody still wants to dispute the science around climate change, have at it,\u201d Obama said. \u201cYou\u2019ll be pretty lonely, because you\u2019ll be debating our military, most of America\u2019s business leaders, the majority of the American people, almost the entire scientific community, and 200 nations around the world who agree it\u2019s a problem and intend to solve it.\u201d Scientists and environmentalists say that the president has done what he can to craft  a comprehensive climate policy  in the face of Republican intransigence. Most notably, his administration has advanced regulations to make vehicles more energy efficient and to curb pollution from  existing and future power plants . On the international front, Obama has committed the United States to reduce its greenhouse-gas emissions to 26% below 2005 levels by 2025 and helped to secure  a new global climate agreement  at the United Nations climate summit in Paris last December. But Obama has yet to bridge the national political divide on climate issues. And with one year left in office, he has little leeway to propose any major initiative to fight global warming. In his address, the closest thing to a commitment was a promise to \u201cchange the way we manage our oil and coal resources, so that they better reflect the costs they impose on taxpayers and our planet\u201d. \u201cOverall, the speech raises climate change to the highest level of importance but leaves the listener hungry for specifics about how to move forward to get the job done,\u201d says Michael Oppenheimer, a climate scientist at Princeton University in New Jersey. David Victor, a political scientist at the University of California, San Diego, noted that Obama has succumbed to the probably unrealistic notion that deploying clean energy and reducing greenhouse-gas emissions will save money, rather than raising the cost of energy. \u201cAlmost no serious analyst actually believes that,\u201d Victor says. But he credits Obama with stressing both technological innovation and international cooperation \u2014 even if the president did not specifically refer to the UN climate agreement reached in Paris. \u201cMost presidents come into office focused on national policy challenges, and they leave having spent a huge fraction of their time on foreign matters,\u201d Victor says. \u201cFor this president, climate is among them.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   Obama orders stronger limits on power-plant emissions 2015-Aug-03 \n                 \n                   Obama acts alone on climate 2015-Jan-27 \n                 \n                   Cancer treatment: The killer within 2014-Apr-02 \n                 \n                   Biden's statement on \u201ccancer moonshot\u201d \n                 \n                   Text of Obama's State of the Union address \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19138", "url": "https://www.nature.com/articles/nature.2016.19138", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Transmission of the virus has been stopped in West Africa \u2013 but what has the world learned? \n             Update, 15 January: After this article was published,  \n             a death from Ebola was announced in Sierra Leone \n              \u2013 underlining, as health officials have emphasized, the potential for new cases of the virus to emerge. \n           After the deaths of more than 11,000 people, public-health officials  declared on 14 January  that the spread of Ebola in West Africa has been stopped \u2014 at least for now. Officials with the World Health Organization (WHO) said that no new cases have been detected in Liberia since December. Since Sierra Leone and Guinea have already been declared Ebola-free, this officially ends the chain of human transmission in the region that began more than two years ago. \u201cDetecting and breaking every chain of transmission has been a monumental achievement,\u201d said WHO director-general Margaret Chan. But the epidemic may not be over for good. The WHO cautioned that the virus could re-emerge, as  happened twice in flare-ups in Liberia  after the country was first declared Ebola-free last May. The epidemic has been one of the worst international health disasters in history: unprecedented in its duration as well as the number of people it infected and killed. Here are seven lessons that health officials and the world at large have learned from the harrowing event. 1.  The world isn\u2019t equipped to deal with international public-health crises, especially in poor countries. The epidemic emerged in Guinea in December 2013, then grew out of control as local and foreign governments and the WHO  failed to contain it  or devote adequate resources to stopping it. Although  numerous global panels of experts  have  called for reform , there has been little movement towards fixing the broken international health systems whose failure led to the problem. 2.  The balance of power in global health has shifted. The WHO acknowledges its own failings on Ebola, which demonstrated how the organization was  unable to respond quickly  to fast-moving epidemics in developing countries. In fighting the West Africa epidemic, non-governmental organizations \u2014 including local groups, religious charities and the international health-aid organization  M\u00e9decins Sans Fronti\u00e8res  (also known as Doctors Without Borders) \u2014 shouldered much of the burden. 3.  West Africa's medical infrastructure is extremely shaky. A few dedicated local health workers fought valiantly against Ebola when it first emerged, but they had too few resources to do the job. Many who fought the disease  lost their lives , compounding the problem. And the epidemic is likely to have  long-lasting impacts  on health in West Africa \u2014 for instance, by diverting resources away from fragile gains in  maternal and child health , orphaning children and causing lingering medical problems in survivors. Ebola and other viral threats are likely to re-emerge, underscoring the importance of shoring up resources in the region. 4.  Stigma and fear can fuel an already deadly epidemic. Early misconceptions that Ebola was always fatal and impossible to treat kept people from seeking treatment, allowing the disease to spread in communities. And a dearth of clear communication about how to contain the virus and safely care for the sick  drove its spread  among those brave and loyal enough to care for loved ones. Survivors are among the most valuable workers against Ebola, because they are thought to have some immunity to the virus, but in many places  they have been ostracized  from their communities. Countries outside Africa compounded irrational fear by clamping down on international travel and quarantining returning health-workers; the state of Louisiana even  banned scientists  who had worked to combat the virus from attending a meeting. 5.  Beating Ebola required officials to understand the local culture and let the region\u2019s leaders lead. Efforts by foreign countries often collided with realities on the ground, contributing to the spread of the disease. The lack of a word for \u2018virus\u2019 in some local languages, for instance, caused confusion; people chafed at travel bans and quarantines; and many families balked at sending their loves ones to distant treatment centres. Informed local leaders , such as chiefs and religious leaders, educated communities more effectively than well-intentioned foreign experts. 6.  Clinical trials need to happen even faster in the next epidemic. Scientific leaders and health officials organized faster than ever before to test candidate Ebola drugs and vaccines during the epidemic, and were able to prove that one  vaccine is effective . But  bureaucratic delays and infighting  stalled many trials until the epidemic had largely passed its peak, so there are still no definitive results on whether experimental treatments such as  the drug ZMapp  actually work. 7.  It isn't over yet. Before this epidemic, few thought that an Ebola outbreak could grow to this scale. But increasing urbanization and connectivity have changed the dynamic of this and other emerging infectious diseases. Officials hope to beef up disease surveillance in West Africa, but they still don\u2019t even know for certain  which animals harbour Ebola  in the wild, so it is difficult to predict where or when the next outbreak will occur. And there are other lethal viruses that  could cause as much suffering  as Ebola has in West Africa, or even more. This outbreak has demonstrated that the world is much more vulnerable to global epidemics than anyone realized two years ago. \n                   Disease specialists identify post-Ebola threats 2015-Dec-07 \n                 \n                   Ebola experience leaves world no less vulnerable 2015-Nov-22 \n                 \n                   Nature  special: Ebola \n                 Reprints and Permissions"},
{"file_id": "529140a", "url": "https://www.nature.com/articles/529140a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Rumours frustrate physicists in a global competition to understand elusive particles. Time is running out for Indian scientists to build a facility that would let them compete in one of the hottest races in physics. The India-based Neutrino Observatory (INO) \u2014 an effort to learn about the masses and other properties of mysterious particles called neutrinos \u2014 is under threat as a result of baseless rumours about its aims and environmental impact. Despite a government go-ahead in January 2015 to build a massive detector under a mountain in the southern state of Tamil Nadu, opposition from environmentalists and state politicians means that not a single grain of earth has been shifted. Neutrinos are abundant subatomic particles that are extremely hard to detect. Billions pass through each square centimetre of Earth every second, but barely any leave a trace. The INO would study neutrinos produced when cosmic rays strike the atmosphere, and would seek to reveal the relative masses of the three known types of neutrino. The measurements could lead to  Nobel-prize-worthy insights  into the relationship between nature\u2019s four fundamental forces, as well as the imbalance between matter and antimatter in the Universe. But if the INO is not built soon, other projects \u2014 including one that broke ground in China a year ago \u2014 may get there first, says D.\u00a0Indumathi, a theorist at the Institute of Mathematical Sciences in Chennai who is part of the INO collaboration, and coordinates outreach for it. \u201cLonger than a year of delay and I think it will be difficult to have viable physics goals, at least of the current type,\u201d she says. Conceived in 2001 and originally slated for completion in 2012, the INO has faced a rocky path to construction. To shield the enormous detector from the confounding zoo of subatomic particles that pummels Earth\u2019s surface, the facility needs to be built more than a kilo\u00admetre underground. The first earmarked site was ruled out in 2009 after a lengthy battle with conservationists over its proximity to an  elephant and tiger reserve . The current site, in the Tamil Nadu district of Theni, faced opposition as soon as it was put forward in 2010. Local villagers worried that the facility would deplete or contaminate their restricted water supply, and cut off access to land for grazing livestock, says Indumathi. But, she says, villagers consented after scientists assured them that the facility would not interfere with their resources. Since then, however, local environmental organizations and regional politicians have taken up the issue, and the list of objections has swelled to include fears that the lab will emit radiation and store nuclear weapons, and that the excavation will threaten a nearby dam. The rumours are untrue, says Naba Mondal, a physicist at the Tata Institute of Fundamental Research in Mumbai who leads the INO collaboration. INO scientists have visited schools and held community meetings to counter misconceptions. But many villagers have turned against the project. \u201cThey don\u2019t know what the truth is, and I can understand that,\u201d says Mondal.  They don\u2019t know what the truth is, and I can understand that.  At the root of the rumours is mistrust of the state and the scientific establishment, says Govind Krishnan, an Indian journalist who has closely followed the project. He believes that the fears that have been raised lie \u201cin the realm of fantasy\u201d, but are understandable given the poor environmental record of past state-sponsored construction projects. Govind disagrees with activists who say that INO scientists have ignored the project\u2019s impact on the poor, but he says that scientists\u2019 efforts have been hampered by class and linguistic barriers. India\u2019s government allocated 15 billion rupees (US$225 million) to construction when it gave the INO the green light last year, but the Madras High Court in Chennai brought the project to a standstill in March following a petition from local activists and politicians. The court said that the Tamil Nadu Pollution Control Board must give consent before construction can start. This is normally a routine, 45-day step, but the process has so far taken 9\u00a0months, says Mondal. The politically contentious nature of the project means that the local board may well delay until after state elections in May. \u201cI am confident that it will eventually be approved, but the question is when,\u201d says Mondal. The delay is damaging the morale of students and researchers on the project, he adds. Meanwhile, China expects to complete the Jiangmen Underground Neutrino Observatory in 2019. To remain competitive, the INO must start construction in the next few months, says Mondal. \u201cScience is something you have to do in time. If you are not in time, your results may not be that important.\u201d But neutrino physicists say that even if the INO loses the race, its findings would help to corroborate discoveries at other detectors. The INO takes a unique approach \u2014 using 50,000\u00a0tonnes of magnetized iron to separate atmospheric neutrino observations from their antineutrino counterparts. That will make its results interesting whenever they come out, says Mark Messier, a physicist at Indiana University Bloomington and co-spokesperson for the NOvA Neutrino Experiment at Fermilab in Batavia, Illinois, which also has a chance of solving the neutrino-mass mystery. Researchers point to other benefits, too. Putting a physics laboratory deep underground gives India the opportunity to host research into areas such as dark matter, they say \u2014 and it is empowering for Indian scientists to bring a major physics facility to fruition. \u201cAlready I\u2019ve seen the tremendous difference it\u2019s made to students having an experiment on which they call the shots,\u201d says Indumathi. \u201cSo I really don\u2019t care whether we get a Nobel prize or not.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Morphing neutrinos win physics Nobel 2015-Oct-06 \n                   \n                     Age of the neutrino: Plans to decipher mysterious particle take shape 2015-Aug-12 \n                   \n                     Research management: Priorities for science in India 2015-May-13 \n                   \n                     Cosmic mismatch hints at the existence of a 'sterile' neutrino 2014-Feb-20 \n                   \n                     Indian neutrino lab site rejected 2009-Nov-24 \n                   \n                     The elephant and the neutrino 2009-Sep-22 \n                   \n                     Nature  special: Science in India \n                   \n                     India-based Neutrino Observatory \n                   \n                     \u2018The case of the killer particle\u2019 by Govind Krishnan (article in  Fountain Ink ) \n                   Reprints and Permissions"},
{"file_id": "529136a", "url": "https://www.nature.com/articles/529136a", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Epidemiologist who spearheaded response to outbreak is a popular choice. Taiwan \n               Update, 16 January: Tsai Ing-Wen has won the election and will become Taiwan\u2019s first female president. Chen Chien-Jen, an epidemiologist known for his influential studies on the dangers of arsenic and hepatitis as well as his handling of the SARS outbreak in 2003, will be the island's vice president. \n             A famous and influential scientist, Chen Chien-Jen, is set to become Taiwan\u2019s vice-president after elections on 16 January. If he does, it is hoped that Chen\u00a0\u2014 an epidemiologist looked upon as a hero for his role in subduing Taiwan\u2019s outbreak of severe acute respiratory syndrome (SARS) in 2003\u00a0\u2014 will help to infuse the new government with an air of integrity and collaboration, maintain good relations with China and stimulate ideas for revitalizing the economy. \u201cHe can negotiate with anyone, and is always trying to help,\u201d says the National Taiwan University\u2019s president, Yang Pan-Chyr. \u201cYou wouldn\u2019t think such a person would be a candidate for a politician.\u201d Chen announced in November that he would be the running mate for Tsai Ing-Wen, leader of the Democratic Progressive Party (DPP). If Tsai were to win, it would be only the second time in Taiwan\u2019s history that the ruling Kuomintang (KMT) party has been dethroned.\u00a0 Tsai is ahead in all the polls: she leads the KMT candidate by 30 percentage points, according to the non-profit Cross-Strait Policy Association, which carries out research on relations between Taiwan and the mainland \u2014 and the KMT\u2019s own survey puts her lead at 8 percentage points. Chen, too, is popular \u2014 the Cross-Strait Policy Association puts his \u2018admiration\u2019 rating at 54%, compared with 27% for his counterpart in the KMT. This is probably a result of his celebrity status with regard to the SARS epidemic. Panic over the viral infection , which initially emerged in mainland China but quickly spread across many parts of the world, was exacerbated in Taiwan because the United Nations recognizes China\u2019s claim that Taiwan is part of China, and thus refuses to give it an independent seat at meetings of the World Health Organization. Excluded from international discussions and sample sharing, Taiwan\u2019s outbreak spiralled out of control even as authorities elsewhere were getting a grip on the epidemic. It was Chen, who was appointed health minister as the epidemic was escalating in Taiwan, who headed containment efforts. He bolstered attempts to isolate patients so as to prevent spread in hospitals, and boosted screening for fever. Even today, mentioning his name can elicit an enthusiastic thumbs-up. \u201cChen is great,\u201d a taxi driver in Taiwan told  Nature  in early January. \u201cWith SARS, he was so fast.\u201d Chen is also popular in scientific circles, where he is known for other groundbreaking work. His research on the effects of arsenic exposure led health agencies around the world to lower the levels deemed acceptable ( C.-J.\u00a0Chen  et\u00a0al. Br. J. Cancer   66,  888\u2013892; 1992 ), and his assessment of the risk of liver cancer in people with chronic hepatitis led to new treatment guidelines ( C.-J.\u00a0Chen  et\u00a0al. J. Am. Med. Assoc.   295,  65-73; 2006 ).  An online petition supporting Chen\u2019s candidacy  has received more than 1,600 signatures \u2014 including those of prominent academics. \u201cWithin days, hundreds of names poured in,\u201d says Ming-Liang Lee, the former Taiwanese health minister who started the petition. Many researchers value Chen\u2019s personality. \u201cHe has the capacity and appeal to pull people together,\u201d says Ming-Chu Hsu, chief executive of TaiGen, one of Taiwan\u2019s most successful biotechnology companies. Chen carries a reassuring air of reliability. \u201cHe would be someone we can trust. Everyone seems to think so,\u201d says Yang. Chen himself told  Nature  that attributes honed during his time as a scientist \u2014 for example, the ability to solve problems \u2014 are beneficial to politics. He also said that it is crucial to revitalize Taiwan\u2019s stagnant economy: increased competition in electronics from China and elsewhere has slashed the profits that once made Taiwan wealthy. Tsai has outlined five areas in which Taiwan can innovate: biopharmaceuticals, green energy, big data, precision machinery and national defence. To bolster those aims, Chen plans to establish a research system that encourages researchers and entrepreneurs to take risks. \u201cNow the government doesn\u2019t allow failure, so everyone goes for \u2018me-too\u2019 modifications, not innovation,\u201d he told  Nature . Scientists and technology-based industrialists say that Chen and Tsai\u2019s intention to promote innovation could bring a much-needed focus on Taiwanese science, although advocates are trying to keep things in perspective. \u201cI think all science and technology would benefit from his taking office,\u201d says Yang. \u201cBut maybe we are expecting too much.\u201d The DPP has traditionally emphasized Taiwanese autonomy, which riles Beijing, but \u201cwe don\u2019t want to be troublemakers\u201d, says Chen. He acknowledges that he himself came up against the Chinese authorities during the SARS epidemic, but says that agreement on how to handle information on health and infectious diseases has largely resolved the issues. A continuation of the status quo suits neuroscientist Chiang Ann-Shyn at Taiwan\u2019s National Tsing Hua University; he expects Chen to act as an antidote to the DPP\u2019s sometimes provocative statements on independence. \u201cRelations with China have been good. I don\u2019t think Chen will do anything radical,\u201d he says. Two decades of stable relations following a crisis in the mid-1990s \u2014 when the mainland tested missiles in the strait \u2014 have led to a boom in business between Taiwan and the mainland, and research collaborations between them have quadrupled in the past ten years (see \u2018Cross-strait collaboration\u2019). Hsu agrees with Chiang; her company\u2019s  antibiotic against multi-drug-resistant  Streptococcus pneumoniae  was the first drug developed in Taiwan to be submitted for approval on the mainland under new rules. \u201cHealth is one thing we can work on together,\u201d she says. Chen becomes emotional when talking about the possible end of his research career. Until recently, he had assumed that this would be at the nation\u2019s premier research organization, the Academia Sinica, where he was vice-president until he declared himself Tsai\u2019s running mate. But although he was at first reluctant to join the electoral race, he finally decided that improving Taiwan\u2019s social and economic situation was more important than his research. A devout Catholic who consulted his archbishop before making his decision, Chen says that he considers his political career a \u201ccalling from God\u201d. He adds: \u201cI told the people in my laboratory that, for the coming years, it\u2019s more important that I serve the people.\u201d\n \n                 Tweet \n                 Follow @NatureNews \n               \n                 weibo \n               \n                     Uncharted territory 2011-Oct-19 \n                   \n                     Angry words over East Asian seas 2011-Oct-19 \n                   \n                     Biology society narrows Chinese rifts 2009-Jun-24 \n                   \n                     Taiwan left isolated in fight against SARS 2003-Apr-17 \n                   \n                     Bridging the Taiwan Strait 2000-Sep-21 \n                   \n                     Democratic Progressive Party \n                   \n                     Chen Chien Jen \n                   Reprints and Permissions"},
{"file_id": "529450a", "url": "https://www.nature.com/articles/529450a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Local expertise is required to provide detailed emissions reports. Indonesia\u2019s Central Kalimantan province, a lightly populated swathe of Borneo, is a hotbed for greenhouse gases that are emitted through deforestation, family farming and industrial palm-oil production. Last year, these activities fuelled  devastating fires  that torched more than 400,000 hectares in the province and at least 2.5 million hectares across the developing nation. By some estimates, the fires released into the atmosphere more than twice as much carbon as Germany emits in a year. Calculating the volume of greenhouse gases emitted across such a dynamic landscape is not an easy task. Nevertheless, the  climate agreement made in Paris  last month dictates that nearly every country will need to begin assembling detailed inventories of their greenhouse-gas emissions in a few years\u2019 time. In Indonesia, the national government has delegated much of that responsibility to provincial governments. Soon, administrations that often struggle to provide basic public services will be required to master the complex science of carbon accountancy. \u201cWe cannot rely on the local governments,\u201d says Rizaldi Boer, who heads the Centre for Climate Risk and Opportunity Management in Southeast Asia and the Pacific in West Java. \u201cWe need to integrate this kind of training into the local universities.\u201d It is a challenge that is being faced by developing countries across the globe. The Paris agreement relies on a \u2018pledge and review\u2019 programme to reduce emissions and halt global warming over the course of the twenty-first century. Under that strategy, countries must document their progress towards voluntary commitments to limit carbon emissions. Solid and transparent data will be needed to verify that they are living up to their promises. \u201cThis is really the compliance regime for the Paris agreement,\u201d says Alden Meyer, director of strategy and policy for the Union of Concerned Scientists in Washington DC. \u201cThis is how you really tell how well you are doing.\u201d Developed countries have been submitting detailed reports on greenhouse-gas emissions to the United Nations for years. But until now, developing countries \u2014 which produce nearly two-thirds of global greenhouse-gas emissions \u2014 were not required to provide such comprehensive reports on a regular basis. Under the Paris agreement, most countries will need to supply inventories of greenhouse-gas emissions every two years \u2014 and although the deal includes some flexibility, the details have yet to be resolved.  We can\u2019t implement this agreement without building capacity.  Efforts are under way to build a network of professional carbon accountants across the developing world. Partnering with the Greenhouse Gas Management Institute (GHGMI), a non-profit organization headquartered in Washington DC that has trained more than 3,000 people in carbon accounting, Boer is developing a formal curriculum for universities in Indonesia. His focus lies on teaching the assessment of land-use emissions, which are the largest \u2014 and hardest to quantify \u2014 source of greenhouse gases in the country. The ultimate aim is to build a qualified workforce to feed into local governments as well as businesses and other institutions that are working to tackle climate change. \u201cWe can\u2019t implement this agreement without building capacity,\u201d says John Niles, who directs the Carbon Institute, an arm of the GHGMI that develops training programmes in the measurement and monitoring of carbon emissions. \u201cWe need the right investments in the right institutions, in every country on Earth.\u201d \n               Local responsibility \n             Although the central government of Indonesia provides basic data on deforestation, provincial officials must calculate emissions from the expanding agriculture sector as well as from the energy, industrial and municipal sectors. After the data have been collected and the calculations performed, Boer says, officials must complete and submit 186 forms to meet the reporting requirements laid out by the Intergovernmental Panel on Climate Change. \u201cIt\u2019s very hard for the local governments to understand,\u201d he says. But if Indonesia succeeds in building the technical capacity to conduct such assessments, it will become easier for the country to test new policies and to assess what will work best to reduce emissions in the future. \u201cWe have to see this as an opportunity,\u201d says Boer. Cost will be a barrier. Although poorer countries such as Indonesia finally agreed to a unified framework for reporting emissions in Paris, they fought hard for assurances that wealthier countries would provide money to help them to kick-start the process. Various initiatives are already under way. The GHGMI has developed an online training course in carbon accounting and is investigating ways to provide ongoing support for individuals and institutions in developing countries. And in March, a coalition of countries and climate-advocacy organizations led by Germany is expected to launch a US$15-million initiative to help less-wealthy countries prepare to monitor and report their greenhouse-gas emissions. The process could function differently in each country. But Yamide Dagnet, a former climate negotiator for the UK government who works for the World Resources Institute in Washington DC, suggests that academic institutions can serve as repositories for expertise on behalf of governments, which often lose their most-skilled and experienced carbon accountants to the United Nations, think tanks and corporations. \u201cYou could have universities and institutes designed to provide data, with some permanent experts and graduate students as well,\u201d says Dagnet. \u201cI think we need to be really creative.\u201d Perhaps the biggest challenge is how to move quickly. Developing countries may need to begin reporting within a few years, says Michael Gillenwater, executive director and dean of the GHGMI. The prevailing approach of hosting workshops and one-time training sessions to promote minimal local expertise while bringing in consultants to oversee one-off greenhouse-gas inventories will not be enough. \u201cThe current model will break if you try and scale it up,\u201d says Gillenwater. \u201cWe need more and better people and we need a different model.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Nations approve historic global climate accord 2015-Dec-12 \n                   \n                     Is the 2\u2009\u00b0C world a fantasy? 2015-Nov-24 \n                   \n                     Combined climate pledges of 146 nations fall short of 2\u2009\u00b0C target 2015-Oct-30 \n                   \n                     Big compromises needed to meet carbon-emissions goal 2015-May-27 \n                   \n                     Nature  special: 2015 Paris climate talks \n                   \n                     UNFCCC \n                   \n                     GHGMI \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19229", "url": "https://www.nature.com/articles/nature.2016.19229", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Autopsies reveal plaques in the brains of people who died after receiving grafts from cadavers. For the second time in four months, researchers have reported autopsy results that suggest Alzheimer\u2019s disease might occasionally be transmitted to people during certain medical treatments \u2014 although scientists say that neither set of findings is conclusive. The latest autopsies,  described in the  Swiss Medical Weekly 1  on 26 January, were conducted on the brains of seven people who died of the rare, brain-wasting Creutzfeldt\u2013Jakob disease (CJD). Decades before their deaths, the individuals had all received surgical grafts of dura mater \u2014 the membrane that covers the brain and spinal cord. These grafts had been prepared from human cadavers and were contaminated with the prion protein that causes CJD. But in addition to the damage caused by the prions, five of the brains displayed some of the pathological signs that are associated with Alzheimer\u2019s disease, researchers from Switzerland and Austria report. Plaques formed from amyloid-\u03b2 protein were discovered in the grey matter and blood vessels. The individuals, aged between 28 and 63, were unusually young to have developed such plaques. A set of 21 controls, who had not had surgical grafts of dura mater but died of sporadic CJD at similar ages, did not have this amyloid signature. \n             Transplant trouble \n           According to the authors, it is possible that the transplanted dura mater was contaminated with small \u2018seeds\u2019 of amyloid-\u03b2 protein \u2014 which some scientists think could be a trigger for Alzheimer\u2019s \u2014 along with the prion protein that gave the recipients CJD. Both diseases have long incubation periods. But whereas CJD progresses quickly once initiated, age-related Alzheimer\u2019s develops slowly. None of the individuals had displayed obvious Alzheimer\u2019s symptoms before their deaths. The results follow  a study published in  Nature 2  last September in which scientists from University College London reported that four of eight relatively young people, all of whom died of CJD decades after receiving contaminated batches of growth hormone prepared from cadavers, also displayed amyloid plaques in the blood vessels and grey matter of their brains. \u201cOur results are all consistent,\u201d says neurologist John Collinge, a co-author on the  Nature  paper. \u201cThe fact that the new study shows the same pathology emerging after a completely different procedure increases our concern.\u201d \n             Not infectious \n           Neither study implies that Alzheimer\u2019s disease could ever be transmitted through normal contact with caretakers or family members, the scientists emphasize. And no one uses cadaver-derived preparations in the clinic anymore. Synthetic growth hormone is used for growth disorders, and synthetic membranes are used for patching up in brain surgery.\u00a0 But the scientists say that if the theory of amyloid seeding turns out to be true, it would have important clinical implications. In general surgery, for example, any amyloid-\u03b2 proteins, which are very sticky, would not be routinely removed from surgical instruments; standard sterilization procedures cannot shift them. \u201cIt is our job as doctors to see in advance what might become a problem in the clinic,\u201d says neuropathologist Herbert Budka of the University Hospital Zurich, Switzerland, who is a co-author of the latest paper. \u201cNothing is proven yet,\u201d cautions Pierluigi Nicotera, head of the German Centre for Neurodegenerative Diseases in Bonn. He points out that amyloid-\u03b2 has not been identified in the preparations that were transplanted in either the growth hormone or dura mater studies. Nor can researchers rule out the possibility that the underlying condition that led to the need for neurosurgery could have contributed to the observed amyloid pathology, as the authors of the latest paper note. \u201cWe need more systematic studies in model organisms to work out if the seeding hypothesis of Alzheimer\u2019s is correct,\u201d Nicotera says. \n               Tweet \n               Follow @NatureNews \n             \n                   Autopsies reveal signs of Alzheimer\u2019s in growth-hormone patients 2015-Sep-09 \n                 \n                   Genetic mutation blocks prion disease 2015-Jun-10 \n                 \n                   Alzheimer\u2019s research takes a leaf from the prion notebook 2015-May-29 \n                 Reprints and Permissions"},
{"file_id": "529446a", "url": "https://www.nature.com/articles/529446a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Pet project hunts genetic links to behaviour by polling owners on their companions\u2019 quirks. Addie plays hard for an 11-year-old greater Swiss mountain dog\u00a0\u2014\u00a0she will occasionally ignore her advanced years to hurl her 37-kilogram body at an unwitting house guest in greeting. But she carries a mysterious burden: when she was 18\u00a0months old, she started licking her front legs aggressively enough to wear off patches of fur and draw blood. Addie has canine compulsive disorder\u00a0\u2014\u00a0a condition that is thought to be similar to human obsessive\u2013compulsive disorder (OCD). Canine compulsive disorder can cause dogs to chase their tails for hours on end, or to suck on a toy or body part so compulsively that it interferes with their eating or sleeping. Addie may soon help researchers to determine why some dogs are more prone to the disorder than others. Her owner, Marjie Alonso of Somerville, Massachusetts, has enrolled her in a project called Darwin\u2019s Dogs, which aims to compare information about the behaviour of thousands of dogs against the animals\u2019 DNA profiles. The hope is that genetic links will emerge to conditions such as canine compulsive disorder and canine cognitive dysfunction \u2014 a dog analogue of dementia and possibly Alzheimer\u2019s disease. The project organizers have enrolled 3,000\u00a0dogs so far, but hope to gather data from at least 5,000, and they expect to begin analysing DNA samples in March. \u201cIt\u2019s very exciting, and in many ways it\u2019s way overdue,\u201d says Clive Wynne, who studies canine behaviour at Arizona State University in Tempe. Researchers have long struggled to find genetic links to human psychiatric disorders by analysing DNA samples from thousands of people. Those efforts have in recent years met with some success in  schizophrenia  and  depression . But for some conditions, including OCD, not a single robust genetic link has been sifted from the background noise of normal genetic variation. Human studies are difficult in part because the species is so genetically diverse, says Wynne. Dogs, however, are more genetically homogeneous. Selected over thousands of years for particular characteristics, they display less genetic variation than do humans. Pure-bred dogs, in particular, have been rendered highly genetically consistent to achieve a homo\u00adgenous appearance and behaviour. Dogs also live side-by-side with humans, which some think can make them a better model for human disorders than mice living in a laboratory cage. These qualities have made dogs attractive targets for studies of analogues to human ailments, including epilepsy, cancer and various psychiatric disorders. Border collies, for example, may over-react to loud noises in a manner akin to people with anxiety disorders. Geneticist Elinor Karlsson of the University of Massachusetts Medical School in Worcester and her colleagues have studied canine compulsive disorder, a condition that is particularly common in certain breeds, including Dobermann pinschers. Their studies in 150 dogs have found possible links to four genes that encode proteins that act in the brain ( R. Tang  et al.   Genome Biol.   15,  R25; 2014 ). To expand on those results, Karlsson has decided to go big. Limiting her studies to specific breeds would make it easier to pick out some genetic links, but others might be missed. So Karlsson and her colleagues, including Jesse McClure, a former dog trainer for the US Marine Corps, decided to collect data from mongrels as well as pure-bred dogs and to crowdsource the data collection. That focus on mixed-breed dogs is unusual but shrewd, says Adam Boyko, a geneticist at Cornell University in Ithaca, New York. Although more than half of the dogs in the United States are mongrels, genetic studies tend to focus on pure-bred animals. \u201cGenetics often deals with the interactions between genes,\u201d says Boyko. \u201cAnd if you want to truly understand those, you want to study individuals where you\u2019ve shuffled up the genes.\u201d Human participants in Darwin\u2019s Dogs, which launched last October, answer about 130\u00a0questions about their pets\u2019 behaviour. The questions cover everything from \u2018Does your dog generally enjoy life?\u2019 (the answer, says Karlsson, is overwhelmingly \u2018yes\u2019) to \u2018Does your dog cross its paws when it lies down?\u2019. Some questions were inspired by surveys that assess impulsivity in humans. Other questions have been suggested by Alonso, who is the executive director of the International Association of Animal Behavior Consultants in Cranberry Township, Pennsylvania, and by other dog trainers on the basis of observations made over decades of working with animals that have behavioural problems. Karlsson says that she is thinking of expanding the list of questions even further. \u201cFortunately, it turns out that people love to talk about their dogs,\u201d she says. Ultimately, the success of the project may hinge on the quality of those surveys and the specificity of the questions asked, says Wynne. Asking owners whether their dog is happy, for example, could yield mixed results. \u201cOne person\u2019s unhappy dog is another person\u2019s comfortably resting dog,\u201d he says. \u201cA good question would be: \u2018Does your dog poop on the carpet?\u2019 Because poop on the carpet is pretty damn clear.\u201d It is still unclear how useful the results from dogs will be in shedding light on human behavioural variation. Karlsson is hopeful that even if different genes are involved in the two species, they may converge on the same cellular pathways. Gerald Nestadt, a psychiatrist who specializes in OCD at Johns Hopkins University in Baltimore, Maryland, notes that affected animals often display only one type of compulsive behaviour, whereas a human with OCD will typically have several. Even so, he adds, the field is hungry for any leads it can get. \u201cAnything that will help is worth trying,\u201d he says. \u201cI think this project is a great idea.\u201d For their part, Alonso and other participants are eager to learn more about their own dogs and why they behave the way they do. Miranda Workman of Buffalo, New York, enrolled her three dogs\u00a0\u2014\u00a0Zeus, Athena and Sherlock\u00a0\u2014\u00a0into the study, in part to gain insight into their behavioural quirks. Although Athena, a 34-kilogram Dutch shepherd, was bred to be a dedicated herding and guarding dog, she has a jovial side that is not often found in her breed. And Sherlock, a Jack Russell, is more shy and sensitive than other terriers. \u201cI have some dogs that don\u2019t necessarily fit the stereotype,\u201d says Workman. \u201cIs it their environment that\u2019s different or are they different? It will be fun to find out why they are that way.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Dogs thwart effort to eradicate Guinea worm 2016-Jan-05 \n                   \n                     Puppy bred to have muscular dystrophy saved by surprise mutation 2015-Nov-12 \n                   \n                     Ancient wolf genome pushes back dawn of the dog 2015-May-21 \n                   \n                     \u2018I can haz genomes\u2019: cats claw their way into genetics 2015-Jan-14 \n                   \n                     Darwin's Dogs \n                   Reprints and Permissions"},
{"file_id": "nature.2016.19476", "url": "https://www.nature.com/articles/nature.2016.19476", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Have you been paying attention to February's science news? \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             Reprints and Permissions"},
{"file_id": "nature.2016.19483", "url": "https://www.nature.com/articles/nature.2016.19483", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Findings could inform forensic science \u2014 and the development of innovative hair products. Bushy and black, downy and blonde, curly and red: human hair comes in myriad shapes and colours. Now researchers have identified ten new genetic variants that influence its appearance \u2014 including the first genes to be associated with the rate at which hair goes grey, the bushiness of someone\u2019s beard or eyebrows and whether they grow a \u2018monobrow\u2019. Understanding the variability in human hair isn\u2019t only interesting from a cosmetic perspective \u2014 it also informs the study of evolution. Hair can signal social status, health and fertility, and regulates body temperature. \"Humans are very distinctive among our primate cousins in that our scalp hair can be very luxuriant and long,\u201d says Desmond Tobin, director of the Centre for Skin Sciences at the University of Bradford, UK, who was involved in the latest study. The amount of hair growing on the body also varies significantly between human individuals. Although previous studies have, among other things, identified genes associated with  male pattern baldness  (the most common type of hair loss in men), hair colour and hair curliness, these have largely focused on European and East Asian populations. To investigate further, Kaustubh Adhikari at University College London and his colleagues turned to a sample of more than 6,000 people living in Brazil, Colombia, Chile, Mexico and Peru. They report their findings in  Nature Communications 1 . The sample contains a mixture of European, African and Native American descendants \u2014 with this last group thought to have originally migrated from East Asia. \u201cYou would expect these people to have quite a lot of additional gene variants,\u201d says Adhikari, who has investigated ear shape in the same population 2 . \n             Hair pattern \n           The researchers categorized volunteers according to the colour, shape and pattern of hair on their scalp and faces, and took a blood sample so that hundreds of thousands of variations in individuals' genetic codes could be recorded. Correlating these variations with physical traits \u2014 an approach known as a genome-wide association study (GWAS) \u2014 revealed areas of the genome that seemed to have the strongest influence on those characteristics. One of the variants identified affects the rate at which hair turns grey, and is located in a gene called  IRF4 , which regulates the production and storage of melanin \u2014 the pigment that determines hair, skin and eye colour. The same variant has previously been associated with pale hair in Europeans. Another, which influences the curliness of hair, is in the  PRSS53  gene. This encodes an enzyme that is produced in the hair follicle, which surrounds and protects growing hair. Such discoveries could pave the way for drugs that alter the colour or curliness of hair. \u201cStandard hair products are applied after your hair has been created, but targeting the hair as it is being produced could result in greater consistency of colour, or longer-lasting effects,\u201d Adhikari says. Other genes identified by the team include a variant of the EDAR gene, previously associated with hair thickness in East Asians, which seems to cause facial hair to grow more sparsely and scalp hair to grow straight; a variant of  FOXL2  that is associated with eyebrow thickness; and a  PAX3  variant that is associated with the growth of a monobrow. \n             DNA mugshot \n           Such knowledge could one day feed into  attempts to create mugshots of criminal suspects from their DNA alone , says Manfred Kayser at Erasmus University Medical Center in Rotterdam, who works on the applications of appearance genetics to forensics and anthropology. But, he cautions, \u201cwith the exception of hair colour, we don\u2019t yet understand nearly enough of the genetic basis of these traits for them to be useful\u201d. The findings will now need to be replicated and many more genes need to be identified, he says: \u201cFor many of the hair traits studied in this paper, they deliver the first genetic knowledge.\" Exactly why some traits appear in some populations and not others remains unclear. \u201cOne can speculate that as beauty is in the eye of the beholder, the perceived physical attractiveness of these traits has encouraged reproduction,\u201d says Rodney Sinclair, a dermatologist at the University of Melbourne, Australia. Some of these traits may have had other physical benefits. \u201cIt may be that straighter scalp hair is an adaptation in cooler parts of the world, where rapid dissipation of heat from the scalp \u2014 which is more effective with curly or kinked hair types \u2014 was less needed,\" says Tobin. Some hair traits also correlate with disease. Premature balding has been linked to cardiac disease and prostate cancer; premature greying to Down's syndrome and the rare genetic disease progeria, which causes rapid ageing; and monobrow to a developmental disorder called Cornelia de Lange syndrome. Understanding these \u201cshared genetic mechanisms\u201d, says Sinclair, \u201ccould ultimately lead to strategies that simultaneously enhance beauty and alleviate disease.\u201d \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n             \n                   Mugshots built from DNA data 2014-Mar-20 \n                 \n                   Clues to the cause of male pattern baldness 2012-Mar-21 \n                 \n                   Genetic test predicts eye colour 2009-Mar-09 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20111", "url": "https://www.nature.com/articles/nature.2016.20111", "year": 2016, "authors": [{"name": "Brian Owens"}], "parsed_as_year": "2006_or_before", "body": "Staff at Canadian university given little guidance on how to mitigate future problems. The first  Patrick Feng  knew about a cyberattack on his university was when one of his colleagues told him that her computer had been infected by hackers and rendered unusable. Feng, who studies technology and sustainability policy at the University of Calgary in Canada, immediately checked the Dropbox folder that he was sharing with that colleague \u2014 and found that it, too, had been compromised. \u201cThe hackers had created encrypted copies of all my Dropbox files and deleted the originals,\u201d he says. \u201cAnd there was a ransom note demanding bitcoin to unlock them.\u201d  Bitcoin is an online, anonymous currency , making it an attractive option for cybercriminals. The attack, which started on 28 May, left many researchers locked out of their data and university e-mail. Most staff and faculty regained access to the school's networks by 30 May, and e-mail was back up by 6 June. Feng\u2019s Dropbox folder contained data and draft manuscripts for a research paper that he is writing on innovative ways of teaching research methods to undergraduates, but he wasn't too concerned. His personal laptop was unaffected, and he asked Dropbox to restore his folder to the last saved version before the attack, which the company was able to do in a couple of days. \n             Locked out \n           Others were not so fortunate. Two of Feng's colleagues, including the one who had informed him about the hack, had to have the hard drives of their university-issued computers wiped and restored. A few of the most badly affected faculty and staff have yet to regain full access to their data. But, there is no indication that any personal or school data were released to the public,  according to the university . \u201cResearch data that was stored on our systems was backed up prior to the attack and remains intact,\u201d says Marina Geronazzo, a university spokesperson. The university is confident that it will be able to restore all data from those back-ups, she says. But the school did pay a ransom of Can$20,000 (US$15,500) for the decryption keys as a precaution. They say it will be used only as a last resort. This kind of  \u201cransomware\u201d attack  is becoming increasingly common, says James Scott, a cybersecurity specialist at the Institute for Critical Infrastructure Technology, a think-tank in Washington DC \u2014 and universities are hardly immune. In the United States, the education sector is the third most common target for hackers, after healthcare and retail, he says. In many cases, the ransom money that hackers can extract from their victims is a secondary goal. \u201cRansomware is the new DDoS,\u201d Scott says, referring to a Distributed Denial of Service attack, in which a network of infected computers overwhelms a target with more connection requests than it can handle. Hackers use these attacks as a distraction while they steal data, he explains. \n             Multiple vulnerabilities \n           City of Calgary police are still searching for the perpetrator. Past incidents, Scott says, make him suspect that Chinese sources may have been involved. The country has allegedly targeted Canadian researchers before. In 2014, the Canadian government  accused \u201cChinese state-sponsored actors\u201d of hacking the National Research Council , a federal research agency headquartered in Ottawa. It\u2019s a matter of Chinese policy to use espionage to bring their country up to speed, technologically, with the West, says Scott, who is not a part of the investigation. \u201cUniversities are a huge target for China because of their advanced research.\u201d Scott says that universities are particularly vulnerable to cyberattacks because they often have multiple overlapping public and private networks, and staff, faculty members or students with infected devices might connect with any number of them. Many labs also have devices \u201cfrankensteined\u201d into their networks that were never intended to be there, which opens up new avenues of attack. Feng says that aside from requiring everyone to change their passwords, the university has provided little guidance on how researchers can better protect themselves against such attacks in the future. He says that it is up to researchers to be aware of the risks, and to take the proper precautions by automatically backing up their data on external hard drives, or to the cloud. \u201cEven though I teach technology policy, and am aware of these kinds of issues, I still thought it was never going to happen to me,\u201d he says. \n                   How to hack the hackers: The human side of cybercrime 2016-May-11 \n                 \n                   The best time to wage cyberwar 2014-Jan-13 \n                 \n                   Forget passwords: How playing games can make computers more secure 2012-Sep-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20282", "url": "https://www.nature.com/articles/nature.2016.20282", "year": 2016, "authors": [{"name": "Davide Castelvecchi"}], "parsed_as_year": "2006_or_before", "body": "Experiment suggests that humans are capable of perceiving even the feeblest flash of light. People can detect flashes of light as feeble as a single photon, an experiment has demonstrated \u2014 a finding that seems to conclude a 70-year quest to test the limits of human vision. The study, published in  Nature Communications  on 19 July 1 , \u201cfinally answers a long-standing question about whether humans can see single photons \u2014 they can!\u201d says Paul Kwiat, a quantum optics researcher at the University of Illinois at Urbana\u2013Champaign. The techniques used in the study also open up ways of testing how quantum properties \u2014 such as the ability of photons to be in two places at the same time \u2014 affect biology, he adds. \u201cThe most amazing thing is that it\u2019s not like seeing light. It\u2019s almost a feeling, at the threshold of imagination,\u201d says Alipasha Vaziri, a physicist at the Rockefeller University in New York City, who led the work and tried out the experience himself. Experiments on cells from frogs have shown that sensitive light-detecting cells in vertebrate eyes, called rod cells, do fire in response to single photons 2 . But, in part because the retina processes its information to reduce \u2018noise\u2019 from false alarms, researchers hadn\u2019t been able to confirm whether the firing of one rod cell would trigger a signal that would be transmitted all the way to the brain. Nor was it clear whether people would be able to consciously sense such a signal if it did reach the brain. Experiments to test the limits of human vision have also had to wait for the arrival of quantum-optics technologies that can reliably produce one photon of light at a time. In June 2015, physicist Rebecca Holmes, who works with Kwiat,  reported evidence that humans can sense light flashes containing as few as three photons . (Those results are still unpublished, Kwiat says.) But that team had not yet tested the ultimate threshold of perception \u2014 the response to single photons. \n             In the dark \n           In Vaziri\u2019s experiment, three volunteers sat in total darkness for around 40 minutes, and then stared into an optical system. When they pushed a button they heard two sounds, separated by one second. Sometimes, one of the sounds was accompanied by the emission of a photon. The participants had to say on which occasion they thought they saw a photon, and how confident they were (on a scale of 1 to 3) about their sighting. In many cases, they got it wrong; this is to be expected, given that more than 90% of photons that enter the front of the eye never even reach a rod cell, because they are absorbed or reflected by other parts of the eye. Still, participants were able to answer correctly more frequently than would be expected if they had guessed at random \u2014 and their confidence level was higher when they were right. The three volunteers sat through a total of more than 2,400 trials in which a single photon was emitted (and many more in which it was not). That high volume of testing, the researchers say, gives them strong statistical evidence of single-photon detection. But not all researchers think the paper is conclusive. \u201cThe only thing that I am sceptical about is that only three individuals have been tested,\u201d says Leonid Krivitskiy, a physicist at the Agency for Science Technology and Research in Singapore. All of them were male, he adds, and the visual physiologies of women and men are known to be subtly different, he points out. But Krivitskiy is convinced that the authors\u2019 method is capable of settling the question once and for all, if the experiment is tested on more volunteers. Vaziri plans to test how the visual system responds to photons in various quantum states \u2014 in particular those that are  in a \u2018superposition\u2019 of two simultaneous states . Some physicists have suggested that such experiments could test whether a superposition of two states could survive in a person's sensory system, and perhaps be perceived in the brain. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Quantum technology probes ultimate limits of vision 2015-Jun-11 \n                 \n                   Photons double up to make the invisible visible 2014-Dec-01 \n                 \n                   Quantum effects brought to light 2011-Apr-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20118", "url": "https://www.nature.com/articles/nature.2016.20118", "year": 2016, "authors": [{"name": "Jane Qiu"}], "parsed_as_year": "2006_or_before", "body": "Crustaceans at depths of 10,000 metres contain higher concentrations of chemicals than do some animals in coastal waters. Shanghai Toxic chemicals are accumulating in marine creatures in Earth\u2019s deepest oceanic trenches, the first measurements of organic pollutants in these regions have revealed. \u201cWe often think deep-sea trenches are remote and pristine, untouched by humans,\u201d says Alan Jamieson, a deep-ocean researcher at the University of Aberdeen, UK. But Jamieson and his colleagues have found man-made organic pollutants at high levels in shrimp-like crustaceans called amphipods that they collected from two deep-ocean trenches, he told a conference on deep-ocean exploration in Shanghai on 8 June. \u201cIt\u2019s really surprising to find pollutants so deep in the ocean at such high concentrations,\u201d says Jeffrey Drazen, a marine ecologist at the University of Hawaii in Honolulu. Before this work \u2014 which has not yet been published \u2014 the study of pollutants in deep-sea organisms had been limited to those that live at depths of 2,000 metres or less 1 , 2 . The latest research tested for levels of organic chemicals in amphipods collected at 7,000\u201310,000 metres depth, from the Mariana Trench in the western Pacific Ocean \u2014 the world\u2019s deepest trench \u2014 and from the Kermadec Trench near New Zealand. The creatures were captured during two international expeditions in 2014, when researchers lowered uncrewed landers into the trenches as part of a research programme to study deep-ocean ecosystems, sponsored by the US National Science Foundation. \n             Polluted depths \n           In both trenches, the amphipods contained polychlorinated biphenyls (PCBs) \u2014 used to make plastics and as anti-fouling agents to stop barnacles growing on ships' hulls \u2014 and polybrominated diphenyl ethers (PBDEs), which are used as flame retardants. Both chemicals are man-made and belong to a category of carbon-based compounds called persistent organic pollutants (POPs) because they are hard to break down. Production of PCBs \u2014 which are carcinogens \u2014 has been banned in many countries since the late 1970s; PBDEs, which animal studies suggest may disrupt hormone systems and interfere with neural development, are only now being phased out. The concentrations of PCBs in the amphipods from the Mariana Trench were particularly high, and 15 times greater than those found in the Kermadec. \u201cIt\u2019s even higher than in the estuaries of two of the most polluted rivers \u2014 the Pearl River and the Liao River \u2014 in China,\u201d says Jamieson. By contrast, the Kermadec Trench contains PBDEs at concentrations five times greater than the Mariana \u2014 and at a level that is higher than in the coastal waters of New Zealand\u2019s North Island, the study finds. Douglas Bartlett, a deep-sea microbiologist at the Scripps Institution of Oceanography in San Diego, California, says that the discovery is fascinating. \u201cIt hits home very dramatically that the trenches are not that remote after all, and the world is all connected,\u201d he says. \n             That sinking feeling \n           \u201cThe take-home message is that when you dump rubbish into the sea, it will ultimately sink. When [pollutants] fall into the trenches, they have nowhere else to go. So they\u2019re just going to keep building up,\u201d says Jamieson. Eventually, the trenches will have higher levels of pollutants than in estuaries, where chemicals are constantly flushed out to open waters, he says. The researchers suspect that the proximity of the Mariana Trench to large plastic manufacturers in Asia, as well as to a long-term US military base on the island of Guam, may have contributed to its high PCB levels. The waters above the trench are also part of the North Pacific gyre, a system of strong swirling ocean currents that might be sucking materials on the surface down into the deep sea. Both the Mariana and Kermadec trenches are around 11 kilometres deep. \u201cIt sounds quite deep, but it\u2019s not in terms of pollutant transport,\u201d says Jamieson. The high POP levels are a cause for concern, researchers say. The deep-ocean canyons are \u201cuntapped natural resources\u201d \u2014 a potential supply of organisms that could be valuable for a range of commercial applications, including drug discovery, but which might be affected by the pollutants, says Drazen. Scientists think that deep-ocean trenches could also be an important carbon sink, playing a key part in regulating climate, Bartlett says. In part, that is because in the trenches, carbon is pushed deep into Earth's interior when one tectonic plate is thrust underneath another. The trenches are also teeming with microbes that may convert carbon-containing chemicals into forms that aren\u2019t easily converted into carbon dioxide. \u201cIf somehow microbial activities are adversely affected because of all this pollution, I\u2019d wonder what that\u2019s doing to the carbon cycle in general,\u201d says Bartlett. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   James Cameron explains science of Deepsea Challenge 3D 2014-Aug-12 \n                 \n                   Submersible loss hits research 2014-May-20 \n                 \n                   Whale earwax a time capsule for stress and toxins 2013-Sep-16 \n                 \n                   Organic pollutants poison the roof of the world 2013-Apr-11 \n                 \n                   Deep-sea research: Dive master 2012-Sep-12 \n                 \n                   Oceanography: Death and rebirth in the deep 2010-May-19 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20269", "url": "https://www.nature.com/articles/nature.2016.20269", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "Chlorine atoms arranged into grids bring researchers closer to data-storage devices that could hold the US Library of Congress. Engineers can only stuff so much computing power into devices like smartphones and tablets before they run up against physical barriers. Although  Moore's law  famously predicts that the number of transistors people can squeeze onto memory chips will double every couple of years,  technology cannot be miniaturized indefinitely . Researchers are trying to get around this by starting small \u2014 using individual atoms \u2014 to make big gains in data-storage capacity. Now, a team has developed a 1-kilobyte rewritable data-storage device using chlorine atoms arranged on a small metal surface. If the team expanded that surface to one square centimetre, it could hold about 10 terabytes of information, the researchers report on 18 July in  Nature Nanotechnology 1 . \u201cIt\u2019s by far the largest assembly on an atomic scale that\u2019s ever been created, and it outperforms state-of-the-art hard disk drives by orders of magnitude in data capacity,\u201d says lead study author Sander Otte, a physicist at Delft University of Technology in the Netherlands. \n             Puzzle pieces \n           The technique depends on the ability to reliably and quickly rearrange individual atoms. Scientists demonstrated how to do this  in 1990 when they carefully gathered xenon atoms scattered across a surface to spell out 'IBM' . Now, Otte and his team have taken the concept further. They arranged chlorine atoms into square grids on a copper surface, and then placed those grids side-by-side like uninterrupted terraces. Each grid contains a few empty slots, or holes. This allows the research team to move atoms around, much like sliding pieces around in a tile puzzle. Each line on a grid encodes one unit of digital information called a byte. Otte\u2019s team uses a scanning tunnelling microscope with a sharp needle, like the tiniest of tweezers, to probe the atoms and make them hop into adjacent spaces. One chlorine atom and one vacancy make one bit (there are 8 bits in one byte). Moving chlorine atoms in and out of vacant spots means researchers can switch between ones and zeroes, the basis for computer code. The researchers were also able to place atomic markers at the upper left corner of each grid, which reduced the amount of time necessary to read the information encoded into each arrangement. The device reading the grids can simply read the marker that indicates the end of a line of code, for instance, rather than slog through the entire pattern bit by bit. The automated process only takes a few hours to read or write, whereas earlier ones would take days. \n             Not for prime time \n           One of the big drawbacks of this device is that it must be kept at \u2013196 \u00b0C: the boiling point of liquid nitrogen. This is a far cry from room temperature, but it\u2019s warmer and less expensive than using liquid helium as a coolant, as did previous attempts to develop atomic memory 2 . \u201cIt\u2019s very nice proof-of-principle work, demonstrating the first step of applying this technique of atomic manipulation to something that could lead to a functional memory device,\u201d says Stefan F\u00f6lsch, a materials physicist at the Paul Drude Institute for Solid State Electronics in Berlin. If researchers could scale the technology up to larger structures and arrange their grids in three dimensions, then one could pack  hundreds of terabytes  \u2014 equivalent to all the information contained in the US Library of Congress \u2014 into a cube the size of a grain of salt. Further improvements could prove useful to data storage in the cloud, reducing the need for new data centres.But data storage is just one application. \u201cOtte\u2019s research gets people interested in thinking about what we want to do on an atomic scale,\u201d says Chris Lutz, a staff scientist at IBM Research at Almaden Research Center in San Jose, California. In the long term, Otte and his colleagues\u2019 research could pave the way to designing new materials, atom by atom. See also  News & Views in  Nature Nanotechnology  by S. C. Erwin \n                   The chips are down for Moore\u2019s law 2016-Feb-09 \n                 \n                   There's more to come from Moore 2015-Apr-17 \n                 \n                   How low can you go? 2009-Jan-24 \n                 \n                   Molecular Braille expands computer memories 2000-Nov-15 \n                 \n                   http://www.pdi-berlin.de/en/staff/personal-page/?tx_pdifrontend_pdifrontend%5Bstaffmember%5D=14&tx_pdifrontend_pdifrontend%5Baction%5D=show&tx_pdifrontend_pdifrontend%5Bcontroller%5D=Staff&cHash=c104605f0d46f8a99b1e25553d7f8635 \n                 \n                   https://www.research.ibm.com/labs/almaden/ \n                 \n                   http://ottelab.tudelft.nl/ \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20283", "url": "https://www.nature.com/articles/nature.2016.20283", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Political turmoil spreads to education sector. More than a thousand Turkish university staff have been ordered to resign their faculty leadership positions \u2014 and others expect to be sacked \u2014 in the aftermath of the country\u2019s failed coup on 15 July.\u00a0 As president Recep Tayyip Erdo\u011fan continues to clamp down on political opposition, the Turkish Council of Higher Education (Y\u00d6K)\u00a0has called for all 1,577 of the country\u2019s university deans \u2014 the staff that head up each institution\u2019s various academic faculties \u2014 to leave their posts. Many of the deans may ultimately be re-appointed, but researchers say the move is designed to ensure that Erdo\u011fan maintains tight political control over the education sector, following earlier purges of the country\u2019s military, judiciary and police. And in what amounts to a temporary international travel ban for Turkish scholars, all vacations at universities have also been cancelled, and academics who are abroad for work and holidays have been told to return. \n             Emergency meeting \n           At an emergency meeting of 165 university rectors on 18 July in Ankara, Y\u00d6K had told university rectors to identify academics and administrators with connections to the G\u00fclen movement \u2014 a religious and social organization that Erdo\u011fan considers to be behind the coup \u2014 and to take steps to expel them. Istanbul University immediately suspended 95 academics in various faculties. The council did not invite a further 28 rectors to that meeting, saying that their universities are suspected of being pro-G\u00fclenist. Some of these institutions will be taken over by the state, Y\u00d6K said.\u00a0 In Turkey\u2019s schools, some 15,000 schoolteachers have been suspended and are under investigation, and 20,000 others have lost their licences to teach. University associations outside Turkey were quick to criticize the measures. On 19 July, the European University Association (EUA) in Brussels issued a  statement  condemning the news of the university deans' forced resignations. \u201cEUA calls on all European governments, universities and scholars to speak out against these developments and to support democracy in Turkey, including institutional autonomy and academic freedom for scholars and students,\u201d said its president, Rolf Tarrach. \u201cWe are all stunned by the deep and seemingly ruthless attacks on academic freedom by the Turkish government,\u201d said Horst Hippler, president of the German Rectors' Conference, an association of Germany's state-recognized universities. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Power of the pen 2016-Mar-23 \n                 \n                   Turkish academics jailed for \u2018making terrorism propaganda\u2019 2016-Mar-16 \n                 \n                   Turkish scientists rocked by accusations of supporting terrorism 2016-Jan-18 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20894", "url": "https://www.nature.com/articles/nature.2016.20894", "year": 2016, "authors": [{"name": "Ramin Skibba"}], "parsed_as_year": "2006_or_before", "body": "If the 2-degree warming threshold of the Paris agreement is exceeded, Mediterranean ecosystems will change beyond anything seen over the past 10,000 years. Seville and Lisbon have thrived for more than a thousand years in a temperate climate. But if global warming continues at the current pace, these cities will be in the middle of a desert by the end of the century, climate modellers report on 27 October in  Science 1 . Maintaining the region\u2019s historic ecosystem ranges would require limiting warming to just 1.5 \u00baC, by making substantial cuts to the world\u2019s greenhouse-gas emissions, the analysis concludes. Otherwise, the vegetation and ecosystems of the Mediterranean basin will shift as temperatures rise.  Increasing desertification  in southern Europe is just one of the changes that would result. \u201cEverything is moving in parallel. Shrubby vegetation will move into the deciduous forests, while the forests move to higher elevation in the mountains,\u201d says Joel Guiot, a palaeoclimatologist at the European Centre for Geoscience Research and Education in Aix-en-Provence, France, and lead author of the study. Guiot\u2019s analysis combines a climate model with a vegetation model that predicts how plants on land will respond to changes in temperature, rainfall and the concentration of greenhouse gases in the atmosphere. He and his co-author, Wolfgang Cramer, scientific director of the Mediterranean Institute for Biodiversity and Ecology in Aix-en-Provence, looked at a range of outcomes based on different scenarios for the world\u2019s future emissions. They include limiting warming to 2 \u00baC and 1.5 \u00baC above pre-industrial levels \u2014 the range  set by the Paris climate pact  ratified earlier this month. \n             Policy guide \n           \u201cI like that they\u2019re doing this comparison across different warming scenarios in line with the Paris agreement, to start to gauge the sensitivity to them,\u201d says Benjamin Cook, a climate scientist at the NASA Goddard Institute for Space Studies in New York City.The study confirms the vulnerability of many ecosystems, and could guide policymakers\u2019 efforts to help natural systems adapt to climate change, says Patrick Gonzalez, principal climate-change scientist at the US National Park Service based at the University of California, Berkeley 2 . \u201cThis study shows how essential it is for nations to meet their Paris commitments.\u201dThe situation in southern Europe is  similar to the US southwest , Gonzalez points out: temperature increases drive droughts 3 . More carbon dioxide in the atmosphere means rising temperatures, less precipitation and then more drying that leads to desertification.The model used in the new study also reconstructs the history of an ecosystem\u2019s vegetation. \u201cEssentially, vegetation hasn\u2019t changed much over the past 10,000 years,\u201d says Filippo Giorgi, head of the Earth System Physics Section of the International Centre for Theoretical Physics in Trieste, Italy. \u201cIt\u2019s interesting that they put potential future changes in that context.\u201dBoth the climate and vegetation models have significant uncertainties, however, and the models can account only for natural vegetation, rather than managed vegetation such as forests and crops. The study ignores the fact that humans continually affect ecosystems through land-use change, urbanization and soil degradation.\u201cIf we had the possibility of including these human impacts, it would be even worse than what we simulated,\u201d Guiot says. \n                   Paris climate deal: what comes next 2016-Apr-22 \n                 \n                   Future US megadroughts set to be the worst in 1,000 years 2015-Feb-12 \n                 \n                   Climate zones will shift faster as world warms 2013-Apr-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19112", "url": "https://www.nature.com/articles/nature.2016.19112", "year": 2016, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "Elements 113, 115, 117 and 118 to be named by scientists from Russia, the United States and Japan. TREND WATCH:  Four new elements have been officially added to the periodic table, completing its seventh row. Elements 113, 115, 117 and 118 have been pencilled in on the table for years, and laboratories in Russia, the United States and Japan have made multiple claims to have discovered them. But official recognition had to wait until the end of 2015, when a group of independent experts agreed that the evidence was valid (see chart). The International Union of Pure and Applied Chemistry (IUPAC), headquartered in Research Triangle Park, North Carolina,  announced the group\u2019s conclusions  on 30 December. All of the elements were created in the lab, by smashing lighter atomic nuclei together. The unstable agglomerations of protons and neutrons last mere fractions of a second before they fall apart into smaller, more stable fragments. The teams that have been given credit for the discoveries can now put forward proposals for the elements\u2019 names and two-letter symbols. Elements can be named after one of their chemical or physical properties, a mythological concept, a mineral, a place or country, or a scientist. Priority for discovering element 113 went to researchers in Japan, who are particularly delighted because it will become the first artificial element to be named in East Asia. When the element was first sighted 12 years ago, 'Japonium' was suggested as a name. The team at the RIKEN Nishina Center for Accelerator-based Science in Wako, near Tokyo, made its first claim to have spotted element 113 in 2004, and followed it up with a  more convincing sighting in 2012 . By then, it had created three atoms of the element. \u201cTo scientists, this is of greater value than an Olympic gold medal,\u201d said Ryoji Noyori, who received the 2001 Nobel Prize in Chemistry, at a press conference about the IUPAC decision. (Noyori was not a member of the Japanese team, but is a former president of RIKEN). Russian and US researchers made a rival claim to have discovered 113, but were not given priority by the expert group, drawn from IUPAC and the International Union of Pure and Applied Physics (IUPAP). However, Russia and the United States did get the credit and naming rights for the other new elements. Elements 115 and  117  were first created by a collaboration between the Joint Institute for Nuclear Research in Dubna, Russia, the Lawrence Livermore National Laboratory in Livermore, California, and the Oak Ridge National Laboratory in Tennessee, the IUPAC/IUPAP committee said. Work from other teams, such as a  Swedish group using a German accelerator , helped to confirm element 115's existence.  The credit for  discovering element 118  \u2014 the heaviest ever created \u2014 has been assigned to the Dubna and Lawrence Livermore teams. The element has a chequered history: a 1999 claim to have made it was retracted two years later amid accusations that data had been falsified. Physicists will now try to create elements 119 and 120, a feat that should be possible with current technology, says Rolf-Dietmar Herzberg, a nuclear physicist at the University of Liverpool, UK. No one has yet claimed a sighting, however: researchers at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany, tried for five months in 2012 without success. Beyond element 120, researchers agree, the chances of getting two nuclei to fuse are vanishingly small. \n               Tweet \n               Follow @NatureNews \n               Follow @RichVN \n             \n               weibo \n             \n                   Exotic atom struggles to find its place in the periodic table 2015-Apr-08 \n                 \n                   Bohr's model: Extreme atoms 2013-Jun-05 \n                 \n                   Element 113 at last? 2012-Sep-27 \n                 \n                   Heaviest element made - again 2006-Oct-17 \n                 \n                   Blogpost: New element \u2018ununseptium\u2019 plugs hole in periodic table \n                 Reprints and Permissions"},
{"file_id": "529010a", "url": "https://www.nature.com/articles/529010a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Epidemic in dogs complicates push to wipe out parasite. A decades-long push to make Guinea-worm disease the first parasitic infection to be wiped out is close to victory. But a mysterious epidemic of the parasite in dogs threatens to foil the eradication effort. \u201cIf we\u2019re going to be aggressive and achieve this, we have to eliminate the infection in dogs,\u201d says David Molyneux, a parasitologist at Liverpool School of Tropical Medicine, UK. The Carter Center in Atlanta, Georgia, is leading the global campaign to eradicate Guinea worm. Next week, it will announce that case numbers for the excruciatingly painful infection are at a record low, with approximately 25\u00a0cases reported in 2015 in just 4\u00a0countries: Chad, Ethiopia, Mali and South Sudan. But infections in dogs are soaring in Chad, where officials will meet at the end of January to grapple with the canine epidemic. The central African nation recorded more than 450\u00a0cases of Guinea worm in domestic dogs last year \u2014 an all-time high (see \u2018Canine comeback\u2019). Researchers and officials strongly suspect that dogs are spreading the infection to humans; now the race is on to understand how this might happen, as well as how dogs acquire the infection in the first place. The World Health Organization is unlikely to declare Guinea worm eradicated until the parasite has stopped spreading in dogs, says Molyneux, who is part of the commission that will make that decision. In 1986, when the Carter Centre joined the Guinea-worm eradication campaign, there were an estimated 3.5 million infections annually, mostly due to poor sanitation and lack of access to clean water. When people drink unfiltered water, they can swallow microscopic freshwater crustaceans called copepods, which Guinea-worm larvae infect. The copepods die, releasing the larvae, which mature and mate in the human intestine. Male worms die after mating, but adult females \u2014 approximately 80\u00a0centi\u00admetres in length\u00a0\u2014\u00a0survive and slowly migrate out of the gut. About a year after infection, they burrow through their host\u2019s skin, usually around the legs and feet, sometimes taking weeks to fully escape. To cope with the searing pain, many people bathe in rivers and lakes, contaminating the water with the next generation of larvae. Although rarely fatal, Guinea worm can debilitate people for months and keep children out of school. There is no vaccine against the parasite and no effective treatment, so eradication efforts have focused on providing clean water and changing people\u2019s behaviour, says Donald Hopkins, a special adviser at the Carter Center who is leading its Guinea-worm eradication efforts. People in areas in which the parasite was once rife have learnt to filter their water using cloths and to avoid re-contaminating water supplies. Even the most out-of-the-way villages now quickly contain cases and report them to health officials. Chad was on the cusp of being declared free of Guinea worm in the late 2000s: no case had been recorded in the previous decade. But starting in April 2010, increased surveillance turned up a handful of human infections, and around 60 cases have been recorded since then. The cases are unusually sporadic and isolated from one another, says Mark Eberhard, a parasitologist who consults on Guinea-worm eradication for the Carter Center. More typically, cases occur in clusters and recur in the same village year after year. \u201cThere was no increase or explosion of cases as one would expect,\u201d he says. Shortly after these observations, officials began to hear rumours of Guinea-worm-infected dogs in Chad. Researchers have known for decades that dogs, leopards and other mammals occasionally acquire Guinea-worm-like infections, but they assumed that these cases stemmed from distinct species of  Dracunculus , the nematode worm that causes the disease, or were rare examples of infections that had somehow spilt over from an outbreak in humans. But in Chad, researchers now think that dogs are spreading the worms to humans\u00a0\u2014\u00a0not the other way around. Between January and October 2015, officials recorded 459 canine infections from 150 villages in the central African nation\u00a0\u2014\u00a0an unprecedented volume. And genome sequencing has confirmed that dogs in Chad are infected by the same nematode worms ( Dracunculus medinensis ) that plague humans ( M. L. Eberhard  et al. Am. J. Trop. Med. Hyg.    90,  61\u201370; 2014 ). To better understand the situation, a team led by James Cotton and Caroline Durrant, genome scientists at the Wellcome Trust Sanger Institute in Hinxton, UK, is now sequencing the genomes of more Guinea worms collected from dogs and humans in Chad to confirm that dogs are indeed transmitting the disease to people. And Eberhard, who is convinced that this is the case, is trying to determine how dogs become infected in the first place. They are unlikely to contract the worms from drinking water, he says, because dogs tend to scare away copepods when they lap. Most of Chad\u2019s cases have occurred among fishing communities along the Chari River, and Eberhard suspects that dogs are eating the entrails of gutted, copepod-eating fish. Dogs then pass the worms to humans by reintroducing the larvae into water. Researchers, including Eberhard, are testing aspects of this hypothesis in ferrets, a common animal model in disease research, but eradication officials in Chad are not waiting for the results before taking action. Since February 2015, they have offered the equivalent of US$20 to people who report Guinea-worm cases in dogs and tie up the animals to prevent them from contaminating water sources. They are also encouraging villagers to bury fish entrails to keep dogs from eating them. And a trial is ongoing to test whether a drug used to treat heartworm \u2014 a roundworm parasite common in dogs \u2014 has any effect on Guinea worm. Because of Guinea worm\u2019s one-year incubation time, it should be clear before the end of 2016 whether these interventions have worked. Older residents from villages along the Chari River say that their fishing practices have not changed, according to Hopkins, and they cannot recall dogs becoming infected with Guinea worm in the past. But Molyneux says that the dearth of humans transmitting the disease could explain the parasite\u2019s jump to dogs. \u201cIf you were Guinea worm and there were only 100 of you left in the world,\u201d he says, \u201cwhat would you do? You\u2019d get the hell out of the host that\u2019s being targeted and move to something else.\u201d \n                 Tweet \n                 Follow @NatureNews \n               \n                     Anti-parasite drugs sweep Nobel prize in medicine 2015 2015-Oct-05 \n                   \n                     Parasitic infections: Time to tackle cryptosporidiosis 2013-Nov-13 \n                   \n                     Road map unveiled to tackle neglected diseases 2012-Jan-30 \n                   \n                     Financial crisis hits developing world disease research 2011-Dec-07 \n                   \n                     Blog post: Jimmy Carter vs the dragon \n                   \n                     Carter Center Guinea Worm Eradication Program \n                   Reprints and Permissions"},
{"file_id": "529012a", "url": "https://www.nature.com/articles/529012a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "AWARE project will help unravel effects of global warming. On Antarctica\u2019s Ross Island, a short drive from the US McMurdo research station, high-tech radar antennas and other atmospheric instruments gaze skyward, gathering detailed measurements of West Antarctic clouds. Remarkably, these are the first such data to be gathered in five decades \u2014 even though weather patterns in the region can influence those half a world away. The US$5-million project, known as the Atmospheric Radiation Measurement West Antarctic Radiation Experiment (AWARE), began to observe the skies near McMurdo in November and will run until early 2017. A second measurement station, 1,600\u00a0kilometres away in the ice sheet\u2019s interior, will operate until the end of this month. (The site is so remote that it can be used only during the Antarctic summer.) A similar experiment in the Arctic in 1997\u201398 relied on an instrument-laden ship that was deliberately frozen into sea ice. It yielded fundamental insights into the physics of northern polar clouds 1 , and AWARE scientists hope that their project will do the same for the south. \u201cThis is going to be a sea change in our understanding,\u201d says Lynn Russell, an atmospheric scientist at the Scripps Institution of Oceanography in La Jolla, California, and a co-principal investigator on AWARE. Antarctica\u2019s massive ice sheet acts as a global heat sink. As a result, changes in Antarctic clouds, such as the amount of ground they cover or how much radiation they absorb, can have ripple effects as far away as the tropics. Climate modellers need to understand the  physics of these clouds  if they are to correctly work out how  weather around the globe will change  as the  polar regions warm . Scientists have not made detailed, in-place measurements of the skies above West Antarctica since 1967, when weather-balloon launches ceased a decade after they began during the 1957\u201358 International Geophysical Year, says Russell. AWARE, which is led by Scripps atmospheric scientist Dan Lubin, aims to get the best data yet on clouds and aerosol particles above West Antarctica. That includes mixed\u2011phase clouds, which occur in polar regions and combine supercooled water with ice. Studies have shown that clouds moving across Antarctica\u2019s interior are mostly ice, whereas those moving onshore from the coast contain more liquid water 2 . The composition of these clouds plays a major part in determining how much sunlight they reflect into space \u2014 which helps to shape atmospheric circulation and weather patterns below. Satellites such as NASA\u2019s CloudSat and CALIPSO (Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observations) can probe the internal structure of Antarctic clouds 3 , but in only a narrow ribbon as seen directly beneath the spacecraft\u2019s orbit. AWARE uses multiple radar instruments and a sophisticated lidar system to explore the clouds\u2019 many layers, examining properties such as phase and particle size at various altitudes. Early AWARE data show mixed-phase clouds over McMurdo, in the first detailed measurements of such cloud systems outside the Arctic. \u201cThe Antarctic is a very different environment than the Arctic, because it is colder year-round and also has a very pristine atmosphere,\u201d says Lubin. Team scientists reported early results on 16\u00a0December at the American Geophysical Union meeting in San Francisco, California. The team has also clocked pulses of humidity swinging in and out of the McMurdo area as a storm passed through, altering how the clouds transmit radiation. Getting the basic data should help scientists to better understand how Antarctic clouds will respond to a changing climate, Russell says. West Antarctica is warming by as much as 0.4\u2009\u00b0C per decade, and as its ice melts, sea levels will rise. The AWARE measurements from the West Antarctic interior are designed to capture the height of the summer melt season. One major question is how climate change may be intensifying westerly winds around Antarctica, and what those changes will do to southern polar clouds, says Andrew Vogelmann, an atmospheric scientist at Brookhaven National Laboratory in New York. With one AWARE location near the coast and another in the interior, project scientists aim to compare how atmospheric systems passing through West Antarctica affect both locations, and how those changes translate to wider global shifts. One final twist, Vogelmann adds, is the presence this year of the El Ni\u00f1o weather pattern, which could affect conditions at the poles. \u201cWe may be able to catch some of that,\u201d he says. \n                 Tweet \n                 Follow @NatureNews \n               \n                     'Stable' region of Antarctica is melting 2015-May-21 \n                   \n                     Polar research: Six priorities for Antarctic science 2014-Aug-06 \n                   \n                     Jet reveals atmosphere's secrets 2010-Aug-17 \n                   \n                     Atmospheric science: Cloudy, with a chance of science 2009-Sep-23 \n                   \n                     Atmospheric science: Inside information 2005-Sep-21 \n                   \n                     AWARE \n                   Reprints and Permissions"},
{"file_id": "nature.2015.19101", "url": "https://www.nature.com/articles/nature.2015.19101", "year": 2016, "authors": [{"name": "Monya Baker"}], "parsed_as_year": "2006_or_before", "body": "Reports of hundreds of biomedical experiments lack essential information. Two studies have unveiled widespread flaws in the reporting of animal experiments \u2014 the latest in a series of papers to criticize  shoddy biomedical research . Whereas reports of clinical trials in major medical journals routinely state how many patients die or drop out of analysis during the course of a study, animal studies generally fail to report this figure \u2014 or drop animals without saying why, according to a team led by Ulrich Dirnagl at the Charit\u00e9 Medical University in Berlin. That lapse could significantly bias results, the team reports in the journal  PLoS Biology 1 . In a second study in the same journal 2 , a team led by John Ioannidis, an epidemiologist at Stanford University in California who has repeatedly called for more reproducible and transparent research, criticizes the lack of data availability and detailed protocols in biomedical papers. \n             Missing mice \n           Dirnagl\u2019s team reviewed 100 reports published between 2000 and 2013 describing 522 experiments that used rodents to test cancer and stroke treatments, and compared the numbers of animals reported in the papers\u2019 methods and results sections. Some two-thirds of the experiments did not state whether they had dropped any animals from their final analysis. Of those that did report numbers, around 30% (53 experiments) reported that they had dropped rodents from their study analysis, but only 14 explained why. The researchers used computer simulations to show that the levels of attrition they saw might seriously affect the results of the studies. If biomedical scientists were biased in how they dropped animals \u2014 excluding outliers that gave extreme data values, for instance \u2014 then results would be fourfold more likely to find a statistically significant result that was in fact just due to chance, and could overstate the actual effectiveness of treatments by as much as 175%, the team says. Ioannidis\u2019s team, meanwhile, examined a random sample of PubMed articles published from 2000 to 2014. They found that none of the 268 biomedical papers made its full data available, and all but one lacked details needed for other researchers to replicate the work. In 2000, more than 90% of examined papers lacked conflict-of-interest statements, compared with about one-third in 2014. \n             Animal studies under fire \n           \u201cI have to say I am distressed but not surprised,\u201d says Malcolm Macleod, a stroke researcher and trial-design expert at the University of Edinburgh, UK. \u201cThese important findings are further evidence of the challenges we face in improving the quality of biomedical research.\u201d Both papers reinforce earlier studies that have criticized poorly designed and reported animal experiments. A study led by Macleod last year 3 , for example, looked at over 2,500 preclinical research papers and found that  many of the studies described were poorly designed ; the majority did not report using recommended methods to avoid bias. Many research journals have endorsed  voluntary reporting guidelines  for animal studies, but  adoption is spotty . The  PLoS Biology  papers come as a part of a special section on 'meta-research': research about how research is done. The number of meta-research studies is increasing, says Marcus Munaf\u00f2, a biological psychologist at the University of Bristol, UK, who writes about ways to improve scientific rigour. \u201cThese studies illustrate what the scope of the problem is,\u201d he says, adding that they should be welcomed as an opportunity to boost scientific quality. \n               Tweet \n               Follow @NatureNews \n             \n                   Poorly designed animal experiments in the spotlight 2015-Oct-13 \n                 \n                   Biomedical researchers lax in checking for imposter cell lines 2015-Oct-12 \n                 \n                   Sluggish data sharing hampers reproducibility effort 2015-Jun-03 \n                 \n                   UK funders demand strong statistics for animal studies 2015-Apr-15 \n                 \n                   Journals unite for reproducibility 2014-Nov-05 \n                 \n                   Studies in Irreproducible Results \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19124", "url": "https://www.nature.com/articles/nature.2016.19124", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Densely packed stars might allow civilizations to survive for many billions of years. Kissimmee, Florida Astronomers may be looking for alien life in all the wrong places. They should be hunting in the dense, old neighbourhoods of stars known as globular clusters, a study suggests. Until now, scientists have largely discounted the idea of finding extraterrestrial civilizations in globular clusters, which each contain thousands to millions of stars. Out of the  thousands of known extrasolar planets , only one has been found in such a cluster, and many astronomers think that the gravitational interactions among tightly packed stars would have long ago hurled any accompanying planets into deep space. But the proximity of all those stars may actually be an advantage for supporting life, says Rosanne Di Stefano, a theoretical astrophysicist at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts. Lots of closely packed stars could also mean lots of planetary systems within easy travelling distance. \u201cIf there is an advanced society in an environment like that, it could set up outposts relatively easily, because we\u2019re dealing with distances that are so much shorter,\u201d she says. With such networking, civilizations in a globular cluster might endure for billions of years, and thus be around for humans to communicate with today or in the future. Di Stefano reported the work \u2014 which she did with Alak Ray of the Tata Institute of Fundamental Research in Mumbai, India \u2014 on 6 January at an American Astronomical Society meeting in Kissimmee, Florida. \n             Fertile ground? \n           Globular clusters contain blobs of stars that hover together like swarms of fireflies. The Milky Way is home to about 150 globular clusters, which contain some of the oldest known stars \u2014 dating back 10 billion years or more. In 1974, scientists beamed one of the most famous search for extraterrestrial intelligence (SETI) messages to the globular cluster M13 using the Arecibo radio telescope in Puerto Rico. But in the decades since, globular clusters have fallen out of favour for SETI hunts. The only planet known to reside in a globular cluster orbits an ancient pulsar, an environment that is unfriendly for life 1 . And targeted searches have failed to turn up more exoplanets in these clusters 2 .\u00a0 But that does not mean that such planets do not exist, says Luca Pasquini, an astronomer at the European Southern Observatory in Garching, Germany. He and his colleagues found planets in an open cluster, in which stars are typically billions of years younger and less densely packed than those in globular clusters 3 . Astronomers had been sceptical of finding planets in open clusters until they looked, he notes; for globular clusters, he says, \u201cthere is room for very exciting discoveries\u201d if scientists continue to probe. \n             Stellar sweet spot \n           Di Stefano and Ray began their work after thinking about the advantages that a globular cluster could offer alien life. If a civilization is close to another star system, \u201cinterstellar travel becomes a whole different thing\u201d, Di Stefano says. Civilizations could theoretically hop from star to star if threatened by cosmic dangers or extinction. This ease of travel, combined with the ancient age of globular clusters, suggests that intelligent life could exist in these systems for longer than in many other places, Di Stefano says. \u201cThe civilization might eventually be destroyed,\u201d she adds, \u201cbut it would have a better opportunity at transferring members of itself and its knowledge.\u201d By analysing the distances between stars in various globular clusters, DiStefano and Ray identified a \u201csweet spot\u201d where conditions would be stable enough for a planet to form and survive for billions of years. The sweet spot varies from cluster to cluster, but corresponds to an interstellar distance of roughly 100 to 1,000 times the Earth-Sun distance. If stars are spaced at roughly this distance within a cluster, then civilizations on planets around those stars would not have all that far to travel \u2014 or to communicate \u2014 with the next star system. Finding these hypothetical planets is the next challenge. Di Stefano has a list of globular clusters that she would like planet hunters to target: at the top is one called Terzan 5 near the centre of the Milky Way. But science fiction is already way ahead of her. Isaac Asimov\u2019s classic short story 'Nightfall' features a civilization that lives in a globular cluster \u2014 although that particular race loses its collective mind when all six of its suns set at once. \n               Tweet \n               Follow @NatureNews \n             \n                   The exoplanet files 2015-Nov-18 \n                 \n                   Exoplanet bounty includes most Earth-like worlds yet 2015-Jan-06 \n                 \n                   So many lonely planets with no star to guide them 2011-May-18 \n                 Reprints and Permissions"},
{"file_id": "529013a", "url": "https://www.nature.com/articles/529013a", "year": 2016, "authors": [{"name": "Declan Butler"}], "parsed_as_year": "2006_or_before", "body": "Academic consortia urge faster changes in scholarly publishing. The Netherlands  is leading  what it hopes will be a pan-European effort in 2016 to push scholarly publishers  towards open-access (OA) business models : making more papers free for all users as soon as they are published. In 2014, publishers worldwide  made 17% of new papers OA immediately on publication , up from 12% in 2011 (see \u2018Growth of open access\u2019). But most papers are still locked behind paywalls when they are first published. The Dutch government, which took over the six-month rotating presidency of the European Union council of ministers this month, has declared furthering OA to be one of its top priorities. With  strong support from Carlos Moedas , the EU\u2019s research commissioner, it is planning a series of discussions on the issue \u2014 between European science ministers at the end of January (with a keynote talk from Bill Gates, whose philanthropic foundation  strongly supports OA ) and at an EU presidency  conference on open science  in April. At that forum, the European Commission is expected to launch an \u2018Open Science Policy Platform\u2019 with a remit that includes investigating how subscription publishers can best transition to OA. The Association of Universities in the Netherlands (VSNU), a consortium of 14 institutes, has already taken radical steps. With backing from the Dutch government, it has negotiated several deals with major publishers over the past two years to make more Dutch papers open in subscription journals, with the aim of shifting the journals to an OA business model. The deals are a \u201cgreat step forward to an OA world\u201d, says Paul Ayris, head of library services at University College London and a spokesperson for the League of European Research Universities, which has urged the commission and the Dutch presidency to speed the OA transition. \n               Open-access deals \n             In 2014, the  VSNU announced a deal  in which it renewed its subscription to a bundle of 2,000 paywalled journals from the publisher Springer, but with terms that made papers by corresponding authors at subscribing Dutch universities OA, for no extra charge. (Springer has since merged with  Nature \u2019s publisher.) Shortly before Christmas 2015, the VSNU  announced a similar agreement with Elsevier , which the consortium had threatened to boycott if its demands were not met: by 2018, 30% of Dutch papers will be OA in VSNU-subscribed Elsevier journals. The hope, Ayris says, is that if other nations\u2019 organizations can make similar deals, publishers will be compelled to release more open papers in return for their flow of subscription income, effectively flipping their journals to become fully OA. OA journals receive no subscription income and instead make money either by direct subsidy or by charging authors (or their research funders) a fee to publish each OA paper. The United Kingdom has gone down the same track. In October 2015, Jisc, a non-profit body that represents UK higher-education institutions,  negotiated a deal  that made OA papers with UK-based corresponding authors free in 1,600 selected Springer subscription journals. A spokesperson for Springer says that the agreements are pilots, but that \u201cdeals which combine subscriptions with OA publishing could accelerate the transition to OA on a large scale\u201d. \n               Hybrid crackdown \n             A major driving force for the Dutch and British deals was to combat the expensive and controversial \u2018hybrid\u2019 business models that have been adopted by many subscription journals worldwide. Hybrid journals collect subscriptions but allow authors to make individual papers open for a fee. They  charge higher fees , on average, than do fully OA journals, yet scientists who want OA papers often choose to publish with them because they are generally more established or prestigious than many recently launched OA journals. Robert Kiley, who is head of digital services at the library of the Wellcome Trust, the London-based biomedical funder, notes that many UK organizations have each paid millions of pounds to hybrid journals for open papers \u2014 while also paying them subscriptions. A deal akin to the VSNU\u2019s one with Springer would help to bypass this hybrid market. But these kinds of deals have their critics. The costs of the agreements are confidential, points out Mark McCabe, an economist at the University of Michigan in Ann Arbor; he surmises that they did not come cheap. He and others say that such secretive deals risk locking academic institutions into continuing to pay expensive fees to major subscription publishers, and they shield the latter from competition. McCabe proposes a more radical strategy: libraries or university consortia should stop paying journal subscriptions and should transfer the money saved to their researchers, who can use it to publish OA in journals of their choice. That way, authors might become more sensitive to the price of publishing \u2014 which might lead to greater competition between journals, promoting leaner-run OA journals that charge lower fees. Some funders are trying other ideas to support OA but steer researchers away from the hybrid market. The Norwegian Research Council and the German Research Foundation both pay OA fees for researchers but prohibit them from being spent on articles in hybrid journals. And the Austrian Science Fund has capped OA payments at a certain level; if researchers want to publish in more expensive journals (often the hybrids), they must find the extra cash themselves. But measures to change industry business models will succeed only with international buy-in. And some other nations, such as the United States, have not followed the Netherlands in urging the publishing industry to make more papers immediately OA. They have favoured other routes to free-to-read papers, such as encouraging academics to archive their pre-publication manuscripts online, and mandating subscription publishers to make papers free after a delay (typically six months or a year after publication). A successful push for immediate OA, Kiley says, would ultimately need to be global \u2014 not limited to Europe. \n                 Tweet \n                 Follow @NatureNews \n               \n                     All that glitters 2015-Apr-07 \n                   \n                     Chinese agencies announce open-access policies 2014-May-19 \n                   \n                     UK funder explains clamp-down on open access 2014-Apr-09 \n                   \n                     Particle-physics papers set free 2014-Jan-07 \n                   \n                     Open access: The true cost of science publishing 2013-Mar-27 \n                   \n                     Europe joins UK open-access bid 2012-Jul-17 \n                   \n                     Nature  special: The future of publishing \n                   \n                     Association of Universities in the Netherlands \n                   \n                     JISC \n                   \n                     League of European Research Universities \n                   \n                     European Commission \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20308", "url": "https://www.nature.com/articles/nature.2016.20308", "year": 2016, "authors": [{"name": "Petra Szilagyi"}], "parsed_as_year": "2006_or_before", "body": "Common contaminant may change shoaling behaviour, a proxy for stress and anxiety in behavioural studies. A common parasite that infects laboratory zebrafish may have been confounding the results of years of behavioural experiments, researchers say \u2013 but critics say the case isn\u2019t proven. Like the rat, the zebrafish ( Danio rerio ) is used in labs worldwide to study everything from the effects of drugs, to  genetic diseases  and disorders such as schizophrenia and autism. Since both zebrafish and people are highly social, researchers think that zebrafish may be a better lab model for some human behaviours than rodents. Zebrafish demonstrate their preference for each other by clustering into shoals \u2013 a social behaviour that researchers measure when they want to test how drugs affect zebrafish stress and anxiety levels, as a  proxy for potential human responses . But this behaviour can change when fish are infected with a neural parasite called  Pseudoloma neurophilia , scientists from Oregon State University in Corvallis report in a paper published on 11 July in the  Journal of Fish Diseases 1 . The team say that individual fish infected with  P. neurophilia  swim closer to each other than do non-infected fish, a behaviour that is also associated with increased stress and anxiety. The finding casts doubt on results from previous experiments, says lead study author Sean Spagnoli, a veterinary surgeon \u2013 since the infection may have scrambled researchers\u2019 interpretations of shoaling behaviour. \n             Ghost in the machine \n           Spagnoli first heard that a parasite was infecting many laboratory zebrafish when he was working at the Zebrafish International Resource Center (ZIRC) in Eugene, Oregon \u2013 a central repository which sends out zebrafish strains to researchers and also tests zebrafish health.  P. neurophilia  settles in the brain, spinal cord and nerves of zebrafish. \u201cThe paper is great, as it raises some doubts about the way behaviour may be used to study brain function in zebrafish,\u201d says Robert Gerlai, a behavioural geneticist from the University of Toronto Mississauga in Canada. But he advises not jumping to conclusions on the basis of one study. Gerlai has concerns about the work; in particular, he says, Spagnoli\u2019s team relied on a low-tech method to measure their fish shoals, taking screen snapshots and measuring the distance between each fish rather than more precise continuous tracking. And the researchers didn\u2019t check what else might have been affecting the zebrafish, he adds. Elena Dreosti, a geneticist at University College London, says that the paper\u2019s data are weak and the effects it shows are small. \u201cConsiderable additional work is needed to know if this is likely to have a significant impact on the type of behaviour research that is done by the community working with zebrafish,\u201d she says. But Spagnoli says that his low-tech method is all that's needed to raise the red flag that infection can influence behaviours such as shoaling. He agrees that he hasn\u2019t proven that the  P. neurophilia  is directly responsible for the changed behaviour \u2013 but says that his study suggests that shoaling changes when the parasite is present. \n             Contamination problem \n           As many as half of all laboratory facilities may be using some infected zebrafish, according to ZIRC data from 2015 \u2013 although only 28 facilities submitted their zebrafish to the centre for health checks that year. Within a facility, infection rates hover around 7-10%; some tanks may have no infected zebrafish, but others have many, Spagnoli says. Nuno Pereira, a zebrafish veterinarian at the Gulbenkian Science Institute in Oeiras, Portugal, says that most researchers are already aware of the importance of testing for the parasite \u2013 and Spagnoli agrees that labs have drastically improved their screening protocols. But Spagnoli thinks that many labs may still have a significant number of fish that are infected. \u201cI haven't seen a single paper that stated that \u2018fish used were certified pathogen-free for  P. neurophilia ',\" he says. The team will continue to study the parasite\u2019s effects, he says, and is also looking at the potential influence of another common contaminant,  Mycobacterium chelonae , on shoaling behaviour. \n                   Fish have feelings too 2014-Feb-25 \n                 \n                   Zebrafish genome helps in hunt for treatments 2013-Apr-17 \n                 \n                   Mapping brain networks: Fish-bowl neuroscience 2013-Jan-23 \n                 \n                   Solitary fish hit rock bottom 2010-Nov-22 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20343", "url": "https://www.nature.com/articles/nature.2016.20343", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Report tries to curb bad behaviours incentivized by academic audit system. The United Kingdom\u2019s mammoth periodic audit of its research is set for a shake-up that could change the way universities hire academics \u2013 and might also encourage scientists to spend more time on public engagement. Every five to seven years, the UK runs an evaluation of the quality of research produced by its universities, and uses it to allocate around \u00a32 billion (US$2.7 billion) in annual research funding. The exercise, called the  Research Excellence Framework (REF) , has had a huge influence on the behaviour of British researchers and university managers \u2013 not least by encouraging a frenetic academic transfer market, in which universities try to improve their quality rating just before the next REF by rushing to sign up star scholars, sometimes on temporary contracts. A  government-commissioned report  on the REF\u2019s future \u2013 led by the economist Nicholas Stern, the chair of the Grantham Research Institute on Climate Change and the Environment \u2013 has broadly backed the system in its current form. But it calls for changes designed to cut costs and prevent 'gaming\u2019 of the system. One of those would prevent universities from claiming credit for research papers written by staff before they joined. If implemented, that change could cause problems for early-career researchers. They are often forced to move between short-term contracts and will be \u201cworrying about their marketability if they can\u2019t take their hard-won papers with them to incentivize universities to take them on\u201d, says Richard Jones, pro-vice chancellor for innovation at the University of Sheffield, UK. On the other hand, he says, \u201cI think it\u2019s really important that universities nurture their own talents rather than rely on a chequebook to hire some people in at the last minute.\u201d Oliver Robinson, a neuroscientist at University College London,  tweeted  that the move would be a \u201chuge blow\u201d to early-career researchers, adding that it would probably exacerbate an expected post-Brexit brain drain. But others suggested the move could be positive: encouraging institutions to look for academic potential when making new hires, rather than making decisions based on past records. Stern\u2019s other major suggestion is that universities must submit all of their staff to the audit process \u2013 not just a selection of staff, as the REF currently allows. That might save costs, as universities currently spend a lot of time working out which staff will win them the highest ratings. (The costs are significant: the  latest iteration of the REF, in 2014 , cost \u00a3246 million to run, compared to \u00a366 million for a simpler version of the process in 2008.) And it might also be more inclusive, avoiding the demotivation of academics who aren\u2019t picked for the REF. Another recommendation is that the audit should encourage universities to boast of their research\u2019s  wider impacts  on public engagement, teaching or cultural life. That could solve what\u2019s known as the \u201cBrian Cox problem\", says Stephen Curry, a structural biologist at Imperial College London. Cox, a physicist at the University of Manchester, UK, has become a television star, but his public engagement work wasn\u2019t adequately recognized in the last audit. \u201cI\u2019m hoping that change creates new incentives to support public engagement work in universities,\u201d Curry says. The report also calls for future REFs to  do more to recognise interdisciplinary work , by including university-wide assessments that look at interdisciplinary and cross-institutional initiatives. Overall, universities have welcomed Stern\u2019s ideas \u2013 not least his conclusion that the principles of the REF, including its assessment of research primarily on the basis of peer review by panels of academics rather than on metrics, should remain unchanged. \u201cI think it\u2019s fairer and more sensible \u2013 very much an evolutionary, rather than a revolutionary, change,\u201d says Curry.  Stern\u2019s report acknowledges that work will be required to test the impact of the proposals on the scope for gaming, and to mitigate against unintended consequences. The UK government said it planned to consider the recommendations before issuing a formal response. A full consultation on the next REF, which is scheduled to begin in 2020, will be published later this year. Additional reporting by Richard Van Noorden \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Impact of UK research revealed in 7,000 case studies 2015-Feb-11 \n                 \n                   UK releases world's largest university assessment 2014-Dec-18 \n                 \n                   Assess the real cost of research assessment 2014-Dec-10 \n                 \n                   Research assessments: Judgement day 2013-Oct-16 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20341", "url": "https://www.nature.com/articles/nature.2016.20341", "year": 2016, "authors": [{"name": "Asher Mullard"}], "parsed_as_year": "2006_or_before", "body": "Multimillion dollar initiative prioritizes drug development over discovery of new molecules. Antibiotics researchers are set to receive hundreds of millions of dollars from a new funding stream \u2014 but not everyone thinks the cash is being directed to the right place. The money is to come from CARB-X, a public\u2013private partnership  announced on 28 July . It is backed mainly by the US government, the London-based biomedical charity the Wellcome Trust and the UK R&D Centre for Antimicrobial Resistance (AMR Centre)s in Alderley Park, a consortium that includes public universities and private firms. Over the next 5 years, the partnership hopes to mobilize at least US$350 million to look for ways to overcome bacteria that are resistant to many common antibiotics. However, it\u2019s unclear whether all the promised money will be raised: the US contribution is anticipated to be $250 million over the 5 years, but that will depend on annual congressional approval. Biotechnology firms welcome the initiative, which aims to accelerate the development of more than 20 antibacterial drugs, vaccines and diagnostics \u2014 for example, by tweaking the chemistry of promising molecules to make them more effective or safer. But some academic researchers worry that CARB-X \u2014 which stands for the Combating Antibiotic Resistant Bacteria Biopharmaceutical Accelerator \u2014 fails to appreciate that one of the main barriers to finding new antibiotics is a lack of promising molecules in the first place. \n             Basic problem \n           \u201cI have mixed feelings about this,\u201d says Kim Lewis, an antibiotics researcher at Northeastern University in Boston, Massachusetts. \u201cIf more money is going into the general area of antibiotics, that\u2019s a good thing. But I\u2019m really surprised that we are getting another influx of funds into development rather than into discovery.\u201d The main problem, says Lewis, is the lack of compounds that can punch through the outer membranes of \u2018gram-negative\u2019 super-microbes such as  Escherichia coli  and  Klebsiella pneumoniae 1 , 2 . Researchers need to work out how to systematically make or find compounds that can slip through bacterial protective barriers, he says. Kevin Outterson, CARB-X\u2019s executive director and a health-law specialist at the Boston University School of Law, agrees that this is a legitimate concern. But he argues that it is a basic research question that falls under the purview of other funders, such as the US National Institute of Allergy and Infectious Diseases. \u201cWe see ourselves helping to move projects from a university lab towards clinical trials,\u201d he says. Outterson expects the bulk of CARB-X\u2019s resources to go to start-up companies spun off from university labs, but he hopes that the funding will bolster the entire antibiotic ecosystem. It will support preclinical research projects around the world. Ankit Mahadevia, chief executive of Spero Therapeutics in Cambridge, Massachusetts, applauds this mission. \u201cAs much as we need new ideas, we also need to advance the ideas that are pretty good but for which there just hasn\u2019t been enough capital or courage to advance into the clinic,\u201d he says. \n             Financial incentive \n           CARB-X is one of several ventures in recent years \u2014 such as  the European Union\u2019s NewDrugs4BadBugs initiative , launched in 2012 \u2014 that has helped to make the regulatory and investment environment for antibiotics look better than ever, says Mahadevia. \u201cFolks are excited about the field for the first time in a long time.\u201d He's encouraged by recent calls for incentives that could change how drug developers get paid for antibiotics. New antibiotics will need to be reserved for rare cases, to delay the emergence of resistance, so drug firms can\u2019t expect big sales for such products. A UK-government-commissioned  report published in May  suggests various ways to encourage firms to run risky and expensive drug-development projects, including \u201cmarket entry rewards\u201d of up to $1.3 billion for companies that successfully produce new antibiotics. Such incentives can\u2019t come soon enough, says Outterson. \u201cWhile our programme can move good products into the pipeline, at the end of the day, drug developers need to be able to sell antibiotics as well.\u201d \n                   The nose knows how to kill MRSA 2016-Jul-27 \n                 \n                   Society must seize control of the antibiotics crisis 2016-May-25 \n                 \n                   ESKAPEing the labyrinth of antibacterial discovery 2015-Jul-03 \n                 \n                   Promising antibiotic discovered in microbial \u2018dark matter\u2019 2015-Jan-07 \n                 \n                   Momentum builds around new antibiotic business models 2014-Oct-01 \n                 \n                   Platforms for antibiotic discovery 2013-Apr-30 \n                 \n                   CARB-X initiative \n                 Reprints and Permissions"},
{"file_id": "536013a", "url": "https://www.nature.com/articles/536013a", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Push to resurrect instrument lost during satellite failure highlights JAXA\u2019s resilience. The Japan Aerospace Exploration Agency (JAXA) is on a quest for redemption. In March, a software error caused the agency\u2019s Hitomi X-ray astronomy satellite  to break up in space , cutting short a planned three-year mission after only one month. Now JAXA is considering whether to rebuild and relaunch a copy of the spacecraft\u2019s key instrument \u2014 a US-built X-ray spectrometer \u2014 with help from NASA. On 5\u00a0August, representatives of the two space agencies will meet to discuss the possibility of resurrecting the instrument that was the heart of Hitomi\u2019s science. But whether JAXA can regain the confidence of the Japanese nation, and of its international partners, remains to be seen. Space experts note that JAXA has pulled off stunning recoveries before. It coaxed its crippled Hayabusa spacecraft  to bring back dust from an asteroid , and nudged its Akatsuki probe  into orbit around Venus  5 years after an engine failure seemed to render the spacecraft useless. \u201cIt\u2019s important to note how resourceful JAXA has been at recovering from failures that typically would be catastrophic,\u201d says Ralph Lorenz, a planetary scientist at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland, and co-author of the book  Space System Failures  (Praxis, 2005). Hitomi broke apart because an erroneous software command prompted the spacecraft to spin faster and faster, until its solar panels flew off into space. A JAXA investigation blamed faulty project-management techniques for not catching the error. The failure has reverberated at every level of JAXA\u2019s Institute of Space and Astronautical Science (ISAS) in Sagamihara, which managed Hitomi. JAXA president Naoki Okumura was one of three leading officials who took a 10% pay cut for four months \"to express our regret and caution ourselves\", he said in a June press conference. He has also ordered a systems review of the institute\u2019s next big project: a mission to study Earth\u2019s radiation belts that is slated to launch in the coming months. Before Hitomi, JAXA\u2019s lowest point was perhaps the loss of its Nozomi mission to Mars, which sailed past the red planet in 2003 without entering orbit as it was supposed to. The same year, a new JAXA rocket design failed during a test launch, prompting a review of all agency projects. \n               Try, try again \n             Some have questioned whether JAXA is trying to do too much with too little. It often assigns one person to cover a number of tasks that NASA would spread among multiple project engineers, says Lorenz, who collaborates on the Akatsuki Venus probe.  It\u2019s important to note how resourceful JAXA has been at recovering from failures.  Okumura has acknowledged as much, saying that ISAS will generally develop a mission using a small in-house team, along with the spacecraft manufacturer. By contrast, Hitomi involved a larger number of complex systems. There were simply not enough safeguards built into the process to catch the software error. \u201cThe previously conventional ISAS methods were not necessarily suited for the production of modern satellites and spacecraft,\u201d Okumura said. JAXA has released an extraordinary level of technical detail about the failure. Agency officials have said that because Hitomi was meant as a community mission to serve X-ray astronomers across the globe, they feel obligated to explain what happened so that nobody makes the same mistake. Because of this determination and openness, \u201cI think Hitomi\u2019s successor is in safe hands with JAXA,\u201d says Elizabeth Tasker, an astrophysicist at Hokkaido University in Sapporo, Japan. But such projects may be a hard sell to politicians. \u201cHigh-profile setbacks like Nozomi and Hitomi make it difficult for JAXA to justify big-ticket science missions in today\u2019s political atmosphere,\u201d says Saadia Pekkanen, an expert in Japanese space policy at the University of Washington in Seattle. JAXA has not yet decided whether a Hitomi successor would fly or which instruments it would carry, says ISAS spokeswoman Chisato Ikuta. But Hitomi\u2019s premier scientific instrument was the spectrometer provided by NASA; data that it collected before the spacecraft died revealed  secrets about gas flows in the Perseus galaxy cluster . The spectrometer seems to be thrice cursed; two earlier versions on different satellites were lost to a launch failure and a coolant leakage. Even so, a NASA advisory group reported on 5\u00a0July that launching a copy of the instrument no later than 2023 \u201cwould fulfill the immense scientific promise of the Hitomi\u201d spectrometer. The cost to rebuild would be roughly US$70\u00a0million to $90\u00a0million. Paul Hertz, NASA\u2019s astrophysics director, will meet with JAXA representatives to discuss the options. \u201cCertainly we would not be overseeing JAXA,\u201d he told a NASA advisory committee on 20\u00a0July. \u201cWe can discuss practices that NASA implements to prevent us from making avoidable mistakes.\u201d Other international missions in the works from JAXA include a magnetospheric orbiter, which is scheduled to launch next year on the European Space Agency\u2019s BepiColumbo mission to Mercury. \u201cThe Olympics of engineering is when things go wrong,\u201d says Lorenz. \u201cMaybe the best time to fly is right after a failure.\u201d \n                     Dead X-ray satellite reveals galaxy cluster surprise 2016-Jul-06 \n                   \n                     Software error doomed Japanese Hitomi spacecraft 2016-Apr-28 \n                   \n                     Rescued Japanese spacecraft delivers first results from Venus 2016-Apr-12 \n                   \n                     Japan\u2019s Venus orbiter makes comeback 2015-Dec-07 \n                   \n                     Spacecraft makes a grab for asteroid sample 2005-Nov-28 \n                   \n                     Blog: Japan celebrates asteroid round trip success \n                   \n                     JAXA \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20645", "url": "https://www.nature.com/articles/nature.2016.20645", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Decision based on limited data could herald a shift in how the Food and Drug Administration reviews drugs. The US Food and Drug Administration (FDA) has approved its first drug to treat Duchenne muscular dystrophy, largely on the basis of data from a trial in only 12 boys. The agency announced the decision on 19 September, after more than a year of consideration and controversy as the FDA struggled to balance  tremendous patient need  against the paucity of clinical data. The approval comes with a requirement that the drug, eteplirsen, now be tested in a larger clinical trial. Patient advocates cheered the decision. Many had campaigned vigorously for access to eteplirsen, which is made by Sarepta Therapeutics of Cambridge, Massachusetts. \u201cWe\u2019ve been waiting for this for a long, long time,\u201d says Debra Miller, president and co-founder of CureDuchenne, a charity based in Newport Beach, California. \u201cThis just gives so much hope to the families.\u201d Yet some at the FDA worried that the paucity of clinical data would foster false hope. The approval of the eteplirsen new drug application (NDA) sparked an unusual battle that reached FDA\u2019s top brass \u2014 and a wider debate about  how much data are needed to greenlight drugs  to treat rare diseases, and how much influence patient advocates should have in approval decisions. \u201cThe approval of this NDA in its present form would have far reaching negative consequences for the public health,\u201d wrote Ellis Unger, a director in the FDA\u2019s Center for Drug Evaluation and Research, in an appeal against the decision. \u201dThe precedent set here could lead to the approval of drugs for rare diseases without substantial evidence of effectiveness.\u201d \n             Cruel decline \n           Duchenne muscular dystrophy is caused by  mutations in the dystrophin protein  that protects muscle cells from the stress of repeated contraction and relaxation. Sarepta chief executive Edward Kaye likens dystrophin to a shock absorber: \u201cIf you don\u2019t have it, the cells just gradually degenerate and die,\u201d he says. The result is a cruel, sex-linked disease that affects about 1 in every 3,600 boys. Muscle weakness typically develops in these children before age five. Most people with the disease die of respiratory failure before or in their thirties. Sarepta\u2019s drug attempts to delay this decline in people with mutations in a region of the dystrophin gene called exon 51 \u2014 about 13% of those with Duchenne muscular dystrophy. The mutations in that region often halt production of dystrophin protein prematurely. Eteplirsen binds to the initial messenger RNA made from the dystrophin gene and masks exon 51 so that it is not read by the cell\u2019s protein-producing machinery. The machinery skips exon 51 and continues with the rest of the protein, resulting in a product that is shorter than normal, but more functional, than the original mutated form. Sarepta has tested the drug in about 150 people so far, says Kaye. But the key trial that the FDA used to evaluate the drug enrolled only 12. The trial was designed so that patients in the control group also did not remain on a placebo for the full length of the trial, but switched to eteplirsen after 24 weeks. \u201cNobody wanted to be on a placebo,\u201d says Kaye, a particular problem when the population of eligible patients is already so small. In April, a meeting of FDA advisers heard scientific presentations \u2014 including a highly critical review by FDA analysts \u2014 as well as passionate testimony from patients with Duchenne muscular dystrophy and their advocates. The advisers voted that there was not sufficient evidence to show that eteplirsen is an effective treatment. \n             Back to the drawing board \n           The FDA then asked Sarepta to provide more data about the degree to which dystrophin expression was restored in clinical-trial participants. With that data in hand, the agency granted the drug accelerated approval, on the condition that Sarepta conduct another trial to confirm that the drug works to slow the disease. But Unger\u2019s appeal shows that the disagreements continued to burn within the FDA after the extra data was received. Unger argued that dystrophin expression increased by more than 1% in just 1 of the 12 patients, and that it was unclear whether the drug produced any clinical benefits. Janet Woodcock, director of the Center for Drug Evaluation and Research, felt the drug should be approved. She urged the agency to be as flexible as it could while staying within its remit, given the lack of available treatments and the fact that Duchenne muscular dystrophy is a fatal disease that afflicts children. The dispute was settled by FDA commissioner Robert Califf, who sided with Woodcock but acknowledged the difficulty of the agency\u2019s decision. Eteplirsen will be the first drug approved in the United States that targets the cause of Duchenne muscular dystrophy. Another drug, called ataluren, is available in some European countries but was rejected by the FDA in February. Sarepta has already been working on improvements on eteplirsen, says Kaye, including a form of the drug that better penetrates muscle cells and could yield higher dystrophin concentrations. In the meantime, the FDA\u2019s requirement for another clinical trial is reasonable, says Fawn Leigh, director of the pediatric neuromuscular service at Massachusetts General Hospital in Boston, Massachusetts, who has been an investigator on trials of eteplirsen. \u201cWe had a hard time even just enrolling the 12 boys, they are so far and few,\u201d she says. \u201cBut everybody is motivated now. We\u2019re going to try to follow through.\u201d \n                   Puppy bred to have muscular dystrophy saved by surprise mutation 2015-Nov-12 \n                 \n                   Regulators adopt more orphan drugs 2014-Apr-01 \n                 \n                   Pharma scrambles to fast-track drugs 2013-Oct-01 \n                 \n                   US National Institutes of Health: Duchenne muscular dystrophy \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20578", "url": "https://www.nature.com/articles/nature.2016.20578", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Sociologist hopes to raise cash to carve concrete sculpture. \n             Update:  \n             on 13 September, the proposed monument  \n             reached \n              its $1,300 crowd-funding goal on Kickstarter. \n           Fancy your name, or the title of your latest paper, engraved in a sculpture dedicated to peer review? If so, you may want to drop a line \u2014 and a little donation \u2014 to Igor Chirikov of the Higher School of Economics (HSE) in Moscow. Three months ago the director of the HSE's Institute of Education, Isak Froumin, asked faculty for ideas about how to turn an ugly block of concrete outside the university into something handsome. Chirikov, a sociologist who splits his time between Moscow and the Center for Studies in Higher Education at the University of California, Berkeley, had the idea of turning the block into what he calls the world\u2019s  first Monument to an Anonymous Peer Reviewer . The artistic concept: chisel the concrete into a die, and paint on its five visible sides \u2018Accept\u2019, 'Minor Changes\u2019, \u2018Major Changes\u2019, \u2018Revise and Resubmit\u2019 and \u2018Reject\u2019. Chirikov and his friends\u00a0hope to raise US$1,300 on the crowdfunding site Kickstarter by 2 October to pay a sculptor for the work. Anyone who donates more than $1 can have their name put on a sign near the monument. And art patrons who provide at least $60 can have the title of a research paper of their own adorning one side of the die \u2014 if they are among the first 20 backers to ask for it. \u201cWe believe this monument will not be just a funny square-shaped block in front of our university building,\u201d the team says on its  Kickstarter page . \u201cIt will add a layer of genuine mysticism to the world of peer review and researching. Researchers from across the world will visit to touch the \u201cAccept\u201d side in the hope that the gods of peer review will smile down upon them. Of course, some unsuccessful researchers will want to curse it, and that\u2019s their business. Peer reviewers themselves may view the monument as a place of worship.\u201d \u201cIt's a bit sarcastic,\u201d Chirikov says. \u201cI certainly wanted to acknowledge the role of academic peer review \u2014 but I also wanted to have a good laugh about that process.\u201d \n                   Let\u2019s make peer review scientific 2016-Jul-05 \n                 \n                   Peer review: Close inspection 2016-May-11 \n                 \n                   Peer review: Troubled from the start 2016-Apr-19 \n                 \n                   The scientists who get credit for peer review 2014-Oct-09 \n                 \n                   Kickstarter campaign for Monument to Peer Review \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20285", "url": "https://www.nature.com/articles/nature.2016.20285", "year": 2016, "authors": [{"name": "Linda Geddes"}], "parsed_as_year": "2006_or_before", "body": "Nearly 100 previously unidentified brain areas revealed by examination of the cerebral cortex. Think of a spinning globe and the patchwork of countries it depicts: such maps help us to understand where we are, and that nations differ from one another. Now, neuroscientists have charted an equivalent map of the brain\u2019s outermost layer \u2014 the cerebral cortex \u2014 subdividing each hemisphere's mountain- and valley-like folds into 180 separate parcels. Ninety-seven of these areas have never previously been described, despite showing clear differences in structure, function and connectivity from their neighbours. The new brain map is published today in  Nature 1 . Each discrete area on the map contains cells with similar structure, function and  connectivity . But these areas differ from each other, just as different countries have well-defined borders and unique cultures, says David Van Essen, a neuroscientist at Washington University Medical School in St Louis, Missouri, who supervised the study. Neuroscientists have long sought to  divide the brain into smaller pieces  to better appreciate  how it works as a whole . One of the best-known brain maps chops the cerebral cortex into 52 areas based on the arrangement of cells in the tissue. More recently, maps have been constructed using magnetic resonance imaging (MRI) techniques \u2014 such as functional MRI, which measures the flow of blood in response to different mental tasks. Yet until now, most such maps have been based on a single type of measurement. That can provide an incomplete or even misleading view of the brain's inner workings, says Thomas Yeo, a computational neuroscientist at the National University of Singapore. The new map is based on multiple MRI measurements, which Yeo says \u201cgreatly increases confidence that they are producing the best  in vivo  estimates of cortical areas\u201d. \n             Divide and conquer \n           To construct the map, a team led by neuroscientist Mathew Glasser at Washington University Medical School used imaging data collected from 210 healthy young adults participating in the Human Connectome Project, a US government-funded initiative to map the brain\u2019s structural and functional connections. The information included measurements of cortical thickness; brain function; connectivity between regions; topographic organization of cells in brain tissue; and levels of myelin \u2014 a fatty substance that speeds up neural signalling. Glasser looked for areas in the cerebral cortex where he saw significant changes in two or more properties, and used these to delineate borders on the map. \u201cIf you crawl along the cortical surface, at some point you are going to get to a location where the properties start changing, and where multiple independent properties change in the same place,\u201d he says. The technique confirmed the existence of 83 previously reported brain areas and identified 97 new ones. Scientists tested their map by looking for these regions in the brains of 210 additional people. They found that the map was accurate, but that the size of the areas in it varied from person to person. These differences may reveal new insights into individual variability in cognitive ability and disease risk. \n             Limited view \n           \u201cWhile the focus of this work was on creating a beautiful, reliable, average brain template, it really opens up the possibility to further explore the unique intersection of individual talents with intellectual and creative abilities \u2014 the things that make us uniquely human,\u201d says Rex Jung, a neuropsychologist at the University of New Mexico in Albuquerque. But the map is limited in some important ways. For one, it reveals little about the biochemical underpinnings of the brain \u2014 or about the activity of single neurons or small groups. \u201cIt is analogous to having a fantastic Google Earth map of your neighbourhood, down to your individual back yard,\u201d says Jung. \u201cYet, you cannot really see how your neighbours are moving around, where they are going or what sort of jobs they have.\u201d \u201cWe\u2019re thinking of this as version 1.0,\u201d says Glasser. \u201cThat doesn\u2019t mean it\u2019s the final version, but it\u2019s a far better map than the ones we\u2019ve had before.\u201d  Read the related  News & Views article . \n                   Neuroscience: Map the other brain 2013-Sep-04 \n                 \n                   Neuroscience: Solving the brain 2013-Jul-17 \n                 \n                   See-through brains clarify connections 2013-Apr-10 \n                 \n                   Big Neuroscience: Billions and Billions (Maybe) to Unravel Mysteries of the Brain 2013-Feb-28 \n                 \n                   Human Connectome Project \n                 \n                   Blue Brain Project \n                 \n                   Matthew Glasser \n                 \n                   Van Essen Lab \n                 \n                   Rex Jung \n                 \n                   Thomas Yeo \n                 \n                   Sean Hill \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20648", "url": "https://www.nature.com/articles/nature.2016.20648", "year": 2016, "authors": [{"name": "Jason Bittel"}], "parsed_as_year": "2006_or_before", "body": "Experiments show that the tardigrade\u2019s resilience can be transferred to cultures of human cells. Tardigrades, or water bears, are pudgy, microscopic animals that look like a cross between a caterpillar and a naked mole rat. These aquatic invertebrates are consummate survivors, capable of withstanding a host of extremes, including near total dehydration and the  insults of space . Now, a paper 1  published on 20 September in  Nature Communications  pinpoints the source of yet another tardigrade superpower: a protective protein that provides resistance to damaging X-rays. And researchers were able to transfer that resistance to human cells. \u201cTolerance against X-ray is thought to be a side-product of [the] animal's adaption to  severe dehydration ,\u201d says lead study author Takekazu Kunieda, a molecular biologist at the University of Tokyo. According to Kunieda, severe dehydration wreaks havoc on the molecules in living things. It can even tear apart DNA, much like X-rays can. The researchers wanted to know how tardigrades protected themselves against such harsh conditions. So Kunieda and his colleagues began by sequencing the genome of  Ramazzottius varieornatus , a species that is particularly stress tolerant. It's easier to study processes within the tardigrade's cells when the animal's genome is inserted into mammalian cells, says Kunieda. So researchers manipulated cultures of human cells to produce pieces of the water bear's inner machinery to determine which parts were actually giving the animals their resistance. Eventually, Kunieda and his colleagues discovered that a protein known as Dsup prevented the animal's DNA from breaking under the stress of radiation and desiccation. And they also found that the tardigrade-tinged human cells were able to suppress X-ray induced damage by about 40%. \n             Genomic treasure trove \n           \u201cProtection and repair of DNA is a fundamental component of all cells and a central aspect in many human diseases, including cancer and ageing,\u201d says Ingemar J\u00f6nsson, an evolutionary ecologist who studies tardigrades at Kristianstad University in Sweden. This makes the new paper\u2019s findings \u201chighly interesting for medicine\u201d, says J\u00f6nsson. It opens up the possibility of improving the stress resistance of human cells, which could one day benefit people undergoing radiation therapies. Kunieda adds that these findings may one day protect workers from radiation in nuclear facilities or possibly help us to grow crops in extreme environments, such as the ones found on Mars. Bob Goldstein, a biologist at the University of North Carolina at Chapel Hill who helped to sequence the genome of another tardigrade species 2 , says the research is exciting and clever. He also thinks that the study\u2019s authors are correct in predicting that this is probably just the first of many such discoveries. \u201cThe tardigrade is resistant to a lot of different kinds of extremes,\u201d says Goldstein. And this means that the animals must have many different ways of protecting themselves. \u201cWe are really just at the beginning of exploring the genetic treasure that the tardigrade genome represents,\u201d says J\u00f6nsson. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Nano-suit shields bugs in the void 2013-Apr-16 \n                 \n                   Spacesuits optional for 'water bears' 2008-Sep-08 \n                 \n                   Pressure brought to bear 1998-Nov-05 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20643", "url": "https://www.nature.com/articles/nature.2016.20643", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "First large-scale study of ancient feline DNA charts domestication in Near East and Egypt and the global spread of house cats. Thousands of years before cats came to dominate Internet culture, they swept through ancient Eurasia and Africa carried by early farmers, ancient mariners and even Vikings, finds the first large-scale look at ancient-cat DNA. The study, presented at a conference on 15 September, sequenced DNA from more than 200 cats that lived between about 15,000 years ago and the eighteenth century  ad . Researchers know little about cat domestication, and there is active debate over whether the house cat ( Felis silvestris ) is truly a domestic animal \u2014 that is, its behaviour and anatomy are clearly distinct from those of wild relatives. \u201cWe don\u2019t know the history of ancient cats. We do not know their origin, we don't know how their dispersal occurred,\u201d says Eva-Maria Geigl, an evolutionary geneticist at the Institut Jacques Monod in Paris. She presented the study at the 7 th  International Symposium on Biomolecular Archaeology in Oxford, UK, along with colleagues Claudio Ottoni and Thierry Grange. A 9,500-year-old human burial from Cyprus also contained the remains of a cat 1 . This suggests that the affiliation between people and felines dates at least as far back as the dawn of agriculture, which occurred in the nearby Fertile Crescent beginning around 12,000 years ago. Ancient Egyptians may have tamed wild cats some 6,000 years ago 2 , and under later Egyptian dynasties, cats were mummified by the million. One of the few previous studies 3  of ancient-cat genetics involved mitochondrial DNA (which, contrary to most nuclear DNA, is inherited through the maternal line only) for just three mummified Egyptian cats. \n             Feline travels \n           Geigl\u2019s team built on those insights, but expanded the approach to a much larger scale. The researchers analysed mitochondrial DNA from the remains of 209 cats from more than 30 archaeological sites across Europe, the Middle East and Africa. The samples dated from the Mesolithic \u2014 the period just before the advent of agriculture, when humans lived as hunter\u2013gatherers \u2014 up to the eighteenth century. Cat populations seem to have grown in two waves, the authors found. Middle Eastern wild cats with a particular mitochondrial lineage expanded with early farming communities to the eastern Mediterranean. Geigl suggests that grain stockpiles associated with these early farming communities attracted rodents, which in turn drew wild cats. After seeing the benefit of having cats around, humans might have begun to tame these cats. Thousands of years later, cats descended from those in Egypt spread rapidly around Eurasia and Africa. A mitochondrial lineage common in Egyptian cat mummies from the end of the fourth century  bc  to the fourth century  ad  was also carried by cats in Bulgaria, Turkey and sub-Saharan Africa from around the same time. Sea-faring people probably kept cats to keep rodents in check, says Geigl, whose team also found cat remains with this maternal DNA lineage at a Viking site dating to between the eighth and eleventh century  ad  in northern Germany. \u201cThere are so many interesting observations\u201d in the study, says Pontus Skoglund, a population geneticist at Harvard Medical School in Boston, Massachusetts. \u201cI didn\u2019t even know there were Viking cats.\u201d He was also impressed by the fact that Geigl\u2019s team was able to discern real population shifts from mitochondrial DNA, which traces only a single maternal lineage. Nonetheless, Skoglund thinks that nuclear DNA \u2014 which provides information about more of an individual's ancestors \u2014 could address lingering questions about cat domestication and spread, such as their relationship to wild cats, with which they still interbreed. Geigl\u2019s team also analysed nuclear DNA sequences known to give tabby cats blotched coats, and found that the mutation responsible did not appear until the Medieval period. She hopes to sequence more nuclear DNA from ancient cats. But funding for modern cat genomics is scarce, which is one reason why it  lags far behind such research on dogs . By contrast, a team charting dog domestication announced at the Oxford meeting that it is preparing to sequence nuclear DNA from more than 1,000 ancient dogs and wolves. Geigl disputed this reporter\u2019s insinuation that dogs seem to be more popular among researchers than cats. \u201cWe can do it, too,\u201d she says. \u201cWe just need money.\u201d \n                   \u2018I can haz genomes\u2019: cats claw their way into genetics 2015-Jan-14 \n                 \n                   Leopard-like creature is the oldest big cat yet found 2013-Nov-13 \n                 \n                   Out of the desert, on to the sofa 2007-Jun-28 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20658", "url": "https://www.nature.com/articles/nature.2016.20658", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Worries include how to coordinate research programmes and resources from different countries. In recent years, brain-mapping initiatives have been popping up around the world. They have different goals and areas of expertise, but now researchers will attempt to apply their collective knowledge in a global push to more fully understand the brain. Thomas Shannon, US Under Secretary of State, announced the launch of the International Brain Initiative on 19 September at a meeting that accompanied the United Nations\u2019 General Assembly in New York City. Details \u2014 including which US agency will spearhead the programme and who will pay for it \u2014 are still up in the air. However, researchers held a separate, but concurrent, meeting hosted by the US National Science Foundation at Rockefeller University to discuss which aspects of the programmes already in existence could be aligned under the global initiative. The reaction was a mixture of concerns over the fact that attempting to align projects could siphon money and attention from existing initiatives in other countries, and  anticipation over the possibilities  for advancing our knowledge about the brain. \u201cI thought the most exciting moment in my scientific career was when the president announced the  BRAIN Initiative  in 2013,\u201d says Cori Bargmann, a neuroscientist at the Rockefeller University in New York City and one of the main architects of the US Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative. \u201cBut this was better.\u201d \n               A wealth of ideas \n             One of several goals for the initiative is the creation of universal  brain-mapping tools . Promising experimental tools exist, but labs make their own variations in-house and also tend to run experiments in their own ways. This makes it harder for different teams to collaborate or exchange information. At the Rockefeller meeting, physicist Michael Roukes at the California Institute of Technology in Pasadena noted that the industrial revolution only took off once factories with interchangeable components began replacing companies that had one-off machines. \u201cWe\u2019re still in the neuroscience craft era,\u201d he says. \u201cEveryone has their secret sauce.\u201d Another idea proposed at the meeting is the creation of an International Brain Observatory, with tools such as powerful microscopes and supercomputing resources that scientists from around the world could access \u2014 similar to the way that astronomers share telescope time. \u201cIf you just give people the basic tools, they\u2019ll do better science,\u201d says Alan Evans, a neurologist at McGill University in Montreal, Canada. Scientists cheered the idea of a virtual, cloud-based data-sharing resource, analogous to the GenBank genomics resource. It can be difficult to align data as each neurology lab has a preferred method of collecting, formatting and analysing their data sets. But Joshua Vogelstein, a neuroscientist at Johns Hopkins University in Baltimore, proposes a virtual International Brain Station that could automatically convert data from human brain scans or animal gene expression into standardized formats that would allow more people to analyse them. \n               Different priorities \n             But many attendees worried that marshalling the numerous proposals under one umbrella could backfire. Existing brain-research programmes have different priorities:  Japan  and  China , for instance, are investing heavily in primate research, whereas the United States tends to avoid it for ethical reasons. The European Union\u2019s flagship  Human Brain Project  (HBP) is focused on understanding the basic science of how the brain works, whereas Canada is mainly interested in creating technologies that can be applied to medicine. Other concerns expressed at the US-led Rockefeller meeting, intended to marshal support and ideas for the new International Brain Initiative, felt that some attendees were ignoring existing resources. Canada\u2019s nine-year-old CBRAIN programme serves as a clearinghouse for data and methods, and is already used by neuroscientists in 22 countries and the HBP. But Evans says that it is similar to the International Brain Station proposed at the Rockefeller meeting. \u201cIt\u2019s like, let\u2019s reinvent the wheel,\u201d he says. Others worry that the supposedly global initiative would exclude developing countries. \u201cIf the only way to do international is for each country to put in $300 million, that will not be international,\u201d says Sandhya Koushika of the Tata Institute of Fundamental Research in Mumbai, India. Although smaller countries cannot afford to map a marmoset brain, as Japan is doing, Koushika says that they could contribute to resources with patients, model organisms and efforts to design more affordable technologies. Bargmann says that the point of the Rockefeller meeting was to get a sense of the kinds of programmes already out there, and notes that future meetings will be more focused once they know who will participate. Overall, scientists are hopeful that this new global initiative will enable them to take brain mapping to the next level. Because several brain research projects have been around for a while, it's easier to compare their strengths and weaknesses and begin to talk pragmatically about what we need to align them, says Christoph Ebell, executive director of the HBP. \u201cI think it is the right moment.\u201d \n                     Human brain mapped in unprecedented detail 2016-Jul-20 \n                   \n                     Flagship brain project releases neuro-computing tools 2016-Mar-31 \n                   \n                     Brain-mapping projects to join forces 2014-Mar-18 \n                   \n                     Neurotechnology: BRAIN storm 2013-Nov-06 \n                   \n                     Neuroscience: Solving the brain 2013-Jul-17 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20656", "url": "https://www.nature.com/articles/nature.2016.20656", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Ancient teeth make  Homo sapiens  the lead suspect in the extinction of  Homo floresiensis. A pair of 46,000-year-old human teeth has been discovered in Liang Bua, a cave on the Indonesian island of Flores that was once home to the 1-metre-tall \u2018hobbit\u2019 species  Homo floresiensis . The teeth are slightly younger than the known hobbit remains, which strengthens  the case that humans were responsible for the species\u2019 demise . A team led by archaeologist Thomas Sutikna and geochronologist Richard Roberts, both at the University of Wollongong, Australia, reported the discovery of the teeth in a talk on 17 September at the annual meeting of the European Society for the study of Human Evolution in Madrid. The 2003 discovery of  H. floresiensis  puzzled researchers, in part because some of the remains were carbon dated to 11,000 years ago 1 , 2 , 3 . By then,  Homo sapiens  had colonized southeast Asia, and few scientists could imagine them having co-existed with hobbits for thousands of years. But this year, re-dating work in the cave pushed the extinction of hobbits back to around 50,000 years ago 4 . Roberts, who led that study, noted that humans were known to be already living in southeast Asia around that time.\u00a0\u201cIt\u2019s a smoking gun for modern human interaction, but we haven\u2019t yet found the bullet,\u201d he told  Nature  when the paper was published in March 2016. \n             Toothy tales \n           The human upper premolar and lower molar teeth were discovered in 2010 and 2011 and carbon dated to around 46,000 years old using nearby charcoal, Sutikna told attendees at the meeting. The team is confident that the teeth are from  H. sapiens : they are larger than those of  H. floresiensis , for instance. Mar\u00eda Martin\u00f3n-Torres, a palaeoanthropologist at University College London who attended the talk, thinks that the lower molar looks like those of  H. sapiens , whereas the premolar seems a bit more primitive. To prove conclusively that the teeth are human, she would like to see comparisons with a wide range of remains from  H. sapiens  and also from  H. erectus  (which might have survived in Indonesia until around 50,000 years ago). \u201cI think they have quite a tough job. There are lot of factors to take into account,\u201d she says. Other evidence presented by Sutikna puts humans in Liang Bua very soon after  H. floresiensis  vanished, which adds weight to the possibility that humans played a role in the extinction of hobbits, possibly by out-competing them for limited resources on Flores. Evidence of animals that might have been prey for human hunter\u2013gatherers, such as giant storks ( Leptoptilos robustus ), vultures ( Trigonoceps ) and miniature elephants called stegodons ( Stegodon florensis insularis ), vanishes from the cave\u2019s sediment layers after around 46,000 years ago. At the same time, freshwater mollusc shells begin to appear in sediments. Such shellfish are common at early human sites across Eurasia and Africa. Stone tools made from chert (which are also regularly found at other human sites) and evidence for fire hearths are also more recent than the hobbit remains at Liang Bua 5 . \u201cWhat we don't yet know is whether there was at least a short overlap in the populations, thus raising the question once again of the possible role of modern humans in the extinction of  floresiensis ,\u201d says Chris Stringer, a palaeoanthropologist at the Natural History Museum in London who attended the meeting. If hobbits and humans overlapped, they might even have interbred, Stringer says. Next April, Sutikna, Roberts and their team will return to Liang Bua to explore cave deposits that are between 46,000 and 50,000 years old: they may hold the remains of humans who saw the very last hobbits. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   \u2018Hobbit\u2019 relatives found after ten-year hunt 2016-Jun-08 \n                 \n                   Did humans drive 'hobbit' species to extinction? 2016-Mar-30 \n                 \n                   Human evolution: Small remains still pose big problems 2014-Oct-22 \n                 \n                   'Hobbit' was a dwarf with large feet 2009-May-06 \n                 \n                   Will the hobbit argument ever be resolved? 2006-Aug-25 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20684", "url": "https://www.nature.com/articles/nature.2016.20684", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Follow's Rosetta's descent to the surface of comet 67-P after more than a decade in space. \n             Meet the panel \n             \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             Reprints and Permissions"},
{"file_id": "nature.2016.20709", "url": "https://www.nature.com/articles/nature.2016.20709", "year": 2016, "authors": [{"name": "Barbara Cassasus"}], "parsed_as_year": "2006_or_before", "body": "Research gets 3.7% increase as government prepares for election year. France\u2019s government has proposed an unusually generous boost to research and higher education in its 2017 draft budget, released on 28 September. \u201cThis is the largest increase for 15 years,\u201d  Thierry Mandon , France\u2019s research and higher-education minister, told reporters at a press conference. Although the government\u2019s overall budget would rise by 2%, Mandon\u2019s ministry has been allotted a 3.7% spending hike, to \u20ac23.85 billion (US$26.7 billion) for 2017. The portion of that budget dedicated to research will also rise 3.7%, to \u20ac7.9 billion. But some scientists have a gloomier take on the figures. The government, with one eye on regaining power in next year\u2019s elections, has already promised a salary increase to civil servants \u2014 which, in France, include many researchers and university teaching staff. Those pay rises, together with the strain on the education sector caused by rising student numbers, could swallow up much of Mandon\u2019s increased budget, says Bernard Meunier, a chemist who is president of the French Academy of Sciences. \u201cThis budget is the absolute minimum to prevent the complete collapse of the system,\u201d says Patrick Lemaire, a biologist at the University of Montpellier and founder of the researcher-led campaign group Sciences en Marche. The figures must still be approved by parliament and could change if presidential and parliamentary elections, to be held between April and June 2017, alter France\u2019s balance of power. \n             Research-agency budgets \n           There is good news in the budget for the country\u2019s national research agency (ANR), a sought-after source of project-based funds that judges grant applications on a competitive basis. At the beginning of this year, leading scientists warned that the ANR had been experiencing \u2018 dramatic \u2019 cuts in funding. In March, President Fran\u00e7ois Hollande promised the ANR a larger budget, pledging that more of its competitive projects would be funded than in recent years. In the 2017 draft budget, the agency accordingly receives a 9% hike on its 2016 outlays, to \u20ac609 million. Mandon tells  Nature  that he expects the success rate of grant applications to the agency to rise from 9% last year to 14% this year, and up to 20% next year. Yet, the ANR\u2019s budget is still some 20% lower than it was in 2012, Lemaire notes, and it still has no confirmed amount dedicated to basic or blue-skies research. Hollande emphasized the importance of basic research in a speech given a day before the budget was released, to mark the 350th anniversary of the French Academy of Sciences. \u201cThere can be no savings on basic research,\u201d he said, adding that, over time, it determined the place of the nation\u2019s economy. In the speech, Hollande also delivered a strong defence of science, criticizing the \u201cconstant doubts cast on scientific data\u201d, and \u201cobscurantists\u201d on issues such as climate change. A detailed breakdown of what labs can expect from the budgets of France\u2019s other grant-giving agencies, such as the basic-research agency CNRS and the biomedical agency INSERM, will not be finalized for a few weeks, pending negotiations with research unions, a ministry official says. Meanwhile, a controversial government system that is supposed to increase private-sector research funding \u2014 by giving away around \u20ac6 billion each year in tax credits to French companies \u2014 could be in line for reform, Mandon tells  Nature . The tax credits have come under fire for their cost and for alleged abuses of the system. Mandon says that a university-led economic analysis of the system is being planned this year, and should provide a report next February. \u201cIt will be an independent study, whereas most such exercises are conducted by government agencies,\u201d he says. \n                   France\u2019s research minister lays out his priorities 2016-May-06 \n                 \n                   French scientists welcome new research minister 2015-Jun-17 \n                 \n                   Put focus back on basic research, say science unions 2014-Sep-03 \n                 \n                   French academy decries slide in research spending 2014-Jan-02 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20682", "url": "https://www.nature.com/articles/nature.2016.20682", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Spacecraft will strive to the end to capture best-ever comet images during descent. The Rosetta comet orbiter will  meet a sticky end on 30 September , but not before a finale that should see it gather the most detailed images yet of 67P/Churyumov\u2013Gerasimenko \u2014 or indeed of any comet. In 2014, after a ten-year journey through deep space, Rosetta, operated by the European Space Agency (ESA), became  the first craft ever to orbit a comet . Two years later, the orbiter is losing solar power as it speeds away from the Sun, and ESA scientists have opted to end the mission in style, with a  controlled crash into the comet\u2019s surface . \u201cI love the idea that Rosetta will be resting on the comet surface for many thousands of years \u2014 it\u2019s a fitting resting place for an amazing satellite,\u201d says Laurence O\u2019Rourke, an ESA astrophysicist and engineer. Engineers at the European Space Operations Centre (ESOC) in Darmstadt, Germany, will set Rosetta on a collision course with the comet at around 20:50  utc  on 29 September. The target is a 700-by-500-metre zone on the head of the  rubber-duck-shaped comet , close to a 130-metre wide pit in a region named Ma\u2019at, which is known for expelling gas and dust (see \u2018Rosetta\u2019s last hours\u2019). The crash site is around 2 kilometres away from the  final resting place of Philae,  the probe that  landed in November  2014 but  soon ran out of power.  The trajectory of Rosetta's descent \u2014 a 13.5-hour freefall of around 19 kilometres \u2014 is designed to maximize sunlight and will not afford the orbiter a view of Philae. But the final flyby is expected to include spectacular images from elsewhere on the comet, perhaps as close as 15 metres from the surface and with resolution as high as mere millimetres per pixel. Rosetta has not previously been closer than 1.9 kilometres to its comet. Rosetta scientists hope to use the cameras to see intriguing structures in the walls of the Ma'at pit that might hint at how comet 67P/Churyumov\u2013Gerasimenko formed. Other instruments will chart gas, dust and ionized particles at an unprecedented range. \u201cIt\u2019s a chance to get really unique science,\u201d says Patrick Martin, mission manager for Rosetta. For the final images, Rosetta will have to race to send back precious data before it crashes seconds later. \u201cIt\u2019s going to be really challenging,\u201d adds Martin. \n             Collection challenge \n           Resources are at a premium. At almost 575 million kilometres from the Sun, Rosetta is already operating on low power, and its increasing distance from Earth means that the speed with which it can transfer data is also dropping. To eke out the most science from the descent, scientists broadly agreed on which instruments would operate, with 3 of 11 teams volunteering to turn their instruments off, says Martin. Rather than disintegrate on impact, the orbiter will perform a gentle crash-landing, striking the comet at a slow walking speed (around 1 metre per second) at 10:40  utc . But because Rosetta is not designed to land, even this could cause its 32-metre-wide solar-panel wings to snap, and the craft to tumble and bounce. Exactly how Rosetta meets its end is likely to remain a mystery, because the craft will stop communicating with Earth after impact. The crash will trigger commands that shut down Rosetta even if the orbiter is intact, in order to comply with international regulations aimed at avoiding interference from deep-space network communication channels. (Even without this requirement, it's very unlikely that Rosetta, once crashed, would be capable of communication \u2014 because it will be unable to point its antenna in Earth's direction). Rosetta\u2019s distance from Earth means that news of the craft\u2019s demise will come around 40 minutes after impact, when ESOC\u2019s mission control expects to see Rosetta\u2019s characteristic communication signal flat-line, at around 11:20  utc , or 13:20 local time. \u201cFor sure, it\u2019s going to be a sad time for me,\u201d says O\u2019Rourke. Rosetta's final hours will be  live blogged  by  Nature \u2019s news team. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Photos reveal location of lost comet lander Philae 2016-Sep-05 \n                 \n                   Philae comet lander goes quiet for good 2016-Jul-26 \n                 \n                   Historic Rosetta mission to end with crash into comet 2015-Nov-04 \n                 \n                   Rosetta sniffs oxygen around comet 67P 2015-Oct-28 \n                 \n                   Philae's comet discoveries create series of conundrums 2015-Jul-30 \n                 \n                   Science pours in from Rosetta comet mission 2015-Jan-22 \n                 \n                   Landing on a comet: A guide to Rosetta\u2019s perilous mission 2014-Nov-10 \n                 \n                   ESA's Rosetta blog \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20698", "url": "https://www.nature.com/articles/nature.2016.20698", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Questions surround report of baby created using controversial mitochondrial-replacement technique. A reported world-first in fertility therapy \u2014 a baby boy conceived using a controversial technique that mixes DNA from three people \u2014 has made headlines across the world. But with no way of verifying the claim because the specialists behind the procedure will not release data until October, some researchers are questioning the ethics of the procedure. In particular, they ask why the US-based team behind the operation chose to carry it out in Mexico, a country with less-clear oversight of human-embryo modification than, for instance, the United Kingdom or the United States. Researchers at the New Hope Fertility Center in New York City told  New Scientist  \u2014 which  broke the news on 27 September  \u2014 that they had conducted the procedure for a Jordanian couple, and that the baby boy was born in April. The team, led by John Zhang, a physician at the centre, is not due to present details until 19 October, at the American Society for Reproductive Medicine meeting in Salt Lake City, Utah, but it has published an  abstract online  with sparse information. According to the abstract, the boy\u2019s mother carries a rare disease called Leigh syndrome, a neurological disorder caused by faulty mitochondria, the cell\u2019s energy-producing structures. The couple lost two children to the disease before asking for the clinic\u2019s help. \n             Spindle transfer \n           In an attempt to create embryos without the mother\u2019s faulty mitochondria, the clinic\u2019s team transferred the nucleus of the mother\u2019s egg cell to the egg of a donor with healthy mitochondria and its nucleus removed \u2014  a technique known as spindle nuclear transfer  \u2014 and then fertilized it with the father\u2019s sperm, the team reports in the abstract. Zhang\u2019s team modified five embryos, one of which was implanted into the mother and survived to birth. That baby inherited nuclear DNA from both parents and mitochondrial DNA from the donor. Although other \u2018three-parent\u2019 babies were born in the 1990s, they were created using a different technique in which mitochondria and other\u00a0cellular material from the eggs of healthy donors were transferred into the eggs of the mothers, which were then fertilized with the fathers\u2019 sperm. So the achievement of Zhang team\u2019s, if verified, would represent the first child conceived using the spindle-transfer version of mitochondrial-replacement therapy (MRT). In the United States, MRT is\u00a0in principle allowed, but requires review and approval by the US Food and Drug Administration (FDA). Last year, Congress banned the FDA\u00a0from using federal funds to review proposals that would manipulate the genetics of human embryos \u2014\u00a0hamstringing the agency.\u00a0Lawmakers seem poised to continue the funding ban into the 2017 fiscal year. The United Kingdom, meanwhile, decided last year to allow MRT under licence. \u201cWe\u2019d love to do it with partners around the world and reach out to more families that might need help,\u201d Zhang told  Nature . He says that his group plans to monitor the baby to ensure that the technique was safe and effective. \n             Unresolved issues? \n           Embryologist Jacques Cohen, who carried out mitochondrial-transfer procedures in the 1990s and is now laboratory director of the biotechnology company Reprogenetics in Livingston, New Jersey, was a regulatory adviser on Zhang\u2019s study, and welcomes the news that the spindle-transfer method seems to be effective. \u201cI think the world is ready to try this out. It has been discussed for a long time,\u201d he says. \u201cI think there are risks, but that\u2019s what happens when you do experimental procedure for the first time.\u201d Cohen\u2019s clinic produced 17 babies before the US began to regulate MRT in 2002. He has recently followed up with 13 of the children from his study \u2014 now teenagers \u2014 and is about to publish an article about their outcomes. Although he declines to give details, Cohen says that they have no obvious health problems. But some other researchers are troubled by Zhang\u2019s announcement. \u201cThey just went ahead and did it,\u201d says David Clancy, who studies mitochondrial biology at Lancaster University, UK. \u201cThe number of issues that are still unresolved \u2014 it\u2019s just staggering.\u201d Among the unknowns is the possibility that the technique could  transfer some diseased mitochondria from the mother into the donor egg along with the nucleus . According to Zhang\u2019s abstract, 5% of the embryo\u2019s mitochondrial DNA was the mother's, carried over along with the nucleus \u2014 but mitochondrial DNA samples taken from the baby after birth varied from tissue to tissue and suggested a level of faulty DNA that was, on average, 1.6%. Cohen says that it is generally thought that no symptoms will occur if fewer than about 20% of mitochondrial DNA are faulty. But Dietrich Egli, a stem-cell scientist at the New York Stem Cell Foundation who is also developing mitochondrial-transfer techniques, says that 5% at the embryo stage is 10 times higher than that seen in studies using spindle transfer 1  on embryos not destined for implantation. As a result, he says, the technique \u201cwas not carried out well\u201d. \u201cIt is a remarkable step, but unfortunately it is not well done,\u201d he adds. Clancy notes that it is impossible to analyse mitochondria in a living human from organs such as the heart and brain, and that weak mitochondria would be particularly problematic in these organs. \n             Why Mexico? \n           More concerning to some researchers is the fact that Zhang\u2019s procedure was performed in Mexico. Zhang told  New Scientist  that \u201cthere are no rules\u201d in Mexico. Legal scholar Rosario Isasi at the University of Miami in Florida says that there are laws governing the manipulation of human genes \u2014 but she adds that they are badly worded, and that there are exemptions that seem to be made for manipulations intended to cure deadly disease. Isasi questions the wisdom of performing the procedure in Mexico, which has a reputation of attracting patients from elsewhere who seek unproven cures that are not allowed in their own countries, instead of a country such as Sweden, whose government closely regulates the clinical use of therapies. \u201cYou have all these negatives, and it\u2019s not a place that can offer the scientists a high-tech environment,\u201d says Isasi. The clinic chose Mexico because it already had a branch there, New Hope spokesperson Geoffrey Hawes told  Nature . He declined to comment on whether the regulatory environment in Mexico played a part in the decision. \u201cIt\u2019s off limits. We won\u2019t comment on regulations,\u201d he says. \n             Chinese experiment \n           This was not the first time that Zhang had attempted MRT through spindle technology. In August, he published a paper 2  reporting on an experiment that his team carried out in China in 2003. The team transferred five human embryos produced through spindle technology into a woman who had failed to conceive children, but none survived to term. In a statement sent to  Nature , reproductive biologist Shoukhrat\u00a0Mitalipov at the Oregon Health and Science University in Portland, who pioneered spindle transfer in primates and is currently seeking approval to perform human trials, said that the strict US regulations are forcing researchers to move trials into other countries. \u201cWe believe it\u2019s time to move forward with FDA-approved clinical trials in the United States,\u201d he says. Egli is worried that any poorly done research in this area could hurt the chances of other groups as governments debate whether to allow the techniques. \u201cI think this kind of new technique needs a very serious approach and careful planning,\u201d he says. Isasi points out that Zhang\u2019s group did seem to follow ethical guidelines put forward by professional societies such as the US National Academies of Sciences, Engineering and Medicine. The baby was a boy, and many guidelines specify that only male embryos should be brought to term: because children receive mitochondria only from their mothers, there is no risk of a male passing the donated mitochondria on to his offspring. \n               Additional reporting by Heidi Ledford. \n             \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Three-person embryos may fail to vanquish mutant mitochondria 2016-May-19 \n                 \n                   Reproductive medicine: The power of three 2014-May-21 \n                 Reprints and Permissions"},
{"file_id": "537596a", "url": "https://www.nature.com/articles/537596a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Genetic analyses of endangered animals reveal high level of interbreeding with hardier American species. Ci\u00e9naga de Zapata National Park, Cuba Dozens of spotted baby crocodiles sit as still as garden statues. Only their swivelling eyes betray their intense interest in passing visitors. Then, suddenly, the animals snap to life, and begin ambling around the Zapata Swamp Captive Breeding Farm in Cuba\u2019s swampy Matanzas province. \u201cThey\u2019re cute as long as their mouths are closed,\u201d says Etiam P\u00e9rez, an exotic-fauna researcher at the farm whose leg bears scars from an encounter with an adult crocodile. The facility is the centrepiece of the Cuban government\u2019s 56-year effort to save the critically endangered Cuban crocodile ( Crocodylus rhombifer ). In January, the programme released its first 100 captive-born animals into the wild. But that success has been tempered by genetic analyses that have revealed widespread interbreeding between wild Cuban crocodiles and the more resilient American crocodile ( Crocodylus acutus ). The findings have prompted Cuban conservationists to rethink their ultimate goal. Should their breeding programme fight to  maintain the genetic purity  of the two species? Or should they let hybridization take its course, in the hope that an influx of genes from the hardy American crocodile will help the Cuban species to survive as its habitat shrinks and the climate changes? So far, science has not provided a clear answer. \u201cWe need to follow our instincts, our ideas, our judgement, and hope that future generations won\u2019t criticize us,\u201d says P\u00e9rez. Former president Fidel Castro began the effort to breed and conserve the island\u2019s reptiles in 1960, not long after the revolution that put him in power. Yet today, just a few thousand Cuban crocodiles remain in the wild. Logging and the expansion of agriculture have eaten away at their habitat, and demand for their valuable leather and meat is high. In Cuba, where the average monthly salary is about US$20, people run towards \u2014 not away from \u2014 crocodiles, P\u00e9rez says, despite the steep fines for killing them. The animals are more curious and aggressive than other crocodile species, and can leap metres out of the water to catch tree-dwelling rodents called hutias, says George Amato, a conservation biologist at the American Museum of Natural History in New York City. Cuban researchers have been slow to abandon the traditional method of classifying crocodiles by their head shape in favour of more precise genomic identification \u2014 in part because the country\u2019s research centres lack modern genetic-research tools. Yoamel Mili\u00e1n-Garc\u00eda, a biologist at the University of Havana, discovered that Cuban and American crocodiles were breeding with each other only after taking tissue samples to Canadian and US labs with next-generation DNA-sequencing technology. His most recent analysis 1  showed that half of the 227 wild Cuban crocodiles he tested were hybrids, compared with just 16% of 137\u00a0captive animals. This suggests that the animals\u2019 interbreeding has accelerated, and that genetic analyses are now the only reliable way to distinguish between the species to study their behaviour. Such situations are  becoming common , as improved sequencing technologies reveal the extent to which species  have interbred  through history, says Evon Hekkala, a conservation geneticist at Fordham University in New York City. Her study 2  of Egyptian crocodile mummies that are nearly 2,000 years old or more showed them to be very different from modern Nile crocodiles ( Crocodylus niloticus ), which are thought to be the descendants of multiple species that have probably died out. Hekkala is now studying fossilized crocodiles from the Caribbean to see what they reveal about the history of the various species there. To Mili\u00e1n-Garc\u00eda, the most important question is whether humans have played a part in the loss of the Cuban crocodile\u2019s genetic identity. The Cuban and American species normally occupy different niches: the latter is more tolerant of salt water and nests in holes, whereas the former prefers fresh water and builds nests on mounds. Habitat destruction may be forcing them into the same ecological niche, which could produce hybrids ill-equipped to prosper in a changing ecosystem. But an influx of genes from the salt-water-tolerant American crocodile could also help Cuban crocodiles to survive as Cuba\u2019s rising seas encroach on freshwater rivers and lakes. \u201cDo you want to be judgemental about a species getting by by accessing the genomic resources available to it by hybridization?\u201d Hekkala asks. While they grapple with such questions, Cuban researchers are using in-depth genetic studies to optimize their breeding programme. Last month, Mili\u00e1n-Garc\u00eda, P\u00e9rez and their colleagues reported 3  that female Cuban crocodiles can produce single clutches of eggs that contain DNA from multiple fathers. To maximize the amount of genetic diversity in the captive population, he says, the crocodile-breeding farm should allow each female to mate with several males. Yet conservation research in Cuba remains challenging. Everything from buying fuel to sending samples to other countries requires a US government permit, a consequence of the decades-old  US economic embargo  against Cuba. \u201cIt\u2019s the only place you can\u2019t solve a problem with money,\u201d Amato says. Despite these difficulties, Cuba\u2019s perennially underfunded scientists make do by  forging international collaborations  and dreaming up homemade solutions to equipment shortages. And the Cuban government continues to  make conservation a priority . In 2014, it closed off 500 hectares of the Zapata Swamp to future development, protecting land that had previously produced 15,000\u00a0cubic metres of milled lumber per year. Says Amato: \u201cI give them really high marks.\u201d \n                     Mosquito guns and heavy fines: how Cuba kept Zika at bay for so long 2016-Aug-17 \n                   \n                     Cuba forges links with United States to save sharks 2015-Oct-21 \n                   \n                     A network to track Caribbean hazards 2013-May-22 \n                   \n                     Scientists strive to boost US\u2013Cuban collaboration 2009-Jul-22 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20757", "url": "https://www.nature.com/articles/nature.2016.20757", "year": 2016, "authors": [{"name": "Tom Clynes"}], "parsed_as_year": "2006_or_before", "body": "Undergraduates from small, elite institutions have the best chance of winning a Nobel prize. There are many ways to rank universities, but one that\u2019s rarely considered is how many of their graduates make extraordinary contributions to society. A new analysis does just that, ranking institutions by the proportion of their undergraduates that  go on to win  a  Nobel prize . Two schools dominate the rankings: \u00c9cole Normale Sup\u00e9rieure (ENS) in Paris and the California Institute of Technology (Caltech) in Pasadena. These small, elite institutions each admit fewer than 250 undergraduate students per year, yet their per capita production of Nobelists outstrips some larger world-class universities by factors of hundreds. \u201cThis is a way to identify colleges that have a history of producing major impact,\u201d says Jonathan Wai, a psychologist at Duke University in Durham, North Carolina, and a co-author of the unpublished study. \u201cIt gives us a new way of thinking about and evaluating what makes an undergraduate institution great.\u201d Wai and Stephen Hsu, a physicist at Michigan State University in East Lansing, examined the 81 institutions worldwide with at least three alumni who have received a Nobel award in any of the six categories between 1901 and 2015. To meaningfully compare schools, which have widely varying alumni populations, the team divided the number of Nobel laureates at a school by its estimated number of undergraduate alumni. \n               Small but mighty \n             Many of the top Nobel-producing schools are private, and have significant financial resources. Among the more surprising high performers were several very small US liberal-arts colleges, such as Swarthmore College in Pennsylvania (ranked at number 4) and Amherst College in Massachusetts (number 9). \n               Top Nobel-producing undergraduate institutions \n               \u201cWhat these smaller schools are doing might serve as important undergraduate models to follow in terms of selection and training,\u201d says Wai, who adds that, although admission to one of the colleges on the list is no guarantee of important achievements later in life, the probability is much higher for these select matriculates. To gauge trends over time, Wai cut the sample of 870 laureates into 20-year bands. US universities, which now make up almost half of the top 50 list, began to dominate after the Second World War. Whereas French representation in the Nobel ranks has declined over time, top-ranked ENS has remained steady in its output. Hsu and Wai had previously performed two similar, but broader, analyses of the rate at which US universities produce winners of the Nobel prize, Fields Medal (in mathematics) or Turing Award (in computer science), as well as members of the US National Academies of Sciences, Engineering, and Medicine. These studies produced rankings of US institutions that are similar to the new, global Nobel rankings. \n               Lessons learned \n             Santo Fortunato, a theoretical physicist at Indiana University Bloomington who has researched trends in Nobel prizewinners, deems the analyses \u201cquite interesting\u201d, but cautions that the methodology cannot produce a highly accurate or predictive ranking. \u201cThere is a high margin of error due to the low numbers of prominent scholars,\u201d says Fortunato. Wai and Hsu agree that there are statistical uncertainties in their rankings, owing to the small number of prizes awarded each year. The two are confident that the ENS and Caltech lead the pack, but statistical fluctuations could change the order of schools placed from third to ninth, Hsu says. The researchers say that their findings suggest that more attention should be paid to the role that undergraduate institutions have in their graduates\u2019 outstanding accomplishments. They also argue that quantifiable achievements are a better gauge of the quality of universities than factors such as reputation, graduation rate, faculty and financial resources and alumni donations. Says Wai, \u201cOur findings identify colleges that excel at producing impact.\u201d \n                     World\u2019s tiniest machines win chemistry Nobel 2016-Oct-05 \n                   \n                     Physics of 2D exotic matter wins Nobel 2016-Oct-04 \n                   \n                     Medicine Nobel for research on how cells 'eat themselves' 2016-Oct-03 \n                   \n                     Spats, sniping and science: the rows behind the Nobels 2016-Sep-26 \n                   \n                     Know your Nobel 2015-Sep-24 \n                   \n                     Experience counts for Nobel laureates 2011-Nov-07 \n                   \n                     Nobel Prizes \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20755", "url": "https://www.nature.com/articles/nature.2016.20755", "year": 2016, "authors": [{"name": "Daniel Cressey"}], "parsed_as_year": "2006_or_before", "body": "Plans to restrict freedom of movement intensify researchers\u2019 fears over June vote. UK scientists say they\u2019re dismayed by their new government\u2019s toughened stance on curbing immigration, including ideas to restrict the flow of foreign students and workers. The government outlined its plans this week at the annual Conservative party conference, which was the first since the country gained a new Prime Minister, Theresa May, in the wake of June's vote for Brexit \u2014 the decision that the UK should leave the European Union. In speech after speech at the conference, held in Birmingham, politicians made it clear that they wanted to eliminate the free movement of EU citizens into the UK once the country splits from the EU, an event now expected to take place in 2019.  \u201cWe are not leaving the European Union only to give up control of immigration again,\u201d said May, opening the conference.  Since the referendum, in which concerns over immigration were believed to have played a big role in swaying voters, scientists have worried about how Brexit would affect the free movement of people. Although the government has not yet fleshed out its latest proposals in detail, they are the strongest indication yet that scientists will not be allowed to move freely between the UK and the EU after Brexit \u2014 which in turn means that UK researchers may well be excluded from EU funding programmes. \u201cThere has been a change in tone. I was surprised by how strong some of the comments were,\u201d says Azeem Majeed, who heads the department of primary care and public health at Imperial College London. He says the perception that non-UK citizens are not welcome \u2014 which grew as a result of June\u2019s Brexit referendum \u2014 has only increased since the conference. That is particularly the case in health fields, as the Conservative government has pledged to cut the number of foreign doctors in favour of UK citizens. \u201cFollowing the referendum, there was already a psychological impact on our EU staff,\u201d he says. \u201cThe comments from the conference in the past few days have added to that.\u201d \n               Taking away freedom \n             UK universities get about 16% of their research funding and 15% of their staff from the EU, and  scientists have been vocal  about the need to maintain some form of free movement for people between the UK and EU after Brexit. It may even be a prerequisite for UK access to EU research funding. When Switzerland restricted freedom of movement in 2014, its researchers lost access to the major Horizon 2020 research-funding programme, leading to protracted negotiations that are still ongoing. \u201cThe hard line on freedom of movement is almost certain to restrict us from EU funds,\u201d says Stephen Curry, a structural biologist at Imperial College London. Other comments on immigration and restricting foreign students are also going down poorly in academia. \u201cIt\u2019s reinforcing the rather sour atmosphere,\u201d says Curry. \u201cI think the mood has turned a lot darker [since the conference]\u201d. \n               Worker restrictions \n             UK home secretary Amber Rudd said in her conference speech that the government would consider making it harder to recruit from overseas, forcing companies to disclose the proportion of foreign staff working for them, and cutting down on universities\u2019 ability to recruit foreign students to \u201clower quality courses\u201d. \u201cWe had a very decisive message from the Conservative conference that the priority is simply reducing the number of people who come here, and if that damages the economy, so be it,\u201d says Jonathan Portes, an economist at the UK National Institute of Economic and Social Research in London. The conference was not all bad news for science and science policy, however, says Sarah Main, director of the Campaign for Science and Engineering in London. She says that the comments on immigration are concerning. But she adds that, at the Birmingham conference, \u201cWe\u2019ve seen the government being much more clearly positive about research and innovation in general.\u201d She cites a keynote speech from the Chancellor, Philip Hammond \u2014 which praised science as a driver of growth and emphasized the need to get \u201cthe brightest and best to work here in our high-tech industries\u201d \u2014 and positive comments from science minister Jo Johnson at events away from the main auditorium. But Portes, chief economist for the UK Cabinet Office during the 2008\u201309 financial crisis, says Hammond's positive messages for science don't outweigh the negative impacts of May and Rudd's plans. \u201cIt\u2019s nice to know the chancellor is not on the same page as the PM and the home secretary, but it seems pretty clear who is calling the shots,\u201d he says. \n                     E-mails show how UK physicists were dumped over Brexit 2016-Aug-05 \n                   \n                     Scientists seek influence on \u2018Brexit ministry\u2019 2016-Aug-02 \n                   \n                     Brexit watch: UK researchers scramble to save science 2016-Jul-22 \n                   \n                     Nature  special: Brexit \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20812", "url": "https://www.nature.com/articles/nature.2016.20812", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Schiaparelli touchdown would be ESA's first success on the red planet. Almost three weeks after it  crash-landed the Rosetta orbiter on a comet , the European Space Agency (ESA) is gearing up to land another spacecraft \u2014 this time on Mars. It hopes that a craft called Schiaparelli will touch down on the red planet on 19 October. Compared to the pioneering Rosetta mission, landing on Mars is a more conventional feat. But for ESA, the stakes are high, given that the tally of successful landings on Mars currently stands at NASA 7, Europe 0. Operating on the planet's surface would also be a first for Russia\u2019s space agency, Roscosmos, which is  a partner in the mission  \u2014 and which plans to partake in future joint Europe\u2013Russia missions, including a 2020 rover landing on Mars. The Soviet Union came close to success in 1971 with the Mars 3 probe, which failed just 20 seconds after landing on the surface. Given the importance of the landing, the descent through Mars\u2019s thin atmosphere will represent \u201cour own six minutes of terror\u201d, says Francesca Ferri, a planetary scientist at the University of Padua in Italy, referencing a line coined to describe the  landing of NASA\u2019s Curiosity rover in 2012 . \u201cAround 50% of the landings on Mars haven\u2019t succeeded, so it\u2019s not easy. But I\u2019m feeling pretty confident,\u201d says Ferri, who leads an experiment to study atmospheric data from Schiaparelli\u2019s descent. The ESA-designed Schiaparelli lander, which is about the size of a Smart car, represents one part of the ExoMars mission that  launched from Kazakhstan in March on a Russian rocket . The other half is an orbiter \u2014 also designed by ESA \u2014 that will analyse gases in Mars\u2019s atmosphere, starting from December 2017. \n             Dusty landing \n           Schiaparelli separated from its mothership on 16 October. Its main job is to demonstrate landing technology, although it will also have a short science mission, studying the dust storms of the red planet for as long as its batteries last, probably between two and four days. The lander is touching down in dust-storm season \u2014 and NASA scientists have warned that Mars could see a rare planet-wide storm this year, which would make for challenging landing conditions and hamper visibility. So far, ESA scientists say there are no signs of a major event, although that could change at any time. Schiaparelli has been designed and tested with dust storms in mind, but a strong storm could still cause problems. It would be ideal to have \u201cnice and clear weather for the descent, but a dust storm come a day or two later\u201d, says H\u00e5kan Svedhem, ExoMars 2016 project scientist at ESA. He says the craft should land safely whatever the weather. The idea of landing in the middle of a dust storm thrills Francesca Esposito, the principal investigator for the lander's DREAMS instrument, which will measure characteristics of Mars's dust, as well as recording data on temperature, wind speed, humidity and pressure at the planet's surface. \u201cA dust storm, or at least electrified dust in the atmosphere, would be great for us,\u201d says Esposito, who works at the INAF Astronomical Observatory of Capdiomonte in Naples, Italy. A dusty atmosphere would also warm the night-time temperature on Mars, which would reduce the need for the lander to heat itself and stretch its battery life, she says.\u00a0 \n             Lightning on Mars \n           An antenna on the DREAMS instrument will measure Mars\u2019s electrical field for the first time, and could detect lightning, if it exists on Mars. The team hopes to learn whether electric fields trigger dust storms, whether these in turn enhance the planet\u2019s electric fields, and how the storms eventually die out. Such information could aid basic understanding of the physics of Mars\u2019s atmosphere, and could be useful for future crewed missions to the planet or for building habitats on Mars. Schiaparelli is aiming for a smooth plain known as Meridiani Planum. NASA\u2019s Opportunity rover is situated around 15 kilometres outside Schiaparelli's 100 km \u00d7 15 km landing ellipse, and will try to get snapshots of the probe's descent, says Mark Lemmon, a planetary scientist at Texas A&M University in College Station. Although ExoMars's parachute may appear as no more than a speck, the pictures could help reveal how winds influence its trajectory, says Lemmon, adding that such shots would represent the first time a Mars landing has been seen from below. Anyone expecting spectacular pictures from Schiaparelli itself might be disappointed \u2014 photos will be limited to 15 black-and-white shots of the Martian surface from the air, intended to help piece together the craft\u2019s trajectory. No photos will be taken on the surface, because the lander lacks a surface camera. For now, Svedhem is just hoping for a first successful European landing. For the first three minutes after entering Mars\u2019s thin atmosphere, Schiaparelli will be slowed by drag alone before its parachute deploys to decelerate the craft more rapidly. A little over a kilometre from the surface, after 5 minutes and 22 seconds, the parachute should detach and thrusters will kick in. A 30-second burn will leave the craft a few metres off the ground and travelling at a few metres per second before it drops to the surface, where a crushable honeycomb structure on its base should cushion its landing. \u201cI can\u2019t relax until we really know it\u2019s standing on the ground,\u201d says Svedhem. \n               Tweet \n               Facebook \n               LinkedIn \n               Weibo \n               Wechat \n             \n                   Mission accomplished: Rosetta crashes into comet 2016-Sep-30 \n                 \n                   Mars launch to test collaboration between Europe and Russia 2016-Mar-11 \n                 \n                   British Mars lander find is bittersweet victory 2015-Jan-16 \n                 \n                   Europe looks to Russia after NASA falls short on ExoMars 2011-Oct-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20768", "url": "https://www.nature.com/articles/nature.2016.20768", "year": 2016, "authors": [{"name": "Robynne Boyd"}], "parsed_as_year": "2006_or_before", "body": "Tweaks to treaty that targeted the ozone hole could help to fight powerful greenhouse gasses. An article by    Scientific American . After being directed for almost 30 years at substances that destroy ozone, the\u00a0 Montreal Protocol \u00a0will for the first time target a group of greenhouse gases. Beginning today in Kigali, Rwanda, member states of the United Nations are finalizing the terms of what could be the largest commitment to reducing global warming since the  Paris Agreement on climate  last December. Delegates are likely to take till the meeting\u2019s final day on 14 October to hammer out the knotty details of an amendment to the protocol. Ideally, the amendment will set the terms for a rapid phasedown of hydrofluorocarbons (HFCs), the most common of which is the refrigerant HFC-134a, which has 1,430 times more warming potential than carbon dioxide (CO 2 ) over 100 years. The amendment would stop the manufacture of HFCs and then reduce their use over time. \u201cAn ambitious amendment is the quickest and least expensive way to reduce the effects of climate change,\u201d says Durwood Zaelke, president of the Institute for Governance and Sustainable Development, who has been a mainstay at ozone negotiations since almost the beginning of the 1987 treaty. He says a phasedown could prevent the equivalent of 100 to 200 billion tons of CO 2  being released into the atmosphere by 2050. That prevention could avert half a degree of warming by the end of the century. Considering that the Paris Agreement\u2019s goal is to keep global average temperature rise by less than 2 \u00b0C, an HFC ban offers a significant opportunity. The Montreal Protocol was adopted after scientists recognized that chlorofluorocarbons (CFCs) were destroying the protective layer of ozone in the stratosphere. Two years later countries began eliminating the chemicals, which had a helpful by-product of releasing fewer greenhouse gases. After initially balking, industry giants like DuPont turned from producing CFCs to the less ozone-depleting hydrochlorofluorocarbons (HCFCs), as a temporary bridge to substitution with HFCs. By 2009 it was well known that HFCs, while benign to ozone, had an enormous potential to add to global warming. And so the seed of an HFC amendment took root. Because climate change can threaten many facets of life, UN delegates think it makes sense to tackle it wherever possible. In UN jargon, HFCs are a \u201clow hanging fruit.\u201d They\u2019re a much simpler problem to solve than ratcheting back carbon emissions; they are deliberately produced, primarily as refrigerants in air conditioners and other cooling systems. There are no natural sources of HFCs, so the planet\u2019s emissions come from manufactured goods. Today, HFCs comprise a slim 2% of the world\u2019s hefty annual carbon dioxide emissions. But according to the Institute for Governance and Sustainable Development, that could rise to 12% by 2050 if no limits are established, as the developing world aspires to amenities such as air conditioners. A rapid reduction could help ensure the success of the Paris Agreement, and also allow (or force) the developing world to leapfrog HFC-based technologies. Environmentally friendly alternatives are already for sale. They include natural refrigerants such as what propane and ammonia and a class of fluorinated chemicals known as hydrofluoroolefins. Still, concerns in Kigali will be raised over the cost of substitutes, for countries like India. There is also some question about how effective they can be in hot places like the Persian Gulf states. Even back in 1987 nations recognized the potential climatic effects of certain manufactured chemicals. Countries have undergone what Zaelke calls the \u201cstart and strengthen\u201d approach. With CFCs, the parties originally agree to a 50% phasedown in 12 years. They later agreed to a 100% reduction over a single decade. HCFCs have a similar story, and due to climate concerns, are now in the process of an accelerated phaseout. In a 2007\u00a0 study , Guus Velders, now with the National Institute for Public Health and the Environment in the Netherlands, estimated that had CFCs, HCFCs and halons continued to grow in use, as they had before the Montreal Protocol (at about 2 to 3% annually), by 2010 they would have contributed a cumulative equivalent of 135 billion tons of carbon dioxide. In 2015, the world emitted a\u00a0 total \u00a0of 32.1 billion tons of carbon dioxide. \u201cWhat it [the Montreal Protocol] demonstrates is kind of uplifting in my view, that the world can act together on environmental problems, and did in an effective way,\u201d says Susan Solomon, a professor of atmospheric chemistry and climate science at the Massachusetts Institute of Technology. Research by her and others in 1986 showed that ozone was destroyed by CFCs. \u201cNow the ozone hole is beginning to show the first signs of healing, right on time,\u201d she says. According to Solomon\u2019s most recent\u00a0 paper , published in June, the size of the Antarctic ozone hole has been decreasing since its greatest extent in 2000, mostly attributable to diminishing levels of gases that affect ozone in the atmosphere. A decade ago, scientists predicted the ozone hole would mend by the middle of this century, an increasingly likely forecast. The question is whether the Montreal Protocol can achieve something similar for HFCs. On 22 September in New York, more than 100 countries, including the US, known as the \u201cgroup of ambition,\u201d suggested developed countries set an initial reduction of 10% by 2019. They also called for developing countries to \u201cfreeze,\u201d or stop increasing, the use of HFCs by an \u201cearly date\u201d currently ranging from 2021\u20132031. Pinpointing the grace period between when developed and developing countries must freeze the use of HFCs will be one of the main haggling points of this week\u2019s negotiations. So will the speed at which countries reduce their use of HFCs to zero. Past agreements for the other chemicals typically allowed 30 years. With the  Paris Agreement reaching a crucial threshold  last week that will put it into effect on 4 November, there is a lot of momentum for heroic fixes for climate change. An HFC amendment would also demonstrate that the Paris Agreement cannot solve climate change alone. Sister agreements must be brought in, according to Zaelke. \u201cThere\u2019s a lesson here,\u201d he says. \u201cWhen you focus on one piece of the problem, you can actually learn how to solve it.\u201d \n             This article was  \n             originally published by  \n             Scientific American \n              on 10 October. \n           \n                   Paris climate deal to take effect as EU ratifies accord 2016-Oct-04 \n                 \n                   Nations approve historic global climate accord 2015-Dec-12 \n                 \n                   A breath of fresh air 2015-Nov-11 \n                 \n                   Ozone treaty could be used for greenhouse gases 2010-Nov-09 \n                 \n                   Nature Special: 2015 Paris Climate Talks \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20817", "url": "https://www.nature.com/articles/nature.2016.20817", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Breakthrough raises call for debate over prospect of artificial human eggs. In a tour de force of reproductive biology, scientists in Japan have transformed mouse skin cells into eggs in a dish, and used those eggs to birth fertile pups. The report marks the first creation of eggs entirely outside a mouse. If the process could be made to work for humans, researchers could produce artificial eggs without needing to implant immature cells into ovaries to complete their development. Katsuhiko Hayashi, a reproductive biologist at Kyushu University in Fukuoka, led the group that announced the breakthrough on 17 October in  Nature 1 . In 2012, when at the University of Kyoto, he and stem-cell biologist Mitinori Saitou  reported taking skin cells down the pathway towards eggs : reprogramming them to embryonic-like stem cells and then into primordial germ cells (PGCs) 2 . These early cells emerge as an embryo develops, and later give rise to sperm or eggs. But to get the PGCs to form mature eggs, the researchers had to transfer them into the ovaries of living mice. The next advance came in July 2016, when a team led by Yayoi Obata, at the Tokyo University of Agriculture, reported transforming PGCs extracted from mouse fetuses into oocytes (egg cells) without using a live mammal 3 . Working with Obata, Hayashi and Saitou have now completed the cycle: from skin cells to functional eggs in a dish. With the use of in-vitro fertilization (IVF) techniques, 26 healthy pups were born (some originally from embryonic stem cells and some from reprogrammed skin cells). Hayashi says some of these animals gave birth to a second generation of mice. \u201cThis is truly amazing,\u201d says Jacob Hanna, a stem cell biologist at the Weizmann Institute of Science in Rehovot, Israel. \u201cTo be able to make robust and functional mouse oocytes over and over again entirely in a dish, and see the entire process without the 'black box' of having to do any of the steps in host animals, is most exciting.\u201d \u201cParts of this work were done before \u2014 here they are put together in completeness. It\u2019s impressive that they got pups that way,\u201d says Dieter Egli, a stem cell biologist at the New York Stem Cell\u00a0Foundation Research Institute. Hayashi says the procedure is robust \u2014 although technically challenging \u2014 and that different groups in his lab have reproduced it. Although the biologists did not need to implant the PGCs into living mice, they did need to add cells taken from the ovaries of other mouse fetuses \u2014 effectively, to create an ovary-like support in which the eggs could grow. Hayashi is now trying to concoct an artificial reagent that could replace these cells in his protocol. The egg-in-a-dish feat comes after researchers in China said in February that they had made  rudimentary mouse sperm in a dish 4 . In that case, the researchers created \u2018spermatids\u2019, which are not fully mature cells, although they did claim to use them to create offspring. \n               From mice to humans \n             Hayashi says the work will help him study egg development, now that he can make them fully in a dish. He is not trying to make functional human eggs in the lab. (Japanese guidelines forbid fertilization of engineered human germ cells, even for research purposes). But he suspects that others will try. \u201cI do not think it is going to prove much more complex,\u201d says Hanna \u2014 who himself hopes to create human eggs. Hanna co-led the team that reported  the first artificial human PGCs  in 2014, just two years after Hayashi\u2019s work with mice 5 . For ethical reasons, he has not implanted them in humans to try to mature them into sperm or eggs. But prospects of maturing human PGCs in a dish are enticing. Hanna\u2019s laboratory has already been conducting similar experiments to those described in Hayashi\u2019s new paper, he says. One challenge will be to obtain the necessary supporting ovarian (or, for sperm, testicular) cells; currently, the process only works with fetal cells. But he hopes that similar cells from pigs or monkeys might work. If the Hayashi protocol works with human cells, it could in principle be used to make eggs from a man\u2019s skin cells, Hanna says \u2014 adding that, as a pro-LGBT rights activist, he thinks that this option is \u201clegitimate to explore when the right time comes.\u201d Hayashi, however, has yet to use male skin cells to produce eggs in mice. Hayashi thinks that \u201coocyte-like\u201d human eggs might be produced within ten years, but he doubts that they will be of sufficient quality for fertility treatments. \u201cIt is too preliminary to use artificial oocytes in the clinic,\u201d he says, cautioning that his study showed that the artificial mouse eggs were often of low quality. He worries that such eggs might create genetically abnormal embryos, and potentially abnormal offspring. In the study, only 3.5% of the early embryos created from artificial eggs gave rise to pups \u2014 compared with 60% of eggs that were matured inside a mouse. But debate over the ethics of such a technology should begin now, says Azim Surani, a pioneer in the field at the University of Cambridge, UK. \u201cThis is the right time to involve the wider public in these discussions, long before and in case the procedure becomes feasible in humans,\u201d he says. \n                     Researchers claim to have made artificial mouse sperm in a dish 2016-Feb-25 \n                   \n                     Rudimentary egg and sperm cells made from stem cells 2014-Dec-24 \n                   \n                     Stem cells: Egg engineers 2013-Aug-21 \n                   \n                     Mouse stem cells lay eggs 2012-Oct-04 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20822", "url": "https://www.nature.com/articles/nature.2016.20822", "year": 2016, "authors": [{"name": "Emma Marris"}], "parsed_as_year": "2006_or_before", "body": "Threatened forest icon may be a hybrid of two extinct species. The European bison ( Bison bonasus ) may be the continent\u2019s largest land mammal, but its origins have long been a mystery. Hunted for millennia and pushed into the wild corners of Europe as agriculture expanded, the bison \u2014 also known as wisent \u2014 were reduced to just a few zoo specimens by the late 1920s. Today, a semi-wild population roams  Bia\u0142owie\u017ca Forest , near the Poland\u2013Belarus border, where they slip between hornbeams and mighty oaks, their curly coats and horns lending an aura of the Pleistocene to the ancient forest. https://poly-admin1.nature.com/polopoly/CM#_ftn1 It took a reach into the past using ancient DNA and cave art to unveil the wisent\u2019s origin story. Researchers published the species\u2019 family tree on 19 October in  Nature Communications 1 . https://poly-admin1.nature.com/polopoly/CM#_ftn2 The team took almost a decade to complete their work. Much of the analysis used ancient mitochondrial DNA derived from 65 bison specimens ranging from 14,000 to more than 50,000 years ago. But it wasn\u2019t until technological advances made it possible to examine nuclear DNA that researchers were able to produce a coherent family tree. According to the team\u2019s analysis, the wisent is a hybrid of two extinct animals: the steppe bison ( Bison priscus ), the Eurasian ancestor of the American bison, and the aurochs ( Bos primigenius ), the ancestor of modern cattle. The steppe bison went extinct more than 11,000 years ago and the  last aurochs was shot in 1627 https://poly-admin1.nature.com/polopoly/CM#_ftn3 . From the DNA evidence researchers estimate that hybridization took place 120,000 or more years ago. In most cases, hybrid animals are less fertile and fit than their parents. But in this case, a whole new species seems to have taken flight. \n             Looking to art \n           To have flourished, the hybrid must have had some qualities that made it competitive during climate changes in the Pleistocene, says author Julien Soubrier, a palaeogeneticist at the University of Adelaide in Australia https://poly-admin1.nature.com/polopoly/CM#_ftn4 . In the Urals, for example, wisents (and an extinct related group the researchers call Clade X) were found before 50,000 years ago and again after 34,000 years ago, when Europe was very cold and vegetation in the Urals included tundra and grasslands. In between, steppe bison seem to have roamed the region during an era of warm summers. The cold-adapted wisent and related animals presumably moved further north. To corroborate this timing, the team looked to an unusual source: cave art. Cave drawing and rock art around the world are a source of \u201cincomparable and precious data because they were drawn by \u2018artist-hunters\u2019 trained to observe living animals for hunting,\u201d says Gilles Tosello, a cave-art expert based in Toulouse, France. The alternating dominance of wisent and steppe bison might be reflected in cave paintings created during this period, says Colin Groves, an expert on cattle and their ancestors, and on human evolution, at the Australian National University in Canberra. He suggested that the team take a look at prehistoric cave art, because bison were a favourite subject among cave painters in Europe. Soubrier agreed, and asked Tosello and his wife and colleague Carole Fritz for help https://poly-admin1.nature.com/polopoly/CM#_ftn5 https://poly-admin1.nature.com/polopoly/CM#_ftn6 . Fritz and Tosello, who were lead artists on a huge recreation of the art at  Chauvet cave  in France, had already noticed that there seemed to be two types of bison represented in European cave paintings. In the Chauvet art, which is around 30,000\u201336,000 years old, the bison were drawn with long horns and a very high shoulder compared with the rump. However, in more recent cave art from the Magdalenian period (around 17,000\u201310,000 years old), the couple saw animals with a more horizontal backbone and smaller horns. Given the temporal correspondence with the fossil record, these two forms were likely to be the steppe bison and the wisent, respectively, the team says. \n             A matter of survival \n           This is not the first scientific paper to use cave art as data. Arne Ludwig at the Leibniz Institute for Zoo and Wildlife Research in Berlin https://poly-admin1.nature.com/polopoly/CM#_ftn7  and his team used the spotted patterns on horses in cave art as an inspiration to find genes in ancient horse DNA that could have given rise to the 'leopard' coat pattern recognized by horse breeders today 2 . https://poly-admin1.nature.com/polopoly/CM#_ftn8 \u201cIn my opinion, people at this time had deep knowledge about details in their surrounding environment,\u201d says Ludwig. \u201cThat was essential for their survival and of course it\u2019s no surprise that they separated between the steppe bison and the wisent.\u201d But not everyone is convinced. \u201cThere is no evidence to link the two [lineages of] European bisons with the two kinds of bison morphs drawn in cave paintings,\u201d says systematist Alexandre Hassanin at the National Museum of Natural History in Paris.  https://poly-admin1.nature.com/polopoly/CM#_ftn9 He believes the steppe bison, the American bison, and the wisent are all the same species, and doesn't think that ancient hybridization with aurochs created a new species. But others in the field give the work the thumbs-up. \u201cThis study again illustrates the power of the ancient DNA,\u201d says Hans Lenstra, an expert on the genetics of domestic animals and their wild relatives at Utrecht University in the Netherlands.  https://poly-admin1.nature.com/polopoly/CM#_ftn10 \u201cCorrelation with cave art and climate changes then yielded a consistent and interesting story.\u201d \n                   'Cave of forgotten dreams' may hold earliest painting of volcanic eruption 2016-Jan-15 \n                 \n                   Homo erectus made world's oldest doodle 500,000 years ago 2014-Dec-03 \n                 \n                   World's oldest art found in Indonesian cave 2014-Oct-08 \n                 \n                   Spain claims top spot for world\u2019s oldest cave art 2012-Jun-14 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20818", "url": "https://www.nature.com/articles/nature.2016.20818", "year": 2016, "authors": [{"name": "Nic Fleming"}], "parsed_as_year": "2006_or_before", "body": "Winner's descendants could scoop hundreds of millions of dollars by the middle of next century. Two US researchers have doubled their 16-year-old wager on whether anyone born before 2001 will reach the age of 150. The scientists have now staked US$600 on the question \u2014 but, if the fund in which the cash is deposited keeps growing at its current rate, the descendants of the victor could net hundreds of millions of dollars in 2150. The friendly rivalry began in 2000, when Steven Austad, a biologist who studies ageing, was quoted in a  Scientific American  article 1  with the provocative statement: \"The first 150-year old person is probably alive right now.\" Jay Olshansky, another expert on ageing, didn't think so \u2014 and the scientists agreed to stake cash on the debate. On 15 September 2000, the two put $150 each into an investment fund, and signed a contract stating that the money and any returns would be paid to the winner (or his descendants) in 2150. The bet also stipulates that Austad will only win if the 150-year-old is of sound mind. \n             Lifespan limit? \n           Then last week, a paper in  Nature 2  suggested \u2014 from an analysis of global demographic data \u2014 that there may be  a natural limit to human lifespan of about 115 years . Olshansky, at the University of Illinois at Chicago, wrote an accompanying  commentary  which argues that fixed genetic programs stand in the way of significant human life extension 3 . He says he believes a major breakthrough that will significantly extend human lifespan will occur within his lifetime, but that it will come too late to help those born before 2001 to reach their 150th birthday. But Austad, at the University of Alabama, Birmingham, disagrees. \u201cI\u2019m more convinced than ever that I was correct in our original bet,\u201d he says. He cites recent studies showing that a number of drugs, such as the immune-system suppressor rapamycin, can  significantly extend lifespan in animals . And he points to the imminent start of a clinical trial called Targeting Aging with Metformin, or TAME, which hopes to show that  a well-known diabetes drug can slow ageing . Austad and Olshansky have now agreed to stake another $150 each. In 16 years, their original $300 stake has already grown to $1,275 (increasing by around 9.5% per year). If the topped-up fund maintains this average annual return, the winning pot could top $200 million by 1 January 2150. On that date, three scientists chosen by the president of the American Association for the Advancement of Science will determine the winner \u2014 although neither Austad nor Olshansky expects to be alive to find out. \n                   The limits to human lifespan must be respected 2016-Oct-05 \n                 \n                   Human age limit claim sparks debate 2016-Oct-05 \n                 \n                   Short-lived fish may hold clues to human ageing 2015-Dec-03 \n                 \n                   Cancer drug lengthens fly lifespan 2015-Jun-25 \n                 \n                   Anti-ageing pill pushed as bona fide drug 2015-Jun-17 \n                 \n                   Pet dogs set to test anti-ageing drug 2014-Oct-29 \n                 Reprints and Permissions"},
{"file_id": "538298a", "url": "https://www.nature.com/articles/538298a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "Science policy fades into background for many who back Republican candidate in US presidential race. Kaylee, a structural biologist at Yale University in New Haven, Connecticut, stays quiet when her colleagues talk about politics and religion. As a Catholic with conservative tendencies, she feels that her beliefs are unwelcome in academic institutions, where liberal views often prevail. The strain is particularly acute this year: Kaylee favours Donald Trump for US president. Trump, a Republican, has run a  brash, often divisive, campaign  that has prompted some leading members of his own party to disavow him. He has drawn criticism for his treatment of women, his  pledge to block Muslim immigration  to the United States, and his plan to  build a wall along the US\u2013Mexico border . Still, Kaylee says, \u201cI am 100% certain I will not vote for Hillary Clinton,\u201d Trump\u2019s Democratic opponent, despite her fears that supporting Trump could harm her job prospects. (For this reason, Kaylee \u2014 a postdoc \u2014 asked  Nature  to refer to her by a pseudonym.) Her fears do not surprise Neil Gross, a sociologist at Colby College in Waterville, Maine. Surveys have shown that conservative faculty members are a minority in US universities, although the proportion varies by field (see \u2018Field reports\u2019). \u201cMy sense is that the candidacy of Donald Trump has really intensified disputes that were there already in academic life,\u201d Gross says. \u201cIf Republicans in academia and science felt uncomfortable before, I think the candidacy of Mr Trump has made them all the more uncomfortable.\u201d  Many of the researchers interviewed for this article say that Trump and Clinton\u2019s positions on science have not influenced their vote\u00a0\u2014 in part because the candidates have largely ignored these issues on the campaign trail. \u201cWe\u2019re living in a two-dimensional world: how much do you like each candidate, and how much do you hate each candidate?\u201d says Stanley Young, assistant director for bioinformatics at the National Institute of Statistical Sciences in Research Triangle Park, North Carolina, who backs Trump. \u201cThe popular impression I get is Clinton would go forward with business as usual and Trump is likely to upset things a bit. There\u2019s a lot that could be improved in science.\u201d David Deming, a geophysicist at the University of Oklahoma in Norman, doesn\u2019t think it matters whether Trump and Clinton have much personal knowledge of science. \u201cTrump said he\u2019d appoint good people and I believe him,\u201d says Deming, who has written newspaper opinion pieces in support of Trump. Other scientists who plan to vote for the Republican say they have been let down by US President Barack Obama, and think that Clinton \u2014 another Democrat \u2014 would bring more of the same. To them, Trump represents change. \u201cThe current status quo seems like it\u2019s not working for a lot of Americans,\u201d says one Trump-supporting chemist at the University of Pittsburgh in Pennsylvania, who asked for anonymity. \u201cI\u2019m hopeful for a modest improvement, and that\u2019s about as much as I can hope.\u201d William Briggs, a statistician at Cornell University in Ithaca, New York, likes the fact that Trump has not emphasized science. \u201cThe federal government has become far too involved in setting the scientific agenda,\u201d says Briggs, who argues that Obama has misused science in  politically charged debates over climate change and energy policy . \u201cI think Hillary would worsen that.\u201d Kaylee, who disagrees with Trump\u2019s views on women and minorities, says that her desire for a more conservative Supreme Court is driving her vote. With the next president likely to nominate at least one Supreme Court justice \u2014 a lifetime appointment \u2014 she sees Trump as a tool to move the court\u2019s ideological balance to the right. Otherwise, Kaylee would vote for a \u2018write-in candidate\u2019 who won\u2019t appear on the presidential ballot: her lab\u2019s principal investigator, who has given her a safe space to express conservative views. But not everyone is so lucky. And as the 8\u00a0November election nears, talk of the hard-fought presidential race grows trickier to escape. Some scientists who support Trump worry that political discussions in the lab will not only harm their careers in the long term, but also hinder current collaborations with colleagues, and waste time. \u201cI\u2019ve avoided discussions among my real-life peers for a while,\u201d says the anonymous chemist at the University of Pittsburgh, who prefers to talk about politics online. \u201cA lot of people, if they\u2019re not willing to come out in favour of Hillary, will give the third-party dodge.\u201d See also Editorial:  'Hillary Clinton will make a fine US president' \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Trump vs Clinton: worlds apart on science 2016-Jul-26 \n                   \n                     Trump\u2019s immigration stance stokes fears for science 2016-Apr-05 \n                   \n                     Scientific advice: Crisis counsellors 2014-Aug-27 \n                   \n                     Nature  special: US election 2016 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20831", "url": "https://www.nature.com/articles/nature.2016.20831", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "The enigmatic object travels an orbit that reaches well beyond Pluto. Pasadena, California Astronomers have spotted a distant world that orbits far beyond Pluto, in the extreme reaches of the Solar System. The object, known informally as L91, may be in the process of gradually shifting its way inward from the Oort cloud \u2014 a reservoir of comets and other icy bodies \u2014 into the nearby, equally icy Kuiper belt. No object has ever been seen doing this. The discovery of L91 reveals more about the extreme worlds whose orbits lie beyond the gravitational influence of Neptune, the most distant giant planet in the Solar System. Researchers have yet to fully explain how these bodies end up in their current orbits. \u201cEvery time we find another one of these objects, it adds another piece to the puzzle,\u201d says Meg Schwamb, a planetary scientist at the Gemini Observatory in Hilo, Hawaii. Astronomers with the  Outer Solar System Origins Survey  discovered L91 in September 2013 using the Canada\u2013France\u2013Hawaii Telescope in Hawaii. The group has been conducting a detailed survey of a small portion of the sky, aiming to catalogue and describe the Kuiper-belt objects within it. \n             Going long \n           L91\u2019s elliptical orbit never brings its closer to Earth than about 50 times the Earth\u2013Sun distance (or 50 astronomical units,  au ). At its farthest, the object is 1,430  au  away. That means its orbit is more stretched out, and centred farther from the Sun, than previously discovered worlds such as  Sedna  and  2012 VP 113 . The location and trajectory of L91 make it \u201cfascinating\u201d, said Michele Bannister, an astronomer at Queen\u2019s University Belfast, UK. She reported the finding on 17 October at a joint meeting of the American Astronomical Society\u2019s Division for Planetary Sciences and the European Planetary Science Congress. L91 may have been tossed into its remote orbit by gravitational interactions with Neptune in the distant past.  \u201c This one is right on the hairy edge of everything,\u201d says Nathan Kaib, an astronomer at the University of Oklahoma in Norman. Bannister and her colleagues think the object may have been banished as far as 2,000  au  from the Sun before it began easing its way back towards the star\u2019s gravitational pull. L91\u2019s orbit \u201cis changing in quite a remarkable way\u201d, she said. But Konstantin Batygin, an astronomer at the California Institute of Technology in Pasadena, isn\u2019t so sure. He thinks Bannister\u2019s suggestion that L91 was first tossed towards the Oort cloud and is now moving inward is too complicated. He argues that an unseen giant planet \u2014 such as  Planet Nine , which he and a colleague proposed in January \u2014 might instead be shepherding L91\u2019s orbit more simply and directly. Bannister counters that L91 travels an orbit that is almost within the plane of the Solar System, rather than being tilted at high angles, as might be expected if it were being battered around by a Planet Nine. \n                   On the hunt for a mystery planet 2016-Mar-15 \n                 \n                   Evidence grows for giant planet on fringes of Solar System 2016-Jan-20 \n                 \n                   Astronomers spy most distant Solar System object ever 2015-Nov-10 \n                 \n                   Dwarf planet stretches Solar System's edge 2014-Mar-26 \n                 \n                   Outer Solar System Origins Survey \n                 Reprints and Permissions"},
{"file_id": "538436a", "url": "https://www.nature.com/articles/538436a", "year": 2016, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Justin Trudeau draws praise for boosting budgets and unmuzzling scientists, but tough challenges lie ahead. It didn\u2019t take long for Canada\u2019s Prime Minister Justin Trudeau to send scientists swooning. Within days of taking office on 4 November 2015, the middle-left Liberal relaxed restrictions on government scientists\u2019 ability to speak to the press and the public, and reinstated a long-form census prized by social scientists. A year on, Trudeau has boosted science budgets and restored some research jobs cut by his Conservative predecessor, Stephen Harper. \u201cThe sun has peeked through some of the clouds,\u201d says Paul Dufour, a science-policy analyst at the University of Ottawa. \u201cThe dark prince has left.\u201d Yet many in Canada\u2019s science community say they are reserving judgement, waiting to see whether Trudeau can sustain his string of victories as he tackles some of country\u2019s thorniest science-policy issues. Among them are revisions of processes ranging from environmental regulations to Canada\u2019s system for doling out research grants. Kathleen Walsh, executive director of the non-profit science-advocacy group Evidence for Democracy in Ottawa, worries that some of the Trudeau government\u2019s environ-mental policies may favour style over substance. Take the prime minister\u2019s decision to put a price on carbon \u2014 starting at Can$10 (US$7.5) per tonne in 2018 and rising to Can$50 per tonne in 2022. Environmentalists and economists say that those prices are too low to achieve Canada\u2019s goal of reducing its greenhouse-gas emissions by 30% below the 2005 level by 2030. Many also see that emissions goal, set by Harper, as lacklustre. And Trudeau has not broached harder subjects, such as fulfilling a campaign promise to phase out fossil-fuel subsidies. \u201cThe Trudeau government has squandered an opportunity for effective national action,\u201d says Douglas Macdonald, an environmental-policy expert at the University of Toronto. \n               Rethinking science spending \n             The prime minister\u2019s first budget, released in March, brought good news for scientists: an increase of roughly Can$95 million for the country\u2019s research councils \u2014 more than twice the 2015 boost (see \u2018Budget boost\u2019). But there are still grumbles about how research councils\u2019 funds are apportioned. \u201cA lot of money is going to large institutions,\u201d says Walsh. \u201cYour everyday scientists in everyday labs are still struggling.\u201d Earlier this year, health scientists cried foul over reforms to the Canadian Institutes of Health Research (CIHR) system for awarding grants. Researchers complained that the measures, including a switch to online peer review, made reviews less effective and put early-career scientists at a disadvantage. More than 1,000\u00a0researchers signed a letter demanding changes; in September, the CIHR launched an international review of its grant processes. A broader examination of the government\u2019s science-funding system, called the Fundamental Science Review, began in June. Science minister Kirsty Duncan says that the government has received more than 1,200\u00a0public comments, and a final report on the review is due by early 2017 at the latest. The Trudeau government is also re-examining Harper\u2019s changes to fisheries and environmental-assessment laws, with recommendations due by early 2017. In the meantime, controversial projects such as a natural-gas plant on the British Columbia coast are receiving government approval. \u201cThere is a rush by companies to get hearings over and the necessary papers in place before [environmental assessment] regulations are strengthened,\u201d says David Schindler, an ecologist at the University of Alberta in Edmonton. Trudeau\u2019s main campaign promise to scientists was to reinstate evidence-based decision-making. To that end, jobs are being restored to some government research departments after a loss of roughly 1,800\u00a0positions during the Harper administration \u2014 344\u00a0of those at the agency Environment Canada alone. Now, the department of fisheries and oceans is hiring 135\u00a0scientists. And the Professional Institute of the Public Service of Canada, a union that represents government workers, wants the administration to hire 1,500\u00a0extra scientists next year. Many researchers are waiting for Trudeau to deliver on his promise to install a chief science officer to keep science at the heart of governance. That position is still in the planning stage, and Duncan would not comment on when an appointment would be made. \u201cWe\u2019re kind of still in the honeymoon period,\u201d says Dufour. \u201cEveryone is willing to give the government some long string. But at some point they\u2019re going to have to take some actual action.\u201d \n                     Nine years of censorship 2016-May-03 \n                   \n                     Canada\u2019s top scientist faces tough challenge 2015-Dec-22 \n                   \n                     Canada creates science-minister post 2015-Nov-04 \n                   \n                     Canadian election brings hope for science 2015-Oct-20 \n                   \n                     Canadian election spotlights scientists' frustrations 2015-Sep-17 \n                   \n                     Canadian budget pushes applied research 2015-Apr-22 \n                   Reprints and Permissions"},
{"file_id": "537598a", "url": "https://www.nature.com/articles/537598a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Former Soviet nation bids for independence from Russian fossil fuels. Wind and solar power are wallflowers in oil- and gas-rich Russia. Not so in neighbouring Ukraine. With fears about Russian hegemony at a peak, the former Soviet republic is ready to join the renewables revolution. \u201cEnergy independence has become a matter of national security for Ukraine,\u201d says Sergiy Savchuk, head of the state agency on energy efficiency and energy saving in Kiev. \u201cThat\u2019s why renewable-energy development is now a priority issue for the Ukrainian government.\u201d In July, Ukrainian environment minister Ostap Semerak unveiled plans to build a large solar power plant and a biogas facility in the wasteland around the former Chernobyl reactor. The announcement came just two weeks after parliament reopened the state-owned exclusion zone around the shuttered nuclear site\u00a0to development for business and science. The Chernobyl energy project will cost around US$1.1 billion, a sum that means substantial foreign investment is required. It is part of Ukraine\u2019s broader ambition to step up renewable-energy capacity. According to the National Renewable Energy Action Plan adopted in 2014, the government aims to almost triple capacity for electricity production, transport and heating by 2020\u00a0\u2014\u00a0from its current level of around 9.3\u00a0gigawatts to more than 26\u00a0gigawatts. Renewables would then supply about 11% of all energy consumed in Ukraine. Despite the traumatic Chernobyl reactor meltdown in 1986, which contaminated large parts of Europe and tempered Ukraine\u2019s nuclear ambitions, the country continues to produce about 50% of its electricity from a fleet of 15 Soviet-built nuclear reactors. Ukraine also depends heavily on oil and natural gas imported from Russia. But political turmoil over Russia\u2019s annexation of the Crimean peninsula in 2014 and ongoing pro-Russian unrest in the eastern Donbas region led to the strategic rethink. Already, Ukraine has reduced its reliance on Russian fossil fuels, cutting consumption of natural gas by about one-third since 2013. Ukraine has significant untapped renewable-energy potential, finds a 2015 report by the International Renewable Energy Agency (IRENA) in Abu Dhabi, United Arab Emirates\u00a0\u2014\u00a0enough to support the 2014 plan. The largest country to lie entirely within Europe (Turkey and Russia are mostly in Asia), it gets more sunshine than Germany, where photo-voltaic solar power now exceeds 40\u00a0gigawatts. Ukraine also has good grid infrastructure, including high-voltage transmission lines between Chernobyl and Kiev, says Dolf Gielen, director of IRENA\u2019s Innovation and Technology Center in Bonn, Germany. But the economic environment is less favourable, Gielen says. Electricity demand has declined in the years since the conflict with Russia escalated, and is mostly met by existing nuclear and fossil-fuel sources. More-over, the exceedingly high cost of investment in the politically unstable country might discourage potential backers. As the first phase of implementing the 2014 action plan, Ukraine is scheduled to build 51 solar-power and 15 wind-power projects\u00a0\u2014\u00a0an endeavour that will cost an estimated $7\u00a0billion. \u201cFinancing renewables in Ukraine is comparable to investing in parts of Africa,\u201d Gielen says. \u201cInvestors such as the European Bank for Reconstruction and Development might still be interested, but the Chernobyl solar plant certainly can\u2019t be a purely commercial project.\u201d In Russia, things are different. Solar plants on the annexed sunny Crimean peninsula have some 300\u00a0megawatts of capacity. But elsewhere, utility-scale wind and solar plants are almost non-existent. The Russian government does aim to tap the renewable-energy potential afforded by the country\u2019s Arctic regions, which are sun-drenched during northern summers, and its warm, windy southern steppes. Hydropower already provides 17% of Russian electricity, but by 2020, other renewables will supply 4.5%, up from less than 1% currently, according to the Kremlin\u2019s energy strategy. Yet experts doubt the target is achievable. \u201cManufacturing limitations mean that Russia produces almost no wind turbines and solar panels,\u201d says Deger Saygin, a programme officer for IRENA in Bonn. Foreign capital has been in short supply, because economic sanctions imposed by the European Union and the United States in response to Moscow\u2019s seizure of the Crimea unsettled potential investors. In the short term, Saygin says, small, off-grid renewable-energy systems in Siberia and Far Eastern provinces such as Kamchatka\u00a0\u2014\u00a0where scattered communities, mines and small industries have long relied on diesel generators\u00a0\u2014\u00a0are Russia\u2019s prime opportunity in the clean-energy market. There are currently 13 solar plants operating in Yakutia, including the largest solar plant north of the Arctic Circle, and some wind farms in Kamchatka. \u201cRenewable energy in Russia,\u201d says Saygin, \u201cis mainly driven by Siberia\u2019s distance from the national grid.\u201d \n                     Putin appoints church historian as science minister 2016-Aug-22 \n                   \n                     Germany\u2019s renewable revolution awaits energy forecast 2016-Jul-13 \n                   \n                     Conflicting laws threaten Ukrainian science 2016-Mar-02 \n                   \n                     Ukraine joins flagship European research programme 2015-Mar-20 \n                   \n                     Putin\u2019s Russia divides and enrages scientists 2014-Dec-16 \n                   \n                     Western science severs ties with Russia 2014-Apr-08 \n                   \n                     Renewable energy: Back the renewables boom 2014-Mar-19 \n                   \n                     Energy: Islands of light 2014-Mar-11 \n                   \n                     State Agency on Energy Efficiency and Energy Saving of Ukraine \n                   \n                     International Renewable Energy Agency \n                   \n                     Remap 2030: Renewable Energy Prospects for Ukraine (PDF) \n                   \n                     International Finance Corporation Russia Renewable Energy programme \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20878", "url": "https://www.nature.com/articles/nature.2016.20878", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Wolbachia -infected mosquitoes will be widely deployed in two South American cities to combat viral infections. Two South American metropolises are enlisting bacteria-infected mosquitoes to fight Zika, in the world\u2019s biggest test yet of an unconventional yet promising approach to quell mosquito-borne diseases. Mosquitoes that carry  Wolbachia  bacteria \u2014 which hinder the insects' ability to transmit Zika, dengue and other viruses \u2014 will be widely released in Rio de Janeiro, Brazil, and Medell\u00edn, Colombia, over the next two years, scientists announced on 26 October. The deployments will reach around 2.5 million people in each city. \u201cThis really has the potential to be a game changer in terms of vector control \u2014 the biggest thing since DDT,\u201d says Philip McCall, a medical entomologist who studies mosquito control at the Liverpool School of Tropical Medicine, UK. Small numbers of  Wolbachia -infected mosquitoes have already been released in both Rio de Janeiro and Medell\u00edn. But large biomedical funders have today announced US$18 million for a massive scale-up of these efforts. \u201cWe really want to deploy quite quickly in large sections of these cities,\u201d says Scott O\u2019Neill, a microbiologist at Monash University in Melbourne, Australia, and head of the Eliminate Dengue Program, which is leading the mosquito releases. Footing the bill are the Bill and Melinda Gates Foundation in Seattle, Washington, the London-based Wellcome Trust and the US and UK governments. Brazil\u2019s government is chipping in with an extra $3.7 million, O\u2019Neill says. \n               Virus blockers \n             Wolbachia pipientis  plagues some 60% of insect species worldwide \u2014 but doesn't naturally infect  Aedes aegypti  mosquitoes, the species that transmits Zika, dengue and numerous other viruses. The bacteria can hinder the fertility of their hosts and influence the sex of offspring. They can also block viruses from reproducing in infected fruit flies and mosquitoes, as O\u2019Neill and his colleagues discovered in work that began in the late 1990s. The team later developed laboratory populations of infected  A. aegypti . When tens of thousands of these mosquitoes were released near the small city of Cairns in northern Australia in 2011,  the bacteria spread rapidly among local  A. aegypti  mosquitoes ; 90% of mosquitoes in a targeted area were infected within weeks. Tests in Indonesia and Vietnam found similar success. It's not yet clear whether the strategy also reduces rates of dengue infections in humans, but O\u2019Neill\u2019s team has begun a trial in Yogyakarta, Indonesia, to find out. The Eliminate Dengue team started releasing  Wolbachia -infected mosquitoes in two Rio de Janeiro neighbourhoods in 2014, and in a suburb of Medell\u00edn in 2015. The bacteria block the replication of Zika and chikungunya virus (which caused  widespread outbreaks in Latin America and the Caribbean in 2013\u201314 ). O\u2019Neill\u2019s team hopes that the scaled-up deployments can combat those diseases, as well as dengue, which infected an estimated 1.6 million people in Brazil last year. The researchers plan to release mosquitoes in waves across the cities, survey the insects for viral infection and track the local incidence of disease in areas with and without  Wolbachia -infected mosquitoes. Other scientists are also testing  Wolbachia  to control mosquitoes. In Singapore, officials plan to release male  A. aegypti  mosquitoes infected with a strain of  Wolbachia  that renders their offspring infertile. A US biotechnology company  is seeking approval  to use a similar approach to combat related Asian tiger mosquitoes ( Aedes albopictus ), which carry dengue and chikungunya. In Guangzhou, China, scientists are already releasing millions of  A. albopictus  mosquitoes infected with  Wolbachia  each week, in large-scale field trials. And researchers in French Polynesia are trying the same strategy on another species of tiger mosquito. \n               More evidence needed \n             Wolbachia  has an impressive ability to surge through wild mosquito populations, says McCall, but proving that this limits human infections will be critical before the approach can find widespread use. If  Wolbachia  is to make a dent in mosquito-borne diseases, the technique will also have to be cost-effective and long lasting, he adds. \u201cIf it works, it will be truly remarkable, but it has to still be working in ten years.\u201d Another hurdle facing the tests in Rio de Janeiro and Medell\u00edn is the sheer size of the cities \u2014 especially Rio, with its densely populated and hard-to-access  favelas , says McCall. But if  Wolbachia  can help to combat Zika, dengue and chikungunya in such environments, \u201cthere is a very strong case for doing it for a range of other large cities\u201d, says Mike Turner, acting director of science at the Wellcome Trust. Widespread deployment of  Wolbachia -infected mosquitoes would probably also depend on an endorsement from the World Health Organization, he adds. Public support could make or break the  Wolbachia  approach, says O\u2019Neill, whose team spent years engaging with communities in Australia before deploying mosquitoes there.  Wolbachia  is already widespread among insects and it cannot infect humans, he notes. In Australia, researchers recruited schoolchildren, whom they dubbed  Wolbachia  warriors, to rear the eggs at home, learn about their development and then release the mosquitoes. In Colombia, the Eliminate Dengue team has worked with \u201cCasa  Wolbachia \u201d families to help with the release of mosquitoes, and even written salsa songs about the bacteria, says co-principal investigator Jorge Osorio, a pathobiologist at the University of Wisconsin\u2013Madison. \u201cWe have communities asking us to spread more mosquitoes,\u201d he says. \n                     US reviews plan to infect mosquitoes with bacteria to stop disease 2016-May-24 \n                   \n                     Why transgenic insects are still not ready for prime time 2016-Apr-22 \n                   \n                     Sickly mosquitoes stymie malaria\u2019s spread 2013-May-09 \n                   \n                     Modified mosquitoes set to quash dengue fever 2012-Jan-10 \n                   \n                     Bacterium offers way to control dengue fever 2011-Aug-24 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20877", "url": "https://www.nature.com/articles/nature.2016.20877", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "A study clarifies when HIV entered the United States and dispels the myth that one man instigated the AIDS epidemic in North America. In 1982, sociologist William Darrow and his colleagues at the US Centers for Disease Control and Prevention (CDC) travelled from Georgia to California to investigate an explosion in cases of Kaposi\u2019s sarcoma, a type of skin cancer, among gay men. Darrow suspected that the cancer-causing agent \u2014 later shown to be a complication of HIV infection \u2014 was sexually transmitted, but lacked proof. His breakthrough came one day in April when three men from three different counties told Darrow that they had had sex with the same person: a French Canadian airline steward named Ga\u00e9tan Dugas. CDC researchers tracked down Dugas in New York City, where he was being treated for Kaposi\u2019s sarcoma. With his cooperation, the scientists definitively linked HIV and sexual activity 1 . They referred to Dugas as 'Patient Zero' in their study, and because of a misunderstanding by journalists and the public, the flight attendant became known as the person who brought HIV to the United States. Dugas and his family were vilified for years 2 . But an analysis of HIV using decades-old blood serum samples exonerates the French Canadian, who died in 1984. The paper 3 , published on 26 October in  Nature , shows that the virus had been circulating in North America since at least 1970, and that the disease arrived on the continent through the Caribbean from  Africa . Richard McKay, a historian at the University of Cambridge, UK, and study co-author, says that scientists have always questioned the idea of a single Patient Zero, because some evidence suggested that the virus entered North America several times. A team led by McKay and evolutionary biologist Michael Worobey at the University of Arizona in Tucson wanted a clearer picture of HIV\u2019s arrival. So the team collected more than 2,000 serum samples that health clinics had collected from gay men in 1978 and 1979 while testing for hepatitis B. The researchers found enough genetic traces of HIV that they could sequence in three samples from San Francisco and five from New York City.  \n             Earlier arrival \n           When scientists examined those genetic sequences in detail, they found them to be similar to HIV strains present in the Caribbean, particularly Haiti, in the early 1970s. However, the strains were different from one another, suggesting the virus had already been circulating and  mutating  in San Francisco and New York City since about 1970. Furthermore, Worobey\u2019s analysis of Dugas\u2019 own blood showed that the HIV strain that killed him didn\u2019t match the others. \u201cThere's just no indication that he was anything other than one of many people who were already infected before the disease was noticed,\u201d Worobey says. The latest study shows how easy it is to jump to conclusions about a virus that does not immediately cause disease, says Beatrice Hahn, a microbiologist at the University of Pennsylvania in Philadelphia. Researchers in the 1980s had not yet discovered HIV\u2019s long incubation period: it can stay in the body for ten years on average before making a person ill. The many symptoms associated with AIDS also made it difficult to diagnose. \n             A devastating understanding \n           \u201cThe history of diseases has always been, in part, that someone needs to be blamed,\u201d says Anthony Fauci, director of the National Institute for Allergy and Infectious Disease in Bethesda, Maryland. In the 1980s, it was particularly easy for the public to direct their  anger toward a 'promiscuous' gay man . Dugas was key to  researchers\u2019 efforts to understand HIV , and \u201cthere is something more than a little wrong with what has happened in terms of the popular imagination\u201d, Worobey says. Randy Shilts' 1987 book,  And the Band Played On , which suggested that the flight attendant deliberately spread the disease, was particularly damning. Dugas did still spread the disease, says a physician who treated him for Kaposi's sarcoma. He continued to have unprotected sex until he was too ill, citing the lack of hard evidence that he could spread the \u201dgay cancer\u201d, says Friedman-Kien. Many gay men at the time resisted the idea that unprotected sex spread HIV, says the dermatologist. \u201cIt was a very difficult thing \u2014 because they had fought so much for sexual freedom and for recognition and acceptance \u2014 to be told that every gay man is potentially a carrier of this terrible disease.\u201d The study is a lesson in how scientifically and ethically difficult it can be to identify a 'patient zero', says McKay. Dugas\u2019 story emphasizes that HIV was \u201cnot just a retrovirus undergoing change in some timeless void\u201d, he adds. The quest for scientific understanding of the disease had a very real impact on the man and his family. Read the related Editorial: ' How researchers cleared the name of HIV Patient Zero ' \n                   How researchers cleared the name of HIV Patient Zero 2016-Oct-26 \n                 \n                   South Africa ushers in a new era for HIV 2016-Jul-13 \n                 \n                   Homophobia and HIV research: Under siege 2014-May-14 \n                 \n                   HIV's history traced 2003-May-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20992", "url": "https://www.nature.com/articles/nature.2016.20992", "year": 2016, "authors": [{"name": "Brigitte Osterath"}], "parsed_as_year": "2006_or_before", "body": "Change to immune-system genes in indigenous Canadians linked to epidemic introduced by Europeans. Epidemics from Europe that killed thousands of indigenous Canadians in the nineteenth century have left their signatures in the genomes of the people living there today, researchers say. The Tsimshian people, who live in coastal British Columbia and Alaska and are among Canada\u2019s First Nations, suffered a severe population crash around the nineteenth century, as European colonizers brought diseases including smallpox to communities that had not acquired resistance. The population decline is documented in reports from the time and in oral histories. But it may also show up in changes in immune-system genes, say geneticists who sequenced the genomes of 25 Tsimshian people and compared them with the DNA of 25 people who lived in the same region between 6,000 and 1,000 years ago. The ancient DNA was obtained \u2014 with permission from Tsimshian communities \u2014 from corpses stored in the Canadian Museum of History in Gatineau.  \n             Selected for immunity \n           After analysing the ancient and modern genomes, the scientists were confident that they were following a single population through time. And when they compared the genomes, they spotted clear shifts in a particular class of human leukocyte antigen (HLA) gene, which is associated with immune-system reactions. Most of today's Tsimshians had different versions of the gene than their ancestors \u2014 implying that there had been a strong evolutionary pressure on the population to adapt to pathogens that had hit at some time in the past. The finding backs up what is widely believed, but study co-author John Lindo, a geneticist at the University of Chicago in Illinois, says he was surprised to see his expectations confirmed so clearly. \u201cI hadn\u2019t expected to see such a dramatic change between the two time periods,\u201d he says. By building a demographic model that assumed that the Tsimishian population had crashed at some point in the past 500 years after European contact, the researchers say the best explanation for their genetic data is a sudden population decline around 175 years ago, during the early-to-mid nineteenth century. Lindo and his colleagues extrapolated from the genetic pattern that the Tsimshian population may have shrunk by some 57% \u2014 reasonably close to historical accounts that suggest a 70% decrease due to a smallpox epidemic. Their results are published in  Nature Communications 1 . \u201cWe have always had these hypotheses: demographic collapse, responses to European-introduced diseases,\u201d says Jennifer Raff, an anthropologist at the University of Kansas in Lawrence. But it is valuable to use genetic data to show how populations responded to European colonization, she says. \n             Population participation \n           Raff, who also works with First Nations communities, mostly in the Arctic, is impressed with how the researchers involved Tsimshian people in the study. Scientists are  starting to heal rifts with indigenous communities  after a history of mistrust, in which researchers focusing on scientific results didn\u2019t give their study participants a say on what was done with genetic material and human remains. The latest study\u2019s lead author, anthropologist Ripan Malhi of the University of Illinois in Urbana, began to work with Tsimshians in 2007, and says he visits annually to communicate with research participants, Elders and First Nations governments. The paper has two Tsimshian co-authors who liaised with the Metlakatla First Nation Tsimshian community in British Columbia: Joycelynn Mitchell, and Barbara Petzelt. Petzelt also has an archaeology degree, and both have worked with researchers including Malhi on other DNA studies. \u201cRipan Malhi is one of the leaders in changing the relationship between genetic researchers and indigenous people,\u201d says Raff. \u201cHe is setting a standard of good ethical practices for the rest of us.\u201d \n                   Neanderthal DNA affects ethnic differences in immune response 2016-Oct-20 \n                 \n                   Geneticists attempt to heal rifts with Aboriginal communities 2016-Sep-21 \n                 \n                   Neanderthals had outsize effect on human biology 2015-Jul-29 \n                 Reprints and Permissions"},
{"file_id": "539340a", "url": "https://www.nature.com/articles/539340a", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Davide Vannoni is barred from offering a controversial stem-cell therapy in Italy but may be continuing his work abroad. Public prosecutors in Turin, Italy, are investigating whether disgraced stem-cell entrepreneur Davide Vannoni\u00a0\u2014\u00a0convicted on criminal charges last year for administering unproven stem-cell therapies in Italy\u00a0\u2014\u00a0is offering his treatments again, this time in eastern Europe. In March 2015, Vannoni was convicted on charges of conspiracy and fraud related to his treatments, which had been declared dangerous by the Italian Health Authority (AIFA). His case was a cause c\u00e9l\u00e8bre among Italian scientists,  who fought for many years to stop him administering stem cells to patients  through his Stamina Foundation (see  Nature 518, 455; 2015 ). Vannoni was sentenced to 22\u00a0months in prison, but the sentence was suspended in a plea bargain drawn up by prosecutor Raffaele Guariniello, who said that the terms required Vannoni to refrain from organizing further therapies\u00a0\u2014\u00a0either in Italy or abroad. Soon after the plea bargain, patient groups on social media posted comments that the stem-cell treatment was available once more, in Georgia. And in late October, a patient came forward with a detailed account of his treatment. Prosecutors told  Nature  that this has prompted them to take action. Vannoni did not respond to requests for comment, forwarded through his lawyer, Liborio Cataliotta. But Cataliotta told  Nature  that, although he did not know whether Vannoni was continuing therapies in Georgia, he thought there were \u201ctechnical defects\u201d in what Guariniello had said about the terms of the plea bargain. The prosecutor had no authority to rule on what might be carried out in countries where such stem-cell therapies are allowed, he said. Guariniello has since retired, but another prosecutor in Turin, Vincenzo Pacileo, told  Nature  that the deferred sentence hinges on the premise that Vannoni \u201cgives up\u201d his stem-cell activities, a phrase that Pacileo says implies both in Italy and abroad. However, a senior Italian legal expert who has read the 46-page sentence, but does not wish to be named, says that the premise is legally ambiguous. Nowhere does the document specify that this applies to activities abroad, he says. \u201cIt is really disappointing that science has not been able to put an end to this,\u201d says Luca Pani, a former director-general of AIFA. \u201cA patient is a patient wherever they are treated, and I worry for them and their families.\u201d Pani tried to close down Stamina\u2019s operations in Brescia in 2012, but desperate patients got court orders allowing them to be treated. It took two years before magistrates in Turin ordered the confiscation of equipment and materials from the Stamina lab. In July this year, the Italian news service ANSA reported that patients had claimed to have received the Stamina therapy in Georgia. It did not identify them or detail their clinical experience. But on 24 October, 52-year-old Andrea Zicchieri\u00a0appeared in a tell-all report on the Italian television news channel La7, complete with video documentation. Zicchieri, who has a motor-neuron disease, said he had paid \u20ac18,000 (US$20,000) for a cycle of three treatments in Tbilisi between July and September that had been arranged with Vannoni. Zicchieri told La7 that his brother had gone to Tbilisi in May to donate bone-marrow cells that were used in the treatment, and that Vannoni was present while the treatment was carried out. He said that the treatment had not worked. Zicchieri, who has now been called to give evidence to the police, repeated the same details to  Nature , providing screenshots of messages between himself and Vannoni, and adding that he had sought out Vannoni knowing that the treatment was controversial. \u201cEven if there was only 1% chance of hope, I wanted to take that chance,\u201d he said. His account is consistent with talk on the social-media accounts of patient groups that support Vannoni\u2019s work. According to photographs supplied by Zicchieri, the clinic was the Mardaleishvili Medical Center in Tbilisi, which also features on a patient-group site dedicated to the Stamina treatment. When  Nature  rang the centre for comment, a man said that Vannoni had been there and would return in January, and that all discussions about stem-cell therapy should go through Vannoni and not the clinic. He didn\u2019t answer on further attempts to make contact. Postings on two of Vannoni\u2019s Facebook pages\u00a0\u2014\u00a0previously reported in Italian media\u00a0\u2014\u00a0suggest that he is now working abroad. In February, in response to a question about his whereabouts, Vannoni posted that he was \u201cabroad to continue Stamina\u201d. On another page, he posted a message in June thanking people for their birthday wishes, and noting that \u201csometimes one must abandon a battle to win a war. In short\u00a0\u2014\u00a0to change one\u2019s country. #750.\u201d Underneath the post, commenters said that the #750 means that Vannoni is now claiming to have made 750 stem-cell infusions\u00a0\u2014\u00a0many more than he had made in Italy. (An earlier message, posted on 24 December 2015, ends \u201c#450\u201d). Vannoni\u2019s therapy involves modifying stem cells taken from the bone marrow of a patient or relative, and injecting them into the patient. In Italy, Vannoni has used this approach in people with a range of conditions, from Parkinson\u2019s disease to muscular dystrophy. Recent cases of similar treatments have led to cancers, notes Elena Cattaneo, a neuroscientist at Italy\u2019s University of Milan who was among those who worked to stop Vannoni and who is now an Italian senator. That Vannoni has apparently started again is \u201ca disgrace\u201d, she says. \u201cGovernments and health institutes should do more to inform patients about these sorts of therapies.\u201d \n                     Stem cells: Taking a stand against pseudoscience 2014-Jun-16 \n                   \n                     Leaked files slam stem-cell therapy 2014-Jan-07 \n                   \n                     Italian stem-cell trial based on flawed data 2013-Jul-02 \n                   Reprints and Permissions"},
{"file_id": "539151a", "url": "https://www.nature.com/articles/539151a", "year": 2016, "authors": [{"name": "Sara Reardon"}], "parsed_as_year": "2006_or_before", "body": "World Health Organization asks research initiatives to focus on translating their findings into clinical benefits. Major  brain-mapping projects have multiplied  in recent years, as neuroscientists  develop new technologies  to decipher how the brain works. These initiatives focus on understanding the brain, but the World Health Organization (WHO) wants to ensure that they work to translate their early discoveries and technological advances into tests and treatments for brain disorders. \u201cWe think there are side branches from projects that could be pursued with a very small investment to benefit public health,\u201d says Shekhar Saxena, director of the WHO\u2019s mental-health and substance-abuse department. Saxena will make that case on 12\u00a0November at the annual meeting of the Society for Neuroscience in San Diego, California \u2014 continuing a discussion that began in July at the WHO\u2019s headquarters in Geneva, Switzerland. Among the roughly 70\u00a0people who attended that first meeting were leaders of the major brain initiatives, including the  US BRAIN (Brain Research through Advancing Innovative Neurotechnologies) Initiative , launched in 2013; the European Human Brain Project, started in 2013; and the  Japanese Brain/MINDS project , launched in 2014. All of these projects focus on basic research on the brain or the development of sophisticated tools to study it. Clinical applications are an ultimate, rather than an immediate, goal. But at the Geneva meeting, project leaders agreed, in principle, that they should do more to adapt brain-imaging technologies for use in clinical diagnoses. \u201cThe WHO is concerned that the emphasis on building these very expensive devices could worsen the health disparities that we have now between the developed and underdeveloped world,\u201d says Walter Koroshetz, director of the US National Institute of Neurological Disorders and Stroke, which is part of the BRAIN Initiative. For instance, researchers funded by the BRAIN Initiative are developing imaging procedures to identify every connection in a mouse\u2019s brain, or watch neurons fire in a circuit in real time. Yet versions of these technologies that are suitable for use in humans are likely to be so expensive and difficult to use that they will be available only at a few research centres\u00a0\u2014 and not at the average US hospital, much less in low-income countries.\u00a0 Still, some researchers have found a sweet spot at which they can develop clinical imaging while working to understand the brain\u00a0\u2014 even when working with limited equipment in developing countries, Koroshetz says. Gretchen Birbeck, a neurologist at the University of Rochester in New York, is working in Zambia to understand how cerebral malaria can lead to epilepsy in children. She uses a magnetic resonance imaging (MRI) machine to watch how neural activity changes over time in the brains of children with malaria \u2014 and how, in some cases, epilepsy emerges. Using existing technology, \u201cwe can really drill down and ask some important scientific questions that would have implications much more broadly\u201d, Birbeck says. She hopes to do so despite using an MRI machine that is only about 10% as powerful as those in many US hospitals. The WHO meeting participants also noted that existing technologies \u2014 such as mobile phones, which are prevalent in many developing countries where doctors are not \u2014 can be used to apply research findings to public health. Farrah Mateen, a neurologist at Massachusetts General Hospital in Boston who attended the WHO\u2019s July meeting, has developed a cheap cap studded with electroencephalography sensors and an app that can identify the brain patterns that occur in people with epilepsy when they are between seizures. Her study of 205\u00a0people with epilepsy in Bhutan, now in review at a journal, showed that the app could reliably detect this neural activity \u2014 allowing health-care workers with little training to identify the type of epilepsy someone has and which drug could best treat it. But one big question looms over the WHO\u2019s push to ensure that brain\u2013mapping projects yield clinical benefits: the agency does not fund research. Instead, it hopes to convert private donors and governments to its way of thinking. \u201cWe\u2019re just going to try to influence the scientists as well as the funders to see whether there could be a better balance between long-term outcomes and more short-term, public-health-oriented outcomes,\u201d says Saxena. Not everyone is ready to reset their priorities. Tetsuo Yamamori, a neuroscientist at RIKEN Brain Institute in Saitama and vice project leader of the Brain/MINDS project, says that its primary goal will remain the same: linking behaviour to mapping brain activity in genetically engineered marmosets. But he agrees that developers of cutting-edge technologies should consider how they could be used in people. Yamamori adds that he will continue to participate in the WHO\u2019s brain-mapping discussions. Saxena is optimistic that the WHO\u2019s lobbying will pay off. Eventually, he hopes to establish a network of researchers working to transform advances in brain research to improvements in medicine. \u201cWe really don\u2019t understand this organ,\u201d he says. \u201cWe need to make incremental advancements, and those need to be translated into something actionable in a short time.\u201d \n                     Worldwide brain-mapping project sparks excitement \u2014 and concern 2016-Sep-21 \n                   \n                     Marmosets are stars of Japan\u2019s ambitious brain project 2014-Oct-08 \n                   \n                     Neuroscience: Where is the brain in the Human Brain Project? 2014-Sep-03 \n                   \n                     The benefits of brain mapping 2013-Jul-17 \n                   \n                     Society for Neuroscience lectures \n                   Reprints and Permissions"},
{"file_id": "539147a", "url": "https://www.nature.com/articles/539147a", "year": 2016, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Barrage of proposals would allow developers to sidestep environmental reviews. Environmentalists in Brazil are feeling the heat. Conservative lawmakers want to weaken the country\u2019s environmental regulations to clear the way for rapid development of energy facilities, mines and agriculture \u2014 in the Amazon and beyond. Their push comes  at a time of economic and political turmoil  following the impeachment in August of former President Dilma Rousseff. \u201cIt\u2019s an offensive against our regulatory system,\u201d says Mauricio Guetta, an attorney with the Socio-Environmental Institute, an advocacy group in S\u00e3o Paulo. More than 20 legislative proposals are circulating in the Brazilian Congress to loosen regulations governing activities such as building roads and hydroelectric dams or expanding agricultural businesses. One proposed constitutional amendment would ensure approval of a project once its developers have submitted an environmental-impact analysis \u2014 essentially eliminating government review. That proposal has stalled in the Senate, but the government of President Michel Temer is developing its own legislation to overhaul the environmental-licensing system, which many consider ineffective. \u201cSomething will happen, most probably in the\u00a0wrong direction,\u201d says Nilvo Silva, a former head of the licensing division of the Brazilian Institute of Environment and Renewable Natural Resources, an environmental-enforcement agency. The debate comes  during Brazil\u2019s worst recession in decades , and follows corruption scandals that brought down Rousseff and her leftist Workers\u2019 Party. The Brazilian Democratic Movement Party has taken the reins but it, too, has been tainted. Several cabinet members have resigned, and corruption investigations are continuing \u2014 with Temer in the crosshairs. The embattled president has promised to maintain Brazil\u2019s environmental agenda, including  its commitments under the Paris climate agreement . But agricultural and business interests are pushing back against environmental protections set by the Workers\u2019 Party under Rousseff\u2019s predecessor, Luiz In\u00e1cio Lula da Silva, endangering more than a decade of  progress on issues such as deforestation . \u201cThey keep paying lip service to environmental issues, but we can\u2019t be confident in the implementation of policies,\u201d says Paulo Barreto, a senior researcher at the Amazon Institute of People and the Environment, an activist group in Bel\u00e9m. Much of the concern centres on the Amazon, where the rate of forest loss has increased by nearly 36% since 2012. More than 6,200 square kilometres of land were cleared for agriculture in 2015, and many expect that number to increase when the 2016 data are released next week. The deforestation helped to increase Brazil\u2019s overall\u00a0greenhouse-gas emissions by\u00a03.5% in 2015, even as emissions from the energy sector fell, according to a 27\u00a0October report by the Climate Observatory, a coalition of advocacy groups in S\u00e3o Paulo. Brazil\u2019s environment minister, Jos\u00e9 Sarney Filho, says that some people may be taking advantage of the political crisis to clear forest. The government has responded by bolstering funding to enforce existing laws. \u201cWe expect that we will once more be on the right track of reducing deforestation,\u201d he adds. Barreto says that part of the problem stems from changes to Brazil\u2019s forest law in 2012 that weakened rules and let many landowners off the hook for past violations. The latest efforts to streamline the environmental licensing system would further advance that agenda. One project that could be fast-tracked if the latest regulatory changes take effect is the proposed Volta Grande mine on the Xingu River in the Amazonian state of Par\u00e1, near the controversial Belo Monte hydroelectric dam. The Volta Grande project, which would be Brazil\u2019s largest gold mine, is facing legal challenges from independent prosecutors who say that the government\u2019s analysis of its social and environmental impacts was flawed. But it would be difficult to fight such projects in the courts if the proposed constitutional amendment were enacted, says Raffael T\u00f3foli, an ecologist at the State University of Maring\u00e1. Many scientists and environmentalists acknowledge that Brazil\u2019s regulatory system is slow and often ineffective. The solution is to improve environmental assessments, increase public participation in environmental reviews and give regulators more resources, says Luis S\u00e1nchez, an engineer at the University of S\u00e3o Paulo who conducts environmental assessments. \u201cThis is something that could be solved without changing the law,\u201d he says. It\u2019s not yet clear what solutions Temer\u2019s government will propose. Green groups say that the environment ministry\u2019s first draft of a proposal to reform the licensing process expanded the focus from individual projects to the social and environmental effects of development across an entire landscape. But that proposal is now circulating among other ministries that oversee activities such as mining, energy and infrastructure, and some observers say that the latest leaked drafts show that the plan is being watered down with concessions to industry. \u201cWe are all waiting for the government to present this bill,\u201d says Guetta, \u201cbut we are seeing the text get worse every day.\u201d See  Editorial . \n                     Warning to forest destroyers: this scientist will catch you 2016-Oct-04 \n                   \n                     Dry Amazon could see record fire season 2016-Jun-29 \n                   \n                     Forests in spotlight at Paris climate talks 2015-Dec-01 \n                   \n                     Brazil set to cut forest protection 2012-May-01 \n                   \n                     A struggle for power 2011-Nov-09 \n                   \n                     Brazil\u2019s National Institute for Space Research \n                   \n                     World Resources Institute\u2019s Paris Commitment tracker \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20953", "url": "https://www.nature.com/articles/nature.2016.20953", "year": 2016, "authors": [{"name": "Brigitte Osterath"}], "parsed_as_year": "2006_or_before", "body": "Carbon-dating study suggests governments are not fuelling trade by selling off old tusks. The illegal ivory trade is fuelled almost entirely by elephants that have been recently killed, say researchers who carbon-dated hundreds of ivory tusks seized by law-enforcement officials. \"That puts to rest a speculation which has been at the back of everyone\u2019s mind,\u201d says George Wittemyer, a conservation ecologist and elephant specialist at Colorado State University in Fort Collins. Some had wondered whether corrupt governments were contributing to the ivory trade by selling off old ivory, bit by bit, from stockpiles built up over years. Now, conservationists can concentrate their resources on protecting elephants from poachers, he says, rather than worrying so much about fighting government corruption. Thure Cerling at the University of Utah in Salt Lake City and his colleagues measured the decay of carbon-14 isotopes in 231 ivory tusks, confiscated between 2002 and 2014, to determine when the elephants they were taken from had died. According to their analysis, published on 8 November in the  Proceedings of the National Academy of Sciences 1 , only four specimens were more than five years old at the time they were seized. By combining their measurements with earlier analysis of the tusks\u2019 DNA 2 , the researchers were able to tell where the poached elephants had lived. In East Africa, the seized ivory mostly derived from elephants that were killed less than one year ago. Ivory from Central Africa, however, was on average more than two years old. \u201cThat makes sense,\u201d says Tom Milliken at the wildlife-monitoring network TRAFFIC, based in Cambridge, UK. The road network in East Africa is much better than in Central or West Africa, so poachers can get the tusks to the coast faster to ship them to Asia, he says. The study confirms what many researchers already assumed, but the study is welcome, Miliken adds. \u201cIt helps us to understand fundamental dynamics in ivory trafficking.\u201d As prices for ivory have soared over the past decade \u2014 particularly in east Asian auction markets \u2014 Africa\u2019s elephant population has dropped: falling from 526,000 to 415,000 between 2006 and 2015, according to the International Union for Conservation of Nature\u2019s latest African Elephant Status Report. Tanzania alone has lost 60% of its elephants in the past three years because of poaching, Milliken says. In Africa, countries are strengthening protections: Tanzania, for example, has increased penalties for poaching and ivory trafficking and has prosecuted large-scale ivory traffickers with long prison sentences. Elsewhere, China introduced  restrictions on ivory trade  last year, and delegates at a meeting of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) last month voted for a non-binding agreement to  close remaining legal domestic ivory markets . But it is not yet clear whether these measures are cutting down poaching. \u201cI am sure we are not out of the woods yet,\u201d Milliken says. \n                   Will China\u2019s new ivory controls make a difference? 2015-Jun-03 \n                 \n                   African elephant numbers collapsing 2014-Aug-19 \n                 \n                   Wildlife trade meeting endorses DNA testing of seized ivory 2013-Mar-14 \n                 \n                   Tusk tracking will tackle illegal trade 2013-Feb-27 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.19136", "url": "https://www.nature.com/articles/nature.2016.19136", "year": 2016, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Decades-old assumption about microbiota revisited. It's often said that the bacteria and other microbes in our body outnumber our own cells by about ten to one. That's a myth that should be forgotten, say researchers in Israel and Canada. The ratio between resident microbes and human cells is more likely to be one-to-one, they calculate. A 'reference man' (one who is 70 kilograms, 20\u201330 years old and 1.7 metres tall) contains on average about 30 trillion human cells and 39 trillion bacteria, say Ron Milo and Ron Sender at the Weizmann Institute of Science in Rehovot, Israel, and Shai Fuchs at the Hospital for Sick Children in Toronto, Canada. Those numbers are approximate \u2014 another person might have half as many or twice as many bacteria, for example \u2014 but far from the 10:1 ratio commonly assumed. \u201cThe numbers are similar enough that each defecation event may flip the ratio to favour human cells over bacteria,\u201d they delicately conclude in a manuscript posted to the preprint server bioRxiv 1 . The 10:1 myth persisted from a 1972 estimate by microbiologist Thomas Luckey, which was \u201celegantly performed, yet was probably never meant to be widely quoted decades later\u201d, say the paper\u2019s authors. In 2014, molecular biologist Judah Rosner at the US National Institutes of Health at Bethesda,  expressed his doubts  about the 10:1 claim, noting that there were very few good estimates for the numbers of human and microbial cells in the body. Milo, Sender and Fuchs decided to re-estimate the number by reviewing a wide range of recent experimental data in the literature, including DNA analyses to calculate cell number and magnetic-resonance imaging to calculate organ volume. The vast majority of human cells are red blood cells, they note (see 'Counting human cells'). \n             Faecal factor \n           A particular overestimate in Luckey\u2019s work relates to the proportion of bacteria in our guts, Milo and colleagues say. Luckey estimated that guts contain around 10 14  bacteria, by assuming that there were 10 11  bacteria in a gram of faeces, and scaling that up by the one-litre volume of the alimentary canal, which stretches from the mouth to the anus. But most bacteria reside only in the colon (which has a volume of 0.4 litres), Milo and colleagues point out \u2014 and measurements suggest that there are fewer bacteria in stool samples than Luckey thought. Putting together these kinds of calculations, the researchers produce a ratio for microbial to human cells for the average man of 1.3:1, with a wide uncertainty. Milo declined to comment on the paper, because it is in review at a scientific journal. \u201cIt is good that we all now have a better estimate to quote,\u201d says Peer Bork, a bioinformatician at the European Molecular Biology Laboratory in Heidelberg, Germany, who works on the human and other complex microbiomes. \u201cBut I don\u2019t think it will actually have any biological significance.\u201d \n               Tweet \n               Follow @NatureNews \n             \n                   My digital toolbox: back-of-the-envelope biology 2015-Mar-20 \n                 \n                   Microbiome science threatened by contamination 2014-Nov-12 \n                 \n                   Sugar substitutes linked to obesity 2014-Sep-17 \n                 \n                   Vaginal microbe yields novel antibiotic 2014-Sep-11 \n                 \n                   Microbiome therapy gains market traction 2014-May-13 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.20988", "url": "https://www.nature.com/articles/nature.2016.20988", "year": 2016, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "The move by Chinese scientists could spark a biomedical duel between China and the United States. A Chinese group has become the first to inject a person with cells that contain genes edited using the revolutionary CRISPR\u2013Cas9 technique. On 28 October, a team led by oncologist Lu You at Sichuan University in Chengdu delivered the modified cells into a patient with aggressive lung cancer as part of a  clinical trial  at the West China Hospital, also in Chengdu. Earlier clinical trials using  cells edited with a different technique  have excited clinicians. The introduction of CRISPR, which is simpler and more efficient than other techniques, will probably accelerate the  race to get gene-edited cells into the clinic  across the world, says Carl June, who specializes in immunotherapy at the University of Pennsylvania in Philadelphia and led one of the earlier studies. \"I think this is going to trigger \u2018Sputnik 2.0\u2019, a biomedical duel on progress between China and the United States, which is important since competition usually improves the end product,\u201d he says. June is the scientific adviser for a  planned US trial  that will use CRISPR to target three genes in participants\u2019 cells, with the goal of treating various cancers. He expects the trial to start in early 2017. And in March 2017, a group at Peking University in Beijing hopes to start three clinical trials using CRISPR against  bladder ,  prostate  and  renal-cell  cancers. Those trials do not yet have approval or funding. \n               Protein target \n             Lu\u2019s trial  received ethical approval from a hospital review board in July . Injections into participants were supposed to begin in August but the date was pushed back, Lu says, because culturing and amplifying the cells took longer than expected and then the team ran into China\u2019s October holidays.\u00a0 The researchers removed immune cells from the recipient\u2019s blood and then disabled a gene in them using  CRISPR\u2013Cas9 , which combines a DNA-cutting enzyme with a molecular guide that can be programmed to tell the enzyme precisely where to cut. The disabled gene codes for the protein PD-1, which normally puts the brakes on a cell\u2019s immune response: cancers take advantage of that function to proliferate. Lu\u2019s team then cultured the edited cells, increasing their number, and injected them back into the patient, who has metastatic non-small-cell lung cancer. The hope is that, without PD-1, the edited cells will attack and defeat the cancer. \n               Safety first \n             Lu says that the treatment went smoothly, and that the participant will get a second injection, but declined to give details because of patient confidentiality. The team plans to treat a total of ten people, who will each receive either two, three or four injections. It is primarily a safety trial, and participants will be monitored for six months to determine whether the injections are causing serious adverse effects. Lu\u2019s team will also watch them beyond that time to see if they seem to be benefiting from the treatment. Other oncologists are excited about CRISPR\u2019s entry onto the cancer scene. \u201cThe technology to be able to do this is incredible,\u201d says Naiyer Rizvi of Columbia University Medical Center in New York City. Antonio Russo of Palermo University in Italy notes that antibodies that neutralize PD-1 have successfully put lung cancer in check, boding well for a CRISPR-enabled attack on the protein. \u201cIt\u2019s an exciting strategy,\u201d he says. \u201cThe rationale is strong.\u201d But Rizvi questions whether this particular trial will succeed. The process of extracting, genetically modifying and multiplying cells is \u201ca huge undertaking and not very scalable\u201d, he says. \u201cUnless it shows a large gain in efficacy, it will be hard to justify moving forward.\u201d He doubts it will be superior to the use of antibodies, which can be expanded to unlimited quantities in the clinic.\u00a0Lu says that this question is being evaluated in the trial, but that it\u2019s too early to say which approach is better. \n                 Tweet \n                 Facebook \n                 LinkedIn \n                 Weibo \n                 Wechat \n               \n                     Chinese scientists to pioneer first human CRISPR trial 2016-Jul-21 \n                   \n                     First CRISPR clinical trial gets green light from US panel 2016-Jun-22 \n                   \n                     Leukaemia success heralds wave of gene-editing therapies 2015-Nov-05 \n                   \n                     Where in the world could the first CRISPR baby be born? 2015-Oct-13 \n                   \n                     CRISPR, the disruptor 2015-Jun-03 \n                   \n                     CRISPR: The good, the bad and the unknown \n                   Reprints and Permissions"},
{"file_id": "nature.2016.20986", "url": "https://www.nature.com/articles/nature.2016.20986", "year": 2016, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Researchers worry about misinforming people about the risk of disease. What started as a summer science project soon turned into a family medical crisis for geneticist Heidi Rehm. In July, she ordered a test to sequence her 14-year-old daughter\u2019s DNA, hoping to find a genetic explanation for why one of the girl\u2019s adult teeth hadn\u2019t emerged. Instead, mother and daughter found that they both carried a genetic mutation linked to dilated cardiomyopathy \u2014 a heart-muscle abnormality that can lead to sudden death, especially in adults. After consulting a cardiologist and investigating her family\u2019s mutation \u2014 which had been seen only in people with diagnosed cardiomyopathy \u2014 Rehm found that it might not be as lethal as it had first seemed. Her story shows how far genetic sequencing still has to go before it becomes a routine part of medical care. Although scientists are using sequencing to  save sick people\u2019s lives , many still question whether it helps those without a diagnosis. Because most genes linked to disease were discovered in ill people and their families, geneticists don\u2019t have an accurate understanding of how mutations behave in people who are not obviously sick. \u201cThis is a fascinating flashpoint in the field right now,\u201d says Robert Green, a geneticist at Brigham and Women\u2019s Hospital in Boston, Massachusetts. \u201cMany people are deeply concerned that widespread screening of ostensibly healthy people could actually lead to harm.\u201d Green is an organizer of the Understand Your Genome conference, due to take place on 15 November in Boston, which will bring together scientists and physicians to debate such issues. About 40 of the 140 attendees paid US$2,900 to have the protein-coding portions of their genomes sequenced by Illumina of San Diego, California \u2014 giving them a personal connection to concerns about misdiagnoses. \n             Perfect storm \n           Concerns about the potential harm in sequencing the genomes of healthy people come as new companies  vie to provide such services  for the general public. In August, researchers reported that the average person carries about 54 genetic mutations that are considered lethal, but that  don\u2019t seem to harm  their health. As a result, physicians don\u2019t know what to tell healthy people who harbour these variants.Some people have received erroneous information as a result, says physician and bioinformaticist Isaac Kohane at Harvard Medical School in Boston. He led a team that reported in August that some African American people had wrongly been told a decade ago that they harboured genetic mutations that increased their risk of developing hypertrophic cardiomopathy, a potentially fatal thickening of the heart muscle. Geneticists later sequenced many more African Americans, and realized that the genetic variants were too common in this population to be harmful 1 . \u201cWe really have a perfect storm of insufficient data and insufficient competence,\u201d says Kohane, who adds that physicians aren\u2019t yet prepared to handle genetic test results of this type. Green and other researchers are trying to remedy the information deficit. In a study published on 9 November in  Science Translational Medicine , for instance, Green\u2019s team found that people who carry genetic variants linked to heart disease and cancer are four to six times more likely to develop those conditions, regardless of their family history of the diseases. Green says the study is important because it\u2019s one of the first times that scientists know how much a mutation might increase the risk of a disease in a family with no known history of it 2 . \u201cI\u2019m often in a position of sitting with a family, and they say, \u2018How much does this increase my risk?\u2019,\u201d Green says. \u201cIt\u2019s something we have virtually no data on in the general population.\u201d \n             Insurance concerns \n           Rehm faced precisely that situation when she found out about her family\u2019s mutation. It involves a switch of one DNA base for another in the  MYH7  gene, which encodes a heart-muscle protein, and had only ever been seen in patients with the disease. When Rehm hunted down reports of people with the same variant, she found that it does run in families with cardiomyopathy. But she also discovered that her own mother also carries the variant, and has normal heart function, as does Rehm. This suggests that the variant has what geneticists call incomplete penetrance: it is capable of causing severe disease in some families, yet is harmless in others.It\u2019s not clear what Rehm and her daughter should do with the information. Rehm hasn\u2019t had her daughter\u2019s heart tested yet, because symptoms of cardiomyopathy usually don\u2019t appear until adulthood. But she is concerned about the girl's future. If her daughter\u2019s medical record states that she carries a potentially fatal genetic mutation, she may not be able to buy life, health or long-term disability insurance, because she might be considered a high-risk customer. The election of Donald Trump as US president also concerns Rehm, because Trump has pledged to repeal \u2018Obamacare\u2019, the US health law that compels insurers to offer coverage to people with diagnosed medical conditions.\u201cIt\u2019s very likely to be used against her if Trump repeals Obamacare,\u201d Rehm says.Rehm adds, though, that she and her daughter are not concerned about their own health. Rehm says that she will probably check in with a cardiologist every few years, but doesn\u2019t expect the discovery of the mutation to change the way she lives her life. \u201cPeople deal with uncertainty all the time, and they usually deal with it quite well,\u201d she says. \n                   A radical revision of human genetics 2016-Oct-12 \n                 \n                   US regulators try to tame 'wild west' of DNA testing 2015-Feb-20 \n                 \n                   Sequencing set to alter clinical landscape 2012-Feb-15 \n                 Reprints and Permissions"},
{"file_id": "540019a", "url": "https://www.nature.com/articles/540019a", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Next generation of Trojan-horse drugs designed to minimize damage to healthy cells. After decades of frustration, efforts to develop antibodies that can ferry drugs into cancer cells \u2014 and minimize damage to healthy tissue \u2014 are gathering steam. The next generation of these \u2018weaponized antibody\u2019 therapies, called antibody\u2013drug conjugates (ADCs), is working its way through clinical trials. Researchers will gather to discuss this renaissance on 30\u00a0November at the Symposium on Molecular Targets and Cancer Therapeutics in Munich, Germany. The improvements come after the first wave of experimental ADCs failed to deliver on its promise. \u201cInitially there was a lot of excitement, and then slowly many of them did not work,\u201d says Raffit Hassan, a cancer researcher at the US National Cancer Institute in Bethesda, Maryland. Now, he says, there are two new ADCs in phase III clinical trials, and many more in earlier-stage testing. The concept that underlies these drugs is simple: repurposing an antibody as a vehicle to deliver a toxic drug into a cancer cell. When the antibody in an ADC seeks out and docks onto a tumour cell, the cell takes it up and cleaves the molecular links that bind the drug to the antibody. This frees the drug to kill the cell from within. But this approach has proved tricky to realize. Sometimes the molecular linkers are too tight, and do not release the drug inside the cell. Sometimes they are too unstable, and release the drug near healthy cells \u2014 limiting the dose that can be administered. Even the drugs themselves can be problematic: because most are toxic mainly to rapidly dividing cells, they can leave behind  the slowly dividing cells that seed some tumours . And some have had trouble penetrating more than a few cell layers into their target tumours. Researchers have been chasing ADCs for decades, Hassan says. The US Food and Drug Administration has approved three, but one was subsequently withdrawn from the market amid concerns that it was not effective and posed safety risks. The other two have met a happier fate: sales of Adcetris (brentuximab vedotin),  approved in 2011 to treat lymphoma , and Kadcyla (trastuzumab emtansine), approved in 2013 to treat breast cancer, have been encouraging, says Ryan Million, head of the San Francisco office of the life-sciences and health-care consultancy firm Trinity Partners. The approvals gave investors confidence in the field and sent researchers into a frenzy to improve their designs. More than 40 ADCs are now in clinical testing. Genentech, the biotechnology firm in South San Francisco, California, that developed Kadcyla, is experimenting with alternative drugs and molecular linkers. \u201cChemistry efforts have gotten more sophisticated in making decisions about which linker will go with each drug,\u201d says Bernard Fine, a group medical director at the firm. The company is now working on nine ADCs. Researchers are also mining a wealth of data from cancer-sequencing projects in search of new targets for antibodies to latch onto, says St\u00e9phane Depil, medical director of the cancer immunotherapy programme at the Centre L\u00e9on B\u00e9rard in Lyon, France. Identifying those that are unique, or nearly so, to cancer cells has been a major challenge, he says. But growing interest in  harnessing the immune system  has led researchers to catalogue unique proteins expressed on the surface of malignant cells. Some companies are trying to hit familiar targets with entirely new designs. Mersana Therapeutics, a biotechnology firm in Cambridge, Massachusetts, has attached both an antibody and a drug to a biodegradable polymer, rather than linking them to each other. This allows the company to attach 15 molecules of the drug to each polymer, rather than the usual three or four, says chief scientific officer Timothy Lowinger. Mersana is testing its approach in early clinical trials of a drug conjugate that targets HER2, a protein expressed at high levels in some breast-cancer tumours. Kadcyla targets HER2, too, but Lowinger says that Mersana\u2019s version can bring in more drug per target, so it could be useful against cancers that express only low levels of HER2. And at Tarveda Therapeutics, a biotechnology company in Watertown, Massachusetts, researchers have dispensed with the antibody altogether. Instead they are using a short strand of amino acids, the building blocks of proteins, to target cancer cells. The result is a drug that is about 15 times smaller and likely to penetrate deeper into the tumour, says Richard Wooster, Tarveda\u2019s president of research and development. Even with all this activity, the technology has not reached its peak, says Million. \u201cThere\u2019s still lots to innovate,\u201d he says. \u201cBut when it works, I think it will work powerfully.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @heidiledford \n               \n                     Safety concerns blight promising cancer therapy 2016-Oct-12 \n                   \n                     Cancer experts unveil wishlist for US government \u2018moonshot\u2019 2016-Sep-07 \n                   \n                     Toxic antibodies blitz tumours 2011-Aug-22 \n                   Reprints and Permissions"},
{"file_id": "540018a", "url": "https://www.nature.com/articles/540018a", "year": 2016, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "British team is first to seek site of 1.5-million-year-old sample. As the short Antarctic spring ends and long summer days approach, geo\u00adscientists are flocking to the frozen continent to start a new kind of exploration. In December, the first drill designed to search for a scientifically useful sample of ice that is at least 1.5\u00a0million years old will begin its work. It is part of a broader effort to locate the best place to extract a core containing Earth\u2019s oldest ice, which would help to reveal how climate has shaped the planet\u2019s past and how to predict future fluctuations. \u201cThis exciting field season should bring us a large step nearer to deciding where to drill the oldest-ice core,\u201d says Olaf Eisen, a glaciologist at the Alfred Wegener Institute of Polar and Marine Research in Bremerhaven, Germany, who coordinates an exploration team funded by the European Union. More than a decade ago, the European Project for Ice Coring in Antarctica (EPICA) drilled the oldest existing core, which contains 800,000-year-old ice, from an ice dome in East Antarctica known as Dome C. The core reaches only as far back as the latter part of the Pleistocene epoch, when Earth began cycling between warm and cold periods every 100,000\u00a0years. Before 1\u00a0million years ago, the cycle occurred every 40,000\u00a0years ( L.\u00a0E. Lisiecki and M. E. Raymo  Paleoceanography    20,  PA1003; 2005 ), so scientists want an ice core that is twice as old as EPICA to better understand this transition. Digging such a core would cost about US$50\u00a0million and take several years, so researchers want to be sure that the location is optimal \u2014 with ice that is sufficiently deep but not melted at the bottom by geothermal activity. \u201cIt\u2019s absolutely crucial to thoroughly investigate all options,\u201d says Eisen. Enter a new breed of drill,  designed to do fast, cheap reconnaissance  instead of extracting a single, intact ice core, as previous deep drills have done. One promising location, \u2018little Dome\u00a0C\u2019, lies just 40 kilometres away from the EPICA site\u00a0\u2014\u00a0and is where the \u00a3500,000 (US$620,000) Rapid Access Isotope Drill (RAID) will start boring this month, led by climate scientist Robert Mulvaney of the British Antarctic Survey in Cambridge, UK. A narrow drill, RAID will excavate to 600\u00a0metres in about 7\u00a0days\u00a0\u2014\u00a0compared with 5\u00a0years for a 3.4-kilometre core such as EPICA\u2019s. And rather than extract a core, RAID will measure the ice\u2019s temperature and collect chips of ice. Scientists will then comb these for clues from isotopes as to the age and temperature of the ice at the bottom of the sheet.  You cannot trust a single core.  A more expensive reconnaissance instrument, which will do its first drilling tests this season at Dome\u00a0C, should be ready to take a deeper look next year. Led by glaciologist J\u00e9r\u00f4me Chappellaz of Joseph Fourier University in Grenoble, France, the \u20ac3.2-million (US$3.4-million) SUBGLACIOR probe, which is about the same width as RAID, can penetrate the more than 3-kilometre-thick ice sheet in a single season. Both the UK and French drilling projects are funded as part of the EU collaboration. But also this season, a US team led by climatologist Jeffrey Severinghaus of the Scripps Institution of Oceanography in La Jolla, California, and John Goodge of the University of Minnesota, Duluth, will test the $10.5-million Rapid Access Ice Drill (also abbreviated RAID) at Minna Bluff, near the US McMurdo Station on Ross Island. Producing a hole of about 8 centimetres \u2014 similar to the boreholes of the other drills \u2014 it is the only rapid drill that can extract rocks from the bottom of a core. Next Antarctic summer, the team will begin its hunt for the site of a 1.5-million-year-old core. Dome\u00a0C is one option for its first excavation. Another is the relatively unexplored Dome\u00a0F in Antarctica\u2019s Queen Maud Land, which ground-based radar suggests is a promising candidate (see \u2018Ice search\u2019). In January, a German team will run reconnaissance flights there. Funded by the same European grant as the UK RAID and SUBGLACIOR drills, this radar survey will give a more comprehensive view of the ice thickness. Severinghaus says that his team will watch for the data when deciding where to point the US RAID. Both the US and European teams are working under an umbrella group. The International Partnerships in Ice Core Sciences (IPICS) aims to identify a suitable site to drill a core representing Antarctica\u2019s oldest ice\u00a0in the next two years. That drilling could start by the end of 2020, says Eisen. But how the international teams would work together on a joint project, or share funding, is unclear. There\u2019s a possibility that a record-breaking ancient core could show up sooner. For several years, scientists at the Polar Research Institute of China in Shanghai, who are also members of IPICS, have been probing the ice sheet that covers Dome\u00a0A, a plateau close to the centre of the Antarctic continent. Using a conventional corer rather than a rapid exploratory drill, they are working on obtaining a deep, intact ice core from the region, says Eisen\u00a0\u2014\u00a0and it is possible that it could stretch back to 1.5\u00a0million years. Such a surprise success would increase pressure on teams from other nations to produce their own record, he says. Multiple cores would benefit science. \u201cWe would carry on with our project,\u201d says Eisen. The IPICS effort would ideally excavate multiple 1.5-million-year-old cores in any case. \u201cYou cannot trust a single core,\u201d says Severinghaus. \u201cWe absolutely need different records from different thermal regimes.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @tomboy180463 \n               \n                     The ultimate experiment: How Trump will handle science 2016-Nov-11 \n                   \n                     World\u2019s largest marine reserve hailed as diplomatic breakthrough 2016-Oct-28 \n                   \n                     Super-fast Antarctic drills ready to hunt for oldest ice 2015-Oct-28 \n                   \n                     Lakes under the ice: Antarctica\u2019s secret garden 2014-Aug-20 \n                   \n                     Sediment cores reveal Antarctica's warmer past 2008-Apr-24 \n                   \n                     Nature  Web Focus: EPICA Dome C \n                   \n                     EU Beyond EPICA programme \n                   \n                     International Partnership in Ice Core Sciences \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21098", "url": "https://www.nature.com/articles/nature.2016.21098", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "Two studies illuminate how the northern ice sheet waxed and waned over millions of years. Evidence buried in Greenland's bedrock shows the island's massive ice sheet melted nearly completely at least once in the last 2.6 million years. This suggests that Greenland's ice may be less stable than previously believed. \u201cOur study puts Greenland back on the endangered ice-sheet map,\u201d says Joerg Schaefer, a palaeoclimatologist at the Lamont-Doherty Earth Observatory in Palisades, New York, and co-author of a paper published on 7 December in  Nature 1 . A second paper in the same issue paints a slightly different view of the ice sheet\u2019s past stability 2 . A group led by Paul Bierman, a geomorphologist at the University of Vermont in Burlington, found that ice covered eastern Greenland for all of the past 7.5 million years. Experts say the two papers do not necessarily contradict one another: at times, nearly all of Greenland's ice could have melted (as seen by Schaefer's team) while a frosty cap remained in the eastern highlands (as seen by Bierman's group). If  all of Greenland's ice melted , it would raise sea levels by seven metres. Models suggest that Greenland could become ice-free as soon as 2,500 years from now, depending on the concentration of greenhouse gases in the atmosphere 3 . The latest papers add to a growing understanding of  how Greenland\u2019s ice has shifted  over millions of years. Both studies used radioactive isotopes of beryllium and aluminium to estimate how long the island's bedrock was exposed to the atmosphere \u2014 as cosmic rays pummel rock, they produce radionuclides such as beryllium-10 and aluminium-26. By counting those radionuclides in the topmost rock, researchers can estimate how long the surface was exposed to cosmic rays \u2014 that is, not shielded by thick ice. Schaefer\u2019s team analysed bedrock collected from the very bottom of the hole drilled for the GISP2 ice core, which was completed in central Greenland in 1993. \u201cWe just asked the surface, 'Have you been ice free or not?'\u201d says Schaefer. \u201cIt clearly told us, 'I have been ice free.'\u201d \n             Hidden history \n           Because the radionuclide history can be interpreted in different ways, the researchers cannot say exactly when the bedrock would have been exposed, or for how long. \u201cThat's a big drawback,\u201d says Anders Carlson, a palaeoclimatologist at Oregon State University in Corvallis who has studied ice-sheet history in south Greenland 4 . \u201cIf they could have gotten the timing of when it was ice-free, that would have been really cool.\u201d One possibility, says Schaefer, is that Greenland was ice-free for at least 280,000 years, starting more than 1.1 million years ago. The second study suggests that most of the ice sheet hung around for all of the last 7.5 million years. Bierman and his colleagues studied radionuclides in marine sediments off the east coast of Greenland, which had been washed off as glaciers ground through the underlying bedrock. Using a similar method to determine exposure ages, Bierman\u2019s team concluded that glaciers eroded eastern Greenland through the entire time period. Model simulations show that if the ice sheet shrinks to about 5\u201310% of its current extent, it would leave the GISP2 location bare while still coating parts of east Greenland. Both studies are consistent with Greenland having an ice sheet that grew to full size about 1.1 million years ago, says Dorthe Dahl-Jensen, a palaeoclimatologist at the University of Copenhagen in Denmark who has studied how  Greenland's ice persisted through a warm spell 130,000 to 115,000 years ago. Bierman compares the two papers to the parable of blind men feeling an elephant. \u201cThey have the tip of the tusk, and we have a large side of the flank,\u201d he says. \u201cTogether they can really inform each other.\u201d A new class of rapid-access ice drills under development  could accelerate discovery by providing more samples from the bottom of the ice sheet, says Michael Bender, a geologist at Princeton University in New Jersey. Earlier this year, he and his colleagues reported the ice at the bottom of a different Greenland ice core, known as GRIP, was at least 1 million years old 5 . That, too, supports the idea that Greenland's ice has been stable for at least the past million years. \n                   180,000 forgotten photos reveal the future of Greenland\u2019s ice 2016-Jul-27 \n                 \n                   Algae are melting away the Greenland ice sheet 2016-Jul-15 \n                 \n                   Cold truths at the top of the world 2016-Apr-19 \n                 \n                   NASA launches mission to Greenland 2015-Jul-28 \n                 \n                   Greenland defied ancient warming 2013-Jan-23 \n                 Reprints and Permissions"},
{"file_id": "540178a", "url": "https://www.nature.com/articles/540178a", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "DNA proves Native American roots of 10,600-year-old skeleton. The sequencing of a 10,600-year-old genome has settled a lengthy legal dispute over who should own the oldest mummy in North America \u2014\u00a0and given scientists a rare insight into early inhabitants of the Americas. The controversy centred on the \u2018Spirit Cave Mummy\u2019, a human skeleton unearthed in 1940 in northwest Nevada. The Fallon Paiute-Shoshone Tribe has long argued that it should be given the remains for reburial, whereas the US government opposed repatriation. Now, genetic analysis has proved that the skeleton is more closely related to contemporary Native Americans than to other global populations. The mummy was handed over to the tribe on 22\u00a0November. The genome of the Spirit Cave Mummy is significant because it could help to reveal how ancient humans settled the Americas, says Jennifer Raff, an anthropological geneticist at the University of Kansas in Lawrence. \u201cIt\u2019s been a quest for a lot of geneticists to understand what the earliest peoples here looked like,\u201d she says. The case follows the US government\u2019s  decision this year  that another controversial skeleton,  an 8,500-year-old human known as Kennewick Man , is Native American and qualifies for repatriation on the basis of genome sequencing. Some researchers lament such decisions because the buried skeletons are then unavailable for scientific study. But others point out that science could benefit if Native American tribes use ancient DNA to secure the return of more remains, because this may deliver long-sought data on the peopling of the region. \u201cAt least we get the knowledge before the remains are put back in the ground,\u201d says Steven Simms, an archaeologist at Utah State University in Logan, who has studied the Spirit Cave Mummy. \u201cWe\u2019ve got a lot of material in this country that\u2019s been repatriated and never will be available to science.\u201d \n               Spirit Cave lawsuit \n             The Spirit Cave Mummy is one of a handful of skeletons from the Americas that are more than 10,000\u00a0years old (see \u2018Sequencing North American skeletons\u2019). Archaeologists Georgia and Sydney Wheeler discovered it in Nevada\u2019s Spirit Cave in 1940. The skeleton, an adult male aged around 40 at the time of his death, was shrouded in a rabbit-skin blanket and reed mats and was wearing moccasins; he was found with the cremated or partial remains of three other individuals. The Wheelers concluded that the remains were 1,500\u20132,000 years old. But when radiocarbon dating in the 1990s determined that they were much older, the finds drew attention from both scientists and the Fallon Paiute-Shoshone Tribe. The tribe considers Spirit Cave to be part of its ancestral homeland and wanted the remains and artefacts. The US Native American Graves Protection and Repatriation Act (NAGPRA) mandates that remains be returned to affiliated tribes if they are deemed \u2018Native American\u2019 by biological or cultural connections. In 2000, the US government\u2019s Bureau of Land Management (BLM), which oversees the land where the mummy was found, decided against repatriation. The tribe sued, and in 2006 a US District Court judge ordered the agency to reconsider the case, calling the BLM\u2019s decision \u201carbitrary and capricious\u201d. The mummy\u2019s remains were stored out of view in a Nevada museum, and placed off-limits to most research, except for efforts to determine its ancestry. In a 2014 monograph based on earlier examination of the remains, US anthropologists Douglas Owsley and Richard Jantz noted that the mummy\u2019s skull was shaped differently from those of contemporary Native Americans from the region ( Kennewick Man , Texas A&M Univ. Press). That contributed to the BLM\u2019s decision to seek DNA analysis, says Bryan Hockett, an archaeologist at the bureau\u2019s Nevada office in Reno. The tribe was originally opposed to genetic analysis to prove the mummy\u2019s ancestry, says Hockett, but eventually agreed. In October 2015, Eske Willerslev, an evolutionary geneticist who specializes in ancient DNA analysis at the Natural History Museum of Denmark in Copenhagen, travelled to Nevada to collect bone and tooth samples from the mummy and other remains for DNA sequencing, after meeting with tribe members several months earlier. \n               America\u2019s earliest peoples \n             Willerslev\u2019s team concluded that the Spirit Cave remains are more closely related to indigenous groups in North and South America than to any other contemporary population. The BLM gave  Nature  a preliminary scientific report from the team, and a 31-page memo outlining its reasoning for repatriating the remains. Willerslev declined to comment because his team\u2019s data have not yet been published in a journal. Hockett says the genome findings offered the only unequivocal evidence that the remains are Native American. No evidence links the remains to any specific group \u2014 not even the ancient DNA \u2014 but  NAGPRA allows the return of human remains to tribes that have a geographical connection . Len George, chair of the Fallon Paiute-Shoshone Tribe, did not respond to requests for comment. The genome of a 12,600-year-old skeleton from Montana, called  the Anzick Child , is the only other published ancient genome from the Americas that is older than 10,000\u00a0years. The Spirit Cave remains and the Anzick Child both seem genetically closer to South American groups than to some North American groups, and the migrations behind this pattern are not yet understood, says Raff. One possibility is that both individuals lived before their local populations began spreading across regions of the Americas, says population geneticist Pontus Skoglund at Harvard Medical School in Boston, Massachusetts. Sequencing ancient DNA, which has become easier and cheaper in recent years, could help to determine the origins of many other ancient bones. Remains as old as the Spirit Cave Mummy are rare, but there are many younger remains that are not clearly affiliated to any tribe, and which might now be deemed Native American through ancient DNA sequencing and thus repatriated, scientists say. The BLM announced its intentions to repatriate the Spirit Cave remains in October and received no formal objections, says Hockett. But Jantz, the anthropologist who co-led the Spirit Cave skull study and is based at the University of Tennessee in Knoxville, laments the decision. \u201cIt\u2019s just a sad day for science. We will lose a lot of information about the history of human occupation in the Americas as a consequence,\u201d he says. Further molecular study of the remains could identify details about the Spirit Cave individuals\u00a0\u2014\u00a0from the foods they consumed to the diseases that afflicted them. \u201cI think Willerslev is the last guy who is going to look at these things,\u201d Jantz adds. Dennis O\u2019Rourke, a biological anthropologist at the University of Kansas, says he would like to see more researchers follow Willerslev\u2019s example and work with Native American groups to decide whether to sequence ancient human remains, rebury them, or both. And Kimberley TallBear, an anthropologist who studies the views of indigenous groups on genetics at the University of Alberta in Edmonton, Canada, says researchers with O\u2019Rourke\u2019s attitude to studying ancient remains are becoming more common. She thinks it is wrong for scientists opposed to repatriation to conclude that tribes are not open to research. \u201cTribes do not like having a scientific world view politically shoved down their throat,\u201d she says, \u201cbut there is interest in the science.\u201d \n                     Lessons from the Ancient One 2016-May-04 \n                   \n                     Ancient American genome rekindles legal row 2015-Jun-18 \n                   \n                     Ancient genome stirs ethics debate 2014-Feb-12 \n                   \n                     Ancient migration: Coming to America 2012-May-02 \n                   \n                     Rule poses threat to museum bones 2010-Mar-31 \n                   Reprints and Permissions"},
{"file_id": "nature.2016.21092", "url": "https://www.nature.com/articles/nature.2016.21092", "year": 2016, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Dietary needs of these wandering cells could prove to be their Achilles heel. The cells responsible for  cancer\u2019s spread  \u2014 and for most deaths from cancer\u00a0\u2014 may have a fatal weakness according to studies in mice: a reliance on certain fats to fuel their invasion. It is a difficult and hazardous undertaking for a cancer cell to uproot itself, travel through the bloodstream and take hold in an entirely different part of the body. (Non-cancerous cells are often programmed to self-destruct if they leave the tissue they live in.) Researchers have long struggled to understand which cancer cells can manage the feat, and  how they do so . But a study published on 7 December in  Nature 1  has identified a population of oral tumour cells that are able to make the journey in mice, and has found that such cells may feast on fats to fuel the trip. Determining how certain cancer cells spread throughout the body \u2014 a process called metastasis \u2014 is a big step forward, says Xiang Zhang, a cancer researcher at Baylor College of Medicine in Houston, Texas, who was not involved in the study. \u201cNow people have a suspect they can follow.\u201d To find that suspect, Salvador Aznar Benitah of the Institute for Research in Biomedicine at the Barcelona Institute of Science and Technology in Spain and his colleagues looked among oral-cancer cells for those that could seed tumours. Within that population of cells, the team found some that expressed high levels of a molecule called CD36, which helps cells to take up lipids from their environment. Such lipids could serve as an energy source for wandering tumour cells, they reasoned. \u201cMetastasis takes a lot of energy,\u201d says Ernst Lengyel, a gynaecological oncologist at the University of Chicago in Illinois, who was not involved in the project. \u201cAs a cell you must be able to adapt to changing environments, reprogram protein expression, establish a beachhead and start proliferating as soon as possible.\u201d \n             Stopping the spread \n           Benitah and his team found that high CD36 expression was required for metastasis in mice. Antibodies that blocked CD36 \u2014 and eliminated its interaction with fatty acids \u2014 completely inhibited metastasis, although they did not affect the development of primary tumours.  The researchers also mined public databases and found that high expression of CD36 correlated with poor medical outcomes in bladder, lung, breast and other cancers in people. Benitah\u2019s team is now working to develop antibodies against CD36 that could be used in clinical trials, although he estimates it would take at least another four years to reach that milestone. Benitah notes that such a therapy may be effective even after cancer has started to spread: in mice, experimental antibodies eradicated metastatic tumours 15% of the time. The remaining metastatic tumours shrunk by at least 80%. The team is also looking at the implications of another finding: feeding the mice a high-fat diet led to more and larger tumours in the lymph nodes and lungs \u2014 a sign of metastasis \u2014 compared with mice on normal diets. Benitah\u2019s team is now carrying out a study that aims to enrol 1,000 people with cancer, profiling lipids in their blood to look for any links to the spread of cancer cells. But at this stage, it is too early to tell people to avoid fatty foods, cautions Lengyel \u2014 especially people with cancer  who may need a high-energy diet . \u201cThat\u2019s a very dangerous message,\u201d he says. \n                   Cancer therapy: an evolved approach 2016-Apr-13 \n                 \n                   Imaging: Cancer caught in the act 2014-May-07 \n                 \n                   Breast cancer caught in the act of spreading 2013-Jan-31 \n                 \n                   Cancer theory faces doubts 2011-Apr-19 \n                 \n                   US National Cancer Institute: Metastatic Cancer \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21182", "url": "https://www.nature.com/articles/nature.2016.21182", "year": 2016, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "Fertility regulator says mitochondrial-replacement therapy can be trialled \u2014 but only in some cases. Britain\u2019s fertility regulator has decided to allow the birth of babies from  embryos modified to contain three people\u2019s DNA  in \u201ccertain, specific cases\u201d \u2014 making the United Kingdom the first country to explicitly permit the therapy. On 15 December, the UK Human Fertilisation and Embryology Authority (HFEA) announced that it would allow clinics to apply for licences to conduct limited trials of the technique, which aims to prevent mothers from passing down mutations in cellular structures called mitochondria. Last month, the HFEA\u2019s scientific advisory board  recommended that trials go ahead . \u201cToday\u2019s historic decision means that parents at very high risk of having a child with a life-threatening mitochondrial disease may soon have the chance of a healthy, genetically related child. This is life-changing for those families,\u201d said HFEA chair Sally Cheshire, in a  press statement . Researchers at Newcastle University and the Newcastle Fertility Centre have already said that they will apply for a licence to carry out the procedure. Called mitochondrial-replacement therapy, it involves exchanging faulty mitochondria for healthy ones \u2014 by transferring the nuclear DNA from one egg (or just-fertilized embryo) into another donor egg (or embryo). Doug Turnbull, director of the Wellcome Trust Centre for Mitochondrial Research at Newcastle University, says that \u201cup to 25\u201d selected patients could be treated at Newcastle with the therapy each year. However, the United Kingdom will not be the first country in which the therapy has been used. Fertility doctors said this year that  they had already performed the procedure in Mexico and Ukraine , which do not have laws preventing it. John Zhang, a physician at New Hope Fertility Center in New York City, has said that a baby boy conceived from the treatment in Mexico seems healthy so far. Research suggests that the treatment may not always be 100% effective. Clinicians say it is hard to prevent a few mutant mitochondria being transferred along with the nuclear genome into the donor egg \u2014 and tests on embryos suggest that in some cases, these faulty mitochondria can out-compete the healthy ones 1 . The HFEA will approve each use on a case-by-case basis, it says. Last month, an HFEA spokesperson estimated that the United Kingdom\u2019s first child with three people\u2019s DNA could be conceived as early as March or April 2017. \n                   \u2018Three-parent baby\u2019 claim raises hopes \u2014 and ethical concerns 2016-Sep-28 \n                 \n                   Three-person embryos may fail to vanquish mutant mitochondria 2016-May-19 \n                 \n                   The hidden risks for \u2018three-person\u2019 babies 2015-Sep-23 \n                 \n                   World hails UK vote on three-person embryos 2015-Feb-10 \n                 \n                   Reproductive medicine: The power of three 2014-May-21 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21166", "url": "https://www.nature.com/articles/nature.2016.21166", "year": 2016, "authors": [{"name": "Alexandra Witze"}], "parsed_as_year": "2006_or_before", "body": "NASA spacecraft finds that Ceres is full of water. Asteroids might look dry and barren, but the Solar System\u2019s biggest asteroid \u2014 Ceres \u2014 is chock full of water, NASA\u2019s Dawn spacecraft has found. \u201cIt\u2019s just oozing,\u201d says Thomas Prettyman, a nuclear engineer at the Planetary Science Institute in Tucson, Arizona. He led the team that built the neutron-counting instrument aboard Dawn, which reported its findings on 15 December in  Science 1 . Today, the water is either frozen as ice, filling pore spaces deep inside Ceres, or locked inside hydrated minerals at the surface. But billions of years ago, early in Ceres\u2019s history, heat left over from the Solar System\u2019s formation probably kept the asteroid warm inside. This allowed the water to churn and flow, helping to separate Ceres into layers of rock and ice.\u00a0 \u201cWe know the water and the rock have separated and interacted over time,\u201d said Carol Raymond, a planetary scientist at NASA's Jet Propulsion Laboratory in Pasadena, California, at a meeting of the American Geophysical Union in San Francisco on 15 December. The discovery adds to a growing awareness of Ceres as an active, wet world that pushes the boundary of what it means to be a planet. Today it sports  a 4-kilometre-high ice volcano  and  bright spots of salt mixed with ice and rock . At 940 kilometres across, Ceres is so big that it contains roughly one-third of all the mass in the asteroid belt \u2014 and it is technically both an asteroid and a dwarf planet. Researchers knew that Ceres was rich in water on the basis of its estimated density, by studying light reflecting off the hydrated minerals on its surface and  because they spotted water apparently steaming from it . But they did not know exactly how much water was there until Dawn showed up in March 2015. \n             Hydrogen highs and lows \n           The spacecraft studies chemical elements by counting the gamma-rays and neutrons reflecting off Ceres as cosmic rays bombard it. Prettyman\u2019s team generated a map of the asteroid\u2019s hydrogen, which appears in water ice and hydrated minerals. Hydrogen levels were richest in the middle to high latitudes, with the greatest concentrations \u2014 up to 30% water \u2014 present at the north pole. Around the equator, frozen water has probably sublimated into space and dried out Ceres\u2019s surface, Prettyman says. An astronaut there would have to dig down about 1 metre to find frozen water, whereas at the north pole, a visitor \u201cwould just swipe and find the ice table\u201d, he says. Ceres\u2019s dampness stands in stark contrast to Vesta,  a much drier asteroid  visited by Dawn in 2011\u201312. On average, Ceres is more than 100 times richer in hydrogen than Vesta, Prettyman says. A second paper, appearing on 15 December in  Nature Astronomy , shows where other frozen water might lie 2 . A team led by Thomas Platz of the Max Planck Institute for Solar System Research in G\u00f6ttingen, Germany, studied 634 craters on Ceres that are always in the dark. Ten of those have bright areas on the crater floor, and spectral studies of one of them found that it consisted of water ice. Similarly to the Moon and Mercury, the airless Ceres apparently manages to trap frozen water in dark areas on its surface, the team says. \n                   Giant ice volcano spotted on dwarf planet Ceres 2016-Sep-01 \n                 \n                   Mysterious bright spots on Ceres are probably salt 2015-Dec-09 \n                 \n                   Dawn spacecraft finds signs of water on Vesta 2012-Sep-20 \n                 Reprints and Permissions"},
{"file_id": "nature.2016.21181", "url": "https://www.nature.com/articles/nature.2016.21181", "year": 2016, "authors": [], "parsed_as_year": "2006_or_before", "body": "Our editors' pick of this year\u2019s influential expert opinions. \n             \n                 Reproducibility: A tragedy of errors \n               \n           Mistakes in peer-reviewed papers are easy to find but hard to fix, report David B. Allison and colleagues.  3 February 2016 \n             \n                 The circular economy \n               \n           A new relationship with our goods and materials would save resources and energy and create local jobs, explains Walter R. Stahel.  23 March 2016 \n             \n                 Peer review: Troubled from the start \n               \n           Pivotal moments in the history of academic refereeing have occurred at times when the public status of science was being renegotiated, explains Alex Csiszar.  19 April 2016 \n             \n                 Seven chemical separations to change the world \n               \n           Purifying mixtures without using heat would lower global energy use, emissions and pollution \u2014 and open up new routes to resources, say David S. Sholl and Ryan P. Lively.  26 April 2016 \n             \n                 Embryology policy: Revisit the 14-day rule \n               \n           Studies of human development in vitro are on a collision course with an international policy that limits embryo research to the first two weeks of development, warn Insoo Hyun, Amy Wilkerson and Josephine Johnston.  4 May 2016 \n             \n                 Take responsibility for electronic-waste disposal \n               \n           International cooperation is needed to stop developed nations simply offloading defunct electronics on developing countries, argue Zhaohua Wang, Bin Zhang and Dabo Guan.  3 April 2016 \n             \n                 Agricultural R&D is on the move \n               \n           Big shifts in where research and development in food and agriculture is carried out will shape future global food production, write Philip G. Pardey and colleagues.  14 September 2016 \n             \n                 End class wars \n               \n           Mike Savage calls on sociologists to resolve their differences over definitions of social class to allow better analyses of inequality.  21 September 2016 \n             \n                 Where to put the next billion people \n               \n           Richard T. T. Forman and Jianguo Wu call for global and regional approaches to urban planning.  28 September 2016 \n             \n                 Genomics is failing on diversity \n               \n           An analysis by Alice B. Popejoy and Stephanie M. Fullerton indicates that some populations are still being left behind on the road to precision medicine.  12 October 2016 Reprints and Permissions"},
{"file_id": "540491a", "url": "https://www.nature.com/articles/540491a", "year": 2016, "authors": [{"name": "Elizabeth Gibney"}], "parsed_as_year": "2006_or_before", "body": "Shift in focus comes in response to a changing world order and the threat of terrorism. Faced with a changing world order and buffeted by a slew of political crises and terrorist attacks, the historically civilian European Union is bolstering its military capabilities. And that means making its first major investment in military research. On 1\u00a0December, the European Parliament approved a \u20ac25-million ($26-million) fund dedicated to military research. It will form part of a proposed broader European Defence Fund, aimed at making military innovation more efficient and enlarging Europe\u2019s industrial defence base. The research portion of the fund will cover electronics, advanced materials, encrypted software and robotics. The European Commission, the EU\u2019s policymaking arm, expects to invest a total of \u20ac90\u00a0million by 2020. It hopes the figure will rise to \u20ac500\u00a0million a year for defence research from 2021. The sum is dwarfed by the EU\u2019s major research-funding programme, Horizon 2020, which will hand out \u20ac80\u00a0billion over 7 years, the \u20ac8.8\u00a0billion spent by EU member states on defence research in 2014, and what the United States and probably China spend on defence research (see \u2018Military metrics\u2019). But some scientists fear that funding defence research is a step in the wrong direction for the EU. \u201cIt will necessarily divert much-needed funding from civilian R&D budgets, at a time when they are urgently needed for areas such as climate and energy,\u201d says Stuart Parkinson, executive director for UK-based advocacy group Scientists for Global Responsibility. One of the EU\u2019s main objectives is to promote peace. In the past, defence was seen as a national issue rather than something for the bloc to handle. The decision to create the research fund is in part driven by a drop in national defence-research funding, which declined by 18%, or \u20ac1.9\u00a0billion, between 2006 and 2014 in real terms, according to the European Defence Agency (EDA) in Brussels, which will manage the research fund on behalf of the commission. The perception that international security is under threat is a driver for the broader defence fund. In November, the European Parliament passed a motion that says terrorists are targeting the continent on an unprecedented scale, and that Europe is \u201cnow compelled to react to an arc of increasingly complex crises\u201d. The motion notes that for the first time since the Second World War, \u201cborders in Europe have been changed by force\u201d \u2014 referring to the annexation of Crimea in 2014 and the incursion into Ukraine by Russian forces. In September, Jean-Claude Juncker, president of the commission, made a similar point when speaking about the European Defence Fund. \u201cEurope can no longer afford to piggy-back on the military might of others,\u201d he said. The rules for participating in the research fund are still being discussed, but it will be modelled loosely on Horizon 2020. It will probably promote projects that combine researchers from industry and academia and from different countries, says Denis Roger, a director in charge of research at the EDA. But whereas researchers on Horizon 2020 projects are expected to publish their results, or to patent products for anyone to license, the commission is likely to restrict how the results of defence-fund research are publicized, classifying some and restricting licensing to national ministries. The EU has no army of its own\u00a0\u2014 although Juncker has said he would like to create one. Instead, national ministries, alongside members of the defence industry, will be involved in setting priorities for the scheme, says Roger. And unlike Horizon 2020, which welcomes participation from more than a dozen \u2018associated\u2019 countries, the research defence fund is likely to be open only to EU member states and Norway. The project could boost certain fields. Roger says it will include research into metamaterials, which are made of tiny structures that manipulate the path of light and could potentially hide objects from radar, as well as methods of energy storage, flexible radio antennas that can be incorporated into clothing, and prototype maritime surveillance drones. \u201cI would imagine that a lot of countries would definitely see this as another opportunity for funding,\u201d says Ortwin Hess, a physicist at Imperial College London. He notes that US scientists working on photonics and metamaterials can readily access defence funding. \u201cMy US colleagues wouldn\u2019t survive without it. They live on it.\u201d Hess, who has received defence funding from the US and UK governments in the past, says he is a realist when it comes to what he calls the moral question. \u201cI have to accept that our society has values that deserve to be defended,\u201d he says. The military will adopt technologies developed in the civilian domain, and sometimes technology transfer can go the other way, he adds. But Parkinson says that defence research often supports military efforts beyond actual defence, as well as the export of weapons to other countries: \u201cOur view is that we need a much stronger focus on R&D which contributes to tackling the root causes of conflict\u00a0\u2014 including a range of social and environmental problems.\u201d \n                 Tweet \n                 Follow @NatureNews \n                 Follow @LizzieGibney \n               \n                     Military technology: Death by remote control 2016-Jun-29 \n                   \n                     Boon or burden: what has the EU ever done for science? 2016-Jun-15 \n                   \n                     South Korean scientists fight plan to scrap military exemptions 2016-Jun-13 \n                   \n                     Military technology: Laser weapons get real 2015-May-27 \n                   \n                     Japanese academics spooked by military science incursions 2015-May-05 \n                   \n                     Britain sets up defence advisory group 2009-Nov-10 \n                   \n                     Nature  special: Beyond the bomb: science and the military \n                   \n                     European Defence Action Plan \n                   Reprints and Permissions"}
]