[
{"file_id": "492335a", "url": "https://www.nature.com/articles/492335a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "Ten people who mattered this year. \n               Rolf-Dieter Heuer: The Higgs diplomat \n             \n               Gentle nudging from the head of CERN ensured that the world heard about the discovery of a long-sought particle. \n             \n               By Geoff Brumfiel \n             The detection of the Higgs boson, announced to the world on 4\u00a0July, was the scientific discovery of the year, if not the decade. But it might not have been a discovery at all had it not been for the diplomacy of Rolf-Dieter Heuer. As the director-general of CERN, the particle-physics laboratory located near Geneva, Switzerland, Heuer has budgetary control over the Large Hadron Collider (LHC), which generated the Higgs by smashing together protons at energies higher than those of any other accelerator in the world. But Heuer has considerably less authority over the two experiments that detected the particle in the debris of the collision; those facilities are run democratically by the thousands of physicists who built them. Heuer didn\u2019t even know what the groups had seen until mid-June, when their two sleep-deprived leaders, Fabiola Gianotti and Joe Incandela, gave him short presentations on what their building-sized detectors had found. The results were tantalizing: after months of gathering data, both experiments now had strong signals from a new kind of particle inside the LHC\u00a0\u2014\u00a0signals that closely mirrored what theorists expected from the Higgs, first predicted nearly 50 years ago. \n               boxed-text \n             Yet neither group leader was willing to claim that they had \u2018discovered\u2019 the Higgs. High-energy physicists are reluctant to make such a declaration until the chances of a statistical error are whittled down to a level known as 5-sigma\u00a0\u2014\u00a01 part in 3.5 million\u00a0\u2014\u00a0and neither experiment was quite there with the Higgs data. Both leaders had many group members pushing to delay announcement of the discovery until the end of the year, when the steadily accumulating data would make the conclusion cast iron. \u201cFabiola and I felt tremendously stressed about the whole thing,\u201d Incandela recalls. Heuer was under pressure, too. That same week, there was a meeting of CERN\u2019s governing council: a committee of civil servants, diplomats and independent scientists from the lab\u2019s member states. The council made it clear that, if there was something to say about the Higgs, the physicists had a duty to say it out loud to the governments and citizens who had paid for the LHC. \n               boxed-text \n             Heuer and the detector groups agreed to have a public seminar at CERN on 4\u00a0July, but with days to go it was still unclear just what would be claimed. The evidence was growing stronger every day as more data were analysed, but the detector groups remained cautious and reluctant to make any bold claims. A less astute director-general might have pushed Incandela and Gianotti to declare victory, says Incandela. \u201cImagine, you\u2019ve got these two people coming in who are both paranoid as hell and incredibly conscientious showing you these unbelievable results,\u201d he says. \u201cRolf was looking at us both and thinking, \u2018What\u2019s the matter with these guys?\u2019\u201d But the affable, 64-year-old Heuer has a reputation for guiding without being bossy, and for listening. \u201cIn German it\u2019s \u2018 ein H\u00e4ndchen \u2019\u201d \u2014 a gentle hand\u201d, he says. \u201cYou have to have a feeling for people, a feeling for what they can do and what they cannot do.\u201d If the consensus within the experiments wasn\u2019t quite there, he wasn\u2019t going to push it further. But after consulting with Incandela, Gianotti and others, says Heuer, \u201cI\u00a0decided that I could use the word \u2018discovery\u2019.\u201d He would take the risk that the experiment groups wouldn\u2019t. The final press release was drafted with just two days to go and, as promised, the word \u201cdiscovery\u201d appeared just once, in a quote from Heuer. On the morning of the announcement, Gianotti and Incandela stood before their peers, politicians and the press. In back-to-back talks, they laid out the evidence they had for the new particle. \u201cWe agreed that we would just stick to the facts,\u201d says Gianotti. After the talks, Heuer, who had played the role of jovial master of ceremonies for the entire affair, stood before the packed auditorium. Now was the time for him to drop the \u2018D\u2019 word. But he paused ahead of his prepared remarks. Ever the diplomat, his first words were not a declaration but a question: \u201cAs a layman, I would now say, \u2018I think we have it.\u2019 Do you agree?\u201d The auditorium burst into applause. \n               Cynthia Rosenzweig: Guardian of Gotham \n             \n               New York\u2019s climate-adaptation champion is determined to make her city more resilient to natural disasters. \n             \n               By Jeff Tollefson \n             As Superstorm Sandy battered the US east coast this year, Cynthia Rosenzweig huddled with her 97-year-old mother in a suburb of New York City, not far from where she grew up. After making sure that her own home had sustained only minor damage, Rosenzweig turned her attention to the city, which had not been so lucky. Sandy had driven a 4-metre wall of water into low-lying neighbourhoods, destroying homes, flooding transportation tunnels and leaving millions of people without power. Although the damage came as a shock to most, Rosenzweig and a team of researchers had forecast those consequences a dozen years earlier as part of the first national assessment by the US Global Change Research Program. \u201cEverything that happened is in our earliest report,\u201d says Rosenzweig. Because of that work and many follow-on studies conducted for state and city officials, New York has incorporated climate-change adaptation and resilience into its long-term planning initiatives, which include upgrading building codes and managing parks and wetlands to accommodate flooding and sea-level rise. The actions have made New York a leader among cities working to prepare for the threats of climate change, says Rosenzweig. She is now trying to assess whether these steps helped to lessen Sandy\u2019s impacts, which may offer a preview of the threats expected as climate change intensifies storms and raises sea levels. \n               boxed-text \n             Rosenzweig\u2019s path to urban protector started in the fields of Tuscany, Italy, in 1969. She had left university in California to rent a small farm with her future husband, where they learned to pick grapes and olives and raise goats, pigs, ducks and geese. Eventually, she decided it was time to go back to university to study agriculture. While pursuing a master\u2019s degree at Rutgers University in New Jersey, she found her way to a job at NASA\u2019s Goddard Institute for Space Studies (GISS) in New York, analysing satellite data on croplands. When she arrived, GISS director James Hansen was busy modelling the impacts of a doubling in atmospheric carbon dioxide concentrations. He wanted to know what would happen to crops. As an agriculture expert, \u201cI was the only person at GISS at that time who could begin to answer that question\u201d, she says. \u201cI\u2019ve been answering that question ever since.\u201d \n               boxed-text \n             To do so, Rosenzweig had to expand her focus from crops to agricultural economics, folding in the broader impacts on farmers, food supply systems and society. Thanks to her experience in complex assessments, Rosenzweig was chosen to head up the northeastern regional analysis when the first national climate assessment kicked off in 1997. Her team\u2019s analysis suggested that singular shocks such as Sandy would cause widespread problems. Today, she co-chairs the New York City Panel on Climate Change, which advises local policy-makers. She is also helping to coordinate regional and international groups that are exploring climate adaptation and resilience. The city has a long way to go. Rather than focusing on big-ticket solutions such as storm-surge barriers, Rosenzweig calls for a range of initiatives, from increasing redundancy in the electric grid to sealing off tunnels and making coastal areas more resilient to flooding. She doesn\u2019t pause for breath while running through the litany of needs. \u201cWe have to do more. We have to do better. We have to spend more money. We need pilot funding projects. There\u2019s just a lot to it.\u201d Then Rosenzweig flashes a wide smile. \u201cI\u2019m not a pessimistic person,\u201d she says. \u201cWe have to succeed. We don\u2019t have a choice.\u201d \n               Adam Steltzner: Our man on Mars \n             \n               NASA called on an unconventional engineer to give its pricey new rover a baby-soft landing on the red planet. \n             \n               By Eric Hand \n             When NASA\u2019s Curiosity rover slammed into the Martian atmosphere at 5,900 metres per second on the night of 5 August, no one on Earth was more worried than Adam Steltzner, the engineer who led the 50-person entry, descent and landing (EDL) team for the US$2.5-billion mission. At first, says Steltzner, all the data coming back from the spacecraft seemed fine as it began to brake by carving S-turns in the thin air like a crazed snowboarder. But then a few abnormal telemetry signals arrived at the control room at the Jet Propulsion Laboratory in Pasadena, California. \u201cBeta out of bounds catastrophic,\u201d read one. Translation: Curiosity was tilting too much to the side. \u201cThe first two data points we see are like: \u2018You\u2019re going to die,\u2019\u201d says Steltzner. He still uses the present tense as he recollects the landing sequence, and is not averse to hyperbole and dramatic pauses, unlike most engineers, who cloak their emotions in cautious jargon. \u201cHe\u2019s a very instinctual person,\u201d says colleague Al Chen, who was the voice of mission control that night. \u201cAnd his instincts are often right.\u201d \n               boxed-text \n             Part of Steltzner\u2019s persona stems from growing up in Marin County, north of San Francisco. More interested in theatre and rock music than in his studies, the feckless teenager barely graduated from high school. Eventually, he realized he was just \u201cbright and bored\u201d. He went on to earn a PhD in engineering physics and deeply absorbed the Navier\u2013Stokes equations on fluid motion and the laws of thermodynamics until, he says, \u201cthey were woven into my soul\u201d. But he still hasn\u2019t given up his flair for the dramatic. Nor, with his western-style shirts, pomaded hair and big-buckle belts, has he ceded a rock star\u2019s fashion sense. He describes his look as \u201crockabilly meets post-punk Poindexter\u201d. On the night of the landing, however, Steltzner was wearing one of the several hundred blue Curiosity golf shirts that had been issued to the mission team. Steltzner had had the acronym \u2018EDL\u2019 discreetly embroidered on the left sleeve of his team\u2019s shirts \u2014 a badge of honour for the tightly knit group. \n               boxed-text \n             Steltzner paced around the control room. The dire tilt warnings turned out to be false alarms. But a second moment of tension came 7 minutes later, as a hovering jet pack called a sky crane slowly unspooled the 1-tonne rover to the floor of Gale crater from an altitude of 20 metres. Nothing like the sky crane had been tried before in a Mars landing. Steltzner vividly recalls the brainstorming session in which he and a dozen others \u201cgroped it into existence\u201d. In guiding other design choices, Steltzner tended towards a ruthless simplicity; he argued for the spacecraft to use one parachute instead of two, and for the rover to use a pulverizing drill instead of one that extracts a core. But with the sky crane, Steltzner can\u2019t help but acknowledge a design sensibility that was a bit more baroque. \u201cBecause it looked so outlandish, we all felt very exposed,\u201d he says. \u201cIf it failed, people would have been like, \u2018You idiots\u2019.\u201d That\u2019s one reason why, in the control room, Steltzner wouldn\u2019t declare success until he had two independent confirmations that the rover had landed, one from the rover itself and one from the sky crane, still hovering overhead. Then came the hardest part: he counted to ten, to ensure that the sky crane, after being severed and rocketed away, hadn\u2019t somehow crashed down on top of the rover. He recalls, \u201cAt that point, I pointed at Al and said, \u2018Do it\u2019. And he called out: \u2018Touchdown confirmed. We are safe on Mars\u2019.\u201d \n               C\u00e9dric Blanpain: Cell tracker \n             \n               By tracing the descendants of a single cell, a cautious developmental biologist tackled a controversy over tumour growth. \n             \n               By Monya Baker \n             C\u00e9dric Blanpain likes to see things for himself. His students, he says, \u201ctell me in the morning that they have something very important. And I run, not to the screen, but to the microscope.\u201d When he was first setting up his lab at the Free University of Brussels six years ago, Blanpain\u2019s see-it-to-believe-it approach drew him to study untouched cells in tissues from living animals rather than, as is often done, in dishes or after transplantation. He didn\u2019t trust what cells do outside their normal environment. His advisers warned him that the task would be tough\u00a0\u2014\u00a0but Blanpain, a quick-talking developmental biologist with a penchant for snowboarding and jazz, was undeterred. He decided to refine a technique called lineage tracing, which reveals patterns of cell division in tissue. Blanpain uses low levels of a drug to activate a gene and change the colour of specific cells and all their descendants, so that they can be seen under a microscope. He often works with a theoretical physicist to analyse the starting cells\u2019 contribution to the resulting tissue. No one has been able to track cell lineages as carefully or as quantitatively, says Brigid Hogan, a cell biologist at Duke University in Durham, North Carolina. \n               boxed-text \n             In October last year, Blanpain\u2019s team looked at mammary glands in mice during fetal development, pregnancy and lactation. Cell-culture work had led researchers to believe that a common cell type gives rise to multiple kinds of mammary cells. But when Blanpain looked at cells left undisturbed in mammary fat pads, he saw that they contributed just to a single lineage. He then went on to show that the adult mammary gland actually contains distinct types of stem cells ( A. Van Keymeulen et al. Nature 479, 189\u2013193; 2011 ), a fact that could help to pin down the genesis of breast cancers. Blanpain \u201ccleared up what had been a very confusing field\u201d, says Hogan. \n               boxed-text \n             This year, Blanpain tackled a long-standing controversy over the existence of cancer stem cells. By applying a carcinogen to mouse skin and then using his cell-tracking method, his team was able to show that cells do not contribute equally to the resultant tumours: some of the cells in a tumour peter out after a few divisions, and others\u00a0\u2014\u00a0the stem cells\u00a0\u2014\u00a0produce thousands of clones ( G. Driessens et al. Nature 488, 527\u2013530; 2012 ). This implies that drug developers should focus on killing these tumour-generating cells. Blanpain says that he hadn\u2019t expected such dramatic results. \u201cI saw the first slide, and I said \u2018show me the second one\u2019. After the fifth, I was sure what I was seeing.\u201d \n               Elizabeth Iorns: Replication hound \n             \n               A geneticist takes her quest to check results to the forefront of science. \n             \n               By Monya Baker \n             Elizabeth Iorns did not expect to be attacked for following the scientific method. As a postdoc at the University of Miami in Florida in the late 2000s, she spent a year trying to replicate findings that a particular gene worked as a switch for malignancy. After she concluded that the original research was flawed\u00a0\u2014\u00a0a conclusion denied by its authors\u00a0\u2014\u00a0she wanted to warn others. But she struggled to publish her data, and faced personal attacks and career setbacks after she succeeded. \u201cIt\u2019s still an experience that I don\u2019t like to bring up,\u201d she says. Given the obstacles, she began to suspect that many published experiments are never repeated. And this year, she decided to do something about it. The need was clearer than ever, she says. Increased retraction rates had drawn the attention of the US National Academy of Sciences. Scientists at Amgen and Bayer reported that they had been unable to reproduce the vast majority of \u2018landmark\u2019 papers describing promising approaches to treat disease. The field of psychology was hauled up for widespread replication problems (see   Nature 485, 298\u2013300; 2012 ). \n               boxed-text \n             In August, Iorns founded the Reproducibility Initiative, based in Palo Alto, California, which allows authors to submit their papers for replication. Scientific advisers select key experiments and arrange for disinterested third parties to repeat them. If the results are replicated, the validation study is published in  PLoS ONE , linked to the original paper. This, says Iorns, can draw more attention to the original findings and motivate authors to put their results up for testing. \n               boxed-text \n             The Reproducibility Initiative is a limited solution to an important problem, says Ferric Fang, a molecular biologist at the University of Washington in Seattle who has investigated causes of sloppy science. \u201cThe ability of work to be reproduced is a hallmark of good science, but it\u2019s difficult to publish work that replicates someone else.\u201d Fang advocates finding easier ways for scientists wishing to expand on the original research to report their replication attempts. On 14\u00a0November, the Reproducibility Initiative e-mailed about 7,000 corresponding authors of recent publications in PubMed asking them if they would like their study validated. By the next day, they had 675 replies, of which 77% said yes. But someone has to foot the bill\u00a0\u2014\u00a0which Iorns estimates will be about 10% of the original research cost. Iorns is busy convincing funders that supporting replication work eventually frees up more resources for discovery. \u201cIt\u2019s wasteful to not have any idea what is real,\u201d she says. \n               Jun Wang: Genome juggernaut \n             \n               The head of a Chinese sequencing powerhouse reveals the scale of the institute\u2019s genome ambitions. \n             \n               By David Cyranoski \n             \u201cWe are the muscle \u2014 we have no brain,\u201d said Jun Wang in 2009, describing BGI, the Chinese genome-sequencing institute he leads. It was the kind of cheeky statement for which Wang has become known, but there seemed some truth to the claim. BGI had just purchased 128 top-of-the-line DNA-sequencing machines and was putting hundreds of young programmers\u00a0\u2014\u00a0often plucked directly from universities\u00a0\u2014 to work on an onslaught of data. It was a sequencing centre on steroids, using its unparalleled technical power to tackle almost every project going. Today, BGI is the biggest genome-sequencing operation in the world, and Wang, a 36-year-old bioinformatician who has been with it from the start, is well on his way to demolishing the organization\u2019s brawn-without-brains reputation. BGI was established in 1999 to support the Human Genome Project. It went from accounting for about 1% of the genomics community\u2019s sequencing capacity at that time, to \u201cmore like 50%\u201d today, says George Church, a geneticist at Harvard University in Cambridge, Massachusetts. With eight overseas offices and 600 representatives around the globe, BGI works with more than 10,000 collaborators from universities, pharmaceutical and agricultural companies and other research institutions. Although it calls itself a non-profit organization, BGI has courted investors and made moves to acquire other companies in the sequencing field. The rapid growth has been stressful at times. Wang remembers chucking a computer out of the window during the race to sequence the rice genome a decade ago because his team didn\u2019t know enough computer programming for the task at hand. \u201cI had a bad temper. But that\u2019s history,\u201d Wang says. \u201cI\u2019m very nice and gentle now.\u201d \n               boxed-text \n             As a public face for the institute, Wang uses his energy and self-effacing humour to highlight BGI\u2019s ambitions, which seem to include sequencing the genome of just about every organism on the planet. It is taking a leading role in sequencing 10,000 vertebrates through the Genome 10K project; 5,000 insects and other arthropods through the i5k initiative; and more than 1,000 birds, including some extinct ones in a separate project. This year, BGI was listed in more than 100 publications. It was a main player in the 1,000 Genomes Project Consortium, which aims to tease out genetic factors in disease by comparing human genomes from geographically distinct regions. And it has increasingly been initiating its own projects, including two studies that analyse the genomes of single cells to chart cancer development ( Y. Hou  et al. Cell    148,  873\u2013885; 2012  and  X. Xu  et al. Cell    148,  886\u2013895; 2012 ). \n               boxed-text \n             But the largest change in 2012 was BGI\u2019s progress in translating genomic science into real-world applications. A partnership with the Gates Foundation signed in September will expand the repertoire of sequenced agricultural organisms and infectious diseases. The institute is also working on genetic tests that detect fetal chromosome abnormalities from a mother\u2019s blood, and it is pushing to use next-generation sequencing for diagnostic tests in newborns. In an attempt to secure a dominant position in clinical testing, BGI offered US$118 million in September to acquire sequencing-technology company Complete Genomics of Mountain View, California. Church, who serves as an adviser to both companies, says that Complete Genomics has technologies that will be invaluable in screening for disease-related genes. Wang says now that he never really doubted that BGI was more than just brawn. \u201cI was just being modest,\u201d he says when reminded of his comments from three years ago (see   Nature 464, 22\u201324; 2010 ). \u201cIf you really don\u2019t have a brain, you can\u2019t move the muscles.\u201d \n               Jo Handelsman: The bias detective \n             \n               With an experiment that exposed sex discrimination, a microbiologist has opened researchers\u2019 eyes to their unconscious biases. \n             \n               by Helen Shen \n             Ever since she saw the results of her study, Jo Handelsman has thought twice about any recommendation letter she writes. Has she somehow slighted a woman or given an unconscious boost to a man, despite her commitment to advocate for women in science? Last summer, Handelsman injected new life into the long-standing debate about what holds women back in science with a study that showed that both male and female researchers tend to rate job applications from women lower than those from equivalent men ( C.\u00a0A.\u00a0Moss-Racusin  et\u00a0al. Proc. Natl Acad. Sci. USA    109,  16474\u201316479; 2012 ). Handelsman, a microbiologist at Yale University in New Haven, Connecticut, asked more than 100\u00a0scientists to evaluate applications from undergraduate students seeking a job as a laboratory manager\u00a0\u2014\u00a0often a stepping stone to graduate school. Unbeknown to the researchers, the students were fictitious. But the prejudice that Handelsman uncovered was not. On average, researchers who received \u2018John\u2019s\u2019 resume said that they would offer an annual salary of US$30,238; those who read an identical resume from \u2018Jennifer\u2019 offered just $26,508. \n               boxed-text \n             Chemists, physicists and biologists \u2014 men and women alike \u2014 also rated Jennifer as less competent than John and expressed less interest in mentoring her. \u201cThere was simply one treatment and one variable, and there\u2019s no escape from the conclusion,\u201d says Handelsman. This type of bias could be one factor holding back female scientists, she says. \n               boxed-text \n             Handelsman says that she has never personally experienced significant hurdles because of her sex. But she became an outspoken campaigner for women in science in the 1990s, after hearing how female colleagues and students had faced gender discrimination and seeing them passed up for honours that went to male scientists who were no better qualified. A wealth of social psychology data had convinced Handelsman that unconscious bias presents a major obstacle for female scientists. But when she spoke about that bias at universities around the country, she encountered scepticism. \u201cI had heard so many times from scientists that this couldn\u2019t possibly be true of us, that we\u2019re trained to be rational,\u201d says Handelsman. So she decided to put it to the test. \u201cThis is one of us \u2014 telling us that there are problems,\u201d says Ronald Breaker, who chairs Handelsman\u2019s department. \u201cIt comes with a certain amount of street cred.\u201d \n               Tim Gowers: Seed of discontent \n             \n               A disgruntled mathematician ends up sparking a global publishing boycott. \n             \n               by Richard Van Noorden \n             Tim Gowers is still surprised that he ended up leading a global boycott of Elsevier, the Dutch publishing giant. \u201cI\u2019m not someone who naturally seeks to be a campaigner,\u201d says the mathematician at the University of Cambridge, UK. Yet Gowers\u2019 impatience with the publisher\u2019s business practices had been building for years. He particularly disliked what he saw as its high prices, its habit of forcing libraries to subscribe to unwanted journals by \u2018bundling\u2019 them with the popular ones and its opposition to open-access publishing. On 21\u00a0January, Gowers let rip in a searing blogpost entitled \u2018Elsevier\u00a0\u2014\u00a0my part in its downfall\u2019. \u201cWhy do we allow ourselves to be messed about to this extraordinary extent,\u201d he wrote. \u201cI am not only going to refuse to have anything to do with Elsevier journals from now on, but I am saying so publicly,\u201d he went on\u00a0\u2014\u00a0and he encouraged others to do the same. \n               boxed-text \n             The blog caught the attention of Tyler Neylon, a software engineer in Mountain View, California, who the next day created a website ( www.thecostofknowledge.com ) inviting people to sign up for a boycott. More than 13,000 scientists across the world have now pledged variously not to publish with or referee or do editorial work for Elsevier. \n               boxed-text \n             The signatories are only a tiny fraction of the world\u2019s researchers\u00a0\u2014\u00a0but the campaign was a spark in this year\u2019s explosion of interest in open access and new visions for research publishing. In February, Elsevier, facing growing criticism, withdrew its support of the Research Works Act, a proposal to prohibit the US government from requiring open-access publication for the research it funds. In July, the UK government mandated that much of the nation\u2019s taxpayer-funded work be published openly from April 2013. This year also saw the birth of several experimental publishing models, such as the open-access venture PeerJ, which will publish any number of an author\u2019s papers for a one-off fee. \u201cWe\u2019ve disagreed with a lot of what [Gowers] has claimed, but for certain he\u2019s helped us better understand the sentiment of the maths community,\u201d says Tom Reller, head of Elsevier\u2019s global corporate relations. Gowers\u2019 campaign was \u201ca little bit accidental\u201d, says Ben Green, a fellow Cambridge mathematician. Gowers agrees. He may have won the Fields Medal in mathematics and, this year, a knighthood, but in academic publishing he says he is an amateur. \u201cI feel more like an individual whose views just happened to resonate with others\u2019.\u201d \n               Bernardo De Bernardinis: On the fault line \n             \n               Convicted of manslaughter after a deadly earthquake, an Italian official says that he had put his trust in scientists. \n             \n               By Nicola Nosengo \n             Minutes after hearing himself declared guilty of manslaughter, Bernardo De Bernardinis looked like a defeated man. With shadowed eyes, he told journalists outside the court in L\u2019Aquila, Italy, that he was \u201cinnocent before God and men\u201d. De Bernardinis\u2019s journey to court began in early 2009, when a string of seismic shocks around L\u2019Aquila rattled the local community. On 31\u00a0March, De Bernardinis and six of the country\u2019s seismic experts participated in a meeting of Italy\u2019s Major Risk Commission to assess whether a serious earthquake might be imminent. Some townspeople say that the advice they received from the experts was reassuring\u00a0\u2014 but six days later, a magnitude-6.3 quake struck, killing more than 300\u00a0people in the region. In October this year, the court of L\u2019Aquila found the seven guilty of the manslaughter of 29 of those people, and sentenced them all to six years in prison. The trial and verdict attracted worldwide attention \u2014 and De Bernardinis was at the centre of the storm. An engineer by training, De Bernardinis was in 2009 deputy head of the Italian Department of Civil Protection. He was the only government official on the expert panel and was charged with deciding what to do. In a now-infamous television interview shortly before the meeting, he said that the situation was \u201cfavourable\u2009\u2026\u2009according to the scientific community\u201d, that minor shocks were linked to \u201ca continuous discharge of energy\u201d and that \u201cthere is not an immediate danger\u201d. \n               boxed-text \n             The trial prosecutors argued that those messages falsely reassured the local population. Seismologists from the National Institute for Geophysics and Volcanology (INGV) in Rome, some of whom were tried alongside De Bernardinis, have criticized him for suggesting that minor shocks release energy and lower the risk of a big earthquake\u00a0\u2014 an incorrect concept, they say, which was not raised at the meeting or in any official INGV communication. Throughout the trial, De Bernardinis, now president of the Institute for Environmental Research and Protection in Rome, never hid from his critics. He was the only one of the indicted who showed up at every hearing and he speaks with respect of the citizens who brought the case. \u201cHad I lost a son, a relative or a friend in the earthquake, I would have done the same,\u201d he says. \n               boxed-text \n             In November, a few weeks after the verdict, De Bernardinis is ready to resume battle at appeal. A chatty, energetic man in his mid-60s, he flips through hundreds of pages of press clippings and documents that he has put together for the case. He pounds his fist on the table when he rejects charges that he meant to reassure the population or that he denied the risk of a big earthquake. In interviews before and after the L\u2019Aquila meeting, he insists, he was \u201crepeating, not modifying\u201d concepts used by the seismologists, and he denies saying that the discharge of energy decreased risk. He blames the press for misreporting his interviews and says that by \u201cfavourable\u201d, he meant that the minor shocks had not yet caused major damage. De Bernardinis does acknowledge that he should have waited until after the meeting before giving an interview, and that he would have avoided problems if he had asked the scientists to prepare a written note for the press. \u201cI understand scientific language, but I am not a seismologist,\u201d he says. \u201cI could only trust what seismologists said.\u201d The prosecutor at the trial, Fabio Picuti, seemed to agree when he called De Bernardinis \u201ca victim of the seismologists\u201d in his final argument; the seismologists disagree. While the case inches towards appeal, De Bernardinis continues to work, and keeps the wrinkled trial documents in his briefcase. \u201cThey follow me everywhere,\u201d he says. De Bernardinis hopes that the trial will eventually lead to a better risk-prevention system in Italy, by clarifying the obligations of scientists, government officials and the media. He still considers himself innocent. \u201cBut if at the end of the appeals I will still be found guilty, I\u2019ll go to jail, no problem,\u201d he says. \u201cI\u2019d rather go to jail feeling I am innocent than stay out feeling I\u2019m guilty.\u201d \n               Ron Fouchier: Flu fighter \n             \n               A virologist did research that some deemed too dangerous to publish, and he spent much of the year defending his work. \n             \n               By Declan Butler \n             The Dutch are known for being blunt, and Ron Fouchier, a virologist at the Erasmus Medical Centre in Rotterdam, certainly seems to live up to that reputation. His candour caught global attention at the end of 2011, when he described his experiments to engineer a strain of highly pathogenic H5N1 avian influenza that can be transmitted between mammals. His team had \u201cmutated the hell out of H5N1\u201d, Fouchier told a flu-research conference in Malta, until it could infect ferrets\u00a0\u2014\u00a0and presumably humans\u00a0\u2014\u00a0through the air. Just five mutations were enough to cause this change, suggesting that wild H5N1 strains might eventually evolve to spread in humans. \u201cThis is very bad news, indeed,\u201d he said. \n               boxed-text \n             His work ( S. Herfst  et al. Science    336,  1534\u20131541; 2012 ), and similar experiments by Yoshihiro Kawaoka ( M. Imai et al. Nature 486, 420\u2013428; 2012 ), a virologist at the University of Wisconsin\u2013Madison and the University of Tokyo, prompted the US National Science Advisory Board for Biosecurity (NSABB) to recommend in December\u00a02011 that the research findings be published only if key methodological details were left out. The events sparked an international debate as to whether the risks of an accidental or intentional release of the pathogens outweighed any benefits of the research. Fouchier relentlessly defended the rationale and safety of his work. In public debates, commentaries and media interviews, he often dismissed opponents\u2019 arguments against the research, playing down the risks, and he often seemed exasperated when arguing against those who scrutinized the flu-research community. In March, the NSABB reconvened and eventually gave the green light to publishing both papers. Fouchier was at the airport on his way home from the NSABB meeting when he heard the news. \u201cBoy, did that glass of champagne in the airplane taste good!\u201d he recalls. \n               boxed-text \n             Still, the Dutch government refused to let him publish until he applied for an export permit, which the government requires for the release of material or information that could have malicious uses. Fouchier threatened to defy the mandate, but backed down after it became clear that such action risked up to six years\u2019 imprisonment (see   Naturehttp://doi.org/hvg;2012 ). He got the permit and published the work, but is still disputing in the courts that export-control laws apply. \u201cIf there is anything I can do to prevent future generations of infectious-disease specialists being censored against their will by government, I\u00a0will do it,\u201d says Fouchier. In January 2012, flu biologists including Fouchier agreed to a voluntary moratorium on the specific kinds of experiments that had sparked the debate. Although initially set for 60 days, the moratorium remained in place as  Nature  went to press, and Fouchier, among others, complains that it has gone on for too long. It has put a hold on some of his research, but Fouchier says that a mysterious case of deadly pneumonia in Saudi Arabia over the summer drew him back into the lab. He discovered that the victim had died from a previously unknown coronavirus that has since been recognized as the cause of an outbreak in the Middle East (see  Nature   492, 166\u2013167; 2012 ). Before that case, Fouchier had been resigned to spending the year dealing with the \u201cpolitics, censorship, moratorium, biosafety and biosecurity\u201d of the H5N1 experiments, he says. \u201cIt was a good therapy for me to get back to work.\u201d \n                     Nature special: 2012 review of the year 2012-Dec-20 \n                   \n                     366 days: Images of the year 2012-Dec-19 \n                   \n                     366 days: An interactive journey through 2012 in numbers 2012-Dec-19 \n                   \n                     366 days: 2012 in review 2012-Dec-19 \n                   \n                     Features of the year 2012-Dec-18 \n                   \n                     News: Readers' choice 2012-Dec-14 \n                   \n                     Nature\u2019s sexism 2012-Nov-21 \n                   \n                     Hurricane sweeps US into climate-adaptation debate 2012-Nov-06 \n                   \n                     Independent labs to verify high-profile papers 2012-Aug-14 \n                   \n                     Curiosity sets down safely on Mars 2012-Aug-06 \n                   \n                     Cancer stem cells tracked 2012-Aug-01 \n                   \n                     Physicists declare victory in Higgs hunt 2012-Jul-04 \n                   \n                     Elsevier boycott gathers pace 2012-Feb-09 \n                   \n                     Call to censor flu studies draws fire 2012-Jan-03 \n                   \n                     Scientists on trial: At fault? 2011-Sep-14 \n                   \n                     Chinese bioscience: The sequence factory 2010-Mar-03 \n                   Reprints and Permissions"},
{"file_id": "491176a", "url": "https://www.nature.com/articles/491176a", "year": 2012, "authors": [{"name": "Leigh Phillips"}], "parsed_as_year": "2006_or_before", "body": "The African Institute for Mathematical Sciences was set up to breed a new generation of numerical talent. Now it is spreading across the continent. Alex Bamunoba is not quite sure how many siblings he has. \u201cMy father was polygamous, so we ended up being very many,\u201d he says. \u201cSomething close to 30\u00a0brothers and sisters, with different stepmums.\u201d But when it comes to the branch of pure mathematics known as number theory, Bamunoba is on solid ground. He won a place in a PhD programme at Stellenbosch University in South Africa, and he hopes to teach mathematics in his home country, Uganda, or elsewhere in Africa. The bridge that took Bamunoba from a Ugandan village to Stellenbosch is the African Institute for Mathematical Sciences (AIMS). The aim of AIMS, which was started in 2002 by cosmologist Neil Turok, is to recruit the brightest students from across Africa and match them up with a faculty of top-tier mathematicians, computer scientists and physicists from around the world for a one-year postgraduate diploma in maths. Turok argues that a generation of mathematically trained graduates will empower Africa by strengthening the continent\u2019s research base and by focusing on fields that are key to industry and policy, ranging from mathematical modelling to computing, censuses and financial management. \u201cThere is nothing more cost-effective for development than mathematics,\u201d says Turok, who is head of Canada\u2019s Perimeter Institute for Theoretical Physics in Waterloo. Ten years on, AIMS, based in Muizenberg, South Africa, has graduated 407 students, of whom 315 are still in Africa (see \u2018Where the graduates go\u2019). Around 40% have gone on to do PhDs, one-quarter are working in academia as postdocs, researchers or teachers, and nearly 7% are in industry. Turok\u2019s team is proud to have produced statisticians for the Zambian Energy Regulation Board, systems engineers for Namibian IT consulting firms, epidemiology researchers in South Africa and lecturers at multiple African universities who in turn educate hundreds of students each year. \u201cWhat AIMS is doing is so important,\u201d says Kwame Akyeampong, a senior policy analyst and mathematician with the United Nations Educational, Scientific and Cultural Organization (UNESCO) in Paris, who specializes in education evaluation. \u201cAfrica is deluding itself if it thinks it can produce a South Korea or a China without advanced maths and science training.\u201d Now Turok and his team are expanding. In the past 14 months, they have opened institutes in Senegal and Ghana. Next year, they plan to open a fourth in Ethiopia. Turok\u2019s long-term vision is a network of 15 such schools throughout Africa. \u201cOur future goal is to have a major impact on Africa\u2019s development,\u201d says Turok. \u201cThis will require training large numbers \u2014 many thousands \u2014 of students, so they form a highly skilled community.\u201d And to build that community, says Turok, AIMS is pioneering a new style of education. \u201cWe\u2019re reinventing the university,\u201d he says, \u201cand if you want to do this, the best place to come is Africa.\u201d \n               Early inspiration \n             Turok was born in Johannesburg, to prominent anti-apartheid militants. His parents were imprisoned for their activism, and his father is still an ANC member of parliament. Neil Turok left the country to pursue studies in theoretical physics in the United Kingdom and the United States. But he remained strongly connected to \u2014 and increasingly frustrated by \u2014 his home continent. \u201cAbout a trillion dollars has been spent on aid to Africa over the past decade, with no obvious results,\u201d he says. Part of the problem, according to Turok, is a lack of mathematical expertise in African governments. \u201cThey bring in consultants from Europe or buy off-the-shelf software that may not be appropriate. Major policy decisions are being made off the back of this with such poor understanding.\u201d Yet African education systems are in no position to fill the gap. \u201cUniversities over the past 30\u201340 years have suffered from chronic underinvestment, privatization, isolation and a terrible loss of morale,\u201d he says. \u201cThe teaching of mathematics and sciences has really been in crisis.\u201d After Turok came up with the idea for AIMS, he convinced the South African theoretical physicist Fritz Hahne to become the school\u2019s first director. In 2002, using a 1-million-rand (US$100,000) donation from the Turok family, the pair bought and transformed a rundown art deco hotel a street away from the beach in a small town 21 kilometres from Cape Town. In August 2003, with funding from international donors and the South African government, the institute opened its doors to the first 30\u00a0students. Today, the annual cohort stands at 50. A visitor to the institute today steps off the scruffy yellow cars of Cape Town\u2019s metropolitan railway and smells the sharp tang of the Atlantic ocean. The beach and its crashing waves have long made this village, with its vegan caf\u00e9-cum-bookshop and marijuana-fragranced jazz hangout, a magnet for surfers and freethinkers. The peach-coloured institute, filled with utopian mathematicians, seems right at home. The programme is divided into three parts. An introductory phase ensures that everyone has a common grounding in problem-solving and computing, and a good grasp of English. This is followed by intensive three-week courses in topics such as biomedical signal processing, quantum computing and natural-systems modelling, taught by instructors who fly in from around the world. All this is rounded out with a seven-week research project that can form the basis of doctoral work should a student decide to continue to a PhD. Students are tested in oral examinations rather than in written ones, in an effort to test their knowledge of ideas rather than their skill at passing a test. The three-week courses have been key to the institute\u2019s success, says Turok. In the past year, course teachers have included 15 South African and 18 international academics, including mathematicians Laurent Lafforgue and Maxim Kontsevich, both winners of the Fields Medal (the International Medal for Outstanding Discoveries in Mathematics) and based at the Institute of Advanced Scientific Studies near Paris. The village\u2019s long, surfer-friendly beach is one attraction for instructors, jokes Barry Green, the school\u2019s director since 2010 and former head of Stellenbosch University\u2019s Department of Mathematical Sciences. \u201cBut more seriously, it\u2019s because we\u2019re flexible. With courses three weeks long, it\u2019s easy for people to get away.\u201d Juan Rodr\u00edquez Aguilar, a computer scientist at Spain\u2019s Artificial Intelligence Research Institute in Bellaterra, last year taught a short course on the programming language Python and, seduced by the experience, is back again this year. \u201cIt was so shocking when I first went to the lab,\u201d he says. \u201cIt slowly became clear that some people had never seen a computer before. I was thinking: \u2018Where the hell am I?\u2019\u201d The level of interaction is intense, says Aguilar. Students work all hours and go for long walks on the beach to thrash out ideas. Instructors and students live on site and eat together in the cafeteria, where the lively discussion continues. \u201cThe schedule says we should be working with them for two hours a day, but really, it\u2019s more like five.\u201d And after three weeks, he says, \u201cthey were writing their own programmes, doing loops, doing integrals, derivations. I thought: \u2018This is just fantastic.\u2019\u201d The institute\u2019s fees also set it apart. There are none: travel, accommodation, food and a stipend are all covered by AIMS, at a cost of roughly $10,000 per student per year. Turok says that this is essential in a continent where some students wouldn\u2019t be able to afford even the plane ticket to Cape Town. AIMS South Africa now costs 18 million rand a year to run, with an extra 1.5 million rand for an enrichment programme for elementary and secondary school teachers and pupils and 5 million rand for the attached research centre. The South African government currently funds the school\u2019s infrastructure and research groups to the tune of 13 million rand, and tuition costs are paid for by donors. Above all, the institute\u2019s success hinges on finding and recruiting good students, which it does through a network of trusted contacts in academia that keep an eye out for mathematical talent. Tina Ambinintsoa Malalanirainy Rakotoson, a tiny woman from Madagascar who writes down her name for a reporter to make sure it\u2019s not misspelt, wanted to come because her home country doesn\u2019t offer high-level training in the aspects of mathematics that fascinate her. She beams when she talks about the school and the thrill of being with students from across the continent. \u201cEverybody speaks science. It\u2019s very exciting. It\u2019s not really like this back home,\u201d she says. \u201cIt\u2019s like a library with people instead of books.\u201d \n               Inclusive approach \n             But is AIMS helping Africa? The school\u2019s administration is certainly proud that most of its alumni have remained in the continent. \u201cWhen students want to build their career, it\u2019s normal that they may want to go elsewhere,\u201d says Green. \u201cBut we want to have a significant number that stay.\u201d Students are instilled with the school\u2019s mission to help Africa, and its leaders often talk of its \u2018pan-African spirit\u2019 \u2014 a term from the days of anti-colonial and anti-Apartheid struggle denoting the unity of the continent. Turok and his colleagues are also making tangible efforts to keep students there. In 2008, AIMS opened a research centre across the road from the main building, funded by the South African government to the tune of 5 million rand per year. There, current and former AIMS students mix with academics, postdocs and PhD students from elsewhere. \u201cWe realized we had created such a unique community. Such highly motivated students,\u201d Turok says. \u201cWhy were we sending them away? Here, they would be much more encouraged to do path-breaking research.\u201d The research centre hosts four research groups, which explore cosmology and astrophysics, mathematical biology, computational algebra and mathematical finance. \u201cWe picked ideas that were not very mainstream in Africa, but very modern, that could then be spun off to universities after ten years,\u201d says Bruce Bassett, the ebullient head of the cosmology research group. With Africa\u2019s sky-high incidence of HIV, malaria and tuberculosis, it was obvious to focus on mathematical biology, which can help to tackle such diseases through systems biology, for example, or epidemiological modelling. The cosmology group, the largest at AIMS, is girding itself for rapid growth alongside the two giant astronomy facilities planned for South Africa: the Square Kilometre Array (SKA), a \u20ac1.5-billion (US$1.9-billion) effort to build the world\u2019s largest radio telescope (see  Nature 485, 555\u2013556; 2012 ) in South Africa and Australia; and South Africa\u2019s MeerKAT, a giant radio telescope in its own right and the technology demonstrator for SKA. The group hopes to develop methods for handling the overwhelming amounts of data that these instruments will generate as they survey the sky. The focus on cosmology and astrophysics, Turok admits, has prompted observers to ask: \u201cWhat\u2019s that got to do with Africa\u2019s needs?\u201d \u201cBut that\u2019s missing the point,\u201d he says. \u201cIt\u2019s not about bringing Africa up to some mediocre level, or worse, about mere survival. It\u2019s about demonstrating that Africa can produce world-leading scientists.\u201d \n               IN search of excellence \n             Charles Leadbeater, a London-based expert who has advised companies and governments on education innovation, compares AIMS to the Indian Institutes of Technology, a network of regional public engineering schools developed in the 1960s, and their successors, the Indian Institutes of Information Technology, which, he says, have been real drivers of the country\u2019s development. He also praises AIMS\u2019s intensive teaching structure. \u201cThere are really few places at any level that quite have that dynamic, highly creative, lateral community feel. It\u2019s like going to Pixar or Google,\u201d he says. But Akyeampong says that higher education alone can\u2019t drive Africa\u2019s development. \u201cWhat\u2019s really lacking is excellence in maths education at the base\u201d for children in their first few years of schooling, he says. \u201cUntil that is resolved, you are never going to get the critical mass of mathematically literate that will have the serious impact on development that the AIMS people are hoping for,\u201d he says. AIMS has had its rough patches. The South African government has long demanded more return on its investment, and pushes AIMS to take in more domestic students. AIMS responded by adding a second intake in January \u2014 after South Africa\u2019s summer \u2014 to fit with the country\u2019s educational timetable and open it up to students. And the expansion of AIMS to other countries has caused growing pains. Funders were sceptical, and a partnership to start an AIMS centre with the African University of Science and Technology (AUST), a private university set up by the World Bank in 2007 in Abuja, Nigeria, foundered. One reason, says Turok, is that the AUST charges US$20,000 a year, but AIMS insisted that all costs be covered. \u201cThey also don\u2019t emphasize the importance of having women students the way we do,\u201d says Turok. \u201cWe have a minimum placement of 30% women students. They have two to three women out of a hundred students. From our point of view, this is unacceptable.\u201d After the first flush of success with the South African campus and initial efforts to expand, \u201cwe seemed to be in danger of losing momentum\u201d, says Jan Groenewald, an IT specialist at AIMS. But in 2008, Groenewald says, things started to go their way. An AIMS alumna Esra Khaleel from Darfur in Sudan came up with the idea of an \u2018African Einstein\u2019. Turok adopted that branding, and the proposed network of institutes became known as the \u2018Next Einstein Initiative\u2019. \u201cIt turned out to be a hit with students and funders,\u201d Groenewald says. \u201cThen things started to move really fast.\u201d In 2010, Google awarded AIMS US$3 million to the project, and last year, the Canadian government committed Can$20 million (US$20 million) over five years. The initiative now encompasses an office in Cape Town with more than ten full-time staff, as well as the new centres in Ghana and Senegal. As the centres proliferate, the plan is to open neighbouring research groups with their own mathematical specializations. The Senegal institute in M\u2019bour, 80\u00a0kilometres south of Dakar, will be specializing in mathematics associated with solar energy and erosion \u2014 two natural topics in a country threatened by a steadily advancing Saharan desert. Hahne, who continues to teach at the school, says gruffly that he is not fond of the branding. \u201cI\u2019m not looking for the next Einstein,\u201d he says. \u201cI\u2019m looking for the solid development of science in Africa.\u201d But Turok, who says that the Perimeter Institute has now modelled its one-year master\u2019s programme on AIMS, is clear that there is substance beneath the slogan. \u201cAfrica is the greatest untapped pool of scientific talent anywhere, and no one realizes this,\u201d he says. Rakotoson does. Although some of her friends back home also like maths, they enter finance \u201cto make money\u201d, she says. \u201cThey don\u2019t love mathematics. I love it!\u201d \u201cDo you want to know why?\u201d she asks, leaning forward, as if divulging a secret. \u201cIt\u2019s because it\u2019s like a game. When you know all the rules, you\u2019ll always win.\u201d See Editorial  page 159 \n                     Africa AIMS high 2011-Jun-29 \n                   \n                     Material progress in Africa 2010-Nov-02 \n                   \n                     Advancing science in Africa 2007-Oct-21 \n                   \n                     African institute ready for meeting of mathematical minds 2003-Sep-18 \n                   \n                     Nature special: Africa \n                   \n                     African Institute for Mathematical Sciences \n                   Reprints and Permissions"},
{"file_id": "491322a", "url": "https://www.nature.com/articles/491322a", "year": 2012, "authors": [{"name": "Geoff Brumfiel"}], "parsed_as_year": "2006_or_before", "body": "Fully fledged quantum computers are still a long way off. But devices that can simulate quantum systems are proving uniquely useful. When high-energy physicists announced in July that they had found the long-sought Higgs boson \u2014 their biggest find in decades \u2014 the thousands of individuals involved rightly held their heads high. But in some sense, they had already been beaten to the prize. Months earlier, a team of nine physicists had taken a rarefied vapour of rubidium-87 atoms, cooled it down to very near absolute zero and used lasers to arrange the atoms into a tiny grid. The physicists then tweaked the temperature until the atoms neared a critical \u2018phase transition\u2019 \u2014 a point between two different behaviours, such as liquid water and solid ice. Monitoring their grid in this in-between region, the researchers saw an unusual wave of energy that appeared momentarily and then died away 1 . Mathematically speaking, this behaviour was the same as the appearance and decay of a Higgs particle inside a particle collider. \u201cObviously, it\u2019s not at all the Higgs particle,\u201d says Immanuel Bloch, the researcher who led the study at the Max Planck Institute for Quantum Optics in Garching, Germany. If nothing else, this particle moved in only two dimensions, whereas the Higgs moves in three. But the experiment is still helpful for particle physicists, says Bloch, because it gives them a new way to explore and test the complex quantum field theories that underlie the Higgs. This experiment also put Bloch and his team at the vanguard of the rapidly growing field known as quantum simulation. The idea, broadly speaking, is to use orderly systems such as a grid of atoms to model much more complicated things\u00a0\u2014\u00a0new particles, for example, or high-temperature superconductors. The behaviour of such systems cannot be derived by hand, and even the world\u2019s fastest super\u00adcomputers can\u2019t model them. Quantum simulators are the lesser sibling of an idea in physics known as quantum computers, which have been touted for more than three decades as a way to do everything from complex modelling to code-breaking. What the simulators and computers share is an ability to operate by the rules of quantum mechanics. Where they differ is in computational power: quantum computers are general-purpose machines able to carry out any possible algorithm, whereas quantum simulators have to be tailored specifically for the problem at hand. Current-generation simulators are also tough to control, and they may not be able to tackle every problem. Nevertheless, the simulators are much easier to build than quantum computers. And researchers say that the devices will soon be able to solve at least some quantum problems that can\u2019t be tackled in any other way. \n               Nuts and bolts \n             The world of quantum physics is full of theorems, but one goes unwritten: if you want to get noticed, show that your idea came from Richard Feynman. Feynman, the mid-twentieth-century\u2019s greatest theoretical physicist, came up with the idea of quantum simulation in 1981 when he was asked to deliver a keynote speech at the Massachusetts Institute of Technology (MIT) in Cambridge 2 . He decided to talk about how physics might be simulated with computers and got straight to the core of the problem: computers run on certainty, but at a fundamental level, nature deals in probability. According to the laws of quantum mechanics, he knew, particles very rarely exist in one state or another, but instead live in a \u2018superposition\u2019 of two states at once. When observed, the paradox resolves itself according to the laws of statistics. For example, an electron\u2019s \u2018spin\u2019 may orient itself in one direction half the time, and in the other direction for the other half. It is not hard to program a normal computer to model the probabilistic behaviour of that one electron, said Feynman. But particles do not live in isolation, and in quantum systems their probabilities are linked, or \u2018correlated\u2019. These correlations mean that every combination of particle states must be computed separately, and this creates an exponential rise in complexity. A system with three electrons has eight possible configurations, with eight probabilities to compute; 300 electrons create as many configurations as there are atoms in the known Universe. Feynman spent most of his lecture trying to find a way out of this conundrum. It is not easy using ordinary computers, he concluded, but there is another possibility: build a computer that thinks in terms of probabilities. This quantum imitator, as he called it, would look a lot like whatever system you were trying to model. It wouldn\u2019t need to crunch every outcome, but instead would simply recreate the range of probabilities. Rather than delivering one solution, the imitator would deliver many, and the likelihood of each answer would create a probabilistic picture of how the complex system behaves. Feynman didn\u2019t do the maths, but he did conclude that almost any quantum system \u201ccan be simulated in every way, apparently, with little latticeworks of spins and other things\u201d. At the time of Feynman\u2019s talk, the little lattices of which he spoke didn\u2019t exist. Quantum systems are extremely fragile, in the sense that almost any interaction with the outside world will destroy the delicate correlations. It has taken 30 years to develop the technology required to keep the particles isolated enough to finish the simulation unimpeded, yet interactive enough to let physicists extract the answer. But there are now several options. Bloch\u2019s group uses neutral atoms, other teams are combining electric and magnetic fields with lasers to trap ions of lighter atoms, such as beryllium. A third technique involves controlling eddies of current inside superconducting microcircuits, and a fourth uses quantum particles of light \u2014 photons \u2014 moving through microscopic waveguides (see \u2018Quantum board games\u2019). All these techniques are rapidly increasing in their capabilities. In April, a group led by John Bollinger at the National Institute of Standards and Technology in Boulder, Colorado, unveiled a two-dimensional system of hundreds of trapped ions that could simulate a form of quantum magnetism 3 . The simulator seems to work well for weak fields of the sort that can already be modelled on classical computers, says Bollinger. Now, with some modifications, he hopes to simulate strong magnetic fields, which are beyond the reach of even the most powerful supercomputers. Bloch, meanwhile, is considering applications beyond the Higgs for a neutral-atom simulator. For example, the rubidium atoms in his lattice might be used to model a complex class of materials called high-temperature superconductors. These \u2018high- T c \u2019 materials can conduct electrons with no resistance at temperatures much higher than conventional superconductors can \u2014 but for decades nobody has been able to understand why. Theorists have developed a number of competing models to explain the behaviour, but haven\u2019t been able to test them: the electrons in the superconductors are just too difficult to isolate and study. So Bloch wants to use atoms as surrogates. By changing the intensity of the criss-crossing laser beams, atoms can be made to tunnel from one point in the lattice to another in a way that mimics the motion of electrons through the atomic lattice of a high- T c  material. At least some theories of high- T c  superconductivity should be checkable with Bloch\u2019s set-up. Quantum simulators might even be able to model non-quantum problems, such as protein folding, that still require huge amounts of computing power to decipher. A group at the Canadian company D-Wave Systems in Burnaby and at Harvard University in Cambridge, Massachusetts, recently did just that by mathematically mapping the folding problem onto a quantum system of 128 loops of current spinning on a superconducting chip 4 . Each loop could spin clockwise, anticlockwise or in a superposition of both directions simultaneously. The performance of the system wasn\u2019t great; in one of its protein-folding problems, it found the correct, experimentally determined, answer just 13 out of 10,000 times. Still, says Al\u00e1n Aspuru-Guzik, a theoretical chemist from Harvard and co-author of the paper, \u201cit\u2019s remarkable to me that it was possible to do it\u201d at all. \n               Goal change \n             Despite all the technical progress, however, the existing simulators are at best a limited approximation of Feynman\u2019s original vision\u00a0\u2014\u00a0a fully fledged quantum computer that is \u2018universal\u2019, or able to execute any quantum algorithm and simulate any conceivable quantum system. Researchers have been exploring the potential applications of such a device ever since Feynman described it. Arguably the most important one came in 1994, when mathematician Peter Shor, now at MIT, laid out an algorithm that would allow a quantum computer to function as a powerful code-breaking machine 5 . Other quantum algorithms have followed, drawing many scientists (and several intelligence services) into the quest for quantum computing and sparking widespread efforts to create such a machine. Yet building a powerful, universal quantum computer has proven to be a tough task. A true Feynman computer would be able to control thousands or millions of atoms at once, but most of the current systems face a trade-off between size and control. Bloch, for example, can hold as many as hundreds of thousands of atoms in his laser lattice, but he can\u2019t then set their quantum states individually. Other researchers have more control over individual atoms, but their systems, which use trapped ions of beryllium, can manage only a handful of atoms with exquisite precision. On top of this comes the omnipresent problem of disruptions from the outside world, which ruin delicate quantum states: even the tiniest bump will create a computational error.  In a quantum computer you have to make sure that no particle makes a mistake.  With current systems so far from the ideal, quantum simulators have come to be seen as less of a stepping stone, and more of a goal in their own right. Simulators do not need to be as large as computers, and, crucially, because the answer is encoded as an average across all their atoms, they are believed to be tolerant of the outside disruptions. \u201cIn a quantum computer you have to make sure that no particle makes a mistake,\u201d says Ignacio Cirac, a theorist at the Max Planck Institute for Quantum Optics. \u201cIn a quantum simulation, if you have 100 particles and one of them is wrong, then 99 are still right.\u201d Some see parallels to the middle of the last century, when scientists such as Vannevar Bush were experimenting with \u2018analog\u2019 computers made from resistors and capacitors. The machines were tailored to specific problems or to a class of problems, and could perform a simple set of operations on an input signal. Some of the devices could even perform mathematical calculations. In retrospect, they seem puny compared with digital computers, which use programmable combinations of transistors to perform practically any program. But they were fast, robust and valuable for applications that matched their architecture, says Seth Lloyd, a theoretical physicist and engineer at MIT. They were particularly good at controlling machinery, for example. \u201cAll the control circuits in the Saturn moon rocket were analog,\u201d Lloyd says. Like analog computers, quantum simulators are closely tied to their constituent parts, and are less flexible than a true quantum computer. But Lloyd thinks that they might yet find their \u2018Moon shot\u2019 in problems of quantum complexity. For example, as microprocessors shrink and new materials are engineered at a molecular level, quantum effects become more and more important. That, in turn, will lead to a dramatically growing need for quantum modelling that allows designers to understand and predict the materials\u2019 behaviour. At least some of those needs are going to be met by quantum simulators, Lloyd predicts. \u201cWhat seems to be happening is that quantum simulators work on a variety of special cases,\u201d he says, \u201cand the number of cases seems to be growing rather rapidly.\u201d Aspuru-Guzik has one such process in mind: photosynthesis. When light strikes a leaf, it creates a pair of negative and positive charges that travel long distances to reaction centres, where they are used to make energy for the plant. The charge pairs may travel according to the rules of quantum mechanics: some researchers think that the collective wavefunction of the pairs spreads out across the light-absorbing chromophore molecules inside the leaf, allowing the pairs to move more efficiently than they would classically (see  Nature 474, 272\u2013274; 2011 ). Aspuru-Guzik and others think that a simulator could help them to pin down exactly how this happens. Photosynthesis is what Aspuru-Guzik calls a \u201cdirty quantum system\u201d\u00a0\u2014\u00a0that is, it contains both quantum and classical elements. A little matrix of superconducting current loops might be perfect for modelling it, he argues, because the loops, too, are subject to noise from the outside world. It still wouldn\u2019t be easy, however: Aspuru-Guzik estimates that something such as photosynthesis would require hundreds of quantum bits to simulate, and those systems, he predicts, are at least a decade away. The ambitions of the scientists developing quantum simulators are considerably more modest. Most are starting their systems out on models that can be calculated with conventional supercomputers to prove that their simulators produce reliable results. Gradually, they plan to push their atoms, current loops or other little units to the point at which the supercomputers can no longer cope.  The model that we\u2019re able to implement might not even correspond to a real material.  At that point, \u201cthe model that we\u2019re able to implement might not even correspond to a real material, but in a sense, who cares?\u201d, says Chris Monroe, a physicist at the University of Maryland in College Park. Even if they don\u2019t behave like a superconductor or a Higgs particle, the new systems may still be able to tell researchers a thing or two that their older machines can\u2019t. Eventually, Monroe and others believe that simulators will be tailored to model different things. Cold atoms, for example, might work best on superconductors, whereas ions could handle magnetism. Of course, there will still be quantum systems that are too tough for any set-up to tackle. It may be a vision considerably less flashy than Feynman\u2019s universal quantum machine, yet within the physics community, quantum simulators are getting more attention than ever before. \u201cMany physicists who sort of pooh-poohed the idea of quantum computing, especially ten years ago or so, they\u2019re now sort of embracing this,\u201d says Monroe. The systems may be less ambitious, but that may make them more achievable. Lloyd puts it another way. \u201cIf life doles you quantum lemons, let\u2019s make quantum lemonade,\u201d he says. Simulators may not be as sweet as quantum computers, but \u201cas long as the lemonade is tasty and refreshing, I think that\u2019s fine\u201d. \n                     Silicon quantum computer a possibility 2011-Jan-19 \n                   \n                     Quantum computation: The dreamweaver's abacus 2008-Apr-16 \n                   \n                     2020 computing: Champing at the bits 2006-Mar-22 \n                   \n                     Nature Physics  Insight: Quantum simulation \n                   \n                     Immanuel Bloch \n                   \n                     Quantum simulation at NIST \n                   \n                     Alan Aspuru-Guzik \n                   \n                     Christopher Monroe \n                   Reprints and Permissions"},
{"file_id": "491514a", "url": "https://www.nature.com/articles/491514a", "year": 2012, "authors": [{"name": "Courtney Humphries"}], "parsed_as_year": "2006_or_before", "body": "Ecologists are exploring how people, buildings, wildlife and pollution interact in the world's cities. Nathan Phillips steps out onto the roof of Boston's Prudential Tower and looks down at the city 50 stories below. Up here, the rush of the wind has replaced the cacophony of car horns, screeching brakes and conversations filling the streets. And the rarefied air carries none of the odours that wrinkle an urban nose. The roof is \u201cessentially a different atmospheric environment from the rest of the city\u201d, says Phillips, an ecologist at Boston University in Massachusetts. That rarefied air is what brings Phillips to the top of the tower. He has set up four book-sized collectors, one at each corner of the roof, to capture air blowing across the city. Black tubing carries the air samples to a tank inside the building, where a computer analyses their levels of carbon dioxide, carbon monoxide, methane and water vapour. Like most cities, Boston brews up a blend of gases that covers the urban area like a dome. The top of the Prudential Tower is inside or outside this metropolitan atmosphere, depending on the weather. From his rooftop eyrie, Phillips looks towards three other sampling sites around the city and another some 70 miles west, in the green hills outside the pollution zone. Phillips and his colleagues are using data from these sites to model how carbon dioxide and other gases move through the city, and how the mix differs from the air in rural areas. The work is part of an interdisciplinary project to study Boston's 'metabolism' \u2014 how elements are exchanged between natural and human systems. Phillips and his team are now focusing on atmospheric carbon \u2014 particularly carbon dioxide and methane. Next, they plan to look at carbon in the city's soils and water, and to track the flow of water, nitrogen and pollutants. \u201cThe goal is to understand the function of a major city,\u201d Phillips says. \n               Cities under the microscope \n             The work is part of the growing field of urban ecology, in which scientists study cities as if they were ecosystems. In the past, artificial and natural elements have been studied separately, but urban ecologists seek to understand the interplay between them \u2014 such as how heat and high carbon dioxide levels boost plant growth, how trees cool cities and how green spaces improve animal habitat. Using ecological methods to tease apart those relationships can improve urban areas for people as well as natural systems, says Phillips. \u201cThe scientific study of cities should yield practical benefits in terms of making our cities more sustainable,\u201d he says. There is a growing need for this kind of research. With cities launching efforts to slash carbon emissions, reduce water use and improve habitats, scientists are beginning to evaluate how such policies affect the overall health of the urban environment. \u201cYou need science to help you understand how you are going to best progress towards those goals,\u201d says Steward Pickett, an urban ecologist at the Cary Institute of Ecosystem Studies in Millbrook, New York. Viewed from the top of the Prudential Tower, Boston is all buildings, cars, pavement and people. But the metropolis also contains nearly 2 million trees, countless tonnes of soil and microbes and a web of wildlife that includes rats, coyotes, deer, more than 100 bird species and the occasional bear or moose in the suburbs. This mix makes for complex relationships \u2014 urban trees, for instance, are affected not only by soil pollutants and heat radiating from asphalt, but also by water-metering policies and landscaping. They can provide cooling shade, but they can also block winds that would blow away pollutants. To study these various factors requires a blend of biological, physical and social sciences. \n               Seeds of change \n             In 2009, the US National Science Foundation (NSF) and the US Forest Service gave urban ecology a boost by providing US$6 million to fund 21 projects, including Phillips's, that directly address the environmental concerns of cities. Many scientists see these grants, dubbed 'Urban Long-Term Research Areas: Exploratory' (ULTRA-Ex) awards, as the first step towards fostering a much-needed research network for long-term projects in urban ecology. The NSF has funded this type of work since the late 1990s, when it set up Long-Term Ecological Research (LTER) sites in Phoenix, Arizona, and Baltimore, Maryland. But such examples are rare. This year, an analysis of more than 8,000 ecological studies found that only 4% assessed densely populated areas 1 , despite calls from some ecologists and the NSF for more investigation of how people shape environments. \u201cWhat has been very surprising,\u201d says Morgan Grove, a research forester at the Forest Service who is involved in the Baltimore LTER study, \u201cis how much of a demand there is for urban-ecology science and data.\u201d The results are not always what civic leaders want to hear. An ULTRA-Ex team at the University of California, Los Angeles (UCLA), for example, raised questions about the impacts of a plan to plant one million trees in that city. The study found that some property owners are reluctant to plant trees along streets, because of maintenance costs and concerns that trees reduce visibility and lead to more crime, says Stephanie Pincetl, a land-use researcher at UCLA, who led the study. And because trees vary in water requirements and how much shade they provide, some species could increase the need for irrigation in the arid region 2 . Another ULTRA-Ex project in Cleveland, Ohio, is studying the effects of converting vacant lots into urban farms. This process could benefit cities with shrinking populations, like Cleveland's, and save millions of dollars in annual maintenance costs, says Michael Walton, an ecologist at Cleveland State University, who is leading the project. Researchers at Ohio State University in Wooster have analysed pollutants, nutrients and food webs in soil from vacant lots, and found that they are generally suitable for planting crops 3 . Other studies show that gardens established in these plots can, over time, develop healthy populations of pest-killing microbes and ants 4 , suggesting that urban farming will not necessarily boost pesticide use in cities. Such studies are becoming more common worldwide, as organizations such as the Stockholm Resilience Centre commit to studying social and ecological interactions in cities. With two ULTRA-Ex projects that are now joining forces, Boston is emerging as a major centre of urban-ecology research. While Phillips studies the city's gaseous metabolism, Paige Warren, an ecologist at the University of Massachusetts in Amherst, is leading a group to assess how efforts to plant vegetation throughout Boston have affected air quality, people and wildlife. \u201cThere should be predictable consequences, but we haven't studied them that much,\u201d says Warren. Phillips and his team are collaborating with Steven Wofsy, an atmospheric scientist at Harvard University in Cambridge, Massachusetts, to model how carbon dioxide moves throughout the city. In addition to the rooftop measurements, the researchers are driving around Boston in a car outfitted with a sampling device to gather high-resolution data on street-level carbon dioxide. They are also studying how carbon dioxide levels and shade from buildings affect plants \u2014 and how trees, in turn, absorb carbon dioxide and cool buildings. \n               Urban exhalations \n             Such studies will be crucial as nations move to reduce greenhouse-gas pollution, because cities are responsible for more than two-thirds of global carbon dioxide emissions from energy use. Most of what is known about cities' overall carbon output comes from combining emissions estimates for traffic, buildings and industries, but there is considerable uncertainty in such inventories. Road transportation is thought to account for about one-third of US greenhouse-gas emissions, but credible inventories for that source in Massachusetts can differ by nearly 40%, says Lucy Hutyra, an environmental scientist and co-leader of the ULTRA-Ex project at Boston University. As cities begin to take carbon regulation more seriously, \u201cwe need to have a transparent, robust, verifiable reporting of carbon dioxide emissions\u201d, she says. Otherwise, cities cannot track their successes and failures. As the researchers complete the first analyses from their atmospheric model of Boston's carbon dioxide concentrations, they are finding some surprises. Their data indicate that traffic emissions in the core of the city are higher than some estimates have suggested. Phillips and Hutyra are also working to identify natural-gas leaks from underground pipes 5 , and they have found more than 3,000 so far (see \u2018Hidden gas leaks\u2019). Their aim is to quantify how such leaks contribute to greenhouse-gas emissions and affect nearby plants and soil. Phillips says that methane from natural gas depletes oxygen in soils, causing plant roots to rot. It is not yet clear whether any ULTRA-Ex sites will receive funding to establish expanded research programmes \u2014 which Tom Baerwald, a programme manager at the NSF, estimates would cost around $1 million a year. For Phillips, future funding concerns take a back seat as he wraps up his work on the Prudential Tower. His data show that carbon dioxide levels in Boston average 388 parts per million (p.p.m.) in summer \u2014 when photosynthesis is in high gear \u2014 and 413 p.p.m. in winter. But the breeze on this August day has brought fresh air to the rooftop, and the carbon dioxide concentration is a modest 379 p.p.m. That value, says Phillips, \u201cis probably what you'd read over Hawaii right now\u201d. With that, he packs up and boards an elevator for a ride down to the urban air of Boston proper. \n                     Stress and the city: Urban decay 2012-Oct-10 \n                   \n                     Cities: The century of the city 2010-Oct-20 \n                   \n                     Urbanization effects on tree growth in the vicinity of New York City 2003-Jul-10 \n                   \n                     Science and the City special issue \n                   \n                     Boston University's ULTRA-EX project \n                   \n                     University of Massachusetts\u2019 ULTRA-EX project \n                   Reprints and Permissions"},
{"file_id": "491659a", "url": "https://www.nature.com/articles/491659a", "year": 2012, "authors": [{"name": "Olive Heffernan"}], "parsed_as_year": "2006_or_before", "body": "With nations doing little to slow climate change, many people are ramping up plans to adapt to the inevitable. When Superstorm Sandy hit the US coast last month, it blew millions of New Yorkers back into the nineteenth century. The southern part of Manhattan went black after floodwaters shorted out electrical systems. With the subway system disabled, many residents resorted to traversing the island by foot, and water supplies in some areas became contaminated with bacteria and pollutants. The largest Atlantic hurricane on record, Sandy wreaked US$50 billion in economic losses along the US northeast coast, providing a costly reminder of how ill-prepared even the richest nations are for weather extremes. Some recent weather disasters have now been attributed, at least in part, to human activity, including the 2003 European heatwave 1  and the floods in England in 2000 (ref.  2 ). According to the Intergovernmental Panel on Climate Change (IPCC), storms, floods and droughts will strike more frequently and with greater strength as the climate warms 3 . And if nations are struggling to cope now, how will they manage in a warmer, harsher future? Just a decade ago, 'adaptation' was something of a dirty word in the climate arena \u2014 an insinuation that nations could continue with business as usual and deal with the mess later. But greenhouse-gas emissions are increasing at an unprecedented rate and countries have failed to negotiate a successor to the Kyoto Protocol climate treaty. That stark reality has forced climate researchers and policy-makers to explore ways to weather some of the inevitable changes. \u201cAs progress to reduce emissions has slowed in most countries, there has been a turn towards adaptation,\u201d says Jon Barnett, a political geographer at the University of Melbourne in Australia. Adaptation has tended to focus on hard defences, such as shoring up sea walls and building dams. But as awareness of adaptation has grown, so too has the concept. \u201cAdaptation means different things to different people, and is extremely location specific,\u201d says Neil Adger, an environmental and economic geographer at the University of Exeter, UK. Although residents in Bangladesh can raise their houses on stilts to survive floods, some settlements in Alaska and the Maldives must move in the face of rising sea levels. Olive Heffernan dissects the Kyoto Protocol and discusses the best ways for countries to adapt to climate change. Increasingly, it is local people who are deciding how to make their communities more resilient \u2014 and that is increasing the chances of success. \u201cA solely top-down approach to adaptation \u2014 focusing on heavy investment in engineering and infrastructure \u2014 will not work as it is expensive and impractical,\u201d says Robert Lempert, who researches decision-making at the RAND corporation, a think tank in Santa Monica, California. \n               Fearsome floods \n             With its low-lying deltas, Bangladesh has always been threatened by storms that blow in from the Bay of Bengal. But the cyclone that hit the southeastern edge of the nation on 29 April 1991 caused massive flooding and killed some 138,000 people, mainly children and older women. Twenty-one years earlier, a cyclone had claimed up to a half million lives. Rising sea levels are increasing the risks to Bengalis, both from cyclones and from the spread of saline groundwater, which ruins aquifers and kills off crops. Projections by the IPCC indicate that a sea-level rise of 1 metre \u2014 expected sometime within a century \u2014 would inundate up to 20% of the country's land area and displace 14% of the total population 4 . In response, the country is busy building and strengthening its 13,000-kilometre network of embankments, planting salt-resilient crops and storing fresh water. One project, supported by the United Nations Development Programme, taught 18,000 households in coastal communities to plant mangroves and fruit trees and to harvest rainwater by digging ditches. The project aims to provide fresh water and income as well as to protect against flooding and erosion. In 2005, the country became one of the first to complete a national adaptation programme of action, and it later established a climate-change trust fund for financing local, small-scale projects in adaptation and mitigation. Although Bangladesh's per capita income ranks the nation among the world's poorest, the country has mounted such a strong response to climate change that it has become something of a model for other nations, says Saleemul Huq, a Bangladeshi scientist and senior fellow in the Climate Change Group at the International Institute for Environment and Development in London. \u201cIn the past few years, the level of public awareness about climate change in Bangladesh has skyrocketed and it is now probably higher there than in any other country,\u201d Huq says. But here and in other developing countries, it is hard to separate adaptation efforts from development that would have happened anyway. This confusion permeates discussions on financing adaptation efforts; of the $125 million that Bangladesh has received in climate funds from overseas, it remains unclear how much is in addition to development aid. And like almost everywhere, Bangladesh is having to play catch-up with the climate. \u201cThere is an adaptation deficit out there right now to current climate variability,\u201d says Kristie Ebi, an expert on climate and health impacts at Stanford University in California. Still, many experts say that Bangladesh has made significant progress. \u201cWhat we can say is that there is collective action in the most climate-vulnerable country in the world,\u201d says Huq. \u201cThe issue has galvanized people even across the political spectrum.\u201d Whereas Bangladesh has focused on involving citizens in many small-scale projects, the city of Melbourne has sought to head off problems through a massive engineering venture. Over the past decade, southern Australia has been hit by the worst drought in a century. After water restrictions implemented in 2007 angered thousands of farmers, the state of Victoria announced it would invest Aus$3.5 billion (US$2.9 billion) in a new desalination plant at the site of Wonthaggi and commissioned a pipeline to bring water to the region from a river in the north. Overdue and over budget, the desalination project will take decades to pay off and is eating up the region's adaptation resources, argue critics. It is a clear case of maladaptation and will increase overall vulnerability to climate change, says Barnett, who has studied the project 5 . By investing so heavily in the desalination plant, the Victorian government has effectively shut off the possibility of funding other adaptation options, such as harvesting rainfall and recycling domestic waste water from showers and dishwashing, which would be cheaper and more effective, he says. But John Thwaites, the water minister of Victoria until mid-2007, says that Melbourne has taken a multi-pronged approach that includes conservation and harvesting storm water. The government originally preferred measures other than desalination, but decided to build the plant in response to the unprecedented water shortage. The United Kingdom has taken a different approach to planning for water problems. In autumn 2000, rainfall was at its highest since records began in 1766, causing devastating floods that left the village of Hambledon under water for six weeks at a cost of more than \u00a31 billion (US$1.6 billion). Early this year, a long drought led to water restrictions in parts of Britain, but the spring and summer that followed were the wettest in a century. Climate projections indicate that the country will face more frequent droughts and floods, but the models do not agree on the extent and timing of the changes. Given the uncertain predictions, UK water companies are adopting a more flexible approach for making decisions about building reservoirs, extracting groundwater and other water-related plans. Rather than developing one strategy and sticking with it, they plan incrementally and frequently re-evaluate on the basis of new information, says Nigel Arnell, director of the climate research-focused Walker Institute at the University of Reading, UK. Communities living on tiny islands, however, don't have the luxury of considering many different options and reevaluating plans. For people in the Maldives, Kiribati and Carteret, there is simply nowhere to retreat when rising sea levels infiltrate their drinking-water supplies and flood their homes, so they will have to flee. Small island nations can learn valuable lessons from the Alaskan village of Newtok, which is already in the process of moving. Located on the Ninglick River next to the Bering Sea, Newtok is below sea level and losing ground at a rate of roughly 22 metres per year to erosion. The villagers selected a site for their new home on Nelson Island, which is 15 kilometres away. Turning a hardship into an opportunity, the residents are learning building skills to construct sustainable homes in their new village, and that will give them more job options in the future, says Robin Bronen, head of the Alaska Immigration Justice Project in Anchorage, which works with communities being relocated as a result of climate change in Alaska. The experience in Newtok serves as a model for how 'climigration' should work in practice, says Bronen. \u201cThat's because of the process \u2014 the community has made all of the decisions.\u201d Heat is often considered less dangerous than floods, but some of the most serious consequences of climate change will arise from hot weather. During the 2003 heatwave in Europe, temperatures reached their highest since 1500, topping 40 \u00b0C for seven days in some parts of France. Almost 15,000 people died in that country alone. One climate modelling study of the Mediterranean region found that by the end of the current century, the frequency of heatwaves will increase from one every 3\u20135 summers to 2\u20133 heatwaves each summer; and they will last 2\u20135 times longer 3 . In the aftermath of the 2003 disaster, France established a heatwave warning system, one of 12 now in operation throughout Europe 6 . In France, alerts are triggered when the five-day weather forecast predicts that temperatures will exceed thresholds for three days. In addition, scientists analyse mortality data, hospital patient loads and drinking-water supplies. The system can issue public warnings, mobilize personnel to visit vulnerable populations and call hospital and nursing-home staff back from their holidays. In 2006, a heatwave similar to the 2003 event put the system to the test; although it did reduce mortality and morbidity, thousands still died, in part because a significant fraction did not receive the warning and many did not heed the advice. Ebi says that cities can do much better. \u201cHeat-related deaths are completely preventable,\u201d she says, if people are warned and told how to protect themselves. Yet the most vulnerable \u2014 the elderly, ill and poor, for example \u2014 often don't see themselves as being at risk, says Graham Bickler, regional director at the Health Protection Agency in Brighton, UK. So one challenge is identifying and communicating to those groups. During a heatwave in Chicago, Illinois, in 1995, Ebi says, many of those who died were adults over 65 who lived in poor areas, where it was common practice to board up windows to protect against break-ins. The fans they used to try to keep cool had the reverse effect and turned their homes into convection ovens. They could have reduced their risk by consuming cold liquids and foods, taking cool showers and going to air-conditioned public spaces, says Ebi. \n               Early warning \n             Like Bangladesh, the nations of sub-Saharan Africa are particularly vulnerable to climate change, but they have received relatively little adaptation funding from international donors. Mozambique stands out as one of the most threatened, with 2,700 kilometres of coastline and more than half its 24 million inhabitants living in poverty. Between 1965 and 1998 the country experienced 12 major floods, 9 major droughts, and 4 major cyclone events. Located at the end of river systems that stretch more than 1,000 kilometres into other countries, Mozambique can be struck floods without warning. \u201cMozambique is a country where every year there is a weather-related problem,\u201d says Filipe L\u00facio, a Mozambican meteorologist who now heads the Global Framework for Climate Services Office at the World Meteorological Organization in Geneva, Switzerland. In 2000, Mozambique was hit by a flood worse than any in its history; it left 700 dead and caused damages totalling nearly US$300 million, a significant fraction of its budget at the time. The event \u201cwasn't at all anticipated\u201d, says L\u00facio. Warnings of above-average rainfall came too late and failed to convey the magnitude of the coming flood. Since then, the country has switched to a colour-coded system that indicates the lead time for a predicted event and has recruited locals to record and monitor precipitation and water levels \u2014 information they can use to raise alarms. The system has succeeded in reducing risks. In 2007, a flood of similar magnitude to the 2000 event killed just 29 people. Looking to the future, the government has commissioned a study on national climate impacts and is working on a long-term strategic adaptation plan. But efforts to implement these plans will probably be hindered by lack of funding and sluggish bureaucracy 7 . The state has a budget of just $5 billion, and half of Mozambique's funds come from overseas aid, so resources are scarce even for crucial areas such as education and health. As of November 2011, Mozambique had received $30 million in overseas climate finance and a further $86 million has been pledged by the Pilot Program on Climate Resilience for a range of issues from upgrading roads to improving its meteorological service 8 . But experts say that this is far from enough. It is a picture repeated across the globe. In 2011, developing nations received only about $960 million in money dedicated for adaptation-related activities, but a 2007 report by the United Nations Development Programme estimated that developing countries would need $86 billion a year by 2015 in funding to adapt to climate change 9 . The issue is pushing the world's rich and poor farther apart, says Desmund Tutu, the former archbishop of Cape Town in South Africa. In the UN report, he warned that \u201cwe are drifting into a world of 'adaptation apartheid'\u201d. For both wealthy and poor nations, the challenge is to convince people to act before it is too late. \u201cAdaptation is largely a matter of changing social processes so that fewer people are at risk,\u201d says Barnett. \u201cThis of course won't be easy \u2014 but it does mean the solutions are determined by people, not by nature\u201d. \n                     Hurricane sweeps US into climate-adaptation debate 2012-Nov-06 \n                   \n                     Where warming hits hard 2009-Jan-15 \n                   \n                     Human activity implicated in Europe's 2003 heat wave 2004-Dec-01 \n                   \n                     Nature special: Rio+20 \n                   \n                     Nature Reports Climate Change : special issue on sea-level rise \n                   Reprints and Permissions"},
{"file_id": "491318a", "url": "https://www.nature.com/articles/491318a", "year": 2012, "authors": [{"name": "Trisha Gura"}], "parsed_as_year": "2006_or_before", "body": "Jonathan Tilly defied decades of dogma by suggesting that women can make new eggs throughout their lives. Now some of his critics are taking a second look. Jonathan Tilly likes to gauge the significance of his work by the hair on the backs of his arms. \u201cLook at it standing up,\u201d he says, thrusting out his forearm on a mid-August afternoon. A reproductive biologist at Massachusetts General Hospital in Boston, Tilly was explaining a procedure to retrieve stem cells from the ovaries of a sterile woman. This experiment, he hopes, will help to quell criticism of his most controversial claim: that ovaries have the potential to make eggs indefinitely. This defies the long-held dogma that female mammals are born with all the oocytes (precursors to eggs) they will ever produce, a population that dwindles with age and is exhausted at menopause. Tilly first challenged that doctrine in 2004, in a paper 1  suggesting that the oocytes in mouse ovaries are being replenished by stem cells. If properly understood, such cells could be harnessed to generate fresh eggs for women with fertility problems, or even achieve a goal Tilly has been pursuing for 25 years: delaying or halting menopause. \u201cThe hairs are still up,\u201d Tilly says. It \u201chappens every time I think about that experiment\u201d. He has since published a parade of headline-grabbing papers, culminating this year in a report 2  that he had isolated the elusive stem cells from human ovaries and coaxed them to develop into bona fide oocytes. But his work has been dogged by doubt. Some researchers question his methods and reasoning. Others have tried, and failed, to repeat his experiments. Tilly \u201calways makes what I call \u2018big satellites\u2019, something tremendous in the sky,\u201d says molecular biologist Kui Liu at the University of Gothenburg in Sweden. \u201cHe exaggerates,\u201d Liu says, and produces a \u201cbig press release\u201d. \u201cA few years later, people realize, \u2018Oh, not right\u2019.\u201d Tilly says he has weathered a lot of attacks. \u201cWhen I made the decision to pursue this, it was out of pure excitement that we found something that could revolutionize the field. It never even crossed my mind that it would be so negative and so nasty. And it really is negative and nasty.\u201d Trisha Gura discusses Jonathan Tilly\u2019s controversial work. But now the stand-off of mistrust, and sometimes open contempt, has taken a strange twist. Two of Tilly\u2019s most vociferous critics have become his collaborators: one serving on the board of advisers at his start-up company, OvaScience in Cambridge, Massachusetts; the other working directly with the stem cells that Tilly had isolated. \u201cThese cells are doing things  in vitro  that can really start to address scientific problems,\u201d says Evelyn Telfer, a reproductive biologist at the University of Edinburgh,UK, who was doubtful of Tilly\u2019s work in the past. \u201cIf we are really interested in the science\u00a0...\u00a0then this is a great tool.\u201d \n               A counting problem \n             The \u2018no new eggs\u2019 doctrine has a long history. In 1951, the influential anatomist Solly Zuckerman, at the University of Birmingham, UK, performed an in-depth analysis of evidence available at the time. He concluded that none of it effectively countered a proposal from the 1870s stating that female mammals stop producing oocytes after birth 3 . For the first 15 years of his career, Tilly focused mainly on programmed cell death, or apoptosis, and he was struck by the fact that no one had ever quantified the loss of eggs due to ovulation and natural oocyte death over time. So beginning around 1999, Tilly commandeered a microscope and mouse ovarian tissue in order to count the follicles, the cellular compartments in which oocytes develop, in mice at different ages. He found a mathematical imbalance: the number of degenerated follicles was three times higher than expected on the basis of the starting pool. If the mice were losing oocytes at this rate, their eggs should be depleted far sooner than they actually were. Something had to be replacing them, he concluded: stem cells were the likely culprit. Few were willing to accept the idea. It took Tilly two years \u2014 and numerous rejections and revisions \u2014 to get the data published in  Nature , in 2004. Controversy ensued over his methods as well as his conclusions. One critique said, for example, that it was \u201calarming\u201d that Tilly used the rate of follicle disappearance in one mouse strain to calculate loss for another 4 . Tilly dropped most of his apoptosis work and steered his entire lab towards proving the existence and functionality of these stem cells. \u201cYou are sort of standing on the precipice wondering whether or not you should make the jump,\u201d he says. \u201cGetting the 2004 paper published was for me the jump, because there was no turning back at that point.\u201d A year later, Tilly reported that he had identified the source of these putative cells: bone marrow 5 . When he transplanted either marrow or blood from healthy mouse donors into sterile mice, the animals could produce cells that looked like oocytes. But he could not yet fertilize the resulting eggs and create embryos\u00a0\u2014 the true test of an egg stem cell. At least six groups challenged the bone-marrow finding. In one critique 6 , a group led by Telfer wrote that none of Tilly\u2019s experiments had successfully been replicated, and that the results could be interpreted in other ways. Critics also asserted that Tilly was overreaching, particularly in media interviews.  There are a lot of people struggling to understand how this can possibly work.  In  The Boston Globe  in 2005, for example, Tilly is quoted as saying: \u201cThey\u2019re your own cells; you don\u2019t need anybody\u2019s approval. They go right into your blood supply and go right to your ovaries, where they mature into eggs.\u201d David Albertini, a reproductive biologist at the University of Kansas Medical Center in Kansas City, calls such claims outrageous: \u201cA lot of us reproductive biologists feel that this is a frank travesty that has falsely raised the hopes of many women.\u201d Tilly defended his comments and challenged his peers to go back to their labs and reproduce his experiments. Several did. In 2006, stem-cell biologist Amy Wagers at Harvard University in Cambridge, Massachusetts, and her collaborators stitched together the circulatory systems of two mice 7 . One, the donor, expressed green fluorescent protein (GFP) in its cells. The other did not. The scientists found that although green, glowing, blood-borne cells could infiltrate the ovaries of the recipient mice, these cells acted like blood cells, not oocytes. Tilly, in response, performed a similar experiment, showing that mice sterilized by chemotherapy could give birth after a bone-marrow transplant 8 . But the babies did not express GFP, indicating that the eggs from which they were derived came from the recipient, not the donor. Tilly argued that the bone marrow either protected existing oocytes or revived oocyte formation, but critics argued that the chemotherapy probably didn\u2019t kill off all the recipient\u2019s oocytes in the first place. \n               Shanghai surprise \n             With little independent replication of his work, Tilly was standing alone through much of the fray. Then, in 2009, Ji Wu at Shanghai Jiao Tong University in China and her colleagues reported that they had isolated from mice what she called \u201cfemale germline stem cells\u201d\u00a0\u2014 not from bone marrow, but from ovarian tissue 9 . When her team transplanted the cells into chemotherapy-treated female mice, they developed into mature oocytes, then fertilizable eggs and, the clincher, healthy pups. Although previously sceptical of the prospect, Telfer says that when she read Wu\u2019s paper in 2009 she paused, thinking \u201cthere must be something in this\u201d. She had met Tilly at the bar during a scientific meeting the year before and they talked about their differences. After Wu\u2019s paper, the two co-authored a commentary that articulated something like a truce 10 . \u201cAlthough these findings do not establish that oogenesis occurs in adult females under physiological conditions,\u201d Tilly and Telfer wrote, \u201cthey strongly support the existence of [germline stem cells] in adult mouse ovaries. If equivalent cells can be found in human ovaries, stem-cell-based rejuvenation of the oocyte reserve in ovaries on the verge of failure may one day be realized.\u201d Many set out to replicate Wu\u2019s results, including Tilly. And in February, he reported the isolation of what he called \u201coogonial stem cells\u201d from human ovaries 2 . By injecting the cells into human ovarian tissue transplanted into mice, he was able to generate both follicles and what seemed to be mature oocytes (see  Nature 483, 16; 2012 ). \u201cSo now we have two different labs, using conceptually a similar protocol, and both groups got confirmatory data,\u201d he says. \u201cWe felt at that point there should be no more debate.\u201d But there was. Critics soon began pointing out a problem shared by both the teams\u2019 approaches. Each identify their respective stem cells using antibodies meant to bind a cell-surface protein, a common technique in cell biology. But the protein they target, called vasa, normally sits inside the cell, not on its surface. \u201cThere are a lot of people in the field struggling to understand how this can possibly work,\u201d says Patricia Hunt, a reproductive biologist at Washington State University in Pullman. Tilly says that although mature oocytes do not express vasa on their surface, his cells \u2014 which are a cross between embryonic precursors and full-blown oocytes \u2014 do. Vasa, he says, becomes non-detectable on the cell surface as the cells mature into eggs. But, he adds, \u201cWe don\u2019t have any proof of that yet.\u201d Liu in Sweden says that he initially believed Wu\u2019s paper when it came out. But his group could not repeat the technique. To bypass the cell-surface problem with vasa, Liu used an approach that tracks the protein inside the cells 11 . He was able to extract ovarian, vasa-expressing cells, but none of them underwent division \u2014 a major criterion for stem cells. Wu contends that her cell-isolation technique is not easy to perform and invites scientists to come to her lab to learn it. She adds that Liu\u2019s group \u201cdidn\u2019t use our protocol of isolating the cells. So how to compare?\u201d In fact, Tilly says that his lab had trouble repeating Wu\u2019s protocol, too. Eventually, his team retrieved cells but \u201cfound consistent oocyte contamination\u201d. He had to modify the protocol to retrieve the mouse and human oogonial stem cells, and they differed in size from those Wu had isolated. Wu says that her cells and Tilly\u2019s are probably \u201csubtypes\u201d of each other and that there is still \u201ca lot of work to do\u201d to figure out exactly how they are related. Telfer, meanwhile, has begun to collaborate with Tilly. After going to Boston in 2011 to observe his human stem cells, she was impressed, and took a sample back to Scotland. Her team had worked out a culture system using mouse and cow tissues to grow egg precursor cells into fertilizable eggs entirely outside the body. With Tilly\u2019s cells she needed to adapt the technique for use in humans. \u201cThe first experiments blew me away, just blew me away,\u201d she says. Tilly\u2019s cells, she found, grew rapidly into oocyte-like structures. \u201cI spent the whole night trying to find another explanation other than new follicles had formed,\u201d she says. \u201cAnd I could not come up with one.\u201d Telfer has applied for permission from the UK Human Fertilisation and Embryology Authority to attempt to fertilize the cells; such experiments are forbidden using US federal funding. If successful, the technique to make fertilizable human eggs outside the body could eventually be disseminated to fertility clinics throughout the world. \n               Boundaries and backlash \n             The cells are also being used at OvaScience, which was founded in April 2011 and has secured US$48 million in venture capital. The company is exploiting Tilly\u2019s cells in several ways. One aim is to rejuvenate egg cells from older women by adding fresh cytoplasm and mitochondria. The research builds on a controversial experimental fertility technique in which egg cells are injected with cytoplasm from another woman\u2019s eggs. The OvaScience approach would use mitochondria extracted from the mother\u2019s own oogonial stem cells, which Tilly says would be healthier than those from an ageing mother\u2019s eggs, and should skirt some of the ethical and safety questions raised by using donor mitochondria. OvaScience plans to begin clinical trials this year in collaboration with two Boston-based fertility clinics. Tilly\u2019s oogonial stem cells will also serve as a screening tool for new drugs that might block or boost egg production. Such drugs might help reverse infertility or even help delay or halt menopause. Albertini still worries that such claims inflate hopes but, like Telfer, he is trying to keep an open mind. The prospect of new models for screening fertility drugs convinced him to join OvaScience\u2019s scientific advisory board. \u201cThere are a lot of things that I know and I do that could be helpful to them,\u201d he says. The company is swiftly moving forward, steered by the team that guided Sirtris, based in Cambridge, Massachusetts, a biotech firm focused on anti-ageing therapies. In fact, it was a collaboration between Tilly and Sirtris\u2019s founder, David Sinclair, at Harvard Medical School in Boston, that sparked the launch of OvaScience. He and Tilly are \u201cmutual admirers\u201d, Sinclair says, explaining that they joined forces in 2009 to explore the idea that egg quality declines with age because older eggs lack enough energy to support fertilization. Sinclair offers his anti-ageing expertise and his experience of controversy; some of the initial results on which Sirtris was founded could not be replicated and have been a source of contention in the field (see  Nature 464, 480\u2013481; 2010 ). \u201cIt is an interesting team that Jon and I make,\u201d Sinclair says, \u201cbecause the two of us push the boundaries of science. And both of us have encountered backlashes in doing so.\u201d Still, despite his characteristic gumption and ebullience, Tilly seems to be burdened by the continual sparring. Although he\u2019s shifted much of his time to studying oogonial stem cells in the ovary, he still maintains that bone-marrow stem cells might also create new eggs. His critics disagree, and even if they accept the existence of oogonial stem cells, they still question whether such cells normally function to produce new eggs. \u201cThe data provided so far don\u2019t support this concept,\u201d says Albertini. Tilly maintains that these stem cells must be doing something in the body. But in exasperation, he is willing to concede that it may not matter in the clinic. \u201cIf you could take these cells outside the body, and get them to make a functional egg that can make a normal healthy baby, what do you care about the physiology?\u201d \n                     Mouse stem cells lay eggs 2012-Oct-04 \n                   \n                     Egg-making stem cells found in adult ovaries 2012-Feb-27 \n                   \n                     Ageing: Much ado about ageing 2010-Mar-24 \n                   \n                     Making new eggs in old mice 2009-Apr-11 \n                   \n                     Born or made? Debate on mouse eggs reignites 2006-Jun-14 \n                   \n                     Ovaries may lay new eggs 2004-Mar-11 \n                   \n                     Jonathan Tilly \n                   \n                     OvaScience \n                   Reprints and Permissions"},
{"file_id": "491516a", "url": "https://www.nature.com/articles/491516a", "year": 2012, "authors": [{"name": "Roberta Kwok"}], "parsed_as_year": "2006_or_before", "body": "DNA has been around for billions of years \u2014 but that doesn't mean scientists can't make it better. When Steven Benner set out to re-engineer genetic molecules, he didn't think much of DNA. \u201cThe first thing you realize is that it is a stupid design,\u201d says Benner, a biological chemist at the Foundation for Applied Molecular Evolution in Gainesville, Florida. Take DNA's backbone, which contains repeating, negatively charged phosphate groups. Because negative charges repel each other, this feature should make it harder for two DNA strands to stick together in a double helix. Then there are the two types of base-pairing: adenine (A) to thymine (T) and cytosine (C) to guanine (G). Both pairs are held together by hydrogen bonds, but those bonds are weak and easily broken up by water, something that the cell is full of. \u201cYou're trusting your valuable genetic inheritance that you're sending on to your children to hydrogen bonds in water?\u201d says Benner. \u201cIf you were a chemist setting out to design this thing, you wouldn't do it this way at all.\u201d Life may have had good reasons for settling on this structure, but that hasn't stopped Benner and others from trying to change it. Over the past few decades, they have tinkered with DNA's basic building blocks and developed a menagerie of exotic letters beyond A, T, C and G that can partner up and be copied in similar ways. But the work has presented \u201cone goddamn problem after another\u201d, says Benner. So far, only a few of these unnatural base pairs can be inserted into DNA consecutively, and cells are still not able to fully adopt the foreign biochemistry. The re-engineering of DNA, and its cousin RNA, has practical goals. Artificial base pairs are already used to detect viruses and may find other uses in medicine. But scientists are also driven by the sheer novelty of it all. Eventually, they hope to develop organisms with an expanded genetic alphabet that can store more information, or perhaps ones driven by a genome with no natural letters at all. In creating these life forms, researchers could learn more about the fundamental constraints on the structure of genetic molecules and determine whether the natural bases are necessary for life or simply one solution of many. \u201cEarth has done it a certain way in its biology,\u201d says Gerald Joyce, a nucleic-acid biochemist at the Scripps Research Institute in La Jolla, California. \u201cBut in principle there are other ways to achieve those ends.\u201d Benner first became interested in those other ways as a graduate student in the 1970s. Chemists had synthesized everything from peptides to poisons, and some were trying to build molecules that could accomplish the same functions as natural enzymes or antibodies with different chemical structures. But DNA was largely ignored, he recalls. \u201cChemists were looking at every other class of molecule from a design perspective except the one at the centre of biology,\u201d says Benner. In 1986, Benner started a lab at the Swiss Federal Institute of Technology in Zurich and began to rebuild DNA's backbone. He quickly realized that what seemed like a flaw might be a feature. When he and his team replaced the backbone's negatively charged phosphates with neutral chemical groups 1 , they found that any strand longer than about a dozen units folded up on itself \u2014 probably because repelling charges were needed to keep the molecule stretched out. The bases proved more amenable to tinkering. Benner set out to create base pairs that are similar to nature's, but with rearranged hydrogen bonding units. His team tested two new pairs:  iso -C and  iso -G (ref.  2 ) and  \u03ba  and xanthosine 3 . It showed that polymerase enzymes \u2014 which copy DNA or transcribe it into RNA \u2014 could read DNA containing the unnatural bases and insert the complementary partners into a growing DNA or RNA strand. Ribosomes, the cellular machines that 'translate' RNA into protein, could also read an RNA snippet containing  iso -C and use it to add an unnatural amino acid to a growing protein 4 . \u201cThe base pairing, which is at the centre of genetics, turned out to be for us the most malleable part of the molecule,\u201d says Benner. The researchers did encounter a problem, however. Because its hydrogen atoms tend to move around,  iso -G often morphed into a different form and paired with T instead of  iso -C. \n               Unnatural bonds \n             Eric Kool, a chemist now at Stanford University in California, wondered whether his team could develop unnatural bases with fixed hydrogen-bonding arrangements. He and his colleagues made a base similar to the natural base T, but with fluorine in place of the oxygen atoms (see 'Designer DNA'), among other differences 5 . The structure of the new base, called difluorotoluene (designated F), mimicked T's shape almost exactly but discouraged hydrogen from jumping. The team soon discovered that F was actually terrible at hydrogen bonding 5 , but polymerases still treated it like a T: during DNA copying, they faithfully inserted A opposite F (ref.  6 ) and vice versa 7 . The work suggested that as long as the base had the right shape, a polymerase could slot it in correctly. \u201cIf the key fits, it works,\u201d says Kool. Other scientists were dubious. \u201cI got outraged e-mails from people saying, 'How can you possibly tell us that hydrogen bonds are not needed for DNA replication?',\u201d says Kool. \u201cThat was the centre of the helix. And people were so fixated on hydrogen bonds that it was hard to even conceive of alternatives.\u201d Instead of forming hydrogen bonds \u2014 a property normally associated with hydrophilic, or water-loving, molecules \u2014 F and other shape-mimicking bases developed by Kool's team were hydrophobic. Water repels them, which helps them to stabilize in the double helix. DNA is analogous to a stack of coins, says Kool, and staying in the stack shields an unnatural base from water. Floyd Romesberg, a chemical biologist at the Scripps Research Institute, has expanded the repertoire of hydrophobic bases. Starting with molecules such as benzene and naphthalene, his team built \u201cevery imaginable derivative\u201d, he says. \u201cIt drove us very much away from anything that looked like a natural base pair at all.\u201d But while testing steps in the replication process, the researchers found two contradictory requirements. A crucial position in the base had to be hydrophobic for enzymes to insert the base into DNA, yet it also had to accept hydrogen bonds if enzymes were to continue with copying the strand. Romesberg's team screened 3,600 combinations of 60 bases for the pair that was copied the most efficiently and accurately 8 . The two that won, MMO2 and SICS, \u201cwalk a thin line\u201d between being hydrophobic and hydrophilic at the key position, Romesberg says. A major challenge remained, however: researchers had to show that DNA would retain the unnatural base pairs while billions of copies are made. If enzymes pair unnatural with natural bases too often, the new letters could eventually disappear. \n               Base jumping \n             Ichiro Hirao, a chemist at the RIKEN Systems and Structural Biology Center in Yokohama, Japan, had been intrigued by the idea of creating unnatural bases ever since reading James Watson's 1968 book  The Double Helix  as a teenager. Hirao and his colleagues found that they could reduce mispairing by designing shapes that fit awkwardly with natural bases, and by adding negatively charged or electron-rich chemical groups that repel the natural bases' corresponding parts. In 2011, Hirao's team reported that DNA containing an unnatural hydrophobic base pair, called Ds and Diol1-Px, could be copied with 99.77\u201399.92% fidelity per replication 9 . The same year, Benner and his colleagues showed that another unnatural base pair \u2014 P and Z, which join using hydrogen bonds \u2014 achieved fidelity of 99.8% per replication 10 . And in July, Romesberg's team reported rates of 99.66\u201399.99% for optimized versions of his bases, called NaM and 5SICS (ref.  11 ), overlapping with the sloppiest rate for natural DNA. \u201cOur best case is now approaching nature's worst case,\u201d says Romesberg. Unnatural bases still have a lot to prove, however. Researchers haven't shown that polymerases can copy more than four of the paired bases in a row 10 . The polymerase is \u201cthe hard nut to crack\u201d, says Benner. And the solution may be to re-engineer it, too. Philipp Holliger, a chemical biologist at the Medical Research Council Laboratory of Molecular Biology in Cambridge, UK, and his colleagues demonstrated this approach earlier this year \u2014 using nucleic acids called XNA, in which the sugars normally present in DNA or RNA had been replaced by other ring structures 12 . The team generated billions of mutants of a natural polymerase and let them evolve by putting selective pressure on them to convert DNA to XNA (see   Naturehttp://doi.org/jrh;2012 ). The researchers then compared the most effective mutants to identify the best one. The polymerase is shaped roughly like a hand, and it turns out that the 'thumb' was the key region that needed to change, says Holliger. This region makes contact with the DNA as it exits the enzyme and might act as a final checkpoint to ensure correct synthesis. The team also engineered an enzyme that could convert XNA back into DNA. Much of the tinkering so far has been done  in vitro , but researchers hope to show that organisms can read and process the information. Perhaps the closest they have come to incorporating unnatural bases into a living system is an engineered bacterium reported last year 13  by Philippe Marli\u00e8re, co-founder of the microbial fluidics company Heurisko in Newark, Delaware. He and his team replaced most of the organism's T bases with chlorouracil, a form of the RNA base uracil in which a hydrogen atom is replaced with chlorine. The team developed an automated system to introduce the base gradually to a strain of  Escherichia coli  that couldn't make thymine on its own. After about five months, some of the bacteria couldn't survive without chlorouracil and they had expunged roughly 90% of the thymine from their genomes. Benner, Romesberg and Hirao are also working to coax cells to accept their base pairs. But even if the cells accept the pairs, they might have trouble carrying out processes such as recombination \u2014 a highly orchestrated reshuffling of genetic material. \u201cIt's not just a matter of getting these darn things in,\u201d says Andrew Ellington, a biochemist at the University of Texas at Austin and a former graduate student of Benner. \u201cI think this is going to be a modestly Herculean task from here on out.\u201d Just how far researchers will get is unclear. Marli\u00e8re's team aims to replace all four natural bases with unnatural ones. But Romesberg says that developing an organism with only hydrophobic bases will be close to impossible, because cells contain too many components that have adapted to work with natural bases. As for combining an unnatural backbone and unnatural bases in one organism, \u201cour theory is not good enough for us to go in and do both at the same time\u201d, says Benner. Even if unnatural base pairs don't yet function in cells, they can still be put to practical use. Siemens Healthcare Diagnostics in Tarrytown, New York, and Luminex in Austin, Texas, already use Benner's  iso -C and  iso -G pair to improve detection and monitoring of viral infections. Siemens, for example, uses a series of linked DNA sequences that bind to HIV-1 RNA in a patient's blood sample. Inserting unnatural bases into some of the sequences discourages the sequences from binding to random DNA sequences in the sample and makes the HIV-1 RNA easier to detect at low levels. DNA and RNA molecules can also catalyse reactions and be used as drugs. Developers can improve the performance of a sequence by attaching chemical groups to the bases, and unnatural bases make it easier to target a specific site in a sequence rather than saturating every C or G. Romesberg's team has added 'linker' groups to unnatural bases in DNA that allow precise attachment of a variety of molecules. The team is now trying to engineer sequences that will catalyse reactions more efficiently than their natural counterparts. Hirao says that his team has generated DNA sequences containing the Ds base that bind much better than natural sequences to interferon-\u03b3, an immune-system protein, and to vascular endothelial growth factor (VEGF), a therapeutic target in cancer and eye disease. Practical applications aside, researchers are still driven by what Kool calls the \u201cscience-fiction appeal\u201d of designing or even improving on living systems. Earth's early life forms may have settled on their genetic alphabet simply because they were constrained by the chemicals available. Adenine, for example, is easy to make from hydrogen cyanide, which was probably present when life first emerged. Once organisms had a working set of bases, perhaps they got locked into that system. \u201cIf you start dabbling too much with your fundamental biochemistry, you're going to get eaten,\u201d says Benner. Although RNA \u2014 generally thought to have preceded DNA \u2014 might not be the best possible solution for supporting life, it might be the best solution that could have emerged on prebiotic Earth, Benner suggests. So if nucleic acids arose independently on another planet, would they have the same bases? Benner thinks not, unless the organisms were subjected to the same constraints. Some universal rules might apply, however. For example, Benner says that backbones with repeating charges \u2014 which initially seemed to him like a liability \u2014 actually discourage folding and ensure that strands with different base sequences behave similarly during processes such as replication. Although some researchers have had success with alternative backbones, many attempts have resulted in molecules that are too stiff or too loose to form a helix. \u201cI think there is a limit to the chemical variation that can be introduced,\u201d says Holliger (see  Nature   483 , 528\u2013530; 2012 ). But that isn't going to stop researchers from pushing the limits. \u201cWhy is the chemistry of living things the way it is? Is it because it's the only possible answer?\u201d asks Kool. \u201cI believe the answer to that question is no. And the only way to prove it conclusively is to do it.\u201d \n                     Custom gene editing rewrites zebrafish DNA 2012-Sep-23 \n                   \n                     Bacteria replicate close to the physical limit of efficiency 2012-Sep-20 \n                   \n                     Rewritable memory encoded into DNA 2012-May-21 \n                   \n                     Bespoke genetic circuits rewire human cells 2010-Nov-25 \n                   \n                     Genome-building from the bottom up 2010-Oct-10 \n                   \n                     Synthetic genome resets biotech goals 2010-May-26 \n                   \n                     Genome stitched together by hand 2008-Jan-24 \n                   \n                     Biotechnology@nature.com \n                   \n                     Steven Benner \n                   \n                     Eric Kool \n                   \n                     Floyd Romesberg \n                   \n                     Ichiro Hirao \n                   \n                     Philipp Holliger \n                   Reprints and Permissions"},
{"file_id": "491180a", "url": "https://www.nature.com/articles/491180a", "year": 2012, "authors": [{"name": "Barbara Fraser"}], "parsed_as_year": "2006_or_before", "body": "Researchers are racing to determine how shrinking glaciers in the Andes will affect the water supply of millions of people. From the shade of an adobe house overlooking Peru's Santa River, Jimmy Melgarejo squints at the dual peaks of Mount Huascar\u00e1n looming against a cloudless sky. \u201cThe snow keeps getting farther away,\u201d says Melgarejo, a farmer worried about his livelihood. \u201cIt's moving up, little by little. When the snow disappears, there will be no water.\u201d Throughout the Andes, millions of people voice the same concern as they watch climate change eat away at the mountain chain's icy mantle. But although everyone fears a water shortage, they do not know how quickly it will come or how severe it will be. An interdisciplinary team of scientists is now trying to provide some answers through a US$1-million project funded by the US National Science Foundation. The crew, which pulls together hydrologists, geochemists, geographers and historians, mainly from the United States and Canada, is tracking the fate of glacial meltwater as it runs from the mountains down to the ocean. Their goal is to develop models to forecast water flow and its effects on residents downstream. The rapid changes in the Andes \u201cwarrant a new kind of interdisciplinary, integrated study\u201d, says geographer Bryan Mark of Ohio State University in Columbus, who is one of the principal investigators of the project. \u201cWe're trying to cross traditional boundaries, so we're not studying water separately from people.\u201d Peru has the largest mass of tropical glaciers in the world, and most are in the Cordillera Blanca, or White Mountains (see 'Going with the flow'). The snow-capped range towering over the Santa River, which winds 347 kilometres to the desert coast, is \u201cthe most densely glaciated mountain range in the tropics\u201d, says Mathias Vuille, a climate scientist at the State University of New York in Albany. With so much melting ice, and hundreds of thousands of people dependent on the glaciers, the Santa River valley \u2014 also known as the Callej\u00f3n de Huaylas \u2014 has become a prime place to assess the changes caused by global warming. Barbara Fraser spends some time in the Peruvian highlands with scientists monitoring the water supply. As the most comprehensive study so far to examine melting glaciers and their impacts, the project will arm policy-makers with crucial information about how to adapt to climate change in the region, says Mark. The project could also contribute to models for other watersheds in the Andes and for ones as far away as the Himalayas. The results so far present a mixed forecast. Despite the fears of Melgarejo and other residents, the river will not dry up completely during the dry season. But increasing demands on river water for drinking, irrigation and electricity generation will lead to conflicts over the dwindling \u2014 and increasingly expensive \u2014 resource. And there is not much time to plan for the changes. \u201cThis is a reality now,\u201d says Michel Baraer, a project member and hydrologist at the University of Quebec, Canada. \u201cWe don't have 50 years to adapt.\u201d \n               The heat is on \n             On a crisp morning in July, Mark, Baraer and some colleagues with the project climb a lupin-fringed path to Lake Cuchillacocha, which sits at 4,600 metres above sea level, just below a glacier on Mount Pucaranra. There, they work in shifts through the day and frigid night, taking infrared images every half hour of the glacier and surrounding rock. Other instruments on and around the glacier's tongue record solar radiation, wind speed and direction, temperature and humidity. The researchers are studying how quickly the ice, rock and lake warm up during the day and cool at night. By correlating these detailed data with measurements of ice thickness and extent made remotely by satellite and planes, the team hopes to develop models for forecasting how quickly glaciers will retreat across the Cordillera Blanca and what the impacts will be. Earlier studies have shown that glaciers in the mountain range have shrunk by 20\u201330% since 1970 (ref.  1 ), and the rate seems to be accelerating. Researchers at the French Research Institute for Development (IRD) in Marseilles have found that the glaciated area in the tropical Andes is now decreasing by 3% a year (ref.  1 ). Because the amount of precipitation has not changed much over the past few decades, researchers blame rising temperatures for the glacial retreat; the region has warmed an average of about 0.1 \u00b0C per decade since the 1970s, said Antoine Rabatel, a glaciologist at France's University of Grenoble and a member of the IRD study, at a conference at Santiago Ant\u00fanez de Mayolo National University in Huaraz in early July. According to Rabatel, glaciers above 5,400 metres \u2014 such as those on Huascar\u00e1n, Peru's highest peak \u2014 will shrink but survive because temperatures there will remain relatively cool. But those at lower elevations are doomed to disappear. In the past few decades, those glaciers have lost twice as much mass as ones at higher elevations 1 . That is bad news for residents because the glaciers serve as a buffer, locking up precipitation during the rainy season and releasing water slowly during the dry season, between June and September, when almost no rain falls. \u201cYou can think of glaciers as hydrological Prozac \u2014 they smooth out the highs and lows,\u201d says Jeffrey McKenzie, a hydrogeologist at McGill University in Montreal, Canada. Without the glaciers, downstream water users will have to adapt to greater variability between the wet and dry seasons. From Lake Cuchillacocha, the Quilcayhuanca River tumbles down a broad, glacially carved valley. At a site about 7 kilometres downstream, McKenzie dips a probe into the river and measures a pH of 3.4. The lake is even worse, with a pH of 2.8. McKenzie, who is studying the interaction between surface water and groundwater, explains that many lakes and rivers in the Cordillera Blanca are naturally acidic because glaciers grind over rocks rich in sulphate, which gets dissolved into the meltwater. McKenzie also collects samples to identify the water's geochemical 'fingerprint' \u2014 its concentrations of stable isotopes of oxygen and hydrogen as well as several types of dissolved ions, which meltwater picks up as it flows through rocks near the leading edge of the glacier. Those data have allowed McKenzie and his colleagues to calculate that glaciers contribute about 30% of the water in the Santa River during the dry season 2 ; the rest comes from wet-season precipitation that slowly flows through groundwater and eventually reaches the river. The finding suggests that after the glaciers melt away, substantial amounts of water from rain and snow will still flow through the Santa River during the dry season. Yet with the population and agriculture expanding in the region, losing even 30% of the river flow during that season could still cause severe distress, particularly during a drought, says Baraer. And residents may not have much time to prepare because Baraer calculates that the Santa River valley has already passed a critical point known as 'peak water'. When glaciers first begin to recede, the rivers downstream initially swell with the added meltwater until the glacial supply starts to ebb. After that peak water point, the amount of discharge drops off sharply. Baraer and his colleagues studied discharge records for nine tributaries of the Santa River, with data going back to the 1950s. The records suggest that seven of the nine catchments passed the peak water point between the 1960s and the 1980s (ref.  2 ). Georg Kaser, co-chair of the Climate and Cryospheric Research Center at the University of Innsbruck in Austria, cautions that without data from all catchments, it is difficult to know whether peak water has passed for the entire Santa River watershed. The ice caps on the higher mountains in the centre of the Cordillera Blanca remain largely intact, he notes. Nonetheless, the results should prompt Peruvians, especially policy-makers, to finally deal with the threat of declining water supplies, says Kaser. \u201cWe have been telling them for more than 20 years that this peak flow will come soon, but we just spoke into the wind,\u201d he says. Peru currently has no comprehensive plan for addressing future water shortages in the Santa River catchment, according to Gabriel Quijandr\u00eda, vice-minister for strategic development of natural resources in the environment ministry. \u201cThere needs to be a substantial improvement in the way water is used,\u201d he says. Construction of small reservoirs that could be tapped in the dry season could be \u201cpart of the answer, but not all of it\u201d, Quijandr\u00eda says. Some researchers, however, question the feasibility of building artificial reservoirs within the steep topography of the Cordillera Blanca, where earthquakes are a constant threat. For McKenzie, peak water is only part of the story. To forecast discharge rates more accurately, he is studying how the glacial meltwater and precipitation eventually reach the Santa River. The valley floor below Lake Cuchillacocha is a boggy wetland that acts as a sponge, storing meltwater and water from precipitation and releasing it gradually into the river. McKenzie has found that it takes groundwater an average of 18 months to work its way through the wetland and into the river. This year, McKenzie spent two weeks drilling narrow bore holes up to 6 metres deep in the Quilcayhuanca Valley and another one farther north. Material from the holes provided clues about the composition of the soil, and in some of the holes McKenzie installed piezometers \u2014 devices that use pressure to gauge water levels. By next year, he expects to have data that will help to answer questions about the direction, levels and fluctuations of groundwater movement. From there, the researchers intend to model how the flow of groundwater into the river system will change as the meltwater decreases. They are also concerned about the threat of human activities in the upper valleys; livestock grazing and extraction of peat for potting soil could dry out the wetlands and diminish their capacity to store water, warn the researchers. \n               Extreme floods \n             Although residents of the Santa River valley fret over forecasts of declining flows, they also worry about the opposite problem: too much water. The lakes at the feet of glaciers are often contained by unstable natural dams that give way in outburst floods, caused, for example, by a large chunk of ice dropping into the water. And the glaciers can steepen as they melt, making them more prone to avalanches. Outburst floods and avalanches have killed more than 25,000 people in the Callej\u00f3n de Huaylas since the 1940s, says Mark Carey, an environmental historian at the University of Oregon in Eugene who is one of the leaders of the glacier project. The largest city in the Santa River valley, Huaraz, and many smaller towns are built on the deposits of former floods and landslides, he says. An outburst flood could kill tens of thousands of people, he estimates. The National Water Authority in Peru currently monitors more than 35 lakes, according to Jes\u00fas G\u00f3mez of the agency's glaciology unit. He says that the agency has prepared for the risk by lowering water levels when they reach a dangerous point, but an unusually large ice fall could still cause a flood, and the unit's $300,000 annual budget is not sufficient to install automated systems that could warn of an advancing flood. The shrinking glaciers could also amplify other hazards, notably water pollution. Downstream from Huaraz, Mark gingerly steps past a stream of raw sewage pouring into the Santa River from the tiny community of Mancos. Nearby, Alfonso Fern\u00e1ndez, a Chilean doctoral candidate studying with Mark, lays out an array of small plastic bottles on a rock and uses a syringe to sample the water. Back in the lab, a team will analyse them for isotopic signatures to pinpoint the source of the water and will measure concentrations of pollutants such as heavy metals. Sewage is not the only problem. Some tributaries of the Santa River contain naturally high levels of heavy metals, whereas others leach arsenic, cadmium and lead from tailings at old mine sites. The water quality in the river will probably fall as decreasing discharge concentrates the pollution, says Mark. That could intensify competition for clean water, says Ad\u00e1n Pajuelo, president of a local irrigation committee, as he deftly cuts carnations in a field in Cruz de Mayo, a farming community near glacier-fed Lake Par\u00f3n. In 2008, local farmers accused Duke Energy, a US power company, of overdrawing water from Lake Par\u00f3n for its hydroelectric dam downstream. The farmers padlocked the lake's sluice gates, which limited the amount of water the company could draw from the lake. The stand-off lasted nearly two years, until national government officials brokered a truce. Tensions have subsided, but Pajuelo worries that a drought year combined with impacts from a gold mine slated to be built near the lake could leave the farmers with only a small flow of polluted water to irrigate their crops. Competition gets even stiffer downstream, where the river plunges through a narrow canyon past the hydroelectric plant towards the Pacific Ocean. In the coastal desert, asparagus, artichokes, fruit trees and sugar cane \u2014 mostly bound for export markets \u2014 sprout from land that was barren just over a decade ago. The Chavimochic irrigation project, which diverts water from the Santa River to irrigate 75,000 hectares of land, will cover more than twice that area when it is complete. \u201cExport agriculture is transforming the region,\u201d says Jeffrey Bury, a geographer at the University of California, Santa Cruz, who is a principal investigator on the Santa River project. If the peak water scenario holds true, he says, \u201cthat will put inevitable tension on what the water is supposed to be used for and who is supposed to get it\u201d. All the issues affecting the Santa River come together at its mouth on the Peruvian coast. In the dry days of July, the once mighty river has shrivelled into a narrow stream trickling among cobbles and rubbish. If demands for water continue to grow, says Carey, then within a few years, it is possible that in the dry months no water from the Cordillera Blanca will reach the sea. \n                     Tibetan glaciers shrinking rapidly 2012-Jul-15 \n                   \n                     Rediscovered photos reveal Greenland's glacier history 2012-May-28 \n                   \n                     Taking the pulse of a shrinking glacier 2011-Dec-30 \n                   \n                     In the shadow of a melting glacier 2011-Mar-22 \n                   \n                     Climate: When the ice melts 2009-Oct-21 \n                   \n                     Blogpost: Don't cry for me Argentina's glaciers \n                   \n                     Blogpost: Melting glaciers \n                   \n                     Blogpost: Glaciers: going, going\u2026 \n                   \n                     Bryan Mark \n                   \n                     Mark Carey's Andes Research \n                   Reprints and Permissions"},
{"file_id": "491656a", "url": "https://www.nature.com/articles/491656a", "year": 2012, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Commitments made under the Kyoto climate treaty expire at the end of 2012, but emissions are rising faster than ever. After 8 days of fractious negotiating, delegates at the 1997 climate conference in Kyoto, Japan, were running out of time to deliver a treaty aimed at slowing global warming. The leader of the talks, Michael Zammit Cutajar of Malta, took the unusual step of invoking Zen Buddhism, telling everyone that they must break through mental barriers to achieve enlightenment. Two days later, after a marathon all-night session, the negotiators finally hammered out the climate agreement known as the Kyoto Protocol. It was the first \u2014 and so far, only \u2014 pact to commit rich countries to reducing emissions of carbon dioxide and other greenhouse gases. But even before the ink was dry on the agreement, it was clear that the protocol faced a rocky future. Although the United States had signed the treaty, President Bill Clinton signalled that the world's largest economy would not ratify the pact unless China and other developing nations agreed to limit their emissions, something that they had objected to doing before the developed world acted. By the time the Kyoto Protocol came into force in February 2005, the United States had pulled out. The remaining signatories \u2014 37 developed nations and economies in transition \u2014 pledged to reduce their greenhouse-gas emissions from 1990 levels by an average of 4.2% in the period from 2008 to 2012. As that window closes, the countries that stuck with the treaty can claim some success. Overall, they met their target with room to spare, cutting their collective emissions by around 16%. But most of those cuts came with little or no effort, because of the collapse of greenhouse-gas producing industries in eastern Europe and, more recently, the global economic crisis. Furthermore, the cuts by industrialized nations have done little to combat the global problem. Worldwide emissions have surged by 50% since 1990, driven by economic growth in China and other parts of Asia, South America and Africa (see \u2018Before and after\u2019). In the 1990 base year, developed nations including the United States accounted for two-thirds of global emissions. Now, their contribution has dropped below 50%. \u201cKyoto had a very limited impact on climate,\u201d says Atte Korhola, an environmental-policy researcher at the University of Helsinki. \u201cIt was too narrow in ambition, its tools were too massively bureaucratic and it offered too many loopholes.\u201d But the treaty has taught policy-makers some valuable lessons and possibly laid the groundwork for more ambitious efforts. \u201cKyoto was a grand policy experiment with important lessons we ought to take forward. It had its flaws \u2014 no wonder, you rarely get policies right the first time \u2014 but the overall architecture is still useful,\u201d says Roger Pielke Jr, who studies energy and innovation policy at the University of Colorado Boulder. \n               Difficult legacy \n             The seeds of Kyoto's problems were planted long before the treaty took shape. Many go back to June 1992, when negotiators at the Earth Summit in Rio de Janeiro, Brazil, were hammering out the United Nations Framework Convention on Climate Change (UNFCCC), the umbrella treaty that would encompass the Kyoto Protocol. Negotiators in Rio were still crafting the document just hours before heads of state arrived to sign it. Pressed by time and mounting expectations, the delegates borrowed heavily from past treaties, including a US\u2013Soviet nuclear-arms agreement and the 1989 Montreal Protocol designed to protect the ozone layer, says Gwyn Prins, who studies environmental politics at the London School of Economics and acted as an adviser for the British negotiating team in 1992. \u201cTake out nuclear warheads, put in CO 2  \u2014 the basic idea was as easy as that,\u201d says Prins. \u201cBut it turned out that climate change is a much more wicked beast \u2014 scientifically and economically \u2014 than ozone chemistry or nuclear-arms control.\u201d A meeting in Berlin in 1995 created another major problem, when parties to the UNFCCC decided to divide the world into two categories for the future treaty. There would be a set of rich countries with ambitious climate responsibilities and a set of less-developed economies \u2014 including China \u2014 with no responsibilities. That decision, part of an agreement known as the Berlin Mandate, did not sit well with US politicians. In the summer of 1997, Robert Byrd, a Democratic senator from West Virginia and one of the senior politicians of his day, declared: \u201cIt is the Berlin mandate \u2014 and the fact that it lets the developing world off the hook scot-free \u2014 that will seriously harm the global environment in future years.\u201d His colleagues agreed. The US Senate voted 95 to 0 in favour of a proposal demanding that developing nations participate in emissions commitments. Because Kyoto included no such commitments, the United States \u2014 the world's largest greenhouse-gas emitter at the time \u2014 would not ratify it. The industrialized countries that remained with the treaty were each bound by individualized commitments, based on the state of their economy and energy mix at the time (see 'Uneven progress'). The developed nations of Germany and Denmark agreed to cut their emissions by 21% relative to 1990 levels, whereas Portugal, with its less-developed economy, was allowed to increase its emissions by 27%. Kyoto covered four main greenhouse gases \u2014 CO 2 , methane, nitrous oxide and sulphur hexafluoride \u2014 and two further groups of gases, hydrofluorocarbons and perfluorocarbons. But it did not include another warming force: black soot particles from the incomplete combustion of wood and fossil fuels. Countries could meet their commitments by cutting their own emissions or by buying emission allotments from other nations that had exceeded their required reductions. Rich countries could also get credit by investing in low-carbon technologies in developing countries. For most central and eastern European nations, the job was easy: industrial emissions were high in the base year but had plummeted even by the time the treaty was signed. By 2010, Russia's CO 2  emissions were 34% lower than in the base year (excluding cuts attributable to land-use changes) and Ukraine's had fallen by 59%. The United Kingdom also easily met its 12.5% reduction target, thanks to the closure of many coal mines and a corresponding drop in consumption. More recently, the economic downturn has helped to reduce emissions. Economists estimate that between 2007 and 2008, decreased energy use caused a 2% drop in the emissions of the Kyoto Protocol countries; and that trend has continued as economies have sputtered. But the reductions made under the treaty were dwarfed by the rise in emissions not covered by the accord, especially in Asia. Since 2000, CO 2  emissions in China have nearly tripled to almost 10 billion tonnes, and those in India have doubled to around 2 billion tonnes. The rise in Asian emissions is partly a result of the migration of heavy industry from developed nations to developing countries, which make products that then get shipped back to wealthy nations. Between 1990 and 2010, the emissions embodied in such products grew by an average of 10% per year \u2014 to an annual total of 1.4 billion tonnes \u2014 surpassing the total emissions reductions achieved under Kyoto, says Glen Peters, a climate-policy researcher at the Center for International Climate and Environmental Research \u2014 Oslo. The gains made by the treaty were therefore deceptive, says David Victor, an energy-policy researcher at the University of California, San Diego. The treaty, he adds, was based on \u201cdubious economic assumptions and flawed accounting systems\u201d. \n               Faulty reasoning \n             One of those dubious assumptions was that fossil fuels would soon grow scarcer and prices would spiral upwards, helping to push countries towards alternative energy sources. But the globe is currently going through a massive coal renaissance, driven by abundant supplies that have grown much cheaper relative to other fuels in much of the world: the share of energy derived from coal has increased in the past ten years in both developing and developed countries. There has even been a shift towards coal in some parts of Europe, despite the mandatory cap-and-trade system to limit emissions. As a result, global energy production has grown more carbon-intensive in the past decade. \u201cThe fathers of the UNFCCC and Kyoto Protocol quite severely underestimated the amount of hydrocarbons buried in the ground,\u201d says Ottmar Edenhofer, chief economist at the Potsdam Institute of Climate Impact Research in Germany and a lead scientist with the Intergovernmental Panel on Climate Change. These trends in energy use have made it nearly impossible for countries to limit global warming to less than 2 \u00b0C above preindustrial levels, the value chosen by the EU as a threshold likely to prevent dangerous climate change. Calculations suggest 1  that emissions of CO 2  must stay below 1,000 billion tonnes between 2000 and 2050 to give the world a 75% chance of containing the temperature rise to 2 \u00b0C. But emissions from fossil-fuel burning and deforestation since 2000 have already pumped more than 450 billion tonnes of CO 2  into the atmosphere. If the current trend continues, the 1,000-billion-tonne margin will be surpassed in a little more than a decade. Despite its shortcomings, Kyoto has not been an utter failure, says Robert Stavins, an environmental economist at Harvard University in Cambridge, Massachusetts. Rather than judging the agreement on the emissions reductions it has achieved, he says, people should consider whether it has put the world on the right path. \u201cNobody with a right mind could have expected that a climate regime that treats China like sub-Saharan Africa and that excludes 50 developing countries with a higher per-capita income than Romania could be anything other than a cautious first step,\u201d he says. \u201cWhat we need to create is a workable successor with binding national emission targets that all governments can be realistically expected to adopt.\u201d Kyoto will leave a valuable legacy, says Yvo de Boer, former chief executive secretary of the UNFCCC and adviser for global auditing firm KPMG. The methodologies developed for reporting and verifying national greenhouse-gas emissions and land-use changes will be important components of any future climate treaty, he says. The protocol also gave birth to a method for trading carbon emissions among countries that face limits. Pioneered by the EU's Emissions Trading Scheme, which launched in 2005, this carbon market could one day become a globally linked CO 2  cap-and-trade system, says de Boer. An additional element of the Kyoto agreement \u2014 the Clean Development Mechanism (CDM) \u2014 established a way for rich countries to get credits towards their targets by making cost-effective emissions cuts in poor countries. Critics have charged that the CDM is plagued by cumbersome bureaucracy and that some Western-funded clean-technology projects in developing countries would probably have been built without it. Nevertheless, a total of 5,000 CDM projects have attracted investments worth almost US$100 billion. The projects have ranged from providing rural Chinese villagers with solar cookers to supporting a 100-megawatt wind farm in Mexico. \u201cWithout Kyoto we wouldn't have achieved anything at all\u201d in that area, says Victor. He would like to see a successor treaty constructed more like trade accords, which are tailored using realistic assumptions about commitments and rely on mutual action. \u201cWhat one country is willing to pay to control emissions depends a lot on what its economic competitors will pay as well,\u201d he says. \u201cMore flexible treaties could help countries craft deals that are truly interdependent \u2014 where the efforts of one country get multiplied because they lead others to do more.\u201d \n               Follow the money \n             Many other policy experts agree that the next climate treaty must take a more pragmatic approach than the UNFCCC and the Kyoto Protocol, which failed to win over the biggest polluters in part because it relied on a mix of ethical and environmental rationales rather than economic ones. \u201cMaking energy more expensive is a political liability everywhere,\u201d says Pielke. \u201cWhen emission reductions run up against economic growth, economic growth will inevitably win out. There is no magical solution, so you better set yourself tangible goals that aren't doomed to clash with the iron laws of politics.\u201d Emissions targets for all countries should be allocated in a way that acknowledges the political and economic costs of complying with a climate agreement, argued Valentina Bosetti, a climate-impact modeller at the Eni Enrico Mattei Foundation in Milan, Italy, and Jeffrey Frankel, an economist at Harvard, in a discussion paper last year 2 . China, for example, would be asked to accept only targets that it could meet without sacrificing its developmental aspirations; the United States would be assigned more stringent goals. But with time, all nations' emissions targets would be adjusted progressively according to a common economic formula. Attaching a price to carbon, through cap-and-trade mechanisms or a direct carbon tax, would help by stimulating technological advances that reduce emissions. The challenge, says Pielke, is to get the price right and make sure that the revenue will go towards investments in technology. A moderate carbon tax \u2014 applied when fossil fuels are removed from the ground \u2014 might work best to stimulate innovation in technologies that will eventually make alternative energy sources cheaper than fossil fuels, he says. But the approach has to be global. In a policy paper 3  published in 2010, Pielke, Prins and 12 others called for a more pragmatic, diversified and less bureaucratic approach than Kyoto, which would wean the global economy off carbon as a by-product of reducing poverty and expanding energy access to the poor. The group takes the focus off CO 2 , which has a long lifetime in the atmosphere, and instead emphasizes cuts in black carbon and methane emissions, which don't last as long. This, say the paper's authors, would slow global warming more quickly and would provide time for a transition to a low-carbon economy. They also suggest that negotiations for the next emissions treaty avoid topics such as deforestation, land use, air quality and adaptation, which would greatly complicate its architecture. That agreement will take shape slowly over the next few years. In Copenhagen in 2009, nations failed to produce a follow-on treaty to the Kyoto Protocol. However, in Durban, South Africa, last year, countries including China and the United States agreed to negotiate a new climate treaty by 2015. If the past is any indication, the final details of that pact will not emerge until the sleep-deprived delegates have reached the deadline of the final negotiating session. Will the world find a solution to this so far intractable problem? \u201cI'm confident it will,\u201d says de Boer, who presided over the unsuccessful negotiations in Copenhagen. \u201cBut I'm not convinced that it will come on time.\u201d \n                     Legacy of a climate treaty: After Kyoto 2012-Nov-28 \n                   \n                     Why we are poles apart on climate change 2012-Aug-15 \n                   \n                     Durban maps path to climate treaty 2011-Dec-13 \n                   \n                     Climate panel says prepare for weird weather 2011-Nov-18 \n                   \n                     Clean-energy credits tarnished 2011-Sep-27 \n                   \n                     How green is my future? 2011-May-11 \n                   \n                     Nature special: After Kyoto \n                   \n                     United Nations Framework Convention on Climate Change \n                   \n                     Intergovernmental Panel on Climate Change \n                   \n                     Potsdam Institute for Climate Impact Research \n                   \n                     Harvard Project on Climate Agreements \n                   Reprints and Permissions"},
{"file_id": "491654a", "url": "https://www.nature.com/articles/491654a", "year": 2012, "authors": [{"name": "Jeff Tollefson"}, {"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "More than ever, nations are powering themselves from abundant supplies of fossil fuels. \n               boxed-text \n             Even though countries are burning unprecedented amounts of oil and gas, the estimates of how much is left continue to grow, thanks to high prices and new technologies that have enabled companies to find and extract new resources. A decade ago, it was the tar sands of Canada and Venezuela. More recently, hydraulic-fracturing technologies have opened up oil and gas resources in the United States. Across the globe, proven oil and gas reserves are 60% higher today than they were in 1991. At current consumption rates, those reserves would last for about 60 years \u2014 and that could be extended by new discoveries and unconventional deposits. Coal reserves have not increased in size, but the supply will last for at least a century at current rates of consumption. Renewables such as solar and wind power are growing faster than any other source of energy, but are barely making a dent in fossil-fuel consumption. The scale of the challenge will only grow as the expanding global population requires more energy. This tour of global and regional energy trends makes clear that even with aggressive action to reduce energy consumption and curb emissions, fossil fuels will be around for a very long time. \n                     Legacy of a climate treaty: After Kyoto 2012-Nov-28 \n                   \n                     What's at stake in Doha climate talks 2012-Nov-23 \n                   \n                     Slow progress to cleaner coal 2012-Apr-11 \n                   \n                     Oil-sands vote ends in deadlock 2012-Feb-24 \n                   \n                     Global change: China at the carbon crossroads 2009-Apr-22 \n                   \n                     Nature special: After Kyoto \n                   \n                     Nature special: Rio+20 \n                   \n                     Nature special: Climate showdown in Durban \n                   \n                     Nature special: Fossil fuels \n                   \n                     World Energy\u00a0Outlook 2012 \n                   \n                     BP Statistical Review of World Energy \n                   \n                     International Energy Agency 2010 special report: How to make a modern energy access universal \n                   Reprints and Permissions"},
{"file_id": "491653a", "url": "https://www.nature.com/articles/491653a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "In this special issue,  Nature  examines the end of the 1997 Kyoto climate treaty \u2014 and the path ahead. On 1 January 2013, the world can go back to emitting greenhouse gases with abandon. The pollution-reduction commitments made by 37 nations as part of the Kyoto Protocol will expire, leaving the planet without any international climate regulation. In practice, the 1997 treaty did little to curb emissions of greenhouse gases (see  page 656 ). Most of the parties to the treaty met their commitments easily but, because the Kyoto Protocol did not set limits for developing countries, the total emissions of greenhouse gases are rising faster than ever, thanks mainly to massive growth in coal consumption by China. A graphic view of the world's energy resources shows just how difficult it will be to wean the planet off fossil fuels (see  page 654 ). Many nations are acknowledging the inevitable and scrambling to gird themselves against stronger and more frequent floods, droughts, heat waves and other climate threats (see  page 659 ). But Kyoto has provided valuable lessons. As nations press forward towards a new climate treaty in 2015, they should focus on controlling the carbon that each country consumes, both at home and through imports, rather than the carbon pollution that they emit, argues energy-policy researcher Dieter Helm (see  page 663 ). They can also build on one legacy of the Kyoto Protocol: the carbon cap-and-trade systems and carbon taxes that have emerged in Europe, Australia, Japan, China, California and parts of Canada. Expanding these mechanisms to cover a bigger share of the world will be crucial for solving the carbon problem, says climate-policy researcher Michael Grubb (see  page 666 ). Rather than a dead end, Kyoto could prove to be a first step towards an eventual solution. \n                     Why we are poles apart on climate change 2012-Aug-15 \n                   \n                     Durban maps path to climate treaty 2011-Dec-13 \n                   \n                     Climate panel says prepare for weird weather 2011-Nov-18 \n                   \n                     Clean-energy credits tarnished 2011-Sep-27 \n                   \n                     How green is my future? 2011-May-11 \n                   \n                     Nature special: After Kyoto \n                   \n                     United Nations Framework Convention on Climate Change \n                   \n                     Intergovernmental Panel on Climate Change \n                   \n                     Potsdam Institute for Climate Impact Research \n                   Reprints and Permissions"},
{"file_id": "492022a", "url": "https://www.nature.com/articles/492022a", "year": 2012, "authors": [{"name": "Zeeya Merali"}], "parsed_as_year": "2006_or_before", "body": "Fierce rivals have joined forces in the race to teleport information to and from space. Three years ago, Jian-Wei Pan brought a bit of  Star Trek  to the Great Wall of China. From a site near the base of the wall in the hills north of Beijing, he and his team of physicists from the University of Science and Technology of China (USTC) in Hefei aimed a laser at a detector on a rooftop 16 kilometres away, then used the quantum properties of the laser's photons to 'teleport' information across the intervening space 1 . At the time, it was a world distance record for quantum teleportation, and a major step towards the team's ultimate aim of teleporting photons to a satellite. If that goal is achieved, it will establish the first links of a 'quantum Internet' that harnesses the powers of subatomic physics to create a super-secure global communication network. It will confirm China's ascent in the field, from a bit-player a little more than a decade ago to a global powerhouse: in 2016, ahead of Europe and North America, China plans to launch a satellite dedicated to quantum-science experiments. It will offer physicists a new arena in which to test the foundations of quantum theory, and explore how they fit together with the general theory of relativity \u2014 Einstein's very different theory of space, time and gravity. It will also mark the culmination of Pan's long, yet fiercely competitive, friendship with Anton Zeilinger, a physicist at the University of Vienna. Zeilinger was Pan's PhD adviser, then for seven years his rival in the long-distance quantum-teleportation race, and now his collaborator. Once the satellite launches, the two physicists plan to create the first intercontinental quantum-secured network, connecting Asia to Europe by satellite. \u201cThere's an old Chinese saying, 'He who teaches me for one day is my father for life',\u201d says Pan. \u201cIn scientific research, Zeilinger and I collaborate equally, but emotionally I always regard him as my respected elder.\u201d \n               Fast mover \n             Pan was only in his early thirties when he set up China's first lab for manipulating the quantum properties of photons in 2001, and when he proposed the satellite mission in 2003. And he was 41 in 2011, when he became the youngest researcher ever to be inducted into the Chinese Academy of Sciences. \u201cHe almost single-handedly pushed this project through and put China on the quantum map,\u201d says team member Yu-Ao Chen, also at the USTC. Pan's drive dates back to his undergraduate years at the USTC in the late 1980s, when he first encountered the paradoxes at play in the atomic realm. Quantum objects can exist in a superposition of many states: a particle can spin both clockwise and anticlockwise at the same time, for instance, and it can simultaneously be both here and over there. This multiple personality is described mathematically by the particle's wavefunction, which gives the probability that it is in each of those states. Only when the particle's properties are measured does the wavefunction collapse, choosing a definite state in a single location. Crucially, there is no way, even in principle, to predict the result of a single experiment; the probabilities show up only as a statistical distribution and only when the experiment is repeated many times. Things get even weirder when two or more particles are involved, thanks to the quantum property of entanglement. Multiple particles can be prepared in such a way that measurements on one are correlated with measurements made on the others, even if the particles are separated by huge distances \u2014 and even though the phenomenon of superposition demands that these properties cannot be fixed until the instant they are probed. It is as strange as a physicist in Beijing and another in Vienna flipping coins in unison, and finding that they always either both throw heads or both throw tails. \u201cI was obsessed with these quantum paradoxes,\u201d says Pan. \u201cThey distracted me so much that I couldn't even study other things.\u201d He wanted to test the veracity of these almost inconceivable claims, but he could not find a suitable experimental quantum physics lab in China. The natural progression for budding Chinese physicists in Pan's position was to study in the United States \u2014 so natural, in fact, that fellow students joked that their university's acronym, USTC, actually stood for 'United States Training Centre'. But Pan wanted to learn from a quantum experimental master. And for him, one physicist stood out: Zeilinger. In 1989, Zeilinger had collaborated with physicists Daniel Greenberger, now at the City University of New York, and Michael Horne, now at Stonehill College in Easton, Massachusetts, on a key theorem governing the entanglement of three or more particles 2 . The work was a turning point for the field \u2014 and for Zeilinger. \u201cAt conferences, I realized that very important older physicists had started to regard me as the quantum expert,\u201d he says. By the mid-1990s, Zeilinger had set up his own quantum lab at the University of Innsbruck in Austria and needed a student to test some of his ideas. Pan seemed the perfect fit. So, in a rare move for a Chinese student, Pan relocated to Austria, beginning a relationship with Zeilinger that would see their careers develop in tandem over the next two decades. Even as a graduate student, Pan had big ambitions for his home country. At their first meeting, Zeilinger asked Pan what his dream was. \u201cTo build in China a world-leading lab like yours,\u201d Pan replied. Zeilinger was impressed. \u201cWhen he first came, he knew nothing about working in a lab, but he quickly picked up the rules of the game and was soon inventing his own experiments,\u201d he says. \u201cI always knew he would have a wonderful career \u2014 but the incredible success that he has had, I don't think anyone could have foreseen. I am very proud of him.\u201d While Pan was mastering his craft in Zeilinger's lab, physicists around the world were slowly embracing the notion that the esoteric quantum features that so enchanted Pan could be harnessed to create, say, ultra-powerful quantum computers. Standard computers chug slowly through information coded in binary digits \u2014 strings of zeros and ones. But as early as 1981, the physicist Richard Feynman had pointed out that quantum bits, known as 'qubits', need not be so encumbered. Because a qubit can simultaneously exist in superpositions of 0 and 1, it should be possible to build faster, more powerful quantum computers that would entangle multiple qubits together and perform certain calculations in parallel, and at breathtaking speed. Another emerging idea was ultra-secure quantum encryption for applications such as bank transactions. The key idea is that measuring a quantum system irrevocably disrupts it. So two people, Alice and Bob, could generate and share a quantum key, safe in the knowledge that any meddling by an eavesdropper would leave a trace. By the time Pan returned to China in 2001, the potential for quantum-based technologies was recognized enough to attract financial support from the Chinese Academy of Sciences and the National Natural Science Foundation of China. \u201cThe lucky thing was that in 2000 the economy of China started to grow, so the timing was suddenly right to do good science,\u201d Pan says. He plunged into building his dream lab. Back in Austria, meanwhile, Zeilinger had moved to the University of Vienna, where he continued to set quantum records thanks to his penchant for thinking big. One of his most celebrated experiments showed that buckyballs, fullerene molecules containing 60 carbon atoms, can exhibit both wave and particle behaviour 3  \u2014 a peculiar quantum effect that many thought could not survive in such large molecules. \u201cEveryone had been talking about maybe trying this experiment with small, diatomic molecules,\u201d recalls Zeilinger. \u201cI said, 'no guys, don't just think of the next one or two steps ahead, think about how to make a huge unexpected leap beyond everyone's thinking'.\u201d That was a lesson that Pan heeded well. Physicists around the world were beginning to imagine the futuristic quantum Internet, based on links between quantum computers that had yet to be built. At a time when most practitioners were still happy to get quantum information safely across a lab bench, Pan was already starting to think about how to teleport it across the planet. First proposed in 1993 by computer scientist Charles Bennett of IBM in New York and his colleagues 4 , quantum teleportation earned its sensational name because, \u201clike something out of  Star Trek \u201d, says Chen, it allows all information about a quantum object to be scanned in one location and then recreated in a new place. The key is entanglement (see 'Quantum at a distance slideshow'): because operations carried out on one of the entangled particles affect the state of its partner, no matter how far away it is, the two objects can be manipulated to act like two ends of a quantum telephone line, transmitting quantum information between two widely separated locations. The challenge arises when entangled particles, which must be produced together, are transmitted to their respective ends of the phone connection. Such a journey is fraught with noise, scattering interactions and all manner of other disruptions, any of which can destroy the delicate quantum correlations required to make teleportation work. Currently, for example, entangled photons are transported through optical fibres. But fibres absorb light, which keeps the photons from travelling more than a few hundred kilometres. Standard amplifiers can't help, because the amplification process will destroy the quantum information. \u201cFor teleporting to distances beyond the range of a city, we need to teleport through a satellite,\u201d says Chen. But would entanglement survive the upward trip through Earth's turbulent atmosphere to a satellite hundreds of kilometres overhead? To find out, Pan's team, including Chen, began in 2005 to carry out ground-based feasibility tests across ever-increasing expanses of clear air to find out whether photons lose their entanglement when they bump into air molecules. But they also needed to build a target detector that was both small enough to fit on a satellite and sensitive enough to pick out the teleported photons from background light. And then they had to show that they could focus their photon beam tightly enough to hit the detector. The work aroused Zeilinger's competitive instincts. \u201cThe Chinese were doing it, so we thought, why not try it?\u201d he says with a laugh. \u201cSome friendly competition is always good.\u201d The race began to push the distance record farther and farther (see 'Duelling records'). Over the next seven years, through a series of experiments carried out in Hefei, then by the Great Wall in Beijing and finally in Qinghai, the Chinese team teleported over ever-greater distances, until it passed 97 kilometres 5 . The researchers announced their results in May, posting a paper on the physics preprint server, arXiv \u2014 much to the chagrin of the Austrian team, which was writing up the results of its own effort to teleport photons between two of the Canary Islands. The Austrian group posted its paper on arXiv eight days later, reporting a new distance record of 143 kilometres 6 . The papers were eventually published, in quick succession, in  Nature 5 , 6 . \u201cI think that was in recognition of the fact that each experiment has different and complementary merits,\u201d says Xiao-song Ma, a physicist at the University of Vienna and a member of the Austrian team. Both teams agree that any scientific concerns about teleporting to a satellite have been defused. Now they just need a satellite to host the tests and a functioning payload to put on board. Zeilinger's team had been discussing a possible quantum satellite mission with the European Space Agency (ESA), but those talks gradually fizzled out. \u201cIts mechanisms are so slow that no decision was made,\u201d says Zeilinger. ESA's hesitation opened up a gap for the China National Space Administration to swoop in. Pan has been instrumental in pushing through the mission, which should see a quantum-physics satellite launched in 2016. This places Pan ahead in the quantum space race, and his team will handle the bulk of the scientific tests. \n               Key to success \n             But there is no point in developing the first global quantum communication network if you do not have anybody to talk with. So Pan has invited his one-time rival to join him on the project. Their first joint goal will be to generate and share a secure quantum key between Beijing and Vienna. \u201cUltimately, teleporting to a satellite is too big a task for any single group to do alone,\u201d says Ma. Although the promise to push forward the technological frontier has been the main attraction for the Chinese government, many physicists find the satellite project tantalizing for other reasons. \u201cAs a scientist, what drives me is learning more about the foundational side of physics,\u201d says Chen. So far, quantum theory's weirdness has been replicated time and again in labs, but it has never before been tested across distances that stretch into space \u2014 and there is reason to think that if it is going to break down anywhere, it will be there. At these larger scales, another fundamental theory of physics holds sway: general relativity. Relativity portrays time as another dimension interwoven with the three dimensions of space, thereby creating a four-dimensional space-time fabric that comprises the Universe. Gravity manifests because this malleable fabric bends around massive objects such as the Sun and it pulls less-massive objects, such as planets, towards them. The challenge is that quantum theory and general relativity present fundamentally different conceptions of space and time, and physicists have struggled to meld them into one unifying framework of quantum gravity. In Einstein's picture, space-time is perfectly smooth, even when examined at infinitesimal scales. Quantum uncertainty, however, implies that it is impossible to examine space at such small distances. Somewhere along the line either quantum theory or general relativity, if not both, must give way, but it is not yet clear which. The satellite experiments could help by testing whether the rules of quantum theory still apply over scales across which gravity's pull cannot be ignored. An obvious question is whether entanglement can stretch between Earth and a satellite. The team plans to answer it by producing a series of entangled particles on the satellite, firing one of each pair down to a ground station and then measuring its properties to verify that the pairs are correlated \u2014 and that the equipment is working properly. \u201cIf entanglement doesn't survive we'd have to look for an alternative theory to quantum mechanics,\u201d says Nicolas Brunner, a theoretical physicist at the University of Geneva, Switzerland, who works on protocols for teleportation to a satellite. The satellite could also go a step further and probe some of the predictions about the structure of space-time made by candidate quantum-gravity theories. For instance, all such theories predict that space-time would become grainy if scientists could somehow see it at scales of 10 \u221235  metres, a characteristic distance known as the Planck length. If that is indeed the case, then photons travelling from the satellite along this grainy road would be very slightly slowed 7  and their polarizations would undergo a tiny, random rotation 8  \u2014 effects that could be large enough to be picked up at the ground station. \u201cA satellite will open a truly novel window into a regime that experimenters haven't had access to before \u2014 and that is fantastic,\u201d says Giovanni Amelino-Camelia, a physicist at the Sapienza University of Rome, Italy. Pan, Zeilinger and their teams are currently scrutinizing the ideas generated in a recent series of workshops at the Perimeter Institute for Theoretical Physics in Waterloo, Canada, where physicists were asked to come up with other foundational questions that could be tested by satellites 9 . The questions that arose included: how does an entangled particle always know the result of a measurement made on its far-distant partner? Do the pairs somehow communicate though some still-unknown information channel? What causes the quantum wavefunction to collapse when it is measured? Is gravity somehow involved? And is time a precisely defined quantity, as described in general relativity \u2014 or is it fuzzy, as might be expected from quantum mechanics? Answering such questions will require apparatus of extraordinary sensitivity, says Pan. But meeting the technical challenges they raise will be easier now that the teams have joined forces, he says. The Austrian group, too, is seizing the new collaboration with enthusiasm. As Zeilinger says, \u201cOne of my students has just started learning Chinese.\u201d \n                     Quantum cryptography conquers noise problem 2012-Nov-20 \n                   \n                     Simulation: Quantum leaps 2012-Nov-14 \n                   \n                     First universal quantum network prototype links two separate labs 2012-Apr-12 \n                   \n                     Quantum information: The conundrum of secure positioning 2011-Nov-16 \n                   \n                     Lasers illuminate quantum security loophole 2011-Oct-25 \n                   \n                     Hackers blind quantum cryptographers 2010-Aug-29 \n                   \n                     Nature special: China \n                   \n                     Jian-Wei Pan \n                   \n                     Anton Zeilinger \n                   \n                     Chinese Space Agency \n                   \n                     Giovanni Amelino-Camelia \n                   Reprints and Permissions"},
{"file_id": "492170a", "url": "https://www.nature.com/articles/492170a", "year": 2012, "authors": [{"name": "Douglas Fox"}], "parsed_as_year": "2006_or_before", "body": "Crabs invading the Antarctic continental shelf could deal a crushing blow to a rare ecosystem. On a dim February evening, seven people crowded around a row of television monitors in a shack on the rear deck of the RV  Nathaniel B. Palmer . The research icebreaker was idling 30 kilometres off the coast of Antarctica with a cable as thick as an adult's wrist dangling over the stern. At the end of that cable, on the continental shelf 1,400 metres down, a remote-operated vehicle (ROV) skimmed across the sea floor, surveying a barren, grey mudscape. The eerie picture of desolation, piped back to the television monitors, was the precursor to an unwelcome discovery. The ROV had visited 11 different sea-floor locations during this 57-day research cruise along the Antarctic Peninsula in 2010. Each time, it had found plenty of life, mostly invertebrates: sea lilies waving in the currents; brittlestars with their skinny, sawtoothed arms; and sea pigs, a type of sea cucumber that lumbers along the sea floor on water-inflated legs. But at this spot, they were all absent. After 15 minutes, the reason became clear: a red-shelled crab, spidery and with a leg-span as wide as a chessboard, scuttled into view of the ROV's cameras. It probed the mud methodically \u2014 right claw, left claw, right claw \u2014 looking for worms or shellfish. Another crab soon appeared, followed by another and another. The crowded shack erupted into chatter. \u201cThey're natural invaders,\u201d murmured Craig Smith, a marine ecologist from the University of Hawaii at Manoa. \u201cThey're coming in with the warmer water.\u201d Cold temperatures have kept crabs out of Antarctic seas for 30 million years. But warm water from the ocean depths is now intruding onto the continental shelf, and seems to be changing the delicate ecological balance. An analysis 1  by Smith and his colleagues suggests that 1.5 million crabs already inhabit Palmer Deep, the sea-floor valley that the ROV was exploring that night (see 'A warming welcome'). And native organisms have few ways of defending themselves. \u201cThere are no hard-shell-crushing predators in Antarctica,\u201d says Smith. \u201cWhen these come in they're going to wipe out a whole bunch of endemic species.\u201d Researchers are worried that rising crab populations and other effects of the warming waters could irrevocably change a sea-floor ecosystem that resembles no other on Earth. Scientists are racing to document these effects, even as they continue to explore this little-understood region. \u201cThis could have a really major reorganizing impact on these unique and endemic marine communities,\u201d says Richard Aronson, a marine biologist at the Florida Institute of Technology in Melbourne, who was part of a team that found crabs on another part of Antarctica's continental shelf in December 2010 (ref.  2 ). \u201cIt's a fascinating thing,\u201d he says. \u201cA little scary, because it's a very obvious footprint of climate change.\u201d \n               Cut off by cold \n             Aronson has worried about the fragility of life on the Antarctic shelf for more than a decade. He spent December 1994 collecting fossils from Seymour Island, on the northeast fringe of the Antarctic Peninsula. The island's bare, crumbling hills contain the remnants of an ancient sea floor. In 200 metres of layered rock and fossils exposed by wind erosion, Aronson saw evidence of the most pivotal event in Antarctica's history: the continent's final separation from South America, starting around 40 million years ago. This event allowed the emergence of the circumpolar ocean current, which isolated Antarctica from warmer air and water masses farther north, and plunged it into perpetual winter. Aronson and his students analysed 10,000 fossils from before and after that sudden cooling, and a striking pattern emerged. As temperatures fell, the sea floor bloomed with soft-bodied echinoderms \u2014 invertebrates including starfish, brittlestars, sea lilies and sea cucumbers. At the same time, crush wounds caused by crabs or sharks on the arms of fossil starfish and sea lilies became rare \u2014 evidence that these predators were declining 3 . Crabs and lobsters were probably excluded by a physiological quirk. At temperatures below about 1 \u00b0C, they become unable to regulate magnesium in body fluids, leading to narcosis, clumsiness and paralysis of breathing. Most of the 100 or so fish species currently found on the Antarctic shelf belong to a single sub-order, whose members evolved antifreeze proteins to keep their blood flowing at subzero temperatures and then diversified to fill most niches in the frigid seas. They lack powerful jaws 4 . The result is an ecosystem reminiscent of that 350 million years ago, in which the top predators are slow-moving invertebrates such as starfish, sea spiders and ribbon worms 4 . \u201cAll of this stuff has got a very Palaeozoic flavour to it,\u201d says Aronson. The relaxation of natural selection allowed species to lose their natural armour, says James McClintock, a marine biologist at the University of Alabama at Birmingham. Animals on the Antarctic sea floor \u201care very weakly skeletonized\u201d, he says. \u201cYou can pick up an Antarctic clam and crush it in your hand.\u201d By the mid 2000s, Aronson began to believe that if Antarctica's oceans warmed up, the ecological cascade that caused this blast-from-the-past ecosystem to flourish would run in reverse: crushing predators would return and wreak havoc 4 . That prediction is now being tested. Westerly winds are strengthening and the circumpolar current is intensifying, driven by atmospheric warming and a hole in the ozone layer over Antarctica. These changes are lifting warm, dense, salty water from 4,000 metres down in the Southern Ocean up over the lip of the continental shelf. Douglas Martinson, an oceanographer at the Lamont\u2013Doherty Earth Observatory in Palisades, New York, has documented this process on the western side of the Antarctic Peninsula, where crabs are invading. Martinson installed five temperature and current sensors around Marguerite Trough \u2014 a deep canyon carved into the sea floor by glaciers advancing to the edge of the continental shelf in past ice ages. The moorings captured an insidious process: as the circumpolar current skirts Antarctica's continental shelf, it runs head-on into the steep wall of the trough. About once a week, a swirling eddy containing 100 cubic kilometres of warm water wafts up from that collision, spilling onto the continental shelf 5 , 6 . The same thing happens elsewhere, says Martinson: \u201cIt looks like this is what happens at all of the canyons that cut across the shelf.\u201d The temperature of this intruding water is only about 1.8 \u00b0C \u2014 but for an ocean region generally between 1 and \u22122 \u00b0C, the impact is substantial. And the incursion seems to have begun only recently, says Eugene Domack, a marine geologist at Hamilton College in Clinton, New York, who led the 2010 cruise to Palmer Deep. Domack has managed to date 7  the onset by measuring the amount of radioactive carbon-14 in deep-sea corals collected from the continental shelf \u2014 a process similar to reading tree rings. The corals had grown for 400 years before being dredged up. The carbon-14 content increased smoothly along the coral's growth axis for the first 350 years, and then dropped suddenly \u2014 indicating that the coral was being bathed in water with a reduced carbon-14 content. The water from the depths of the circumpolar current would fit the bill: it has been isolated from the carbon in the atmosphere for centuries. On the basis of these measurements, Domack has deduced that the warm-water incursion \u201ckicked in somewhere around the turn of the last century, 1920 or 1930\u201d. According to Domack's results, the incursion seems to have started following the end of the Little Ice Age \u2014 a period of relative cold that began in the Middle Ages \u2014 but it has intensified as anthropogenic warming and southern ozone depletion have taken hold. Average water temperatures west of the Antarctic Peninsula have risen by 1 \u00b0C in the past 50 years, and continue to rise by 0.01\u20130.02 \u00b0C per year 1 , 6 . \u201cThe heat injection is going through the roof,\u201d says Martinson. \u201cIt's going up exponentially.\u201d \n               Invasive species \n             The first evidence that crabs were poised to invade along with the warm water came early in 2007. Sven Thatje, a marine ecologist at the University of Southampton, UK, launched an ROV to the outer slope of the Antarctic Peninsula to map glacial grooves on the sea floor. But its cameras also caught sight of 13 king crabs ( Paralomis birsteini ) between depths of 1,300 and 1,100 metres (ref.  8 ). Thatje had studied the cold tolerance of these crabs and concluded that they could probably survive farther north at 2,000\u20134,000 metres, where the water is a degree or two warmer \u2014 \u201cbut then we found them even on the continental slope\u201d only 500 metres below the shelf itself, he says. \u201cThese crabs were thriving at 1 \u00b0C. They were basically at the physiological limit that I had anticipated.\u201d But it was Smith's discovery of  Neolithodes yaldwyni  king crabs in Palmer Deep, 120 kilometres in from the edge of the continental shelf, that demonstrated a true invasion. West of the Antarctic Peninsula, cold water sits on top of warmer water. To reach Palmer Deep from the outer ocean, crabs or larvae must have crossed what amounts to a cold, high mountain pass only 450 metres below sea level before settling into Palmer Deep, at depths of 800\u20131,400 metres (ref.  1 ). In December 2010, Thatje, working with Aronson and McClintock, returned to Antarctica and towed a submersible up and down the continental slope near the mouth of Marguerite Trough. The ROV traced 100 kilometres of sea floor, capturing 150,000 photographs that revealed hundreds of  P. birsteini  crabs between 2,300 and 830 metres down 2 . \u201cIf you extrapolate,\u201d says McClintock, \u201cwe're talking about millions of crabs.\u201d The crab invasion could have started a decade or two ago. When Smith re-examined photographs taken at the bottom of Palmer Deep in 1998, he saw telltale claw marks in the mud \u2014 indicating that at least some crabs were already present, even if none had been caught on camera 1 . Domack looked at 30 years of water-temperature data measured at Palmer Deep during earlier cruises, and found that the sea-floor valley had gradually warmed 1  \u2014 becoming ever-more hospitable to the crabs. Smith is now comparing gene sequences from crabs sampled in Palmer Deep with ones collected from deeper, warmer waters farther north in the Southern Ocean. The data from these experiments should help him to zero in on the crabs' origins and the date of their arrival. But even without knowing the exact history of the invasion, the implications seem clear. Animals living on the edge of their physiological limits often struggle to survive and reproduce, but 19 out of 27 crabs that Smith collected during a cruise in 2011 turned out to be females carrying larvae or eggs. \u201cThis population is reproducing like crazy,\u201d he says. \u201cIt's probably here to stay and expand.\u201d As the ceiling of cold water continues to lift over the next 10 or 20 years, crabs could spill out of Palmer Deep and Marguerite Trough \u2014 and colonize the broader continental shelf at depths of 400\u2013600 metres, devastating the endemic sea life. \n               Stifling heat \n             The warm waters will also bring other perils for Antarctica's sea-floor gardens. Many of the species here are exquisitely sensitive to increases in temperature. The brittlestars and other invertebrates have extremely slow metabolisms \u2014 an adaptation to the cold water \u2014 and only meagre ability to absorb and transport oxygen. \u201cSo what do those guys do if it warms up and their metabolic rate speeds up?\u201d asks Lloyd Peck, a biologist at the British Antarctic Survey in Cambridge, who has monitored these creatures in aquarium warming experiments. Their oxygen demand revs beyond what their gills can supply \u2014 and they slowly suffocate 9 , 10 . About half of the two dozen Antarctic species that Peck has studied seem to do fine in water 2 \u00b0C warmer than current maximum summer temperatures \u2014 but the rest seem to suffer. \u201cAt least two of the species that we think are going to be the first [to disappear] could give problems for the balance of the ecosystem,\u201d he says. Those are the Antarctic clam ( Laternula elliptica ) 9  and the shallow-water brittlestar ( Ophionotus victoriae ) 10 , both mainstay species that eat dead plankton and other organic trash that falls from above, and turn it into the biomass that feeds everything else on the sea floor. But these species either die or become dangerously sluggish at even 1 \u00b0C above current summer highs \u2014 temperatures that could become widespread in 50\u2013100 years. If rising temperatures cause brittlestars and clams to disappear, then more falling detritus might be consumed by microbes instead of being converted into edible biomass \u2014 meaning that it would sustain fewer animals, overall, on the sea floor. Alternatively, filter-feeding sponges might multiply to fill the niche. Either way, the mix of species supported further up the food chain might no longer include large numbers of archaic predators such as starfish, ribbon worms and sea spiders. Julian Gutt, a marine ecologist at the Alfred Wegener Institute for Polar and Marine Research in Bremerhaven, Germany, admires Smith's work with the crabs, but withholds final judgement on whether the crustaceans are a new piece of this destructive puzzle, or a long-present fixture. Repeat surveys showing that the crabs are expanding their foothold over time would confirm an invasion, he says. But \u201cif they move into new habitat, some serious impact is quite likely\u201d. Aronson, for one, will be watching closely for signs that this is happening. And in his experience, optimism is not warranted. \u201cEvery time we make a prediction of what we think will happen in the next 50 years, then poof, 10 years later, there it is,\u201d he says. \u201cSo I think this is going to be happening more rapidly than, as conservative scientists, we're used to predicting.\u201d \n                     Life abounds in Antarctic lake sealed under ice 2012-Nov-26 \n                   \n                     Antarctic temperature spike surprises climate researchers 2009-Nov-18 \n                   \n                     Evolution: Biology's next top model? 2009-Apr-08 \n                   \n                     RV  Nathaniel B. Palmer  \n                   \n                     Larsen Ice Shelf System, Antarctica \n                   \n                     Renard Centre of Marine Geology \n                   Reprints and Permissions"},
{"file_id": "492174a", "url": "https://www.nature.com/articles/492174a", "year": 2012, "authors": [{"name": "Philip Ball"}], "parsed_as_year": "2006_or_before", "body": "The more that microcircuits are shrunk, the hotter they get. Engineers are on the hunt for ways to cool off computing. A laptop computer can double as an effective portable knee-warmer \u2014 pleasant in a cold office. But a bigger desktop machine needs a fan. A data centre as large as those used by Google needs a high-volume flow of cooling water. And with cutting-edge supercomputers, the trick is to keep them from melting. A world-class machine at the Leibniz Supercomputing Centre in Munich, for example, operates at 3 petaflops (3 \u00d7 10 15  operations per second), and the heat it produces warms some of the centre's buildings. Current trends suggest that the next milestone in computing \u2014 an exaflop machine performing at 10 18  flops \u2014 would consume hundreds of megawatts of power (equivalent to the output of a small nuclear plant) and turn virtually all of that energy into heat. Increasingly, heat looms as the single largest obstacle to computing's continued advancement 1 . The problem is fundamental: the smaller and more densely packed circuits become, the hotter they get. \u201cThe heat flux generated by today's microprocessors is loosely comparable to that on the Sun's surface,\u201d says Suresh Garimella, a specialist in computer-energy management at Purdue University in West Lafayette, Indiana. \u201cBut unlike the Sun, the devices must be cooled to temperatures lower than 100 \u00b0C\u201d to function properly, he says. To achieve that ever more difficult goal, engineers are exploring new ways of cooling \u2014 by pumping liquid coolants directly on to chips, for example, rather than circulating air around them. In a more radical vein, researchers are also seeking to reduce heat flux by exploring ways to package the circuitry. Instead of being confined to two-dimensional (2D) slabs, for example, circuits might be arrayed in 3D grids and networks inspired by the architecture of the brain, which manages to carry out massive computations without any special cooling gear. Perhaps future supercomputers will not even be powered by electrical currents borne along metal wires, but driven electrochemically by ions in the coolant flow. This is not the most glamorous work in computing \u2014 certainly not compared to much-publicized efforts to make electronic devices ever smaller and faster. But those high-profile innovations will count for little unless engineers crack the problem of heat. Philip Ball talks about the engineering challenge of keeping computers cool. \n               Go with the flow \n             The problem is as old as computers. The first modern electronic computer \u2014 a 30-tonne machine called ENIAC that was built at the University of Pennsylvania in Philadelphia at the end of the Second World War \u2014 used 18,000 vacuum tubes, which had to be cooled by an array of fans. The transition to solid-state silicon devices in the 1960s offered some respite, but the need for cooling returned as device densities climbed. In the early 1990s, a shift from earlier 'bipolar' transistor technology to complementary metal oxide semiconductor (CMOS) devices offered another respite by greatly reducing the power dissipation per device. But chip-level computing power doubles roughly every 18 months, as famously described by Moore's Law, and this exponential growth has brought the problem to the fore yet again 2  (see 'Rising temperatures'). Some of today's microprocessors pump out heat from more than one billion transistors. If a typical desktop machine let its chips simply radiate their heat into a vacuum, its interior would reach several thousand degrees Celsius. That is why desktop computers (and some laptops) have fans. Air that has been warmed by the chips carries some heat away by convection, but not enough: the fan circulates enough air to keep temperatures at a workable 75 \u00b0C or so. But a fan also consumes power \u2014 for a laptop, that is an extra drain on the battery. And fans alone are not always sufficient to cool the computer arrays used in data centres, many of which rely on heat exchangers that use liquid to cool the air flowing over the hot chips. Still larger machines demand more drastic measures. As Bruno Michel, manager of the advanced thermal packaging group at IBM in R\u00fcschlikon, Switzerland, explains: \u201cAn advanced supercomputer would need a few cubic kilometres of air for cooling per day.\u201d That simply is not practical, so computer engineers must resort to liquid cooling instead 3 . Water-cooled computers were commercially available as early as 1964, and several generations of mainframe computers built in the 1980s and 1990s were cooled by water. Today, non-aqueous, non-reactive liquid coolants such as fluorocarbons are sometimes used, often coming into direct contact with the chips. These substances generally cool by boiling \u2014 they absorb heat and the vapour carries it away. Other systems involve liquid sprays or refrigeration of the circuitry. SuperMUC, an IBM-built supercomputer housed at the Leibniz centre, became operational in 2012. The 3-petaflop machine is one of the world's most powerful supercomputers. It has a water-based cooling system, but the water is warm \u2014 around 45 \u00b0C. The water is pumped through microchannels carved into a customized copper heat sink above the central processing unit, which concentrates cooling in the parts of the system where it is most needed. The use of warm water may seem odd, but it consumes less energy than other cooling methods, because the hot water that emerges from the system requires less chilling before it is reintroduced. And the use of hot-water outflow for heating nearby office buildings results in further energy savings. Michel and his colleagues at IBM believe that flowing water could be used not just to extract heat, but also to provide power for the circuitry in the first place, by carrying dissolved ions that engage in electrochemical reactions at energy-harvesting electrodes. In effect, the coolant doubles as an electrolyte 'fuel'. The idea is not entirely new, says Yogendra Joshi, a mechanical engineer at the Georgia Institute of Technology in Atlanta. \u201cIt has been used for many years in thermal management of aircraft electronics\u201d, which are cooled by jet fuel, he says. Delivering electrical power with an electrolyte flow is already a burgeoning technology. In a type of fuel cell known as a redox flow battery, for example, two electrolyte solutions are pumped into an electrochemical cell, where they are kept separate by a membrane that ions can flow through. Electrons travel between ions in the solutions in a process known as a reduction\u2013oxidation (redox) reaction \u2014 but they are forced to do so through an external circuit, generating energy that can be tapped to provide electrical power. \n               Salty logic \n             Redox-flow cells can be miniaturized using microfluidic technology, in which the fluid flows are confined to microscopic channels etched into a substrate such as silicon 4 . At such small scales, the liquids can flow past each other without mixing, so there is no need for a membrane to separate them. With this simplification, the devices are easier and cheaper to make, and they are compatible with silicon-chip technology. Michel and his colleagues have begun to develop microfluidic cells for powering microprocessors, using a redox process based on vanadium ions. The electrolyte is pumped along microchannels that are 100\u2013200 micrometres wide and similar to those used to carry coolant flows around some chips. Power is harvested at electrodes spaced along the channel, then distributed to individual devices by conventional metal wiring. The researchers unveiled their preliminary results in August, at a meeting of the International Society of Electrochemistry in Prague 5 . But they remain some way from actually powering circuits this way. At present, the power density of microfluidic redox-flow cells is less than 1 watt per square centimetre at 1 volt \u2014 two or three orders of magnitude too low to drive today's microprocessors. However, Michel believes that future processors will have significantly lower power requirements. And, he says, delivering power with microfluidic electrochemical cells should at least halve the power losses that occur with conventional metal wiring, which squanders around 50% of the electrical energy it carries as resistive heating. \n               Becoming brainier \n             Electrochemical powering could help to reduce processors' heat dissipation, but there is a way to make a much bigger difference. Most of the heat from a chip is generated not by the switching of transistors, but by resistance in the wires that carry signals between them. The problem is not the logic, then, but the legwork. During the late 1990s, when transistors were about 250 nanometres across, 'logic' and 'legwork' accounted for roughly equal amounts of dissipation. But today, says Michel, \u201cwire energy losses are now more than ten times larger than the transistor-switching energy losses\u201d. In fact, he says, \u201cbecause all components have to stay active while waiting for information to arrive, transport-induced power loss accounts for as much as 99% of the total\u201d. This is why \u201cthe industry is moving away from traditional chip architectures, where communication losses drastically hinder performance and efficiency\u201d, says Garimella. The solution seems obvious: reduce the distance over which information-carrying pulses of electricity must travel between logic operations. Transistors are already packed onto 2D chips about as densely as they can be. If they were stacked in 3D arrays instead, the energy lost in data transport could be cut drastically. The transport would also be faster. \u201cIf you reduce the linear dimension by a factor of ten, you save that much in wire-related energy, and your information arrives almost ten times faster,\u201d says Michel. He foresees 3D supercomputers as small as sugar lumps. What might 3D packaging look like? \u201cWe have to look for examples with better communication architecture,\u201d Michel says. \u201cThe human brain is such an example.\u201d The brain's task is demanding: on average, neural tissue consumes roughly ten times more power per unit volume than other human tissues \u2014 an energy appetite unmatched even in an Olympic runner's quadriceps. The brain accounts for just 2% of the body's volume, but 20% of its total energy demand. Yet the brain is fantastically efficient compared to electronic computers. It can achieve five or six orders of magnitude more computation for each joule of energy consumed. Michel is convinced that the brain's efficiency is partly due to its architecture: it is a 3D, hierarchical network of interconnections, not a grid-like arrangement of circuits. \n               Smart build \n             This helps the brain to make much more efficient use of space. In a computer, as much as 96% of the machine's volume is used to transport heat, 1% is used for communication (transporting information) and just one-millionth of one per cent is used for transistors and other logic devices. By contrast, the brain uses only 10% of its volume for energy supply and thermal transport, 70% for communication and 20% for computation. Moreover, the brain's memory and computational modules are positioned close together, so that data stored long ago can be recalled in an instant. In computers, by contrast, the two elements are usually separate. \u201cComputers will continue to be poor at fast recall unless architectures become more memory-centric\u201d, says Michel. Three-dimensional packaging would bring the respective elements into much closer proximity. All of this suggests to Michel that, if computers are going to be packaged three-dimensionally, it would be worthwhile to try to emulate the brain's hierarchical architecture 6 . Such a hierarchy is already implicit in some proposed 3D designs: stacks of individual microprocessor chips (on which the transistors themselves could be wired in a branching network) are stacked into towers and interconnected on circuit boards, and these, in turn, are stacked together, enabling vertical communication between them. The result is a kind of 'orderly fractal' structure, a regular subdivision of space that looks the same at every scale. Michel estimates that 3D packaging could, in principle, reduce computer volume by a factor of 1,000, and power consumption by a factor of 100, compared to current 2D architectures. But the introduction of brain-like, 'bionic' packaging structures, he says, could cut power needs by another factor of 30 or so, and volumes by another factor of 1,000. The heat output would also drop: 1-petaflop computers, which are now large enough to occupy a small warehouse, could be shrunk to a volume of 10 litres. If computer engineers aspire to the awesome heights of zetaflop computing (10 21  flops), a brain-like structure will be necessary: with today's architectures, such a device would be larger than Mount Everest and consume more power than the current total global demand. Only with a method such as bionic packaging does zetaflop computing seem remotely feasible. Michel and his colleagues believe that such innovations should enable computers to reach the efficiency \u2014 if not necessarily the capability \u2014 of the human brain by around 2060. That is something to think about. \n                     The energy should always work twice 2009-Mar-11 \n                   \n                     Big data: Welcome to the petacentre 2008-Sep-03 \n                   \n                     Newcomers hit top 10 in supercomputer list 2007-Nov-13 \n                   \n                     Nanotechnology: Beyond the silicon roadmap 2002-Oct-10 \n                   \n                     IBM Zurich \n                   \n                     Bruno Michel \n                   \n                     SuperMUC at the Leibniz Rechenzentrum \n                   Reprints and Permissions"},
{"file_id": "492026a", "url": "https://www.nature.com/articles/492026a", "year": 2012, "authors": [{"name": "M. Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "For decades, one design has dominated nuclear reactors while potentially better options were left by the wayside. Now, the alternatives might finally have their day. Back in 2000, when Kirk Sorensen was a NASA engineer looking at nuclear-power options for future colonies on the Moon, he came across a book that described the molten-salt reactor: an energy source in which the nuclear fuel was liquid. It sounded bizarre, says Sorensen. Every reactor he had ever heard of used some form of solid uranium fuel \u2014 starting with the 'light-water' reactors that currently dominate the nuclear-power industry. But the book explained that the molten-salt technology had been demonstrated some three decades earlier at the Oak Ridge National Laboratory in Tennessee \u2014 and that the fluid uranium- or thorium-containing fuel offered major advantages. Molten-salt reactors would be impervious to catastrophic meltdown, for example, and instead of producing nuclear waste laced with plutonium and other long-lived radioisotopes, they could destroy those isotopes almost completely. The list of advantages went on and on, says Sorensen: the molten-salt idea \u201chad the potential to solve almost all the problems of nuclear energy in a far, far more elegant way\u201d than light-water reactors. \u201cSo why didn't we do it this way in the first place?\u201d M. Mitchell Waldrop discusses radical reactor designs. A lot of people have been asking that question in the past decade \u2014 and not just about the molten-salt reactor. That particular technology was abandoned in 1976 because of warring agendas within the US research programme. But it was just one of several alternative technologies to be sidelined during the first rush to commercialize nuclear power. Others include 'fast' reactors that would also burn up nuclear waste, and high-temperature reactors that could take a huge bite out of greenhouse-gas emissions by generating zero-carbon heat for industry. Taken together, these alternative technologies could eliminate most or all of nuclear energy's drawbacks. But they have received only fitful attention from researchers over the decades, thanks to constantly shifting agendas and funding levels. Now, change may be coming. Over the past decade, the need for safe, carbon-free energy \u2014 especially in fast-developing nations such as China \u2014 has sparked government interest in alternative nuclear technologies, along with commercial efforts to revive and market some designs. Optimists think that even the nuclear disaster at the Fukushima Daiichi power plant in Japan last year will ultimately boost the market for safer alternative reactors. From start-ups such as Flibe Energy, which Sorensen founded last year in Huntsville, Alabama, to commercialize the molten-salt reactor, to industry giants such as General Electric-Hitachi Nuclear Energy, which is developing a commercial fast reactor, companies hope to be ready. Reviving the technologies will not be quick or easy. Although the basic designs were worked out decades ago, engineers hoping to put them into practice must develop things such as radiation-resistant materials, more-efficient heat exchangers and improved safety systems \u2014 and must then prove to regulators that all these systems will work. \u201cNuclear is hard,\u201d says Edwin Lyman, senior global-security analyst for the Union of Concerned Scientists in Cambridge, Massachusetts. \u201cIt's expensive. It's slow. And the stakes are very high, because safety has to be a factor.\u201d But those involved share a conviction that the best hope for the nuclear industry's future is to reclaim its past. As Sorensen points out about the cancellation of the molten-salt programme: \u201cNobody ever said, 'Maybe we made a mistake. Maybe we should go back and revisit that decision'.\u201d \n               First, not best \n             Light-water reactors achieved their dominance not because they were best, but because they were first. Originally developed in the late 1940s as a compact power source for nuclear ships and submarines, the light-water design was adapted and scaled up during the 1950s, when the United States sought to put a peaceful face on atomic energy by creating a commercial nuclear-power industry. 'Light water' is ordinary H 2 O, which flows through the reactor core, absorbs its heat and circulates it to a conventional steam turbine that turns the heat into electricity (see 'The nuts and bolts of nuclear'). Eventually, such reactors were meant to be part of a larger system that would make up for a basic inefficiency: left alone, any nuclear reactor will quickly poison itself. As the chain reaction proceeds, the fuel accumulates more and more of the fragments left over after the uranium atoms split, which in turn absorb more and more of the neutrons required to keep the reaction going. After perhaps 18 months, the fuel is 'spent' and has to be removed \u2014 even though it still contains much of its original energy. \u201cSo there was always this vision that there would be a recycled-spent-fuel infrastructure that would allow you to recover more of the fuel's energy,\u201d says William Magwood, a former director of the Office of Nuclear Energy at the US Department of Energy (DOE) and now a member of the US Nuclear Regulatory Commission. A worldwide network of reprocessing plants would take the spent fuel, chemically extract the still-usable components \u2014 mostly uranium-235, plus the fissionable plutonium-239 formed when neutrons are captured by non-fissile uranium-238 \u2014 and then turn them into fresh reactor fuel. Ultimately, the plan was to transition to a new generation of 'breeder' reactors designed to maximize plutonium production. The only waste would be a comparatively small residue of intensely radioactive fission products that would decay within a few centuries, and could be disposed of in, say, a well-designed concrete bunker. This vision became the dominant US strategy in the 1960s and early 1970s, says Magwood, to the point at which authorities terminated much of the research funding for non-breeder reactor designs \u2014 including the molten-salt reactor. And the scheme took off: of the 437 nuclear-power reactors currently operating around the world, 356 are light-water reactors. But then, in May 1974, India tested a nuclear bomb made with plutonium extracted from reactor fuel. Governments around the world suddenly had to face the geopolitical realities: large-scale commercial reprocessing would invite rampant nuclear-weapons proliferation. Because each reprocessing plant would be working with bomb-grade plutonium by the tonne, how could inspectors ever be sure that no one had diverted the 4\u20136 kilograms required for a weapon? So in April 1977, US President Jimmy Carter banned commercial reprocessing. President Ronald Reagan lifted that ban a few years later, but the costs of the facilities were so high that only two commercial reprocessing plants have been opened for reactor fuel since then, both in France. Research on breeder reactors largely ceased, because they seemed to make little sense without reprocessing. And engineers found themselves left with a complicated disposal problem: they would now have to isolate tens of thousands of tonnes of spent fuel for hundreds of centuries, thanks to the 24,100-year half-life of plutonium-239. No one has yet worked out how to guarantee isolation on that timescale (see  Nature   473 , 266\u2013267; 2011 ). Meanwhile, the 1970s also brought an increasing outcry over safety. If the flow of water through a light-water reactor is interrupted for any reason, then heat becomes trapped in the core. Even if the reactor is technically shut down, the fission products can still produce enough heat from radioactive decay to melt the fuel and escape into the environment. All light-water reactors have emergency back-up cooling systems \u2014 but what if those systems fail? That fear was realized in March 1979, when an accidental loss of coolant triggered a partial meltdown at the Three Mile Island nuclear power plant near Harrisburg, Pennsylvania \u2014 and dramatically confirmed at Fukushima Daiichi, which saw a complete meltdown in March 2011 (see  Nature   483 , 138\u2013140; 2012 ). \n               A second chance \n             The public and political backlash after the Three Mile Island incident created a worldwide 'nuclear brown-out' that lasted for a quarter of a century. Power companies scrapped their nuclear expansion plans and cancelled almost all of their reactor orders. And the industry became even more reluctant to explore new technologies. \u201cThe industry is risk-averse to moving beyond technology and materials they have lots of experience with\u201d and that they know can get regulatory approval, says Per Peterson, a nuclear engineer at the University of California, Berkeley. With little interest from industry and no practical hope for deployment, advanced-reactor research struggled with inconsistent direction and support. \u201cIt's very hard to do planning and advanced engineering R&D if you're up and down, up and down,\u201d says Michael Corradini, a nuclear engineer at the University of Wisconsin-Madison. This picture didn't begin to change until around the turn of the millennium. \u201cNuclear construction had taken off in China and south Asia \u2014 any place that doesn't have oil and gas,\u201d recalls Charles Forsberg, a nuclear engineer at the Massachusetts Institute of Technology (MIT) in Cambridge. (There are currently 64 reactors under construction around the world, with hundreds more planned.) In the United States, he says, \u201cthe feds realized that, if we're not doing anything on nuclear, we won't be at the table\u201d. Climate change, too, drove renewed interest in nuclear technology in the United States and Europe. Given the erratic output of both wind and solar generators, says Forsberg, \u201cif you're going to get off fossil fuel, you have to have a serious nuclear programme\u201d. \n               Radical investment \n             One result of this renewed focus was the US Nuclear Power 2010 programme. Announced by the DOE in February 2002, this government\u2013industry cost-sharing plan was designed to help manufacturers to develop and license light-water reactors with advanced safety features, such as the ability to keep the coolant moving during an accident, using gravity and natural convection. Several such reactors are now being planned around the world, including four under construction in the United States \u2014 the first new reactors there in a generation. Even more radical designs might find an opening with the DOE's cost-sharing programme for Small Modular Reactor development, launched this year. That scheme's goal is to move away from the current multi-gigawatt nuclear plants, which can cost between US$10 billion and $15 billion to build, towards plants of 250 megawatts or less \u2014 small enough to mass-produce in a factory and ship to the intended site. Four reactor vendors, all with advanced light-water designs, competed for the award, which on 20 November went to a consortium headed by the Babcock and Wilcox Company of Charlotte, North Carolina. But other designs could also benefit, says Peterson. \u201cIf we can generate a market for light-water small modular reactors,\u201d he says, \u201cthat makes it much easier to develop a market for prototype advanced reactors.\u201d Power companies could experiment with the new technology by simply sliding in another module. If it works, great, says Peterson. If it doesn't, not much has been lost. \u201cThis lowers their whole risk threshold,\u201d he says. Prime candidates for slide-in modules are high-temperature reactors, which do exactly what the name implies: they generate steam at up to 1,000 \u00b0C, much hotter than the roughly 300 \u00b0C available from light-water reactors. This requires some radically different design choices, such as the use of helium gas instead of water to extract heat, and the use of a heat-resistant fuel made from oxides and carbides of uranium. Such reactors cannot melt down: the fuel is stable up to 1,600 \u00b0C, hundreds of degrees hotter than the core would become even if all power and coolant were lost. The high temperatures would make the reactors more efficient at producing electricity. And they could slash carbon emissions by supplying heat for industrial processes. In the United States, roughly 23% of all energy is used in industrial applications such as petroleum cracking and plastics manufacture, many of which need temperatures of at least 700 \u00b0C. Currently, those temperatures tend to be generated by burning natural gas; high-temperature reactors could provide a zero-carbon alternative. A number of commercial high-temperature reactors are under development around the world. But this year, a consortium of petrochemical companies and reactor manufacturers agreed to back the Antares high-temperature reactor design from the French company AREVA, based in Paris. \u201cAll that's left is about $800 million of work design and licensing effort required to get the technology to the point where the Nuclear Regulatory Commission could approve it,\u201d says Fred Moore, head of the division that provides power and steam for the Dow Chemical Company, headquartered in Midland, Michigan. He estimates that this should take 5\u20137 years. If all goes to plan, high-temperature systems will be among the first advanced reactors to be deployed, starting in the 2020s. Not far behind would be fast reactors, which tackle a problem that high-temperature reactors cannot: spent nuclear fuel. Fast reactors could consume the stuff, turning waste into energy and easing the disposal problem. Fission neutrons are 'fast' when they have just emerged from newly split nuclei at a mean energy of roughly 2 million electronvolts. In light-water reactors, collisions with the hydrogen nuclei in the coolant water quickly slow the neutrons to just a fraction of an electron volt, which makes them more likely to trigger another fission reaction. But slow neutrons have a drawback: instead of splitting the target uranium nuclei, they often get absorbed, transforming the nuclei into long-lived isotopes of plutonium, neptunium, americium, curium or other heavy elements \u2014 the ones that collectively make disposal of spent fuel a nightmare. Fast neutrons, by contrast, rarely get absorbed. They don't hit their targets often, but when they do, that target almost always splits. As a result, fast reactors not only avoid the problem of producing long-lived isotopes, but can even destroy them in spent fuel. Building a fast reactor is tricky, says Peterson, not least because it has to be cooled by liquid sodium or some other substance that won't slow the neutrons down as water does. This can make for a bulky design. \u201cAnd it's very challenging to build heat exchangers\u201d to make steam for the power turbines, he says, because sodium reacts violently with moisture to produce explosive hydrogen gas. Researchers are actively studying other, less reactive options for cooling, such as lead and supercritical carbon dioxide, he says. Nevertheless, some 20 fast reactors have been operated over the years \u2014 many of them following the 1970s breeder design that was built to maximize plutonium production instead of consuming it \u2014 and at least four manufacturers are developing small fast reactors for spent-fuel consumption. A leading example is the Super Power Reactor Innovative Small Module (S-PRISM) from General Electric-Hitachi in Wilmington, North Carolina. It calls for a compact sodium-cooled fast reactor, integrated with a recycling unit that would take the reactor's spent fuel, remove the fission products that poison the nuclear reaction, and put the rejuvenated fuel back into the reactor. At no point would it isolate bomb-ready plutonium. The potential market is substantial, says Eric Loewen, head of advanced-reactor development for General Electric-Hitachi. \u201cWe have a usability study going on with the United Kingdom, where we would take the 100 tonnes of plutonium from their reprocessing plants and turn it into an energy resource,\u201d he says. And in the United States and elsewhere, he says, \u201cour vision is a network of advanced recycling centres\u201d, each with six S-PRISM reactors and one recycling centre that could keep up with the waste from between one and three light-water reactors, and get rid of the backlog currently sitting in storage. That network will not be cheap. But the fundamental challenge is political, says Loewen, echoing Forsberg and many other experts: what is needed is \u201ca policy framework that lets people see spent fuel as an asset, rather than something to be thrown away.\u201d \n               Molten-salt reactors \n             The great virtue of solid reactor fuel is its predictable geometry. The great drawback is its complexity. The intensity of neutron bombardment, the distribution of fission products, the radiation damage to the fuel's crystalline structure: everything varies from point to point. This is a constant headache for designers trying to ensure that the reactor operation is stable \u2014 and trying to convince regulators that even the worst meltdown won't allow any part of the fuel to collapse into a critical mass. But all these concerns go away when the fuel is already a liquid \u2014 one major reason why Oak Ridge wanted to develop the molten-salt reactor back in the 1960s. 'Molten-salt' refers to the fuel, usually uranium tetrafluoride, which is liquid at operating temperatures when blended with 'FLiBe': a mixture of lithium fluoride and beryllium fluoride that serves as a coolant. \u201cIt's a pot \u2014 a big, dumb, pot,\u201d says Forsberg. \u201cYou throw fuel in, it's mixed, and the overall composition changes not at all.\u201d Liquid fuel has another big advantage, says Sorensen: \u201cYou don't have to remove it from the reactor until it's completely consumed.\u201d Instead, the fuel is circulated through an external recycling unit that extracts the fission products continuously, keeping the fuel from being poisoned. The design also allows for an elegant approach to safety, says Sorensen: at the bottom of the reactor is a hole, plugged with a chunk of fuel that is kept solid by a refrigeration unit. If the reactor loses power in an emergency, the refrigeration will cease, the plug will melt and the fuel will safely drain into underground holding tanks. Finally, the molten-salt design can accommodate a variety of fuels, ranging from conventional uranium to raw nuclear waste or thorium \u2014 an element that is roughly three times more abundant than uranium. For all of that, reviving the molten-salt reactor after a four-decade hiatus is a daunting task. \u201cWe have to rebuild a knowledge base that has largely gone away,\u201d says Sorensen. He founded Flibe Energy to try, though. The company is developing a 40-megawatt reactor that might be used on military bases so that they can operate independently of the grid. \n               Solid chance \n             In September 2011, Forsberg, Peterson, MIT's Lin-wen Hu and Todd Allen, a nuclear engineer at the University of Wisconsin-Madison, became principal investigators on a 3-year, DOE-funded project that could be a step on the way to the molten-salt reactor: a FLiBe-cooled high-temperature reactor. \u201cNo one has ever built a salt-cooled solid-fuel reactor,\u201d says Peterson. But if the project works, the reactor core could be four to five times smaller than those in other designs and, because of the stability of the FLiBe salt, it would \u201calways be hundreds of degrees below the failure limits\u201d, he says. Peterson says that the company could have a test reactor within a decade, although \u201cthat assumes abundant resources\u201d. That is a big assumption: the global economic crisis has made financing for all advanced reactors much harder to come by. Furthermore, notes Corradini, pointing to the sudden abundance of shale gas in the United States, \u201ccheap fossil fuels have postponed many of the clean-energy projects in the United States, not just nuclear\u201d. Paul Genoa, director of policy development for the Nuclear Energy Institute trade group in Washington DC, takes the long view. \u201cWe did the light-water reactors first, to get going,\u201d he says. Next, in the 2020s, will come advanced light-water reactors for increased safety, followed closely by high-temperature reactors that expand the attack on carbon emissions. \u201cAnd then we build fast reactors to consume the waste.\u201d Molten-salt reactors are something of a wild card, says Genoa, but are worth developing. Some even wilder cards are under investigation: one notable example is the accelerator-driven reactor, which would drive fission reactions using neutrons from a high-energy particle accelerator. It could be fuelled with thorium, and shut down instantly by switching off the accelerator. But will nuclear energy really evolve? Those in the field see reason for optimism, particularly if the increasingly tangible consequences of climate change force governments to put a price on carbon. Even the Fukushima disaster could ultimately spur new nuclear technologies, says Genoa. \u201cIt scared people and made them concerned about nuclear energy,\u201d he says. But as people looked more closely, \u201cthey said, 'Hey, those were 30-year-old plants'\u201d. In time, he says, smart, new reactors will look a whole lot more appealing. \n                 See Comment \n                 page 31 \n               \n                     Battle of Yucca Mountain rages on 2011-May-17 \n                   \n                     Concerns over nuclear energy are legitimate 2011-Mar-30 \n                   \n                     Chernobyl's legacy 2011-Mar-28 \n                   \n                     Do not phase out nuclear power \u2014 yet 2011-Mar-23 \n                   \n                     Next-Generation Nuclear Power 2002-Jan-01 \n                   \n                     Nature special: Fukushima crisis \n                   \n                     Flibe Energy \n                   \n                     Next Generation Nuclear Plant Industry Alliance \n                   \n                     Scientific American on fast reactors \n                   \n                     Nuclear Energy Institute on new reactors \n                   \n                     World Nuclear Society on generation IV nuclear reactors \n                   \n                     World Nuclear Society on accelerator-driven reactors \n                   Reprints and Permissions"},
{"file_id": "490325a", "url": "https://www.nature.com/articles/490325a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "In a special issue,  Nature  examines the changing global landscape of research. A fundamental shift is taking place in where, and by whom, science is being done. Once, a succession of science superpowers were dominant: France, Germany, the United Kingdom and the United States. Today, more nations \u2014 from China and India to Singapore, Brazil and South Korea \u2014 are taking their place at the high table of research. National boundaries are being transcended by networks of collaborators and researchers who are much more mobile than in the past. Academics are moving to where the funding and facilities are. As Rajika Bhandari of the Institute for International Education puts it: \u201cKnowledge generation and research is really a border-less enterprise\u201d. This special issue of  Nature  looks at how this movement of people and ideas will change how science is done, how it is funded and the questions that it addresses. A News Feature explores data on migration and explains that ideas of 'brain drain' and 'brain gain' are being replaced by 'brain circulation', in which scientists move more fluidly around the world (see  page 326 ). Analysing data on co-authorship, a Comment on  page 335  charts the rise of collaboration networks \u2014 in Asia, Africa, the Middle East and South America \u2014 and challenges the traditional science heavyweights to keep up. But ideas and talent could still circulate more freely, both within and between nations. On  page 331 , eight leaders of institutes and research programmes worldwide outline the steps that must be taken to raise the scientific bar in their countries. And on  page 337 , Subra Suresh, head of the US National Science Foundation in Arlington, Virginia, calls for greater cross-border cooperation and the pooling of resources to address global challenges such as climate change, pandemics, earthquakes, nuclear catastrophes, water shortages and malnutrition. Science must go truly global if it is to equip us for life on our changing planet. \n                 See Editorial \n                 page 309 \n               \n                     Research funding: Global challenges need global solutions 2012-Oct-17 \n                   \n                     Global mobility: Science on the move 2012-Oct-17 \n                   \n                     Research policy: How to build science capacity 2012-Oct-17 \n                   \n                     Global reach 2012-Oct-17 \n                   \n                     Collaborations: The rise of research networks 2012-Oct-17 \n                   \n                     Career choices: The mobility imperative 2011-Feb-23 \n                   \n                     Nature special: The new map of science \n                   Reprints and Permissions"},
{"file_id": "490462a", "url": "https://www.nature.com/articles/490462a", "year": 2012, "authors": [{"name": "Dan Fagin"}], "parsed_as_year": "2006_or_before", "body": "Researchers say that some chemicals have unexpected and potent effects at very low doses \u2014 but regulators aren't convinced. Near the end of an adventurous life spent wandering the fortress towns of central Europe, clashing with blood-letters and other tradition-bound healers of the day, the irascible sixteenth-century physician Paracelsus wrote a defence of his unorthodox use of mercury, opium and other potentially dangerous medicines. \u201cAll things are poison, and nothing is without poison: the dose alone makes a thing not poison,\u201d he wrote. Centuries later, after many of his once-radical ideas found wide acceptance, Paracelsus's pronouncement would be distilled into a pithy phrase that became foundational dogma for the modern science of toxicology: \u201cthe dose makes the poison.\u201d The contemporary interpretation of Paracelsus's famous declaration, for which he is often called the father of toxicology, is that dose and effect move together in a predictably linear fashion, and that lower exposures to a hazardous compound will therefore always generate lower risks. This idea is not just a philosophical abstraction; it is the core assumption underlying the system of chemical-safety testing that arose in the mid-twentieth century. Risk assessors typically look for adverse effects of a compound over a range of high doses and, from there, extrapolate downwards to establish health standards \u2014 always assuming, like Paracelsus, that chemicals toxic at high doses are much less risky at lower, real-world levels. But what if the Paracelsian presumption is wrong? What if, for a large and potent class of compounds, lower doses pose higher risks? A growing number of academic researchers are making just such a claim for endocrine disrupters, a large group of synthetic chemicals able to interact with cellular hormone receptors. These compounds, which range from the common weed killer atrazine and the plasticizer bisphenol A (BPA) to the antibacterial agent triclosan (used in cleansers) and the vineyard fungicide vinclozolin, don't play by the usual rules of toxicology. On the basis of conventional high-dose testing, regulators have set maximum acceptable levels for each of them that assume all doses below that level are safe. But academic researchers who have studied a wider range of doses, including very low ones found in the everyday environment, say that their experiments usually do not generate the tidy, familiar 'ski-slope' dose-response graphs of classic toxicology. Instead, most endocrine disrupters have 'non-monotonic' dose-response curves, meaning that their slopes change at least once from negative to positive, or vice versa, forming 'U' shapes, inverted 'U's or even stranger shapes that resemble undulating Chinese dragons (see 'Curious curves'). \u201cWe're seeing that for every one of these compounds we test, there will be a non-monotonic response \u2014 every one!\u201d says Frederick vom Saal, a neurobiologist at the University of Missouri-Columbia, who has been sounding the alarm about endocrine disrupters since the 1970s. \u201cLow doses of endocrine disrupters act in ways that are totally unpredicted by the traditional approaches of toxicology.\u201d Vom Saal and his colleagues believe that very low doses of these compounds in the environment are contributing to a wide range of human health problems \u2014 including obesity, diabetes, cancer, cardiovascular disease, and infertility and other disorders related to sexual development. Many toxicologists, however, are not convinced \u2014 especially those in industry or government who have spent their careers deeply involved in traditional risk assessment. Although they acknowledge that endocrine disrupters have unusual toxicological quirks, they say that the work of vom Saal and like-minded researchers is still insufficiently replicated, too reliant on unvalidated assays and too focused on end points such as organ weight, precancerous growths and changes in the activity of genes and proteins, which may not pose significant health threats. \u201cIf we're going to take this seriously, we need to have some evidence of a real phenomenon that happens not just in the hands of one researcher and one test, something repeatable that can stand up to scientific scrutiny about how it could lead to real health effects we want to avoid,\u201d says Lorenz Rhomberg, a toxicologist at the environmental-consulting firm Gradient in Cambridge, Massachusetts. Rhomberg also serves as a consultant on endocrine disrupters to the American Chemistry Council, an association of chemical manufacturers. Vom Saal and his colleagues counter that this is precisely the type of systematic evidence they can now provide, thanks to a boom in endocrine-disrupter research. The most comprehensive review yet of the field 1 , published in March, included more than 600 studies \u2014 almost half of them published within the past five years \u2014 and found credible evidence of non-monotonic responses with low-dose health effects in 18 endocrine disrupters, including BPA, atrazine and vinclozolin. \u201cWe kept hearing from our critics that there aren't enough examples to prove this phenomenon is real, so we took that as a challenge,\u201d says Laura Vandenberg, a postdoctoral fellow at Tufts University in Medford, Massachusetts, and the lead author of the review. Government officials in Europe and the United States are paying attention. \u201cI find the Vandenberg review to be quite compelling and quite convincing,\u201d says Linda Birnbaum, director of the US National Institute of Environmental Health Sciences (NIEHS) in Research Triangle Park, North Carolina. In an April editorial in the NIEHS-published journal  Environmental Health Perspectives , Birnbaum argued that \u201cit is time to start the conversation\u201d about incorporating low doses and non-monotonic relationships into regulatory decisions 2 . At a European Commission scientific conference on endocrine disrupters this June in Brussels, delegates failed to reach a consensus on the importance of non-monotonicity at low doses but they did agree that existing regulations need to be stricter, according to Bj\u00f6rn Hansen, who heads the chemicals unit at the commission's Directorate-General for Environment in Brussels. In the United States, meanwhile, the Environmental Protection Agency (EPA) and the Food and Drug Administration (FDA) are showing a new willingness to at least discuss the issue \u2014 although they say that major regulatory revisions are not on the table for now. Big changes are unlikely, some observers suggest, as long as the field remains so polarized. \u201cThere is a very large divide out there between the risk assessors and the endocrine scientists,\u201d says Thomas Neltner, who studies chemical food additives at the non-profit Pew Health Group in Washington DC, which has been trying to arrange a rapprochement through a series of scientific meetings. \u201cOur feeling is that the two sides have been talking past each other.\u201d \n               Early signs \n             For as long as there has been controversy over the effects of endocrine disrupters, vom Saal has been at the centre of it. Lean and intense, the 67-year-old native New Yorker is an amateur pilot who flies his Cessna to scientific conferences and is not shy about tangling with his critics wherever he lands. As a postdoctoral fellow at the University of Texas at Austin in the 1970s, vom Saal was startled to discover that subtle variations in sex-hormone levels in the womb could have life-long effects on mice. A female mouse positioned between two males in the uterus would later, as an adult, display significantly more 'masculine' characteristics, such as aggression, than would a female surrounded prenatally by other females, vom Saal found 3 . The apparent cause: a minuscule amount of extra testosterone released by the neighbouring male fetuses. Experimenting first with natural hormones and the synthetic oestrogen diethylstilbestrol (DES), vom Saal found that male mice exposed prenatally to very low levels of DES developed heavier prostates than unexposed mice \u2014 making them more vulnerable later in life to prostate disease, including cancer. Strangely, however, he found that higher doses of DES did not trigger the same effect 4 . It was one of the first non-monotonic dose-response curves mapped for an endocrine disrupter. Since then, vom Saal and his Missouri colleague Wade Welshons have identified similar non-monotonic responses from a variety of endocrine disrupters, most notably BPA 5 , a ubiquitous ingredient of polycarbonate plastics and epoxy coatings, including in food packaging.  If we're going to take this seriously, we need to have some evidence of a real phenomenon.  Vom Saal's early work helped to generate a torrent of international interest in BPA, including an ultimately successful campaign by activists in the United States, Canada and some European countries to halt its use in baby bottles and toddlers' sippy cups. It also helped to inspire a legion of researchers to look for \u2014 and often find \u2014 other endocrine-related effects in animals exposed to very low levels of BPA and other hormone mimics. At Tufts, for example, cell biologist Ana Soto won notoriety for discovering that early exposure to BPA can alter the development of mammary glands in mice and rats, spurring the growth of oestrogen receptors and leading to precancerous growths and non-invasive cancers 6 . In Spain, another cell biologist, Angel Nadal of Miguel Hern\u00e1ndez University in Elche, exposed human pancreatic cells to BPA and mapped non-monotonic relationships between dose levels and altered glucose metabolism, a key risk factor for diabetes and obesity 7 . Epidemiologists jumped into the fray, too. They found associations between urine BPA levels and obesity in children 8 , and linked other endocrine disrupters to incidence of diabetes 9 . Their studies, and many others, depict a weird world of endocrine disruption that is as different from traditional toxicology as quantum mechanics is from the staid clockwork of Newtonian physics. When even minuscule quantities of BPA and other disrupters interact with hormone receptors at crucial moments in development \u2014 activating, jamming, hijacking or otherwise messing with their normal function \u2014 they can give rise to strange-looking experimental results, especially when other hormones are thrown into the mix. At the University of Illinois at Chicago, for example, reproductive physiologist Gail Prins implants prostate-like glands, grown from human stem cells and mixed with mouse tissue, into young mice, and then feeds some of them very low doses of BPA. As the mice age, Prins also gives them low doses of oestradiol, a naturally occurring hormone that becomes more potent in human males as they age and is a known risk factor for prostate cancer. Between 35% and 40% of the mice fed BPA plus oestradiol have developed prostate cancer, compared with 10% of the mice that were given oestradiol only. Her working theory is that BPA binds with oestrogen receptors in prostate stem cells, reprogramming genes in ways that leave the cells more sensitive to oestradiol later on. \u201cWhat's remarkable,\u201d she says, \u201cis that we're working with very low doses that are definitely within the range of normal human exposure.\u201d She plans to publish her results in early 2013, as soon as she has collected more data. The interplay of these types of receptor mechanisms can generate bizarre dose-response relationships, many of which are still being mapped out. Earlier this month, vom Saal's group at Missouri published the first full non-monotonic dose-response curve for the widely used plastics ingredient known as DEHP, or di(2-ethylhexyl) phthalate 10 . The Missouri team subjected 78 pregnant mice to an extremely wide range of DEHP doses \u2014 from 0.5 micrograms per kilogram of body weight per day all the way up to 500,000 micrograms. They found that the animals' testosterone levels rose or fell in surprising ways, altering sexual development depending on the dose received. For male offspring, for example, the dose-response curve looked something like the profile of a craggy mountain. Serum levels of testosterone rose between the 0 and 0.5 microgram dose levels, then fell slightly at 1, rose again through 5 and 500 before declining again at 50,000 and plunging at the 500,000-microgram dose level. The highest dose, in fact, was virtually identical to the results for unexposed controls. Seeking to deflect another potential line of attack from his critics, vom Saal conducted a 'goodness of fit' statistical analysis confirming that a non-monotonic curve best fits his data. The biochemical mechanism behind the strange DEHP curve is unknown \u2014 vom Saal says that it awaits further study \u2014 but researchers have worked out the specific causes of other non-monotonic curves. One of the best understood examples involves not a pollutant, but a drug: the chemotherapy agent tamoxifen, which binds to oestrogen receptors in breast cells and has a dose-response curve shaped like an upside-down U. Very low doses have little effect on cancer cells, but as the drug builds up in breast tissue it actually stimulates tumour growth, triggering a painful 'flare' period for patients. When tamoxifen levels grow high enough to occupy most of the available oestrogen receptors, the effect reverses and the drug begins to inhibit the cancer cells' growth. \u201cAll of this is very well known to endocrinologists,\u201d says Thomas Zoeller of the University of Massachusetts Amherst, who studies the effects of endocrine disrupters on the thyroid. \u201cNon-monotonic dose-response is a fact of life.\u201d A turning point was a 2009 scientific statement by the Endocrine Society in Chevy Chase, Maryland, the first in its 95-year history. It called endocrine disrupters a \u201csignificant concern to public health\u201d; endorsed stricter regulations; acknowledged non-monotonic responses; and declared that \u201ceven infinitesimally low levels of exposure \u2014 indeed, any level of exposure at all \u2014 may cause endocrine or reproductive abnormalities\u201d 11 . Seven other scientific bodies then joined the Endocrine Society in a letter of concern published last year in  Science 12 . \u201cThat's as mainstream as you can get. It really changed the nature of the game,\u201d says another long-time researcher in the field, molecular biologist Bruce Blumberg of the University of California, Irvine. \n               Put to the test \n             Critics, however, say that the mere existence of non-monotonic responses and low-dose effects is not the point. What matters is the extent of the health concerns they raise. \u201cThere is non-monotonicity, but the question is, is it toxicologically relevant?\u201d asks Jason Aungst, a supervisory toxicologist with the FDA's Center for Food Safety and Applied Nutrition in Silver Spring, Maryland. He and a senior toxicologist at the EPA, Earl Gray, argue that the low-dose health effects identified in studies by vom Saal, Soto and others are still relatively rare and have not been conclusively linked to major health problems. Low-dose effects that are more clearly harmful, such as organ deformities, are usually monotonic, and can be identified under current regulatory testing protocols, according to Gray. \u201cYou could never say that non-monotonicity doesn't happen, but as far as its relevance to risk assessment, we really haven't seen it in the high-quality studies,\u201d he says. The schism in the field is in part a result of the different types of tests that academic researchers and risk assessors carry out. Many of the private testing labs hired by manufacturers seeking regulatory approval for new products are not equipped to do the radioimmunoassay analyses required to measure extremely low chemical concentrations. Nor do private labs typically look for the complex biochemical changes, such as alterations in protein levels, that are now part of the standard tool kit of researchers such as Zoeller, Soto and vom Saal. Instead, agency-mandated guideline tests are standardized; involve simpler assays that are easier to replicate; use higher numbers of test animals; and generally seek to identify more obvious health problems, such as acute toxicity, cancer and physical deformities. \u201cWe do validated studies, the basic researchers don't,\u201d says Rochelle Tyl, a developmental toxicologist at RTI International, a firm in Research Triangle Park that conducts research for clients such as regulatory agencies and chemical manufacturers. \u201cThat doesn't mean they're wrong, it just means they're doing work that hasn't been validated.\u201d  Low doses of endocrine disrupters act in ways that are totally unpredicted by the traditional approaches of toxicology.  Yet even when government and industry-hired scientists look for low-dose effects, they often don't find them. For example, Tyl 13  (who conducted her studies for two industry groups) and Gray 14  have each tested BPA at very low doses without finding the potent developmental effects identified by vom Saal, Prins and others. Vom Saal and his allies counter that the Tyl and Gray studies were insensitive to low-dose effects because their positive-control animals, which were given oestradiol alone, received doses that were much too high. The dispute has been harsh and public, playing out at conferences and in a seemingly endless series of sharply worded journal articles, rebuttals, counter-rebuttals and counter-counter-rebuttals. The arguments became so heated that Tyl stopped doing BPA work. \u201cI gave up BPA when it ceased to be scientific and became personal,\u201d she says. \u201cIt became flag-waving and it became political.\u201d Largely because of the Tyl and Gray studies, neither the FDA nor the EPA have altered their risk assessments for BPA. The FDA still says that BPA has no adverse effects at levels below 50 milligrams per kilogram of body weight per day \u2014 a level that vom Saal contends should actually be two million times lower, at 25 nanograms. Both agencies, however, are now cooperating on a much larger study designed to settle the dispute. The newly launched US$20-million study, led by the NIEHS and the FDA's National Center for Toxicological Research, is the most ambitious effort ever to look for non-monotonic dose-response curves that include very low doses. Last month, researchers began hand-feeding BPA to about a thousand rats at five dose levels ranging from 2.5 micrograms per kilogram of body weight up to 25,000 micrograms, plus two positive-control groups (which received much lower oestradiol doses than either Tyl or Gray used) and an unexposed control group. Vom Saal, Zoeller and other academics will be participating in the tissue analysis, allowing them to look for an array of health effects, such as metabolic changes in the prostate and mammary glands, that go well beyond those in standard regulatory protocols. But with the results of the BPA mega-study not expected for at least five years, a major rewriting of chemical regulations to take non-monotonic low-dose effects into account still seems distant. The European Commission has to meet a self-imposed deadline of December 2013 to draft the first governmental criteria defining endocrine disruption, but without a scientific consensus on the issue the criteria may end up addressing only high-dose effects, predicts Andreas Kortenkamp, a toxicologist at Brunel University in Uxbridge, UK, who has been advising the European Commission. In the United States, meanwhile, the EPA and FDA have convened a joint working group to review the evidence accumulating in the peer-reviewed literature, but \u201cnot only is the jury still out, the jury hasn't even had a chance to look at the evidence yet\u201d, says Rita Schoeny, a senior science adviser at the EPA in Washington DC. Some veterans of the field have decided not to wait, and are collaborating on what amounts to an effort to bypass the regulatory system. They have written a paper 15 , scheduled to be published in January in the journal  Green Chemistry , that gives industrial chemists detailed advice on how to screen newly synthesized compounds for endocrine-related effects, how to test at very low doses and how to look for non-monotonic dose-response curves. The paper, and a companion website, are aimed at trying to head off potentially harmful endocrine disrupters before they reach the marketplace. An ancillary benefit, vom Saal hopes, will be to increase the pressure on regulatory agencies to curb exposures to compounds already on the market. \u201cWe're saying that if you care about developing a safe chemical, here's what you should do,\u201d says vom Saal. \u201cWho could argue with that?\u201d \n                     US opts not to ban BPA in canned foods 2012-Apr-01 \n                   \n                     Prehistoric proteins: Raising the dead 2012-Mar-21 \n                   \n                     Toxicology: The big test for bisphenol A 2010-Apr-21 \n                   \n                     National Institute of Environmental Health Sciences \n                   \n                     National Toxicology Program \n                   \n                     Environmental Protection Agency \n                   Reprints and Permissions"},
{"file_id": "491024a", "url": "https://www.nature.com/articles/491024a", "year": 2012, "authors": [{"name": "Shanta Barley"}], "parsed_as_year": "2006_or_before", "body": "An impoverished African nation was making promising strides in medicine \u2014 before the government clamped down on its foreign partnerships. Early this year, Eritrea severed a scientific lifeline almost as old as the African nation itself. The Eritrean National Health Laboratory in Asmara cut long-standing ties with Washington University School of Medicine in St Louis, Missouri, potentially setting back many gains that the country had made in public health. \u201cSt Louis supplied everything: American doctors, expertise, chemicals, materials,\u201d says Assefaw Ghebrekidan, an Eritrean ex-freedom fighter who now heads the public-health programme at Touro University in Mare Island, California. \u201cAnd now it's all over.\u201d Eritrea, an impoverished country of 3 million people on the Horn of Africa (see 'A troubled corner'), is not known for its science. It ranks 177th out of 187 countries on the United Nations Human Development Index. It comes in last in terms of press freedom and is the eighth most militarized country in the world. The World Health Organization estimated that there were just 5 medical doctors per 100,000 people in the country in 2004. But against this depressing backdrop, the country's medical-research partnerships have been a source of promise and pride. Eritrea built its first medical school in 2003, aided by scientists from the Central University of Las Villas in Santa Clara, Cuba. After US universities helped to establish postgraduate training and research programmes in paediatrics, surgery, and obstetrics and gynaecology at the institution, Eritrean medical scientists published their first papers in international, peer-reviewed journals. Public health has benefitted. In 1991, Eritrea was cursed with the highest maternal mortality rate in the world \u2014 14 deaths per 1,000 births. In 2010, it was on track to meet the Millennium Development Goal of cutting that rate by 75% by 2015. But progress in Eritrean science has now gone into reverse, say a number of scientists and doctors in exile. In response to mounting criticism from the United Nations and the United States over the country's human-rights record, Eritrean President Isaias Afwerki is severing partnerships with all US universities, says Ghebrekidan. \u201cEverything that Eritrea has worked so hard to achieve is at stake.\u201d Jon Abbink, an anthropologist at the Free University of Amsterdam, says that these actions will have widespread negative effects, \u201cin the education system, in the constant 'brain drain' of educated people to greener and freer pastures, and in the inhibition of international scientific cooperation\u201d. Eritrea, he says, is one of the few remaining countries in Africa that have failed to embrace scientific freedom. \u201cIt's out of sync with global trends,\u201d says Abbink. Eritrea was once a colony of Italy, but the United Nations handed it over to Ethiopia after the Second World War. In 1961, Eritrea started to fight for its independence in a war that would last three decades: the United States supplied Ethiopia with guns and money, but the rebels, led by Afwerki and the Eritrean People's Liberation Front (EPLF), persevered. The liberation movement had remarkable credentials. \u201cIt was led by 29 doctors of medicine,\u201d says Ghebrekidan, who was head of the EPLF's medical services. \u201cNo other rebel movement has ever had so many intellectuals.\u201d Even Afwerki had abandoned a degree in engineering to lead the fight. Another academic, Melles Seyoum, was working as a pharmacist at an Ethiopian hospital when the war broke out. He coolly stole US$140,000 worth of antibiotics, microscopes, surgical blades and stethoscopes and delivered them to Eritrean freedom fighters, wrote journalist Michela Wrong in her book  I Didn't Do It For You  (HarperCollins, 2005). Seyoum became an integral member of the EPLF, teaching soldiers how to test blood and prepare Petri dishes in a hospital 5 kilometres long and dug into the side of a rocky valley \u2014 a clinic known as 'the longest hospital in the world'. After a visit in 1987, a British doctor wrote 1  about the impressive standards of care at the hospital: a 1-tonne machine manufactured antibiotics every day; a doctor performed facial reconstructions; and amputees played basketball. \n               Power struggle \n             In 1993, after the war ended and Eritrea gained independence, Afwerki was elected president by a national assembly largely composed of former members of his rebel army. He promised that within four years, Eritrea would have parliamentary and presidential elections, press laws and a new constitution. Seyoum enthusiastically backed Afwerki and was, in return, appointed director of the prestigious National Health Laboratory, which performed most of the country's clinical testing and worked on developing treatments for disease. But following a failed assassination attempt in 1996, the president postponed elections indefinitely and refused to implement the constitution that had been drafted. In 1998, he invaded Ethiopia, triggering a humiliating two-year war that caused the deaths of more than 60,000 Eritreans and a temporary loss of one-quarter of Eritrean territory. Afwerki's popularity plummeted, and many of the academics who had helped to rebuild the country moved abroad. On 3 October 2000, some of them decided to use their friendship with Afwerki to persuade him to hold elections or step down. From a conference hotel in Berlin, Ghebrekidan and 12 other scientists and professionals, many of whom had been involved in drafting the constitution, composed a letter to the president. \u201cMuch of the world community, including our fellow Africans, perceive the Eritrean government and its leadership as aggressive and irresponsible,\u201d wrote the group, urging Afwerki to implement the constitution, hold democratic elections and set free the growing number of people his regime had jailed. \u201cWe urge you most sincerely to seize this moment of crisis and turn it into an opportunity to reclaim your hard-earned reputation as a leader.\u201d Four days later, after it had reached Afwerki, the letter was leaked to the press, igniting Eritrea's first-ever public debate about leadership. To its members' surprise, the group \u2014 which became known as the G-13 \u2014 was invited to Eritrea for discussions with Afwerki. One member, Mohammed Kheir, later wrote that he was nervous that it might be a trap. But they accepted the invitation and flew to Eritrea. After waiting for several days, the president agreed to see them. Soldiers escorted the academics to his office, where Afwerki berated them for leaking the letter to the media \u2014 something that they denied \u2014 and cast them as traitors. The group was escorted back to the airport. Since then, no members have returned to Eritrea; most now hold prestigious positions at US universities. \u201cIt is very fortunate that we escaped,\u201d says Haile Debas, now head of the University of California Global Health Institute in San Francisco. Although the plea failed to sway the president, it encouraged others to criticize him openly for the first time. In July 2001, Semere Kesete, leader of the student union at the University of Asmara \u2014 Eritrea's only institute of higher learning \u2014 criticized the government for reducing academic freedom. He was arrested and thrown into solitary confinement, causing riots at the university. When the government demanded that the students do extra national service \u2014 on top of the 18 months required of all men and women \u2014 they didn't turn up. In retaliation, the government bussed all of the students to the Danakil Depression in southern Eritrea, one of the hottest places on Earth, to build roads. Two students died from the heat. \n               Crackdown \n             A month later, Afwerki launched his biggest crackdown yet. He shut down all private media, threw 10 journalists in jail and imprisoned 11 politicians who had demanded elections \u2014 many of whom were old comrades in arms. He also began to dismantle the University of Asmara. \u201cWhat could be the justification for killing the only university we had capable of producing students that could be accepted by universities abroad?\u201d asks an Eritrean scientist who lives out of the country and wishes to remain anonymous because of concerns about the safety of family members still in Eritrea. \u201cThe aim was simply to prevent the students from all being in one place, where they had the power to rise up,\u201d says Debas. In place of the university, the government built a number of small colleges, arguing that these would be more accessible to students. Even as Eritrea lost its only university, it continued to make progress in medicine. In 1997, the country had gained a proactive health minister, Saleh Meki, who helped to develop crucial partnerships with US universities including George Washington University in Washington DC; Washington University in St Louis; Columbia University in New York City; Stony Brook University in New York; and the University of California, Berkeley. By bringing experts into Eritrea, these partnerships helped the country to pass scientific and public-health milestones. A polio-immunization campaign extended coverage to 95% of all one-year-olds and eradicated the disease. An anti-malaria drive from 2000 to 2004 reduced morbidity and case fatality by 84% and 40%, respectively. In 2003, Haile Mezgebe, then a surgeon at George Washington University, was part of the group of medics who helped to set up the Orotta School of Medicine in Eritrea. Mezgebe moved to the country to run the collaboration; he was joined by Mary Polan, who travelled regularly from the department of obstetrics and gynaecology at Columbia University, and other US doctors and surgeons who worked to treat and train Eritreans. In 2009, Orotta graduated its first class of 39 doctors. \u201cIt was quite extraordinary,\u201d says Jack Ladenson, a doctor based at Washington University. \u201cSuddenly, in one day, there was a 30% increase in the number of doctors in Eritrea.\u201d \n               Success story \n             Meanwhile, clinical testing and research was taking off at the National Health Laboratory. In 1998, the only blood tests available in Eritrea had been done on a single machine. Scientists from Washington University installed new equipment at the lab and trained technicians to perform a range of chemical tests, including the haemoglobin A 1 C test for diabetes and a test for thyroid malfunction. They also launched a national diabetes-management programme and a long-term research project to gauge its progress; in 2007, the project leaders found 2  that the programme had significantly improved Eritrean diabetes management. Ladenson, Seyoum and others co-authored a paper 3  showing that the overall quality of chemical tests for disease at the national lab was on a par with that at Washington University. \u201cA simple but sustainable national laboratory system has been established in the developing nation of Eritrea,\u201d the paper said. But outside the medical arena, the situation was less rosy. Richard Reid, a historian at the School of Oriental and African Studies in London, visited the Eritrea Institute of Technology in Mai Nefhi, one of the unaccredited colleges set up after the University of Asmara was shut down. He was told that students who cheated on exams or skipped classes were jailed on site. Military training was mandatory between 4 and 7 a.m., and students wryly referred to digging trenches as 'digology', adds Reid. And any success in science and medicine was short lived. In 2008, without explanation, Meki was removed as health minister, along with the coordinator for US\u2013Eritrean scientific partnerships. The chair of the paediatrics department at Orotta was arrested because of his religious views. And in 2011, Afwerki ordered all scientists from George Washington University \u2014 including Mezgebe \u2014 to leave the country. At the start of 2012, Afwerki cut off the partnership between the National Laboratory and Washington University in St Louis. Several sources, who wish to remain anonymous for fear of retaliation against friends and relatives, report that Seyoum, the lab's director, was \u201cfrozen\u201d, an Eritrean term for the practice of stripping government employees of their titles and duties while restricting them from travel and other jobs to silence them.  Nature  contacted officials in the Eritrean government and its US and UK embassies repeatedly by phone and e-mail for a response to these allegations, but had received none at the time of going to press. The severing of ties may be a backlash against the United States and the United Nations over their criticism of Afwerki's human-rights record, says Ghebrekidan. In 2009, the United States imposed sanctions on Eritrea for supporting Islamist insurgents in Somalia. A highly publicized cable from US ambassador Ronald McMullen, later released by Wikileaks, said that \u201cEritrea's prisons are overflowing, and the country's unhinged dictator remains cruel and defiant\u201d. In July, the UN Human Rights Council established a special rapporteur to investigate reports of rights violations by Eritrean authorities, amid stories that Afwerki keeps his critics in solitary confinement in shipping containers. Berhane Ghebrehiwet, an Eritrean immunologist at Stony Brook University, says that Afwerki's distrust of foreign involvement and aid in Eritrea is understandable. The United States did, after all, support Ethiopia during the fight for independence. \u201cYou cannot cripple a man and then accuse him of having limped,\u201d he says. \u201cAll the president dreams of is to make Eritrea a prosperous and self-reliant nation at peace with itself, its neighbours and the rest of the world.\u201d Others are less sympathetic. \u201cAfwerki is getting more and more paranoid,\u201d says Ghebrekidan. \u201cHe thinks that the American doctors who come to save Eritrean lives are actually CIA agents.\u201d Afwerki has effectively destroyed intellectual freedom in Eritrea, says Abbink. \u201cNo independent academic research in any field is possible.\u201d Fundamental research \u201cor what is left of it\u201d is now under pressure to pursue \u201cpractical\u201d issues with immediate applications to development, he concludes. Yet some scientists are still proud of the progress Eritrea has made. Andemariam Gebremichael, dean of the Orotta School of Medicine, wrote in an e-mail that he aims to create \u201can environment where individuals develop their intellectual potential\u201d, adding that he hopes to produce another 150 doctors to bring the country up to international standards. It will be a significant challenge, writes Gebremichael. Only seven foreign teaching doctors \u2014 all Cuban \u2014 remain at the institution. After a year in solitary confinement, student-union leader Kesete escaped with his guard to Ethiopia, and from there to the United States. \u201cWe walked for six days and nights, surviving on nothing more than biscuits,\u201d he says. Kesete sees little prospect of change, and despairs of his country's future. \u201cThe government has persecuted not only scientists, but also the science itself,\u201d he says. He calls international collaborations a \u201cwaste of resources and energy\u201d, because Afwerki will not hesitate to eject foreign scientists, no matter how crucial they are to Eritrea's development. Rumours that the University of Asmara may reopen this year are preposterous, he adds. \u201cIt is safe to say that academia is dead.\u201d \n                 See Editorial \n                 p.8 \n               \n                     The Arab Spring offers hope but no quick fix 2011-Aug-31 \n                   \n                     Security focus hinders progress in Arab world 2011-Feb-10 \n                   \n                     Ethiopia launches first science academy 2010-Apr-09 \n                   \n                     Free at last 2007-Aug-01 \n                   \n                     Assefaw Ghebrekidan \n                   \n                     Partnership for Eritrea at George Washington University \n                   \n                     Eritrean ministry of information \n                   \n                     Eritrea in the CIA World Factbook \n                   Reprints and Permissions"},
{"file_id": "491027a", "url": "https://www.nature.com/articles/491027a", "year": 2012, "authors": [{"name": "Brian Owens"}], "parsed_as_year": "2006_or_before", "body": "Sequencing DNA from individual cells is changing the way that researchers think of humans as a whole. All Nicholas Navin needed was one cell \u2014 the issue was how to get it. It was 2010, and the postdoctoral fellow at Cold Spring Harbor Laboratory in New York was exploring the genetic changes that drive breast cancer. Most of the cancer-genome studies before then had ground up bits of tumour tissue and sequenced the DNA en masse, giving a consensus picture of the cancer\u2019s genome. But Navin wanted to work out the sequence from individual cells to see how they had mutated and diverged as the cancer grew. He ran into trouble almost immediately. \u201cCells like to stick together,\u201d he says. He tried the most advanced microdissection techniques, which use robots to peel cells apart or suck them into the tips of hair-thin glass pipettes. But he could never be sure that asecond cell hadn\u2019t come along for the ride. Eventually, he settled on using chemicals to dissolve the cell\u2019s outer membrane and release the dense nucleus. Then he separated out the nucleus using an automated cell sorter, and extracted its DNA. He repeated the process for around 100 cells, and the sequences he obtained revealed how the tumour had evolved from a few rogue cells into a complex m\u00e9lange of genetically distinct ones 1 . The ability to sequence 100 human cancer genomes was unthinkable a decade ago, and it is still a remarkable feat. Technology has moved apace, dramatically reducing costs and making genome sequencing fairly routine. But most human genomes, cancer or otherwise, are still sequenced from DNA extracted from multiple cells, which misses differences between cells that could be crucial in controlling gene expression, cell behaviour and drug response. \u201cPeople are becoming very interested in what is the variation from cell to cell,\u201d says Navin, now at the University of Texas MD Anderson Cancer Center in Houston. Last month, the US National Institutes of Health (NIH) announced that it would be funding single-cell studies, including genome sequencing, to the tune of US$90 million over 5 years. But challenges abound. Amplifying the tiny amount of DNA in a single cell until there is enough to sequence without introducing too many errors is still difficult (see \u2018One genome from many\u2019). The bioinformatics required to stitch the data together and deal with artefacts can be fiendishly complicated. And, as Navin found, even isolating a cell can be tough. For this reason, several research groups have started with cells that are easily separated, such as sperm, or those that are likely to have dramatic genomic differences, such as tumour cells. But as the techniques are refined, scientists hope to work out ever more subtle differences between cells, such as the tiny genomic rearrangements that happen in many neurons and may serve a purpose in organizing information flow. One of the most startling facets of such research is not the differences between cells, but how tissues and organs manage to work coherently despite them. To get a handle on these issues, it makes sense to start at the smallest possible unit. \u201cThe cell is kind of the ultimate denomination of an organism,\u201d Navin says. \n               Tumour diversity \n             In his first effort with breast-cancer tumours 1 , Navin was able to sequence only about 10% of the DNA\u00a0\u2014\u00a0not enough to see individual point mutations, but good enough to study larger segments that are commonly duplicated or deleted, called copy number variants. The results suggested that the tumour was made up of three major populations of cells, which emerged from the root tumour population in leaps and spurts at different times during the tumour\u2019s growth. \u201cIt suggested a model of evolution where, instead of having lots of gradual intermediates, we saw hundreds of chromosomal rearrangements that occurred probably in very short periods of evolutionary time,\u201d he says. Since moving to Texas, Navin has started a research group focused entirely on single-cell genomics. He has been improving his methods, and can now piece together up to 90% of a cell\u2019s genome, he says, which allows him to study the mutations in individual cancer cells in much more detail. The team has also looked at another type of breast cancer. Sequencing the tumour as a whole, the group found six mutations in cancer-associated genes. \u201cIt seemed like a very simple genome,\u201d says Navin. But when his group sequenced four individual cells they identified \u201chundreds of additional mutations, many of which where unique or \u2018private\u2019 to that individual cell\u201d. In addition to tumours, his group has studied a breast-cancer cell line that has been maintained in the laboratory. The cells in such lines might be expected to contain identical genomes, but in data that have not yet been published, the team found that about 1% of the mutations, involving 12,000\u201320,000 base pairs, differed from cell to cell and that these variations could not be detected when the cells were sequenced together. In both studies, many of the new-found mutations were in cancer genes, or in other regions expected to disrupt protein function. \u201cNicholas\u2019s work was very nice,\u201d says Timour Baslan, a graduate student studying cancer genetics at Cold Spring Harbour Laboratory and a former colleague of Navin\u2019s in Michael Wigler\u2019s lab. \u201cIt was very informative, but it was extremely expensive\u201d \u2014 $1,000 or more per cell. Baslan and his colleagues are trying to bring down the cost. They add genetic barcodes\u00a0\u2014\u00a0short, easily traceable strands of DNA\u00a0\u2014\u00a0to a cell\u2019s DNA, which allows them to sequence cell genomes en masse then identify the sequences from individual cells. Use of the barcodes, in combination with improved bioinformatics approaches, brings the cost of a genome down to about $60 per cell. At that price, more researchers can work with the number of cells necessary to dissect a tumour-cell population as it proliferates and evolves. \u201cNow we\u2019re doing hundreds and we\u2019re thinking in the future we\u2019ll be able to do thousands,\u201d says Baslan. Baslan\u2019s group is using the techniques to study which tumour cells are left behind after chemotherapy treatment and why those cells were resistant to the drugs. Such analysis could guide treatment, says Navin. \u201cBy sequencing a few single cells you can get an idea of the heterogeneity in a tumour before chemotherapy and that might affect your choice of which agent to use, or whether to subject the patient to chemotherapy at all,\u201d he says. \n               Every sperm is sacred \n             The tendency of sperm to swim alone makes the cells ideal for single-cell genomics. Adam Auton, a statistical geneticist at Albert Einstein College of Medicine in New York is using sperm to study recombination, the process that shuffles genes during the formation of germ cells and therefore influences which genes are inherited. \u201cRecombination is one of the fundamental forces that shapes genetic diversity,\u201d he says. \u201cIn recent years we\u2019ve learned that there is considerable variation in the recombination rate between different populations, between the sexes and even between individuals.\u201d But pinning down the rate in people once seemed impossible because it would have required finding individuals with hundreds of children and sequencing their genomes. The ability to sequence single cells meant that researchers could take another approach. Working with a team at the Chinese sequencing powerhouse BGI, Auton sequenced nearly 200 sperm cells and was able to estimate the recombination rate for the man who had donated them. The work is not yet published, but Auton says that the group found an average of 24.5 recombination events per sperm cell, which is in line with estimates from indirect experiments 2 . Stephen Quake, a bioengineer at Stanford University in California, has performed similar experiments in 100 sperm cells and identified several places in the genome in which recombination is more likely to occur. The location of these recombination \u2018hotspots\u2019 could help population biologists to map the position of genetic variants associated with disease. Quake also sequenced half a dozen of those 100 sperm in greater depth, and was able to determine the rate at which new mutations arise: about 30 mutations per billion bases per generation 3 , which is slightly higher than what others have found. \u201cIt\u2019s basically the population biology of a sperm sample,\u201d Quake says, and it will allow researchers to study meiosis and recombination in greater detail. Perhaps the most intriguing potential use of single-cell sequencing lies in neuroscience. Alysson Muotri, a neuro\u00adscientist at the University of California, San Diego, would like to study how long interspersed nuclear elements (LINEs) \u2014 \u2018jumping\u2019 genes that can move around the genome \u2014 cause each neuron to differ from its neighbours. His group has compared the number of LINEs in human brain, heart and liver tissue, and found that brain tissue contains significantly more jumping genes than the others 4 . Each human neuron probably has between 80 and 300 unique insertions, he says, differences that could affect a person\u2019s susceptibility to neuro\u00adlogical disorders 5 , or provide the brain with a reservoir of diversity with which to respond to challenges. He says that it would be useful to sequence individual neurons and work out what effect this heterogeneity is having on brain function and even on personality. \u201cI think it\u2019s the next level of complexity,\u201d he says. \u201cWe look at the brain and we think about the tissue, but actually it seems like lots of tissues in one, because the cells are so heterogeneous. It\u2019s almost like every cell was there for a purpose.\u201d To make good on these plans, however, the techniques will need to improve further. Ramunas Stepanauskas, director of the Single Cell Genomics Center at the Bigelow Laboratory for Ocean Sciences in East Boothbay, Maine, says that the processes involved will continue to be integrated and miniaturized, until eventually they will form an off-the-shelf technology that involves just the press of a button \u2014 although he cautions that this is still many years off. In the meantime, his centre offers single-cell sequencing for labs that lack the necessary equipment and expertise to do it themselves. The US Department of Energy\u2019s Joint Genome Institute in Walnut Creek, California, offers a similar service. With its new funding for single-cell studies, the NIH is attempting to spur innovation in the field. So is Life Technologies, a sequencing company based in Carlsbad, California, which is offering a $1\u00a0million prize to the first researchers who can sequence the whole genome and all the RNA in a single human cancer cell using the company\u2019s technology. The deadline for the challenge is the end of this year, and the company says that there has been an enthusiastic response. Baslan, for one, is intent on breaking down tissues into their components. \u201cEvery time we look at our data we discover something new,\u201d he says. \u201cThere\u2019s just so much analysis to be done that it\u2019s quite daunting.\u201d Reprints and Permissions"},
{"file_id": "490466a", "url": "https://www.nature.com/articles/490466a", "year": 2012, "authors": [{"name": "Lizzie Buchen"}], "parsed_as_year": "2006_or_before", "body": "From genes to hormone levels, biology may help to shape political behaviour. A popular political advertisement from early this summer begins with US President Barack Obama addressing a crowd of moon-eyed supporters. Suddenly, the screen goes dark to a crescendo of minor chords. Phrases such as \u201cFear and Loathing\u201d, \u201cNauseating\u201d and \u201cDivide and Conquer\u201d flash onto the screen, along with video clips of commentators complaining that Obama has used scare tactics to manipulate voters. In the final scene, the iconic poster from Obama's 2008 election campaign appears, the word HOPE transforming into FEAR as it bursts into flames. The advertisement, produced by the conservative organization American Crossroads in Washington DC, is typical of those that have come to dominate the US airwaves and YouTube in preparation for next month's presidential election. Emerging from both the right and the left, these commercials increasingly resemble horror films as they seek to sway voters by triggering basic emotions such as fear, anger and disgust. That strategy fits with emerging scientific evidence about how people acquire their political beliefs. In the past, political scientists agreed that social forces \u2014 most importantly, parents and the childhood environment \u2014 strongly influenced whether people became conservative or liberal, and whether they voted or engaged in politics at all. \u201cWe now know that it is probably not the whole story,\u201d says John Jost, a psychologist at New York University. An increasing number of studies suggest that biology can exert a significant influence on political beliefs and behaviours. Biological factors including genes, hormone levels and neurotransmitter systems may partly shape people's attitudes on political issues such as welfare, immigration, same-sex marriage and war. And shrewd politicians might be able to take advantage of those biological levers through clever advertisements aimed at voters' primal emotions. Many of the studies linking biology to politics remain controversial and unreplicated. But the overall body of evidence is growing and might alter how people think about their own and others' political attitudes. \u201cPeople are proud of their political beliefs,\u201d says John Hibbing, a political scientist at the University of Nebraska\u2013Lincoln. \u201cWe tend to think they're the result of some rational responses to the world around us.\u201d But in fact, a combination of genes and early experiences may predispose people to perceive and respond to political issues in certain ways. Recognizing that could help the public and politicians to develop more respect for those with opposing viewpoints. \u201cI'd like to see people have a little less chutzpah about their political beliefs, and understand that some people experience the world differently,\u201d says Hibbing. \n               Innate ideology \n             The past few decades have seen a wave of research connecting genes to disorders such as schizophrenia, depression and alcoholism, and to complex outcomes such as sexual orientation and how far people progress in education. But until the past decade, this trend largely passed by the field of political science. Modern politics seemed too divorced from basic human biology, too recent an innovation in human evolutionary history, to be influenced by genetic material. In 1986, Nicholas Martin and his colleagues published a study 1  suggesting that genes could exert a pull on attitudes concerning topics such as abortion, immigration, the death penalty and pacifism. Martin, a geneticist now at the Queensland Institute of Medical Research in Brisbane, Australia, used a classic behavioural-genetics technique: comparing genetically identical twins with fraternal twins of the same sex (who share only 50% of genes on average). The identical twins had similar political beliefs more often than fraternal twins did. Because twins tend to grow up in the same family environments, Martin's team suggested that genes made the difference, and that they have a significant role in helping to shape attitudes on social issues. Although Martin's study had obvious implications for political science, researchers in that field ignored the work. The eugenics movement in the early part of the twentieth century and Nazi theories about the biology of human differences had made political scientists extremely wary about topics that examined genetic differences among people. The publication \u201cwas like a stone down a well\u201d, says Martin. \u201cThere was absolutely no reaction. It just lay there for 20 years.\u201d But in the early 2000s, Hibbing and John Alford, a political scientist at Rice University in Houston, Texas, learned about Martin's work. They reanalysed his data and incorporated similar data from a study 2  of attitudes among US twins. In 2005, Hibbing and Alford published 3  findings nearly identical to those earlier studies \u2014 showing strong correlations between genetics and political views. These finally caught the attention of political scientists. It wasn't the kind of attention that Alford and Hibbing were hoping for, however. \u201cThey thought we were crazy,\u201d says Hibbing. But a few researchers, mainly in the United States, were intrigued enough to follow up with further work. James Fowler, a political scientist at the University of California, San Diego, used the twin method to show 4  that voter turnout and political participation also had a genetic component. Peter Hatemi, a political scientist at Pennsylvania State University in University Park, found results similar to Alford and Hibbing's using twins from Australia, Denmark, Sweden and the United States, although the work has not yet been published. \n               Trouble with twins \n             The twin studies were far from definitive, in large part because such research cannot completely control for environmental factors. Compared with fraternal twins, genetically identical twins are more likely to have the same friends and to maintain regular contact as adults. Furthermore, parents, friends and teachers often treat identical twins more equally than fraternal twins. All of that makes it hard to unpack how much genes and environment each contribute to the shared political attitudes of identical twins. A few attempts have been made to tease apart the various influences. In one study 5 , Hatemi found that identical twins who do not spend much time together are still more concordant than are fraternal twins who do, suggesting that genetic factors do matter. But the twin studies continue to face strong opposition. \u201cI'm very sceptical about estimating heritability from twin studies,\u201d says Laura Stoker, a political scientist at the University of California, Berkeley. \u201cThe entire framework is built with a tonne of assumptions.\u201d  I would like to see people have a little less chutzpah about their political beliefs.  Twin studies also offer no insight into how the genome can nudge people to lean left or right on various political issues. For that, researchers have started exploring candidate genes. Genes involved with the olfactory system and the neurotransmitters glutamate, dopamine and serotonin have all been linked to behaviours such as voter turnout 6  and ideology 7 , although these findings have come under scrutiny and are yet to be independently replicated. Jeremy Freese, a sociologist at Northwestern University in Evanston, Illinois, says that such studies have found \u201cimplausibly large\u201d effects from individual genes. \u201cWhat's been revealed over the past few years is just how vulnerable the candidate-gene approach is,\u201d he says. Part of the problem, says Freese, is that studies linking specific genes to political behaviours have usually been published in political-science journals, rather than scientific journals, so editors and reviewers may not have picked up on some deficiencies in the studies. \u201cThe reviewers have not been familiar with the replication problems that exist,\u201d says Freese. Christopher Dawes, a political scientist at New York University, acknowledges complications in some of his own studies of specific genes and says that more illuminating results might come from molecular techniques such as genome-wide association studies, which scan the genomes of large numbers of people, looking for sequences linked to a behaviour or trait. But researchers in this area are only just beginning to use such resource-intensive strategies. \u201cWe're starting to better appreciate the limitations of the data and techniques,\u201d says Dawes. If other complex behaviours and traits are any indication, the answer is not going to be simple. Even for traits known to have a very large genetic component, such as height, the evidence points to the influence of thousands of genes, each applying a feather-light force. So it seems unlikely that a small number of genes can push someone towards being a liberal activist, a social conservative or a libertarian. Many researchers have come to the conclusion that it is premature to focus on the genetics of politics. \u201cIt doesn't make sense to go after the most difficult part of the puzzle,\u201d says Alford. An easier approach is to investigate the pathways that might connect genes with political behaviours and attitudes. One connection that has been suggested is personality. US conservatives may not seem to have much in common with Iraqi or Italian conservatives, but many political psychologists agree that political ideology can be narrowed down to one basic personality trait: openness to change. Liberals tend to be more accepting of social change than conservatives. Some studies 8  suggest that liberals tolerate more ambiguity and uncertainty, whereas conservatives are more decisive, conscientious and attracted to order. Theoretically, a person who is open to change might be more likely to favour gay marriage, immigration and other policies that alter society and are traditionally linked to liberal politics in the United States; personalities leaning towards order and the status quo might support a strong military force to protect a country, policies that clamp down on immigration and bans on same-sex marriage. But some researchers baulk at such simple links between personality and ideology. Evan Charney, a political scientist at Duke University in Durham, North Carolina, points out that conservatives sometimes embrace change, such as proposals in the United States to alter the tax code and welfare system. He also says that he and most people in his field are liberals \u2014 an imbalance that could bias how they interpret connections between personality and politics. \n               Visceral reactions \n             Some researchers have sought to move beyond personality studies to evaluate how participants' physiological reactions can influence how they interpret and respond to political issues. In 2008, Alford, Hibbing, Hatemi and others measured how people reacted to threatening images and sudden, loud noises 9 . People who blinked harder and showed heightened sensitivity \u2014 as gauged by their skin conductance \u2014 were more likely to favour gun rights, capital punishment and the war in Iraq than were those who showed less sensitivity.  If people spend most of their lives focusing on negative rather than positive, they're probably going to have a different way of experiencing the world.  In another study 10 , Hibbing showed subjects a series of emotionally charged images, including a spider on a man's face, a maggot-infested wound, a cute rabbit and a happy child. People who described themselves as conservatives tended to respond more strongly when looking at the negative images than at the positive images, whereas liberals reacted more to the positive pictures. Conservatives also stared at the negative images longer than liberals did, which Hibbing connects to the idea that conservatives are more likely to confront fearful or disgusting situations, making them more disposed to support a strong military and harsh sanctions for criminals. Some researchers are exploring whether hormone systems play a part in political attitudes. A few studies, for example, have looked at connections between people's prejudices and their levels of oxytocin \u2014 the feel-good hormone linked to empathy and bonding with loved ones. In one experiment 11 , Dutch participants who had taken puffs of oxytocin responded more favourably to Dutch people than to foreigners, suggesting a bias towards their own group. Hatemi and Rose McDermott, a political scientist at Brown University in Providence, Rhode Island, are currently investigating whether other hormones, such as testosterone and cortisol, have any connections with ideology. Many of the hormone studies done so far have come under attack, because they often rely on small samples and the reported effects are sometimes weak. Given the research so far, Hibbing remains \u201cagnostic\u201d about whether genes or environmental factors such as parental guidance influence political behaviour the most. Either way, he says, it is difficult to change someone's mind about political issues because their reactions are rooted in their physiology. \u201cIf people spend most of their lives focusing on negative rather than positive, they're probably going to have a different way of experiencing the world than those who do the opposite,\u201d says Hibbing. So people on the right are unlikely to be reached by arguments that seem rational to the left, or vice versa. But tapping into emotions might prove more successful. After the terrorist attacks in the United States on 11 September 2001, New Yorkers who had been directly exposed to the trauma of the events experienced a 'conservative shift', expressing views that were more patriotic, more supportive of the military and more religious than they had before 12 . Disgust, too, can shift attitudes. One study 13  suggested that people exhibit more conservative views when reminded of impurity \u2014 for example, by the proximity of a bottle of hand sanitizer, a sign reminding them to clean their hands or a foul smell. Does that mean that negative political adverts, designed to invoke fear and disgust, could actually change people's views? Alford says that these commercials are targeted more at mobilizing favourable voters \u2014 and demobilizing the opposition. \u201cPeople who run political campaigns know that it's all about turnout,\u201d says Alford. \u201cIt's not about changing hearts and minds; it's about changing who shows up on election day.\u201d Regardless of whether biology shapes political choice, it may affect a person's likelihood of voting in the first place. In an as-yet unpublished study, Hibbing has found that people with high levels of the stress hormone cortisol are much less likely to vote than are demographically similar people who have lower cortisol levels. Hibbing is currently working to find a way to ease voting for these 'stressed' people, perhaps through options such as postal voting. Alford says that the biggest impact of all this research may be to make political discourse more civil and accepting of differences. \u201cIt would be nice if political science made dinner tables a little more humane,\u201d he says. Reprints and Permissions"},
{"file_id": "490326a", "url": "https://www.nature.com/articles/490326a", "year": 2012, "authors": [{"name": "Richard Van Noorden"}], "parsed_as_year": "2006_or_before", "body": "The big picture of global migration shows that scientists usually follow the research money \u2014 but culture can skew this pattern. Husband-and-wife neuroscientists Yuh Nung Jan and Lily Jan have run their laboratory at the University of California, San Francisco, for more than three decades: time enough to see the geography of the science world change. When the Jans started hiring employees in the 1980s, they chose home-born scientists. Nine of their first eleven employees were American. But Yuh Nung and Lily\u00a0\u2014\u00a0who themselves arrived in the United States from Taiwan in the 1960s\u00a0\u2014\u00a0have increasingly drawn on talent from overseas. Today, researchers originally from China dominate the bench tops, with the lab hosting 16 Chinese scientists, 12 Americans, 2 Koreans and 1 researcher each from Canada, India, Singapore, Taiwan, Turkey and Germany. The Jans\u2019 story is not unusual. \u201cThere is a progressively wider geographical variety of graduate students and postdocs in most leading universities,\u201d Yuh Nung says. During the 1970s, for example, non-citizens claimed around one-quarter of the doctorates awarded in the United States in physical sciences, engineering, mathematics and computer science; but by 2010, their share had risen to more than half, according to the US National Science Foundation. In life sciences, the foreign share has risen from just under 20% to 30%. The United Kingdom, Germany and Australia have seen similar trends. By sifting through data, talking to experts and conducting our own survey of 2,300 readers around the world,  Nature  sought to identify underlying trends in scientists\u2019 movements, investigate what is driving them and explore how they may change. At stake is the shape of global science and the prospects for individual countries that hope to build up\u00a0\u2014\u00a0or preserve\u00a0\u2014\u00a0their research strength. It is plausible\u00a0\u2014\u00a0although hard to prove\u00a0\u2014\u00a0that highly productive research systems such as those in the United States and the United Kingdom have benefited from their openness to foreign scientists. To the Jans (who together won this year\u2019s US$500,000 Gruber prize for their discoveries in molecular neurobiology), the advantages are obvious. They believe that foreign researchers enrich the lab culturally as well as scientifically. Being able to draw on a global talent pool may also help to make up for weaknesses in the US science-education system. But some countries worry that they are losing their top researchers. Of the world\u2019s most highly cited scientists from 1981 to 2003, one in eight were born in developing countries, but 80% of those had since moved to developed countries (mostly the United States), according to a 2010 study by Bruce Weinberg at Ohio State University in Columbus. India, for example, loses out, says Binod Khadria, an economist who studies international mobility at Jawaharlal Nehru University in New Delhi. \u201cThe best and brightest are kept in other countries.\u201d All this underscores that science, which has always been a global culture, is now a global marketplace, and one in which countries with well-funded and dynamic research systems come out on top. \u201cKnowledge generation and research is really a borderless enterprise,\u201d says Rajika Bhandari, who studies the mobility of international students at the Institute for International Education in New York. \u201cAcademics go where the funding is and where the facilities are.\u201d \n               Comings and goings \n             Yet the global picture of these migrations is blurry. When tracking arrivals and departures, most countries lump scientists with other \u2018highly skilled migrants\u2019, and record-keeping differs from country to country. \u201cWhat\u2019s very frustrating is that there is no consistent tracking of people using the same methodology across countries,\u201d says Paula Stephan, who researches economics and science at Georgia State University in Atlanta. \u201cWe have lots of little studies on particular groups of scientists, but no world bank of data.\u201d Talk of \u2018migration\u2019 and \u2018mobility\u2019 often confuses permanent long-term relocations with the short-term visits\u00a0\u2014\u00a0six-month sabbaticals or fortnight-long trips\u00a0\u2014\u00a0that allow scientists to build research networks without actually settling in another country. \u201cThere are so many kinds of mobilities, and people rarely specify this,\u201d says Grit Laudel, a sociologist at the University of Twente in Enschede, the Netherlands. Stephan is part of one attempt to cut through this confusion: the \u2018GlobSci\u2019 survey, to be published in  Nature Biotechnology  in December. The authors asked around 17,000 researchers in four fields (biology, chemistry, Earth and environmental sciences and materials) in 16 countries about their movements; the result was what they call \u201cthe first systematic study of the mobility of scientists in a large number of countries\u201d. The numbers show big disparities from country to country, both in the proportion of scientists with foreign origins (see \u2018Foreign fractions\u2019 \u2014 or  interactive version ) and in the proportion of researchers who work outside their countries of origin (see \u2018The global diaspora\u2019 \u2014 or  interactive version ). The United States is indeed open: of the respondents working or studying there when the survey was done in early 2011, 38% were brought up overseas, and it is the number-one destination for expatriate scientists from almost every nation. Proportionally, however, Switzerland, Canada and Australia all housed more foreign researchers than the United States, with Switzerland having the highest foreign share, at 57%. India had the lowest proportion of foreign scientists, followed by Italy and Japan, but also the largest diaspora, with 40% of its home-born researchers working overseas. (The survey did not include China.) Japanese and US researchers were the least likely to be working abroad. Career stage affects scientists\u2019 mobility. Chiara Franzoni, another GlobSci author, who studies science and innovation at Milan Polytechnic in Italy, has done an unpublished analysis of the GlobSci data and shown that a country\u2019s postdocs are much more likely to be foreigners than its professors (see \u2018Restless youth\u2019). In the United States, for example, 61% of postdocs were brought up overseas\u00a0\u2014\u00a0but only 35% of assistant, associate or full professors. Nature  found similar patterns when it surveyed readers about their attitudes toward migration, and their own histories (click for  full survey data  ). Those who had just obtained their PhDs were much more likely to be living outside their country of upbringing than were more senior scientists\u00a0\u2014\u00a0and they were also more open to an international move, presumably because their career paths were not settled and they were less likely to be tied down by relationships and families. The proportion of respondents who said they were \u201cnot interested\u201d in international relocation rose from a mere 10% in those who gained their doctorates within the past two years to 40% in those who had done their PhD at least 16 years ago. \u201cOne take-away from a policy perspective is that if you are trying to bring people back who have studied overseas, then you should target the young because they are more likely to move,\u201d says Patrick Gaule, an economist who studies science and innovation at Charles University in Prague. He has tracked the movements of almost 2,000 senior-level foreign chemists affiliated with US universities between 1993 and 2007. Only 9% will return home by the end of their professional career, he estimates, and those that do are seven times more likely to return between the ages of 35 and 45 than after 50. \n               Itchy feet \n             What policy-makers eager to attract foreign scientists\u00a0\u2014\u00a0or stem a loss of domestic talent\u00a0\u2014\u00a0most want to know is what entices scientists across borders. In the GlobSci survey, migrants uniformly put the same two factors at the top: opportunities to improve their career prospects and outstanding research teams. The excellence of the foreign institution was also important, with quality of life and other personal reasons coming further down the list. For those who had migrated abroad and subsequently returned to their country of origin, however, personal and family reasons scored highest. Many economists note that the richer a country becomes, the more researchers tend to flock to it. Gross domestic product and wage levels are convenient metrics, but it is unlikely that they alone are the lure: they almost certainly correlate with career opportunities and top research facilities, for example. But wealth is not the whole picture: dynamic, flexible and competitive systems for funding and advancement are also crucial, notes Kieron Flanagan, who studies science and technology policy at the University of Manchester, UK. Japan and Italy, for example, are wealthy nations yet attract few foreign scientists because of their relatively rigid bureaucracy. \u201cIt\u2019s hard to get a job when you go there,\u201d Flanagan says, \u201cand when you\u2019re in, it\u2019s hard to get rid of you.\u201d A rigid system can also discourage native-born researchers from emigrating, Laudel says, noting that in Germany and the Netherlands, young scientists are encouraged to go abroad, but swiftly return. \u201cPeople tell me: \u2018I must go back to Germany, or I will never be able to get back into the system,\u2019\u201d she says. \u201cIf you return too late you don\u2019t fit the career structure any more.\u201d Atsushi Sunami, an expert in science and technology policy at Tokyo\u2019s National Graduate Institute for Policy Studies, points to another reason for Japan\u2019s insularity: culture. \u201cOften when we ask foreign researchers about their daily research activities, they say it\u2019s fine but it\u2019s hard to adjust to our society outside of the laboratory.\u201d In some respects, researchers considering an international move are like all migrants, weighing up factors that include wages and career prospects, but extend to quality of life, schooling for any children and career prospects for spouses, says Louise Ackers, who studies the movement of European scientists at the University of Liverpool, UK. Governments can try to tip the scales through immigration policies and travel incentives. Europe, for example, has programmes to encourage travel within the multi-country European Research Area; China has a \u2018One Thousand Talents Scheme\u2019 to recruit academics from abroad, as well as to persuade Chinese scientists to return. Recently, says Bhandari, \u201cChina and South Korea have done a much better job of deliberately creating well-structured incentives and opportunities for students to return back home, than, say India\u201d. And in the United States, both presidential candidates have said that they would like to expand the availability of visas for skilled immigrants. Yet a dynamic, well-funded science system seems to trump all other incentives. Even the visa crackdown after 9/11 did not dent science students\u2019 enthusiasm for migrating to the United States. \u201cDespite all the hand-wringing and the concern that numbers would plummet, statistically there was only a 2% drop in international student enrolment,\u201d says Bhandari. \u201cBy 2006 the numbers were rebounding.\u201d \n               The China question \n             US science-policy experts are asking how long the nation can retain its grasp on foreign talent. The country\u2019s largest contingent of foreign doctoral students in science comes from China, and research by Mike Finn, an economist at the Oak Ridge Institute for Science and Education in Tennessee, shows that for now, most stay on. Studying a cohort of Chinese scientists who had received their PhDs in 2004, Finn found that five years later, 89% were still in the United States. Higher salaries may be the biggest attraction. Robert Zeithammer, at the Anderson School of Management at the University of California, Los Angeles, has surveyed almost 300 Chinese science students studying for their doctorates in the United States, asking them for their reactions to hypothetical job offers from the two countries. \u201cChinese doctoral graduates currently tend to remain in the United States because of a large salary disparity between the two countries rather than because of an inherent preference for locating in the United States,\u201d he concludes. But as China continues its economic rise and builds its science infrastructure, that may change. Data from China\u2019s Statistical Yearbook show a slight uptick in return rates of Chinese students from abroad over the past few years (although the data do not single out scientists), notes Cong Cao, a sociologist at the School of Contemporary Chinese Studies at the University of Nottingham, UK. But Finn says that there is no sign yet of any overall decline in stay-rates in the United States. The proportion of foreigners who say that they have \u201cplans to stay\u201d after graduation has gone up, not down, over the past decade, he points out. And the lure of China remains faint for non-Chinese scientists.  Nature \u2019s survey (which drew responses mainly from the United States and Europe) asked researchers which countries would be producing the best science in their field by 2020, and more than 60% of respondents in both biological and physical sciences picked China as an option. However, only 8% said they would be prepared to relocate to China\u00a0\u2014\u00a0instead preferring the United States, Europe, Canada and Australia (see \u2018Lands of promise\u2019 \u2014 or  interactive graphic ). Responses suggested that China is unappealing for foreign researchers for political and cultural reasons (see \u2018Weighing up a move\u2019 \u2014 or  interactive graphic ), despite high expectations for the future quality of its research. Such a disparity could be dangerous, says Jonathan Adams, director of research evaluation at Thomson Reuters, which is based in New York. If researchers in Europe and the United States do not spend serious time in China, he says, they will find it hard to understand how research is conducted there, even as the country\u2019s influence in science grows. \n               Win\u2013win? \n             Those who study scientists\u2019 mobility argue that the discussion need not pit nation against nation, as if China\u2019s gain is the United States\u2019s loss. In place of \u2018brain drain\u2019 and \u2018brain gain\u2019, they prefer to talk about \u2018brain circulation\u2019, in which international scientists dip in and out of countries at will, and everyone benefits from the collaboration. \u201cOf course America will decline in relative terms, as the United Kingdom has, but it will do enough leading-edge research to benefit from work done elsewhere,\u201d says Flanagan. \u201cThe key thing is to have a strong-enough science base to interact with a globalized and mobile scientific world.\u201d Researchers at the Dutch publishing firm Elsevier, who are tracking the movements of scientists by following their publishing addresses, have detected hints of that pattern. Most notable among the early results for each country is a large proportion of \u2018transitory\u2019 scientists, who stay in a country for less than two years at a time. The University of Liverpool\u2019s Ackers adds that some evidence, including a survey of researchers in Europe\u2019s Marie Curie Fellowship Programme, suggests that shorter, more frequent visits are increasingly supplementing long-term travel to other labs. With the Internet making it easier to work with international collaborators at a distance, Ackers suggests, repeated week- or month-long visits can yield as much as, if not more than, a half-year stay. \u201cThe old idea of researchers moving permanently from one country to another is now quite outdated,\u201d she says, adding that it will become increasingly common for people to live in one country but work in two or three. With all this globe-hopping, the question is how long researchers will need to spend in the same place for effective collaboration\u00a0\u2014\u00a0an answer that will surely differ between disciplines. Yet this vision of a globalized, circulating world is still a long way from reality: very few scientists are global citizens, popping in and out of the best research facilities. And in developing countries such as India, \u201cbrain circulation\u201d does not accurately reflect the situation, says Khadria. For him, the brain drain is still very real. \u201cIt is not the top-of-the-line scientists who come back; rather, they return at a time when most of their productive work is over,\u201d he says. Science may increasingly be a globalized enterprise, but until would-be competitors boost their spending on science and facilities, it will simply give scientists even more opportunities to clump inside the countries that are already at the top of the pack.\n \n                 Click for the full data from  Nature \u2019s migration survey \n               \n                     Research funding: Global challenges need global solutions 2012-Oct-17 \n                   \n                     Research policy: How to build science capacity 2012-Oct-17 \n                   \n                     Global reach 2012-Oct-17 \n                   \n                     Collaborations: The rise of research networks 2012-Oct-17 \n                   \n                     Global council aims to coordinate science 2012-May-21 \n                   \n                     European groups go global 2012-Apr-18 \n                   \n                     Career choices: The mobility imperative 2011-Feb-23 \n                   \n                     Eastern Europe: Scaling the wall 2009-Sep-30 \n                   \n                     In praise of the 'brain drain' 2007-Mar-14 \n                   \n                     Nature special: The new map of science \n                   \n                     The \u2018Global Science\u2019 survey \n                   \n                     The Institute of International Education \n                   \n                     National Science Foundation: science and engineering indicators 2012 \n                   Reprints and Permissions"},
{"file_id": "489198a", "url": "https://www.nature.com/articles/489198a", "year": 2012, "authors": [{"name": "Sharon Weinberger"}], "parsed_as_year": "2006_or_before", "body": "Despite 50 years of research on high-power microwaves, the us military has yet to produce a usable weapon. For some Pentagon officials, the demonstration in October 2007 must have seemed like a dream come true \u2014 an opportunity to blast reporters with a beam of energy that causes searing pain. The event in Quantico, Virginia, was to be a rare public showing for the US Air Force's Active Denial System: a prototype non-lethal crowd-control weapon that emits a beam of microwaves at 95 gigahertz. Radiation at that frequency penetrates less than half a millimetre into the skin, so the beam was supposed to deliver an intense burning sensation to anyone in its path, forcing them to move away, but without, in theory, causing permanent damage. However, the day of the test was cold and rainy. The water droplets in the air did what moisture always does: they absorbed the microwaves. And when some of the reporters volunteered to expose themselves to the attenuated beam, they found that on such a raw day, the warmth was very pleasant. A demonstration of the system on a sunny day this March proved more successful. But that hasn't changed a fundamental reality for the Pentagon's only acknowledged, fully developed high-power microwave (HPM) weapon: no one seems to want it. Although the Active Denial System works (mostly) as advertised, its massive size, energy consumption and technical complexity make it effectively unusable on the battlefield. The story is much the same in other areas of HPM weapons development, which began as an East\u2013West technology race nearly 50 years ago. In the United States, where spending on electromagnetic weapons is down from cold-war levels, but remains at some US$47 million per year, progress is elusive. \u201cThere's lots of smoke and mirrors,\u201d says Peter Zimmerman, an emeritus nuclear physicist at King's College London and former chief scientist of the US Arms Control and Disarmament Agency in Washington DC. Although future research may yield scientific progress, he adds, \u201cI cannot see they will build a useful, deployable weapon\u201d. For many critics, the US HPM programme has become a study in wishful thinking, exacerbated by a culture of secrecy that makes real progress even more difficult. The quest to build an electromagnetic weapon \u2014 an e-bomb, in military jargon \u2014 was sparked on 8 July 1962, when the United States carried out Starfish Prime, the largest high-altitude nuclear test that had ever been attempted. The 1.4-megaton thermonuclear warhead, detonated 400 kilometres above the central Pacific Ocean at 9 seconds past 11 p.m., Hawaii time, blasted huge swarms of charged particles outwards along Earth's magnetic field. Their gyrations generated a pulse of microwave energy that drove measuring instruments off the scale. Artificial auroras lit up the night across swathes of ocean. And in Honolulu, more than 1,300 kilometres from the detonation point, the pulse set off burglar alarms, knocked out street lights and tripped power-line circuit breakers. Nothing like Starfish Prime has been seen since August 1963, when the Partial Test Ban Treaty outlawed nuclear explosions anywhere but underground. But the test showcased the potential destructiveness of an electromagnetic pulse to military planners on both sides of the cold-war divide, and launched them into a race to harness it as a weapon using a non-nuclear source. \n               Power cut \n             The US Air Force has been the main funder of the country's HPM programme from the beginning. At first, its goal was a weapon capable of taking out an enemy's computers, communication systems and other electronics. In theory, the idea remains compelling: an e-bomb would be able to fire microwave 'bullets' at the speed of light and, if tuned to the right frequencies, disable its targets without collateral damage. Cars could be stopped in their tracks, radars blinded and computers destroyed, with no need for high explosives. But that goal has foundered on the HPM weapon's main technical challenge: generating a pulse that is directed enough to pick out a specific target and powerful enough to have an effect when it gets there, ideally using a generator that is small and light enough for an aeroplane or missile to lift. A battery-powered device can generate an HPM pulse, but producing the kind of highly concentrated power needed to destroy electronics typically requires detonating a conventional explosive inside a device that destroys itself in the act of pulsing (see 'E-blast'). Because doing this inside a piloted aircraft is risky \u2014 \u201ca few pounds in the right place will take down anything\u201d, notes Zimmerman \u2014 the Air Force has in recent years pursued HPM weapons designed for single-use missiles. For example, the Counter-electronics High-power Microwave Advanced Missile Project (CHAMP) is an experimental cruise missile designed to take out electronic targets such as production sites for weapons of mass destruction. Neither the Air Force nor Boeing, its main contractor for CHAMP, will discuss technical details of the programme. But the project is just a prototype; when CHAMP was flight-tested last year, it still didn't include the HPM payload. It is possible to make a microwave generator compact enough for a missile. Engineers at Texas Tech University in Lubbock have developed an experimental explosive-based source less than 2 metres long and 16 centimetres in diameter (M. A. Elsayed  et al .  Rev. Sci. Instrum.   83 , 024705; 2012 ). But lead developer Andreas Neuber points out that there are physical limits: to maximize the microwave power while keeping the system small, the engineers had to increase the internal electrical field. The result can be a catastrophic failure of the system's insulating materials that short-circuits it before the system can build up much power. Even if the military succeeds in packaging an HPM system, there is serious doubt over how effective the pulses will be when they hit their targets. In the late 1980s, a device called Gypsy successfully took out a bank of personal computers during the Air Force's first unclassified test of a microwave weapon. But building on that success \u201cbecame an incredibly difficult research project\u201d, says Doug Beason, a physicist who was associate director for threat reduction at the Los Alamos National Laboratory in New Mexico until 2008, and wrote  The E-Bomb  (Da Capo, 2005), a discussion of directed-energy weapons. \u201cYou could understand how microwaves affected components of electronic circuits \u2014 transistors, capacitors, inductors and all that. But when you started putting them together in complex circuits, it became more of a stochastic process and you wouldn't always get the same results each time.\u201d There is similar uncertainty over how electromagnetic energy flows through enclosures such as buildings. The process is chaotic, says Edl Schamiloglu, an electrical engineer at the University of New Mexico in Albuquerque who is involved in a multi-university research initiative funded by the US defence department to improve such predictions. \u201cWhen an electromagnetic ray or wave-beam enters the enclosure,\u201d he says, \u201cit will continue bouncing around and not repeat its trajectory.\u201d In short, more than 20 years after the Gypsy test, scientists still can't reliably predict the damage a weapon would do. And that is without even considering the countermeasures that an adversary might use, which could be as elementary as surrounding sensitive electronics with a Faraday cage \u2014 the equivalent of the aluminium mesh used to shield microwave ovens. The effort to disable electronics has remained mostly secret. But in 2001, the Air Force publicly announced that it had made substantial progress in developing microwave weapons that target people, when it unveiled the Active Denial System. Development of the system began in the 1990s with the Air Force's efforts to explore the biological effects of microwaves. A project code-named Hello studied how to modulate the clicking or buzzing sounds produced by microwave heating in the inner ear, to produce psychologically devastating 'voices in the head'. 'Goodbye' explored the use of microwaves for crowd control. And 'Good Night' looked at whether they could be used to kill people. \n               Hello goodbye \n             Only the Goodbye effect went into development as a weapon. Further bioeffects research was conducted in secrecy at Brooks Air Force Base near San Antonio in Texas, but even that programme almost stalled when the weapon was ready to move from animal to human testing. Hans Mark, a nuclear engineer at the University of Texas at Austin who was then the Pentagon's director of defence research and engineering, paid a visit to Brooks in 2000 to check out the work. \u201cDr Mark didn't believe in the effect,\u201d recalls Beason, \u201cand he actually had a shouting match with one of the main researchers.\u201d But Mark's approval was needed to advance the project, so he agreed to be subjected to the beam. The Air Force got its human tests. The Brooks scientists joke that \u201cyou've never seen a political appointee run so fast\u201d, says Beason. Mark says that his doubts about the Goodbye effect were rooted in what he calls the \u201cextravagant claims\u201d made by its advocates. If nothing else, he says, the superconducting electromagnet that powered the system's pulse generator required a cooling system too big and cumbersome to be used in the field. Mark says that he allowed the system to proceed to human testing not because he was convinced that it would work, but because after exposing himself to the beam, he decided that human testing at least wouldn't harm anyone. \u201cAlmost all of this programme has been a waste of money,\u201d he says. Mark's concerns have proved prescient: efforts to deploy the weapon have been futile. At the 2001 unveiling, the defence department touted the Active Denial System for use in peacekeeping missions in places such as Kosovo and Somalia. But after the invasion of Iraq in 2003, when the US Joint Non-Lethal Weapons Directorate offered to deploy the Active Denial System to the region, it was rebuffed. \u201cWe knew it wasn't reliable,\u201d said Franz Gayl, the Marine Corps's science and technology adviser, in an interview last year. Worse, he said, the pulse generator was so big that it had to be carried on its own utility vehicle. \u201cThat was a recipe for disaster,\u201d said Gayl, \u201cbecause the operators are going to be a target.\u201d And worst of all, he said, before use the system had to be cooled down to 4 kelvin \u2014 a process that took 16 hours. The defence department tried to deploy the weapon in Afghanistan in 2010, but it was sent home unused. In the same year, California rejected a smaller version meant for use in prisons. The device was built by defence contractor Raytheon of Waltham, Massachusetts, which declines to discuss it. Other weapons have fared little better. The Air Force Research Laboratory developed an HPM system called MAXPOWER to detonate roadside bombs remotely, but it was the size of an articulated lorry \u2014 too unwieldy to be deployed in Afghanistan. The Joint Improvised Explosive Device Defeat Organization, the defence department's bomb-fighting agency, declined to discuss the system, citing classification issues. But it did say that, as of 2011, it was not funding MAXPOWER. In July, General Norton Schwartz, the Air Force chief who retired last month, warned that the service would have to withdraw from some science efforts amid budgets cuts, but that HPM technology would still be pursued. It \u201cclearly has potential\u201d, he told the trade magazine  Aviation Week & Space Technology , warning that countries such as Russia could be ahead of the United States. \n               The microwave gap \n             The concern that other nations, or even terrorists, could be working on similar technology seems to have been one of the prime motivations for the US military to continue investing in microwave weaponry, despite the apparent lack of progress. According to a 2009 briefing on non-lethal technologies prepared by the Office of Naval Research and obtained under the Freedom of Information Act, Russia, China and even Iran are pursuing HPM programmes \u2014 and the UK Defence Science and Technology Laboratory at Fort Halstead is sponsoring a classified car-stopping programme. But such programmes are not necessarily proof that the cold-war HPM arms race is still going on. At least some countries may \u2014 like the United States \u2014 be conducting research out of fear of becoming vulnerable to such weapons. Modern technologies such as mobile phones are particularly susceptible to HPMs, says Michael Suhrke, head of the electromagnetic effects and threats business unit at the Fraunhofer Institute for Technological Trend Analysis in Euskirchen, Germany. As for HPM weapons in the hands of terrorists, many scientists regard that threat as far-fetched at best. Even if terrorist groups had the sophistication to carry out the necessary testing, says Yousaf Butt, a physicist in the high-energy astrophysics division at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, why would they? A microwave weapon of any magnitude would probably have to be powered by explosives. And if they had that kind of material, he says, \u201cwhy wouldn't they just explode it?\u201d \u201cIs it conceivable?\u201d asks Philip Coyle, who in 2010\u201311 served as associate director for national security and international affairs in the White House Office of Science and Technology Policy, and is now a senior fellow at the Center for Arms Control and Non-Proliferation, a think tank based in Washington DC. \u201cBarely, I think. I wouldn't take it for granted that terrorists couldn't do it. But I'd rather terrorists spent all their time working on [an HPM weapon] than car bombs.\u201d Experts still disagree on whether HPMs might eventually make useful weapons. But one thing is clear: the mythical e-bomb capable of stopping cars or planes has not yet materialized on the battlefield. Asked whether the Air Force had produced any operational weapons, its research lab said only: \u201cDue to operational concerns, we are unable to respond to this question.\u201d The secrecy that surrounds HPM weapons research seems to have greatly exacerbated technical obstacles to the programme. In 2007, for example, a report on directed-energy weapons by the Defense Science Board said that the Pentagon had not effectively used data collected by university researchers to understand microwave effects. The Air Force claims that sharing is better now. But working in a field shrouded in secrecy still affects how information is disseminated. Neuber, for example, could agree to answer questions for this article only if he replied in writing, and only after his responses had been cleared through the US Army office that sponsors his team's work. \u201cWorking in an area that is to a large extent of military interest requires playing by a set of different rules to some extent,\u201d he wrote. \u201cSome flow of information is not as free as in other areas of the research endeavour.\u201d To John Alexander, a retired army colonel who once headed the non-lethal weapons programme at Los Alamos National Laboratory, the secrecy reinforces the air of fantasy around the whole endeavour. \u201cMy point is always: chemistry and physics work the same way for everyone, and there are smart folks out there, so who are you trying to fool?\u201d he says. \u201cThe people not getting adequate information were our own commanders.\u201d \n                 See Editorial \n                 page 177 \n               \n                     Power of the Pentagon: The changing face of military science 2011-Sep-21 \n                   \n                     Nature News special: Beyond the bomb \n                   \n                     US Air Force fact sheet on high-power microwave research (PDF) \n                   \n                     Global Security on high-power microwave weapons \n                   Reprints and Permissions"},
{"file_id": "489352a", "url": "https://www.nature.com/articles/489352a", "year": 2012, "authors": [{"name": "Michelle Nijhuis"}], "parsed_as_year": "2006_or_before", "body": "Forests in the American west are under attack from giant fires, climate change and insect outbreaks. Some ecosystems will never be the same. A little after noon on Sunday 26 June 2011, strong winds toppled an aspen tree onto a power line in the Jemez Mountains of northern New Mexico. The year had been extraordinarily dry, and the temperatures that week had soared well above normal. When a spark from the power line ignited a fire, wind gusts spread the flames into nearby dense stands of fir and pine. Within an hour, ecologist Craig Allen, 55 kilometres away at his home in Santa Fe, learned about the fire in an e-mail from a US Forest Service fire manager. \u201cI hope you guys catch this,\u201d Allen wrote back. \u201cWe don't need another big fire in the Jemez.\u201d But Allen could already see a plume of grey smoke rising to the west. By early the next morning, the Las Conchas fire had burned 17,500 hectares \u2014 about a hectare every three seconds. Within five days, it had grown to 42,000 hectares and become the largest fire in New Mexico's history. By the time the fire was contained weeks later, it had burned more than 60,000 hectares of forest and scrubland, in many places roasting the vegetation so thoroughly that only charred stumps and bare dirt remained. For Allen, who works for the US Geological Survey (USGS) in Los Alamos, New Mexico, and has been studying the forests of the Jemez Mountains for more than 30 years, a large fire was not unexpected, but its speed and intensity caught him off guard. Later that year, when Allen and other forest scientists toured the burned area, they were all stunned into silence. The size of the areas scorched bare by the fire dwarfed the patterns of past burns, judging from studies of fire scars in tree rings reaching back to 1600. This time, says Allen, the forest may not recover. Across the American west, the area burned each year has increased significantly over the past several decades (see 'Bigger blazes'), a trend that scientists attribute both to warming and drying and to a century of wildfire suppression and other human activities. Allen suggests that the intertwined forces of fire and climate change will take ecosystems into new territory, not only in the American west but also elsewhere around the world. In the Jemez, for example, it could transform much of the ponderosa pine ( Pinus ponderosa)  forest into shrub land. \u201cWe're losing forests as we've known them for a very long time,\u201d says Allen. \u201cWe're on a different trajectory, and we're not yet sure where we're going.\u201d \n               Dead zone \n             Thirteen months after the Las Conchas fire, on a clear, late-summer day, Allen hikes down a valley on the southern edge of the burn, just outside Bandelier National Monument, a tangle of canyons that shelter pre-Columbian cliff dwellings. Apart from a few shrubs and grasses, many of the hillsides \u2014 once covered with pine and fir \u2014 are empty and brown. Blackened stumps of alligator junipers ( Juniperus deppeana ), squat, gnarly trees that can live for many hundreds of years, stick up like twisted hands. Shade is just a wish and the landscape is still, with only a few raptors circling overhead. Allen is pleased to see some ants on the ground. It looks as arid as Death Valley, but it is not. These mountains typically get more than 40 centimetres of rain a year, a healthy amount in the generally dry US southwest and enough \u2014 in theory \u2014 to regrow a forest. In the past, that is what happened. Because the fires burned unevenly, they left stands of surviving trees that then supplied seeds to scorched areas, allowing the forest to regenerate. Over the past century, however, the policy of quickly dousing fires has allowed brush and spindly young trees to build up in many western forests, so they tend to burn hotter and less patchily than before. And over the past decade, a severe drought across the southwest has weakened trees and made them vulnerable to widespread attack by beetles, leading to a die-off of more than one million hectares of pi\u00f1on pines ( Pinus edulis ) 1 . Many of the dead trees are still standing, and can serve as ladder fuels that transform relatively cool surface fires into hot, fast-moving crown fires that leap from treetop to treetop. \u201cIt's not the area of these fires that's of most concern,\u201d says Allen. \u201cIt's the scale of the contiguous patches of dead trees.\u201d Fires such as the Las Conchas one leave behind few seed sources, strip soils of nutrients and increase the likelihood of landslides. In their wake, vegetation of any kind can struggle to take root. When trees and shrubs do regrow, the region's warming temperatures and more frequent dry spells are likely to favour heat- and drought-tolerant species. By looking at tree rings, Park Williams of the Los Alamos National Laboratory and his colleagues have been able to assess how droughts stress southwestern forests 2 . They forecast that if temperatures rise as projected by climate models, trees will face worse drought stress in the first half of the twenty-first century than they have experienced for 1,000 years, probably driving a transformation of the ecosystem. In some places in the Jemez, the transformation seems to have started. In 1996, the Dome Fire burned almost 7,000 hectares in the mountains, leaving patches of dead trees that at the time seemed surprisingly large, say Allen and others. Swathes of shrubby vegetation, dominated by scrub oaks, sprouted in the burned patches, surrounding small islands of surviving ponderosa pine and other conifers. When the Las Conchas fire roared through some of the same areas last summer, the oaks burned hot and fast, killing almost all the conifers that had survived the Dome fire. Because the shrubs are better adapted to warmer, drier conditions than the trees, Allen expects that they will regrow in even larger patches. Eventually, they could dominate the entire landscape and establish a pattern of intense and frequent fires that is currently more common in coastal California and other Mediterranean-style ecosystems. On his hike through the burned area, Allen turns to Jorge Castro Guti\u00e9rrez, an ecologist at the University of Granada, Spain, who is visiting Santa Fe for the summer. \u201cWe're turning into something that's going to look very familiar to you,\u201d he says. \n               The new normal \n             All around the American west, scientists are seeing signs that fire and climate change are combining to create a 'new normal'. Ten years after Colorado's largest recorded fire burned 56,000 hectares southwest of Denver, the forest still has not rebounded in a 20,000-hectare patch in the middle, which was devastated by an intense crown fire. Only a few thousand hectares, which the US Forest Service replanted, look anything like the ponderosa-pine stands that previously dominated the landscape. \u201cOtherwise, it's grassland and shrub land, and probably will be for centuries to come,\u201d says Peter Brown, a forest ecologist and director of the non-profit organization Rocky Mountain Tree-Ring Research in Fort Collins, Colorado. From tree-ring analyses, he knows that even small bare patches left by crown fires in the nineteenth century have not returned to forest, so he holds little hope for the intensely burned patch from 2002. In the Alaskan interior, as summers have turned warmer and drier and permafrost has thawed, fires are hitting more frequently and the fire season lasts longer. Burns reach deeper into soils and alter their chemistry. By favouring the regeneration of deciduous species, which are better adapted to burned soils and frequent fires, these changes could break what researchers call the 'legacy lock' of the black spruce ( Picea mariana ) forests in the region 3 . Similar dynamics are at work in the Great Basin and Sonoran deserts of the American west, where invasive grasses regenerate quickly after wildfires, creating a carpet of fast-burning fuel that makes future fires more likely. In the saguaro cactus ( Carnegiea gigantea ) forests of southern Arizona, wildfires were once an oddity. Now, flaming cacti are an increasingly common sight, and invasive species such as buffelgrass ( Cenchrus ciliaris ) are spreading. In the high mountains of Glacier National Park, Montana, fire and warming may favour a new kind of forest \u2014 or none at all. Last year, Rachel Loehman of the US Forest Service's fire sciences lab in Missoula, Montana, and her colleagues used an ecosystem process model that simulated interactions between fire, climate and vegetation to assess the park's future. Their results 4  predict that climate change and frequent fires will trigger the spread of western white pine ( Pinus monticola ), a species common there until logging and wildfire suppression favoured the dominance of western red cedar ( Thuja plicata ), western hemlock ( Tsuga heterophylla ) and other shade-tolerant species. But as temperatures in the Rockies rise, western white pine is becoming vulnerable to white-pine blister rust ( Cronartium ribicola ) and beetle attack. If the western white pine succumbs to disease, the park could be left with little forest cover, says Loehman. To keep the park's forests from disappearing, Loehman and her colleagues recommend that authorities there continue to conduct small 'prescribed' burns that limit future fires. She also supports ongoing efforts to develop and plant trees that have genetic resistance to blister rust. Allen stressed these threats in August, when he testified before the US Senate Committee on Energy and Natural Resources about the issues being faced by western forests. Given the recent die-offs and the forecasts for the future, many forests could be heading towards a tipping point, he said. \u201cIf the climate projections of rapid warming for the Southwest are correct, then by the middle of the twenty-first century our Southwestern forests as we know them today will experience significant vegetation mortality and can be expected to reorganize with new dominant species.\u201d The forest die-offs in the American west resemble shifts happening in other parts of the world. In 2010, Allen and 19 colleagues from around the world found that published reports of forest die-offs associated with drought have increased significantly since 1985, and are occurring in ecosystems ranging from the tropical forests of Costa Rica to Australian acacia forests and pine forests in east-central China 5 . They also found that no type of forest or climate zone was immune. With collaborators in Australia, Europe and throughout North America, Allen is now working to identify the physiological limits of various tree species, which should help in predicting future die-offs and changes in fire-prone areas worldwide. \u201cWe don't really understand what it takes to kill a tree,\u201d says Allen. \n               Fixing forests \n             Forest managers may try to slow down or stop the conversion of some forests, to preserve biodiversity, carbon storage or an iconic species, says Nathan Stephenson, a USGS ecologist at the Sequoia and Kings Canyon Field Station in Three Rivers, California, who studies one such icon \u2014 the sequoia. But that tends to require expensive and ongoing intervention, such as irrigating seedlings in habitats that are growing too hot and dry. In other cases, managers will decide to let the forests shift, says Stephenson. \u201cBut the worst thing is for it to happen through disturbances that completely wipe out the vegetation, increase erosion and sap nutrients out of the soil,\u201d he says. \u201cIf we can find ways to ease the transition from one state to another, we'll be in much better shape.\u201d One way to do that is to keep fires from spreading so quickly and burning so intensely. For well over a decade, the US Forest Service has been 'treating' some of its forest stands with selective logging and prescribed burning \u2014 not to prevent all fires, but to reduce the risk of large and severe burns. Managers at the Santa Fe National Forest in New Mexico, which includes the Jemez, now plan to treat about 45,000 hectares of forest. \u201cOne of the things we've learned is that these treatment areas have to be very large in order to work,\u201d says prescribed-fire specialist William Armstrong. That means not hundreds of hectares, but thousands or tens of thousands of hectares, he says. Despite repeated urgings from Allen and other scientists, however, most treatment projects aren't on this scale. Funding and person power are often scarce, and the only way to thin large areas quickly and economically is to use prescribed burning \u2014 a tactic that generally meets with public resistance. \u201cWe're well aware of the science,\u201d says Armstrong, \u201cand we're acutely aware that there's a whole lot we're not going to be able to do.\u201d If large, high-severity fires do continue, some managers may choose to speed up landscape transitions, rather than slow them down. Nancy Grulke, director of the US Forest Service Western Wildland Environmental Threat Assessment Center in Prineville, Oregon, says that when fires burn through low-elevation conifer forests in the mountains around Los Angeles, California, and create landslide hazards, she advises managers not to replant conifers but to choose oaks and other species that are better adapted to a warm, dry future. Given the uncertainties in how climate change, insect outbreaks and other stresses will affect forests in coming decades, Allen thinks that it is necessary to hedge bets after a fire by planting a range of species. He suggests building a \u201cbridge to the future\u201d, by mixing some of the original tree types with species from lower elevations or warmer slopes, which could do well as conditions change. That approach would help to make the ecosystems more resilient. But it will not restore the past, says Allen, who is saddened by the dramatic changes in the Jemez Mountains and beyond. At the end of a long, dry and fiercely hot hike through the Las Conchas burn, he surveys the bare hillsides and recalls what they were like just over a year ago \u2014 forested, cool and full of life. \u201cFor so many of us who have worked here for so long,\u201d he says, \u201cthis feels like a failure.\u201d \n                     Conservation biology: The end of the wild 2011-Jan-12 \n                   \n                     Russia counts environmental cost of wildfires 2010-Aug-12 \n                   \n                     Warming climate fuels fires in Rockies 2006-Jul-06 \n                   \n                     National Interagency Fire Center \n                   \n                     Craig Allen \n                   Reprints and Permissions"},
{"file_id": "489356a", "url": "https://www.nature.com/articles/489356a", "year": 2012, "authors": [{"name": "Kerri Smith"}], "parsed_as_year": "2006_or_before", "body": "Neuroscientists are trying to work out why the brain does so much when it seems to be doing nothing at all. For volunteers, a brain-scanning experiment can be pretty demanding. Researchers generally ask participants to do something \u2014 solve mathematics problems, search a scene for faces or think about their favoured political leaders \u2014 while their brains are being imaged. But over the past few years, some researchers have been adding a bit of down time to their study protocols. While subjects are still lying in the functional magnetic resonance imaging (fMRI) scanners, the researchers ask them to try to empty their minds. The aim is to find out what happens when the brain simply idles. And the answer is: quite a lot. Some circuits must remain active; they control automatic functions such as breathing and heart rate. But much of the rest of the brain continues to chug away as the mind naturally wanders through grocery lists, rehashes conversations and just generally daydreams. This activity has been dubbed the resting state. And neuroscientists have seen evidence that the networks it engages look a lot like those that are active during tasks. Resting-state activity is important, if the amount of energy devoted to it is any indication. Blood flow to the brain during rest is typically just 5\u201310% lower than during task-based experiments 1 . And studying the brain at rest should help to show how the active brain works. Research on resting-state networks is helping to map the brain's intrinsic connections by showing, for example, which areas of the brain prefer to talk to which other areas, and how those patterns might differ in disease. But what is all this activity for? Ask neuroscientists \u2014 even those who study the resting state \u2014 and many will sigh or shrug. \u201cWe're really at the very beginning. It's mostly hypotheses,\u201d says Amir Shmuel, a brain-imaging specialist at McGill University in Montreal, Canada. Resting activity might be keeping the brain's connections running when they are not in use. Or it could be helping to prime the brain to respond to future stimuli, or to maintain relationships between areas that often work together to perform tasks. It may even consolidate memories or information absorbed during normal activity. \u201cThere's so much enthusiasm about the approach now, and so little basic understanding,\u201d says Michael Greicius, a neuroscientist at Stanford University in California, who started studying resting-state networks a decade ago. \n               Always active \n             A set of experiments in the mid-1990s first suggested that the brain never really takes a break. Bharat Biswal, then a PhD student at the Medical College of Wisconsin in Milwaukee, was trying to find ways of identifying and removing background signals from fMRI scans, in the hope that it would improve interpretations of the signals from tasks. \u201cThe assumption was, it was all noise,\u201d says Biswal, who is now a biomedical engineer at the New Jersey Institute of Technology in Newark. But when he looked at scans taken when people were resting in the scanner, he saw regular, low-frequency fluctuations in the brain 2 . Biswal's experiments suggested that neuronal activity was causing these fluctuations. Let your mind wander as Kerri Smith explores resting brain activity with the help of two neuroscientists.\u00a0 In the early days of resting-state research, some people were sure that they had found something profound. \u201cWhen I first started looking at these networks, I was convinced we were tapping into the stream of consciousness, and this was real-time ongoing conscious processing,\u201d says Greicius. But, he says, \u201cI was relatively quickly disabused of that notion\u201d. The networks of activity also appeared in altered states of consciousness such as when sleeping or under anaesthesia 3 , 4 , so they weren't necessarily linked to conscious processing. But they weren't meaningless either. Several years after Biswal's discovery, studies of the resting state in its own right began to emerge. A team led by Marcus Raichle, a neuroscientist at Washington University in St. Louis, Missouri, characterized 5  activity in one such network as the brain's default mode \u2014 what they considered its baseline setting. During tasks, default-mode activity actually dropped, coming back online when the brain was no longer focusing so intensely 5 . The default-mode network has been joined by dozens of other flavours of resting-state network \u2014 some of which resemble the circuitry that contributes to attention, vision, hearing or movement. They seem very similar across study participants but are also dynamic, changing over time. \u201cThe fact that it's always present but modifiable tells you that it's got its importance,\u201d says Michael Milham, director of the Center for the Developing Brain at the Child Mind Institute in New York. Still, some researchers have questioned whether these resting patterns represent anything real. After all, fMRI does not measure brain electrical activity directly: it monitors blood flow. The low-level idling activity could be an artefact. \u201cPeople suspected it was lousy scanners or respiratory noise,\u201d says Andreas Kleinschmidt, director of research at the French National Institute of Health and Medical Research's Cognitive Neuroimaging Unit in Gif-sur-Yvette. But using fMRI and electroencephalography (EEG) recordings, Kleinschmidt and his team confirmed 6  that various resting-state networks are correlated with real neural activity. Shmuel and David Leopold, a neurophysiologist at the US National Institute of Mental Health in Bethesda, Maryland, did much the same 7 , imaging resting states in monkeys while recording the animals' electrical brain activity using probes implanted deep in the visual cortex. They found correlations between resting-state networks and electrical activity in a band of frequencies around 40 hertz. Such '\u03b3 activity' is associated with communication between distant brain areas, and seeing it convinced Shmuel that resting-state networks represent actual brain activity. \u201cI strongly believe that there is a neurophysiological mechanism that underlies the entire thing that we call resting-state networks,\u201d he says. \n               Disordered thinking \n             It is a mechanism that may go awry in brain disorders. People with early signs of Alzheimer's disease, for example, have unusual resting-state signatures that can be detected even at very mild levels of dementia and which vary as the disease progresses 8 . In children with autism spectrum disorder, resting-state networks can be 'hyperconnected', displaying more links than for kids without the condition 9 . The reasons for these differences are not clear, and they may not matter to clinicians, who are interested in finding disease markers. \u201cFrom a clinical perspective, you're not always going to understand why a biomarker is serving as that biomarker,\u201d says Milham. But some neuroscientists are deeply curious as to what these fluctuations do. \u201cIt keeps me up at night,\u201d says Timothy Ellmore at the University of Texas Health Science Center in Houston, who is studying resting brain activity in people with Parkinson's disease. Some researchers now think that resting-state networks may prime the brain to respond to stimuli. \u201cThe system is not sitting there doing nothing and waiting,\u201d says Kleinschmidt. Cycling activity in these networks may be helping the brain to use past experiences to inform its decisions. \u201cIt's incredibly computationally demanding to calculate everything on the fly,\u201d says Maurizio Corbetta at Washington University School of Medicine in St. Louis. He has been studying resting state using magnetoencephalography, a technique that measures magnetic fields associated with the electrical activity of neurons. \u201cIf I have ongoing patterns that are guessing what's going to happen next in my life, then I don't have to compute everything.\u201d He likens the activity to the idling of a vehicle. \u201cIf your car is ready to go, you can leave faster than if you have to turn on the engine.\u201d But idling networks might not just save time. They may also influence perceptions \u2014 albeit unconsciously. To study how spontaneous resting activity affects perception, Kleinschmidt and his colleagues scanned 10  the brains of people who were looking at a picture that can be perceived as a face or as a vase. Study participants who reported seeing a face had more spontaneous activity in the fusiform face area \u2014 a brain region that processes faces \u2014 before they were shown the picture. Kleinschmidt suspects that the brain is running several models of the world in the background, ready for one of them to turn into reality. \u201cIdeally, you're always prepared for what happens next,\u201d he says. Corbetta has discovered evidence in people with brain damage that resting activity can change behaviour. In unpublished work, he has found hints that lesions in frontal brain regions \u2014 caused by stroke, for example \u2014 can give rise to changes in spontaneous brain activity in distant areas. What is more, the changes to the resting activity are linked to the behavioural deficit. \u201cThis is clear evidence that resting-state impairments are affecting the way the network is recruited during a task,\u201d he says. \n               Zen and the art of network maintenance \n             Raichle favours the idea that activity in the resting state helps the brain to stay organized. The connections between neurons are continually shifting as people age and learn, but humans maintain a sense of self throughout the upheaval. Spontaneous activity might play a part in maintaining that continuity. \u201cConnections between neurons turn over in minutes, hours, days and weeks,\u201d says Raichle. \u201cThe structure of the brain will be different tomorrow but we will still remember who we are.\u201d Or perhaps the activity is part of the reshaping process, tweaking connections while we idle. Several teams have reported changes in resting connectivity after language and memory tasks and motor learning. Chris Miall, a behavioural brain scientist at the University of Birmingham, UK, and his colleagues have shown that spontaneous activity at rest can be perturbed by what has just happened 11 . The team scanned volunteers at rest, and then asked them to learn a task involving using a joystick to track a moving target. When the participants were scanned at rest again, the team could see the effects of motor learning in the resting networks. That study, and subsequent work along the same lines, suggests that \u201cthe brain is not only thinking about supper coming up, but it's also processing the recent past and converting some of that into long-term memories\u201d, says Miall. The network changes are specific to the tasks performed. Work on memory consolidation in animals backs that conclusion. It used to be assumed that memories from the day were strengthened during a night's sleep. Working with rats, however, Loren Frank and Mattias Karlsson, neuroscientists at the University of California, San Francisco, have found 12  that the brain replays and consolidates new memories at any chance it gets \u2014 even when awake. \u201cThese events happen when it doesn't look like the animal is doing very much,\u201d says Frank. He speculates that resting activity could be doing the same thing in human brains \u2014 reactivating patterns that correspond to past experiences. At the same time, activity in the networks could have a normalizing, housekeeping function too. \u201cHow do you keep the brain flexible?\u201d Frank asks. \u201cIf you have random patterns of activity washing through your network, those can help reduce the strength of the pathways associated with what you've just learned.\u201d That would stop the brain from reinforcing the same pathways too often. \u201cPerhaps down-time periods are also important for that,\u201d he says. Shmuel says that it is still not possible to rule out the idea that this activity is just a by-product of the brain being alive. Current may flow through these circuits \u201csimply because there is current \u2014 the brain is not dead \u2014 and there are anatomical connections that give this current a non-random structure\u201d. But, he admits, \u201cI hope this is not the case. Then it's extremely uninteresting.\u201d Narrowing down the range of interesting possibilities may take time, given that the very nature of resting-state science makes it difficult to test hypotheses. When a researcher slides someone into a scanner and instructs them to think about nothing in particular, there is no task to do and no hypothesis to address. So researchers have to generate reams of data and line up hypotheses as they go along. \u201cResting state opens up discovery science,\u201d says Milham enthusiastically, before admitting that, because he trained as a hypothesis-driven cognitive neuroscientist, \u201cit's like heresy that I've got into this\u201d. Whatever resting activity is doing, its existence certainly proves one thing. Miall puts it bluntly: \u201cThe brain only rests when you're dead.\u201d \n                     Diagnosis by default 2012-Mar-06 \n                   \n                     Neuroscience vs philosophy: Taking aim at free will 2011-Oct-01 \n                   \n                     \n                         Nature Reviews Neuroscience  \n                       \n                   \n                     Amir Shmuel \n                   \n                     Michael Greicius \n                   \n                     Marcus Raichle \n                   Reprints and Permissions"},
{"file_id": "489487a", "url": "https://www.nature.com/articles/489487a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "Science and politics are uneasy bedfellows. The first is built on evidence and objectivity; the second thrives on opinion and persuasion. Nowhere is that relationship more fraught than in the United States, where the need to win votes can trump scientific evidence on issues such as climate change and public health \u2014 and where scientists may have little sympathy for political give and take. This week,  Nature  scrutinizes the intersection of politics and science in the run-up to the US election on Tuesday 6 November. With the presidency, all 435 spots in the House of Representatives and 33 of the 100 seats in the Senate at stake, the outcome could change the course of US science for the next four years. When Barack Obama swept into office, he pledged to make science a guiding tenet of his leadership. A News Feature on  page 488  examines how that pledge has fared in the face of hard political realities and crises such as the Deepwater Horizon oil spill. A pair of Comment pieces examines the relationship between scientists and Congress. On  page 494 , Lawrence Goldstein, a stem-cell biologist at the University of California, San Diego, urges researchers to hound their congressional representatives to make the case for funding science. And on  page 493 , Rush Holt, a physicist and Democratic congressman from New Jersey, says that Congress would function better if more of his colleagues thought like scientists, or sought their advice. Such interactions would leave both politicians and scientists better informed \u2014 and the relationship between their fields a little less fraught. \n                 See Editorial \n                 page 473 \n               \n                     Cuts loom for US science 2012-Jul-24 \n                   \n                     Obama shoots for science increase 2012-Feb-14 \n                   \n                     Last-minute wins for US science 2011-Dec-21 \n                   \n                     Nature special: US election 2012 \n                   \n                     US Office of Science and Technology Policy \n                   Reprints and Permissions"},
{"file_id": "490024a", "url": "https://www.nature.com/articles/490024a", "year": 2012, "authors": [{"name": "Ann Finkbeiner"}], "parsed_as_year": "2006_or_before", "body": "A fresh look at our Galaxy points to a chaotic past and a violent end. Arcing across the night sky is a pale band of light the Romans called the  via lactea  \u2014 the Milky Way. Astronomers have known since the 1920s that this band is an edge-on view of the Galaxy in which we live: a vast pinwheel teeming with nebulae, gas clouds and billions upon billions of stars. For most of the nine decades since, astronomers also thought that our Galaxy and others like it were rather quiet places: ponderous, slowly rotating structures that formed many eons ago and had settled into uneventful middle age. But then they began to see the Milky Way with fresh eyes (see \u2018Galactic portrait\u2019). Starting in the 1970s and 1980s, new generations of ground- and space-based telescopes began mapping the Milky Way at wavelengths ranging from microwaves to X-rays, revealing an unimagined richness. By the 2000s, syste-matic observing programmes were tracing galactic structures that sprawl across most of the heavens, and are so big that no one had noticed them before. By the present decade, teams of astronomers were racing to build ever-more powerful computer simulations to model the origins of galaxies on every scale from cosmos to star clusters. And by next year, the Atacama Large Millimeter/Submillimeter Array (ALMA) in Chile will be mapping the Galaxy at unprecedented levels of detail. Astronomers are still struggling to assimilate all this new information. Disagreements, uncertainties and unanswered questions abound. But no one today would argue that our cosmic home town is a quiet backwater. The emerging picture of the Milky Way reveals that the Galaxy was born in chaos and shaped by violence, that it lives in a state of turbulent complexity, and that its future holds certain catastrophe. \n               The dark-matter halo\u2002 \n             Astronomers are still arguing about the precise sequence of events during the Milky Way\u2019s birth, but every-one agrees that the story began with dark matter. The stuff is everywhere, even though it is invisible and no one yet knows what it is. It outweighs ordinary matter \u2014 stars, gas and everything else made of atoms \u2014 by a factor of about five, and yet can be detected only through its gravitational pull on visible stars and galaxies. Astronomers have known since the 1970s that the Milky Way, like every other galaxy, is wrapped in a vast cocoon of dark matter; without it, the gravity generated by ordinary matter would be nowhere near enough to hold the Galaxy together. In the immediate aftermath of the Big Bang, some 13.7 billion years ago, gravity caused tiny irregularities in the dark matter to grow, forming denser and denser clumps on every size scale. Simulations show that this clumping process invariably becomes a chaos of collisions and mergers. But within a billion years of the Big Bang things settle down slightly, and some of the dark-matter clumps begin to look much like the one that surrounds the Milky Way: a roughly spherical halo several hundred kiloparsecs (1\u2009kiloparsec is about 3,200 light-years) across, with a mass of about 10 12  times that of the Sun, and a multitude of subhalos all the way down to the mass of Earth. Inside this halo was a thin haze of primordial hydrogen and helium gas that got pulled along by the dark matter\u2019s gravity. After a few hundred million years, as this gas cooled and condensed enough to start forming stars, it would become the raw material from which our Galaxy was created. But modelling that process is anything but simple. \u201cDark matter answers only to gravity and we understand gravity,\u201d says Piero Madau, an astronomer at the University of California, Santa Cruz. But marshalling ordinary matter into today\u2019s galactic structure involved collisions, dissipations, cooling, heating and explosions. \u201cIt\u2019s very complicated,\u201d says Madau. \n               Dwarf galaxies\u2002 \n             One complication involves those dark-matter subhalos. Above a certain mass, yet to be determined, they would have pulled in enough gas to form stars and become dwarf galaxies \u2014 irregular aggregations of stars and gas with roughly 1% the mass of the modern Milky Way. But if that were the case, the Milky Way ought to have thousands of dwarf galaxies in orbit around it. So far, observers have found some two dozen. One possible explanation for this discrepancy is that there are many more dwarf galaxies, but they are vanishingly faint because they contain unusually high amounts of dark matter. The dwarf galaxy Segue\u00a01, for example, has a thousand times more dark than shining matter 1 . \u201cWe are very, very interested in finding those vanishingly faint ones,\u201d says Connie Rockosi, an astronomer at the University of California, Santa Cruz, \u201cbecause they tell us the threshold mass below which dark-matter subhalos don\u2019t form stars and host galaxies at all.\u201d Another possi-bility is that some subhalos are too small to have ever formed stars, and so are completely dark. Finding such a galaxy-less clump of dark matter means looking for its gravitational effect on nearby dwarf galaxies or on streams of stars, and the signatures of such effects haven\u2019t yet been convincingly seen. \u201cWe\u2019d love to find a dark-matter subhalo without a galaxy in it,\u201d says Rockosi. \u201cThat\u2019s high up on the list of things I hope I see.\u201d Still another possibility is that many more dwarf galaxies did form, but the first generation of stars were all so massive, hot and explosive that they blasted all the gas and stars out of all but the largest subhalos 2 . \n               The stellar halo\u2002 \n             Either way, creation of the Galaxy continued apace, with gas and dwarf galaxies swirling inwards towards an ever-increasing mass of gas and stars accumulating at the dark-matter halo\u2019s centre: the proto-Milky Way. The dwarf galaxies were \u201cwhizzing all over the place\u201d, says Heather Morrison, an astronomer at Case Western Reserve University in Cleveland, Ohio. \u201cThings were just a mess.\u201d Inevitably, some of them would have got too close to the ever-growing core and been pulled apart by its gravity. The region just outside today\u2019s Milky Way seems to be laced with remnants of such events: distinct streams of stars that loop around the galaxy along the dwarf galaxy\u2019s original orbit. These streams are tricky to identify, because they are faint and extend across much of the sky. But teams of observers are finding more and more of them. In at least one case, that of the Sagittarius dwarf galaxy and its associated star stream, observers have found a dwarf galaxy in the act of disintegrating 3 . These streams thread through a faint, diffuse halo of stars that extends outwards from the Milky Way perhaps 100\u2009kiloparsecs in every direction, forming a rough sphere with a total mass of about 10 9  times that of the Sun (see \u2018The big picture\u2019). This stellar halo may be nothing more than the remnant of all the dwarf galaxies that got disrupted over billions of years. But the story may be a little more complicated than that. In 2007, a team led by Daniela Carollo, now at Macquarie University in Sydney, Australia, and Timothy Beers, now director of the Kitt Peak National Observatory in Tucson, Arizona, confirmed earlier hints that the stellar halo is divided into inner and outer components 4 . Stars in the outer halo generally have spectra showing only trace amounts of heavy elements such as iron. This suggests that these stars are only one generation removed from the very first stars to form in the Universe, less than a billion years after the Big Bang. If nothing else, this means that the precise distribution of heavy elements in the outer halo should give astronomers a record of what those long-vanished first stars were like. The stars in the inner halo contain higher amounts of heavy elements, and are somewhat younger \u2014 only about 11.4 billion years old, according to work 5  by Jason Kalirai of the Space Telescope Science Institute in Baltimore, Maryland. In addition, the average motion of the outer halo stars is opposite to that of the Galaxy, whereas the inner halo rotates in the same direction 4 . \n               The disk\u2002 \n             This pattern suggests that the outer halo formed from disrupted dwarf galaxies and the inner halo is a remnant of the maelstrom at the centre, where the proto-Milky Way was collapsing into its modern pinwheel form. The dynamics of this collapse have been understood for decades: every collision among the incoming gas and dwarf galaxies dissipated some of their orbital energy, so that they fell farther inwards. As they approached the centre, what started out as a small, random amount of rotation became magnified. And as the contracting mass spun faster and faster, it steadily flattened into a thin disk. Within the disk, meanwhile, gravitational interactions caused the orbits of the stars and gas clouds to start piling up and causing celestial traffic jams: coiling \u2018density waves\u2019 that formed the spiral arms. (In some galaxies, spiral arms also seem to be the result of shock waves propagating through interstellar gas.) The uncertainties arise when it comes to the details. Did it take a billion years for the disk to form? Ten billion years? \u201cNobody really knows,\u201d says James Bullock, an astronomer at the University of California, Irvine. And how is it that the Milky Way can keep on making stars, when it probably should have run out of raw material billions of years ago? To do that, the Galaxy has to maintain itself as a complex ecosystem in which matter cycles back and forth between stars and interstellar gas. Much of that gas is quite sparse, perhaps a few hundred atoms per cubic metre, and, thanks to ultraviolet light from stars, it drifts through the disk in a hot, ionized form. But in the 1970s, astronomers discovered that sometimes, for reasons that still aren\u2019t completely clear, the gas can gather itself into clouds so dense that their interiors are shielded from starlight. The gas on the inside can get as cold as 10\u201330\u2009K, allowing atoms in the gas to form molecules such as molecular hydrogen and carbon monoxide; thus the name \u2018molecular clouds\u2019. But because of gravity, this density also brings instability. No sooner do the molecular clouds form than their thickest clumps collapse, heating up and igniting by thermonuclear fusion to become stars. These star-forming regions of the clouds, often called the Galaxy\u2019s stellar nurseries, are tumultuous: newborn stars eject matter in the form of fierce stellar winds, along with floods of ultraviolet radiation. The most massive of them also quickly die in supernova explosions; others end their lives by expanding into red giants and shedding their outer layers. All of these processes blast gas back into the wider galaxy, where it will eventually cool, condense and start the cycle again. The problem is that the Milky Way turns gas into stars at the rate of a few solar masses every year, a pace that by now should have used up all the available gas. But the Galaxy has been forming stars for at least the past 10 billion years. \u201cIt\u2019s got to get gas from somewhere,\u201d says Ken Freeman of the Australian National University in Canberra. That somewhere may be an outside reservoir: a halo of gas that\u2019s been observed in X-ray and extreme-ultraviolet wavelengths surrounding the Milky Way\u2019s stellar halo 6 , 7 . Such reservoirs of gas have also been seen around other galaxies 8 . It is mostly ionized hydrogen at maybe 1,000,000\u2009K, and extends a few hundred kiloparsecs from the centre. It is low density, around a hundred hydrogen atoms per cubic metre, but so large that its mass should be at least that of all the stars in the Galaxy \u2014 \u201ca terrific reservoir\u201d, Freeman says, \u201cand just a little of it coming in would kick off star formation\u201d for billions of years. If halo gas does cool and condense enough to fall into the Galaxy \u2014 \u201clike dew settling out of a fog\u201d, says David Weinberg of Ohio State University in Columbus \u2014 it may give rise to what observers see as high-velocity clouds 9 , falling towards the disk. These clouds, in turn, may be related to the \u2018fountains\u2019 that result when stars explode into supernovae and kick gas 10\u2013100 kiloparsecs out of the disk 10 . The theory is that the fountains soar up into the gas halo, pick up some of the ionized gas, and fall back towards the disk as high-velocity clouds. \u201cWe see stuff going out and stuff coming in,\u201d says Weinberg, \u201cbut we don\u2019t know if they\u2019re the same things.\u201d \n               The bulge and bar\u2002 \n             At the Galaxy\u2019s centre, roughly 8 kiloparsecs from Earth, is the bulge: a collection of mostly elderly stars, around 10\u00a0billion years old, arranged in a sphere holding around 10 10  solar masses. Bisecting the bulge is a roughly linear \u2018bar\u2019 of younger stars some 2\u20134 kiloparsecs long. Its origins are a matter of debate, but similar features are commonly seen in other \u2018barred\u2019 spiral galaxies. And at the heart of the bulge is an enormous black hole, which sits at the precise centre of the Galaxy. At 4 million solar masses, our local black hole is on the small side as such objects go: most galaxies seem to have one, and they often reach billions of solar masses. Ours also happens to be inactive at present \u2014 that is, nothing is falling into it. It was once livelier. In 2010, Douglas Finkbeiner (no relation to this writer) at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, found two bubbles on either side of the bulge and perpendicular to the disk 11 . The bubbles were each 7,600 parsecs long and outlined by X-ray emissions; shooting into them from the galactic centre were small, faint \u03b3-ray jets. Both bubbles and jets are signatures of an active black hole, formed when matter falling into the black hole sends out jets of energy and creates shockwaves in the surrounding gas. Active black holes in the centres of galaxies are fairly common and are probably a stage through which all galaxies pass. Finkbeiner estimates that the Milky Way\u2019s black hole was active somewhere around 10 million years ago, and probably at intervals before that too. \u201cThe black hole didn\u2019t get to be 4 million solar masses if nothing fell into it,\u201d he says. \n               The future\u2002 \n             Observers have known for decades that the nearest large galaxy, the spiral M31 in the constellation Andromeda, is heading towards the Milky Way. But they didn\u2019t know whether a collision was inevitable because they hadn\u2019t been able to measure its movement sideways across the sky \u2014 a quantity known as \u2018proper motion\u2019. In May, Roeland van der Marel at the Space Telescope Science Institute and his colleagues compared Andromeda\u2019s position over time with background galaxies, and measured its proper motion to an accuracy of 11 microarcseconds per year 12 , 13 , 14  \u2014 roughly equivalent to watching human fingernails grow from the distance of the Moon. They found that Andromeda and the Milky Way \u2014 now about 770 kiloparsecs apart and moving towards each other at 109 kilometres per second \u2014 will collide head on in about 6 billion years. They will then pass through each other and mutually orbit until, at 7\u00a0billion years, the two spiral galaxies will merge to form one elliptical galaxy. Ellipticals are one of the two main shapes of galaxy. In contrast to the lively spiral galaxies, which tend to be actively forming stars, the ellipticals are more like featureless blobs containing little gas and few new stars. Oddly, only a minority of galaxies seem to be in transition; on the whole they\u2019re either lively or quiescent. Theorists\u2019 best explanation for this is that the merger between two big galaxies leads to a burst of star formation, which quickly uses up the available gas. Or maybe the merger reactivates the black holes in the galaxies\u2019 centres, and the resulting high-energy shocks and jets either drive the gas out of the galaxies or keep the gas stirred up and so hot that it can\u2019t form stars. One way or another, says Tim Heckman of Johns Hopkins University in Baltimore, Maryland, \u201cinfalling gas is cut off and the galaxy uses up the gas it\u2019s got\u201d. The Universe holds only so much gas, and sooner or later \u2014 maybe as long again as galaxies have already existed \u2014 galaxies will have converted all their gas into stars. In the Universe, \u201cstar formation is gradually shutting down\u201d, says Heckman, \u201cand the dead are building up\u201d. Little stars, one-tenth of a solar mass, can live quietly for a trillion years. But even they will eventually burn out \u2014 and that will be it. The end.\n \n                     Andromeda on collision course with the Milky Way 2012-May-31 \n                   \n                     Ghostly jets seen streaming from Milky Way's core 2012-May-30 \n                   \n                     Galactic archaeology: Overcoming great barriers 2009-Jul-01 \n                   \n                     Nearest galactic neighbour discovered 2003-Nov-05 \n                   \n                     Cannibalism feeds growing galaxies 2001-Jul-05 \n                   \n                     Max Planck Institute for astrophysics simulation of Milky Way formation \n                   \n                     Harvard simulation of galaxy formation \n                   \n                     Simulations of Milky Way dark matter \n                   \n                     Simulations of galaxy mergers \n                   Reprints and Permissions"},
{"file_id": "489488a", "url": "https://www.nature.com/articles/489488a", "year": 2012, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Nearly four years after US President Barack Obama pledged to put science in its rightful place,  Nature  asks if he kept his word. On 15 December 2008, president-elect Barack Obama made clear to the world that science would have a central seat in his administration. At a press conference in Chicago, Obama introduced Nobel laureate Steven Chu as the next secretary of the energy department and the person who would help to wean the country off its addiction to climate-warming fossil fuels. \u201cHis appointment should send a signal to all, that my administration will value science,\u201d Obama said. Within days, he announced other members of his future staff, who would make up a star-studded science team (see \u2018The science dream team\u2019): marine ecologist Jane Lubchenco would head the National Oceanographic and Atmospheric Administration in Washington\u00a0DC and physicist John Holdren would be Obama\u2019s science adviser and head the Office of Science and Technology Policy, also in Washington DC. They joined Lisa Jackson, a respected chemical engineer with political experience, who had been named to run the US Environmental Protection Agency (EPA) in Washington DC. After taking office, the president completed the team by appointing geneticist Francis Collins at the National Institutes of Health (NIH) in Bethesda, Maryland, and geophysicist Marcia McNutt at the US Geological Survey in Reston, Virginia. Never before had a president assembled such a strong crop of researchers to lead his science agencies. \u201cThe truth is that promoting science isn\u2019t just about providing resources\u00a0\u2014\u00a0it\u2019s about protecting free and open inquiry,\u201d Obama proclaimed as he made the initial appointments. \u201cIt\u2019s about listening to what our scientists have to say, even when it\u2019s inconvenient\u00a0\u2014\u00a0especially when it\u2019s inconvenient.\u201d \n               boxed-text \n             Scientists and environmentalists swooned; they had spent 8 years complaining that the administration of President George W. Bush had overly politicized science. Climate researchers in government had charged that they were being muzzled and that their data were being manipulated. Pollution regulations were blocked or watered down. With Obama\u2019s election, scientists would finally have a president who not only said the right things but actually appointed the right people. Even journalists drooled. \u201cScience Born Again in the White House, and Not a Moment Too Soon,\u201d read a headline in  Wired  magazine, endorsing Obama\u2019s appointments with a swipe at Bush\u2019s reputation as a born-again Christian. The love affair would soon cool, however, as the Obama administration started to hit a number of obstacles while trying to govern a politically fractured nation in the midst of the worst economic crisis in 70 years. The president has not fulfilled some of his top science-related promises, such as passing climate legislation to reduce the nation\u2019s emissions of greenhouse gases. He has paid relatively little attention to NASA and the NIH, and got into bruising budget wars with Congress that sapped support for some science agencies. And his vaunted team stumbled in its response to the Deepwater Horizon oil spill in the Gulf of Mexico, which damaged the administration\u2019s credibility with some researchers. But as Obama and his science team round out their first term in office and make a bid for a second, they can point to substantial achievements, some of them little noticed. Even in fiscally tight times, Obama has invested heavily in science education and research, particularly in energy. His administration has also made headway in tackling pollution, in part by introducing the country\u2019s first greenhouse-gas regulations. And by driving the creation of integrity policies that seek to protect scientists from political interference (see \u2018Integrity test\u2019), his team has sent positive signals to agencies that had become demoralized during the Bush years. \u201cThe president never let up in his consistent support for science, and actually he got a lot done in spite of the Republican resistance,\u201d says Neal Lane, who was science adviser to former President Bill Clinton and is now a professor at Rice University in Houston, Texas. \n               boxed-text \n             \n               Stimulating science \n             Within a week of the election in November 2008, and with the economy in free fall, Obama\u2019s advisers started working with the scientific community to survey \u2018shovel-ready\u2019 projects for potential inclusion in a stimulus package intended to boost construction and get people back to work. They initially aimed for US$5\u00a0billion in initiatives, but House Democrats doubled that in a draft of the stimulus bill released on 15 January 2009, five days before Obama\u2019s inauguration. And the role of science and innovation continued to grow. On 17 February, exactly 4 weeks into office, Obama signed a $787-billion stimulus bill that contained at least $53 billion for science. The bill made good on Obama\u2019s promises to advance basic and applied research and development aimed at the major problems of the day, including clean energy and global warming. It boosted research funding by $2\u00a0billion at the National Science Foundation in Arlington, Virginia, and by $8.2\u00a0billion at the NIH. As he signed the bill at the Denver Museum of Nature & Science in Colorado, Obama called it the biggest increase in the history of basic-research funding. \u201cYou would have to go back to the 1940s, when Harry Truman became president, to find an administration that was receptive to doing something really significant onscientific research straight out of the box,\u201d says Michael Lubell, who handles government affairs for the American Physical Society in Washington DC and was one of a trio of scientists who helped to compile the initial suggestions for the science stimulus package. \u201cAnd I think part of it has to do with Obama himself. This guy likes science.\u201d In those early months, the science agenda continued to ride high. In April, Obama visited the National Academy of Sciences in Washington DC and proposed a long-term expansion of funding for basic and applied research and development. When he submitted his budget for 2010, Obama fulfilled that promise by including full funding for the America COMPETES Act, a stalled 2007 initiative that called for a doubling of the federal budget for physical sciences. He also increased funding for science and mathematics education. Bigger budgets were not the only things that were fuelling optimism. In March, Obama overturned Bush\u2019s restrictions on using federal funds to support research into human embryonic stem cells, and other early moves by the administration thrilled energy and climate researchers. On 19\u00a0May 2009, the president invited the chief executives of ten of the world\u2019s largest car manufacturers to the White House Rose Garden to announce a historic agreement to establish the first greenhouse-gas standards for US vehicles. For two decades, the companies had been fighting against attempts to make cars more efficient, but the economic crisis and new regulatory authority had given Obama some leverage over the industry. Tough regulations in California had also helped to make car makers more receptive to higher standards. Obama\u2019s team later brokered a pact with the automobile industry to nearly double the average fuel efficiency of cars by 2025, to around 23\u00a0kilometres per litre. \u201cA lot of the credit goes to the president, who really persevered and insisted that this was going to be part of the package,\u201d says Kevin Knobloch, president of the Union of Concerned Scientists, an advocacy group based in Cambridge, Massachusetts. \u201cHe believed that technology was the key to saving the industry.\u201d The deal was part of a broader push by the White House to reduce emissions. In 2007, the Supreme Court had given the EPA the power to regulate greenhouse gases, but the Bush administration had declined to do so. When Jackson came in, she immediately went to work building up the regulatory system. This new-found authority extended beyond vehicles; in theory, the EPA could regulate greenhouse-gas emissions from any source, but neither the president nor Congress preferred that route for cutting emissions. Instead, there were high hopes that Congress would act. In June, the House of Representatives took the first step and passed comprehensive climate legislation seeking to reduce US greenhouse-gas emissions by roughly 80% below 2005 levels by 2050, leaving the Senate as the next big hurdle. But then the climate bill had to wait. Obama and his team wanted first to push a health-care overhaul through Congress that would tame rising costs and expand insurance to millions of Americans. The plan was to deal with health care before Congress took its August break and then shepherd climate legislation through the Senate in time for Obama to take something concrete to the United Nations\u2019 global-warming summit in Copenhagen in December. But the health-care initiative proved divisive and time-consuming. Obama ended up flying into Copenhagen empty-handed. He pledged that the United States would reduce its emissions; but without the backing of law-makers at home, he could make no binding commitments. On Christmas Eve of 2009, the Senate finally passed the health-care legislation. It was a historic achievement, decades in the making, but it would come at a heavy political price. \n               An oily mess \n             If the health-care bill demonstrated the administration\u2019s skills with Congress, then the way it handled NASA in early 2010 revealed how easily relations could sour. When the president rolled out his budget request in February, it held a bitter surprise for congressional supporters of the space agency. On the list of projects to be eliminated was Constellation, a programme to develop massive rockets to return humans to the Moon. \u201c This was a major policy pronouncement but it was revealed in a budget release,\u201d says Scott Pace, director of the Space Policy Institute at George Washington University in Washington DC.Normally, an administration prepares Congress for such a change\u00a0\u2014\u00a0but Obama\u2019s sudden move led to what Pace calls a \u201cbruising, year-long fight\u201d with lawmakers in both parties. Eventually, several parts of the Constellation programme were reinstated. But by then, NASA had become an agency adrift, left to the mercy of parochial interests in Congress. Human space flight and many other elements of NASA\u2019s mission were never priorities of the Obama administration. In the 2013 budget request, the agency\u2019s astrophysics and planetary-science programmes lost 8% of their funding compared with 2008. Obama was more interested in fixing problems with his home planet, and boosted funding for NASA\u2019s Earth-sciences programmes by 44% over the same period. With health care finally out of the way, in early 2010, Obama\u2019s team set out to build a coalition for the president\u2019s climate and energy policies. Obama started on 31 March by announcing a plan to open up large swathes of the US coast, including the eastern Gulf of Mexico and parts of the east coast, to offshore drilling. The decision was enormously controversial, with environmentalists and many lawmakers in his own party, who had opposed such plans for years, arguing that accidents were inevitable. But Obama saw the offshore-drilling expansion as part of a broader strategy to move the US economy from foreign to domestic sources. By increasing oil production, the president also aimed to soften opposition to a comprehensive climate policy that would require cuts in carbon emissions. But any lingering hopes for a climate agreement disappeared in a plume of smoke above the Gulf of Mexico on 20 April. The crisis began with an explosion that killed 11 crewmen on the Deepwater Horizon oil rig. Two days later, the rig sank, leaving untold quantities of oil and gas spewing into the gulf at a daunting depth of some 1,500 metres. British energy giant BP would not succeed in capping the well until 15 July, and the clean-up efforts continued for months. This was Obama\u2019s Hurricane Katrina, and the incident raised questions about the president\u2019s commitment to scientific integrity. Critics charged that administration officials were downplaying the risks by publicizing extremely low estimates of the amount of oil spilling into the gulf and by misstating what was known about the fate of the oil. The administration was also accused of misrepresenting scientists when it said \u2014 incorrectly \u2014 that they had recommended a temporary drilling moratorium, imposed in late May. But the political ramifications went well beyond the crisis in the gulf. The administration\u2019s response kept top officials from several agencies working around the clock for weeks on end, leaving little time or energy for a simultaneous effort to push the climate bill. Worse, the disaster ruptured the shaky coalition that Obama had been trying to build over climate and energy. Most visibly, when his administration responded by placing a moratorium on drilling in the gulf, Republicans argued that the Obama administration was harming US industry through excessive regulations at a time when the economy was still deep in recession. In the run-up to congressional elections in November 2010, Tea Party candidates pushed the idea that the administration was overspending, overregulating and overreaching by exerting government control over issues such as health care. The Republican party swept the Congressional elections, and many ultra-conservative politicians went to Washington DC promising that they would block Obama\u2019s initiatives. Within weeks of arriving, the new Republican-controlled House of Representatives passed a spending bill for 2011 that took aim at Obama\u2019s energy and environment agendas. The measure slashed the budgets of key science agencies by nearly $6.7 billion as part of a broad reduction in federal spending. But Obama and the Democrats in the Senate fought back, and the final budget trimmed core science activities by just $1.2 billion. A similar story would play out during negotiations over the fiscal 2012 budget, and few doubt that Obama will try to protect science this year, which is shaping up to be his biggest budgetary showdown with conservatives yet. The administration deserves credit for recognizing that science is a priority even when times are tough, says Norman Augustine, former chief executive of aerospace and defence firm Lockheed Martin in Bethesda, and the Republican who chaired the 2005 report  Rising Above the Gathering Storm , which made the case for greater federal investment in science. Augustine says that in terms of the science budget over the past few years, \u201cthings are not as bad as they might have been\u201d. \n               Modest goals \n             In late February 2011, just as the new Republican majority was flexing its muscles in the budget battle, energy secretary Chu threw a party to celebrate one of his newest projects: the Advanced Research Projects Agency-Energy (ARPA-E). Former California governor Arnold Schwarzenegger stole the show with a rousing speech calling on Democrats and Republicans to advance the clean-energy research agenda in the name of public health, national security and economic competitiveness, if not global warming. He ended his pep talk quoting one of the film characters he had played, Conan the Barbarian. \u201cConan was not big on philosophical arguments, or navel gazing or complaining,\u201d said Schwarzenegger. \u201cHe believed in action.\u201d Obama would not have chosen the same source of inspiration, but his team shared the sentiment. During the second half of Obama\u2019s term, the administration scaled back some of its grand goals and instead advanced the science agenda through smaller actions. For Chu, ARPA-E was one of the success stories, part of his effort to shake up the Department of Energy and create a more nimble agency that could tackle complex research challenges. Initiated with $400\u00a0million in stimulus money, ARPA-E provides grants for the type of high-risk energy research that industry tends to avoid. Obama and Chu managed to build lasting bipartisan support by convincing Congress that such blue-sky research was key to establishing US leadership in new energy technologies. Even in this year\u2019s tight budget, ARPA-E received $275 million. Chu also battled to create a series of \u2018energy innovation hubs\u2019 to bring together scientists from different disciplines in institutes reminiscent of the defunct Bell Labs, where Chu had done some of his seminal work. The five hubs focus on simulations for nuclear reactors; fuels from sunlight; energy-efficient buildings; energy storage; and critical materials. \u201cHave the energy hubs worked?\u201d asks the American Physical Society\u2019s Lubell. \u201cIt\u2019s too soon to tell, but I give him credit for trying.\u201d Chu paid a political price for his energy agenda when a US solar manufacturer that had received $535 million in federal loan guarantees as part of the stimulus went belly-up in September 2011, in part because competition with Chinese manufacturers had driven down prices for solar cells. Applied research and development has always been a harder sell among conservatives, who fear that the government will \u2018pick winners and losers\u2019, and in this case, Republicans were all too happy to run advertisements pointing out that the government had chosen a loser. Chu was sanguine during congressional testimony in November 2011. \u201cWhen it comes to the clean energy race, America faces a simple choice: compete or accept defeat,\u201d Chu told lawmakers. \u201cI believe we can and must compete.\u201d And even though the climate legislation has stalled, the president\u2019s policies have helped to change the landscape. According to the Office of Science and Technology Policy, the capacity for generating electricity from renewable sources has nearly doubled since Obama took office. A boom in natural-gas production and tightened air-quality regulations have led many utilities to switch from coal to gas, helping to reduce US carbon emissions in the electricity sector. And rising oil production in the United States has cut imports substantially. Obama cannot take credit for all this, but his broad energy policies supported those trends. Roger Pielke Jr, a science-policy expert at the University of Colorado Boulder, says that the administration swerved politically toward the centre on energy and environmental issues after realizing that its climate objectives were unachievable on Capitol Hill. In the end, Pielke says, Obama proved himself to be a policy pragmatist who is more interested in achieving modest goals than in shooting for the Moon. At the NIH, however, Collins did not rein in his big ambitions. In December 2011, he and a few dozen colleagues gathered for beers at the Rock Bottom brewery in Bethesda to cele\u00adbrate one of the biggest changes at the agency in a generation. Collins and his team had succeeded in creating the National Center for Advancing Translational Sciences (NCATS), providing the administration with another victory in applied research. Collins had proposed NCATS a year earlier, to catalyse the ailing process of drug development by attacking bottlenecks in clinical trials, toxicology research and other areas. Although his plan hit some resistance in the NIH, in industry and on Capitol Hill, Collins managed to convince key members of Congress to support the shifting of funds within the NIH to create the $575-million centre, and it opened in the final days of 2011. Some critics question the centre\u2019s mission. At a congressional hearing in March, Roy Vagelos, former chief executive of drug-maker Merck, asked whether anyone believed that NCATS would be able to solve problems that are stumping the pharmaceutical industry. \u201cIf you believe that, you believe in fairies,\u201d he said. In May, Collins announced the first fruits of the centre. Standing with the research chiefs of three top pharmaceutical companies, he unveiled a $20-million effort to resurrect drugs that had passed safety trials but had been shelved by industry for business reasons or because they did not work for specific conditions. Under the agreement, the companies gave NIH-funded scientists a stab at repurposing those compounds. \u201cThe Obama administration is all about innovation,\u201d says Collins. \u201cAnd that\u2019s very much what NCATS means to do.\u201d As the election nears, Obama\u2019s science team is racing to finish up its work. On 28 August, the EPA and the transportation department finalized the changes in vehicle standards that Obama initiated in the rose garden with car makers more than three years ago. In the intervening years, the EPA has moved forward with its Supreme Court authority and begun to lay the groundwork for a broad array of climate regulations. In March, it proposed a rule that would set emissions standards for new power plants and effectively ban coal plants unless they capture and bury carbon dioxide. Looking back over the past four years, Holdren says that \u201cPresident Obama has made an unprecedented commitment to science, technology and innovation. \u2026 He promised on inauguration day to \u2018restore science to its rightful place\u2019\u00a0\u2014\u00a0a promise he has kept in spades.\u201d But even his supporters acknowledge that the president did not achieve some of his biggest science-related goals. Carol Browner served as Obama\u2019s climate and energy adviser during the first two years and led the administration\u2019s push to pass climate legislation. \u201cThere\u2019s the disappointment of not getting legislation,\u201d she says. \u201cBut we didn\u2019t just sit on our hands.\u201d In his speech to the Democratic Convention on 6 September, Obama laid out some of his energy goals, should the country extend his stay in the White House. He talked about further reducing oil imports and advancing natural-gas production. He discussed improving energy efficiency and advancing clean, renewable energies. \u201cAnd yes, my plan will continue to reduce the carbon pollution that is heating our planet because climate change is not a hoax,\u201d he said. But in sharp contrast to the soaring rhetoric and bold plans of 2008, he didn\u2019t make any big promises. Additional reporting by Eric Hand, Meredith Wadman and Eugenie Samuel Reich. See Editorial  page 473 \n                     A second wind for the president 2012-Sep-26 \n                   \n                     US election: Politicians should think like scientists 2012-Sep-26 \n                   \n                     US election: Know your representatives 2012-Sep-26 \n                   \n                     The NIH faces up to hard times 2012-Sep-26 \n                   \n                     Cuts loom for US science 2012-Jul-24 \n                   \n                     Obama shoots for science increase 2012-Feb-14 \n                   \n                     US translational-science centre gets under way 2012-Jan-10 \n                   \n                     Last-minute wins for US science 2011-Dec-21 \n                   \n                     Nature special: US election 2012 \n                   \n                     US Office of Science and Technology Policy \n                   \n                     Advanced Research Projects Agency-Energy \n                   \n                     Department of Energy\u2019s innovation hubs \n                   \n                     National Center for Advancing Translational Sciences \n                   Reprints and Permissions"},
{"file_id": "490022a", "url": "https://www.nature.com/articles/490022a", "year": 2012, "authors": [{"name": "Helen Thompson"}], "parsed_as_year": "2006_or_before", "body": "Once king of eastern forests, the American chestnut was wiped out by blight. Now it is poised to rise again. \u201cThey're hard to breed and easy to kill,\u201d says plant pathologist Fred Hebard as he attacks a 2-metre-tall chestnut tree in southwest Virginia. Hebard bores a hole in the bark and squeezes a mash of orange fungus into the wood. The tree is a hybrid of the Chinese and American chestnut species, and Hebard hopes that it has enough resistance genes to keep the fungus \u2014 called chestnut blight \u2014 at bay. If so, the hybrid could help to resurrect a long-gone icon. Until a century ago, the American chestnut ( Castanea dentata ) was the cornerstone tree species of eastern North America. With long, straight trunks and bushy crowns, it carpeted the forest floor each autumn with prickly brown nuts. But the arrival of chestnut blight ( Cryphonectria parasitica ) from Asia wiped out almost all the stately trees, leaving only a few, isolated stands. Since then, a faithful fan club of scientists and citizens has sought to tame the blight. As chief scientist of the American Chestnut Foundation (ACF), a group of chestnut enthusiasts and scientists, Hebard has bred thousands of hybrids at the organization's research farm in Meadowview, Virginia. He crosses descendants of the original American chestnut with the much smaller Chinese variety ( Castanea mollissima ), which has some natural immunity to the Asian fungus. And after decades of work, he is within reach of his goal, a tall American tree with enough Chinese traits to keep it healthy. Other researchers are trying to attack the blight with viruses or are creating trees that are genetically modified (GM) to resist the fungus, and could be the first GM forest trees released in the wild in the United States. Progress with all three approaches is raising hopes that chestnuts will soon start to flourish again in the forests of the American east. \u201cWe're starting to pull the American chestnut tree back from the brink of extinction,\u201d says Hebard. The work is also offering lessons that could help to save other trees, such as elm and ash, which face similar threats in America and abroad. \n               From giants to stumps \n             Once known as the sequoia of the east, the American chestnut was one of the tallest trees in the forest, and dominated a range of 800,000 square kilometres, from Mississippi to Maine (see 'Felled by a fungus'). It made up 25% of the forest, and its annual nut crop was a major source of food for both animals and humans. The decay-resistant wood was also used to make telephone poles, roofs, fence posts and parts of railway lines. The first warning signs came in 1904, when rust-coloured cankers developed on chestnuts at the Bronx Zoo in New York. Zoo forester Hermann Merkel took a sample across the street to the New York Botanical Garden, where mycologist William Murrill soon identified the spores as chestnut blight. The blight probably hitched a ride on nursery imports of Japanese chestnuts beginning in 1876. Spreading through rain and air, fungal spores infected trees through bark wounds and breaks. Cankers developed, quickly encircling a branch or trunk and cutting off the supply of water and nutrients from the soil. Within 50 years, the blight had laid waste to nearly the entire population of some 4 billion trees. Other hardwoods, mainly oak, eventually filled the void but they do not produce a consistent crop of nuts every year. \u201cYou had a really dominant species that the wildlife depended on which was then replaced with a species that then didn't produce as much,\u201d says Douglass Jacobs, a forest ecologist at Purdue University in West Lafayette, Indiana. Reports from the period suggest that squirrel populations initially collapsed, and that five moth species dependent on chestnuts went extinct (D. A. Orwig  J. Biogeogr.   29 , 1471\u20131474; 2002 ). As the chestnut succumbed to the blight, scientists raced to find solutions. They started breeding hybrids of American and Asian chestnuts, which have evolved alongside the blight. But the attempts produced no trees that were sufficiently resistant yet still had enough American traits to make them a popular replacement. Asian chestnuts are shorter and less sturdy than their American counterparts. Over the years, chestnut lovers have tried a range of remedies, including fungicides, sulphur fumes and radiation. They even conducted religious ceremonies, assuming that the sins of the people had brought on the blight. But all these strategies failed. \n               Restoration chestnut \n             In 1983, a group of plant scientists joined together to form the ACF with the goal of creating a resistant tree. The foundation has since grown to 6,000 volunteer members, ranging from retired physicists to farmers, and it maintains 486 regional breeding orchards and 120,000 experimental trees. At Meadowview Research Farm, where Hebard is based, a refrigerator holds prized pollen from American chestnuts and between 600 and 700 strains of the fungus. The valley and hillsides are lined with rows of hybrid chestnuts as well as unadulterated American, Chinese and Japanese chestnuts ( Castanea crenata ). Some have plastic bags covering their flowers to prevent unwanted natural pollination from ruining the experiments. \u201cIt's a chastity belt for chestnuts,\u201d jokes Hebard. \u201cYou bag it if you want to know who the daddy is.\u201d Nearby are rows of chestnuts that stand about a metre tall, the most promising hybrid yet to emerge from nearly 30 years of breeding experiments. This 'restoration chestnut' is 94% American and 6% Chinese and seems to show strong resistance to the blight. But the Virginia trees may not thrive in other locations, so the researchers are working to adapt the restoration chestnut to other climates. At the same time, they are breeding new hybrids at other experimental farms to preserve a healthy degree of genetic diversity. More than 1,100 kilometres to the north, researchers are experimenting with chestnuts that contain genes thought to provide resistance, which were taken from Chinese chestnuts as well as plants such as wheat, peppers and grapes. At the State University of New York in Syracuse, plant pathologist Bill Powell and forest biologist Chuck Maynard have planted some 600 transgenic trees for field trials of disease resistance. A transgenic variety with a wheat gene for the enzyme oxalate oxidase, which disarms the fungus, has already shown resistance in the field. Maynard, Powell and their colleagues are collaborating with a non-profit organization called the Forest Health Initiative in Research Triangle Park, North Carolina, to develop a GM version of an American chestnut with strong resistance based on genes from Asian chestnuts. Because such 'cisgenic' trees contain only chestnut genes, researchers hope that the trees won't provoke strong public objection. The Forest Health Initiative is testing the cisgenic chestnuts now and aims to obtain federal approval to conduct larger plantings. \u201cChestnut may be the first case of a genetically engineered tree that's planted out. If that happens it can probably pave the way for other trees,\u201d says Jacobs. Along the way, the transgenic work will help researchers to determine which resistance genes are the most useful. Other researchers are enlisting viruses that attack the chestnut fungus. Such viruses spread most easily among closely related fungi and are effective at controlling the blight in Europe. But American fungal strains are more diverse, so the virus cannot spread as effectively. To get around that problem, virologist Don Nuss at the University of Maryland in College Park has developed a transgenic fungus that is designed to spread the virus more easily. Other researchers are conducting field trials to test whether the engineered fungus can compete with \u2014 and replace \u2014 wild-type fungal strains. If so, the viruses could be used in targeted ways to protect American chestnuts. Most researchers agree that restoring the American chestnut will require a combination of fungal viruses and resistant trees, whether hybrid, GM or a mixture of both. And the trees will need to defend themselves against more than just the blight. Researchers are also concerned about the threat of diseases already attacking other trees, such as root rot mould ( Phytophthora cinnamomi ) and invasive insects, including ambrosia beetles and gall wasps. Hybridization and transgenic programmes are beginning to target some of these threats. Lessons learned from the battle to restore the chestnut could help save other threatened trees. The American elm ( Ulmus americana ) and its European counterpart ( Ulmus laevis ) have been hit hard by Dutch elm disease, and ash and hemlock are succumbing to invasive insects. In the United Kingdom, the beloved horse chestnut ( Aesculus hippocastanum ) is in danger of being wiped out by a combination of a bacterium and a moth. Researchers are developing hybrid and transgenic programmes to defend against many of those threats. \n               Never-ending battle \n             \u201cIt's the pest of the month club. We've lost chestnut and lost elm. Now, it's almost a new species or pest is being identified and a new tree or forest is being threatened almost on a monthly basis,\u201d says Carlton Owen, a forester and wildlife biologist who chairs the Forest Health Initiative's governing board. Owen says that the results of the chestnut work will help researchers to protect other species by showing which strategies work best in different situations and by testing public acceptance of GM trees. Once researchers have a resistant chestnut, the question is where to plant it. Forest ecosystems have transformed in the past century, and reintroducing the chestnut could upset the new ecological balance. \u201cYou can't assume that a forest with chestnut is better than a forest without. You can't roll the clock back,\u201d says Steve Hamburg, chief scientist at the Environmental Defense Fund in Boston. \u201cReintroduction is going to be kind of a gradual thing,\u201d says Jacobs. In 2009, the ACF began planting restoration chestnuts on US Forest Service land in Virginia, Tennessee and North Carolina. In April 2012, it also started planting hybrid chestnuts and other hardwood saplings at a former mining site. For chestnut lovers, other signs of hope stand alongside a path at the New York Botanical Garden. In a corner of the garden, a transgenic chestnut and a restoration hybrid both reach about a metre high. Although their leaves have shrivelled a bit, the scrappy saplings have managed to survive one of the warmest summers on record. And their bark is smooth, with no sign of the cankers that claimed their ancestors. \n                     Forest fires: Burn out 2012-Sep-19 \n                   \n                     Plant pathology: Sudden larch death 2010-Aug-11 \n                   \n                     GM crops: Battlefield 2009-Sep-02 \n                   \n                     Plant pathology: The rise of the hybrid fungi 2000-May-11 \n                   \n                     Chestnut Blight 1951-Sep-08 \n                   \n                     The American Chestnut Foundation \n                   \n                     American Chestnut Research and Restoration Project \n                   \n                     Forest Health Initiative \n                   \n                     Connecticut Chestnut Research \n                   Reprints and Permissions"},
{"file_id": "490165a", "url": "https://www.nature.com/articles/490165a", "year": 2012, "authors": [{"name": "Virginia Hughes"}], "parsed_as_year": "2006_or_before", "body": "Most people bounce back from trauma \u2014 but some never recover. Scientists are trying to work out what underlies the difference. On a chilly, January night in 1986, Elizabeth Ebaugh carried a bag of groceries across the quiet car park of a shopping plaza in the suburbs of Washington DC. She got into her car and tossed the bag onto the empty passenger seat. But as she tried to close the door, she found it blocked by a slight, unkempt man with a big knife. He forced her to slide over and took her place behind the wheel. The man drove aimlessly along country roads, ranting about his girlfriend's infidelity and the time he had spent in jail. Ebaugh, a psychotherapist who was 30 years old at the time, used her training to try to calm the man and negotiate her freedom. But after several hours and a few stops, he took her to a motel, watched a pornographic film and raped her. Then he forced her back into the car. She pleaded with him to let her go, and he said that he would. So when he stopped on a bridge at around 2 a.m. and told her to get out, she thought she was free. Then he motioned for her to jump. \u201cThat's the time where my system, I think, just lost it,\u201d Ebaugh recalls. Succumbing to the terror and exhaustion of the night, she fainted. Ebaugh awoke in freefall. The man had thrown her, limp and handcuffed, off the bridge four storeys above a river reservoir. When she hit the frigid water, she turned onto her back and started kicking. \u201cAt that point, there was no part of me that thought I wasn't going to make it,\u201d she says. Few people will experience psychological and physical abuse as terrible as the abuse Ebaugh endured that night. But extreme stress is not unusual. In the United States, an estimated 50\u201360% of people will experience a traumatic event at some point in their lives, whether through military combat, assault, a serious car accident or a natural disaster. Acute stress triggers an intense physiological response and cements an association in the brain's circuits between the event and fear. If this association lingers for more than a month, as it does for about 8% of trauma victims, it is considered to be post-traumatic stress disorder (PTSD). The three main criteria for diagnosis are recurring and frightening memories, avoidance of any potential triggers for such memories and a heightened state of arousal. Ebaugh experienced these symptoms in the months after her attack and was diagnosed with PTSD. But with the help of friends, psychologists and spiritual practices, she recovered. After about five years, she no longer met the criteria for the disorder. She opened her own private practice, married and had a son. About two-thirds of people diagnosed with PTSD eventually recover. \u201cThe vast majority of people actually do OK in the face of horrendous stresses and traumas,\u201d says Robert Ursano, director of the Center for the Study of Traumatic Stress at the Uniformed Services University of the Health Sciences in Bethesda, Maryland. Ursano and other researchers want to know what underlies people's mental strength. \u201cHow does one understand the resilience of the human spirit?\u201d he asks. Since the 1970s, scientists have learned that several psychosocial factors \u2014 such as strong social networks, recalling and confronting fears and an optimistic outlook \u2014 help people to recover. But today, scientists in the field are searching for the biological factors involved. Some have found specific genetic variants in humans and in animals that influence an individual's odds of developing PTSD. Other groups are investigating how the body and brain change during the recovery process and why psychological interventions do not always work. The hope is that this research might lead to therapies that enhance resilience. \n               A natural response \n             Although no one can fully understand what was going on in Ebaugh's mind during her attack, scientists have some idea of what was happening to her body. As soon as Ebaugh saw her attacker and his knife, her brain's pituitary gland sent signals to her adrenal glands, atop the kidneys, to start pumping out the stress hormones adrenaline and cortisol. In turn, her pulse quickened, her blood pressure rose and beads of sweat formed on her skin. Her senses sharpened and her neural circuits formed strong memories, so that if she ever encountered this threat in the future, she would remember the fear and flee. The repercussions were profound. For the first week after the abduction, \u201cI felt like a newborn baby\u201d, Ebaugh says, \u201clike I had to be held, or at least be in the presence of somebody\u201d. She shivered constantly, was easily startled and felt only fear. She could not go near the grocery store. Nearly every trauma victim experiences PTSD symptoms to some degree. Many people who are diagnosed with the disorder go on to have severe depression, substance-abuse problems or suicidal thoughts. PTSD can take a horrific toll. Between 2005 and 2009, as a growing number of soldiers faced multiple deployments in Iraq and Afghanistan, suicide rates in the US Army and Marines nearly doubled. Over the past two decades, researchers have used various kinds of imaging techniques to peer inside the brains of trauma victims. These studies report that in people with PTSD, two areas of the brain that are sensitive to stress shrink: the hippocampus, a deep region in the limbic system important for memory, and the anterior cingulate cortex (ACC), a part of the prefrontal cortex that is involved in reasoning and decision-making. Functional magnetic resonance imaging (fMRI), which tracks blood flow in the brain, has revealed that when people who have PTSD are reminded of the trauma, they tend to have an underactive prefrontal cortex and an overactive amygdala, another limbic brain region, which processes fear and emotion (see 'The signature of stress'). People who experience trauma but do not develop PTSD, on the other hand, show more activity in the prefrontal cortex. In August 1 , Kerry Ressler, a neuroscientist at Emory University in Atlanta, Georgia, and his colleagues showed that these resilient individuals have stronger physical connections between the ACC and the hippocampus. This suggests that resilience depends partly on communication between the reasoning circuitry in the cortex and the emotional circuitry of the limbic system. \u201cIt's as if [resilient people] can have a very healthy response to negative stimuli,\u201d says Dennis Charney, a psychiatrist at the Mount Sinai School of Medicine in New York, who has conducted several brain-imaging studies of rape victims, soldiers and other trauma survivors. \n               Environmental protection \n             After her abduction, Ebaugh began seeing a psychotherapist and several alternative-medicine practitioners. But more than anything else, she attributes her resilience to being surrounded by caring people \u2014 beginning within minutes of her escape. After Ebaugh crawled up the rocky riverbank, a truck driver picked her up, took her to a nearby convenience store and bought her a cup of hot tea. Police, when they arrived, were sympathetic and patient. The doctor at the hospital, she says, treated her like a daughter. A close friend took her in for a time. And her family offered reassurance and emotional support. \u201cFor the first month, I almost had to tell people to stop coming because I was so surrounded by friends and community,\u201d she says. Studies of many kinds of trauma have shown that social support is a strong buffer against PTSD and other psychological problems. James Coan, a psychologist at the University of Virginia in Charlottesville, has done a series of experiments in which women lie in an fMRI scanner and see 'threat cues' on a screen. They are told that between 4 and 10 seconds later, they may receive a small electric shock on the ankle. The cue triggers sensory arousal and activates brain regions associated with fear and anxiety, but when the women hold the hands of their husbands 2  or friends 3 , these responses diminish. Social interactions are complex and involve many brain circuits and chemicals; no one knows exactly why they provide relief. Being touched by someone is thought to stimulate the release of natural opioids, such as endorphins, in the brain. The ACC is packed with opioid receptors, suggesting that touch could influence its response to stress. Other clues come from the hormone oxytocin, which courses through the brain during social interaction and has been shown to boost trust and reduce anxiety. In one imaging study 4 , participants viewed frightening images after receiving nasal sprays of either oxytocin or a placebo. Those who sniffed oxytocin showed reduced activation in the amygdala and weaker connections between the amygdala and the brainstem, which control some stress responses, such as heart rate. The oxytocin surge that comes from being around other people could, like endorphins, help to reduce the stress response. Past social interactions may also affect how a person responds to trauma. Chronic neglect and abuse unquestionably lead to a host of psychological problems and a greater risk of PTSD. Ressler, however, points to a factor that is well recognized but poorly understood: 'stress inoculation'. Researchers have found that rodents 5  and monkeys 6 , at least, are more resilient later in life if they experience isolated stress events, such as a shock or a brief separation from their mothers, early in infancy. Ebaugh says that early stress \u2014 and the confidence she gained in conquering it \u2014 helped her to recover from her traumatic abduction. She was born with a condition that made her feet turn inwards. At age ten, she underwent surgery to rebuild her knees followed by a year of intensive rehabilitation. \u201cIt wasn't foreign to me to be hurt and have to walk the walk of being strong again,\u201d she says. \u201cIt's like a muscle, I think, that gets built up.\u201d \n               Resilient by nature \n             Although most people, like Ebaugh, recover from trauma, some never do. Some scientists are seeking explanations for such differences in the epigenome, the chemical modifications that help to switch genes on and off (see  page 171 ). Others are looking in the genes themselves. Take, for example,  FKBP5 , a gene involved in hormonal feedback loops in the brain that drive the stress response. In 2008, Ressler and his colleagues showed that in low-income, inner-city residents who had been physically or sexually abused as children, certain variants in  FKBP5  predisposed them to developing PTSD symptoms in adulthood. Other variants offered protection 7 . The most talked-about biological marker of resilience is neuropeptide Y (NPY), a hormone released in the brain during stress. Unlike the stress hormones that put the body on high alert in response to trauma, NPY acts at receptors in several parts of the brain \u2014 including the amygdala, prefrontal cortex, hippocampus and brainstem \u2014 to help shut off the alarm. \u201cIn resiliency, these brake systems are turning out to be the most relevant,\u201d says Renu Sah, a neuroscientist at the University of Cincinnati in Ohio. Interest in NPY and resilience took off in 2000, partly because of a study of healthy US Army soldiers who participated in a survival course designed to simulate the conditions endured by prisoners of war, such as food and sleep deprivation, isolation and intense interrogations 8 . NPY levels went up in the soldiers' blood within hours of the interrogations. Special Forces soldiers who had trained to be resilient had significantly higher NPY levels than typical soldiers. Researchers are now conducting animal experiments to study how NPY works. In one experiment, a team at the Indiana University School of Medicine in Indianapolis restrained a rat in a tight-fitting plastic pouch for 30 minutes, then released it into a box with another rat 9 . The restraint made the rat so anxious that it avoided interacting with the other animal for 90 minutes. But when rats were injected with NPY before the treatment, they interacted with cage-mates as if nothing had happened. The work could lead to treatments. Charney's group at Mount Sinai is carrying out a phase II clinical trial of an NPY nasal spray for individuals with PTSD. Others are investigating small molecules that can cross the blood\u2013brain barrier and block certain receptors that control NPY release. \n               Conflict resolution \n             The US military is leading the hunt for additional biological markers of resilience. Since 2008 \u2014 driven in part by soaring suicide rates among soldiers \u2014 the US Army has collaborated with the National Institute of Mental Health and several academic institutions on a US$65-million project called Army STARRS (the Study to Assess Risk and Resilience in Servicemembers). The project has many parts, including a retrospective look at de-identified medical and administrative records for 1.6 million soldiers, in search of early warnings of suicide, PTSD and other mental-health problems. STARRS scientists are also collecting data \u2014 such as blood samples, medical histories and cognitive testing results \u2014 on tens of thousands of current soldiers. The researchers expect to publish their first findings early next year. The military also funds research into animal models of resilience. Most rodents will quickly learn to associate painful foot shocks with a certain cue, such as a tone or a specific cage. After they have learned the association, the rodents freeze on experiencing the cue, even without the shock. Several years ago, Abraham Palmer, a geneticist now at the University of Chicago in Illinois, made a line of resilient mice by selectively breeding mice that froze for abnormally short periods of time. After about four generations, he had mice that froze for about half the time of typical animals 10 . The effect was not due to a difference in pain sensitivity or general learning ability. This month, Luke Johnson, a neuroscientist at the Uniformed Services University, will present data at the Society for Neuroscience meeting in New Orleans, Louisiana, showing that these mice have uncommonly low activity in the amygdala and hippocampus, consistent with human studies of PTSD resilience. They also have low levels of corticosterone, a stress hormone, in their urine. \u201cThey have a quieter system, even at rest,\u201d says Johnson. \u201cIt suggests that there are underlying biological traits that are associated with the capacity of the animal for fear memory.\u201d In future experiments, Johnson plans to use the mice to study NPY and potential new therapies. Ebaugh, who now specializes in therapy for trauma victims, agrees that drug-based treatments could aid in recovery. But some people may find relief elsewhere. Religious practices \u2014 especially those that emphasize altruism, community and having a purpose in life \u2014 have been found to help trauma victims to overcome PTSD. Ebaugh says that yoga, meditation, natural remedies and acupuncture worked for her. Today, she buys groceries at the plaza where she was abducted, and she drives over the bridge she was thrown from as though it were any other road. She says that she has forgiven the man who abducted her. When she reflects on what he did, it's not with anger, sadness or fear. \u201cIt doesn't feel like it affects my life at all at this point, at least not in a negative way,\u201d she says. \u201cIn a positive way, it's been a huge teacher.\u201d \n                     Gene linked to post-traumatic stress 2012-May-14 \n                   \n                     Can a traumatic brain injury explain a killing spree? 2012-Mar-20 \n                   \n                     Psychiatry: A molecular shield from trauma 2011-Feb-23 \n                   \n                     Drug banishes bad memories 2009-Feb-13 \n                   \n                     Nature Stress and Resilience Special \n                   Reprints and Permissions"},
{"file_id": "490162a", "url": "https://www.nature.com/articles/490162a", "year": 2012, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Scientists are testing the idea that the stress of modern city life is a breeding ground for psychosis. In 1965, health authorities in Camberwell, a bustling quarter of London's southward sprawl, began an unusual tally. They started to keep case records for every person in the area who was diagnosed with schizophrenia, depression, bipolar disorder or any other psychiatric condition. Decades later, when psychiatrists looked back across the data, they saw a surprising trend: the incidence of schizophrenia had more or less doubled, from around 11 per 100,000 inhabitants per year in 1965 to 23 per 100,000 in 1997 \u2014 a period when there was no such rise in the general population (J. Boydell  et al .  Br. J. Psychiatry   182 , 45\u201349; 2003 ). The result raised a question in many researchers' minds: could the stress of city life be increasing the risk of schizophrenia and other mental-health disorders? The question is an urgent one. Back in 1950, less than one-third of the world's population lived in cities. Now, lured by the prospect of work and opportunity, more than half do. Mental illnesses already comprise the world's biggest disease burden after infectious diseases and, although global statistics do not yet show any major increase in incidence, the cost is rising. In Germany, the number of sick days taken for psychiatric ailments doubled between 2000 and 2010; in North America, up to 40% of disability claims for work absence are related to depression, according to some estimates. \u201cIt seems that cities may be making us sick,\u201d says Jane Boydell at the Institute of Psychiatry in London, who led the Camberwell study. Anecdotally, the link between cities, stress and mental health makes sense. Psychiatrists know that stress can trigger mental disorders \u2014 and modern city life is widely perceived as stressful. City dwellers typically face more noise, more crime, more slums and more people jostling on the streets than do those outside urban areas. Those who have jobs complain of growing demands on them in the workplace, where they are expected to do much more in less time. But the idea has not been widely tested. It is difficult to study whether something as complex as a 'city environment' has an impact on the brain. To complicate matters, many growing cities include immigrant populations, which already have an increased risk of psychiatric disease associated with social isolation. Now, a few scientists are tackling the question head on, using functional brain imaging and digital monitoring to see how people living in cities and rural areas differ in the way that their brains process stressful situations. \u201cYes, city-stress is a big, messy concept, but I believed it should be possible to at least see if brains of city-dwellers looked somehow different,\u201d says Andreas Meyer-Lindenberg, director of the Central Institute for Mental Health in Mannheim, Germany. And if scientists can work out what aspects of the city are the most stressful, the findings might even help to improve the design of urban areas. \u201cEveryone wants the city to be beautiful but no-one knows what that means,\u201d says Meyer-Lindenberg. Wider streets? Taller buildings? More trees? \u201cArchitects theorize a lot, but this type of project could deliver a scientific basis for a city code.\u201d \n               Relentless stress \n             Considered from an evolutionary standpoint, the physiological stress response is definitely a good thing: it helps mammals to survive. Any threat, whether from a predator, dwindling food supplies or an aggressive enemy, triggers release of hormones such as cortisol and adrenaline. These hormones raise levels of sugar in the blood and redistribute blood flow to muscles and lungs, so that animals can respond to the threat by running, hunting or fighting. Problems arise when the stress response doesn't switch off. Stress-hormone levels that stay too high for too long cause high blood pressure and suppress the immune system. And, although the mechanisms are unknown, scientists agree that severe or prolonged stress also raise the risk of psychiatric disease \u2014 most brutally in those who have a genetic predisposition, and when the stress occurs while the brain is still developing. In theory, then, the ceaseless challenges of the city could produce this kind of damaging stress. Some fear that they could end up driving an increase in mental illness around the world. The only signs of an increase, however, come from relatively small, local studies. \u201cIt's frustrating \u2014 we feel it should be rising,\u201d says Ronald Kessler, a mental-health epidemiologist at Harvard Medical School in Boston, Massachusetts. \u201cBut globally we have not seen this, and there are also studies which indicate it isn't even rising in cities.\u201d However, reliable data on the prevalence of psychiatric disease are hard to find because diagnoses are often imprecise or incompletely recorded. The Camberwell study was influential because, unusually, it captured all those who were diagnosed with a mental disorder, even if they were not admitted to hospitals, and the researchers involved carefully reviewed every case. Published in 2003, the Camberwell study deeply impressed Meyer-Lindenberg, who was then at the US National Institute for Mental Health in Bethesda, Maryland, researching how genetic risk factors for schizophrenia affect brain function. As a student in Manhattan some years earlier, Meyer-Lindenberg says, \u201cI had been struck by the number of homeless mentally ill people on the streets, and the problems of the city somehow resonated with me\u201d. He wondered if city living was somehow making the brain more susceptible to mental-health conditions. When he returned to his native Germany in 2007, he decided to tackle the question directly. But at the time, Meyer-Lindenberg says, \u201cpeople said the effect would be too subtle to make sense of\u201d. Yet the results of his study, published last year in  Nature  (F. Lederbogen  et al .  Nature   474 , 498\u2013501; 2011 ), clearly showed that people who grow up in cities process negative emotions such as stress differently from those who move to the city as adults. His team scanned the brains of 55 healthy volunteers as they carried out arithmetic tasks under a constant bombardment of negative social feedback. \u201cWe'd always let them know through headphones that we thought they were failing, or at least not doing as well as other subjects we'd had in the scanner,\u201d says Meyer-Lindenberg. \u201cIn one set of experiments we let them see our impatient faces on computer screens.\u201d This social stress activated two brain areas \u2014 but the pattern depended on the volunteers' histories of urban living. The amygdala, which processes emotion, showed much greater activity in people who were currently living in a city. And the cingulate cortex, which helps to regulate the amygdala and processes negative emotion, responded more strongly in those brought up in large cities than in those brought up in the countryside, irrespective of where they lived now. Meyer-Lindenberg thinks that this over-responsiveness to stress could make city-dwellers more prone to psychiatric conditions such as schizophrenia \u2014 and his results chime with the idea that stress in childhood or adolescence can have a lasting effect on the brain's development and increase susceptibility to psychiatric disease. Other scientists are following Meyer-Lindenberg's lead. Daniel Weinberger, director of the Lieber Institute for Brain Development in Baltimore, Maryland (and a self-confessed addict \u201cto the cultural stimulation of the city\u201d), is planning a huge, long-term project to study environmental and genetic risk factors for schizophrenia in China, where urbanization is happening at lightning speed. The proportion of people living in cities there has doubled in the past two decades, to more than half. Together with colleagues at Peking University in Beijing, Weinberger hopes to study thousands of people who moved to Beijing from the countryside before they were 12 years old, after they turned 18 and between the two ages. He will use brain imaging and genetic analyses to try to understand how urban upbringing and genes alter cognition and reasoning, functions that are often disrupted in schizophrenia. Researchers suspect that the stress of city living leads to psychiatric disease mainly in people who are already at risk because of other environmental stresses or because they carry risk genes. One candidate gene, the details of which have not yet been published, has emerged from a large brain-imaging study being conducted by Meyer-Lindenberg in Iceland. He chose more than 500 people who had been identified by the Reykjavik-based company deCODE Genetics as carrying rare mutations that confer a high risk of schizophrenia, and subjected them to functional magnetic resonance imaging tests similar to the ones he used in his city study. \u201cWe've already found that people carrying that one particular gene variant activate the cingulate cortex when they process social stress, just like those who were brought up in cities,\u201d he says. He expects to find many more gene candidates through the project, which will run for several more years. Identifying which parts of a busy city life are the most stressful is another massive challenge (see 'Stress and the city'). The common urban experience of feeling different from your neighbours because of socioeconomic status or ethnicity could be one factor, Meyer-Lindenberg thinks. If so, immigrant groups, who often experience isolation, may be processing stress in a similar way to city-dwellers. He is now testing this hypothesis in the children of immigrants to Germany. (First-generation immigrants are not suitable because the stress of social isolation could be confounded by the stress of moving country.) Jim van Os, a psychiatrist and epidemiologist at Maastricht University in the Netherlands, is planning a detailed look at city living to identify sources of stress. \u201cIt had been slowly dawning on me that as we know that the brain interacts with the environment, nothing about mental health will become clear unless we can look at the environment,\u201d he says. Van Os has developed a smart-phone app that allows participants to record their moods, thoughts, location and activities as they go about their daily lives. \u201cThis is important because mood and affect change dynamically in the brain, just as blood pressure does,\u201d he says. In a \u20ac2-million (US$2.6-million) field study, van Os intends to use the app to collect regular information on these factors from 264 people who have started to show psychological disturbance. He will combine these data with brain imaging to test his hypothesis that risk of progressing from disturbance to full-blown psychosis is connected to a distorted ability to learn which aspects of a new environment are rewarding and which are threatening. \u201cFor example,\u201d he says, \u201cif you move to a new district, you'll need to quickly learn which neighbours you like enough to develop a relationship with, and how to interpret social signals that could be harmful.\u201d Meyer-Lindenberg is planning an even more technologically ambitious project with geoscientists at the nearby University of Heidelberg, who have generated a high-resolution map of their city, and physicists at the Karlsruhe Institute of Technology in Germany, who have developed a mobile device that allows people to be tracked and tested for a week as they walk and work around Heidelberg. The device can recognize when participants reach a specific location \u2014 such as a green space or a particularly noisy intersection \u2014 and instantly question them about their state of mind or send them a cognitive test to be completed on the spot. The scientists will then ask the participants to come into the lab for brain-imaging studies that examine how they process stress and emotion. By correlating the imaging data with their states of mind at different locations, the team hopes to trace how different aspects of city life affect the brain \u2014 whether, for example, strolling through a park really does have a calming influence on the amygdala and cingulate cortex. It is a high-risk project that has yet to tempt funders. But Meyer-Lindenberg sees the future of the city in it. So too does Annette Rudolph-Cleff, an architect and city planner at the Technical University of Darmstadt in Germany, who contacted Meyer-Lindenberg after reading his  Nature  paper last year and is now advising him on the project. \u201cWe know far too little about the city at the moment and we need these new technologies and approaches to help us make decisions about how the city should best be developed,\u201d she says. As well as helping in the design of future cities, such work might also pinpoint the most stressful parts of an existing metropolis \u2014 and help to make a case for urban regeneration. Cities are already great economic and cultural incubators; Rudolph-Cleff hopes that the new science of urban stress could also allow them to be turned into cradles of mental health. See Editorial  p.143 \n                     A radical approach to mental illness 2011-Sep-06 \n                   \n                     City living marks the brain 2011-Jun-22 \n                   \n                     Schizophrenia: The drug deadlock 2010-Nov-10 \n                   \n                     Nature special on stress and resilience \n                   \n                     Schizophrenia special \n                   \n                     Neuropsychiatric-disease supplement \n                   \n                     Andreas Meyer-Lindenberg lab \n                   Reprints and Permissions"},
{"file_id": "490161a", "url": "https://www.nature.com/articles/490161a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "A special section of  Nature  traces the emerging links between stress and mental illness. A battlefield; an abusive parent; the ongoing struggle to make ends meet; a pile-up of unanswered e-mails \u2014 stress can take many forms. But stressful situations have something in common: they trigger reactions such as fear and a surge of hormones. These responses can be beneficial in the short term but, if severe or prolonged, can damage the mind, triggering conditions ranging from depression to post-traumatic stress disorder. That much has been known for decades; now researchers are getting to grips with how stress can alter the biology of the brain, and tip a mind into illness. Here,  Nature  takes a look at what they have learned, and at the gaps that remain. Modern life \u2014 with more people, more pressure and more gadgets \u2014 certainly seems more stressful than life in the past, but how does it affect the mind? Some scientists are seeking answers by examining how the brains of city- and country-dwellers process stressful situations ( see page 162 ). Others are looking for the molecular scars left by stress. Neuroscientist Eric Nestler argues that stress may influence the brain through epigenetics, mechanisms that change how genes behave ( see page 171 ). Biologists Elizabeth Blackburn and Elissa Epel, meanwhile, suggest that stress causes chronic diseases in part by shortening telomeres, structures that cap and protect the ends of chromosomes ( see page 169 ). Still others hope to draw lessons from people who can bounce back from stress \u2014 even from experiences as devastating as abduction and rape. By tracing the social and biological factors that help these people to recover, the research could yield ways to make the rest of us more resilient ( see page 165 ). \n                 See Editorial \n                 p.143 \n                 and Careers \n                 p.299 \n               \n                     National Institute of Mental Health \n                   Reprints and Permissions"},
{"file_id": "488269a", "url": "https://www.nature.com/articles/488269a", "year": 2012, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Scientists have travelled the ancient Silk Road to understand how genes shape people's love for foods. It wasn't quite the lowest point of the expedition. But Paolo Gasparini was decidedly uncomfortable at a banquet in the small town of Alga, Kazakhstan, when he was given the honour of dividing a boiled sheep's head among the gathering. He could sense the silent alarm of his young colleagues, fearing that soon they would be politely chewing on an eye or an ear. Fighting nausea, Gasparini, a medical geneticist at the University of Trieste, Italy, sympathetically sliced each of them just a taste of skin, passing the traditionally valued sense organs to the village elders. The sheep's-head ritual did, however, neatly reflect the mission of the trip. The Italian scientists were gathering DNA samples from members of the many different ethnic groups that live along the Silk Road \u2014 a 2,000-year-old trading route between China and Europe \u2014 to map the genetic roots of food preference and of the senses that contribute to it. The team set out from Trieste in July 2010 and collected its final samples this June in northern Kyrgyzstan. It had amassed about 1,100 DNA samples and thousands of sensory-test results from a dozen or so distinct populations, ranging from Caucasian to Turkish and Mongolian. \n               Full flavour \n             Over the past two decades, researchers have identified receptors on the tongue for sweet, umami ('savoury'), bitter, sour and salty. They have realized that the sensation of flavour is created when signals from these receptors are integrated in the brain with food-related signals from the hundreds of odorant receptors in the nose and nasal passages. But understanding why people prefer certain foods is still a major scientific puzzle. Subtle variations in the genes that encode the taste and smell receptors are likely to have a big influence. But many genes involved in touch, hearing and sight \u2014 those that respond to the creamy feel of fatty food, the sound of crunching nuts, the sight of a crimson tomato \u2014 also have a role. Travelling the Silk Road gave Gasparini and his team a unique opportunity to identify genetic influences on food preference by studying isolated populations, in which such variants are relatively easy to find. \u201cThe expedition approaches an almost unexplored dimension of what makes people different,\u201d says Yurii Aulchenko, a statistical geneticist from the Russian Academy of Sciences Institute of Cytology and Genetics in Novosibirsk. Researchers in evolutionary and population genetics are watching with interest, as is the food industry. Humans evolved in environments where food was scarce and poisonous plants a constant threat. As a result, calorie-dense fatty foods can be hard to resist, whereas the bitter tastes that are common in toxic plants can make some nutritious foods, such as broccoli, unpalatable. In the modern, food-rich world, that genetic legacy helps to push people towards diets that contribute to obesity and ill-health. Understanding the roots of food preferences might one day help to change people's behaviour. \u201cEventually, industry might be able to develop foods that are enjoyable without being bad for you,\u201d says Jim Kaput, head of clinical translational research at the Nestl\u00e9 Institute of Health Sciences in Lausanne, Switzerland, which collaborates with the Nestl\u00e9 Research Center in Lausanne on studies linking genomics and food preferences. \u201cBut right now we understand almost nothing \u2014 we need a lot more basic research,\u201d says Kaput. \n               Genetic gastronomy \n             The Silk Road expedition \u2014 officially called Marco Polo, after the Venetian explorer who travelled the route in the thirteenth century \u2014 was born five years ago, when Gasparini met Enrico Balli, director of the Medialab of the International School for Advanced Studies in Trieste. The two hit it off immediately. Balli, a straight-talking physicist turned science-communicator, was itching to film exotic locations. Gasparini, tall and genial, had spent most of his scientific life studying the genetics of isolated communities in dead-end valleys of the Italian Alps. He had become interested in the genetics of food preferences, was consulting with food companies, and had been dreaming vaguely of accessing remote, isolated populations in more grandiose mountain chains in Asia or South America, where scientists have rarely ventured. Such populations were often founded by just a few people who went on to marry within the group, so their descendants tend to be genetically homogeneous. This makes it easier to work out if a gene variant is associated with a particular characteristic, such as a taste preference, than it is in a large, genetically diverse group. Comparing different isolated populations can be even more valuable. If a variant is associated with the same trait in genetically different groups, that may be a sign that it is important across almost all populations. Alison Abbott takes a tasty journey through Kyrgyzstan with the expedition team. The Silk Road offers a potential paradise for such genetic exploration. The route traverses massive mountain ranges such as the Pamir and the Tian Shan in central Asia and passes through pockets of the nomadic tribes who originally populated the region, as well as ethnically diverse groups descended from traders who settled en route, often near the roadside inns called caravanserais. These populations did not tend to share their genes, but they did share recipes. Cuisines are remarkably similar along much of the Silk Road \u2014 variations on tandoor breads, noodles with vegetable or mutton sauces, and dried or fresh fruit. This means that differences in food preferences between groups are likely to be down to variations in genes rather than in dietary cultures, making them even more appealing to the geneticists. But before Gasparini and Balli could study these groups, they had to reach them. They originally conceived the expedition as a do-it-yourself venture, in which they would simply drive themselves from country to country. Fortunately, they consulted Lilia Smelkova \u2014 co-founder of Terra Madre, a network of farmers in developing countries established by the non-profit campaign group Slow Food, which is based near Turin, Italy. Smelkova is an expert in the former Soviet republics that Gasparini and Balli planned to visit. \u201cI thought they were quite crazy,\u201d she says, knowing the civil-war-torn, multilingual, sometimes despotic territories that the scientists planned to traverse and the closed communities that they wanted to study. \u201cBut I loved their ideas, so I agreed to help \u2014 by joining them.\u201d Smelkova used her contacts to help the researchers to win the confidence, and the cooperation, of villages on the route. \n               Taste test \n             The team, consisting of ten or so people, split the expedition across three summers (see 'Silk-Road science'). The first year, they set off for Georgia armed with just a few clothes and some compact equipment, and fell into a gruelling schedule. Each day, they drove \u2014 often for many hours \u2014 to a community that was to be sampled and tested. A local Terra Madre helper explained the tests, and volunteers were asked to donate DNA by spitting into plastic tubes. Then the scientists tested volunteers' abilities to hear different sound frequencies, to taste salty or bitter compounds soaked into scraps of filter paper, to distinguish different shades of colour and to identify 12 different smells impregnated in marker-pen-like sticks. The team also showed the volunteers pictures of 80 different food types and asked them to indicate how much they liked or disliked each one. At night, the scientists would feed the results into their computers before collapsing into bed. The expedition's success depended entirely on getting sample tubes containing saliva back to Italy, but this proved nerve-rackingly difficult. When they arrived home after the first leg in September 2010, the researchers found that Uzbek customs had stopped a precious shipment of 350 tubes gathered in Azerbaijan, Turkmenistan and Uzbekistan. Despite exhaustion, Balli says, \u201cI flew back to Tashkent, and brought them straight back in a suitcase.\u201d Systematic analyses of the Silk Road data will keep the scientists busy for years. The team is carrying out a detailed analysis of small variants known as single-nucleotide polymorphisms (SNPs) in all the DNA samples, and will fully sequence up to 50 samples. The scientists have already identified eight variants in known genes, including one for an ion channel involved in sensing spicy-hotness, which are associated with a taste for particular foods. And they have found that variants of the gene for the TAS1R2 protein, part of a sweetness receptor, are associated with a strong liking for vodka and white wine (N. Pirastu  et al .  J. Food Sci.  ; in the press). The results fit with reports linking preferences for alcohol and sweetness in mice (S. M. Brasser  et al .  Physiol. Genomics   41 , 232\u2013243; 2010 ), and hint that both substances are perceived by the same receptor. There may be bigger scientific stories hiding in the data. Gasparini says that the team is seeing an emerging association in Tajikistani populations between an olfactory receptor gene and both sensitivity to bitter tastes and a tendency to mistake smells. If the finding holds up, it will be the first demonstrated genetic link between smell and taste perception, and it could help to explain how signals from different senses combine to sculpt individual food preferences. The finding may also offer clues to how evolution might have shaped the senses. \u201cWho knows?\u201d Gasparini muses. \u201cMight evolution have compensated those who can't distinguish smells efficiently by selecting genes that make them more sensitive to bitter tastes, so they have a better chance of recognizing poisons?\u201d \n               Diet and diversity \n             The genetic data will serve another purpose by filling a gap in the international 1000 Genomes Project, which is cataloguing genetic variants in different populations across the globe, but until now had no representatives from central Asia. Population geneticists curious about how different peoples evolved will find their own stories in the Silk Road DNA, says Aulchenko. \u201cWe know a lot about the big migrations \u2014 out of Africa, for example \u2014 but we don't know how trade shaped genetic variation.\u201d The data were hard won. At the trip's lowest point, on the drive through Tajikistan from Qal'aikhum to Khorugh in the Pamir Mountains, a road closure forced the jeep convoy to detour for 16 tense, sweltering hours along the Panj River, which forms part of the border with Afghanistan. The few metres between the road and the river were laid with landmines. Still, Gasparini and Balli have caught the fieldwork bug, and are planning another expedition for next year. At the end of the nineteenth century, members of a small, isolated Italian population near Trieste emigrated in droves to South America \u2014 where they settled in different valleys in the Andes. Gasparini wants to compare these people's taste preferences and the acuity of their senses with those of their relatives in Italy. Unlike the Silk Road populations, the groups have the same genetic backgrounds but very different diets. Gasparini hopes that this will create a natural laboratory for exploring the interaction of diet and other environmental factors with interesting gene variants identified in the Silk Road samples. Any discomforts of expedition science are overwhelmingly compensated for by the gains, says Gasparini. And if nothing else, the Marco Polo expedition taught him that boiled sheep's head is not his dish of choice. \n                     Science in the Sahara: Man of the desert 2012-Aug-15 \n                   \n                     Neuroscience: Hardwired for taste 2012-Jun-20 \n                   \n                     Evolutionary biology: The lost appetites 2012-Jun-20 \n                   \n                     Gustatory system: The finer points of taste 2012-Jun-20 \n                   \n                     Sensory science: Partners in flavour 2012-Jun-20 \n                   \n                     Food science: Taste bud hackers 2012-Jun-20 \n                   \n                     Nature Taste Outlook \n                   \n                     The Marco Polo Expedition \n                   Reprints and Permissions"},
{"file_id": "488272a", "url": "https://www.nature.com/articles/488272a", "year": 2012, "authors": [{"name": "Quirin Schiermeier"}], "parsed_as_year": "2006_or_before", "body": "Stefan Kr\u00f6pelin has carved out a career where few dare to tread \u2014 in the heart of the Sahara. Stefan Kr\u00f6pelin's first research trip to the eastern Sahara was nearly his last. As a graduate student in January 1982, he travelled alone to Gilf Kebir \u2014 a remote plateau in the southwest corner of Egypt \u2014 to study sediment deposition in the steep canyons. Things didn't start well. On the first night, he found that his thin clothes and sleeping bag were no match for the freezing conditions. During the day, fierce sandstorms forced him to dig a pit for shelter and keep his eyes and mouth shut for most of the time. After a week, the driver who was scheduled to pick him up was nowhere in sight. Three days later, and running out of water, Kr\u00f6pelin was just about to embark on a desperate 150-kilometre march to the nearest oasis when the jeep finally arrived. Kr\u00f6pelin, now a geologist and climate researcher at the University of Cologne in Germany, not only survived the ordeal but went on to become one of the most devoted Sahara explorers of our time. In dozens of expeditions to some of the farthest corners of the desert (see 'A career in the sand'), he has endured week-long sandstorms, suffered bouts of serious disease, including schistosomiasis, and faced heavily armed groups that roam the eastern Sahara. But those decades of difficult field work have paid off for Kr\u00f6pelin, who has made seminal discoveries about the climatic history of the Sahara that are challenging assumptions about the tipping points the world may face in a warmer future. At the same time, Kr\u00f6pelin has worked to document the Sahara's cultural history and to preserve its heritage by lobbying to protect important scientific and cultural sites. \u201cI've never ceased to be excited about the chance to investigate some of the least known parts of the desert,\u201d he says. Siddiq Abd Algadir, president of the Sudanese Geologists' Union in Khartoum and a fellow student with Kr\u00f6pelin in the 1980s, says that the German researcher has added immeasurably to Saharan science. \u201cMuch of what we now know about the geology, the environments and even the people in some of the most remote parts of the Sahara, we really owe to him and the expeditions he has led.\u201d With his wiry build and boundless energy, Kr\u00f6pelin seems much younger than his 60 years. The desks in his office are covered with parchment-coloured maps featuring vast expanses of desert. And his bookshelves sag with hundreds of volumes covering Africa's natural and cultural history, from early human evolution and migration to the trans-Saharan trade routes that carried gold and salt between West Africa and the Mediterranean. In the 1960s, Kr\u00f6pelin's sense of adventure was sparked by reading the exploits of nineteenth-century explorers such as Heinrich Barth and Gustav Nachtigal, who were among the first Europeans to document the cultures and environment of the Sahara. Two decades later, in graduate school at the Technical University of Berlin, that early curiosity about the area became a scholarly passion as he studied its physical geography and geology. Similar in size to Australia or the United States, the Sahara is one of the most inhospitable and least explored spots on the globe. Throughout his work there, Kr\u00f6pelin has tried to amass detailed knowledge of the scientific and cultural facets of his study areas before turning out results. Researchers who have travelled with Kr\u00f6pelin describe him as a circumspect, hard-driving leader, equally at home in geomorphology, archaeology, human psychology and \u2014 when necessary \u2014 motor mechanics. \n               Map quest \n             Over the past few years, Kr\u00f6pelin's work has helped to reveal how the Sahara transformed from a savannah more than 5,000 years ago to the desert it is today. Researchers had previously thought that the transition happened abruptly \u2014 within little more than a century \u2014 when a cyclical shift in Earth's orbit reduced the amount of sunlight in the tropics and weakened the African monsoon. This idea was championed by Peter deMenocal of Columbia University in New York, who studied a core of deep-sea sediments from the tropical Atlantic ocean and saw a rapid rise in the amount of dust blowing off the continent at the time of climatic transition 1 . The sediment record agreed with models suggesting that a number of sensitive components of the planet \u2014 such as monsoon patterns, Amazon and Saharan vegetation, polar ice sheets and even the Atlantic Ocean circulation \u2014 will, under certain circumstances, flip from one stable state to another 2 . But Kr\u00f6pelin wasn't convinced. The concept of an abrupt climate switch didn't mesh with his previous research on ancient settlements in the eastern Sahara 3 . \u201cThere is evidence from thousands of archaeological sites throughout the Sahara that prehistoric human settlements weren't abandoned within a few decades or so,\u201d he says. He was also piqued that deMenocal reached his conclusion without ever setting foot in the desert, and used a single marine record to make generalizations about the entire Sahara. \u201cThe idea of catastrophically fast climate change is untenable \u2014 it can only come from someone who doesn't know the Sahara,\u201d says Kr\u00f6pelin. From his past reconnaissance work, Kr\u00f6pelin knew one place in the Sahara with a climate record potentially long enough to test his ideas \u2014 a series of permanent lakes in the remote Ounianga basin in northeastern Chad, a practically rainless and notoriously insecure region bordering Libya and Sudan. French military geographers had explored the lakes in the early twentieth century but the area had since been forgotten by most foreign researchers. The lakes are fed by ancient groundwater, and their depths are layered with sediments containing climatic indicators such as pollen. Kr\u00f6pelin suspected that one of the largest lakes, Lake Yoa, held a sedimentary cache thick enough to reconstruct the long-term climatic history of the region. Working in Ounianga has its challenges. On a reconnaissance mission in 1999, Kr\u00f6pelin had to persuade a superstitious local population that drilling a hole in the lake bottom would not drain the water or release the jinns and demons they feared might dwell in the ground. After extensive preparations, he returned to the remote lake in 2003 and 2004, and pulled up a continuous 8-metre-long core of sediment from its bottom \u2014 a climate record reaching back 6,000 years. Kr\u00f6pelin's analysis revealed that it took some 3,000 years \u2014 from 5,600 to 2,700  BC  \u2014 for the fully vegetated savannah there to transform into a barren desert 4 . \n               The great drying \n             At first, some researchers questioned the dating of the core and whether it represented conditions across a broad region. But Kr\u00f6pelin answered his critics 5 , and his ideas eventually gained acceptance. Today, deMenocal maintains that the western Sahara dried out quickly, but he acknowledges that the eastern part around Lake Yoa took much longer. \u201cStefan knows the Sahara better than any other living scientist, and the climate archive he has uncovered, while not perfect, is uniquely well-dated,\u201d he says. The debate has intrigued climate modellers interested in potential tipping points in the Earth system, in which small perturbations cause abrupt and major changes. Kr\u00f6pelin's findings imply that the most recent savannah-to-desert transition does not fit this pattern \u2014 although he leaves open the possibility of earlier tipping points in the Saharan climate. Climate researchers are therefore eager for Kr\u00f6pelin to report his analysis of a 16-metre-long core from Lake Yoa that he drilled in 2010, which he is now readying for publication. \u201cThe published record is fascinating but rather short,\u201d says Martin Claussen, a climate modeller at the Max Planck Institute for Meteorology in Hamburg, Germany, who is exploring ways to predict fast climate\u2013vegetation transitions 6 . \u201cThe complete 12,000-year record should help us get a better sense of how rapidly the system might be capable of switching from one state to another and what the transition period may look like.\u201d The results from Lake Yoa crown a long list of discoveries that Kr\u00f6pelin has made in the region. In one of his earliest major finds, Kr\u00f6pelin established that the dry valley known as Wadi Howar, which sits in an extremely arid part of northern Sudan, was once one of Africa's largest rivers and a tributary to the Nile 7 . This extinct river flowed from about 9,500\u20134,500 years ago and supported a rich savannah that was home to a host of animals, including antelopes, giraffes, zebras and elephants. Kr\u00f6pelin's extended trips through the Sahara, which typically last two months, have sometimes placed him in difficult situations. During one expedition to northern Sudan in 1995, he was chased for several days across the desert by a truck. When the pursuers caught him, they turned out to be Sudanese forces who thought they were following outlaws smuggling weapons or people. The soldiers were nearly out of fuel from their chase, so Kr\u00f6pelin gave them a share of the expedition's diesel supplies and they enjoyed a friendly meal together. The excavations carried out on that trip revealed how prehistoric humans settled there during the Sahara's humid phase and then disappeared as the climate dried out 3 . Another experience in 2005 was more troubling. One night, the sound of heavy gunfire terrified a team that Kr\u00f6pelin had led to Erdi Ma, an uninhabited and largely unexplored tableland in the northwest corner of Chad. The next morning they learned that Darfur rebels had massacred 20 Sudanese soldiers not far from the expedition's campsite. Sometimes, nature is the biggest enemy. On the way to Lake Yoa in April 2010, Kr\u00f6pelin and his team got caught in a dust storm fiercer than any he had seen in 30 years. For more than a week visibility dropped to two metres. Under non-stop bombardment, the researchers' bodies and vehicles became electrically charged and each touch caused painful electric shocks. Refilling the trucks from metal gas canisters was Russian roulette, as large sparks shot around the filler necks. \u201cBack home, it took weeks until I could open my car again without inhibition,\u201d Kr\u00f6pelin says. Through his expeditions, Kr\u00f6pelin has developed relationships with many of the regional governments, and he has helped to advise officials in Egypt, Libya and Chad on the impact of mining, oil drilling and tourism. He has campaigned for and won protection for two environmentally and culturally unique regions that he explored \u2014 Wadi Howar and Gilf Kebir. For the past 13 years, Kr\u00f6pelin has also lobbied to protect the Ounianga lakes \u2014 an effort that involved hundreds of meetings with ministers in Chad and international agencies and officials. That work paid off in July, when the region was declared a world heritage site by UNESCO (the United Nations Educational, Scientific and Cultural Organization). Researchers wonder what will happen when Kr\u00f6pelin retires, leaving a major hole in Saharan studies. \u201cHe has taken risks few researchers would be happy to take any more,\u201d says deMenocal. The risks in the region have grown lately because of rebel activity and recurring armed conflict in places including Darfur, Libya, Mali and Chad. But despite some anxious moments over the years, Kr\u00f6pelin considers that the risk of getting robbed, kidnapped or killed is smaller in the Sahara than in sections of London or New York City. \u201cIn the desert there is an air of fellowship with whoever crosses your way,\u201d he says. \u201cEncounters with nomads, rebels and more shady folks can be scary, but I've always managed, somehow, to talk us out of even the most delicate incidents.\u201d For now, Kr\u00f6pelin shows no signs of slowing down. He plans to return to the Sahara in November for a celebration of the UNESCO decision and to do some geological field work. Next year, he will search for traces of prehistoric writing and trading, and will explore a mysterious crater in Jebel Uweinat, the tallest mountain in the eastern Sahara. Gone are the days of foolhardy solo trips, but not the deep love for the land. \u201cUnder the vast desert skies, your whole existence takes on a different meaning,\u201d he says. \u201cI'd like to return for as long as I can.\u201d \n                     Science on the Silk Road: Taste for adventure 2012-Aug-15 \n                   \n                     Human evolution: Cultural roots 2012-Feb-15 \n                   \n                     Revolution offers chance for Libyan archaeology 2011-Nov-18 \n                   \n                     Sudan splits and science community divides 2011-Jul-08 \n                   \n                     'Climate wars' claims disputed 2010-Sep-08 \n                   \n                     Lakes of Ounianga \n                   \n                     University of Cologne \u2013 Collaborative Research Centre \u2018Our Way to Europe\u2019 \n                   \n                     Peter deMenocal \n                   Reprints and Permissions"},
{"file_id": "488444a", "url": "https://www.nature.com/articles/488444a", "year": 2012, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "With his knack for knowing what stem cells want, Yoshiki Sasai has grown an eye and parts of a brain in a dish. In December 2010, Robin Ali became suddenly excited by the usually mundane task of reviewing a scientific paper. \u201cI was running around my room, waving the manuscript,\u201d he recalls. The paper described how a clump of embryonic stem cells had grown into a rounded goblet of retinal tissue. The structure, called an optic cup, forms the back of the eye in a growing embryo. But this one was in a dish, and videos accompanying the paper showed the structure slowly sprouting and blossoming. For Ali, an ophthalmologist at University College London who has devoted two decades to repairing vision, the implications were immediate. \u201cIt was clear to me it was a landmark paper,\u201d he says. \u201cHe has transformed the field.\u201d 'He' is Yoshiki Sasai, a stem-cell biologist at the RIKEN Center for Developmental Biology in Kobe, Japan. Sasai has impressed many researchers with his green-fingered talent for coaxing neural stem cells to grow into elaborate structures. As well as the optic cup 1 , he has cultivated the delicate tissue layers of the cerebral cortex 2  and a rudimentary, hormone-making pituitary gland 3 . He is now well on the way to growing a cerebellum 4  \u2014 the brain structure that coordinates movement and balance. \u201cThese papers make for the most addictive series of stem-cell papers in recent years,\u201d says Luc Leyns, a stem-cell scientist at the Free University of Brussels. Sasai's work is more than tissue engineering: it tackles questions that have puzzled developmental biologists for decades. How do the proliferating stem cells of an embryo organize themselves seamlessly into the complex structures of the body and brain? And is tissue formation driven by a genetic program intrinsic to cells, or shaped by external cues from neighbouring tissues? By combining intuition with patient trial and error, Sasai has found that it takes a delicate balance of both: he concocts controlled environments that feed cells physical and chemical signals, but also gives them free rein to 'do their thing' and organize themselves into issues. He sometimes refers to himself as a Japanese matchmaker who knows that, having been brought together, two strangers need to be left alone. \u201cThey know what to do,\u201d he says. \u201cThey interact in a delicate manner, and if the external cues are too strong, it will override the internal ones.\u201d Sasai's work could find medical applications. Recapitulating embryonic development in three dimensions, it turns out, generates clinically useful cells such as photoreceptors more abundantly and efficiently than two-dimensional culture can, and houses them in an architecture that mirrors that of the human body. Sasai and his collaborators are now racing to implant lab-grown retinas into mice, monkeys and humans. The way Sasai sees it, maturing stem cells in two-dimensional culture may lead to 'next generation' therapy \u2014 but his methods will lead to 'next, next generation' therapy. \n               Self-determined \n             A bit stiff in movement and reserved in manner, Sasai nevertheless puts on a theatrical show with a cocktail shaker at parties held by his institute after international symposia. \u201cMy second job is bartender,\u201d he says, without a trace of a smile. It is, however, the cocktails he mixes in 96-well culture plates that have earned him scientific acclaim. Like many members of his family, Sasai studied medicine. But he soon became frustrated by the lack of basic understanding in the field, especially when it came to neurological conditions. \u201cWithout knowing the brain, a doctor cannot do much for the patient and therapeutics will always be superficial,\u201d he recalls thinking. There seemed no better way to know the brain than to study how it emerges and folds in the embryo. \u201cIt's complex and usually complex systems are messy,\u201d says Sasai. \u201cBut it's one of the most ordered.\u201d He wanted to know how this elaborate system was controlled.  We set up the permissive conditions. But after that we don't do anything. Keep them growing and let them do their job.  One piece of the puzzle was well known: the Spemann organizer, a node in vertebrate embryos that induces surrounding cells to become neural tissue. How the organizer works had been a mystery since its discovery in 1924; to find out, Sasai accepted a postdoctoral position at the University of California, Los Angeles. The post got off to a difficult start when Sasai was robbed of his money and passports at the airport on his way to California. But his scientific efforts were soon rewarded. \u201cHe replaced the passports and within a month produced the clones that gave us the famous gene chordin,\u201d says his supervisor, developmental biologist Eddy De Robertis. Sasai and his colleagues discovered that the chordin protein is a key developmental signal released by the Spemann organizer 5 . Rather than pushing nearby cells to become neurons, they found, chordin blocks signals that would turn them into other cell types 6 , 7 . The work helped to establish the default model of neural induction: the idea that, without other signals, embryonic cells will follow an internal program to become neural cells. By the late 1990s, embryonic-stem-cell scientists were also looking at these signals. They wanted to turn stem cells into mature cell types \u2014 particularly neurons \u2014 that might lead to therapies. The problem, says Sasai, is that scientists generally \u201cpush too hard and perturb the system\u201d. Sasai knew that in the embryo, subtracting signals from the system is what counts, not perturbing it. \u201cWe tried to minimize external cues,\u201d he says. Sasai built an experimental system around that philosophy. He threw out the serum usually added to growing embryonic stem cells, which contains a brew of uncharacterized growth factors and other signalling molecules. He also removed physical cues, such as contact with the plastic surfaces of a culture dish, by allowing embryonic stem cells to spontaneously form floating aggregates known as embryoid bodies. \u201cIf they're attached, they're like prisoners and can't act out their own desires,\u201d he says. Keeping the cells alive without these support systems was a challenge but, five years of careful experimentation later, Sasai published 8  and later patented his serum-free embryoid body culture \u2014 a pared-down life-support system with just the right mixture of ingredients for cells to survive. It would go on to form the heart of his brain-tissue factory. \n               Tailor-made \n             Embryoid bodies in Sasai's system quickly become what he calls \u201cbrain balls\u201d \u2014 populated with neural precursor cells. Sasai found that balls left entirely alone give rise to cells like those in the developing brain region called the hypothalamus 9 , but those given just a whiff of growth factors start differentiating into cerebral-cortex cells 2 . And when Sasai cultured the cells for about two weeks, he got a surprise: the cortical cells spontaneously started to form a layered structure that ended up strikingly similar to the cortex of a 15-day-old mouse. When transplanted into the brain of a newborn mouse, the structure survived. \u201cThat's what we do,\u201d says Sasai. \u201cWe set up the permissive conditions, selecting the right medium and cell number. But after that we don't do anything. Keep them growing and let them do their job.\u201d The lab-grown cortex wasn't perfect, however: it had only four of the cerebral cortex's six cell layers, for example. Sasai thought that a retina \u2014 a layered tissue that sprouts from the embryonic brain and contains light-sensing photoreceptors \u2014 might be easier to grow. The retina is thinner than the cortex, forms earlier in embryo development and doesn't require a complex vascular system. To adapt his system to a different type of tissue, Sasai makes minute changes to the culture conditions that nudge the cells down a developmental path. He genetically engineers fluorescent 'reporter' genes into the stem cells so that they are expressed when the cells differentiate into the desired type \u2014 in this case, retinal precursor cells \u2014 and reveal whether the system is working. \u201cOur success depends on knowing how slight modifications can lead to dramatic change,\u201d he says. All it took to grow a retina, it turned out, were a few tweaks, such as a reduction in the concentration of growth factors and the addition of a standard cell-culture ingredient called Matrigel. The result closely mimics eye development in the embryo (see 'How to grow an eye'). By the sixth day in culture, the brain balls start sprouting balloon-like growths of retinal cells, which then collapse in on themselves to make the double-walled optic cups. Sasai's team snip them off \u2014 \u201clike taking an apple from a tree\u201d, says Sasai \u2014 transfer them to a different culture and let them be. Two weeks later, the cups have formed all six layers of the retina, an architecture that resembles the eye of an 8-day-old mouse (which, at that age, is still blind). That the cells could drive themselves through this dramatic biomechanical process without surrounding tissues to support them 1  stunned Sasai as much as anyone else. \u201cWhen I saw it, I thought, 'Oh my god.' Shape, topology and size are all recapitulated,\u201d he says. Carefully explaining the pun to come, he adds: \u201cIn English, when you are surprised, you say 'eye-popping' \u2014 so we really thought this was eye-popping.\u201d Reproducing the results with human cells was the obvious, but not simple, next step. Peter Coffey, an ophthalmologist and neuroscientist at University College London, tried following Sasai's recipe to grow optic cups with human cells, and, as Coffey puts it, \u201cfailed catastrophically\u201d. Sasai, who reported 10  this year that he had accomplished the feat, says that it took careful tweaks to accommodate the sensitivities of human embryonic stem cells. Because these cells grow three times slower than those from mice, for example, Sasai had to start with of 9,000 cells instead of 3,000. Coffey says that his experience made him realize how much expertise has been built up in Sasai's lab. \u201cThey've been doing it a long time. Good on 'em,\u201d he says, with an air of good-natured jealousy. \n               All eyes \n             All this will not create eyes that can be plugged into an eye socket like a light bulb into a lamp. Even if Sasai could get his optic cups to develop into mature retinas, researchers have little idea about how to wire a transplanted retina up to the brain. What the work does offer is a potentially abundant source of pure, dense, well-organized photoreceptors, the developmental stage of which can be precisely selected \u2014 something that has been difficult to achieve in standard two-dimensional culture. Eventually, Sasai hopes, his optic cups will provide sheets of photoreceptors that can be inserted into a retina damaged by conditions such as retinitis pigmentosa or macular degeneration. Sasai demonstrates the procedure by grabbing a stack of papers to stand in for the retinal layers and then slipping one sheet between the others.  In English when you are surprised, you say 'eye popping' \u2014 so we really thought this was eye-popping.  But linking the transplanted photoreceptors with the rest of the retina and with the brain will not be easy, as researchers working on eye stem-cell technologies have found. Robert Lanza, chief scientific officer of the stem-cell therapy company Advanced Cell Technology in Santa Monica, California, is sceptical. \u201cI don't think we're anywhere near when we get those cells to connect up in any meaningful way,\u201d he says. Ali is more hopeful. In April, his team reported 11  that it had improved the vision of partially blind mice using transplants of photoreceptor precursor cells taken from mice a few days old. Ali and another of Sasai's collaborators, Masayo Takahashi at the RIKEN Center for Developmental Biology, are starting to extract sheets of photoreceptors that have been grown using Sasai's methods and transplant them into mice; Takahashi plans to transplant them into monkeys by the end of the year. Both are cagey about their early results, but Takahashi says that in mice, the transplanted photoreceptors \u201csurvived well\u201d. \n               Hormonal challenge \n             Sasai has set his sights on more complex neural tissues. Last November, he reported 3  the formation of a part of the pituitary gland \u2014 his \u201cmost complicated\u201d tissue yet. In the embryo, the pituitary gland arises when two different tissues integrate to form a pouchlike structure. Sasai managed to recapitulate this  in vitro  partly by starting out with more than three times more embryonic stem cells than he had used to grow a mouse retina; the adjustment seems to increase the levels of signals that the cells exchange. When transplanted into mice in which the pituitary glands had been knocked out, the rudimentary organs restored the endocrine system and saved the mice. This work, too, might eventually provide a supply of pure, specialized cells, which could be used to treat endocrine disorders. Sasai hopes to improve on his early efforts by growing a better pituitary gland, equipped with a blood supply; a cerebral cortex with all six layers of tissue; and photoreceptors mature enough to detect light. But his next major task is to culture a cerebellum, which will involve growing and integrating three tissues of different embryonic origins. The matchmaker is already at work, trying to conjure up the right atmosphere. \u201cWhen a boy meets a girl, they start their own story \u2014 but not in a large auditorium full of people,\u201d he says. \u201cYou need to put them on a beach or in a disco. Our system is simply going to create this environment.\u201d What Sasai plans to take on after the cerebellum is a secret, but he hopes eventually to encompass the whole brain. He does not mean building one \u2014 that would be enormously difficult and ethically fraught. Instead, he wants to work out how brain parts, with their remarkable capacity for autonomous growth and organization, combine and fold into a structure of such tremendous complexity. \u201cI don't want to be a parts-maker, making more and more tissues,\u201d says Sasai. \u201cI always want something conceptually different.\u201d \n                     Biologists grow human-eye precursor from stem cells 2012-Jun-15 \n                   \n                     Regenerative medicine repairs mice from top to toe 2012-Apr-18 \n                   \n                     Stem cells make 'retina in a dish' 2011-Apr-06 \n                   \n                     Human cortical neural cell balls 2008-Nov-13 \n                   \n                     An intrinsic program of brain development 2008-Aug-28 \n                   \n                     Blind mice see after cell transplant 2006-Nov-08 \n                   \n                     Nature News special: Neuroscience \n                   \n                     Nature Focus: Induced pluripotent stem cells \n                   \n                     Nature Focus: Regenerative medicine \n                   \n                     Yoshiki Sasai \n                   \n                     Masayo Takahashi \n                   \n                     Robin Ali \n                   Reprints and Permissions"},
{"file_id": "488448a", "url": "https://www.nature.com/articles/488448a", "year": 2012, "authors": [{"name": "Jim Giles"}], "parsed_as_year": "2006_or_before", "body": "From e-mails to social networks, the digital traces left by life in the modern world are transforming social science. Jon Kleinberg's early work was not for the mathematically faint of heart. His first publication 1 , in 1992, was a computer-science paper with contents as dense as its title: 'On dynamic Voronoi diagrams and the minimum Hausdorff distance for point sets under Euclidean motion in the plane'. That was before the World-Wide Web exploded across the planet, driven by millions of individual users making independent decisions about who and what to link to. And it was before Kleinberg began to study the vast array of digital by-products generated by life in the modern world, from e-mails, mobile phone calls and credit-card purchases to Internet searches and social networks. Today, as a computer scientist at Cornell University in Ithaca, New York, Kleinberg uses these data to write papers such as 'How bad is forming your own opinion?' 2  and 'You had me at hello: how phrasing affects memorability' 3  \u2014 titles that would be at home in a social-science journal. \u201cI realized that computer science is not just about technology,\u201d he explains. \u201cIt is also a human topic.\u201d Kleinberg is not alone. The emerging field of computational social science is attracting mathematically inclined scientists in ever-increasing numbers. This, in turn, is spurring the creation of academic departments and prompting companies such as the social-network giant Facebook, based in Menlo Park, California, to establish research teams to understand the structure of their networks and how information spreads across them. \u201cIt's been really transformative,\u201d says Michael Macy, a social scientist at Cornell and one of 15 co-authors of a 2009 manifesto 4  seeking to raise the profile of the new discipline. \u201cWe were limited before to surveys, which are retrospective, and lab experiments, which are almost always done on small numbers of college sophomores.\u201d Now, he says, the digital data-streams promise a portrait of individual and group behaviour at unprecedented scales and levels of detail. They also offer plenty of challenges \u2014 notably privacy issues, and the problem that the data sets may not truly be reflective of the population at large. Nonetheless, says Macy, \u201cI liken the opportunities to the changes in physics brought about by the particle accelerator, and in neuroscience by functional magnetic resonance imaging\u201d. \n               Social calls \n             An early example of large-scale digital data being used on a social-science issue was a study in 2002 by Kleinberg and David Liben-Nowell, a computer scientist at Carleton College in Northfield, Minnesota. They looked at a mechanism that social scientists believed helped drive the formation of personal relationships: people tend to become friends with the friends of their friends. Although well established, the idea had never been tested on networks of more than a few tens or hundreds of people. Kleinberg and Liben-Nowell studied the relationships formed in scientific collaborations. They looked at the thousands of physicists who uploaded papers to the arXiv preprint server during 1994\u201396. By writing software to automatically extract names from the papers, the pair built up a digital network several orders of magnitude larger than any that had been examined before, with each link representing two researchers who had collaborated. By following how the network changed over time, the researchers identified several measures of closeness among the researchers that could be used to forecast future collaborations 5 . As expected, the results showed that new collaborations tended to spring from researchers whose spheres of existing collaborators overlapped \u2014 the research analogue of 'friends of friends'. But the mathematical sophistication of the predictions has allowed them to be used on even larger networks. Kleinberg's former PhD student, Lars Backstrom, also worked on the connection-prediction problem \u2014 experience that he has put to good use now that he works at Facebook, where he designed the social network's current friend-recommendation system. Another long-standing social-science idea affirmed by computational researchers is the importance of 'weak ties' \u2014 relationships with distant acquaintances who are encountered relatively rarely. In 1973, Mark Granovetter, a social scientist now at Stanford University in Stanford, California, argued that weak ties form bridges between social cliques and so are important to the spread of information and to economic mobility 6 . In the pre-digital era it was almost impossible to verify his ideas at scale. But in 2007, a team led by Jukka-Pekka Onnela, a network scientist now at Harvard University in Cambridge, Massachusetts, used data on 4 million mobile-phone users to confirm that weak ties do indeed act as societal bridges 7  (see 'The power of weak ties'). In 2010, a second group, which included Macy, showed that Granovetter was also right about the connection between economic mobility and weak ties. Using data from 65 million landlines and mobile phones in the United Kingdom, together with national census data, they revealed a powerful correlation between the diversity of individuals' relationships and economic development: the richer and more varied their connections, the richer their communities 8  (see 'The economic link'). \u201cWe didn't imagine in the 1970s that we could work with data on this scale,\u201d says Granovetter. \n               Infectious ideas \n             In some instances, big data have showed that long-standing ideas are wrong. This year, Kleinberg and his colleagues used data from the roughly 900 million users of Facebook to study contagion in social networks \u2014 a process that describes the spread of ideas such as fads, political opinions, new technologies and financial decisions. Almost all theories had assumed that the process mirrors viral contagion: the chance of a person adopting a new idea increases with the number of believers to which he or she is exposed. Kleinberg's student Johan Ugander found that there is more to it than that: people's decision to join Facebook varies not with the total number of friends who are already using the site, but with the number of distinct social groups those friends occupy 9 . In other words, finding that Facebook is being used by people from, say, your work, your sports club and your close friends makes more of an impression than finding that friends from only one group use it. The conclusion \u2014 that the spread of ideas depends on the variety of people that hold them \u2014 could be important for marketing and public-health campaigns. As computational social-science studies have proliferated, so have ideas about practical applications. At the Massachusetts Institute of Technology in Cambridge, computer scientist Alex Pentland's group uses smartphone apps and wearable recording devices to collect fine-grained data on subjects' daily movements and communications. By combining the data with surveys of emotional and physical health, the team has learned how to spot the emergence of health problems such as depression 10 . \u201cWe see groups that never call out,\u201d says Pentland. \u201cBeing able to see isolation is really important when it comes to reaching people who need to be reached.\u201d Ginger.io, a spin-off company in Cambridge, Massachusetts, led by Pentland's former student Anmol Madan, is now developing a smartphone app that notifies health-care providers when it spots a pattern in the data that may indicate a health problem. Other companies are exploiting the more than 400 million messages that are sent every day on Twitter. Several research groups have developed software to analyse the sentiments expressed in tweets to predict real-world outcomes such as box-office revenues for films or election results 11 . Although the accuracy of such predictions is still a matter of debate 12 , Twitter began in August to post a daily political index for the US presidential election based on just such methods ( election.twitter.com ). At Indiana University in Bloomington, meanwhile, Johan Bollen and his colleagues have used similar software to search for correlations between public mood, as expressed on Twitter, and stock-market fluctuations 13 . Their results have been powerful enough for Derwent Capital, a London-based investment firm, to license Bollen's techniques. \n               Message received \n             When such Twitter-based polls began to appear around two years ago, critics wondered whether the service's relative popularity among specific demographic groups, such as young people, would skew the results. A similar debate revolves around all of the new data sets. Facebook, for example, now has close to a billion users, yet young people are still overrepresented among them. There are also differences between online and real-world communication, and it is not clear whether results from one sphere will apply in the other. \u201cWe often extrapolate from how one technology is used by one group to how humans in general interact,\u201d notes Samuel Arbesman, a network scientist at Harvard University. But that, he says, \u201cmight not necessarily be reasonable\u201d. Proponents counter that these are not new problems. Almost all survey data contain some amount of demographic skew, and social scientists have developed a variety of weighting methods to redress the balance. If the bias in a particular data set, such as an excess of one group or another on Facebook, is understood, the results can be adjusted to account for it.  \u201cWe didn't imagine in the 1970s that we could work with data on this scale.\u201d  Services such as Facebook and Twitter are also becoming increasingly widely used, reducing the bias. And even if the bias remains, it is arguably less severe than that in other data sets such as those for psychology and human behaviour, where most work is done on university students from Western, educated, industrialized, rich and democratic societies (often denoted WEIRD). Granovetter has a more philosophical reservation about the influx of big data into his field. He says he is \u201cvery interested\u201d in the new methods, but fears that the focus on data detracts from the need to get a better theoretical grasp on social systems. \u201cEven the very best of these computational articles are largely focused on existing theories,\u201d he says. \u201cThat's valuable, but it is only one piece of what needs to be done.\u201d Granovetter's weak-ties paper 6 , for example, remains highly cited almost 40 years later. Yet it was \u201cmore or less data-free\u201d, he says. \u201cIt didn't result from data analyses, it resulted from thinking about other studies. That is a separate activity and we need to have people doing that.\u201d The new breed of social scientists are also wrestling with the issue of data access. \u201cMany of the emerging 'big data' come from private sources that are inaccessible to other researchers,\u201d Bernardo Huberman, a computer scientist at HP Labs in Palo Alto, wrote in February 14 . \u201cThe data source may be hidden, compounding problems of verification, as well as concerns about the generality of the results.\u201d A prime example is Facebook's in-house research team, which routinely uses data about the interactions among the network's 900 million users for its own studies, including a re-evaluation of the famous claim that any two people on Earth are just six introductions apart. (It puts the figure at five15.) But the group publishes only the conclusions, not the raw data, in part because of privacy concerns. In July, Facebook announced that it was exploring a plan that would give external researchers the chance to check the in-house group's published conclusions against aggregated, anonymized data \u2014 but only for a limited time, and only if the outsiders first travelled to Facebook headquarters16. In the short term, computational social scientists are more concerned about cultural problems in their discipline. Several institutions, including Harvard, have created programmes in the new field, but the power of academic boundaries is such that there is often little traffic between different departments. At Columbia University in New York, social scientist and network theorist Duncan Watts recalls a recent scheduling error that forced him to combine meetings with graduate students in computer science and sociology. \u201cIt was abundantly clear that these two groups could really use each other: the computer-science students had much better methodological chops than their sociology counterparts, but the sociologists had much more interesting questions,\u201d he says. \u201cAnd yet they'd never heard of each other, nor had it ever occurred to any of them to walk over to the other's department.\u201d Many researchers remain unaware of the power of the new data, agrees David Lazer, a social scientist at Northeastern University in Boston, Massachusetts, and lead author on the 2009 manifesto. Little data-driven work is making it into top social-science journals. And computer-science conferences that focus on social issues, such as the Conference on Weblogs and Social Media, held in Dublin in June, attract few social scientists. Nonetheless, says Lazer, with landmark papers appearing in leading journals and data sets on societal-wide behaviours available for the first time, those barriers are steadily breaking down. \u201cThe changes are more in front of us than behind us,\u201d he says. Certainly that is Kleinberg's perception. \u201cI think of myself as a computer scientist who is interested in social questions,\u201d he says. \u201cBut these boundaries are becoming hard to discern.\u201d \n                     Facebook 'likes' the scientific method 2012-Jul-25 \n                   \n                     Sociology of science: Big data deserve a bigger audience 2012-Feb-15 \n                   \n                     Social science: Open up online research 2011-Dec-07 \n                   \n                     Can Facebook influence funding? 2011-May-25 \n                   \n                     Jon Kleinberg \n                   \n                     Duncan Watts \n                   \n                     Michael Macy \n                   \n                     David Lazer \n                   \n                     Facebook\u2019s Data \n                   Reprints and Permissions"},
{"file_id": "488576a", "url": "https://www.nature.com/articles/488576a", "year": 2012, "authors": [{"name": "Leigh Phillips"}], "parsed_as_year": "2006_or_before", "body": "Nature assesses the aftermath of a series of nanotechnology-lab bombings in Mexico \u2014 and asks how the country became a target of eco-anarchists. The shoe-box-sized package was addressed to Armando Herrera Corral. It stated that he was the recipient of an award and it was covered in official-looking stamps. Herrera, a computer scientist at the Monterrey Institute of Technology and Higher Education in Mexico City, shook the box a number of times, and something solid jiggled inside. What could it be? He was excited and a little nervous \u2014 so much so, that he walked down the hall to the office of a colleague, robotics researcher Alejandro Aceves L\u00f3pez, and asked Aceves to open it for him. Aceves sat down at his desk to tear the box open. So when the 20-centimetre-long pipe bomb inside exploded, on 8 August 2011, Aceves took the full force in his chest. Metal pierced one of his lungs. \u201cHe was in intensive care. He was really bad,\u201d says Herrera's brother Gerardo, a theoretical physicist at the nearby Centre for Research and Advanced Studies of the National Polytechnic Institute (Cinvestav). Armando Herrera Corral, who was standing nearby when the bomb went off, escaped with a burst eardrum and burns to his legs. The next day, an eco-anarchist group calling itself Individuals Tending Towards Savagery (ITS) claimed responsibility for the bombing in a 5,500-word diatribe against nanotechnology that it published online. Police found a charred copy of a similar text in the detritus of the explosion. The bombers said that Herrera had been targeted for his role as director of the technology-transfer centre at the Monterrey Institute of Technology and Higher Education (commonly known as Monterrey Tec), \u201cone of the major universities that has staked everything on the development of nanotechnology\u201d. The text talked of the potential for the field to cause environmental \u201cnanocontamination\u201d, and concluded that technology and civilization as a whole should be held responsible for any environmental catastrophe. Chillingly, the bombers listed another five researchers at Monterrey Tec as presumptive targets, as well as a further six universities. Reporter Leigh Phillips talks about anti-science violence in Mexico. The incident had precedent. The ITS had already claimed responsibility for bomb attacks in April and May 2011, both targeting Carlos Alberto Camacho Olgu\u00edn, head of engineering and nanotechnology at the Polytechnic University of the Valley of Mexico in Tultitl\u00e1n. The first bomb wounded a security guard; the second was identified and disposed of before anyone could be hurt. Last December, the group struck again \u2014 this time at the Polytechnic University of Pachuca, where a package containing gunpowder exploded in the hand of a teacher, causing minor burns (see 'A litany of letter bombs'). No other developing country has suffered a comparable string of anti-technology attacks. \n               Closing ranks \n             One year on from the bombing at Monterrey Tec, the repercussions are still being felt. Armando Herrera Corral and Aceves will not speak to  Nature  about what happened. \u201cIt's too sensitive, you understand?\u201d is all Aceves would say. Herrera has left his job as director of the university's technology park and is now head of postgraduate studies. Other Mexican universities with nanotechnology research programmes have evacuated campuses in response to bomb threats, and universities across the country have introduced stringent security measures. Some researchers are anxious for their own safety; some are furious about being targets. But all the researchers that  Nature  spoke to in Mexico are adamant that the attacks will not discourage them from their research or dissuade students from entering the field. So far, there has been little explanation of where the vitriol is coming from. Why are radical environmental groups targeting nanotechnology? Is this field being confronted with the same sort of militant hostility that has dogged genetic-modification research and animal testing? And why Mexico? Reporting by  Nature  suggests that several broad trends have come together to precipitate the violence. Over the past decade, Mexico has invested heavily in nanotechnology relative to other developing countries, because it sees the field as a route to economic development; mainstream green groups worldwide have grown increasingly concerned about nanotechnology's health and environmental risks; and there has been a shift towards extreme ideas and tactics among radical environmentalists critical of technology. In Mexico, this has been set against a general background of growing violence and political upheaval. The bombings come at a pivotal moment. Those who study public perception of risk say that the public discourse about nanotechnology is currently fairly moderate but could easily become more polarized. Until the bombings, the radical environmental movement had mostly restricted itself to non-violent actions and property destruction, says Richard Widick, a sociologist at the University of California, Santa Barbara. But, he says, the global economic crisis and the growing perception that ecological catastrophe is imminent could fuel further attacks. \u201cMore and more people who have hitherto been able to restrain themselves will just go over the edge,\u201d says Widick. \u201cWe are going deeper still into an era of deepening and proliferating extremisms. I see a future of environmental struggles marred by violence of every variety.\u201d That violence leaves scars. According to Gerardo Herrera Corral, Aceves \u201cstill has problems and will do for the rest of his life. There's a piece of shrapnel in his lung they couldn't take out, close to his heart.\u201d And only amateurism by the bombers prevented the attack at Monterrey Tec from having more tragic consequences: the police say that only about 8 centimetres of the dynamite in the pipe detonated. The bombers had packed it in such a way that the rest did not burn. If all the dynamite had gone off, the police say, it could have destroyed the whole building \u2014 as well as Herrera, Aceves and dozens of researchers who work alongside them. Mexico started a concerted nanotechnology push in 2002, when the government identified the field as a strategic sector for development. Dozens of public research institutes signed agreements with foreign institutions, companies and the military, and many opened graduate courses focused on nanotechnology research. Along with other Latin American countries that have invested in the field \u2014 Brazil and Argentina, in particular \u2014 Mexico views nanotechnology as a pathway to a more powerful research and industrial base. \u201cThey see it as a recipe for transition to the knowledge economy. It's less an option than a necessity,\u201d says Guillermo Foladori, an anthropologist at the Autonomous University of Zacatecas in Mexico and coordinator of a group of academics studying the regional growth of the field. The most important university in Mexico for nanotechnology, says Foladori, is Monterrey Tec. \n               Technology backlash \n             As nanotechnology has been growing in Latin America, a violent eco-anarchist philosophy has taken root among certain radical groups in Mexico. Mexican intelligence services believe that the perpetrators of the bombings last year were mainly young and well educated: their communiqu\u00e9s are littered with references to English-language texts unlikely to have been translated into Spanish. Intelligence services say that the eco-anarchist groups have been around for about a decade. They started off protesting against Mexico's economic and political system by setting off small explosives that destroyed bank machines. But around 2008, certain groups began to adopt an 'anarcho-primitivist' perspective. (Locally, they are called  primativistas , says Gerardo Herrera Corral.) This philosophy had won little notice until the past few years, but with increasing media reports of looming global climate disaster, some radical green activists have latched on to it. California-based environmental writer Derrick Jensen \u2014 whose popular books call for an underground network of 'Deep Green Resistance' cells \u2014 is a highly influential figure in this otherwise leaderless movement, which argues that industrial civilization is responsible for environmental destruction and must be dismantled. In their writings, anarcho-primitivist groups often express deep anxiety about a range of advanced research subjects, including genetic engineering, cloning, synthetic biology, geoengineering and neurosciences. But it is nanotechnology, a common subject for science-fiction doomsday scenarios, that most clearly symbolizes to them the power of modern science run amok. \u201cNanotechnology is the furthest advancement that may yet exist in the history of anthropocentric progress,\u201d the ITS wrote in its first communiqu\u00e9, in April 2011. The same network of 'anti-civilization' anarchists has graduated to violence elsewhere. Attacks include the 2010 attempted bombing of IBM's flagship nanotechnology lab near Zurich, Switzerland, and the non-lethal shooting in May this year of Roberto Adinolfi, a nuclear engineer for a subsidiary of Italian industrial conglomerate Finmeccanica, which was targeted for its links to nanotechnology (see  Nature   485 , 561; 2012 ). In Mexico, the existing social and political climate may have helped light the fuse, says Miguel M\u00e9ndez Rojas, coordinator of the department of nanotechnology and molecular engineering at the University of the Americas Puebla in Mexico. He says that the bombings cannot be understood outside the context of what he describes as a dangerous cocktail of poverty and poor education, widespread ignorance of science, ongoing social upheaval and a climate of violence. In July, Mexico City saw some of the country's largest-ever protests, over alleged fraud in this year's presidential election. And since 2006, wars with the major drug gangs have resulted in around 55,000 deaths. Human-rights groups have accused the military and police of illegal arrests, secret and prolonged detention, torture, rape and extrajudicial execution. \u201cI think we are in just the moment for a social explosion,\u201d says M\u00e9ndez Rojas. Taken together, all these developments made Mexican universities, with their burgeoning nanotechnology industry, a target for violence. In its communiqu\u00e9 from May last year, the ITS warned professors and students: \u201cIt would be best for them to walk carefully within and outside the university, that they take warning of every suspicious shape in rooms, buildings, parking areas and campus, because one of these days, we are going to make them pay for everything that they want to do to the Earth with these kinds of nano-scale technologies.\u201d \n               Escalating tension \n             The \u201cboom in eco-anarchism\u201d \u2014 as CNN Mexico describes it \u2014 has had widespread consequences. In the wake of the bombings, officials at Monterrey Tec, which was the first campus in Latin America to offer an undergraduate programme in nanotechnology, introduced a slew of security procedures, including sniffer dogs and campus sweeps. Similar procedures have been put in place at the University of the Americas Puebla, which was home to the first nanotechnology lab in Mexico. \u201cWe were very worried that we could be a target,\u201d says M\u00e9ndez Rojas, whose research encompasses the development of nanomaterials for tackling cancer and simple toxicology tests on nanoparticles. After the first attacks last year, he was warned that the ITS was going to target campuses outside Mexico City. On his suggestion, he says, the university formed a task force of professors, security staff and administrators to respond to threats. The campus implemented car checks and a policy that visitors can meet professors only with an appointment; a visitor today undergoes a 15-minute identity check, and is escorted to their meeting by two security guards. M\u00e9ndez Rojas says that he doesn't receive some visitors as a result, but that, despite the hassles, \u201cI feel safer\u201d. There have been false alarms, including one at Monterrey Tec\u2019s Puebla campus last August. In all, at least ten campuses have received bomb threats, although it is unclear whether they were sent by the ITS or copycats. Greenpeace Mexico, criticized by the ITS for having a soft stance on environmental issues, received an incendiary device from the group last November. Universities in seven states and the capital city have implemented increased security controls, including random bag checks and bomb-evacuation drills, but the Mexican National Association of Universities and Higher Education Institutions warns that only one-third of campuses in the country have taken sufficient action. The increased security has met with criticism from some quarters. In March, Hugo Aboites, an education specialist at the Autonomous Metropolitan University in Xochimilco, told  La Jornada , one of the country's leading national daily newspapers, that stringent security precautions could create an environment of \u201cinstitutionalized fear\u201d. The role of universities, he said, is to \u201ctrain and impart knowledge, not to reproduce police control of the population\u201d. But M\u00e9ndez Rojas says that research activities have not been thrown off course. Despite the attacks, he says, the number of students enrolled in nanotechnology programmes across the country rose to 800 this year, up from 500 in 2011. \u201cApart from the fear some people may be feeling about the subject, not much will change in the academic community. Researchers in nanoscience and nanotechnology won't switch. They'd lose decades' worth of work and millions in investment,\u201d he says. Some researchers in Mexico say that more-moderate groups are stoking fears about nanotechnology. One such body is the Action Group on Erosion, Technology and Concentration (ETC, pronounced et cetera), a small but vocal non-profit organization based in Ottawa, Canada, which was one of the first to raise concerns about nanotechnology and has to a large extent framed the international discussion. Silvia Ribeiro, the group's Latin America director, based in Mexico City, says that the organization has no links to the ITS. The bombings were a \u201csick development\u201d, she says. \u201cThese kinds of attacks \u2014 they are benefiting the development of nanotechnology,\u201d she says. \u201cIt polarized the discussion. Do you want nanotech or the bomb?\u201d ETC wants to see a moratorium on all nanotechnology research, says Ribeiro, who is the lead author on many of the group's reports criticizing nanotechnology research and commercialization. She says that there have not been enough toxicological studies on engineered nanoparticles, and that no government has developed a regulatory regime that explicitly addresses risk at the nanoscale. However, ETC also infuriates researchers by issuing warnings of a more speculative nature. For example, it has latched on to the concept of 'grey goo' \u2014 self-replicating nanorobots run wild \u2014 that was raised in the book  Engines of Creation  (Doubleday, 1986) by nanotechnology engineer Eric Drexler. In ETC's primer on nanoscale technologies, it says that the \u201clikely future threat is that the merger of living and non-living matter will result in hybrid organisms and products that are not easy to control and behave in unpredictable ways\u201d. Ribeiro has also criticized genetic modification and vaccination against human papillomavirus in a weekly column in  La Jornada . M\u00e9ndez Rojas says that ETC \u201cpromotes beliefs, but they are not based on facts, and we need a public discussion of the facts\u201d. The sentiment is echoed by Beatriz Xoconostle C\u00e1zares, a biotechnology researcher at Cinvestav, who is experimenting with transgenic crops resistant to drought and insects \u2014 and who regularly debates with ETC in public forums. Last September, Xoconostle arrived at work to find that her lab had been set on fire. A month later, arsonists attacked the lab of a neighbouring researcher. \n               Open debate \n             Xoconostle does not accuse ETC of responsibility for these acts, but she worries that the organization's communications are helping to spread fears about technology. \u201cThese are small groups. But they know how to communicate, and that's a huge advantage. It's becoming a larger group of people who oppose these things.\u201d Xoconostle fears that extremist groups might adopt such views and use them to support their acts. Ribeiro denies that ETC's reports are not based on facts and says that \u201cwe have nothing to do with ITS and we strongly and publicly have condemned their violence. Those who exercise violence and those who bluntly and uncritically defend nanotech coincide in hindering a real public open debate on the facts.\u201d The real question now is whether the violence will recur \u2014 or spread. The nanotechnology-activist movement does seem to be gaining momentum. For the past four years, nano-critical groups have held an annual International Nanotechnology Activist Summit; the one last October welcomed 14 environmental and consumer-advocacy groups worldwide, including the European Environmental Bureau \u2014 a Brussels-based federation of European green groups, which says it represents a combined membership of 15 million people. Opposition to nanotechnology has sometimes been hostile outside Mexico. In 2009 and 2010, protesters in France shut down public debates on nanotechnology in Grenoble, Rennes, Lyons and Marseilles. Pi\u00e8ces et Main d'Oeuvre (Parts and Labour), a Grenoble-based group, has organized protests in the city outside Minatec, France's flagship nanotechnology research centre. But Barbara Harthorn, director of the Center for Nanotechnology in Society at the University of California, Santa Barbara, says that most debate about nanotechnology so far has been measured. She has tracked 125 green groups around the world in an ongoing study of engagement in nanotechnology by non-governmental organizations. She says that most groups restrict themselves to issues of environmental health and safety rather than the more speculative scenarios painted by ETC and the ITS. At the same time, public awareness of the topic is extremely low, says Harthorn. She collaborated on a meta-analysis of 22 surveys done in the United States, Canada, Europe and Japan between 2002 and 2009, which found that, on average, more than 51% of survey respondents report that they know \u201cnothing at all\u201d about nanotechnology (T. Satterfield  et al .  Nature Nanotechnol.   4 , 752\u2013758; 2009 ). \u201cThere's a huge public that is undecided, which means that opinion is still highly malleable,\u201d says Harthorn. Her own surveys have shown no evidence that the public in general has the same aversion to nanotechnology that has been seen for genetic engineering, because nanotechnology is not viewed as 'messing with nature' in the same way. But subjects' reactions depend on the type of nanotechnology being considered: applications in clean energy are embraced, but uses in food or the far-reaching idea of human 'nano-enhancement' elicit a sharply negative reaction. All this means that there is still a lot to play for in public perception, says Harthorn. If the discourse becomes framed by more speculative notions, the moderate public stance could be lost. And that creates an opportunity for scientists to tip the debate. Most nanotechnology researchers acknowledge that some areas of their work raise legitimate environmental, health and safety concerns. The most important response, says Gerardo Herrera Corral, is for scientists to engage with the public to address and dispel concerns. Herrera is head of Mexico's only experiment at CERN, Europe's particle-physics laboratory near Geneva, Switzerland, and he points to how CERN dealt with public fears that its Large Hadron Collider could create a black hole that would swallow Earth. \u201cWe set up a committee to deal with this. We looked into the real dangers. There were journal articles and we answered all the e-mails we got from people. I mean top-level physicists answering thousands of e-mails.\u201d \u201cBut this is work we should all be doing,\u201d says Herrera. \u201cEven if it's extra work on top of all the other things we have to do. It's just part of our job now.\u201d In Mexico, bomb threats are also becoming part of the job. On 31 May, a hoax threat forced evacuations at the University of Xalapa. The same day, emergency services and military forces descended on the faculty of engineering at the University of Veracruz in Boca del Rio after a suspicious device was found. It turned out to be a professor's forgotten briefcase. For Xoconostle, the fear is taking its toll. \u201cThe fact is I am kind of worried. I'm terrified of these people,\u201d the soft-spoken scientist says. \u201cWe are in a fight.\u201d See Editorial  page 557 \n                     Anarchists attack science 2012-May-28 \n                   \n                     Nanomaterials offer hope for cerebral palsy 2012-Apr-18 \n                   \n                     Stand up against the anti-technology terrorists 2011-Aug-22 \n                   \n                     Environmental activism: In the name of nature 2006-Oct-04 \n                   \n                     Nature Focus: Public perceptions of nanotechnology \n                   \n                     Monterrey Institute of Technology \n                   \n                     ReLANS report on Nanotechnologies in Latin America \n                   Reprints and Permissions"},
{"file_id": "489022a", "url": "https://www.nature.com/articles/489022a", "year": 2012, "authors": [{"name": "Kerri Smith"}], "parsed_as_year": "2006_or_before", "body": "As he revolutionizes ideas about dinosaur evolution, Xing Xu is helping to make china into a palaeontological powerhouse. Palaeontologist Xing Xu bends low over a beautifully preserved specimen of the ancient bird species  Sapeornis , entombed in a glass museum cabinet in Shandong Province, China. The bird's spindly legs stretch as if it were about to stride forward, even though the creature has been dead for more than 110 million years. From its chicken-sized body juts a fine neck, a delicate skull and the clear imprint of a long, jaunty tail feather \u2014 something never seen before in this species. Sapeornis  is one of hundreds of plumed specimens pouring out of fossil beds in China \u2014 most notably out of the rock formations in Liaoning Province, northeast of Beijing. Some of the Liaoning fossils are the earliest known birds. Others are feathered dinosaurs, the group that spawned birds millions of years before the age of  Sapeornis . Together, they are among the most important finds in dinosaur palaeontology in the past century. Xu is at the centre of that bonanza. He is \u201cthe go-to man in China for anything people want to know about dinosaurs\u201d, says Paul Barrett, who studies dinosaurs at the Natural History Museum in London and first met Xu in the 1990s, when both were graduate students. Xu, who is based at the Institute of Vertebrate Paleontology and Paleoanthropology (IVPP) in Beijing, has named 60 species so far \u2014 more than any other vertebrate palaeontologist alive today. And he is only 43 years old. In describing the flock of feathered fossils, Xu has helped to show that birds arose from dinosaurs, ending decades of debate. Along the way, he has shed light on the origins of feathers and flight. And he has bucked 150 years of received wisdom by declaring that the fabled genus  Archaeopteryx  is not the oldest known bird, but rather belonged to a group of dinosaurs removed from the avian line 1 . \u201cHe has patience and persistence \u2014 and an audacity when scientific evidence calls for it,\u201d says Zhe-Xi Luo, who studies fossil mammals at the University of Chicago in Illinois. Kerri Smith hears why China is the place to be for dino palaeontologists as she accompanies Xing Xu around a fossil site in Zhucheng. Even as he unveils new species at a breakneck pace, Xu is concerned about the future of palaeontology in China and the commercialization of fossils. Many of the feathered fossils from Liaoning are dug up by local farmers tending their fields, who try to sell them to the highest bidder. This fossil 'grey market' \u2014 it is technically illegal to sell fossils in China, but the practice continues openly \u2014 encourages fakery and causes specimens to disappear into private collections. By cultivating a vast network of contacts at important fossil sites in Liaoning and elsewhere, Xu has laboured to ensure that scientists gain access to the best specimens. It's a job that requires hard work and luck, he says. \u201cWhen I started my career, I never expected that I would have so many discoveries.\u201d \n               Dino Disney \n             Nobody knows what happened about 80 million years ago near what is now the town of Zhucheng in Shandong Province, but it must have been disastrous. On the outskirts of the city, about an hour's flight south of Beijing, hundreds of bones litter a 300-metre stretch of hillside. Palaeontologists have been finding dinosaurs near Zhucheng for decades, but in 2008 local farmers unearthed a large community of duck-billed dinosaurs and others that had apparently died en masse. Xu was called in to investigate and he is now studying a possible new species of ceratopsian \u2014 herbivorous beaked dinosaurs \u2014 recovered from the fossil bed. He is also acting as scientific consultant to local administrators, who want to build a dinosaur theme park in Zhucheng. During a visit to the site in June, Xu had hoped to do research, but he ended up correcting display captions and reading through proposals for the park. \u201cIn terms of scale it may be comparable to Disneyland,\u201d says Xu, a hint of trepidation in his voice. Fossils are a thriving business as well as a science in China, and palaeontologists often have to negotiate with local prospectors and directors of museums and tourism bureaux to gain access to fossil sites and specimens. Despite Xu's boyish appearance, he is a dexterous diplomat and has managed to arrange for the most scientifically interesting specimens to cross his desk, wherever they are found. Thanks to those arrangements, Xu has had a bounty of fossils to work on, particularly from Liaoning. The creatures unearthed there are remarkably well preserved, perhaps because they were entombed quickly during volcanic eruptions and mudslides between 160 million and 120 million years ago. The rocks record fine details including the imprints of feathers, which allowed Xu to determine 2  that a fierce 9-metre-long tyrannosaurid, which he named  Yutyrannus , had a coat of long feathers (see 'Xing Xu's feathered friends'). One of Xu's favourite Liaoning fossils,  Microraptor , is one of the smallest known dinosaurs not on the avian line. From the imprint of feathers, Xu and his colleagues concluded 3  that  Microraptor  had four wings \u2014 one on each arm and leg \u2014 and could probably glide. From other Liaoning specimens, he has established 4  that some feathered dinosaurs slept curled up, just like birds. When he can find the time, Xu does fieldwork of his own (see 'Dinosaur hunting grounds'). He led teams to three sites this summer. Near the northern Chinese town of Lingwu, the excavations turned up a new sauropod \u2014 a dinosaur from the same group as  Diplodocus . In the autonomous region of Inner Mongolia, the Xu group found a new type of bird and what may be a previously unknown theropod \u2014 the dinosaur lineage that led to birds. At another northern site, he uncovered a collection of beaked dinosaurs. To power this dinosaur-discovery factory, Xu runs a lab of 14 people, including five students, seven preparators who carefully separate the fossils from the surrounding rock, one artist and a photographer. Those resources have been known to induce jealousy in Western palaeontologists. The Natural History Museum in London, for example, has just two full-time preparators for about 20 palaeontology curators and researchers, says Barrett. Xu didn't set out to be a palaeontologist; in fact, he had no idea what a dinosaur was until he entered university. He was born in the poor Western province of Xinjiang in 1969, a few years after his parents relocated there as part of a Cultural Revolution development initiative in which educated couples were forced to move to rural provinces. He excelled in school and in 1988 earned a place at Peking University in Beijing, the nation's premier university. Xu wanted to study economics, but at the time students had no choice in their degrees. For reasons that are unclear to him, he was obliged to study palaeontology. \n               Late starter \n             Xu's interest in the subject picked up only when he reached the third year of a master's degree at the IVPP. He was studying two specimens that his adviser, Xijin Zhao, had discovered in the 1960s and 1970s and had not found time to analyse fully. They turned out to be the earliest examples of ceratopsians, pushing the record of this group back by up to 30 million years, from the early Cretaceous period, which started 145 million years ago, to the middle or late Jurassic period 5 . \u201cMy excitement [over a fossil] is proportional to the information you get from it,\u201d says Xu. \u201cAnd those were really exciting fossils.\u201d Xu's timing was perfect. While he was working on his master's thesis, the trickle of dinosaur species turning up in China grew to a deluge. Funding for palaeontology was increasing; farmers in Liaoning started recognizing the value of the fossils they sometimes found; and a burst of construction meant that new fossils were being unearthed more frequently. As a budding dinosaur palaeontologist, Xu was well placed to study some of those specimens. However, fortuitous timing can explain only a portion of Xu's productivity. A large part comes from his legendary work ethic. \u201cIf I want to learn something I put all my time into it,\u201d says Xu. He currently has more than 20 manuscripts in draft form, including one on the  Sapeornis  specimen from the Shandong Tianyu Museum of Nature. He estimates that there are eight or nine new species among the crop of fossils awaiting publication. Even away from his office, any spare moment is filled with talk of projects. Outside the Tianyu museum, Xu chats to a colleague about  Microraptor  and \u2014 to make an anatomical point \u2014 starts drawing a diagram of the creature's feathers in the dust on a nearby car. Xu has an international outlook that also contributes to his success. From the start of his career, he has done what has not come naturally to many Chinese palaeontologists \u2014 building up a fat book of contacts in the United Kingdom and the United States, and publishing much of his work in English in international journals. Playing to a tougher international audience was \u201creally important for my career\u201d, says Xu. Chinese journals, he adds, don't require the same level of critique and peer review as international publications. Luo says that Xu is one of only a few palaeontologists in China to embrace cladistics \u2014 a process for determining evolutionary relationships by analysing the features that groups share. Western researchers and international journals have been using cladistics for more than two decades, but it has been slow to catch on in China. Within his own country, Xu crosses boundaries between the academic and commercial sectors. For example, he has forged a close relationship with Xiaoting Zheng, the former head of a local state-owned gold mine who is now a keen amateur fossil collector, a budding palaeontologist and director of the Tianyu museum. In his museum, Zheng has accumulated one of the largest assemblages of feathered dinosaur fossils in the world. Over the years, Xu has been teaching him what to look out for in his purchases and has analysed some of the acquisitions. The two make a formidable team. \n               Feathers flying \n             Last year 1 , Xu made a big splash with a specimen from the Tianyu museum's collection: a small feathered dinosaur that he named  Xiaotingia zhengi  to honour Zheng. The creature had a shallow snout, a distinctive skull shape and other features that led Xu and his colleagues to place it as a close relative of  Archaeopteryx . That animal has long been regarded as the oldest known bird, but Xu and his colleagues performed a cladistic analysis that knocked  Archaeopteryx  from its special perch on the bird lineage, relegating it to a different branch along with a host of other feathered dinosaurs. That study has met resistance from some other palaeontologists, who question the strength of the cladistic analysis and say that the evolutionary relationships will remain unclear until more early birds and their close relatives are discovered. The Liaoning fossils have led Xu to make other bold proposals about the origins of flight. The discoveries of  Microraptor  and  Anchiornis , another four-winged dinosaur, led Xu to argue 6  that the four-winged trait was not an evolutionary dead end, as had been previously assumed, but could actually have been the transitional step between dinosaurs and birds. The feathered dinosaur fossils have also provided some of the first hard evidence for when and why feathers evolved. \u201cFor most of the past century, the classic issue in feather evolution was that the fossil record told us essentially nothing,\u201d says Richard Prum, who studies the evolution of birds at Yale University in New Haven, Connecticut. \u201cWhat's happened with the Liaoning formation has been a totally new chapter.\u201d In the past, palaeontologists had presumed that when feathers first arose, they helped bird ancestors to fly. But on the basis of his discoveries, Xu makes the controversial argument that most dinosaurs probably had at least a smattering of plumage, which would mean that feathers originally served other functions, such as attracting mates or insulating against the cold. \n               Role model \n             With his extraordinary track record, Xu brings to mind the prodigious US palaeontologists Othniel Marsh and Edward Cope, who discovered dozens of dinosaurs in the late nineteenth century in a frenetic competition that became known as the bone wars. But whereas those Victorian fossil hunters made frequent errors, such as giving new names to species that had already been described, Xu is a careful researcher who does not rush into print. His published record of new species has rarely been challenged, says Mike Benton, a palaeontologist at the University of Bristol, UK, who has analysed the accuracy of dinosaur researchers. Xu would like to see Chinese science as a whole become more careful. \u201cChinese culture is a problem for science because it's not logical enough,\u201d says Xu during a trip this summer, as his driver gaily overtakes on the wrong side of the road. \u201cTraditionally people don't like to criticize, either. For peer review you have to criticize in some way\u2026\u201d . He breaks off mid-sentence to answer a phone call in Mandarin for a few minutes, before resuming exactly where he left off \u201c\u2026but here in China we don't have a real peer-review system.\u201d Another problem hanging over Chinese palaeontology is fakery. Xu is keenly aware of it. In 2000, he helped 7  to unmask one of the biggest hoaxes in a generation: a composite specimen named  Archaeoraptor , made up of the upper body of an ancient bird and the tail of the dinosaur  Microraptor . Scientists are getting better at spotting fakes, says Xu, but they do still crop up, because poor farmers know that they can sell the most unusual fossils to museums or institutes for hefty sums. \u201cWe have the greatest resources in palaeontology now,\u201d says Zhonghe Zhou, director of the IVPP, \u201cbut on the other hand, the destruction of localities, the faking \u2014 those kinds of things are often the most severe. The law isn't good enough.\u201d Xu worries about the future of his profession, particularly the next generation of scientists. His current students aren't showing the dedication that their boss would like. \u201cThey don't work as hard as me,\u201d he says. \u201cMaybe I ask too much, maybe that's my problem.\u201d Qing-Jin Meng, director of the Beijing Museum of Natural History, says, \u201cExcellent palaeontologists [such as Xu] are hard to find.\u201d Part of the problem may be the globalization of Chinese palaeontology, he adds. \u201cMany students who have great potential have gone to the United States and European countries to study.\u201d Xu says that if only he could find the time, he would like to write articles about how to improve Chinese science. But so far he has published only one blog post in Mandarin. \u201cHonestly, I don't like it much. I'd rather do science,\u201d he says. Xu's packed schedule can be hard on his family \u2014 his wife Zhonghia Zhou, who is a secretary at the Institute for Geology and Geophysics in Beijing, and their two boys, aged 7 and 12. \u201cMy wife complains because the kids are growing up,\u201d confesses Xu. \u201cShe says they need a male example. And I thought, yeah, that's important.\u201d So in the past couple of years he has tried to spend more time at home, helping with homework, playing table tennis with his wife and taking his family on days out to Beijing's parks. Even the director of the IVPP recognizes a candidate for burn-out when he sees one: \u201cHe should slow down a bit!\u201d says Zhou. \u201cYou can't study everything \u2014 you need time for hobbies.\u201d To that end, Xu and Zhou sometimes play badminton on the court installed in the entrance hall of the IVPP. It is unlikely that Xu's hobbies will eat into his prodigious output too much. Back in his office in Beijing after the trip to Zhucheng, Xu rummages through the floor-to-ceiling cupboards lining two walls. He pulls out slabs of rock, pointing out salient features and clues that he might have an unknown species on his hands. More than setting records by finding new creatures, Xu is interested in asking and answering questions about a far-gone era, when his country was filled with a dizzying array of feathered dinosaurs and birds. He is keen, for example, to continue exploring how non-avian dinosaurs developed feathers and whether the plumage differed from that of modern birds. As he looks over the fossils in his office, Xu's eyes glint with a blend of tiredness and excitement. Luo, who has watched Xu's career take off, sees no end to the potential discoveries. \u201cFossils are silent,\u201d says Luo. \u201cIt takes an insightful palaeontologist to tell their story, and Xu Xing is a fantastic storyteller.\u201d\n \n                     Archaeopteryx no longer first bird 2011-Jul-27 \n                   \n                     Oldest feathered dinosaur found 2009-Sep-25 \n                   \n                     Dinosaur's digits show how birds got wings 2009-Jun-17 \n                   \n                     Xing Xu \n                   \n                     Institute of Vertebrate Paleontology and Paleoanthropology \n                   Reprints and Permissions"},
{"file_id": "489046a", "url": "https://www.nature.com/articles/489046a", "year": 2012, "authors": [{"name": "Brendan Maher"}], "parsed_as_year": "2006_or_before", "body": "First they sequenced it. Now they have surveyed its hinterlands. But no one knows how much more information the human genome holds, or when to stop looking for it. Ewan Birney would like to create a printout of all the genomic data that he and his collaborators have been collecting for the past five years as part of ENCODE, the Encyclopedia of DNA Elements. Finding a place to put it would be a challenge, however. Even if it contained 1,000\u00a0base pairs per square centimetre, the printout would stretch 16\u00a0metres high and at least 30 kilometres long. ENCODE was designed to pick up where the Human Genome Project left off. Although that massive effort revealed the blueprint of human biology, it quickly became clear that the instruction manual for reading the blueprint was sketchy at best. Researchers could identify in its 3\u00a0billion letters many of the regions that code for proteins, but those make up little more than 1% of the genome, contained in around 20,000\u00a0genes \u2014 a few familiar objects in an otherwise stark and unrecognizable landscape. Many biologists suspected that the information responsible for the wondrous complexity of humans lay somewhere in the \u2018deserts\u2019 between the genes. ENCODE, which started in 2003, is a massive data-collection effort designed to populate this terrain. The aim is to catalogue the \u2018functional\u2019 DNA sequences that lurk there, learn when and in which cells they are active and trace their effects on how the genome is packaged, regulated and read. After an initial pilot phase, ENCODE scientists started applying their methods to the entire genome in 2007. Now that phase has come to a close, signalled by the publication of 30 papers, in  Nature ,  Genome Research  and  Genome Biology . The consortium has assigned some sort of function to roughly 80% of the genome, including more than 70,000 \u2018promoter\u2019 regions\u00a0\u2014\u00a0the sites, just upstream of genes, where proteins bind to control gene expression\u00a0\u2014\u00a0and nearly 400,000 \u2018enhancer\u2019 regions that regulate expression of distant genes (see  page\u00a057 ) 1 . But the job is far from done, says Birney, a computational biologist at the European Molecular Biology Laboratory\u2019s European Bioinformatics Institute in Hinxton, UK, who coordinated the data analysis for ENCODE. He says that some of the mapping efforts are about halfway to completion, and that deeper characterization of everything the genome is doing is probably only 10% finished. A third phase, now getting under way, will fill out the human instruction manual and provide much more detail. Many who have dipped a cup into the vast stream of data are excited by the prospect. ENCODE has already illuminated some of the genome\u2019s dark corners, creating opportunities to understand how genetic variations affect human traits and diseases. Exploring the myriad regulatory elements revealed by the project and comparing their sequences with those from other mammals promises to reshape scientists\u2019 understanding of how humans evolved. Yet some researchers wonder at what point enough will be enough. \u201cI don\u2019t see the runaway train stopping soon,\u201d says Chris Ponting, a computational biologist at the University of Oxford, UK. Although Ponting is supportive of the project\u2019s goals, he does question whether some aspects of ENCODE will provide a return on the investment, which is estimated to have exceeded US$185 million. But Job Dekker, an ENCODE group leader at the University of Massachusetts Medical School in Worcester, says that realizing ENCODE\u2019s potential will require some patience. \u201cIt sometimes takes you a long time to know how much can you learn from any given data set,\u201d he says. Even before the human genome sequence was finished 2 , the National Human Genome Research Institute (NHGRI), the main US funder of genomic science, was arguing for a systematic approach to identify functional pieces of DNA. In 2003, it invited biologists to propose pilot projects that would accrue such information on just 1% of the genome, and help to determine which experimental techniques were likely to work best on the whole thing. ENCODE coordinator Ewan Birney discusses consortium science with the LHC\u2019s Tejinder Virdee. The pilot projects transformed biologists\u2019 view of the genome. Even though only a small amount of DNA manufactures protein-coding messenger RNA,for example, the researchers found that much of the genome is \u2018transcribed\u2019 into non-coding RNA molecules, some of which are now known to be important regulators of gene expression. And although many geneticists had thought that the functional elements would be those that are most conserved across species, they actually found that many important regulatory sequences have evolved rapidly. The consortium published its results 3  in 2007, shortly after the NHGRI had issued a second round of requests, this time asking would-be participants to extend their work to the entire genome. This \u2018scale-up\u2019 phase started just as next-generation sequencing machines were taking off, making data acquisition much faster and cheaper. \u201cWe produced, I think, five times the data we said we were going to produce without any change in cost,\u201d says John Stamatoyannopoulos, an ENCODE group leader at the University of Washington in Seattle. The 32 groups, including more than 440 scientists, focused on 24\u00a0standard types of experiment (see \u2018Making a genome manual\u2019). They isolated and sequenced the RNA transcribed from the genome, and identified the DNA binding sites for about 120 transcription factors. They mapped the regions of the genome that were carpeted by methyl chemical groups, which generally indicate areas in which genes are silent. They examined patterns of chemical modifications made to histone proteins, which help to package DNA into chromosomes and can signal regions where gene expression is boosted or suppressed. And even though the genome is the same in most human cells, how it is used is not. So the teams did these experiments on multiple cell types \u2014 at least 147 \u2014 resulting in the 1,648 experiments that ENCODE reports on this week 1 , 4 , 5 , 6 , 7 , 8 . Stamatoyannopoulos and his collaborators 4 , for example, mapped the regulatory regions in 125 cell types using an enzyme called DNaseI (see  page 75 ). The enzyme has little effect on the DNA that hugs histones, but it chops up DNA that is bound to other regulatory proteins, such as transcription factors. Sequencing the chopped-up DNA suggests where these proteins bind in the different cell types. The team discovered around 2.9 million of these sites altogether. Roughly one-third were found in only one cell type and just 3,700 showed up in all cell types, suggesting major differences in how the genome is regulated from cell to cell. The real fun starts when the various data sets are layered together. Experiments looking at histone modifications, for example, reveal patterns that correspond with the borders of the DNaseI-sensitive sites. Then researchers can add data showing exactly which transcription factors bind where, and when. The vast desert regions have now been populated with hundreds of thousands of features that contribute to gene regulation. And every cell type uses different combinations and permutations of these features to generate its unique biology. This richness helps to explain how relatively few protein-coding genes can provide the biological complexity necessary to grow and run a human being. ENCODE \u201cis much more than the sum of the parts\u201d, says Manolis Kellis, a computational genomicist at the Massachusetts Institute of Technology in Cambridge, who led some of the data-analysis efforts. The data, which have been released throughout the project, are already helping researchers to make sense of disease genetics. Since 2005, genome-wide association studies (GWAS) have spat out thousands of points on the genome in which a single-letter difference, or variant, seems to be associated with disease risk. But almost 90% of these variants fall outside protein-coding genes, so researchers have little clue as to how they might cause or influence disease. The map created by ENCODE reveals that many of the disease-linked regions include enhancers or other functional sequences. And cell type is important. Kellis\u2019s group looked at some of the variants that are strongly associated with systemic lupus erythematosus, a disease in which the immune system attacks the body\u2019s own tissues. The team noticed that the variants identified in GWAS tended to be in regulatory regions of the genome that were active in an immune-cell line, but not necessarily in other types of cell and Kellis\u2019s postdoc Lucas Ward has created a web portal called HaploReg, which allows researchers to screen variants identified in GWAS against ENCODE data in a systematic way. \u201cWe are now, thanks to ENCODE, able to attack much more complex diseases,\u201d Kellis says. \n               Are we there yet? \n             Researchers could spend years just working with ENCODE\u2019s existing data \u2014 but there is still much more to come. On its website, the University of California, Santa Cruz, has a telling visual representation of ENCODE\u2019s progress: a grid showing which of the 24 experiment types have been done and which of the nearly 180\u00a0cell types ENCODE has now examined. It is sparsely populated. A handful of cell lines, including the lab workhorses called HeLa and GM12878, are fairly well filled out. Many, however, have seen just one experiment. Scientists will fill in many of the blanks as part of the third phase, which Birney refers to as the \u2018build out\u2019. But they also plan to add more experiments and cell types. One way to do that is to expand the use of a technique known as chromatin immunoprecipitation (ChIP), which looks for all sequences bound to a specific protein, including transcription factors and modified histones. Through a painstaking process, researchers develop antibodies for these DNA binding proteins one by one, use those antibodies to pull the protein and any attached DNA out of cell extracts, and then sequence that DNA. But at least that is a bounded problem, says Birney, because there are thought to be only about 2,000 such proteins to explore. (ENCODE has already sampled about one-tenth of these.) More difficult is figuring out how many cell lines to interrogate. Most of the experiments so far have been performed on lines that grow readily in culture but have unnatural properties. The cell line GM12878, for example, was created from blood cells using a virus that drives the cells to reproduce, and histones or other factors may bind abnormally to its amped-up genome. HeLa was established from a cervical-cancer biopsy more than 50\u00a0years ago and is riddled with genomic rearrangements. Birney recently quipped at a talk that it qualifies as a new species. ENCODE researchers now want to look at cells taken directly from a person. But because many of these cells do not divide in culture, experiments have to be performed on only a small amount of DNA, and some tissues, such as those in the brain, are difficult to sample. ENCODE collaborators are also starting to talk about delving deeper into how variation between people affects the activity of regulatory elements in the genome. \u201cAt some places there\u2019s going to be some sequence variation that means a transcription factor is not going to bind here the same way it binds over here,\u201d says Mark Gerstein, a computational biologist at Yale University in New Haven, Connecticut, who helped to design the data architecture for ENCODE. Eventually, researchers could end up looking at samples from dozens to hundreds of people. The range of experiments is expanding, too. One quickly developing area of study involves looking at interactions between parts of the genome in three-dimensional space. If the intervening DNA loops out of the way, enhancer elements can regulate genes hundreds of thousands of base pairs away, so proteins bound to the enhancer can end up interacting with those attached near the gene. Dekker and his collaborators have been developing a technique to map these interactions. First, they use chemicals that fuse DNA-binding proteins together. Then they cut out the intervening loops and sequence the bound DNA, revealing the distant relationships between regulatory elements. They are now scaling up these efforts to explore the interactions across the genome. \u201cThis is beyond the simple annotation of the genome. It\u2019s the next phase,\u201d Dekker says. The question is, where to stop? Kellis says that some experimental approaches could hit saturation points: if the rate of discoveries falls below a certain threshold, the return on each experiment could become too low to pursue. And, says Kellis, scientists could eventually accumulate enough data to predict the function of unexplored sequences. This process, called imputation, has long been a goal for genome annotation. \u201cI think there\u2019s going to be a phase transition where sometimes imputation is going to be more powerful and more accurate than actually doing the experiments,\u201d Kellis says. Yet with thousands of cell types to test and a growing set of tools with which to test them, the project could unfold endlessly. \u201cWe\u2019re far from finished,\u201d says geneticist Rick Myers of the HudsonAlpha Institute for Biotechnology in Huntsville, Alabama. \u201cYou might argue that this could go on forever.\u201d And that worries some people. The pilot ENCODE project cost an estimated $55 million; the scale-up was about $130 million; and the NHGRI could award up to $123 million in the next phase. Some researchers argue that they have yet to see a solid return on that investment. For one thing, it has been difficult to collect detailed information on how the ENCODE data are being used. Mike Pazin, a programme director at the NHGRI, has scoured the literature for papers in which ENCODE data played a significant part. He has counted about 300, 110 of which come from labs without ENCODE funding. The exercise was complicated, however, because the word \u2018encode\u2019 shows up in genetics and genomics papers all the time. \u201cNote to self,\u201d says Pazin wryly, \u201cmake up a unique project name next time around.\u201d A few scientists contacted for this story complain that this isn\u2019t much to show from nearly a decade of work, and that the choices of cell lines and transcription factors have been somewhat arbitrary. Some also think that the money eaten up by the project would be better spent on investigator-initiated, hypothesis-driven projects\u00a0\u2014\u00a0a complaint that also arose during the Human Genome Project. But unlike the genome project, which had a clear endpoint, critics say that ENCODE could continue to expand and is essentially unfinishable. (None of the scientists would comment on the record, however, for fear that it would affect their funding or that of their postdocs and graduate students.) Birney sympathizes with the concern that hypothesis-led research needs more funding, but says that \u201cit\u2019s the wrong approach to put these things up as direct competition\u201d. The NHGRI devotes a lot of its research dollars to big, consortium-led projects such as ENCODE, but it gets just 2% of the total US National Institutes of Health budget, leaving plenty for hypothesis-led work. And Birney argues that the project\u2019s systematic approach will pay dividends. \u201cAs mundane as these cataloguing efforts are, you\u2019ve got to put all the parts down on the table before putting it together,\u201d he says. After all, says Gerstein, it took more than half a century to get from the realization that DNA is the hereditary material of life to the sequence of the human genome. \u201cYou could almost imagine that the scientific programme for the next century is really understanding that sequence.\u201d \n                     Spinning threads 2012-Sep-05 \n                   \n                     Presenting ENCODE 2012-Sep-05 \n                   \n                     Genomics: ENCODE explained 2012-Sep-05 \n                   \n                     The making of ENCODE: Lessons for big-data projects 2012-Sep-05 \n                   \n                     Human genome at ten: Life is complicated 2010-Mar-31 \n                   \n                     Genome project turns up evolutionary surprises 2007-Jun-13 \n                   \n                     Nature special: ENCODE \n                   \n                     Nature News special: The human genome at ten \n                   \n                     Scientfic American : Hidden treasures in \u2018junk\u2019 DNA \n                   \n                     ENCODE \n                   \n                     HaploReg \n                   Reprints and Permissions"},
{"file_id": "488572a", "url": "https://www.nature.com/articles/488572a", "year": 2012, "authors": [{"name": "Matthew Chalmers"}], "parsed_as_year": "2006_or_before", "body": "Physicists are planning the powerful accelerators they will need to study the Higgs boson and its interactions in detail. When particle physicists around the world woke up on 5 July, the scenes of joy, relief and tears were still fresh in their minds \u2014 along with a huge unanswered question. The memories were of celebrations the previous day, when researchers announced that a new particle very much like the long-sought Higgs boson had at last been found in data from the Large Hadron Collider (LHC) at CERN, Europe's particle-physics laboratory outside Geneva in Switzerland. The question promised to define their discipline's whole future. Is the particle a Higgs boson of maximum simplicity, as predicted by the 40-year-old standard model of particle physics? Or is it something more complex and interesting that will point towards a deeper, more complete theory? Physicists hope and expect that the LHC will give them some answers over the next few years. But they are already honing their sales pitches for a machine to follow the LHC \u2014 a 'Higgs factory' that would illuminate such a theory with measurements far more precise than the LHC can provide. \u201cWe know that there must be new physics beyond the standard model,\u201d says Barry Barish, a physicist at the California Institute of Technology in Pasadena. That's guaranteed, he and other physicists argue, by the existence of phenomena that don't easily fit into the model, such as the invisible scaffold of 'dark matter' suspected to comprise a quarter of the mass density of the Universe, or the ability of particles called neutrinos to 'oscillate' from one form to another. Barish heads the global consortium that is designing the International Linear Collider (ILC), one of the candidates for the next big machine. Even if no one yet knows what the new physics will involve, he says, \u201cour strategy is to be ready in the event things fall in place\u201d. The cost, timescales and capabilities of the ILC and other candidate machines will be scrutinized at the European Strategy for Particle Physics workshop in Krakow, Poland, on 10\u201312 September, which will set out the priorities for this field in Europe for the next five years. American particle physicists are planning a similar exercise at a meeting at Snowmass, Colorado, in June 2013. But plans are one thing; reality is another. Funding any new machine, particularly in an economic downturn, will be a \u201cdaunting task\u201d, says Christopher Llewellyn-Smith, director of energy research at the University of Oxford, UK, and director of CERN at the time when the LHC was approved. \u201cIt will depend on what other new particles the LHC finds, on whether the new facility is unanimously supported by the community, and on its cost,\u201d he explains. \u201cEven if the physics case is as strong as that for the LHC, and the cost is such that it can be done with a constant global high-energy physics budget, it will still be tough.\u201d \n               The LHC lives on \n             A key issue under discussion at the Krakow workshop will be how far the LHC teams can go in measuring the properties of the new particle. The physicists working there can expect much more data, plus major upgrades over the next ten years. They already have one piece of good news: the mass of the Higgs-like particle \u2014 roughly 125 billion electron volts (GeV) in the energy units favoured by physicists \u2014 turns out to lie towards the light end of the range that theorists had estimated. This has two important consequences: it means that a relatively modest new collider would be sufficient to produce the Higgs in bulk, and it gives the new particle a rich variety of decay modes that will make it easier for physicists to study its interactions with other standard-model particles. One priority, for example, is to check the standard model's prediction for how the Higgs interacts with standard-model fermions: entities such as electrons, muons and quarks that have an intrinsic angular momentum, or 'spin', of \u00bd in quantum units. The probability of an interaction with each particle is supposed to be proportional to its mass \u2014 not least because, in the standard model, interaction with the Higgs is what creates the mass. Another priority is to verify that the new particle's own intrinsic spin has the standard-model value of 0. The LHC physicists can already say that the new particle is a boson \u2014 meaning that its spin in quantum units is 0, 1, 2 or some other integer \u2014 and that the integer cannot be 1; both conclusions follow from the particle's observed decay into pairs of photons, which are spin-1 bosons. Physicists do not have crazy theories involving bosons with a spin greater than 2, says CERN physicist Albert de Roeck, a scientific coordinator for the team working on the Compact Muon Solenoid detector at the LHC, so their task now is to determine whether it is a spin-2 or a spin-0 'scalar' boson as predicted. The LHC will settle the spin question, says CERN's director-general Rolf Heuer, but it is less clear how far the LHC can go in testing the new boson's couplings to other particles \u2014 in particular the 'self-interaction' by which the Higgs gives itself mass. At present, all the LHC physicists can say is that the new boson's interactions with other particles are consistent with the standard-model predictions within the present measurement uncertainties of 30\u201340%. According to de Roeck, the collider should get those uncertainties down to 20% by the end of this year, and conceivably down to \u201ca few per cent\u201d over the next 10\u201315 years. But that, for many physicists, is precisely why they need a next-generation machine. A truly stringent test of the standard model, which would reveal tiny deviations that could point the way towards better models, demands that researchers measure the Higgs's interaction with other particles to within 1% uncertainty, possibly as little as 0.1% should the precision of theoretical predictions also improve in the next few years. And that is a level the LHC is unlikely to reach. The machine is like a sledgehammer: it crashes together beams containing hundreds of billions of protons at energies that will eventually reach 7 trillion electron volts (TeV) per beam. This is good for discovering new massive particles, but less so for making precision measurements, because protons are chaotic seas of quarks and gluons that make the collisions messy. Instead, every proposal for a next-generation machine calls for some form of lepton collider (see 'After the Higgs'). Leptons, a group of light particles that includes electrons, muons and neutrinos, sidestep the messiness by not participating in the strong quark\u2013gluon interactions that produce it. Leptons are elementary and interact only through the relatively feeble electromagnetic and weak forces. As a result, lepton machines are more like scalpels than sledgehammers: their collisions can be tuned to the mass of a particular particle and the spray of particles created would be comparatively clean and simple to interpret. \n               Muons or electrons \n             A relatively cheap option, argue some physicists, would be to place the tubes of a new accelerator alongside the LHC in the existing tunnel, and use them to collide opposing beams of electrons and antimatter electrons (better known as positrons). This proposal, known as LEP3 in honour of the Large Electron\u2013Positron (LEP) collider that occupied the tunnel before the LHC's construction began in 2000, emerged only in the past year as preliminary evidence for the new particle piled up. LEP3 could produce Higgs bosons with just 120 GeV per beam \u2014 a total energy of 240 GeV \u2014 only a notch up from the original LEP's maximum of 209 GeV. Its production would be boosted further by recent technological advances that would allow for a collision rate, or 'luminosity', some 500 times greater than LEP could have achieved. Building LEP3 in the LHC tunnel could allow some of the LHC's particle detectors to be reused, as well as making use of CERN's existing infrastructure for power, maintenance and data-taking. Such savings bring LEP3's estimated cost down to between US$1billion and $2 billion, far lower than the LHC's $6-billion price tag. \u201cThe idea is there to kill,\u201d says LEP3 advocate Alain Blondel at the University of Geneva, who points out that there should be room to build the new lepton collider without removing the LHC: the tunnel was originally intended to have both types of collider running simultaneously. For all its advantages as a high-output Higgs factory, LEP3 would not be able to study anything much heavier than the Higgs. And that could be a problem if, as many particle physicists hope, the LHC ends up discovering heavier new particles that theorists are predicting from ideas such as supersymmetry, or even finding extra dimensions. Stepping up the energy of LEP3 to study the heavier particles would be virtually impossible because of losses from synchrotron radiation \u2014 the stream of photons emitted when any charged particle moves along a curved path. This isn't so much of a problem for the LHC's protons, because energy losses from synchrotron radiation fall off dramatically for particles of higher mass, and protons outweigh electrons by a factor of nearly 2,000. But losses in LEP3 would be severe. The only way to increase the accelerator's energy would be to increase its radius, which would require a new tunnel. Some physicists have talked about drilling a new tunnel stretching out beneath Lake Geneva, and installing an 80-kilometre circular electron\u2013positron machine, although that's not something for the foreseeable future, says Heuer. Meanwhile, physicists around the world have been exploring concepts for an alternative Higgs factory that would be much smaller than LEP3, perhaps as little as 1.5 km in circumference. By colliding beams of muons, electron-like particles with 207 times the mass of an electron, such a machine has negligible synchrotron-radiation losses and could produce tens of thousands of Higgs bosons from a total collision energy of just 125 GeV, as opposed to LEP3's 240 GeV. It would also be capable of going to much higher energies, to study heavier particles (see  Nature   462 , 260\u2013261; 2009 ). But a muon collider faces major hurdles of its own, not least the fact that muons decay into electrons and neutrinos with a mean lifetime of 2.2 microseconds. That's a very long time in the subatomic realm, where particle lifetimes are often measured in fractions of a trillionth of a nanosecond. But in engineering terms, it is practically instantaneous. Muons for an accelerator would have to be produced by slamming a proton beam into a metal target; then 'cooled', or lined up into an orderly beam; and finally accelerated to the requisite energy, all in a time frame considerably shorter than the blink of an eye. That challenge is being addressed by the muon ionization cooling experiment (MICE) at the Rutherford Appleton Laboratory near Oxford, UK. MICE is expected to conclude its studies by 2016, at which point the cooling technology may be advanced enough for CERN to use it to build a neutrino factory \u2014 a stepping stone to a muon collider \u2014 that would fire beams of muon neutrinos through Earth to a detector thousands of kilometres away, such as one proposed in Finland. Nonetheless, many physicists are sceptical. \u201cI doubt I will see a muon collider working in my lifetime,\u201d says Brian Foster, a physicist at the University of Oxford. \u201cWe've been trying to cool muons for more than ten years, and it is just extremely difficult.\u201d Foster is the European regional director for the rival concept of a linear electron\u2013positron collider. This type of machine would essentially be a long, straight electron accelerator firing right down the barrel of an equally long, straight positron accelerator, with their beams slamming together in the middle. The lack of curvature would eliminate synchrotron radiation losses. And the accelerators could always be bumped up in energy by making them longer on the back end. Ideas for a high-energy linear collider began to emerge in the 1980s, and eventually converged on two concepts. The ILC, developed by a worldwide consortium of laboratories and universities, would be some 30 kilometres long, and would use proven superconducting accelerator technology to reach energies of 0.5 TeV, with the possibility of upgrading to 1 TeV. The ILC team is soon to publish a technical design report and the cost of the project is currently estimated at $6.7 billion. The Compact Linear Collider (CLIC), championed by CERN, would be almost 50 kilometres long, but would use novel acceleration techniques to reach energies of 3 TeV. CLIC's costs are less clear than the ILC's because only a conceptual design report is available, but its higher energies would open up new realms for discovery as well as for precision measurements. The performance of either design has been extensively studied theoretically, but in practice is a \u201cwide open question\u201d according to Blondel, current spokesperson for MICE. He points to the performance of the Stanford Linear Collider (SLC) at Menlo Park, California, which achieved energies of nearly 100 GeV. \u201cThe SLC finally worked very well, but it never quite produced the luminosity that they wanted. It was a very tough machine, and now with the ILC or CLIC we're discussing something that is much more difficult.\u201d Nevertheless, for many, if not most, particle physicists, some form of linear collider seems like the best bet. In June, the International Committee for Future Accelerators, headquartered at Fermilab in Batavia, Illinois, brought the ILC and CLIC together under a single Linear Collider project, headed by former LHC director Lyn Evans. His aim is to deliver a proposal for a single linear collider by the end of 2015. A sensible plan, thinks Evans, is to build a linear collider starting at 250 GeV to probe the Higgs, and then boost its energy in stages until it reaches 500 GeV. At that point it could produce pairs of Higgs bosons and allow researchers to explore how the Higgs couples to itself and also interacts with the heaviest particle of matter, the top quark. Going to higher energies is technically feasible, he says, but requires more electricity \u2014 as much as a medium power station's worth. In practice, he says, \u201cI think an upper limit in power [on the hypothetical new site] is the maximum that can be supplied to the CERN site, which is 300 MW.\u201d Technology aside, the multi-billion-dollar question is who would host the next lepton collider. A rule of thumb is that the host country puts up half the cost in expectation of long-term economic returns, says Foster. But this is not a good economic period to be making that case, especially not for a project that, from a politician's point of view, has no short-term benefit to voters. \n               Going global \n             If a linear collider is to be approved in the next few years, says Evans, it will probably not be built at CERN. Despite the European lab's wealth of technical and political infrastructure, it has its hands full with the LHC, which isn't even scheduled to reach its design energy of 7 TeV per beam until 2014 and is also scheduled to undergo a luminosity upgrade around 2022. \u201cI'd bet that the highest priority of the European strategy workshop will be continuing to exploit and upgrade the LHC,\u201d says John Womersley, chief executive of Britain's Science and Technology Facilities Council, which controls the country's spending on particle physics. The United States is also an unlikely site for a new collider, says Fermilab director Pier Oddone, who is chair of the International Committee for Future Accelerators. \u201cSomething drastic would have to change,\u201d he says. After the closure of Fermilab's 2-TeV Tevatron collider, the energy frontier crossed from the United States to Europe. So the current US strategy is to concentrate on the 'intensity frontier', studying rare particle interactions produced by, for example, intense beams of neutrinos. And yet, says Oddone, \u201cwe had a fairly severe budget cut at the beginning of this year and had problems fitting in a facility [a long-baseline neutrino experiment] that costs one-tenth of the ILC\u201d. Oddone says that it would also be \u201cvery difficult\u201d at this time for the United States to contribute much to a lepton collider built elsewhere. Many observers think that by far the strongest candidate to host the next project is Japan. After all, notes Evans, Japan made a significant contribution to the LHC in the mid-1990s when the project was under financial strain. \u201cPerhaps it's time for Europe to return the favour,\u201d he says. The Japanese premier made positive references to the ILC in December 2011, just after the first preliminary sightings of the new boson were announced. There is a scent of extra funds, because the new accelerator is being discussed as part of a broader economic plan to boost regions devastated by the March 2011 earthquake; the idea is to make it the hub of an 'international city' comprising other research laboratories, industrial zones and education centres. And as Japanese particle physicists update their five-year roadmap this year, the ILC remains at the top of their new-project wish-list. Specifically, explains Atsuto Suzuki, director-general of the KEK laboratory in Tsukuba, the community's recommendation was that \u201cJapan should take leadership of the early realization of an electron\u2013positron linear collider should a particle such as a Higgs boson be confirmed at the LHC\u201d. So is an ILC finally looking like a safe bet? \u201cGood god, no!\u201d says Foster, \u201cbut this is the best chance that we've had in a long time.\u201d Womersley gives odds of the ILC being built as 50:50 at best. \u201cWe shouldn't take it for granted that money is available just because the Higgs has been found,\u201d he says, pointing out that there are also strong cases for next-generation neutrino experiments, for example. It would take around ten years from breaking ground to operating an ILC, estimates Oddone, plus the preparatory time. \u201cYou're talking 2025 at the earliest, but do you launch such a major project before you know what else the LHC might find? There could be things much wilder than the Higgs.\u201d For many particle physicists, the dream scenario is the LHC exploring the high-energy frontier in Europe; multiple neutrino experiments exploring the intensity frontier in the United States; and a new lepton collider in Japan pinning down the details of all the exotic new particles that so far have not turned up in the LHC's collisions. \u201cI would love to see us going in that direction, if countries put their weight behind the programmes in each region,\u201d says Terry Wyatt, a physicist at the University of Manchester, UK, who works on the ATLAS detector at the LHC. As always in the world of big science, however, making such dreams come true is a question of making the sale to outsiders. \u201cThese things would probably be solved outside the particle-physics sphere,\u201d says Oddone. \u201cIt might be a phone call between a president and a prime minister that decides it.\u201d See Comment  page 581 \n                     Higgs boson: Budget cuts leave US science lagging 2012-Aug-01 \n                   \n                     We have it 2012-Aug-01 \n                   \n                     Theorists feast on Higgs data 2012-Jul-18 \n                   \n                     Higgs triumph opens up field of dreams 2012-Jul-10 \n                   \n                     How the LHC came to be 2007-Jul-18 \n                   \n                     This year's Lindau Nobel laureate meeting \n                   \n                     European Strategy for Particle Physics \n                   \n                     International Linear Collider \n                   \n                     MICE \n                   \n                     International Committee for Future Accelerators \n                   Reprints and Permissions"},
{"file_id": "489194a", "url": "https://www.nature.com/articles/489194a", "year": 2012, "authors": [{"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "The US flagship submersible  Alvin  is getting a partial upgrade. But deep-sea exploration faces some rough water. At an industrial hangar in Woods Hole, Massachusetts, a plush toy dog stands guard next to a 5-tonne titanium sphere. Polished to a high shine, the 2.2-metre orb reflects the lights overhead and the faces of passing scientists, who come to ogle the US$11-million engineering marvel \u2014 a container strong enough to ferry researchers 6,500 metres down to the bottom of the ocean. The sphere will be the new heart of the  Alvin  submersible, the United States\u2019 workhorse in the deep sea. Over its five-decade career,  Alvin  has dived to the sea floor more than any other research submersible and has made some of the most important oceanographic discoveries of the past few generations. But in the past few years, it has been showing its age, and other countries have surged past with vehicles that can venture far deeper than  Alvin \u2019s current limit of 4,500 metres. In 2010,  Alvin \u2019s caretakers at the Woods Hole Oceanographic Institution (WHOI) took the venerable submersible out of commission for a $40-million redesign. The massive upgrade was a long time coming. \u201cI started here in 1996 and there was talk about building a new sub then,\u201d says Bruce Strickrott, an  Alvin  pilot and expedition leader at WHOI, who is managing the sub\u2019s reconstruction. This month, Strickrott and his crew will start to rebuild the sub around the passenger sphere, readying it for a series of final tests off the coast of Bermuda by March. Assuming it passes,  Alvin  will resume a full schedule of scientific dives, joining a suite of tools that are giving US researchers unprecedented ways to study the deep sea \u2014 from manned subs like  Alvin  to remotely controlled robots and autonomous mappers. But after celebrating the revamped sub\u2019s maiden voyage, researchers will wake up to some sobering realities. Budget problems have constrained the current  Alvin  upgrade, so researchers must wait for the completion of a second construction phase, in 3\u20135 years, before they can take advantage of the greater depth limit allowed by the new sphere. That leaves the United States well behind France, Russia, Japan and now China, which sent its research submersible below 7,000 metres in June. And as wealthy entrepreneurs such as film director James Cameron capture public attention with dives in privately built subs, the United States is making painful cuts to many of its deep-sea assets. The administration of President Barack Obama is proposing to cut off funding next year for a pair of manned submersibles in Hawaii that can dive to 2,000 metres. \u201cAmerica has one submersible capable of reaching Titanic-ish depths \u2014 in the couple-of-miles range \u2014 which these days isn\u2019t that deep,\u201d says Cameron. \u201cWhat is the future of deep submergence research?\u201d That future once looked boundless. On 17 February 1977,  Alvin  skimmed along the ocean bottom about 400 kilometres northeast of the Galapagos Islands. Days before, sensors towed by a ship had identified a spike in water temperatures near the sea floor.  Alvin  explored the region and brought researchers face to face, for the first time, with hydrothermal vents, fissures in the sea floor that spew streams of warm, shimmering brine into the near-freezing water. In what was supposed to be a barren desert at the ocean bottom \u2014 far from the reaches of life-powering sunlight \u2014  Alvin  revealed oases of clams, crabs, shrimp and alien-like white tube worms crowned with crimson tops. Two years after the Galapagos dives, an  Alvin  expedition witnessed a more violent scene: jets of black fluids, superheated to 400\u2009\u00b0C, shooting out of gigantic chimneys of rock, which were dubbed black smokers. Later, in the geologically quieter Gulf of Mexico,  Alvin  found vents that were releasing cooler methane-rich fluids. These \u2018cold seeps\u2019 also support communities of animals, including slow-growing tube worms thought to be hundreds of years old \u2014 some of the most ancient creatures alive on the planet. The discovery of such ecosystems, powered by microbes that harness chemical energy from vent waters, raised questions about where life originated on Earth and where it may reside on other worlds. Alvin \u2019s string of accomplishments silenced early critics\u00a0\u2014\u00a0some of the top geoscientists of the 1960s and 1970s\u00a0\u2014\u00a0who initially regarded the submersible as little more than a toy. And ever since, the vehicle has been in high demand, trekking to the sea floor 100\u2013150 times a year. Although some countries can dive more deeply,  Alvin  \u201cis the most reliable submersible there is\u201d, says Susan Humphris, a geochemist at WHOI and principal investigator of the  Alvin  overhaul. \u201cWe need a workhorse at the bottom of the ocean. That\u2019s what  Alvin  has been and that\u2019s what  Alvin  will continue to be.\u201d \n               At the helm \n             Cindy Van Dover knows the submersible better than any other scientist. Now the director of the Duke University Marine Laboratory in Beaufort, North Carolina, Van Dover spent nearly three years training and working as an  Alvin  pilot after getting her doctorate at Woods Hole. She is the only researcher, and the only woman, to have piloted the craft, choosing to detour from a conventional research career because the job offered opportunities that few researchers can get. \u201cI wanted to do a lot of dives,\u201d she says. \u201cIt was about wanting to see the environment that I was studying.\u201d In 1991, when Van Dover gave up her pilot\u2019s seat and went back to being an occasional passenger in  Alvin , one of the things she missed most was the view. The old sphere, built in 1973, had three 13-centimetre-wide viewports, one on each side for passengers and one at the front for the pilot. Through those saucer-sized side ports, Van Dover says, \u201csometimes it was a great view but often it wasn\u2019t, so you\u2019d end up watching a video of what the pilot was doing\u201d. The new sphere retains the side windows but has three 18-centimetre-wide ones at the front, giving researchers a field of view that overlaps with the pilot\u2019s (see \u2018Voyager to the bottom of the sea\u2019). The space inside the sphere has also grown, which should make for less-painful rides. With an internal diameter of less than 2\u00a0metres, the old sphere had no room for seats; scientists had to huddle on the floor, and lean awkwardly against the sloped walls. After a 2-hour descent to the bottom, limbs would stiffen up. \u201cYou switch your position because your legs are so uncomfortable and you rock the whole submersible,\u201d says Chris German, a marine geochemist at WHOI and chief scientist for the US National Deep Submergence Facility in Woods Hole, which coordinates the use of  Alvin . \u201cThat can compromise taking the samples.\u201d The new sphere has 18% more interior space and will have ergonomically designed seats. And while sampling or exploring, researchers will be able to take advantage of brighter lights and improved camera systems. Scientists are keen to use the tools to explore the geology and biology of the mid-ocean ridges, the 60,000-kilometre-long chain of volcanic fissures that forge new ocean crust. So far, oceanographers have surveyed only a tiny fraction of the ridge system. The ridges and their flanks hide a subsurface plumbing network of fissures and pores so extensive that it circulates a volume of water equal to the entire ocean about every million years or so, altering the chemistry of the seas. Future dives will also target the communities of microbes living beneath the sea floor, which has been estimated to constitute as much as one-third of the planet\u2019s biomass. And marine scientists want to study the vast abyssal plains, which cover more than half of Earth\u2019s surface and are poorly explored; most of the species that researchers pull up in samples from abyssal sites are new to science. But some places that scientists want to visit lie deeper than 4,500\u00a0metres and so will remain off-limits to  Alvin  for now. The National Science Foundation, which is funding most of the  Alvin  redesign, could not afford to build a 6,500-metre-class sub all at once. In particular, such deep dives require more energy and it would be prohibitively expensive to build a submersible that uses current battery technology to dive frequently and to greater depths. Rich Lutz, an oceanographer at Rutgers University in New Brunswick, New Jersey, who has racked up more  Alvin  dives than perhaps any scientist, was surprised to learn that the current overhaul won\u2019t add to the sub\u2019s depth range. \u201cI certainly would have assumed that one of those improvements would be the capability of going down to 6,500 metres,\u201d he says. \n               Bottom dweller \n             Yet depth isn\u2019t everything. Despite the excitement over record-breaking dives by China\u2019s  Jiaolong  (7,020 metres) and Cameron\u2019s  DEEPSEA CHALLENGER  (11,000 metres), researchers don\u2019t go deep very often. Fewer than 10% of the dives by the French and Japanese submersibles approach their limits. Vincent Rigaud, manager of the underwater systems department at the French Research Institute for Exploration of the Sea in La Seyne-sur-Mer, says that research is increasingly focusing on shallower depths. \u201cThe science today is linked to [minerals] exploitation or areas where there is an impact from man\u2019s activities or man\u2019s interests,\u201d he says. Some US researchers are more upset about other limitations of the new  Alvin . \u201cIt\u2019s a superb tool for what it does but it could have been a hell of a lot better,\u201d says Bruce Robison, a marine ecologist at the Monterey Bay Aquarium Research Institute in Moss Landing, California. In 2004, Robison was a member of a committee of the National Research Council that assessed the future needs of deep submergence science. One of his biggest wishes was for a human-occupied vehicle (HOV) that could adjust its buoyancy to stop at any depth, allowing researchers to work well above the ocean floor. Most of the biological and chemical process in the ocean take place in the water column, not on the sea floor, Robison says. Yet neither the old  Alvin  nor the rebuilt sub can adjust its buoyancy enough to linger above the sea floor without draining its batteries. So nearly all trips go straight to the bottom. Along with concerns over  Alvin \u2019s limitations, US researchers also lament the loss of several scientific submersibles. Funding woes forced Florida International University\u2019s Harbor Branch Oceanographic Institute in Fort Pierce to retire its two submersibles, the Johnson Sea Links, last year. And the National Oceanic and Atmospheric Administration plans to stop funding the National Undersea Research Program, which supports two  Pisces submersibles located in Hawaii. The two HOVs are known for their work exploring seamounts in the Pacific Ocean, including the newest Hawaiian volcano. Robison bemoans the loss of all the other US scientific submersibles. \u201cAs good as  Alvin  is,\u201d he says \u201cthat isn\u2019t enough.\u201d Veteran explorer Robert Ballard is not shedding any tears over the HOVs. \u201cI consider that a dead paradigm,\u201d says the marine geologist who discovered the  Titanic  and co-led the cruise that discovered the first hydrothermal vents; he used  Alvin  to explore them both. He now relies on autonomous underwater vehicles (AUVs) and remotely operated vehicles (ROVs), which can be controlled by researchers on a ship or from halfway across the world. \u201cAUVs augmented with ROVs is where I see the future. I don\u2019t need any people in them.\u201d Alvin  is limited to 4\u20135 hours of work at depth, whereas ROVs can spend days on the bottom and some AUVs can explore for months. And unmanned vehicles don\u2019t require such large support ships and crews as HOVs, which can trim the cost of a mission substantially. Thanks to their data links, ROVs also enable essentially unlimited numbers of researchers around the world to take part in missions. The ROV Jason 2 has become a favourite tool of US marine geologists, who love its flexibility in exploring and collecting samples down to 6,500\u00a0metres. But its heavy steel cable, which supplies power and transmits data, prevents the ROV from diving deeper and complicates missions. Just up the hill from where  Alvin  is taking shape at Woods Hole, researchers are working on an experimental vehicle that will sever that troublesome umbilical cord while retaining the advantages of an ROV. Canary yellow and the size of a delivery van, Nereus made headlines in 2009 by reaching the bottom of Challenger Deep in the South Pacific \u2014 at 11,000 metres, the lowest spot on Earth. Nereus can operate either autonomously or connected to a surface ship through a fibre-optic cable. But the tether, just three times the thickness of a human hair, breaks easily. So the Woods Hole team is now working to cut the physical link with the surface. This month, off Guam, the crew will test a laser system on Nereus that sends the data to a receiver hanging down from a ship. Researchers will control Nereus using acoustic signals from the ship. Despite the advantages of ROVs, most scientists say that there is no substitute for exploring the depths in person. \u201cThere is still a place for having a human brain and eyes at the bottom of the ocean,\u201d says Humphris. To those who say there is no need for HOVs, she says \u201cIt\u2019s a little bit like saying, \u2018Why would you go to the Grand Canyon rather than watching a movie about it?\u2019.\u201d Alvin  is also one of the best recruiting tools in marine science. \u201cIt\u2019s what has brought the very best minds to the deep-sea oceanographic community,\u201d says Lutz. \u201cYou\u2019re able to tell them, \u2018You come work with us and we\u2019re going to take you a mile and a half down to the bottom of the sea in a submersible,\u2019 as opposed to saying, \u2018We\u2019re going to take you out on a ship and you\u2019re going to watch it on a television screen\u2019.\u201d Private money could help to preserve some opportunities for deep-sea science. Eric Schmidt, former chief executive of Google, purchased an 83-metre-long ship in 2010 that he retrofitted for oceanographic science. His Schmidt Ocean Institute will start research cruises with the vessel next year and will test existing ROVs with the aim of purchasing one in a couple of years and making it available for researchers. And Cameron\u2019s dive aboard his one-person  DEEPSEA CHALLENGER  fired up the imagination of researchers such as Lutz. \u201cYou look at it as a scientist and say, \u2018Shit! I\u2019d go down in that thing\u2019.\u201d Cameron says that his sub is available for anyone willing to put up the money for further expeditions. \u201cI\u2019m more than happy to put in the sub and the technology. It\u2019s not doing any good sitting in my barn,\u201d he says. In the meantime, the hopes of the US oceanographic community ride on  Alvin , which currently rests in pieces at Woods Hole. Looking up at the gleaming passenger sphere, Strickrott takes a moment to picture the day his crew has completed all its work and  Alvin  is ready to dive once again. \u201cWhen it gets rolled out here, it\u2019s spotless,\u201d he says. \u201cIt\u2019s a beautiful thing.\u201d \n                     James Cameron shares his deep desires 2012-Sep-12 \n                   \n                     End of an era for research subs 2011-Aug-22 \n                   \n                     Into the Swiss abyss 2011-Jul-29 \n                   \n                     Oldest research sub Alvin set for rebirth 2010-Dec-16 \n                   \n                     Oceanography: Death and rebirth in the deep 2010-May-19 \n                   \n                       Blogpost: China\u2019s Jiaolong submersible plunges below 7,000 metres \n                   \n                     Alvin  at Woods Hole Oceanographic Institute \n                   \n                     History of deep-sea science \n                   Reprints and Permissions"},
{"file_id": "488146a", "url": "https://www.nature.com/articles/488146a", "year": 2012, "authors": [{"name": "Kim Krieger"}], "parsed_as_year": "2006_or_before", "body": "Mechanical instability is usually a problem that engineers try to avoid. But now some are using it to fold, stretch and crumple materials in remarkable ways. Katia Bertoldi is talking fast. She has only 12 minutes to present her work in the burgeoning field of 'extreme mechanics'. But first, the Harvard University engineer smiles at the physicists gathered in Boston at the March 2012 meeting of the American Physical Society. She has to show them what she found in a toy shop. Projected onto the screen, the Hoberman Twist-O looks like a hollow football made of garishly coloured plastic links. Twist it just so, however, and hinges between the links allow it to collapse into a ball a fraction of its original size. Twist it the other way, and it springs back open. Bertoldi explains that the Twist-O inspired her group to create a spherical device that collapses and re-expands, not with hinges but through mechanical instabilities: carefully designed weak spots that behave in a predictable way. Applications might include lightweight, self-assembling portable shelters or nanometre-scale drug-delivery capsules that would expand and release their cargo only after they had passed through the bloodstream and reached their target. The challenge, Bertoldi says, is to figure out the exact instabilities a structure needs to achieve its desired behaviour. She quickly describes the necessary geometry and runs down a list of constraints. There are just 25 shapes that satisfy all the requirements, she explains, glossing over the months of computation it took to solve the problem. Then she starts a video to show the assembled throng the design that her team has come up with. An image of a rubbery chartreuse ball with 24 carefully spaced round dimples (pictured) materializes on the screen. The test begins and the ball slowly collapses, each dimple squeezing shut as the structure twists into a smaller version of itself. There is a moment of silence, then everyone in the room begins to clap. Student engineers have always been taught that mechanical instabilities are a problem to avoid. Such instabilities can quickly lead to structural failures \u2014 the collapse of a weight-bearing pillar, the crumpling of a flat steel plate or the buckling of a metal shell. From failures come disasters, such as the Second World War Liberty Ships that broke up while at sea. And the devilishly complex mathematical analysis of buckling structures ground to a halt in the late nineteenth century, because it was unworkable with the methods then available. During the past half-decade or so, however, a new generation of physicists and engineers has begun to embrace instability. These researchers have been inspired, in part, by advances in geometry and nonlinear mathematics that have allowed them to progress where their forebears could not. They have already, for example, devised a theory for why cabbage leaves and torn plastic rubbish bags ripple 1 ; calculated the patterns of wrinkles in fabric and crumples in paper 2 ; and accounted for the way coils and loops develop in the guts of vertebrate embryos 3 . On the practical side, one source of inspiration has been the widespread availability of flexible polymers and silicone materials, as epitomized by the vast selection of soft yet tough covers for smart phones. Such materials make it possible to imagine electronics, robots, tools and vehicles whose structures can radically deform yet still recover their original shapes. The resulting extreme-mechanics movement has grown rapidly. The first three conference sessions to bear the name, totalling fewer than 40 presentations, were held during the March 2010 meeting of the American Physical Society (APS). Just two years later, Bertoldi's talk on collapsible spheres was one of 111 presentations on extreme mechanics spread across 8 sessions. Hundreds of researchers are now active in the field worldwide. In spring 2011, the US National Science Foundation announced an opportunity for substantial funding in the field: it would allot up to US$2 million over four years to projects in Origami Design for Integration of Self-assembling Systems for Engineering Innovation (ODISSEI). The foundation expects to announce the awards this month. \n               Fold everything \n             \u201cIt was as if they wrote the solicitation just for us,\u201d says Christian Santangelo, a physicist at the University of Massachusetts Amherst and a co-principal investigator on an ODISSEI proposal. Along with two origami artists and an expert in origami mathematics, Santangelo and his colleague Ryan Hayward, a chemical engineer at Amherst who specializes in polymers, are proposing a new kind of three-dimensional (3D) printer. Instead of slowly building an object with layers and layers of polymer, as current 3D printers do, they would print a flat polymer sheet with a two-dimensional (2D) origami-like pattern, then force it to fold into a close approximation of the desired 3D object. One part of the project will involve refining a computer program developed by one of the origami artists, physicist Robert Lang of Alamo, California. Given a desired shape, the program will generate a diagram of the required fold pattern. At present, the program states only whether a particular fold on a sheet should be convex (in origami terms, a mountain fold) or concave (a valley fold). The user still has to devise a sequence of manipulations that can achieve those folds and create the figure. But the kinds of folding required by the project could quickly reach such levels of complexity that a human solution would be impossible. What the researchers foresee instead is a completely automated process in which a 2D sheet is inscribed with a computer-generated pattern of instabilities, and then folds correctly in one smooth, coordinated motion. Unfortunately, in Hayward's experiments so far, the folds just buckle into mountains or valleys at random. A potential solution may lie in the wavy-leaf-edge phenomenon, says Santangelo. If cells along the edge of a growing plant leaf multiply faster than those in the interior, he explains, they run out of room to lie smoothly in a plane, and the leaf edge is forced to ripple to accommodate them. If he and Hayward can work out how to make the polymer sheet swell in a way that varies from point to point, they could produce a complex pattern of rippling and curling that would help to control the sheet's folding. Just as natural phenomena can inform extreme mechanics, the discipline's researchers can also use their knowledge to explain peculiarities in natural structures. \u201cThis field is filled with small secrets,\u201d says Pedro Reis, an engineer at the Massachusetts Institute of Technology in Cambridge and one of the leaders of the movement. Take the mechanisms at work in a grain of pollen, for example. Reis pulls out a small torpedo-like shape made of a light green, rubbery material. He stretches it, then crushes it in his fist. A pollen grain undergoes torture, he says: it gets wet, swells, dries out and is crushed, so plants have evolved strategies such as built-in soft spots to help their pollen to avoid damage. Reis pokes a dimple in the torpedo. Scientists can learn from this that a shell with a soft spot is more resistant to failure than one that is completely rigid, he says. \u201cWe are trying to learn from nature. How it evolved to deal with these problems for which we have no intuition is very inspiring.\u201d Reis sets the torpedo aside and, twisting an imaginary string between his fingers, moves on to the subject of the sea-floor cables that carry Internet traffic around the globe. Mechanical instabilities can cause complex behaviour in these structures, too, he says. Lay too much cable, and it will curl and kink, resulting in poor signal quality. Lay too little, and the line will be tense and vulnerable to snapping. When a ship dragging its anchor sliced through one such cable in February, six countries in East Africa lost Internet connectivity. Although a better understanding of long, thin objects' instabilities wouldn't have prevented the accident, Reis says, it might have made for a cable more resilient to breakage. An improved theory of cables could also be of great use to fields ranging from the oil industry to the mechanics of DNA. In an effort to turn such insights into engineered structures, Reis's lab is competing for one of the ODISSEI grants in partnership with Bertoldi and several others. One of their goals is to compile a lexicon of shapes: polyhedra that will buckle, bend, stretch, collapse and expand in predictable ways in response to specific stimuli. The shapes are based on spherical shells with holes cut in them. But surrounding the holes are ligaments designed to contain weak spots that buckle when stressed. In principle, these buckling polyhedra could be made in a range of sizes, whether it's a nanometre-scale sphere designed for drug delivery or a retractable roof for an athletics stadium. The team calls the resulting structures 'buckliballs' \u2014 the subject of Bertoldi's presentation at this year's APS meeting. Buckliballs, with their geometric design and near-magical behaviour, encapsulate the cleverness and beauty for which extreme-mechanics researchers yearn. Looking ahead, the more theoretically minded foresee a new set of general rules that could describe the behaviour of any flexible solid as it crumples. Meanwhile, those with an engineering bent imagine robots with appendages that can transform into tools or squeeze, octopus-like, through tiny spaces; backpacks that expand into tents; and mobile phones that users can roll up and stick behind their ears like a pencil. They see a whole realm of devices that transmute failure into function. That could all be years in the making \u2014 but Bertoldi and her rapt audience already see far more in this field than engineers' toys. \n                     Materials chemistry: Carbon origami 2012-Jun-20 \n                   \n                     Nanotechnology: The importance of being modular 2012-May-31 \n                   \n                     Q&A: The origami geometer 2012-Mar-14 \n                   \n                     Bioengineering: What to make with DNA origami 2010-Mar-10 \n                   \n                     Nanotechnology: Another dimension for DNA art 2009-May-20 \n                   \n                     Q&A: Origami unfolded 2009-May-13 \n                   \n                     Mathematics: Some assembly needed 2007-Jul-25 \n                   \n                     The folding of thin films \n                   \n                     Katia Bertoldi's laboratory \n                   \n                     Pedro Reis's laboratory \n                   \n                     Christian Santangelo's Laboratory \n                   \n                     Robert Lang\u2019s origami \n                   Reprints and Permissions"},
{"file_id": "487022a", "url": "https://www.nature.com/articles/487022a", "year": 2012, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Three-dimensional printers are opening up new worlds to research. Christoph Zollikofer witnessed the first birth of a Neanderthal in the modern age. In his anthropology lab at the University of Zurich, Switzerland, in 2007, the skull of a baby  Homo neanderthalensis  emerged from a photocopier-sized machine after a 20-hour noisy but painless delivery of whirring motors and spitting plastic. This modern miracle had endured a lengthy gestation: it took years for Zollikofer's collaborators to find suitable bones from a Neanderthal neonate, analyse them with a computed-tomography (CT) scanner and digitally stitch them together on the computer screen. The labour, however, was simple: Zollikofer just pressed 'print' on his lab's US$50,000 three-dimensional (3D) printer. A pioneer in the use of 3D printing for research, Zollikofer started 20 years ago with a prototype that was even more expensive and required toxic materials and solvents \u2014 limitations that put off most scientists. But now newer, cheaper technology is catching on. Just as an inkjet printer sprays ink onto a page line by line, many modern 3D devices spray material \u2014 usually plastic \u2014 layer by layer onto a surface, building up a shape. Others fuse solid layers out of a vat of liquid or powdered plastic, often using ultraviolet or infrared light. Any complex shape can be printed, sometimes with the help of temporary scaffolding that is later dissolved or chipped away. These days, personal kits go for as little as $500, says Terry Wohlers, a consultant and market analyst based in Fort Collins, Colorado \u2014 although industrial systems cost an average of $73,000. Last year, he says, nearly 30,000 printers were sold worldwide, with academic institutions buying one-third of those in the $15,000\u201330,000 price range. Early adopters are using the technology to investigate complex molecules, fashion custom lab tools, share rare artefacts and even print cardiac tissue that beats like a heart. At palaeontology and anthropology conferences, more and more people are carrying printouts of their favourite fossils or bones. \u201cAnyone who thinks of themselves as an anthropologist needs the right computer graphics and a 3D printer. Otherwise it's like being a geneticist without a sequencer,\u201d says Zollikofer. The printouts are yielding insights that are not possible with more conventional methods. Neanderthal neonate fossils, for example, are extremely rare, so Zollikofer did not want to risk copying his fragile specimen with the usual plaster-casting methods. With the printout, however, Zollikofer could explore the logistics of Neanderthal births. Along with the neonate skull, he printed out an adult, female Neanderthal pelvis and literally re-enacted a delivery. Some researchers had speculated that Neanderthals' wide hips made labour easier than it is for modern humans, but Zollikofer's experiment showed that the bigger skulls of Neanderthal neonates counteracted that advantage (M. S. Ponce de Le\u00f3n  et al .  Proc. Natl Acad. Sci. USA   105 , 13764\u201313768; 2008 ). Like humans today, Neanderthals had the biggest heads \u2014 and brains \u2014 possible at birth, giving them a jump-start on development. In his work, Zollikofer swaps back and forth between printed models and virtual ones. The computer models are good for calculating volumes or piecing together bone fragments \u2014 researchers can position them in space without gravity causing them to fall. But with the virtual models, he says, \u201cyou lose the sensation of touch, and even a notion of the size of the fossils\u201d. The physical models are far better for seeing how pieces should fit together in the first place, he adds. \n               Molecular playground \n             Chemists and molecular biologists have long used models to get a feel for molecular structures and make sense of X-ray and crystallography data. Just look at James Watson and Francis Crick, who in 1953 made their seminal discovery of DNA's structure with the help of a rickety construction of balls and sticks. These days, 3D printing is being used to mock up far more complex systems, says Arthur Olson, who founded the molecular graphics lab at the Scripps Research Institute in La Jolla, California, 30 years ago. These include molecular environments made up of thousands of interacting proteins, which would be onerous-to-impossible to make any other way. With 3D printers, Olson says, \u201canybody can make a custom model\u201d. But not everybody does: many researchers lack easy access to a printer, aren't aware of the option or can't afford the printouts (which can cost $100 or more). Yet Olson says that these models can bring important insights. When he printed out one protein for a colleague, they found a curvy 'tunnel' of empty space running right through it. The conduit couldn't be seen clearly on the computer screen, but a puff of air blown into one side of the model emerged from the other. Determining the length of such tunnels can help researchers to work out whether, and how, those channels transport molecules. Doing that on the computer would have required some new code; with a model, a bit of string did the trick. Software that lets researchers twist and turn such structures on a computer screen is extremely useful, says Olson, but inadequate. Even the most advanced software will let two atoms occupy the same space. And tinkering with molecules inside a computer is a grind \u2014 it takes time for the computer to re-render an object after every turn, and interpreting the pictures requires mental effort. Fiddling with a physical model, on the other hand, is more like play. \u201cI don't have to think about it; I just do it,\u201d says Olson. Olson is now trying to meld the tactile advantages of 3D printing with computer power: he has tagged printed models with small paper labels that can be recognized by a webcam, to create an 'augmented reality' view. In this way, a user can play with a physical model, while at the same time using the computer to explore aspects such as the potential energy of a given molecular arrangement. Olson is also looking forward to using printers that can more easily swap between rigid and bendable materials, so as to better replicate molecular behaviour such as protein folding. \n               The cellular matrix \n             Printer 'inks' aren't limited to plastic. Biologists have been experimenting with printing human cells \u2014 either individually or in multi-cell blobs \u2014 that fuse together naturally. These techniques have successfully produced blood vessels and beating heart tissue. The ultimate dream of printing out working organs is still a long way off \u2014 if it proves possible at all. But in the short term, researchers see potential for printing out 3D cell structures far more life-like than the typical flat ones that grow in a Petri dish. For example, Organovo, a company based in San Diego, California, has developed a printer to build 3D tissue structures that could be used to test pharmaceuticals. The most advanced model it has created so far is for fibrosis: an excess of hard fibrous tissue and scarring that arises from interactions between an organ's internal cells and its outer layer. The company's next step will be to test drugs on this system. \u201cIt might be the case that 3D printing isn't the only way to do this, but it's a good way,\u201d says Keith Murphy, a chemical engineer and chief executive of Organovo. Other groups are using 3D printing of plastic or collagen to construct scaffolds on which cells can grow. Carl Simon, a biologist with the biomaterials group at the US National Institute of Standards and Technology in Gaithersburg, Maryland, says that the intricacies of scaffold shape can help to determine how cells grow, or how stem cells differentiate into different cell types. With 3D printing, researchers have a very controlled way to play with different scaffold configurations to see which work best. One problem, however, is that most 3D printers can produce details on the scale of only tens to hundreds of micrometres, whereas cells sense differences at the single-micrometre level. Top-quality printers can currently achieve 100-nanometre resolutions by using very short laser bursts to cure plastics, says Neil Hopkinson, an engineer who works with 3D printing at the University of Sheffield, UK, but this is \u201cstill very much in the lab\u201d. \n               Custom tools \n             In the meantime, basic plastic 3D printers are starting to allow researchers to knock out customized tools. Leroy Cronin, a chemist at the University of Glasgow, UK, grabbed headlines this year with his invention of 'reactionware' \u2014 printed plastic vessels for small-scale chemistry (M. D. Symes  et al .  Nature Chem.   4 , 349\u2013354; 2012 ). Cronin replaced the 'inks' in a $2,000 commercially available printer with silicone-based shower sealant, a catalyst and reactants, so that entire reaction set-ups could be printed out. The point, he says, is to make customizable chemistry widely accessible. His paper showed how reactionware might be harnessed to produce new chemicals or to make tiny amounts of specific pharmaceuticals on demand. For now, other chemists see the idea as a clever gimmick, and are waiting to see what applications will follow. Researchers in other fields have found a more immediate use for the technology. Philippe Baveye, an environmental engineer at Rensselaer Polytechnic Institute in Troy, New York, uses 3D printing to make custom parts for a permeameter \u2014 a device used to measure the flow of water through soils. Although commercially available devices are fine for routine work, he has often had to design his own for more precise research \u2014 a task that previously required many hours on a lathe. Printing, he says, is much easier. Perhaps more importantly, Baveye can share his product just by publishing the design file. \u201cThe idea of being able to reproduce experiments described in the literature is taking on a new meaning,\u201d he says. Others agree that the real power of 3D printing lies in its ability to put science into the hands of the many. Cronin wants to enable anyone \u2014 whether in the far corners of Africa or in outer space \u2014 to print their own tiny drug factory. Museums can already distribute exact copies of rare or delicate fossils as widely as they wish. And students can print out whatever molecule they're trying to come to grips with. \u201cThrough 3D printing,' says Olson, \u201cthe ability to make physical models has become democratized.\u201d See Editorial  page 6 \n                     Homegrown labware made with 3D printer 2012-Apr-16 \n                   \n                     Education: Ten weeks to save the world 2010-Sep-15 \n                   \n                     How to print out a blood vessel 2008-Mar-20 \n                   \n                     Stemcells: Thinking in three dimensions \n                   \n                     Scripps molecular graphics laboratory \n                   \n                     State of the industry report 2012 \n                   \n                     Organovo \n                   \n                     3D museum \n                   Reprints and Permissions"},
{"file_id": "486310a", "url": "https://www.nature.com/articles/486310a", "year": 2012, "authors": [{"name": "Meera Subramanian"}], "parsed_as_year": "2006_or_before", "body": "With turbines threatening some bird and bat populations, researchers are seeking ways to keep the skies safe for wildlife. Marc Bechard turned a worried eye skywards as he walked among the limestone hills at the southern tip of Spain. It was October 2008, and thousands of griffon vultures \u2014 along with other vulnerable raptors \u2014 were winging towards the Strait of Gibraltar and beyond to Africa. But first they had to navigate some treacherous airspace. The landscape on either side of the strait bristles with wind turbines up to 170 metres high, armed with blades that slice the air at 270 kilometres per hour. Bechard, a biologist at Boise State University in Idaho, and colleagues from the Do\u00f1ana Biological Station in Seville, Spain, had been hired to help the birds make it safely past 13 wind farms in C\u00e1diz province. Each time the researchers spotted a raptor heading towards a turbine, they called the wind farm's control tower. Within minutes the blades slowed to a stop, and one more migrating bird soared past unharmed. Then the turbine swung back into action. When the biologists weren't looking up at the sky, they were scouring the ground for carcasses of griffon vultures ( Gyps fulvus ), Spanish imperial eagles ( Aquila adalberti ) and other species. The Spanish Ornithological Society in Madrid estimates that Spain's 18,000 wind turbines may be killing 6 million to 18 million birds and bats annually. \u201cA blade will cut a griffon vulture in half,\u201d says Bechard. \u201cI've seen them just decapitated.\u201d Wind turbines kill far fewer birds in general each year than do many other causes linked to humans, including domestic cats and collisions with glass windows. But wind power has a disproportionate effect on certain species that are already struggling for survival, such as the precarious US population of golden eagles ( Aquila chrysaetos canadensis ). \u201cThe troubling issue with wind development is that we're seeing a growing number of birds of conservation concern being killed by wind turbines,\u201d says Albert Manville, a biologist with the US Fish and Wildlife Service in Arlington, Virginia. The deaths caused by turbines have the potential to harm not only wildlife, but also the wind-energy industry, which is the fastest-growing source of power worldwide, according to the World Bank. With critics vilifying wind turbines as 'bird blenders', wind companies, governments and researchers are teaming up to mitigate the problem before it reaches a crisis point. C\u00e1diz province, for example, requires all wind-energy projects to consider environmental issues, and helps to fund research on reducing any damage. The early signs are that with targeted efforts, wind power and wildlife can cautiously coexist. Bechard and his colleagues, for example, lowered mortality at the C\u00e1diz wind farms by 50%, with only a 0.07% loss in energy production 1 . Others are finding that minor changes in the design or operation of wind farms can bring major reductions in animal deaths. Bechard and others believe research is crucial to making wind energy viable: \u201cIn the long run it'll save a lot of money and a lot of headaches.\u201d \n               The gathering storm \n             Wind power is poised to take off as the world seeks new sources of renewable energy. The industry is growing most quickly in China, which plans a 60% increase in wind power in the next three years. The US Department of Energy is aiming for a sixfold jump by 2030, and the European Union is working towards supplying 20% of its energy demand using renewable sources by 2020, much of that from wind. But the rapid expansion of wind power can harm wildlife in multiple ways. Beyond direct collisions with turbines, wind farms threaten species by displacing habitat. And bats can develop fatal internal haemorrhaging as a result of air-pressure changes when they fly through the wake of a spinning blade. The industry maintains that the effects on wildlife are minor. Although there are only a few, limited estimates of bird fatalities at a national level, the available data for the United States suggest that wind farms account for a tiny fraction of avian deaths (see 'Bird killers'). But the concern is that turbines threaten species that are already struggling, such as bats, which in North America have been hit hard by white-nose fungus. Another vulnerable group is raptors, which are slow to reproduce and favour the wind corridors that energy companies covet. \u201cThere are species of birds that are getting killed by wind turbines that do not get killed by autos, windows or buildings,\u201d says Shawn Smallwood, an ecologist who has worked extensively in Altamont Pass, California, notorious for its expansive wind farms and raptor deaths. Smallwood has found that Altamont blades slay an average of 65 golden eagles a year 2 . \u201cWe could lose eagles in this country if we keep on doing this,\u201d he says. Other species at risk include the critically endangered California condors ( Gymnogyps californicus ) \u2014 which number only 226 in the wild \u2014 and the few hundred remaining whooping cranes ( Grus americanus ), concentrated in the central United States. Biologists can't say whether the increase in wind farms will cause the collapse of these or other bird species, which already face many threats. But waiting for an answer is not an option, says Smallwood. \u201cBy the time we do understand the population-level impacts, we might be in a place we don't want to be.\u201d \n               Damage control \n             In C\u00e1diz, temporarily shutting down turbines has worked because the biggest threat is to migratory birds, which pass through only occasionally. Similar methods could reduce mortalities along the migratory bottlenecks in Central America, Europe and Asia, says Miguel Ferrer, a conservation biologist at Do\u00f1ana and a co-author of the C\u00e1diz study. But that tactic will not work in Altamont Pass, which has both migratory and permanent avian populations. Instead, companies there are making headway by replacing small, ageing turbines with fewer large ones. Choosing sites carefully can help, too. \u201cRaptors do not use the landscape randomly,\u201d explains Doug Bell, wildlife programme manager with the East Bay Regional Park District, which manages parklands and monitors wind farms around Altamont. When the Buena Vista Wind Energy Project at Altamont replaced 179 turbines with 38 taller ones in 2006, Smallwood advised the company to avoid ridge saddles between hills and other hotspots for raptor traffic. Since then, golden eagle fatalities at Buena Vista have dropped by 50% and other raptor deaths by 75%, says Smallwood. In the eastern United States, Todd Katzner, a biologist at West Virginia University in Morgantown, finds troublesome locations using a tracker designed to fit on golden eagles. \u201cWe can identify places where there are wins for both sides,\u201d he says. Moving a turbine site by a few hundred metres can substantially reduce the risk of collisions, says Katzner. Companies say that they have learned from past mistakes. \u201cThat there hasn't been another [location like] Altamont Pass for years should be an assurance that the wind industry has gotten better at siting,\u201d says Stu Webster, director of permitting and environmental affairs at Iberdrola Renewables, a renewable-energy firm in Portland, Oregon. Sometimes a slight change in procedures can make a big difference. For example, most turbines are set to turn on when wind speeds reach 4.0 metres per second. But when the Iberdrola Renewables Casselman Wind Project in Pennsylvania increased the threshold to 5.5 metres per second, it slashed deaths of bats \u2014 which don't fly as much in high winds \u2014 by 93% while shaving just 1% off of power production, says Ed Arnett, who conducted a study there 3  while working at Bat Conservation International in Austin, Texas. Some wind farms are betting on technology to make a difference. The MERLIN radar system, made by DeTect in Panama City, Florida, scans the skies for up to 6.5 kilometres around and uses algorithms to detect incoming flocks and even individual birds and bats, says Gary Andrews, chief executive of DeTect. Iberdrola Renewables and Pattern Energy, a wind-power company based in San Francisco, California, are using the system at wind farms, as is Torsa Renewables, based in Malaga, Spain. Some researchers question the effectiveness of the radar. In 2010, a US Fish and Wildlife Service biologist saw a blade hit an American white pelican ( Pelecanus erythrorhynchos ) at Iberdrola's Pe\u00f1ascal wind farm in Texas, which was using MERLIN. But Iberdrola says that the system there is set up to prevent mass mortalities, not to detect individual birds. According to Iberdrola, birds are most at risk in fog or other periods of low visibility, so Pe\u00f1ascal sometimes shuts down turbines during bad spells, unless the radar reveals that there are no birds around. Generally, however, the radar indicates that birds avoid the turbines by themselves. \u201cWe have terabytes' worth of data that are showing us how birds actually react to wind farms,\u201d says Webster. Researchers would love to see such data, but so far they have not been given access. \u201cI haven't seen any results in the published literature,\u201d says Arnett, \u201cso in my mind, [the radar] remains untested.\u201d Companies worry that any monitoring data that they release could be used against them in lawsuits by environmental organizations or in political attacks from groups that support the fossil-fuel industries and want to scuttle wind power. The American Wind Wildlife Institute, a coalition of industry and conservation organizations based in Washington DC, is attempting to remedy the situation by creating a limited-access data repository that protects company privacy. The institute expects to complete the pilot phase of the project by mid-summer. Even as they start to open up, some sectors of the wind industry acknowledge that they should do more to head off problems. \u201cWe as an industry need to do a better job of incorporating mitigation strategies into our economics,\u201d says John Calaway, director of wind development at Pattern Energy. The strategies seem to be working in C\u00e1diz, but Bechard still frets when he sees vultures on the horizon. \u201cIt's always nerve-wracking\u201d wondering whether the turbines will stop in time, he says. When the birds pass safely, he breathes a sigh of relief. But with wind farms popping up around the globe, Bechard worries about what the vultures will encounter as they disappear into the distance. \n                     Vultures blind to the dangers of wind farms 2012-Mar-13 \n                   \n                     Turbines and turbulence 2010-Dec-22 \n                   \n                     US takes pole position in generation of wind power 2009-Feb-11 \n                   \n                     US Fish and Wildlife Service Wind Energy Development \n                   \n                     Todd Katzner's lab \n                   \n                     Global Wind Energy Council \n                   Reprints and Permissions"},
{"file_id": "486456a", "url": "https://www.nature.com/articles/486456a", "year": 2012, "authors": [{"name": "Ed Yong"}], "parsed_as_year": "2006_or_before", "body": "Scientists now know that the deadly bird flu virus is capable of causing a human pandemic. That makes tackling the remaining unknowns all the more urgent. The biology of the H5N1 avian influenza virus is rife with paradoxes. The virus is widespread, but hard to detect. It kills more than half of the people known to be infected, but thousands of those exposed have no apparent problems. It seems to be just a few mutations away from gaining the ability to spread from person to person, but despite more than 16 years of fast-paced evolution, it has failed to do so. This week saw the publication of the second of two papers identifying mutations that give H5N1 the ability to spread through the air between ferrets. The papers, the latest 1  from a group led by Ron Fouchier at the Erasmus Medical Center in Rotterdam, the Netherlands, and the earlier one 2  by Yoshihiro Kawaoka at the University of Wisconsin-Madison and his colleagues, have been controversial because they offer what some see as a recipe for disaster \u2014 that they increase the risk of accidental or intentional release of a deadly human pathogen. But what is most unsettling about them, say many in the flu community, is the evidence they provide that the wild virus could spark a pandemic on its own. That threat makes the outstanding scientific mysteries about this tiny RNA virus \u2014 its genome just 14,000 letters long \u2014 even more pressing. Here are five of the biggest puzzles, and what researchers are doing to solve them. \n               Why is it so successful? \n             H5N1 influenza gets its name from the combination of two proteins on its surface: haemagglutinin (HA) and neuraminidase. But there are many different strains of H5N1. The highly pathogenic strain that has grabbed headlines for more than a decade was first identified in 1996. Called Gs/Gd because it was found in domestic geese in China's Guangdong province, it is \u201ctotally different to any avian influenza virus in the past\u201d, says Robert Webster, a virologist at St Jude Children's Research Hospital in Memphis, Tennessee. Most avian influenza viruses ride harmlessly aboard wild fowl, occasionally flaring into lethal but short-lived outbreaks in domestic birds. The Gs/Gd lineage, however, has jumped back from poultry into wild fowl. It also infects mammals, including humans, tigers, pikas, civets and more. It has spread to 63 countries, and is endemic in bird populations in six of them. \u201cWhat is so special about this virus that allows it to spread through the animal world so effectively?\u201d asks Jeremy Farrar, a tropical-medicine specialist at the University of Oxford, UK. There are no firm answers. China's crowded farms and markets, which offer a smorgasbord of potential hosts, might have selected for viruses that are adept at crossing the species barrier. The virus evolved quickly in 1999 and 2000, its family tree sprouting many new branches after efforts to stamp it out among domestic birds failed. During this time, one clade of the Gs/Gd lineage, known as 2.2, picked up a mutation in  PB2 , one of three polymerase genes that allow the virus to copy its genome. The mutation is widely considered to be an adaptation to mammalian hosts. In 2002, for reasons that are still unclear, the viruses started hopping back into wild birds and killing them. At first, there were just a few isolated deaths, but in May 2005, clade 2.2 viruses killed more than 6,000 geese, gulls and ducks at Qinghai Lake \u2014 China's largest lake, and a major breeding spot for migratory birds. This outbreak heralded the start of a global tour in which the virus spread through bird trade and wild migrations to the rest of Asia, Europe and Africa. Vaccination controlled the virus in Hong Kong and Vietnam, but where applied haphazardly, it has helped to speed up the virus's evolution. In Egypt, it led to the birth of several new sub-clades 3 , and the country has had more new human cases than any other nation every year since 2009. There is some good news: infections in wild birds have fallen sharply since 2006. But even as old lineages wane, new ones arise, such as clade 2.3.2.1, which has swept through poultry in Asia since early 2011. \u201cThat's the one that is of great concern to me,\u201d says Webster. \u201cIt seems to be becoming dominant and it goes into wild birds readily.\u201d H5N1 may be evolving faster than our ability to understand it. \n               Where is it now? \n             H5N1 seems to be both everywhere and nowhere at the same time, making it hard to predict when, where and whether it will bloom into a human pandemic. Wild birds carry H5N1, but the virus can be hard to detect because very few become ill. No one knows how widespread it is in humans, either. As of 7 June, the World Health Organization had counted 606 H5N1 infections in humans, 357 of them fatal. Many think that the real number is much larger, which would mean that the death rate would be much lower than 60%. Peter Palese, a virologist at Mount Sinai School of Medicine in New York, looked at a number of studies that had found evidence of H5N1 infection in the blood of healthy people. He estimates that 1\u20132% of people in populations exposed to the virus become infected, but most have only mild or no symptoms 4 . Palese's arguments are controversial. Farrar, who has treated patients in Asia, says that most of the cases he has seen have been severe. \u201cIf many mild infections were occurring, we'd expect to see some less severe patients in hospital, given the heightened awareness in the public and the medical profession,\u201d he says. Underlying the debate about the infection rate is a poor understanding of how the immune system responds to the virus. People who become infected produce antibodies and T cells that recognize the virus, but no one knows how these responses rise and fall over time, or how they manifest in people who show no symptoms. The signals could also be false alarms. \u201cIf you go into henhouses every day to clean up bird droppings that are loaded with virus antigen, you may get an antibody response without being infected,\u201d says Fouchier. More thorough surveillance of suspected cases will be needed to resolve the debate about how often people are infected, says Fouchier. Farrar adds that to understand how immune responses change over time, such studies will have to be done over several years. Many researchers have called for better surveillance of domesticated and wild animals, too. To Ilaria Capua, a veterinary virologist at the Experimental Animal Health Care Institute of Venice in Legnaro, Italy, the distribution of H5N1 is the most important issue, and the hardest to work out. \u201cAny prediction about whether this virus will go pandemic is a function of where it is, how much of it there is and how possible the human\u2013animal contacts are. But there are big black holes of information.\u201d \n               How does it kill? \n             Bit by bit, scientists are teasing out the genetic factors that make H5N1 so deadly. The virus has several mutations in its three polymerase genes that allow it to replicate aggressively, and patients who die carry the highest levels of viral RNA. Certain changes to  HA , which codes for a protein that latches onto host cells, also allow the virus to infect tissues beyond the lungs and gut, including the brain. This all-access pass helps the virus to kill ferrets, mice and birds, but it is apparently less important in primates. \u201cIn humans, it still looks predominantly like a respiratory disease kills the patients,\u201d says Malik Peiris, a clinical virologist from the University of Hong Kong. Autopsies might paint a clearer picture, but Peiris says that these are rarely allowed in Asia because of cultural demands for whole-body burials. H5N1 also drives the immune system berserk. Immune cells flock to sites of infection and produce inflammatory chemicals called cytokines, which attract more immune cells. The result, a cytokine 'storm' that floods the lungs with fluid and fatally damages surrounding tissues, is often what kills people. H5N1 triggers a more extensive storm than the human flu viruses H1N1 or H3N2 (ref.  5 ). These factors may explain the severity of recorded cases, but not why infections are so rare. \u201cWhy is it that there are tens of thousands of kids running around playing with sick chickens, but we've only had 600 infections over nine years?\u201d asks immunologist Anthony Fauci, who heads the National Institute of Allergy and Infectious Diseases in Bethesda, Maryland. Palese suspects that the severe cases have simply inhaled high doses of the virus. But Peiris says that this cannot be the sole explanation. \u201cInfection and disease are not directly proportional to exposure. Ninety-nine point nine per cent of the people who are massively exposed don't have disease, and don't have antibodies in their blood. But in people who get sick, the virus replicates like crazy.\u201d Notably, cases are often clustered within families, specifically blood relatives. These people might be genetically susceptible to H5N1 infection, or others may have genetic variants that protect them. Identifying such variants will be hard because fewer than 300 people around the world have survived the infection, but studies are starting to reveal clues. A few months ago, a group from the Wellcome Trust Sanger Institute in Hinxton, UK, found that the gene  IFITM3  plays a pivotal part in responses to some flu infections 6 . One variant of the gene, which encodes a stunted protein, was overrepresented in people who had been hospitalized with pandemic and seasonal flu strains, and even a mild H3N2 virus ran amok in the lungs of mice that lacked the gene 6 . Farrar has just completed a similar study, of 67 Asian patients who had been hospitalized with H5N1. The results, which have been submitted for publication, identify variants in two other genes that seem to confer susceptibility to the virus. \n               Will it become transmissible in humans? \n             So far, people seem to catch H5N1 only through close contact with infected birds. To spread from person to person, the virus would have to become transmissible through airborne droplets. The two papers just published 1 , 2  have shown that that is possible. Fouchier's strategy was to tweak  HA  so that its protein recognized receptors in the upper airways of mammals rather than those on the surface of bird cells 1 . He then allowed the virus to pass between ferrets until it evolved such that it started spreading through coughs and sneezes. Kawaoka took a similar approach 2 , but he fused a mutated  HA  from H5N1 with other genes from a 2009 pandemic H1N1 strain. \u201cIn principle, H5N1 can become airborne,\u201d says Fouchier. \u201cThe critical question is whether it will.\u201d One of the biggest questions about H5N1 is why it hasn't become transmissible after circulating for so many years \u2014 but no-one has a good answer. Many of the mutations that Fouchier and Kawaoka identified are already found in the wild. By searching surveillance databases, Derek Smith, a bioinformatician from the University of Cambridge, UK, found that many wild clades are already two to four mutations away from the sets that Fouchier and Kawaoka identified 7 . Smith was unable to determine the actual risk because surveillance data masks the genetic diversity of the virus. H5N1 reproduces with errors, so any one patient carries a swarm of viruses with subtle genetic differences. The databases contain just the 'consensus' sequence, essentially a mash-up of the most common variant at every position in the genome. Only deeper sequencing, in which each position is read many times over, will reveal all the variants. Even if the same combination of  HA  mutations that Fouchier and Kawaoka identified arises naturally, no one knows whether the resultant viruses would spread between humans as easily as they do between ferrets in the lab. It is also not clear how H5N1's other genes contribute to transmissibility, or whether different combinations of mutations would achieve the same effect. \u201cThese guys have only scratched the surface,\u201d says Webster. Fouchier and Kawaoka say that the value of their work lies in identifying the physical traits that make H5N1 transmissible. Some mutations allowed HA to recognize mammalian receptors, whereas others stabilized the protein. \u201cIf you take those traits, can you then make any flu virus go airborne?\u201d asks Fouchier. The virulence of a transmissible strain is another unknown. One hypothesis suggests that as transmissibility goes up, virulence will become muted. An airborne H5N1 might recognize receptors in the upper airways, for example, but be less likely to descend into the lungs to cause the extensive damage inflicted by wild strains. \u201cTheoretically, one could imagine such a scenario,\u201d says Pereis. \u201cBut I wouldn't want to stake my life on it.\u201d Fouchier and Kawaoka's mutant viruses caused milder disease in ferrets than their wild counterparts do, but both men note that such comparisons are misleading because wild H5N1 has to be administered to the animals directly, which can introduce high doses deep within the lungs. And, Kawaoka notes, transmissible strains do not have to have a fatality rate of 60% to kill millions of people: the H1N1 pandemic of 1918 had a mortality rate of 2.5%, yet claimed around 50 million lives. \n               What else could cause a pandemic? \n             The Gs/Gd strain is what is known as a reassortant. It was born from a flu version of sex, in which different viruses infecting the same cell swap genes, and it probably includes genes from the H6N1 and H9N2 viruses 8 . Since then, H5N1's descendants have swapped genes mostly with each other. \u201cH5N1 is not very sexually promiscuous,\u201d says Capua. \u201cIt likes to reassort within its own lineage.\u201d But the H1N1 strain responsible for the 2009 pandemic could shake H5N1 from its insularity. That strain is itself a cocktail of genes from swine H1N1, avian H1N1 and human H3N2 and includes a set of genes called the triple-reassortant internal gene (TRIG) cassette, which seems to make flu viruses more prone to reassortment. \u201cThat virus loves to mate,\u201d says Webster. Kawaoka's team has shown that the two viruses are compatible, and will reassort spontaneously when they infect the same cells 9 . This is made more likely by their shared ability to infect pigs. Furthermore, Stacey Schultz-Cherry, a virologist at St Jude Children's Research Hospital, has found that reassortant viruses containing  HA  from H5N1 and other genes from pandemic H1N1 are better at replicating in human lung cells than either parent is, and that they become more virulent after a few rounds of replication 10 . Wendy Barclay, a virologist at Imperial College London, cautions that although these experiments reveal that reassortment is possible, they do not quantify the odds that it will happen. \u201cIf you force the event, it'll happen, but I haven't seen anyone do the experiment in a more natural way,\u201d she says. That would involve housing uninfected pigs with ones carrying pandemic H1N1, and poultry carrying H5N1. \u201cDo they catch both viruses and do the viruses mix up?\u201d asks Barclay. \u201cIt's an unknown and a pretty important one.\u201d The upside of an H5N1\u2013H1N1 reassortant is that many people have already been infected with H1N1 and so might have some immunity. But few people have encountered any of the flu viruses that circulate in birds. \u201cI think the great worry is that a purely avian virus somehow crosses over to us,\u201d says Farrar. H5N1 tops the list of concerns because of the severe nature of the known infections, but other subtypes could escalate into pandemics first. \u201cH9N2 may be an equally plausible pandemic candidate,\u201d says Peiris. It generally goes unnoticed, but has hunkered down among Asia's poultry, caused occasional outbreaks in humans and can reassort with seasonal flu. Some strains already have mutations that are associated with greater transmissibility in mammals. H7N7 is similarly widespread and under-reported. In 2003, it flared up in the Netherlands, infecting 89 people and killing a veterinarian. Virologists hope that by understanding the secrets that allow H5N1 to spread and kill, they are in a better position to assess the risk posed by other subtypes. \u201cWith flu, nothing is predictable,\u201d says Capua. \n                     Second mutant-flu paper published 2012-Jun-21 \n                   \n                     Mutant-flu paper published 2012-May-02 \n                   \n                     US biosecurity board revises stance on mutant-flu studies 2012-Mar-30 \n                   \n                     Flu surveillance lacking 2012-Mar-28 \n                   \n                     Death-rate row blurs mutant flu debate 2012-Feb-13 \n                   \n                     Nature  special: Mutant flu \n                   \n                     Influenza at the human\u2013animal interface (WHO) \n                   Reprints and Permissions"},
{"file_id": "487024a", "url": "https://www.nature.com/articles/487024a", "year": 2012, "authors": [{"name": "Jon Bardin"}], "parsed_as_year": "2006_or_before", "body": "Much of our neural circuitry is fixed during childhood. Researchers are finding ways to unglue it, raising hopes for treating many brain disorders. Growing up in the suburbs of New York City, Takao Hensch learned German from his father, Japanese from his mother and English from the community around him. \u201cI was always wondering,\u201d he says, \u201cwhat is it that makes it so easy to learn languages when you're young, and so hard once you begin to get older?\u201d Today, as a neuroscientist at Boston Children's Hospital in Massachusetts, Hensch is at the forefront of efforts to answer that question in full molecular detail. Language acquisition is just one of many processes that go through a 'sensitive' or 'critical' period \u2014 an interval during development when the neural circuits responsible for that process can be sculpted, and radically changed, by experience (see 'Open and shut'). During critical periods, children can make rapid progress at discerning facial features that look like their own, recognizing spoken language and locating objects in space. But within a few months or years, each window of opportunity slams shut, and learning anything new in that realm becomes difficult, if not impossible. Or maybe not. What Hensch and others in the small, but rapidly advancing, field of critical-period research are finding is that those windows can be prised back open. \u201cFor the first time, we are beginning to understand the biology that underlies critical periods,\u201d says Hensch. And that understanding is suggesting ways to intervene in various neural disorders, including intractable conditions such as adult amblyopia, in which information from one eye is not correctly processed by the brain, and possibly even autism. The work could even lead to 'plasticity pills' that enhance learning or help to wipe out traumatic memories. \u201cWhat's so interesting about Takao's work is that he has shown that even if you miss these critical periods, you still may be able to go back in and fix things,\u201d says Charles Nelson, a neuroscientist at Boston Children's Hospital, who studies the developmental effects of early social deprivation on orphans in Romania. \u201cThe idea that you could intervene later and make up for lost time is compelling.\u201d The first scientist to popularize the notion of a developmental critical period was the Austrian biologist Konrad Lorenz, whose pioneering work in animal behaviour earned him a share of the 1973 Nobel prize. In the 1930s, Lorenz showed that if he took on the role of a mother goose within a few hours after goslings hatched, the baby geese would follow him as though he were their mother until adulthood. He called this process 'imprinting'. \n               Dogma, inhibited \n             The first scientists to explore the neural basis of a critical period were David Hubel and Torsten Wiesel, neurophysiologists at Harvard Medical School in Boston who carried out work on the visual system in the early 1960s. First they discovered that in the adult brain, many cells in the visual cortex respond to signals from only one eye. Then they showed that in kittens that had had one eye sutured shut, individual cells that normally would have fired in response to the closed eye instead responded to the open eye, eventually causing amblyopia 1 . Shutting the eye of an adult cat did nothing, indicating that cells in the visual cortex were programmed during a key developmental window in the first few months of life. Hubel and Wiesel lacked the tools to analyse how this programming worked at the molecular level, but they earned a Nobel prize in 1981 for their discovery. Their findings also inspired Hensch, during the 1980s, to change his undergraduate major from computer science and artificial intelligence to neurobiology. \u201cHubel and Wiesel's work made me realize that there was just so much we didn't know about the actual biology of the brain,\u201d he says. Hensch got a chance to learn more when he began his PhD work in Michael Stryker's neuroscience laboratory at the University of California, San Francisco (UCSF). Stryker's group, like most researchers in the field, studied the critical period of the visual system as a model of critical periods in general, and had published a series of papers hinting at a new approach to understanding it. For years, researchers had assumed that the brain's 'plasticity', or its ability to learn during critical periods, was the work of excitatory neurons, which encourage neighbouring neurons to fire. But Stryker's work suggested some kind of involvement by inhibitory interneurons, brain cells that dampen activity in their neighbours. Stryker's team had found that, in kittens, a drug that increases inhibition during the critical period made the visual cortex resistant to Hubel and Wiesel's trick: many neurons in that region began to fire in response to the closed eye rather than the open one 2 . Hensch followed up on this work in a collaboration with Michela Fagiolini and her colleagues at the RIKEN Brain Science Institute in Wako, Japan. The researchers looked at the critical period in genetically engineered mice that had slightly reduced levels of \u03b3-aminobutyric acid (GABA), an inhibitory neurotransmitter. The effect of that reduction was far greater than either Hensch or Stryker had imagined: whereas control mice went through a typical critical period and developed amblyopia when one eye was blocked, mice with GABA deficiencies did not develop amblyopia, or have a critical period at all. Hensch and his colleagues were able to restore plasticity by administering a benzodiazepine, a drug that enhances the inhibitory effect of GABA (ref.  3 ). Inhibition, the authors concluded, was a hidden force driving the onset of the visual critical period. \u201cAt the time, these ideas were just so counter-intuitive,\u201d Hensch says. \u201cWe were turning dogma on its ear.\u201d \n               Clever mechanisms \n             Researchers have since begun to clarify the workings of this force. In 2008, Hensch and Alain Prochiantz, a neuroscientist at the Coll\u00e8ge de France in Paris, found that when mice first open their eyes after birth, a protein called OTX2 is transported through the optic nerve from the retina to the visual cortex \u2014 a marathon in cellular distance. In the visual cortex, the accumulation of OTX2 sparks a series of events that causes PV interneurons, inhibitory cells that contain parvalbumin (PV), to mature and trigger the beginning of the visual critical period. But this transport takes place only after visual input is received; in mice raised in the dark, no OTX2 arrives in the cortex and no critical period ensues 4 . \u201cI think this is a pretty clever mechanism from nature,\u201d says Hensch, \u201cbecause you don't want to be plastic until you know that the periphery is functional and signals are coming in.\u201d But it was unclear how the PV interneurons triggered the critical period. An important clue came from a group led by Stryker with Arturo Alvarez-Buylla and Sunil Gandhi, also at UCSF. The researchers transplanted embryonic cells that were destined to become interneurons into the brains of young mice, says Alvarez-Buylla, after which the mice \u201cstarted having two critical periods\u201d. There was the typical critical period, caused by the mouse's own interneurons, and then a later one, triggered when the transplanted interneurons began to mature 5 . The transplanted cells, says Stryker, were pushing the system's 'reset' button. In the cerebral cortex of the adult brain, information travels through neural circuits along well-defined paths carved out by mature interneurons, which strongly inhibit some cells and not others. But in the transplant experiment, the maturing interneurons were making numerous weak connections with the older cells and inhibiting all the cells equally, overriding the brain's previously defined circuits. Only as those new cells matured were their connections pruned and strengthened, eventually carving out new permanent circuits. The findings suggested that the same mechanism \u2014 PV synapse proliferation followed by pruning \u2014 underlies all critical periods. Hensch and others have found that critical periods do not just taper off as PV interneurons mature. Instead, they are shut down as the brain slams on 'plasticity brakes' \u2014 presumably as a way to protect the newly optimized brain circuits from disruption by further input. Hensch separates these 'brakes' into two categories \u2014 structural and functional. The first comprises physical structures such as the perineuronal net (PNN), a complex of macromolecules that attach to PV interneurons around the time that a critical period ends, and that seem to restrict the extent to which a neural circuit can change. Chemical breakdown of the PNNs in adult rats makes their brains prone to being rewired 6 . Functional brakes are chemical compounds such as Lynx1 \u2014 a molecule, identified by Hensch and his colleagues, that shifts the balance of excitation and inhibition in the cortex by dampening the effect of the neurotransmitter acetylcholine. Experiments in mice show that the amount of Lynx1 in the brain increases at the end of the critical period, and its removal from adult brains, like degradation of the PNNs, seems to restore neural plasticity 7 . Hensch says that what he finds particularly compelling about functional brakes is that they are relatively easy to release. One example of this is a behavioural intervention developed by Roger Li and Dennis Levi, optometrists at the University of California, Berkeley, for adults with amblyopia. People develop amblyopia when problems such as cataracts or crossed eyes disrupt input to one of their eyes during early childhood, often leaving them without three-dimensional (3D) vision. The condition is considered untreatable once the critical period has ended. But when Li and Levi got people with amblyopia to play 40\u201380 hours of video games with their good eyes patched, most of them reported substantial improvements in visual function 8 . Describing one subject who was born with crossed eyes and had never seen the world in depth, Li says: \u201cOnce she found out she was able to see some 3D, she immediately began to cry.\u201d Hensch suggests that playing video games releases some of the brain's functional brakes. He notes that heightened attention, which often goes along with video-game playing, has been shown to increase the activity of acetylcholine \u2014 a surge that would counteract the damping effect of Lynx1. \n               Windows of opportunity \n             Researchers have begun experimenting with drugs to reopen the critical period. Hensch and David Hunter, an ophthalmologist at Boston Children's Hospital, received approval in May to begin a phase I clinical trial for treating amblyopia with a drug that increases the amount of acetylcholine in the brain. A similar study 9 , published in 2010 and led by neuroscientist Michael Silver of the University of California, Berkeley, found that when people with normal vision are given a drug that increases acetylcholine levels, they show greater improvements in visual acuity than people given a placebo. And a group led by Lamberto Maffei, a neurobiologist at the Scuola Normale Superiore in Pisa, Italy, has begun phase II clinical trials for amblyopia with selective serotonin re-uptake inhibitors, a class of drugs often used to treat depression. Such research makes it easy to imagine pills or shots that could aid recovery from a severe brain injury, for example, or make it easier to learn a new language or forget a terrifying memory. Lifting plasticity brakes might even be useful in treating complex disorders such as autism, says Hensch. He points to the difficulty children with autism have integrating input from multiple senses at once \u2014 when looking at a person's facial expressions while listening to them speak, for example. Such integration may require the critical periods for each sense to have occurred in a specific developmental sequence. \u201cI think that autism is a good example of what can go wrong when these different sensory critical periods are mistimed,\u201d he says \u2014 a view for which there is some experimental evidence 10 . For now, however, when it comes to the neural basis of complex psychiatric conditions such as autism, the experimental evidence is limited. But if tests could be created to identify risk factors for some developmental disorders, says Hensch, physicians may one day be able to deploy biologically informed interventions during the critical period, taking advantage of the brain's plasticity to set development on the right course. But no one in the field is suggesting that the brain's critical periods should be tampered with casually. \u201cWhen you reopen a critical period, there is, of course, always the possibility of a worse outcome,\u201d says Alvaro Pascual-Leone, a neurologist at Harvard Medical School, pointing out that disorders such as amblyopia occur because of harmful input during the original critical period. And structural brakes are considerably more difficult to release than functional ones. In 2009, for example, researchers showed that chemically destroying PNNs in mice makes it easier to erase their fear memories, suggesting a potential treatment for conditions such as post-traumatic stress disorder 11 . But to do this in humans could cause widespread brain damage that would outweigh any benefits. After all, says Hensch, the mechanisms that the brain uses to shut down critical periods are very complex, and they require a substantial amount of energy, \u201cwhich gives us a good sense that they've evolved for a reason\u201d. Stryker sounds a further note of caution. \u201cI think it's a romantic notion that you can replicate the critical period later in life,\u201d he says. \u201cSome things just don't unhappen.\u201d \n                     Neuroscience: Sibling neurons bond to share sensations 2012-Jun-06 \n                   \n                     Treating schizophrenia: Game on 2012-Feb-29 \n                   \n                     Japan centres aim to put science in premier league 2007-May-23 \n                   \n                     \n                         The Science of Early Childhood \n                       \n                   \n                     \n                         From Neurons to Neighborhoods \n                       \n                   Reprints and Permissions"},
{"file_id": "487160a", "url": "https://www.nature.com/articles/487160a", "year": 2012, "authors": [{"name": "Edwin Cartlidge"}], "parsed_as_year": "2006_or_before", "body": "Debate rages over whether researchers have managed to see an exceptionally rare form of radioactivity. Experiments this year should finally settle the issue. Once every 10 trillion trillion years or so, certain atomic nuclei might just break the rules. As two of their neutrons undergo an otherwise normal decay, changing into protons and spitting out electrons, they might fail to release the normal by-products: ghostly particles called neutrinos. To have any chance of detecting this rare \u2018neutrino-less double-\u03b2 decay\u2019, physicists have to collect a few trillion trillion atoms of an appropriate isotope \u2014 tens or even hundreds of kilograms\u2019 worth \u2014 put their sample deep underground so that it is isolated from cosmic rays and conventional radioactivity, then spend years counting potential decay events until they are sure that any signals they see aren\u2019t noise. It is an intricate and painstaking process, but several collaborations around the world are doing it, and some could even come up with an answer by the end of the year. A definitive sighting, says Ettore Fiorini, a particle physicist at the University of Milano-Bicocca in Italy, would be \u201cone of the most important discoveries in physics in the past 100 years\u201d. It would mean that the charge-less, almost mass-less neutrino is its own antiparticle, making it unlike any other fundamental particle. The discovery would allow physicists to finally pin down the mass of the neutrino, and it might even help them to understand why matter exists at all (see \u2018Decay tactics\u2019). But even if the decay is not seen, a definitive result would settle a controversy that has beset the neutrino-physics community since 2001, when Hans Klapdor-Kleingrothaus and his colleagues at the Max Planck Institute for Nuclear Physics in Heidelberg, Germany, claimed to have seen the phenomenon in a detector at Italy\u2019s Gran Sasso National Laboratory 1 . Many physicists think that the Heidelberg group simply mistook ordinary radioactivity for the exotic process. Even some researchers working on the experiment, including a team from the Kurchatov Institute in Moscow, didn\u2019t believe the claim and left the collaboration in protest. \n               boxed-text \n             But the Heidelberg group has refused to back down. That\u2019s not surprising, says Stefan Sch\u00f6nert, a physicist at the Technical University Munich in Germany and spokesman for another experiment at Gran Sasso, the Germanium Detector Array (GERDA). If the claim were to be confirmed, he says, \u201cthe Nobel prize would go to Klapdor-Kleingrothaus\u201d. \u201cThere is nothing that I could point to that would say he is obviously wrong,\u201d adds Steven Elliott, a neutrino physicist at the Los Alamos National Laboratory in New Mexico. \u201cBut this is clearly a dramatic claim, so people tend to be sceptical. What we want is really hard-core proof of whether he is right or wrong.\u201d \n               Crystal clear \n             The challenge is how to get that proof. Nothing in this business is easy\u00a0\u2014\u00a0as even the detector at the centre of the controversy demonstrated. Known as the Heidelberg\u2013Moscow experiment, it was built from 11.5 kilograms of germanium that had been enriched to 86% germanium-76 from the natural proportion of 7%. The team chose this isotope because it is one of only about a dozen known to undergo ordinary double-\u03b2 decay, so it was automatically eligible for neutrino-less decay. Germanium is also a semiconductor, which allowed the material to serve as both source and detector \u2014 any electrons emitted would deposit their energy in the surrounding crystal as an observable pulse of current. The experiment started generating data in 1990. The researchers\u2019 first and most obvious challenge was to shield the  76 Ge from any background radiation that could mimic the signal. The 1,400 metres of rock lying above the Gran Sasso lab blocked out cosmic rays 2 . And the researchers screened out most of the radio\u00adactivity from the surrounding rock using thick shields of lead and copper. They also made the components of the experiment from materials that have low natural radioactivity. Their second challenge was to distinguish between the different types of double-\u03b2 decay. The half-life for neutrino-less double-\u03b2 decay, assuming that it happens, was estimated at the time to be longer than 10 22  years. The researchers therefore expected to see no more than a few thousand neutrino-less events per year in their 11.5 kilograms of  76 Ge; ordinary double-\u03b2 decay, which at the time was thought to have a half-life in the order of 10 20  years, would generate at least 100 times more events. And the decay products\u00a0\u2014\u00a0a pair of electrons\u00a0\u2014\u00a0would look identical. Any neutrinos would effectively be invisible, flying out of the detector without leaving a trace. To identify neutrino-less decay, physicists need to measure the energy of the electrons. In ordinary double-\u03b2 decay, the total energy is shared between the electrons and the neutrinos in a way that changes randomly from one decay to the next. The electron energies are therefore spread across a wide range of values. But in neutrino-less decay, the electrons take up all the energy so the energy spectrum should show a sharp peak at a single value\u00a0\u2014\u00a0at 2,039\u00a0kiloelectronvolts (keV) in the case of  76 Ge. That is exactly what Klapdor-Kleingrothaus and his colleagues claimed to have seen. They announced that almost 10 years of data-taking had produced a peak containing about 15\u00a0events right at the expected energy\u00a0\u2014\u00a0and that there was only a 3% chance that the peak was due to a statistical fluctuation in background radiation 1 . Neutrino-less double-\u03b2 decay, they claimed, had been found. But critics \u2014 and there have been many \u2014 are not so sure. Their biggest concern is that the team did not adequately account for the multitude of other peaks in the data, most of which are from background radioactivity that no experiment can ever fully screen out. In 2002, Elliott and 25 other physicists said as much in a letter 3  to  Modern Physics Letters\u00a0A , the journal that had published the result. They weren\u2019t convinced, for instance, that the Heidelberg researchers had correctly attributed some of the peaks to bismuth-214 in the rocks surrounding the lab and in the detector components. And if the team couldn\u2019t prove that, the critics said, then how could it claim to know what caused the feature at 2,039\u2009keV? The Heidelberg group\u2019s response was to collect another three years\u2019 data, taking extra care in the measurement and identification of the bismuth-214 peaks 4 . The researchers also tracked every surge of energy that was deposited in their detector, measuring the rise and fall of the electrical current over several hundred nanoseconds. At that timescale, the energy released in both ordinary and neutrino-less double-\u03b2 decay should form a single pulse, whereas background radioactivity tends to generate multiple pulses, making it easier to distinguish signals from background. This analysis eliminated much of the background noise, as well as four of the events in the 2,039 keV peak, but allowed the team to claim a greatly improved statistical significance for the remaining 11 events. In 2006, the researchers announced 4  that the peak was consistent with a half-life of 2.2\u2009\u00d7\u200910 25  years for neutrino-less double-\u03b2-decay in  76 Ge, and with a neutrino mass of about 0.3\u2009eV. \u201cThere is a signal at the right energy and we show that the events in the signal are of single-site nature,\u201d says Klapdor-Kleingrothaus, referring to the single-pulse energy deposit. \u201cMore than that you cannot do.\u201d Sceptics remain unconvinced; arguments still rage about whether the background radiation had been properly accounted for. But the experiment was closed down in November 2003, and no other double-\u03b2-decay detector had the sensitivity to test the team\u2019s conclusions. Only now has a new generation of experiments begun to reach that level. Perhaps the one that has come closest is EXO, the Enriched Xenon Observatory, which is about 650 metres underground at the US Department of Energy\u2019s Waste Isolation Pilot Plant in Carlsbad, New Mexico. EXO is looking for neutrino-less double-\u03b2 decay in 200 kilograms of liquid xenon enriched in xenon-136. Last month, collaboration member Jacques Farine of Laurentian University in Sudbury, Canada, told delegates at the Neutrino 2012 conference in Kyoto, Japan, that the experiment had seen no evidence of the neutrino-less decay in data collected between September 2011 and April 2012. The finding 5 , the collaboration says, amounts to \u201cthe almost complete refutation\u201d of the Heidelberg claim. Or maybe not. EXO used a different isotope from that used in the Heidelberg\u2013Moscow experiment, and there is considerable uncertainty about how the different nuclear structures affect the rates of neutrino-less double-\u03b2 decay. This gives the Heidelberg team wiggle room even if the negative results continue at EXO, and at two other competing experiments: the KamLAND-Zen project in the kilometre-deep Kamioka mine in Japan, which also uses  136 Xe, and the Cryogenic Underground Observatory for Rare Events (COURE) detector in Gran Sasso, which uses tellurium-130. But there would be no such wiggle room if GERDA were also to see nothing. GERDA uses the same sample of enriched germanium that was monitored in the Heidelberg\u2013Moscow experiment, as well as some similarly enriched material salvaged from the International Germanium Experiment, which was operated by a collaboration of US, Russian, Spanish and Armenian physicists at the Canfranc Underground Laboratory under the Pyrenees Mountains in the 1990s. GERDA has much lower levels of background events than its predecessor, Sch\u00f6nert says, partly because the materials close to the germanium are purer, so it will quickly equal and then surpass the Heidelberg\u2013Moscow experiment\u2019s sensitivity. Having started up in November 2011, it should have acquired enough data to \u201crule Klapdor-Kleingrothaus in or out\u201d by late 2012 or early 2013, he says. \n               Matter of scale \n             But even a negative result from GERDA would not necessarily kill the idea. It could simply mean that the decay is rarer than the Heidelberg group claimed\u00a0\u2014\u00a0in which case researchers will need much bigger detectors to identify it. Michel Sorel, a physicist at the Spanish National Research Council in Valencia, and physics coordinator of the Neutrino Experiment with a Xenon Time Projection Chamber (NEXT) detector in the Canfrac laboratory, estimates that several tonnes of material could be needed. A number of the existing collaborations are planning to upgrade their detectors to reach the multi-tonne scale, but Sorel believes that the cost of building them \u2014\u00a0US$100 million to $200 million each\u00a0\u2014 means that only one such experiment is ever likely to be realized. In the meantime, however, Sorel is eager to see the Heidelberg claim tested with the existing detectors. \u201cMost of the community was against the claim and probably still is,\u201d he says. \u201cBut people take it seriously and that is why germanium experiments like GERDA were built.\u201d Verification of the Heidelberg claim would be \u201cfantastic\u201d, Sch\u00f6nert says, because experiments could then be dedicated to investigating the mechanisms behind neutrino-less double-\u03b2 decay. Physicists know that one mechanism is a \u2018virtual\u2019 neutrino that leaps from one neutron to the other too quickly for them to observe. But another might be one of the long-sought \u2018supersymmetrical\u2019 particles that physicists have hypothesized as extensions to the standard model of particles and forces. The important thing now, says Sch\u00f6nert, is that physicists working on double-\u03b2-decay experiments keep their competitive streaks in check. \u201cIt is not important who rules out or confirms Klapdor-Kleingrothaus first,\u201d he insists, \u201cbut that the data are of high quality. We have to try and keep to the spirit of the community, and not be the loudest shouter.\u201d \n                     Gran Sasso: Chamber of physics 2012-May-23 \n                   \n                     Particle physics: A matter of detail 2012-Apr-18 \n                   \n                     Deep science strikes gold after latest site is named 2007-Jul-18 \n                   \n                     Particle physics: Antimatter matters 2003-Aug-07 \n                   \n                     GERDA \n                   \n                     EXO \n                   Reprints and Permissions"},
{"file_id": "486460a", "url": "https://www.nature.com/articles/486460a", "year": 2012, "authors": [{"name": "Elie Dolgin"}], "parsed_as_year": "2006_or_before", "body": "Tiny molecules called microRNAs are tearing apart traditional ideas about the animal family tree. Kevin Peterson grabs a pen and starts to scribble an evolutionary tree on the paper tablecloth of a bar in Hanover, New Hampshire. Drawing upside down to make it easier for me to see, he maps out the standard phylogenetic tale for placental mammals. First, Peterson scratches a line leading to elephants, which branched away from the rest of the placentals around 90 million years ago. Then came dogs, followed by primates (including humans) and finally rodents \u2014 all within a frenetic 20 million years. This family tree is backed up by reams of genomic and morphological data, and is well accepted by the palaeontological community. Yet, says Peterson, the tree is all wrong. A molecular palaeobiologist at nearby Dartmouth College, Peterson has been reshaping phylogenetic trees for the past few years, ever since he pioneered a technique that uses short molecules called microRNAs to work out evolutionary branchings. He has now sketched out a radically different diagram for mammals: one that aligns humans more closely with elephants than with rodents. \u201cI've looked at thousands of microRNA genes, and I can't find a single example that would support the traditional tree,\u201d he says. The technique \u201cjust changes everything about our understanding of mammal evolution\u201d. Peterson didn't set out to rewrite textbooks. A mild-mannered but straight-talking Montanan, Peterson had made a quiet career studying how bilateral body plans originated more than 500 million years ago. He has a particular interest in marine invertebrates and had intended to stick with that relatively obscure branch of the animal tree. But a chance investigation of microRNAs in microscopic creatures called rotifers led him to examine these regulatory molecules in everything from insects to sea urchins. And as he continues to look, he keeps uncovering problems, from the base of the animal tree all the way up to its crown. That has won him many critics, but also some strong supporters. \u201cPeterson and his colleagues have demonstrated that microRNAs are a powerful tool in determining the relationships of major animal groups,\u201d says Derek Briggs, director of the Yale Peabody Museum of Natural History in New Haven, Connecticut. Now, together with his colleagues around the world, Peterson is putting it all on the line with mammals. \u201cIf we get this wrong, all faith that anyone has in microRNAs [for phylogenetics] will be lost,\u201d says Philip Donoghue, a palaeobiologist at the University of Bristol, UK, who has teamed up with Peterson. And there is more at stake than just the technique. \u201cIt could well be the end of all our careers,\u201d he says. \n               Fossil find \n             If Peterson does end up switching careers, it won't be the first time. In the early 1990s, he was working the night shift unloading trucks at a freight company in his hometown of Helena, Montana, trying to figure out what to do with his life. He had recently graduated with a pre-medical degree from a local liberal arts college, but he knew he didn't want to become a doctor. Then, rummaging in his parents' barn, he happened on the first fossil he had ever collected, as a four-year-old: a crinoid, or sea lily, about the size of a button. \u201cAfter I found it, I knew right away that this was what I wanted to do,\u201d he says. \u201cI applied to graduate school the next week.\u201d He soon enrolled in a PhD programme in the Department of Earth and Space Sciences at the University of California, Los Angeles. There, he teamed up with developmental geneticists Eric Davidson and Andrew Cameron at the California Institute of Technology in Pasadena, and over the course of his graduate and postdoctoral work the three men developed a provocative idea, dubbed the set-aside cell hypothesis 1 . They posited that the ancestor of modern-day animals was a larva-like creature containing a group of undifferentiated cells that retained the capacity to give rise to the spectrum of adult body types seen during the Cambrian explosion. The idea subsequently came under fire from the evolutionary and developmental-biology communities. A few years after moving to Dartmouth in 2000 to start his own lab, Peterson was looking for a way to test the hypothesis when he became intrigued with microRNAs. First discovered in 1993 by Victor Ambros, now at the University of Massachusetts Medical School in Worcester, these short, hairpin-shaped molecules bind to messenger RNAs and stop them from making proteins. A team that included Davidson had shown that a microRNA called let-7 was present in animal lineages that had bilateral body plans but not in simpler organisms such as jellyfish and sponges 2 , hinting that microRNAs could hold the secret to morphological complexity. Peterson teamed up with Lorenzo Sempere, then a graduate student working with Ambros at Dartmouth, and the pair began to search for let-7 and a handful of other microRNAs in relatively simple invertebrates, including rotifers, and in more complex creatures. As they added more microRNAs, they found a clear pattern: the farther away from the trunk of the evolutionary tree the animals were, the more microRNAs they had accumulated 3 . The pair started to realize that the molecules provided \u201ca brand new way to do phylogeny, using a set of rare genomic characters that no one had ever considered before\u201d, Peterson says. MicroRNAs, Peterson and Sempere discovered, are unlike any of the other molecular metrics that biologists typically use to tease apart evolutionary relationships. DNA binding sites, for example, continuously mutate; microRNAs, by contrast, are either there or they aren't, so their interpretation doesn't require such complex sequence and alignment analyses. And once gained, microRNAs usually remain functional, which means that their signal stays intact for hundreds of millions of years. \u201cNo gene family was known to evolve in this way,\u201d Peterson says. In addition, these small molecules are often expressed in specific tissues and help to regulate the development of certain organs, so they could explain the origin of morphological innovations over geological time 4 . According to Peterson's latest tally, 778 microRNA families have arisen during the 600 million or so years of animal evolution, and only 48 have been lost. This pattern of inheritance leaves an easy-to-follow evolutionary trail for phylogenetic sleuths. Eugene Berezikov, a geneticist who studies microRNAs at the Hubrecht Institute in Utrecht, the Netherlands, says that microRNAs give a clearer answer than other molecular markers of evolution \u201cbecause the analysis is much simpler\u201d. \n               Out of obscurity \n             At first, Peterson and Sempere had a tough time publishing their results suggesting that animals had accumulated regulatory microRNAs. \u201cOne of the reviewers said it was impossible, what we were describing,\u201d says Peterson. In the end, the work was published in a specialized zoology journal 3 . Subsequent papers, however, won over some sceptics and Peterson was soon publishing in  Nature  and  Science , and using his growing microRNA library to resolve relationships within and between an assortment of evolutionary lineages, from jawless fishes 5  and reptiles 6  to fruitflies 7  and acoelomorph worms 8 . \u201cIt is a really clever and fresh approach to phylogeny,\u201d says Peter Stadler, an evolutionary bioinformatician at the University of Leipzig in Germany. \u201cI don't quite know why presence/absence of microRNAs is not used more frequently in deep phylogeny approaches.\u201d Still, not everyone is convinced that microRNA genes trump other types of phylogenetic data. A key point of contention is whether microRNAs only rarely drop out of the genome, as Peterson contends. Andreas Hejnol, who studies invertebrate evolution at the Sars International Centre for Marine Molecular Biology in Bergen, Norway, is sceptical. \u201cMicroRNAs behave like other genes \u2014 namely, they can be lost,\u201d he says. \u201cThere's no special mystery about them.\u201d Travis Glenn, an evolutionary biologist at the University of Georgia in Athens, agrees, saying that microRNA losses are probably underestimated. In May, he and his colleagues published a retort 9  to a paper 6  in which Peterson had argued that turtles are more closely related to lizards than to birds and crocodiles \u2014 the opposite of what most genomic data sets had indicated. Glenn argued that ultraconserved DNA elements \u2014 ones that evolution has kept intact over a long time \u2014 show that the conventional view is correct. The critics have mostly been a vocal minority, but as Peterson climbs up the evolutionary ladder with his microRNA analyses, he will be reaching a much bigger audience \u2014 and the detractors are likely to become a lot louder. \u201cWe're mammals, so this matters,\u201d he says. \n               Up a tree \n             When Peterson started his work on the placental phylogeny, he had originally intended to validate the traditional mammal tree, not chop it down. As he was experimenting with his growing microRNA library, he applied it to mammals because their tree was so well established that they seemed an ideal test. Alas, the data didn't cooperate. If the traditional tree was correct, then an unprecedented number of microRNA genes would have to have been lost, and Peterson considers that highly unlikely. \u201cThe microRNAs are totally unambiguous,\u201d he says, \u201cbut they give a totally different tree from what everyone else wants.\u201d The results change the image of the proto-placental mammal. Because microRNAs place mice and rats at the base of the placental tree, they suggest that rodent-like traits, such as continuously growing incisor teeth, were common in the first placentals, then lost in the lineage that leads to primates, elephants, dogs and cows (see 'Duelling trees'). The findings also shift the geographical origin of placental mammals, suggesting that they started in the Northern Hemisphere, where the first rodent fossils are found, not in the Southern Hemisphere, as many researchers have assumed on the basis of fossil and DNA data. At first, Peterson was shocked by his results, which still haven't been published. But he has spent the past year validating his tree with gene-expression libraries and genomic sequences, all of which he says support his findings. Many supporters of the traditional tree suspect that something peculiar is happening with the microRNAs \u2014 probably large losses in the mammalian lineage. \u201cHe's talking about the entire genome that has to be wrong,\u201d says Robert Asher, a mammalian palaeontologist at the University of Cambridge, UK. \u201cI don't give it any serious consideration,\u201d says Mark Springer, a molecular phylogeneticist at the University of California, Riverside, who last year published the most comprehensive genomic data set so far in support of the traditional mammalian tree 10 . \u201cThere have to be other explanations,\u201d he says. Peterson and his team are now going back to mammalian genomes to investigate why DNA and microRNAs give such different evolutionary trajectories. \u201cWhat we know at this stage is that we do have a very serious incongruence,\u201d says Davide Pisani, a phylogeneticist at the National University of Ireland in Maynooth, who is collaborating on the project. \u201cIt looks like either the mammal microRNAs evolved in a totally different way or the traditional topology is wrong. We don't know yet.\u201d Hoping to resolve the issue, Donoghue and phylogeneticist Ziheng Yang at University College London have spent the past year amassing DNA sequences that span more than 14,600 genes from 36 mammalian species \u2014 a data set that dwarfs the one used by Springer. They are trying to determine whether the larger crop of DNA data produces the same tree as microRNAs yield. They have been able to date the origin and diversification of placental mammals 11 , but they are still working to resolve which lineages branched off first \u2014 a key test for the phylogenies. Peterson would like to put it all behind him. \u201cWhat sucks about this mammal project is that it's all-consuming,\u201d he says. \u201cUltimately, I don't really care how mammals are related to one another \u2014 it doesn't matter to me. But what does matter is the validity of the data set.\u201d If it turns out that the traditional mammal tree is right, Peterson won't see that result as a defeat for microRNAs. It would just mean that something odd happened with mammalian microRNAs, he says. \u201cThat says something really interesting about the evolution of microRNAs and the construction of gene regulatory networks in mammalian evolution.\u201d For now, he's trying to amass the best evidence he can before publishing the mammal study. Then he wants to return to the quiet life of an ancient-invertebrate biologist. But if Peterson's voyage upends the mammalian phylogeny, he'll have left a furry mess in his wake. \n                     Turtles emerge from their evolutionary shell 2011-Jul-19 \n                   \n                     Evolution: A can of worms 2011-Feb-09 \n                   \n                     Leggy creatures and long branches 2010-Aug-10 \n                   \n                     Evolution: Mouth to mouth 2009-Sep-09 \n                   \n                     Evolution & ecology \n                   \n                     Evolution supplement \n                   \n                     Kevin Peterson \n                   \n                     MicroRNAs and metazoan phylogeny: big trees from little genes \n                   Reprints and Permissions"},
{"file_id": "487156a", "url": "https://www.nature.com/articles/487156a", "year": 2012, "authors": [{"name": "Virginia Gewin"}], "parsed_as_year": "2006_or_before", "body": "Faeces, lizards, keyboards, faces \u2014 Rob Knight likes to sequence the microbes on anything and everything. Next, he plans to sequence Earth. Rob Knight wants the spit of a komodo dragon. But he is unsure whether Bintang, a metre-long juvenile of this endangered lizard species, will oblige. Wielding a white cotton swab, Knight cautiously approaches the creature, which is squirming in its keeper's arms at the Denver Zoo in Colorado. With an inquisitive flick of the tongue, Bintang deposits a dab of saliva on the swab. Knight pops the swab into a sterile plastic tube, opens another tube and goes on to collect samples from the lizard's head and belly. He also swabs the enclosure, which is part of the world's most successful facility for the captive breeding of komodo dragons ( Varanus komodoensis ). The samples are teeming with the bacteria and viruses that live in the reptile's mouth, gut and skin. Back in his lab at the University of Colorado Boulder, Knight will sequence the DNA of these microorganisms \u2014 and eventually compare the microbes with those found on komodo dragons in the wild and at other facilities, to try to find out whether and how they affect the animals' survival and why captive females tend to die young. If there is a link between this species' microbes and its health, Knight is the one to find it. He is a leader in the burgeoning field of microbiome research, which aims to sequence the mass of genes from microbial communities and use computational tools to count and compare species. Knight has helped to reveal differences between the gut microbes in obese and lean people 1 ; to show that people's intestinal microbes differ dramatically depending on where in the world they live 2 ; and to document the wide differences between the microbes acquired by babies born by Caesarean section and those delivered vaginally 3 . Outside the human body, Knight has probed the microbes that blanket various natural and man-made environments, from freshly fallen snow to computer keyboards and bathroom floors. He does all this at a restless, relentless pace; he co-authored 49 publications in 2011 alone. Knight is sensitive to the charge that all this is an exercise in microbial surveying, rather than in hard hypothesis-testing. \u201cWe don't take on projects if the scientific value isn't clear,\u201d he says. \u201cWhat motivates me, from a pragmatic standpoint, is how understanding the microbial world might help us improve human and environmental health.\u201d The microbiota hold clues, he says, to solving major societal problems \u2014 preserving endangered species, for example, or treating obesity or malnutrition. Since 2010, Knight has been involved with the most ambitious effort yet to probe the microbiota: the Earth Microbiome Project, a collaborative effort to sequence and characterize the microbial communities in at least 200,000 environmental samples such as soils and water collected from around the world. He says that the project, which is led by Jack Gilbert, an environmental microbiologist at the US Department of Energy's Argonne National Laboratory in Illinois, will yield a master list of the proteins required to sustain microbial life across the planet; about 500,000 reconstructed microbial genomes; and the makings of a global-scale model of microbial metabolism. \u201cKnight and Gilbert literally talk about sampling the entire planet. It is ludicrous and not feasible \u2014 yet they are doing it,\u201d says Jonathan Eisen, an evolutionary biologist at the University of California, Davis. \u201cRob is one of the few people who are surfing the exponential curve of increased sequencing power,\u201d Eisen adds, \u201cand planning where the wave will take him next.\u201d \n               Everything of interest \n             A tall, lanky 35-year-old, Knight doesn't look the part of a tenured professor. He speaks so rapidly that he can be difficult to follow, and his ideas erupt at a similar rate. The conversation can swerve from using microbes to estimate time of death to his hopes of one day swabbing the International Space Station to reveal its hidden microbial life. \u201cI've never been interested in just one thing,\u201d he says. As a youth growing up in New Zealand, Knight had interests ranging from fossils to chemistry and computers. \u201cI didn't really have this idea that science should be compartmentalized into biology or physics,\u201d he says. He was soon dabbling in both at Princeton University in New Jersey, as he worked on a PhD project analysing the evolution of the genetic code. He went on a self-taught computer-programming binge, logging 12\u201320 hours of screen time per day, writing code, testing programs and working out bugs. Cathy Lozupone, a technician in the Princeton lab at the time, recalls one night in 2000 when Knight, who was in between apartments, was briefly staying with her. She woke at 2 a.m. to find him trembling with excitement after solving a thorny computational problem. The program he had devised crunched through protein-coding sequences from 600 species spanning all domains of life to show that very simple rules involving mutation and selection could explain a major puzzle about DNA: why different organisms prefer different coding sequences for the same amino acid 4 . Knight moved to Boulder as a postdoc in 2001, and went on to run his own group. He began attending lab meetings with famed microbiologist Norm Pace, whose group was studying microbial diversity by sequencing 16S ribosomal RNA, a stretch of 1,500 nucleotides used for studying evolutionary relationships. Knight saw that mass sequencing of microbes was taking off, but that it was enormously challenging to make sense of so much data. He developed a software tool dubbed UniFrac (unique fraction) 5 , which provides a measure of the difference between two microbial communities by constructing evolutionary trees from the sequences in each sample and calculating the fraction of branches that are unique to each. UniFrac received a high-profile test when Knight teamed up with Jeff Gordon, a leader in microbiome research at Washington University in St Louis, Missouri, and his postdoc Ruth Ley. The researchers used UniFrac to show that microbial populations in the guts of obese mice differ from those in lean ones 6 . That paper has now been cited more than 500 times, and the program has become a standard analytical tool in the field. \u201cBefore UniFrac we had simply been tallying species, but understanding whether the species were related or not gave us deeper insights into the biology of communities,\u201d says Ley, now a microbiologist at Cornell University in Ithaca, New York. \n               Up close and personal \n             Fascinated by the gut's inhabitants, Knight was soon helping to chart a course for the Human Microbiome Project (HMP) \u2014 a US$115-million effort funded by the US National Institutes of Health to sequence the tens of trillions of microbes that live in and on humans \u2014 which published its major results in June 7 . He also plunged into data: Knight and his colleagues showed that the human body's bacteria vary dramatically between the gut, skin, mouth, ears and other locations 8 . And by exploring the faeces of mammals ranging from kangaroos to lemurs and zebras, Knight's team showed that microbiota adapt to diet \u2014 be it carnivorous, herbivorous or omnivorous \u2014 in a similar way across all mammalian lineages 9 . With a rapid succession of high-profile papers, \u201cRob exploded onto the scene \u2014 he went from no profile to being everywhere\u201d, says Phil Hugenholtz, a microbial ecologist at the Australian Centre for Ecogenomics in Brisbane. Knight has continued to develop software for handling the increasingly giant data sets generated by modern sequencing technology. One package, called QIIME (quantitative insights into microbial ecology) 10  uses tools developed by Knight's group and others to simultaneously compare millions of raw sequences, assign species names when possible, build phylogenetic trees and visualize the data in many different ways. During the HMP, Knight was vocal about his concerns that the tools and data weren't being shared effectively with the wider community. In one case, he \u201cchallenged in a very public way\u201d a rule that was slowing down publication, says Owen White, associate director of the Institute for Genome Sciences in Baltimore, Maryland, who oversees the central data repository for the HMP. The rule was later overturned. White says that Knight was also instrumental in shifting the centre of intellectual power in genomic analysis from larger sequencing centres to smaller labs. Knight says that he wants to \u201cdemocratize\u201d the data and tools. \u201cTo maximize the output of science, it makes more sense to do things that are good for the field overall,\u201d he says. Another of his innovations lies in working out how to link sequence data to the sample's metadata \u2014 environmental details such as pH, temperature, salinity and collection time \u2014 so that the maximum amount of information can be stored and extracted. \u201cHe strongly encouraged people to get organized and put their data in a standard format so that studies could be compared,\u201d says Ley. Knight has ruffled some feathers \u2014 perhaps owing to his meteoric rise at an envy-inducing young age, or his unflinching criticism when he thinks something is being done in the wrong way. \u201cHe's not always terribly diplomatic,\u201d says Ley. Some complain of \u201csuperficial, catchy\u201d studies, says one colleague who preferred not to be named. Knight's work certainly can make a splash: in 2010, the popular detective television programme  CSI: Miami  featured a technique developed by Knight and Noah Fierer, a microbial ecologist at Boulder, with which they matched individuals to the unique bacterial fingerprints that they left on computer keyboards 11  (see 'CSI: Microbes'). Knight's team also attracted attention with as-yet unpublished work mapping the microbes that carpet the human face from forehead to lips, and a study documenting how the gut microbiota of a Burmese python ( Python molurus ) shifted from famine to feast mode as the snake digested a rat over three days 12 . \n               Serious business \n             Knight doesn't deny that he is one of two \u201chealthy subjects\u201d involved in generating the largest time series of human microbiota yet collected 13 : he swabbed his palms, mouth and faeces every day for 15 months for the cause. And he relishes the story of an airport official who briefly confiscated the thermos of dry ice he was carrying to transport the samples. Six hours later, in Knight's office, the thermos exploded because the official had cinched down the lid too tightly. Knight says that all his studies have a serious intent. The time-series data, for example, showed that there was vastly more variation within one person's microbiota than expected. He hopes that the finding will convince clinicians that monitoring people's microbiomes over time could be useful in a clinical trial, allowing investigators to, for example, test whether variations in microbiota correlate with a drug response. \u201cIt's the kind of thing where you wouldn't want to ask someone else to go through the trouble if you haven't demonstrated the feasibility yourself,\u201d he says. Knight says he currently has about 70 papers in draft form, involving roughly 50 principal investigators. But that looks set to increase thanks to the Earth Microbiome Project. Knight, Gilbert and Janet Jansson, a microbial ecologist at the Lawrence Berkeley National Laboratory in Berkeley, California, are encouraging microbiologists worldwide to send in samples. They have already received some 60,000, ranging from deep-sea sediments from the Pacific Ocean to owl nests from Alaska. The researchers, funded so far on about $3 million from the US Department of Energy, as well as scraps from private sponsors and their own and their contributors' funds, have sequenced around 15,000 of them. They are making all the data and tools \u2014 many of which Knight developed or is developing \u2014 openly available. \u201cThe Earth Microbiome Project is not a purely exploratory project,\u201d Knight emphasizes. The plan, he says, is to collect a number of hypothesis-driven data sets, such as samples collected in pristine and disturbed areas of the Australia coastline to determine whether the disease-driven decline of algae has knock-on effects for other organisms. By combining data sets, the team should also be able to test broader hypotheses \u2014 such as whether the dominant microbes in a sample always have the most important functions. To that end, Knight continues to collect samples whenever he has the chance; later this month, for example, he will be scraping up microbial 'mats', which are among the most diverse communities known, from hypersaline waters off the Californian coast. The komodo-dragon samples are going into the project, and Knight now has approval to sample these and other species at a further three zoos. Knight has other ventures on the boil. In one project, he is exploring whether gut microbial communities can influence mental health by, for example, changing the signalling patterns between the gut and brain. \u201cMy family has schizophrenia on one side and bipolar disorder on the other,\u201d he says, \u201cwhich has led to my interest in trying to figure out whether we could potentially address those conditions.\u201d With Gordon and Lozupone, he is also part of a global network for the study of malnutrition and intestinal diseases, funded by the Bill & Melinda Gates Foundation in Seattle, Washington. Working in Bangladesh, the team hopes to identify the microbes associated with malnutrition, and to explore potential probiotic or other microbial treatments. Knight struggles to explain how he sustains his eclectic interests and level of intensity. With so much to sequence, over-commitment is an occupational hazard for everyone in microbiome research, he says. But Gilbert says that the research community faces a challenge in keeping up with Knight. \u201cUnless he burns out in the next 20 years,\u201d says Gilbert, \u201cI think we'll look back at him as a pioneer.\u201d \n                     Microbiology: Learning about who we are 2012-Jun-13 \n                   \n                     The human microbiome: at the interface of health and disease 2012-Mar-13 \n                   \n                     Social network wants to sequence your gut 2011-Sep-08 \n                   \n                     Microbiology: The new germ theory 2010-Nov-24 \n                   \n                     The gut's 'friendly' viruses revealed 2010-Jul-14 \n                   \n                     Colonizers give up sequence secrets 2010-May-20 \n                   \n                     Rob Knight \n                   \n                     Human Microbiome Project \n                   \n                     Earth Microbiome Project \n                   Reprints and Permissions"},
{"file_id": "487290a", "url": "https://www.nature.com/articles/487290a", "year": 2012, "authors": [{"name": "Daniel Cressey"}, {"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "The Olympics is a vast experiment in human performance, sport technology and global travel.  Nature  meets some of the scientists behind the scenes. Science has had a hand in every aspect of the Olympic and Paralympic Games. For the thousands of athletes, researchers have helped to develop training techniques, schedules, diet, equipment and doping checks. For the millions of spectators about to descend on London, they have contributed to urban planning, crowd control, public health and security. For the billions watching at home, they have shaped the technology that will measure athletic feats and beam them worldwide. Yet those scientists toil in the background, understandably overshadowed by the sporting spectacle. Here,  Nature  profiles four scientists whose work will contribute to the giant human experiment that is the Olympic Games. \n               The psychologist \n             In 2000, the Spanish basketball team in the Paralympics learning-difficulties category swept the board to win all of their games and take gold. There was just one problem: many of the team were not intellectually disabled. After the scandal was revealed by an undercover journalist, the team was stripped of its medals, and anyone with a learning disability was excluded from the next two Paralympic Games. This year, in London, they can return, in athletics, swimming and table tennis. Jan Burns, head of the Department of Applied Psychology at Canterbury Christ Church University, UK, is one of the key scientists responsible for ensuring that the athletes qualify for competition. Intellectual disabilities are difficult to police because, unlike most physical disabilities, they are not always obvious. In the wake of the Spanish fiasco, the International Paralympic Committee and Inas, the international federation for para-athletes with an intellectual disability, sponsored an international research group to solidify the criteria for 'eligibility' (existence of a disability), and 'classification' (impairment of ability to play the sport). Burns, a specialist in intellectual disability, joined the research group in 2009 and became head of 'eligibility' at Inas. \u201cShe had an incredible interest in the interaction and the application of these psychological concepts in this kind of an environment,\u201d says Peter Van de Vliet, the medical and scientific director of the International Paralympic Committee, based in Bonn, Germany. The criteria Burns helped to develop have paved the way for intellectually disabled athletes to return to the Paralympics. According to the rules now, an athlete is eligible if he or she has had a developmental delay before the age of 18; has an IQ of no more than 75; and has a 'significant limitation' in adaptive behaviour such as social skills. Eligible athletes are then subjected to a battery of tests to show that they classify as disabled for a specific event. A swimmer, for example, would first be assessed on skills that are generically useful in sports, such as reaction time. Then his or her swimming performance would be compared with that of other athletes. Burns points at research showing that people with intellectual disabilities tend to take more strokes to cover a given distance, so classifiers will video swimmers in competition and assess their stroke ratio to see whether it falls within the 'bandwidth' of disabled swimmers. All this has to be comprehensively documented and reviewed by multiple researchers so that the system is robust against fraud. Burns is currently working a hectic schedule juggling her Paralympics work, her regular academic job and huge interest from the world's media. \u201cI'm currently going through and checking everybody's file, making sure we know enough about everybody who's come through the system,\u201d she says. During the Paralympics, which run from 29 August to 9 September, \u201cI'll be around ensuring that the classification goes well and to be on hand if we do have any issues\u201d. Work is already under way to see whether more sports can be added for the 2016 Paralympics in Rio de Janeiro, Brazil. This involves working out the skills that athletes need to play a sport, and how intellectual disabilities might affect performance \u2014 for example, pattern recognition might be relevant to the complex plays in some team sports. The early betting is that the Rio Paralympics will include rowing and will give a second chance to the game that started the story: basketball. \n               The doping detector \n             In this summer's 100-metre sprint, Usain 'Lightning' Bolt will attempt to hold onto his title of 'world's fastest man' against a younger and currently fleeter Yohan Blake. Yet one of the fiercest battles in the Olympic Games will play out in a giant, custom-built suburban laboratory in Harlow, 35 kilometres north of the Olympic village. Here, anti-doping experts will apply the most sophisticated tools in their molecular arsenal in the seemingly Sisyphean pursuit of those athletes who take performance-enhancing drugs. The lab will screen for dozens of stimulants, steroids and other banned substances. Christiaan Bartlett, a senior scientist at the King's College London Drug Control Centre, which is running the Harlow lab, will direct the testing for biological drugs such as the blood-boosting hormone erythropoietin (EPO) and human growth hormone. Anti-doping science is notoriously \u2014 some say unnecessarily \u2014 secretive; Bartlett says that he cannot reveal what drug-detection techniques will be rolled out at the London games. All he will disclose is this: \u201cWe've got the most sophisticated equipment, we spent the past year or so developing and validating new techniques that will give us increased sensitivity in all of our areas.\u201d The first challenge for Bartlett and his 150 or so colleagues lies in handling the sheer volume of urine and blood that Olympic and Paralympic athletes will be required to submit for testing during the games \u2014 collected from as many as 7,000 athletes days before and immediately after sporting events. Samples will arrive hourly, with one part prepared for testing and the other frozen as a back-up, and the lab will run around the clock to turn around most tests within a day. Bartlett has already decamped from his home in south London to live closer to the lab, and he knows that his weekends won't be spent watching sport. The vast majority of the tests he oversees will come back with an all-clear. If the King's lab turns up any banned substances, scientists there will immediately inform the International Olympic Committee and other sport authorities, who will initiate an investigation and possibly disciplinary action. Legitimate drugs are one target for Bartlett, who worked previously in food sciences and toxicology. Pharmaceutical companies such as Roche, Amgen and GlaxoSmithKline now routinely share information about drugs in their pipelines that could potentially be used by athletes. Months after the US Food and Drug Administration approved a new class of red-blood-cell boosters called CERAs in 2007, anti-doping scientists had developed a test for them. The test came too late for the Beijing games the following year, but retrospective testing stripped the men's 1,500-metre winner, Rashid Ramzi, of his gold. Increasingly, dopers are turning to illegal labs in India, China and elsewhere that crank out drugs such as EPO that have been tweaked chemically to evade testing. Bartlett says that his team is ready. The test for EPO, for example, is designed to detect any forms of the protein made using genetic engineering, because these tend to be less acidic than the natural stuff. Athletes participating in the London Olympiad will be the most heavily tested in the history of the games, but will that make them the cleanest? Bartlett is cautiously optimistic. Many countries screen their athletes before departing for London, and some sports have begun to use 'biological passports' that chart characteristics of athletes' blood over time, looking for changes that might signal illicit performance enhancement, even when a substance such as EPO cannot be found. \u201cThe general message is: athletes, if you're coming to London, beware,\u201d Bartlett says. \n               The fluid modeller \n             At the Beijing Olympics in 2008, athletes smashed 25 world records in swimming, more than in any other sport. Many gave the credit to high-tech swimsuits, which cut down on drag. But after Beijing, the international body that governs competitive swimming introduced rules that limited the advantage that could be gained from swimsuits, leaving athletes looking for other ways to gain an edge. British swimmers turned to fluid-dynamics researcher Stephen Turnock. Turnock's speciality is hydrodynamics, particularly in ship design. It wasn't a huge leap to study how air or water flows around the human body, and for the past three years he has directed the Performance Sports Engineering Laboratory (PSEL) at the University of Southampton, UK. The lab previously worked with the British cycling team to devise more aerodynamic riding positions, which may have played at least a small part in the 14 medals that 'Team GB' cyclists brought home from Beijing. Swimming needed similar help, he says. \u201cWhat British swimming lacked was an understanding of what the hydrodynamic forces were during the swimming processes.\u201d Applying a scientific approach to swimming performance has proved a challenge, however. \u201cWith cyclists, you put someone in a wind tunnel and say 'What's your best position to lower your resistance?',\u201d says Turnock. \u201cIt's a complex process to get the instrumentation right but that's a relatively simple bit of fluid dynamics because, typically, most of a position of the cyclist and the body is relatively fixed.\u201d But with swimming, a whole range of factors come into play, including roll along the length of the body, movement of the arms and the legs, forces that are transmitted from limbs to water and the effects of water pressure and movement in turn on the shape of the body. \u201cThere are so many variables and it's all happening quite quickly in a very noisy environment. It is very difficult to repeat exactly the same conditions every test run,\u201d says Turnock. \u201cBy the time you've got all that uncertainty in there it's quite challenging.\u201d The team at the PSEL devised some technical solutions. Its main system is based around a portable winch, which pulls a swimmer through the water fractionally faster than they would normally swim, a technique called overspeeding. Working at pools in which top British swimmers train, Turnock's team measured the tension in the winch line to assess changes in water resistance, and the researchers videoed lap after lap to see how, for example, adjusting posture or even the position of a swimming cap might change water flow and speed. \u201cWe can examine what they've done pretty much as soon as the swimmer gets out of the pool,\u201d says Turnock, who says that the information is all fed back to coaches and athletes. Turnock's team has also been tackling some broader questions about training. Using the winch system, a willing team member and a full-body wax, he explored how body hair affects resistance in the water. (Answer: smoother is faster.) The group is also using computer modelling of the musculoskeletal system to work out how to improve the efficiency of swimming strokes. Turnock's work with Britain's swimmers wrapped up well before the start of the games. But he hopes that what he has learned about the hydrodynamics of human bodies might feed back into his work on marine systems, such as designing rudders that adopt a more hydrodynamic shape under water stresses. He also improved his own swimming and, he says, \u201cI can shout learned things at my children when they learn to swim now.\u201d \n               The disease tracker \n             Kamran Khan will not be anywhere near London during the games. The medical researcher will be sitting thousands of kilometres away at the University of Toronto in Canada. But he will be watching. Organizers have predicted that several million people, from all over the world, will descend on London \u2014 along with their viruses and bacteria. Khan is part of an international team that is testing strategies for predicting the spread of diseases, such as some potential new strain of flu, as the crowds arrive. In all probability, they will see nothing; but it's the 'what if' that keeps Khan awake. Disease outbreaks have been associated with mass gatherings in the past, including a spike in measles around the 2010 winter Olympics in Vancouver, Canada, and an influenza outbreak linked to a Catholic youth festival in Sydney, Australia, in 2008. \u201cWith as big a mass gathering as the Olympic Games we want to think about the potential for health threats, particularly for infectious diseases, to move around the world,\u201d says Brian McCloskey, the UK Health Protection Agency's national lead for the Olympics. To assess those threats, Khan will be using the Bio.Diaspora project, which he has been running since he set it up in 2008. This web-based computer program brings together information on billions of flight itineraries, allowing researchers to see how people are moving around the world. To gauge the risk of those people carrying a pathogen, it will link up with disease surveillance information collected in real time during the games, such as by the HealthMap project at Children's Hospital Boston in Massachusetts, which trawls through news, reports from health-care systems and social-media chatter for signs of emerging infectious threats. If, for example, a new form of flu emerges in China, Khan can piece together a picture of the disease's spread and use it to predict the likelihood of an outbreak reaching London. This type of early warning might give health officials crucial extra time to warn the public and take preventative action. In fact, the Olympics will be a major test of the utility of Bio.Diaspora and global-health systems during a mass gathering, says McCloskey. \u201cIt could be that it doesn't add a lot of value or it could be that it's critically important,\u201d he says. \u201cWe don't know the answer until we've done the experiment.\u201d Khan hopes that the data on the global flow of people can inform the growing field of 'mass-gathering medicine', the study of the public-health risks posed by religious rallies, music festivals and sports events, which are attracting more people than ever before and from more-remote places. He likens global transport to \u201ca network of arteries around the world. There are people moving through those arteries, there's a sort of physiology. And that normal physiology is disrupted or changed by certain types of events,\u201d he says. \u201cThese events have potential implications for global-health security, and we need to understand them better.\u201d Reprints and Permissions"},
{"file_id": "487422a", "url": "https://www.nature.com/articles/487422a", "year": 2012, "authors": [{"name": "Eric Hand"}], "parsed_as_year": "2006_or_before", "body": "Dating features on the Moon and Mars is guesswork. Scott Anderson is building a tool to change that. The bits of rock on Scott Anderson's shelf are not much to look at, but they have stories to tell. In a plastic case is a greenish-grey rock, a 4.5-billion-year-old piece of the asteroid Vesta. Next to it rests a dark sliver of 2.8-billion-year-old lava from the Moon. Anderson, a planetary scientist at the Southwest Research Institute in Boulder, Colorado, picks up his favourite, a 1-gram slice of rock that cost him US$800. The flake came from Zagami, an 18-kilogram meteorite named after the Nigerian village where it was found in 1962. It is one of the rarest and most sought-after types of meteorite \u2014 a piece of Mars that was blasted into space by an asteroid impact and eventually landed on Earth. \u201cKnowing what it is makes me excited to see it every time,\u201d Anderson says. What Anderson wants from these far-flung fragments of the Solar System is elementary: their ages. Coaxing out that information is far more difficult. Zigzagging across his laboratory is a web of laser beams that feed into a mass spectrometer \u2014 all part of a geochronometer that Anderson is building. Like other rock-dating systems, this one computes an age from the radioactive decay of certain isotopes in a sample. What sets Anderson's system apart is his goal to shrink the whole operation down to something that would fit on a desktop. Then, rather than waiting for planetary fragments to fall to Earth, he wants to send his device to the planets. Over the past few decades, planetary scientists have mapped the Solar System in ever more staggering detail. Cameras orbiting the Moon and Mars can zoom in on objects as small as dinner plates, and radars can penetrate several metres below the surface. But when it comes to the fourth dimension \u2014 time \u2014 they are as blind as ever. Scientists have hard dates for only nine places in the Solar System, all on the Moon: six Apollo sites and three Soviet Luna sites, from which samples were returned robotically. When did water flow on Mars? When did the Moon's volcanoes last erupt? Without dates, planetary scientists can only make educated guesses about some of their most pressing questions. A portable,  in situ  chronometer such as Anderson's could revolutionize how researchers study the Moon, Mars or other rocky bodies. The costs of big planetary missions are skyrocketing; the $2.5-billion Mars Science Laboratory that is scheduled to land on 6 August is one of the most expensive Mars missions ever. But Anderson's tool could reduce future costs, in particular by avoiding the need for budget-busting missions to retrieve samples from other planets and haul them back to Earth. And the device could even find a wide audience on Earth, among geologists who could use it to map the ages of rocks in the field, rather than delivering samples to a lab and waiting months for the results. \n               Matter of scale \n             But first, Anderson has to transform the finicky set-up that sprawls across his lab into one that could fly in space. Other groups are trying to develop portable geochronometers, but Anderson's design has some advantages, and he is closer to completing a working prototype. At present, the half-built apparatus sits in the corner of his office: 160 kilograms of gleaming steel and aluminium, roughly the size of a two-drawer filing cabinet. He hopes to finish it later this year, and then he will bolt it into the back of a van and take it on a road trip. \u201cWe've been talking about how we could drive this to NASA headquarters and test this in the parking lot,\u201d says Anderson. At 44 years old, he is tall and boyishly earnest, but savvy enough to understand good public relations. He wants to persuade NASA officials to pay to build an ultra-lightweight geochronometer and then send it on a rover to the Moon or Mars. Eric Hand discusses Scott Anderson\u2019s plans Anderson will have to show not only that his chronometer is fast and light, but also that his dates make sense. Radiometric dates are some of the trickiest, most delicate and most disputed measurements on Earth. Anderson wants to transform what has been a laborious process of chemical extraction and analysis into a laser-based system, automate it and shrink it into a robot small and reliable enough to send to another planet. \u201cWe're extremely sceptical of these things working,\u201d says Lars Borg, a chemist at the Lawrence Livermore National Laboratory in Livermore, California, whose three-person lab usually produces just two dates a year. \u201cWe really struggle to get these ages ourselves.\u201d But this spring, Anderson used the full-sized version of his system to date a 1.7-billion-year-old piece of Boulder Creek granite that he chipped out of the foothills near his lab. Anderson's system computed an age of 2.05 billion years \u00b1 130 million years \u2014 not great in terms of accuracy, but at least a proof of principle 1 . Next up will be Zagami \u2014 a precious rock sample that he does not want to put in the machine until it is ready. Some researchers are now paying attention. \u201cI would not have thought that they could progress this quickly,\u201d says Hap McSween, a planetary scientist at the University of Tennessee in Knoxville. \u201cThey're convincing me that there really is something to this.\u201d \n               Question of time \n             Anderson has wondered about the ages of rocks since he was a boy, when he would often tag along on field trips with his father, a sedimentologist at Temple University in Philadelphia, Pennsylvania. He learned about the principle of superposition \u2014 that younger layers are deposited on top of older ones \u2014 and how fossils can connect layers on different continents to a single epoch in the distant past. But the work was slow. \u201cWe spent hours staring at the same two feet of stone, getting sunburned and the bugs eating at you,\u201d he says. As an undergraduate at Brown University in Providence, Rhode Island, Anderson discovered that he could avoid the insects by doing geology on other planets \u2014 where dates were even harder to come by. Planetary scientists had no fossils to work with, but on the Moon and Mars they had something else: thousands of craters left by large asteroids. In 1965, William Hartmann, a researcher at the Planetary Science Institute in Tucson, Arizona, developed a simple chronometer relying on the idea that surfaces marred by many craters should be older than ones with fewer blemishes. To date a surface, Hartmann used estimates of the rate of impacts over time, which he based on data collected on Earth 2 . This approach improved after the first Apollo rocks had been dated and the crater-count method was calibrated 3 . But even now, it yields dates with significant uncertainties \u2014 between 10% and 40%, Hartmann says. That is mostly because no lunar rock samples have been retrieved from surfaces between 1 billion and 3 billion years old. Scientists are eager to fill in that gap. If chronology on the Moon is still uncertain, then Mars is a mess. The crater-count method does not work as well there, mainly because the wind, water and frost that sculpt the surface also erase craters. Translating the Moon's crater chronometer to Mars is a delicate business, says Barbara Cohen, a planetary scientist at Marshall Space Flight Center in Huntsville, Alabama, who is developing a rival portable chronometer. \u201cOn Mars, and on every other planet, all we're doing is extrapolating, for better or for worse, with a fudge factor.\u201d That 'fudge factor' could be erased with a few choice dates. But those dates could do much more than simply calibrate the crater chronometer. With a portable system, researchers could decipher how long volcanism lasted on Mars and when it stopped. They could find out when the planet's warm, wet and possibly habitable environment gave way to the cold desert it has been for several billion years. \u201cIf any evidence is found for life, we sure as heck will want to know when it was there,\u201d says McSween. These questions are some of the reasons that a generation of scientists have sought a mission to retrieve rock samples from Mars. In 2011, a sample-return mission was ranked the top mission priority for planetary science in the US National Research Council's decadal survey. But NASA's budget-minders baulked at the price tag for the project, which would have required three separate missions and a sample-handling facility \u2014 costing more than $10 billion in total over a decade. Anderson's device would cut out the return trip and do the dating on site. A Mars rover of any size is not cheap, but a medium-sized rover might be possible for about $1 billion. At that price, multiple dating missions could be sent to multiple locations. Doing the science  in situ  also sidesteps the costs of building a quarantined facility on Earth to handle the samples. Defenders of the sample-return approach argue that there are many reasons for such a mission, beyond the mere dating of rocks. Searching for life in the samples would be the top priority, and that would be easier to do in a lab on Earth. But if Anderson and his competitors can demonstrate the viability of their portable geochronometers, support for a more complex and costly sample-return mission could diminish quickly. \u201cI'd rather have five of those ages from five places on Mars than one sample return,\u201d says Hartmann. Even before reaching the red planet, Anderson's device could win fans here on Earth. Geologists typically spend weeks or months out in the field and then haul sacks of rocks back from remote places for extensive analysis. Sometimes much of the effort is for naught \u2014 the samples may be unsuitable for dating, or the researchers may have picked up rocks that were older or younger than the period they wanted to study. A portable geochronometer that could produce a date within hours could solve those problems. At the moment, some technical issues stand in the way. Anderson has spent the summer waiting for the delivery of a $200,000 laser that he needs to complete the device. In the meantime, he's had to jury-rig his lab so that several of his older lasers, cooled by a roomful of refrigerators and water pumps, shine into a vacuum chamber affixed to the brand-new, $700,000 mass spectrometer that will form the bulk of the portable prototype. One of the lasers, nicknamed Jill, is newly rehabilitated after a problem that announced itself with an acrid, burning smell. \u201cOur best guess is something crawled in and committed suicide,\u201d says Keith Nowicki, a laser physicist in the lab. In principle, Anderson's radiometric dating technique is similar to any other. It is based on the radioactive decay of one isotope into daughter isotopes according to a precise clock, a half-life, governed by nuclear physics. Anderson's method relies on rubidium-87, which decays to strontium-87 with a half-life of 48.8 billion years. This method, like any radiometric technique, typically requires monumental efforts. Researchers must first crush the rock and separate its minerals, often by hand. The minerals must then be dissolved in a strong acid, which goes through cation-exchange columns to extract the radioisotopes. These are dried and their abundance measured in a mass spectrometer. The steps can take months to complete. \u201cThe process is a pain in the neck,\u201d says Anderson. \n               Laser power \n             Anderson's method avoids some of these hassles by using tunable lasers to liberate and sort the isotopes all at once. During a visit, Nowicki and Anderson demonstrate the system on a piece of Boulder Creek granite. Even reflected light from the ultraviolet lasers is strong enough to blind, so the researchers first put on thick, $600 protective goggles that dim the room and colour it a sickly ochre. Nowicki turns the lasers onto a wafer-thin slice of rock. Instantly, values for the abundances of rubidium and strontium appear as curves on a computer screen. Anderson is constantly tweaking the protocol for determining a date, but it always involves three basic steps (see 'Speed dating'). First, a blast of laser light vaporizes a smidgeon of the rock sample, creating a cloud of neutral atoms and a pit 70 micrometres around. Next, another, precisely tuned laser fires two shots, nanoseconds apart, to excite only the electrons in the strontium atoms in the cloud. A third shot rips those electrons away, turning the atoms into ions that are then whisked into the mass spectrometer. A microsecond later, three finely tuned shots ionize the rubidium atoms (which are still lingering in the cloud), and these are sucked into the mass spectrometer and measured. The process is repeated 20 times a second \u2014 and 3,000 times in the same place \u2014 and then the laser is pointed at a new spot on the sample's face. To date an entire sample, Anderson usually measures several hundred spots, which takes about a day and a half. Other researchers, such as Cohen and John Eiler, a geochemist at the California Institute of Technology in Pasadena, are trying to develop  in situ  geochronometers that use potassium\u2013argon dating, in which potassium-40 decays to argon-40 with a half-life of 1.3 billion years. Argon, a noble gas, tends to remain trapped in the crystal matrix of minerals. Potassium and argon are more abundant in common minerals than rubidium and strontium, which makes them easier to measure. But the potassium\u2013argon system does not work as well for rocks that have been disturbed by high pressures and temperatures, which can cause argon to leak out and make the rocks seem younger than they are. And samples from Mars could have the opposite problem: argon-40 in the planet's atmosphere and mantle might have seeped into rocks, artificially inflating their ages. Because each system has unique advantages and disadvantages, it may be best to put a couple of portable geochronometers on a rover, so that the results can be checked against each other. So Anderson has been busy forging alliances with Cohen and other former competitors to develop a viable mission proposal for a chronometer-laden rover. They just might have a shot. In February, under intense budget pressure, NASA threw out its $10-billion, long-term Mars plan that would have begun a sample-return mission at the end of the decade. The new plan leaves only about $800 million for a Mars mission in 2018 or 2020, just enough for an orbiter, lander or, perhaps, an inexpensive rover. \n               Major-league pitch \n             One day in June, Anderson flies to Houston, Texas, where NASA officials are holding a conference to solicit ideas for the new mission. Dozens of concept studies are vying for the attention of officials: robots that climb rocks, rovers that hop and autonomous skiffs that would explore Mars as they are whisked along by the wind. Anderson gets ten minutes to present his team's concept. His chronometer would be mounted on an enhanced version of the Mars Exploration Rovers \u2014 Spirit and Opportunity \u2014 that landed in 2004. The new rover would have a life-detection experiment on board and might have room for a small sample cache, to preserve the chance of a future sample-return mission. Cohen's potassium\u2013argon system would also squeeze aboard. By the time Anderson gets round to explaining his part \u2014 the rubidium\u2013strontium geochronometer \u2014 he has three minutes to talk about the thing he has been working on for eight years. He tells the audience that his rover would do important science and lay the groundwork for a sample return, without an absurdly high price tag. \u201cMore science, less commitment,\u201d he says. Later, Anderson says that he has no idea how his concept was received by the NASA officials. \u201cThey're holding their cards pretty close to the vest.\u201d He knows that winning the flight opportunity is a long shot, so he is thinking about fallbacks. In 2015, NASA expects to solicit proposals for low-cost planetary missions, and Anderson plans to pitch sending a geochronometer to the Moon. But the bigger target is never far from his thoughts. Anderson recently bought a 28-centimetre telescope \u2014 pretty big for an amateur \u2014 and installed it in his backyard in Boulder, which sits at 2,200 metres and has a clean view of the sky through the thin Rocky Mountain air. He has spent many an evening staring at the red planet \u2014 and imagining his timepiece at work on its surface. \u201cI want to get it to Mars,\u201d he says. \u201cI want to see it there.\u201d \n                     Solar System: Focus on ancient bombardment 2012-Apr-25 \n                   \n                     Planetary science: Building a planet in record time 2011-May-25 \n                   \n                     Planetary science: The hole at the bottom of the Moon 2008-Jun-25 \n                   \n                     Concepts for Mars Exploration \n                   \n                     KISS workshop \n                   Reprints and Permissions"},
{"file_id": "488024a", "url": "https://www.nature.com/articles/488024a", "year": 2012, "authors": [{"name": "Laura Spinney"}], "parsed_as_year": "2006_or_before", "body": "Advocates of 'cliodynamics' say that they can use scientific methods to illuminate the past. But historians are not so sure. Sometimes, history really does seem to repeat itself. After the US Civil War, for example, a wave of urban violence fuelled by ethnic and class resentment swept across the country, peaking in about 1870. Internal strife spiked again in around 1920, when race riots, workers' strikes and a surge of anti-Communist feeling led many people to think that revolution was imminent. And in around 1970, unrest crested once more, with violent student demonstrations, political assassinations, riots and terrorism (see 'Cycles of violence'). To Peter Turchin, who studies population dynamics at the University of Connecticut in Storrs, the appearance of three peaks of political instability at roughly 50-year intervals is not a coincidence. For the past 15 years, Turchin has been taking the mathematical techniques that once allowed him to track predator\u2013prey cycles in forest ecosystems, and applying them to human history. He has analysed historical records on economic activity, demographic trends and outbursts of violence in the United States, and has come to the conclusion that a new wave of internal strife is already on its way 1 . The peak should occur in about 2020, he says, and will probably be at least as high as the one in around 1970. \u201cI hope it won't be as bad as 1870,\u201d he adds. Turchin's approach \u2014 which he calls cliodynamics after Clio, the ancient Greek muse of history \u2014 is part of a groundswell of efforts to apply scientific methods to history by identifying and modelling the broad social forces that Turchin and his colleagues say shape all human societies. It is an attempt to show that \u201chistory is not 'just one damn thing after another'\u201d, says Turchin, paraphrasing a saying often attributed to the late British historian Arnold Toynbee. Cliodynamics is viewed with deep scepticism by most academic historians, who tend to see history as a complex stew of chance, individual foibles and one-of-a-kind situations that no broad-brush 'science of history' will ever capture. \u201cAfter a century of grand theory, from Marxism and social Darwinism to structuralism and postmodernism, most historians have abandoned the belief in general laws,\u201d said Robert Darnton, a cultural historian at Harvard University in Cambridge, Massachusetts, in a column written in 1999. Most think that phenomena such as political instability should be understood by constructing detailed narratives of what actually happened \u2014 always looking for patterns and regularities, but never forgetting that each outbreak emerged from a particular time and place. \u201cWe're doing what can be done, as opposed to aspiring after what can't,\u201d says Daniel Szechi, who studies early-modern history at the University of Manchester, UK. \u201cWe're just too ignorant\u201d to identify meaningful cycles, he adds. But Turchin and his allies contend that the time is ripe to revisit general laws, thanks to tools such as nonlinear mathematics, simulations that can model the interactions of thousands or millions of individuals at once, and informatics technologies for gathering and analysing huge databases of historical information. And for some academics, at least, cliodynamics can't come a moment too soon. \u201cHistorians need to abandon the habit of thinking that it's enough to informally point to a sample of cases and to claim that observations generalize,\u201d says Joseph Bulbulia, who studies the evolution of religion at Victoria University of Wellington in New Zealand. \n               From ecology to history \n             Turchin conceived cliodynamics during what he jokingly calls a midlife crisis: it was 1997, he was 40 years old, and he had come to feel that all the major ecological questions about population dynamics had been answered. History seemed to be the next frontier \u2014 perhaps because his father, the Russian computer scientist Valentin Turchin, had also wondered about the existence of general laws governing societies. (The elder Turchin's dissident writings about the origins of totalitarianism were among the reasons that the Soviet Union exiled him in 1977, after which he moved his family to the United States.) What is new about cliodynamics isn't the search for patterns, Turchin explains. Historians have done valuable work correlating phenomena such as political instability with political, economic and demographic variables. What is different is the scale \u2014 Turchin and his colleagues are systematically collecting historical data that span centuries or even millennia \u2014 and the mathematical analysis of how the variables interact. In their analysis of long-term social trends, advocates of cliodynamics focus on four main variables: population numbers, social structure, state strength and political instability. Each variable is measured in several ways. Social structure, for example, relies on factors such as health inequality \u2014 measured using proxies including quantitative data on life expectancies \u2014 and wealth inequality, measured by the ratio of the largest fortune to the median wage. Choosing appropriate proxies can be a challenge, because relevant data are often hard to find. No proxy is perfect, the researchers concede. But they try to minimize the problem by choosing at least two proxies for each variable. Then, drawing on all the sources they can find \u2014 historical databases, newspaper archives, ethnographic studies \u2014 Turchin and his colleagues plot these proxies over time and look for trends, hoping to identify historical patterns and markers of future events. For example, it seems that indicators of corruption increase and political cooperation unravels when a period of instability or violence is imminent. Such analysis also allows the researchers to track the order in which the changes occur, so that they can tease out useful correlations that might lead to cause\u2013effect explanations. \n               Endless cycles \n             When Turchin refined the concept of cliodynamics with two colleagues \u2014 Sergey Nefedov of the Institute of History and Archaeology in Yekaterinburg, Russia, and Andrey Korotayev of the Russian State University for the Humanities in Moscow \u2014 the researchers found that two trends dominate the data on political instability. The first, which they call the secular cycle, extends over two to three centuries. It starts with a relatively egalitarian society, in which supply and demand for labour roughly balance out. In time, the population grows, labour supply outstrips demand, elites form and the living standards of the poorest fall. At a certain point, the society becomes top-heavy with elites, who start fighting for power. Political instability ensues and leads to collapse, and the cycle begins again. Superimposed on that secular trend, the researchers observe a shorter cycle that spans 50 years \u2014 roughly two generations. Turchin calls this the fathers-and-sons cycle: the father responds violently to a perceived social injustice; the son lives with the miserable legacy of the resulting conflict and abstains; the third generation begins again. Turchin likens this cycle to a forest fire that ignites and burns out, until a sufficient amount of underbrush accumulates and the cycle recommences. These two interacting cycles, he says, fit patterns of instability across Europe and Asia from the fifth century  BC  onwards. Together, they describe the bumpy transition of the Roman Republic to the Roman Empire in the first century  BC . He sees the same patterns in ancient Egypt, China and Russia, and says that they explain the timing of last year's Egyptian uprising, which took the regime of then-president Hosni Mubarak by surprise. At the time, the Egyptian economy was growing and poverty levels were among the lowest in the developing world, so the regime could reasonably have expected stability. In the decade leading up to the revolution, however, the country saw a quadrupling of graduates with no prospects \u2014 a marker of elite overproduction and hence, Turchin argues, trouble. Turchin has also applied this approach to other historical puzzles, such as how religions grow. Several models have been proposed. One is that they grow in a linear fashion as nonbelievers spontaneously 'see the light'. Another model holds that the number of converts increases exponentially, like infections with a contagious disease, as outsiders come into contact with growing numbers of converts. Using several independent proxies, Turchin has mapped conversions to Islam in medieval Iran and Spain, and found that the data fit the contagion model most closely 2 . Using the same techniques, he has also shown that the model describes the expansion of Christianity in the first century  AD , and of Mormonism since the Second World War. Claudio Cioffi-Revilla, a computer social scientist at George Mason University in Fairfax, Virginia, welcomes cliodynamics as a natural complement to his own field: doing simulations using 'agent-based' computer models. Cioffi-Revilla and his team are developing one such model to capture the effects of modern-day climate change on the Rift Valley region in East Africa, a populous area that is in the grip of a drought. The model starts with a series of digital agents representing households and allows them to interact, following rules such as seasonal migration patterns and ethnic alliances. The researchers have already seen labour specialization and vulnerability to drought emerge spontaneously, and they hope eventually to be able to predict flows of refugees and identify potential conflict hotspots. Cioffi-Revilla says that cliodynamics could strengthen the model by providing the agents with rules extracted from historical data. \n               Global trends \n             Cliodynamics has another ally in Jack Goldstone, director of the Center for Global Policy at George Mason University and a member of the Political Instability Task Force, which is funded by the US Central Intelligence Agency to forecast events outside the United States. Goldstone has searched for cliodynamic patterns in past revolutions, and predicts that Egypt will face a few more years of struggle between radicals and moderates and 5\u201310 years of institution-building before it can regain stability. \u201cIt is possible but rare for revolutions to resolve rapidly,\u201d he says. \u201cAverage time to build a new state is around a dozen years, and many take longer.\u201d But Goldstone cautions that cliodynamics is useful only for looking at broad trends. \u201cFor some aspects of history, a scientific or cliodynamic approach is suitable, natural and fruitful,\u201d he says. For example, \u201cwhen we map the frequency versus magnitude of an event \u2014 deaths in various battles in a war, casualties in natural disasters, years to rebuild a state \u2014 we find that there is a consistent pattern of higher frequencies at low magnitudes, and lower frequencies at high magnitudes, that follows a precise mathematical formula.\u201d But when it comes to predicting unique events such as the Industrial Revolution, or the biography of a specific individual such as Benjamin Franklin, he says, the conventional historian's approach of assembling a narrative based on evidence is still best. Herbert Gintis, a retired economist who is still actively researching the evolution of social complexity at the University of Massachusetts Amherst, also doubts that cliodynamics can predict specific historical events. But he thinks that the patterns and causal connections that it reveals can teach policy-makers valuable lessons about pitfalls to avoid, and actions that might forestall trouble. He offers the analogy of aviation: \u201cYou certainly can't predict when a plane is going to crash, but engineers recover the black box. They study it carefully, they find out why the plane crashed, and that's why so many fewer planes crash today than used to.\u201d None of these arguments, however, has done much to soften scepticism among historians in general. The essential weakness of any attempt to make predictions based on trends, says Szechi, is the appalling patchiness of historical information. Records can be preserved or destroyed by chance: in 1922, for example, fighting in the Four Courts area of Dublin during the Irish Civil War led to a fire that destroyed the country's entire medieval archive. More generally, says Szechi, knowledge tends to pool around narrow subject areas. \u201cWe can tell you in great detail what the grain prices were in a few towns in southern England in the Middle Ages,\u201d he says. \u201cBut we can't tell you how most ordinary people lived their lives.\u201d Concerted efforts are now under way to fill those holes. Harvey Whitehouse, an anthropologist at the University of Oxford, UK, is overseeing the construction of a database of information about rituals, social structure and conflict around the globe since records began. It is a huge undertaking, involving historians, archaeologists, religious scholars, social scientists and even neuroscientists, and it will take decades to complete \u2014 assuming that funding can be found beyond the UK government's current 5-year commitment. But Whitehouse believes that the research that is feeding the database will complement Turchin's approach by throwing light on the immediate triggers of political violence. He argues 3 , for example, that for such violence to happen, individuals must begin to identify strongly with a political group. One powerful way for groups to cement that identification is through rituals, especially frightening, painful or otherwise emotional ones that create a body of vivid, shared memories. \u201cPeople form the impression that the most profound insights they have into their own personal history are shared by other people,\u201d says Whitehouse, who explored this fusion of identities in an as-yet unpublished survey of revolutionary brigades in Misrata, Libya, last December, along with his colleague Brian McQuinn, an anthropologist at Oxford who studies civil wars. Only once such fusion has occurred do people become willing to fight and die for the group, he says. Therefore, if Turchin's prediction of unrest in the United States around 2020 is correct, Whitehouse would expect the next few years to see an increase in tightly knit US groups whose rituals have a threatening quality but promise great rewards. Turchin can't say who those groups might be, what cause they will be fighting for or what form the violence will take. Previous bouts of turbulence were not dominated by any one issue, he says. But he already sees the warning signs of social strife, including a surplus of graduates and increasing inequality. \u201cInequality is almost always a bad thing for societies,\u201d he says. That said, Turchin insists that the violence is no more inevitable than an outbreak of measles. Just as an epidemic can be averted by an effective vaccine, violence can be prevented if society is prepared to learn from history \u2014 if the US government creates more jobs for graduates, say, or acts decisively to reduce inequality. But perhaps revolution is the best, if not the only, remedy for severe social stresses. Gintis points out that he is old enough to have taken part in the most recent period of turbulence in the United States, which helped to secure civil rights for women and black people. Elites have been known to give power back to the majority, he says, but only under duress, to help restore order after a period of turmoil. \u201cI'm not afraid of uprisings,\u201d he says. \u201cThat's why we are where we are.\u201d \n                     Political instability may be a contributor in the coming decade 2010-Feb-03 \n                   \n                     Arise 'cliodynamics' 2008-Jul-02 \n                   \n                     Building nations after conflict 2008-Jun-18 \n                   \n                     Peter Turchin \n                   \n                     Cliodynamics: The Journal of Theoretical and Mathematical History \n                   \n                     Claudio Cioffi-Revilla \n                   \n                     Political Instability Task Force \n                   Reprints and Permissions"},
{"file_id": "488020a", "url": "https://www.nature.com/articles/488020a", "year": 2012, "authors": [{"name": "Ananyo Bhattacharya"}], "parsed_as_year": "2006_or_before", "body": "Physicists, chemists and mathematicians in the United Kingdom are furious about funding reforms that they say threaten blue-skies research. The horse-drawn Victorian hearse canters past London's Houses of Parliament and round Parliament Square before trotting smartly down Whitehall. Straggling behind it comes an eclectic mix of scientists, ranging from students with body piercings to tweed-jacketed professors. The spectacle makes an odd addition to the spring afternoon traffic, bringing to mind an elegant, if unusual, state funeral. The truth, however, is much stranger. \u201cWe're protesting,\u201d explains one PhD student to a puzzled tourist, \u201cagainst our research funder.\u201d That funder is the Engineering and Physical Sciences Research Council (EPSRC), the government body that holds the biggest public purse for physics, mathematics and engineering research in the United Kingdom. Facing a growing cash squeeze and pressure from the government to demonstrate the economic benefits of research, in 2009 the council's chief executive, David Delpy, embarked on a series of controversial reforms. Some were intended to cut the overwhelming number of grant proposals that the EPSRC receives, by limiting resubmissions and temporarily blocking people who submitted too many unsuccessful applications from sending in more. A second set of reforms included requirements that grant applicants explain how their research might generate economic or other benefits, as well as a vigorous overhaul of the EPSRC's research portfolio. The changes incensed many physical scientists, who protested that the policy to blacklist grant applicants was draconian. They complained that the EPSRC's decision to exert more control over the fields it funds risked sidelining peer review and would favour short-term, applied research over curiosity-driven, blue-skies work in a way that would be detrimental to British science. The souring relationship between the EPSRC and parts of its constituency reached a conspicuously public nadir in May, when disaffected researchers launched the 'Science for the Future' campaign with the hearse stunt, which ended by delivering the coffin, signifying the death of British science, and a petition demanding the \u201cimmediate reform of the EPSRC's policies\u201d to the prime minister in Downing Street. In a letter to  The Daily Telegraph  newspaper in support of the protestors, nine Nobel laureates in the United Kingdom and United States accused the EPSRC of \u201cmanipulating the process of peer review\u201d and \u201cestablishing favouritism schemes\u201d. The battle could be played out elsewhere. Many government funding bodies are facing diminishing budgets in the wake of the global financial crisis, and increasing pressure from politicians to show that the research they are funding will contribute to economic growth. \u201cThis is a challenge for research funding agencies across the globe,\u201d says Julia Lane, an expert in science policy who formerly worked at the National Science Foundation (NSF) in Arlington, Virginia, and is now a senior managing economist at the American Institutes for Research in Washington DC. \u201cAnd they're all struggling to provide enough information for policy-makers so that they can keep funding going for basic research.\u201d In Britain, it looks likely that researchers will have to live with this new reality: Delpy and his supporters say that the policies are an unavoidable reaction to a slumping budget and that there will be no U-turns. According to Delpy's detractors, however, the EPSRC provides a lesson in how not to implement such reforms. \u201cThey shot themselves in the foot by alienating the community that they're here to serve,\u201d says Paul Clarke, a synthetic organic chemist at the University of York, and one of the EPSRC's most vociferous critics. \n               Opening round \n             The tensions started rising in 2007, shortly after Delpy, a physicist by training, left his post managing the research portfolio at University College London to take command of the EPSRC and its research budget of some \u00a3800 million (US$1.3 billion). Delpy faced a problem: an overwhelming number of grant applications and a flat budget were starting to push up rejections. In 2008, the success rate for applications dropped from a typical 30% to 26% overall and even lower in some fields (see 'Physics of funding'). In March 2009, the EPSRC announced that from the following month researchers could no longer resubmit grant proposals that had been rejected, a policy that has since been implemented at several other UK research councils. At around the same time, it also barred researchers with a record of rejections from sending in any further funding applications for 12 months \u2014 a policy that initially hit more than 200 people. The changes outraged physical scientists. Within 2 weeks of the blacklisting policy being announced, more than 1,200 people had signed an online petition demanding that it be rescinded (see   Nature   458 , 391; 2009). In May 2009, the EPSRC was forced to water down the policy by delaying its introduction to April 2010, and allowing researchers to apply for one grant during the 12-month 'cooling-off' period. The EPSRC says that only ten researchers are currently blacklisted. Clarke is one of those ten. Six years ago he concurrently held three EPSRC grants \u2014 more than any other researcher at the same career stage. But in January, after submitting a third unsuccessful proposal, he was told that he had been automatically barred from sending in more. Clarke, who works on the chemical origins of life and on synthesizing natural compounds, says that before the EPSRC banned resubmissions, he was able to address critiques of rejected proposals and send them back for re-review \u2014 after which they would often be successful. Rather than being a problem, he views the large number of proposals as a sign of scientists with many good ideas, and advocates widening the pool of reviewers by mandating that those who submit EPSRC grants also review a certain number of proposals each year. The EPSRC was also under growing pressure to demonstrate the impact of its investment in research. This grew out of the 2006 Warry report,  Increasing the Economic Impact of Research Councils , as well as subsequent reports, demanding that all the UK research councils show that they are getting the most bang for their buck. In 2009, the research councils started to require that funding applicants submit a two-page Pathways to Impact statement, summarizing how they intended to maximize the societal or economic benefits of a project \u2014 through commercialization of results, for example, or through public outreach. In November 2011, the EPSRC added a 'national importance' criterion, requiring that researchers describe in a separate statement \u201cthe extent to which the research proposed has the potential, over 10\u201350 years, to meet national strategic needs\u201d. Similar requirements are already routine at some other funding agencies, such as the NSF, which has asked applicants to explain their proposed project's 'broader impacts' on science and society since 1997. That requirement has come in for some criticism (see   Nature   475 , 141; 2011) \u2014 but not the level of anger that the new request seemed to inspire in Britain's physical scientists. The impact statements, they said, showed that the EPSRC is inappropriately favouring short-term projects that will have economic benefits. \u201cIt is changing the fundamental ethos of research to make it more responsive to the market,\u201d says physicist Philip Moriarty of the University of Nottingham, an outspoken critic of the EPSRC reforms. And the national-importance criterion, say some, is simply asking for the impossible. \u201cIt's very hard to justify the economic importance of work that might not become applicable to real-world problems for decades,\u201d says postdoctoral mathematician Will Merry at the University of Cambridge, UK. (Merry's research problem, how to solve the motions of three or more interacting bodies, was first set out by Isaac Newton in 1687 \u2014 suggesting that science sometimes has to take the long road.) Martin Rees, former president of the Royal Society in London and a cosmologist at the University of Cambridge, says he worries that the new requirements could affect how young researchers apply for their first grant. \u201cIt's going to make them slant their application in a way that might not be optimal from the point of view of the research,\u201d he says. The council should focus on making sure that the \u201cbrightest people don't get discouraged\u201d, adds Rees, who says he finds the idea of asking researchers to write about the potential future national importance of their work \u201cabsurd\u201d. But the EPSRC had more reforms up its sleeve. In July 2011, it published the first of three phases in its Shaping Capability strategy, which divided the organization's research portfolio into more than 100 fields, with the aim of maintaining or expanding areas of national importance and excellence, such as catalysis and energy storage, and shrinking others such as mathematical physics and mobile computing. The council revealed that future postdocs and other fellowships would be funded only in areas that were in line with the strategy; at the outset, for example, mathematics postdocs would be funded only in statistics and applied probability. To the critics, that decision was further evidence that the council ranked short-term pay-off above blue-skies research, in this case favouring the needs of the City, London's large financial sector, which is hungry for statistical expertise. The policy had an immediate impact for Merry, who finished a 12-month EPSRC doctoral-prize fellowship and struggled to find a postdoc at home. He is now set to start one at ETH Zurich in September. Merry says that all the maths PhD students he knows at the University of Cambridge are following a similar path. \u201cThe most visible outcome of the change in funding is that to the best of my knowledge they're all going abroad next year,\u201d he says. Some researchers also have a broader concern: that EPSRC administrators are taking over the role of working scientists in deciding how money should be spent and, as a consequence, are funding mediocre research in arbitrarily selected areas. Instead, they say, the EPSRC should focus on supporting the best-quality science in any area of its remit, as judged by peer review. \u201cNon-scientists are making decisions that impact on the future spend of science money \u2014 and that is wrong,\u201d says Tony Barrett, a synthetic organic chemist at Imperial College London and one of the organizers of the Science for the Future campaign. \u201cThey are not qualified to make those decisions.\u201d The uproar over impact and national importance grew so loud that, in November 2011, the House of Lords Science and Technology Committee held a session to discuss the policies with Delpy and civil engineer John Armitt, then the council's chair. The EPSRC also agreed to further discussions with the scientific community before rolling out the final phase of the Shaping Capability strategy, which it did in March 2012. The announcement, which filled in funding details for just over 50 fields, met a frosty, but somewhat less angry, reception. \n               Making impact \n             Delpy stoutly defends his organization and its reforms. The policies to cut grant applications have worked, he says: the success rates for applications are back up to around 30\u201335% \u2014 \u201ca healthy level of competition\u201d. He rejects the criticisms of the impact and national-importance strategies. The focus on economic impacts is nothing new, he says, nor does it come from his own experience in applied bioengineering. (He developed techniques for monitoring premature babies.) The 1994 royal charter that officially established the EPSRC states that contributing to the country's economic competitiveness is one of the body's three main aims. The prominence placed on it in recent years is largely the result of government pressure, Delpy says. \u201cYou must realize that the term 'economic impact' was something that was imposed on us by the Treasury.\u201d What's more, the EPSRC does not expect a precise forecast of what impacts a research proposal could have decades down the line, he says; rather, researchers are encouraged to describe how any impacts that they can foresee might be speedily achieved. Delpy maintains that peer review is paramount at the agency. The decision to limit the EPSRC's maths postdocs to statistics was based on an independent international review of maths commissioned by the council and published in 2010, which singled out the field as an area of serious concern. \u201cWe decided we had to do something to get new blood into statistics,\u201d he says. \u201cThis is not a response to government or the call of the City.\u201d Mathematicians can turn to the Royal Society or the Leverhulme Trust in London for funding, he points out. And although the research council's budget is set to decline \u2014 by 6% in cash terms between 2010\u201311 and 2014\u201315 \u2014 he says that the proportion of funding going to discovery-led or blue-skies research has stayed roughly flat at around 50\u201360% of the total. \u201cWhere's the evidence the system is broken?\u201d he asks. Delpy does regret the rift that the reforms have opened up between the council and researchers. \u201cOf course we could have done things better,\u201d he concedes, particularly in communicating what the council was doing and why. \u201cI would have liked to have been able to carry the community with me and have everyone feel that they were engaged.\u201d At the same time, he says, \u201cif you change any of the ways of working you are going to create some degree of upset\u201d. Britt Holbrook, a philosopher at the University of North Texas in Denton, who specializes in science policy, says that the EPSRC's biggest mistake lay in banning resubmissions and blacklisting researchers. \u201cIt's totally understandable that did not go down well,\u201d he says. \u201cIf you stop people from resubmitting, that cuts out a large part of the value of peer review.\u201d But Holbrook, who co-authored an influential review of the NSF's broader-impacts criterion, says that the critics are fighting a losing battle against the impact agenda. \u201cPeople are working against the political and economic realities,\u201d he warns, and would be better off trying to shape the drive for impact, rather than block it. The hearse parked outside Downing Street, however, suggests that this advice is falling on deaf ears; the organizers of Science for the Future say that they are planning further protests over the summer. And Delpy's critics have little time for his explanations, saying, for example, that they are sceptical of EPSRC figures showing no decline in blue-skies research, given that the council defines the term itself. Clarke prefers to point to figures showing that in 2010\u201311, the EPSRC funded 151 proposals in the physical sciences, excluding engineering, down from more than 500 in 2004\u201305. Yet there are more than 3,000 scientists in the United Kingdom who are eligible to apply for EPSRC funding. \u201cPeople would rather not submit than submit, get blacklisted and hence be seen as a failing academic by their department,\u201d says Clarke. \u201cThere is now a culture of fear in academic departments.\u201d \n                     Budget cuts bite for UK physical sciences 2011-Jul-20 \n                   \n                     The dubious benefits of broader impact 2011-Jul-13 \n                   \n                     UK science faces facilities freeze 2010-Dec-20 \n                   \n                     Fixing a grant system in crisis 2010-Mar-24 \n                   \n                     UK scientists get funding ban reprieve 2009-May-05 \n                   \n                     UK researchers lament grant ban 2009-Mar-19 \n                   \n                     Blogpost: Protesting scientists deliver coffin to Downing Street \n                   \n                     EPSRC \n                   \n                     Science for the Future \n                   Reprints and Permissions"},
{"file_id": "488148a", "url": "https://www.nature.com/articles/488148a", "year": 2012, "authors": [{"name": "Amy Maxmen"}], "parsed_as_year": "2006_or_before", "body": "Jay Bradner believes that cancer can be defeated through control of epigenetics \u2014 and he is not shy about spreading the word. Jay Bradner has a knack for getting the word out online. You can follow him on Twitter; you can become one of more than 400,000 online viewers of the TEDx talk he gave in Boston, Massachusetts, last year; you can see the three-dimensional structure of a cancer-drug prototype created in his laboratory and you can e-mail him to request a sample of the compound. Bradner, a physician and chemical biologist at the Dana-Farber Cancer Institute in Boston, makes defeating cancer sound easy \u2014 one just has to play tricks on its memory. \u201cWith all the things cancer is trying to do to kill our patient, how does it remember it is cancer?\u201d he asked his rapt TEDx audience. Bradner says that the answer lies in epigenetics, the programmes that manage the genome. DNA serves as the basic blueprint for all cellular activity, and DNA mutations have long been known to have a role in cancer. But much of a cell's identity is determined by modifications to chromatin, which comprises DNA and the proteins that bind and package it. Epigenetic instructions, in the form of chemical marks that cling to chromatin, tell cells how to interpret the underlying genetic sequence, defining a cell's identity as, say, blood or muscle. Findings over the past ten years have strongly implicated dysregulation of epigenetic instructions in cancer, where growth-driving genes express like crazy and genes that keep cell division in check are silenced. Bradner's aim is to create a drug that can rewrite those instructions so that cancer cells forget what they are and cease their deadly proliferation. Bradner thinks that this epigenetic approach could strike down one of cancer's most treacherous drivers, the DNA-binding protein Myc. Myc is involved in up to 70% of cancers but is generally considered 'undruggable', because the active parts of its structure are not accessible to the kinds of small-molecule drugs that chemists generally create. \u201cMyc is one of those things that people dream of targeting,\u201d says Dash Dhanak, head of cancer epigenetics at GlaxoSmithKline (GSK) in Collegeville, Pennsylvania. Just as audacious is Bradner's commitment to making his reagents available and his ideas accessible to scientists and laypeople alike, a rare attitude in the highly competitive world of drug discovery. Researchers in Bradner's lab have developed a compound that interferes with Myc by manipulating epigenetic instructions, and he has sent it out to hundreds of collaborators worldwide. \u201cThat's not common in practice,\u201d says Bradner, \u201cbut from first principles, it's the right thing to do.\u201d Detractors may scoff at Bradner's flashy approach, but those who have followed his career say that there is substance to go with the style. \u201cJay has figured out translational science,\u201d says Stuart Schreiber, director of chemical biology at the Broad Institute in Cambridge, Massachusetts, and Bradner's former postdoctoral adviser. \u201cHe's really just good at making important discoveries while staying connected to their clinical potential.\u201d In 1992, while Bradner was an undergraduate at Harvard University, also in Cambridge, he took a chemistry class taught by Schreiber on small-molecule discovery. By the time he graduated, Bradner knew that he wanted to apply the methods he had learned to cancer-drug development. He headed west to Illinois, to study the disease at the Pritzker School of Medicine at the University of Chicago. \n               Marked for death \n             In 1999, Bradner returned to Massachusetts for a clinical residency at Brigham and Women's Hospital in Boston, and in 2004 he joined Schreiber's lab as a postdoctoral researcher. Schreiber's team was researching chemical compounds that override normal epigenetic control of gene expression by modulating chromatin. Such control systems generally involve three types of protein: 'writers', 'readers' and 'erasers' (see 'Rewriting memory'). Writers attach chemical marks, such as methyl groups (to DNA) or acetyl groups (to the histone proteins that DNA wraps around); readers bind to these marks and influence gene expression; erasers remove the marks. The marks serve as instructions that are passed down as cells divide, providing a sort of cellular memory to ensure that skin cells, for example, beget other skin cells. Epigenetics has become one of the hottest areas of biological research. Schreiber and his group had long been looking at histone deacetylases (HDACs), eraser proteins that remove acetyl groups from histones. Some chromatin regions in cancer cells contain fewer acetyl groups than those in normal cells, and drugs called HDAC inhibitors increase acetylation. Since 2006, two such drugs \u2014 vorinostat and romidepsin \u2014 have been approved by the US Food and Drug Administration to treat cutaneous T-cell lymphoma, a rare immune-cell cancer that affects the skin. The drugs generated excitement among cancer researchers, but because they block many types of HDAC \u2014 in both healthy and cancerous cells \u2014 they can be toxic. Several trials for other cancers turned up disappointing results. Bradner experienced the let-down of the HDAC inhibitors first-hand in 2008, soon after starting his own lab. Chris French, a pathologist at Brigham and Women's Hospital, consulted with Bradner about a ten-year-old boy he was treating for a rare and aggressive cancer called NUT midline carcinoma (NMC), which typically kills patients within a year of diagnosis. French, an expert on NMC, diagnosed the disease after cardiac surgeons had opened the boy's chest and found a tumour the size of a baseball in his heart. Chemotherapy was not an option, as it would have hampered his recovery from surgery. Bradner and French discussed other treatments. French had shown in 2003 that NMC is caused by a fusion of two genes 1 :  BRD4 , which encodes a reader protein, and a previously unknown gene called  NUT . This fusion encodes a mutant protein, NUT\u2013BRD4, which seems to act as a reader, spurring errant gene expression and forcing cells to lose their identity and become cancerous. No inhibitors of reader proteins were available then, but French and Bradner knew that vorinostat increased histone acetylation. Perhaps, they thought, if acetylation were increased, NUT\u2013BRD4 would be so busy 'reading' elsewhere that it would overlook the region that was causing cells to become cancerous. Bradner calls the concept \u201cthe chemical equivalent of a smokescreen\u201d. It was thin reasoning, but Bradner and French agreed that the emergency at hand warranted an experiment. They tried the drug on cancer cells extracted from the boy, and the cells seemed to forget their cancerous marching orders, reverting from round, proliferating cells into flat, skin-like cells. This gave them the confidence to try treating the boy. The tumour seemed to respond after five weeks, but the toxicity proved too high. \u201cIt was taking him four hours to swallow three pills because he kept vomiting them back up,\u201d French says. The boy stopped the treatment and died not long afterwards. Bradner dwelled on the case, especially on BRD4, a little-studied protein that now seemed to be capable of causing cancer. Disparate lines of study suggested that BRD4 might be linked to the expression of Myc, a target most drug developers had abandoned. If Bradner could defuse BRD4, perhaps he could bring down one of cancer's most notorious dragons. In 2009, Bradner happened upon a patent from Mitsubishi Tanabe Pharma in Osaka, Japan, for a diazepine-based compound that inhibited BRD4 by blocking its bromodomain, the region that recognizes acetyl groups on histones. Diazepines on the market, such as the anxiety medication alprazolam (Xanax), have only weak interactions with the bromodomain. \u201cYou'd be in a coma by the time you inhibited BRD4,\u201d Bradner says. So he began searching for molecules that were similar in structure but more potent. Jun Qi, a researcher in Bradner's lab, synthesized more than 400 diazepines in search of a candidate. By the end of 2009, they had one. Named JQ1 after Qi, the compound slips into a groove of BRD4, preventing it from binding to acetylated histones and activating genes. With JQ1, the researchers hoped to tease apart which genes BRD4 switches on \u2014 and whether any of them cause cancer. \n               Research promise \n             In March 2010, French introduced Bradner to another patient with NMC, a 29-year-old firefighter from Connecticut. Chemotherapy and romidepsin treatment had failed. Bradner asked the man if he could use his cells for research, pledging that the work would help to find cures. The man agreed. He died that July, but his cells made it possible to test JQ1. The compound stopped the cancer cells from dividing and transformed them into non-cancerous cells, both in culture and in mice 2 . It takes years for promising molecules to lead to clinically useful drugs. Had drug-company researchers discovered JQ1, a single team would have forged ahead, probably in secret, to develop the compound. But Bradner decided that the quickest path to the clinic was to do the research openly, with as many collaborators as possible. Since January 2011, Bradner's team has shipped JQ1 to more than 250 labs worldwide. Work on the molecule has produced at least ten publications in top journals. One of these publications 3 , a collaboration between Bradner and Constantine Mitsiades, a cancer biologist at Dana-Farber, bolstered BRD4's connection to Myc. Mitsiades had found that multiple-myeloma cells express high levels of Myc and BRD4, but without a compound to target either of them, it was difficult to learn much more. With Bradner, he found that JQ1 reduced expression of Myc and its target genes and stopped myeloma cells from dividing in mice 3 . Chris Vakoc, a cancer biologist at Cold Spring Harbor Laboratory in New York, was studying the role of BRD4 in leukaemia when he first learned of JQ1. He phoned Bradner immediately. \u201cThe next day he sent us a huge amount of the compound,\u201d Vakoc says. In Vakoc's hands, JQ1 stopped cancer-cell proliferation in mice with leukaemia and significantly extended their lifespans 4 . JQ1 has also been used to study infectious diseases such as those caused by Epstein-Barr virus 5  and HIV 6 . \u201cIn 20 years, my lab could not accomplish all of the research that has unfolded on JQ1 in one year through this open approach,\u201d says Bradner. With US$15 million in venture capital from HealthCare Ventures of Cambridge, Massachusetts, Bradner has launched Tensha Therapeutics, a biotechnology company focused on bromodomain inhibition. The Cambridge-based biotech is now screening JQ1 derivatives to learn which are likely to have the fewest side effects \u2014 an essential early step in drug development. Bradner is impatient, however, and is always on the lookout for drugs already in development that would be safe to use in NMC. In 2010, scientists at GSK published a study on an inhibitor of BRD4 and related molecules for treating sepsis 7 . Bradner asked the GSK researchers to try one of their compounds in patients with NMC at Dana-Farber. (Dhanak says that the company had been quietly working on BRD4 inhibitors since French's  NUT\u2013BRD4  paper in 2003.) GSK agreed. The first attempt was in March this year, when oncologists at Dana-Farber used the company's BRD4 inhibitor GSK525762 to treat a 23-year-old engineering graduate student with NMC. The patient died about three weeks into the treatment. French says he suspects that the dose was too low and that combining the drug with HDAC inhibitors or other epigenetic drugs could yield better results. Dhanak says that GSK might test combinations in the near future. Any clinical trial for NMC is bound to move slowly \u2014 the disease is aggressive, and only 90 cases have been diagnosed in the past decade. To raise awareness of NMC and make it easier for patients to enrol in trials, in 2011 Bradner and his colleagues created an international NMC registry ( http://www.nmcregistry.org ). It seems to be working. \u201cWe were concerned we'd have a problem finding patients, and now, through social media, the patients are finding us,\u201d Bradner says. \n               Making good \n             Not all scientists share Bradner's optimism. \u201cEpigenetics is the new horizon, but when you get down to it, the fact is that people are just mucking around with it and finding interesting effects,\u201d says Gerard Evan, a cancer biologist who studies epigenetic signalling at the University of Cambridge, UK. Epigenetics affects many cellular functions, and researchers are only beginning to learn how it influences cell memory. Whatever the outcome, some see hopeful signs in Bradner's open approach. Dhanak says that he welcomes it. \u201cPeople like Jay have been tremendous in pushing forward the frontiers,\u201d he says. What Bradner wants most is to fulfil his pledge to the firefighter who died from NMC. \u201cHis gift of that rare tumour, given at a time when he was beyond all conceivable treatment, was a powerful experience,\u201d Bradner says. If bromodomain inhibition fails, Bradner will apply the same open-source strategy to another target. \u201cMore and more, I feel it is so important to impact patients' suffering from cancer, and it doesn't matter whether that's with our molecules or someone else's,\u201d he says. \n                     First drugs found to inhibit elusive cancer target 2011-Nov-07 \n                   \n                     Epigenome effort makes its mark 2010-Oct-06 \n                   \n                     Consortium solves its 1,000th protein structure 2010-Sep-30 \n                   \n                     Project set to map marks on genome 2010-Feb-02 \n                   \n                     The Bradner Lab \n                   Reprints and Permissions"},
{"file_id": "487287a", "url": "https://www.nature.com/articles/487287a", "year": 2012, "authors": [{"name": "Helen Thompson"}], "parsed_as_year": "2006_or_before", "body": "Enhancements such as doping are illegal in sport \u2014 but if all restrictions were lifted, science could push human performance to new extremes. UK sprinter Dwain Chambers faces the race of his life next month, as he attempts to win an Olympic medal at the 2012 games in London \u2014 and complete a long journey back from the disgrace of his 2003 suspension for doping. Chambers, who has devoted much of his time since then to persuading others to steer clear of performance-enhancing drugs, has admitted to using six different substances banned by the sporting authorities. These included two anabolic steroids \u2014 a designer drug and a testosterone cream \u2014 to accelerate recovery; the hormone erythropoietin (EPO), which increases production of red blood cells, to allow him to do more repetitions in training; human growth hormone for recovery; a thyroid hormone called liothyronine to decrease sluggishness; and a narcolepsy drug called modafinil to increase mental alertness and reaction time. The quest for ultimate enhancement is as old as the games: the Greek physician Galen passed on knowledge from the ancient games to the Romans, praising the effects of eating herbs, mushrooms and testicles. But Chambers\u2019 story is just one example of how today\u2019s competitors are taking that quest to a whole new level. \u201cThere\u2019s an arms-race quality to performance-enhancing technologies in sport,\u201d says Thomas Murray, former president of the Hastings Center, a bioethics and public-policy foundation in Garrison, New York. An amateur cyclist, Murray is among the many sports fans appalled by the seemingly endless string of doping scandals that result. \u201cI could probably do a four-mile climb much better with EPO,\u201d he says, \u201cbut I could also do it much better if I put a motor on my bike.\u201d That\u2019s not the point of sport, he says, and neither are drugs \u2014 an attitude shared by the International Olympic Committee and just about every other professional and amateur sports organization. But others argue that enhancers have become so prevalent that the only realistic option is for the sporting authorities to let athletes use what they want, as long as they do it safely. \u201cIf the goal is to protect health, then medically supervised doping is likely to be a better route,\u201d says Andy Miah, a bioethicist at the University of the West of Scotland in Ayr. \u201cBetter yet, the world of sport should complement the World Anti-Doping Agency with a World Pro-Doping Agency, the goal of which is to invest in safer forms of enhancement.\u201d Science alone cannot resolve the ethical conundrum presented by this debate. But it can shed light on the purely technical question: if performance-enhancing techniques were allowed, how far could the human body go? \n               Power pills \n             For strength and power, the best-known drugs are probably those in the vast family of anabolic steroids, a group that is constantly expanding as the structures get slight modifications in a bid to evade detection in drug tests. \u201cThere are about 2,000 different tweaks you could do to a steroid molecule that would all probably make you big and strong,\u201d says Don Catlin, a pharmacologist at the University of California, Los Angeles. The compounds mimic the way testosterone works in the body, triggering protein synthesis and building more muscle tissue. A course of steroids combined with exercise can translate to a 38% increase in strength in men, potentially more in women. Another popular strength enhancer is human growth hormone, which increases levels of the protein insulin-like growth factor\u00a01 (IGF1). This spurs muscle growth, although it is debatable whether or not that growth actually does increase strength. In the only study to show positive effects in recreational athletes 1 , those taking human growth hormone saw their sprinting capacity increase by 4%. That may seem small, but it could make all the difference for, say, a 50-metres freestyle swimmer or a 100-metres sprinter, says Kenneth Ho, an endocrinologist at the University of Queensland in St Lucia, Australia, who co-authored the study. \u201cIf you look at what breaks records, it comes down to 0.01 of a second.\u201d In endurance sports, in which strength is less important than increased stamina, athletes can get dramatic results from blood doping, which aims to increase the number of oxygen-carrying red blood cells. They can accomplish this through blood-cell transfusions or by taking EPO. In one study 2 , blood doping increased normal humans\u2019 stamina by 34%, and in another 3 , it allowed them to run 8 kilometres on a treadmill 44 seconds faster than they could before. And work published last month 4  by Max Gassmann and his colleagues at the University of Zurich in Switzerland, there are signs that the hormone has an effect on the brain, increasing an athlete\u2019s motivation to train. Drugs currently in the pipeline at pharmaceutical companies may also find themselves being co-opted for illicit use by athletes. One family, designed to treat muscular dystrophy and other muscle-wasting disorders, inhibits the activity of myostatin, a protein that keeps muscle growth under control. Similarly, a group of drugs called HIF stabilizers, which are aimed at treating anaemia and kidney disease, regulates a protein that turns on genes for the production of red blood cells, including the gene for EPO. And there may be a part for cognitive enhancers to play, too. \u201cThere\u2019s a range of compounds coming out that try to improve the ability to think more clearly when you\u2019re fatigued,\u201d says Chris Cooper, a biochemist at the University of Essex in Colchester, UK. Improvements don\u2019t just come from the pharmacy. Athletes also rely heavily on nutritional supplements, which are legal. \u201cThey\u2019re 98.5% hype,\u201d says Conrad Earnest, an exercise physiologist at the University of Bath, UK. But one supplement that does work for some athletes is creatine, which contributes to the synthesis of the energy carrier molecule ATP during exercise. Earnest estimates that athletes taking creatine could see their performance improve by as much as 8%. Another effective supplement is beetroot juice. Researchers at the University of Essex have found that the nitrate present in the juice increases nitric oxide levels in the body, allowing muscles to use oxygen more efficiently. As a result, the team found that divers could hold their breath for 11% longer than normal 5 , which could help swimmers who want to minimize the number of breaths they take in short-distance events. Most of these performance enhancements come with a slew of side effects, however. Steroids can cause high blood pressure, thickening of the heart valves, decreased fertility and libido, and changes such as chest hair in women and shrunken testicles in men. And boosting the number of red blood cells thickens the blood, increasing the risk of having a stroke. Adding to the uncertainty, a number of the drugs are used to treat serious diseases such as cancer, AIDS and muscular dystrophy, so they have been tested largely on desperately ill patients with below- normal levels of growth factors and hormones. It is hard to know how to extrapolate those data to the sports arena, says Cooper. \u201cElite athletes are very different beasts from normal people in the sense that they\u2019re genetically enhanced,\u201d he says, \u201cbecause they\u2019ve been selected to be good at what they\u2019re doing and they have a lot of training.\u201d Furthermore, testing in healthy people \u2014 subjecting them to the dosages and combinations that athletes are likely to take \u2014 would be an ethical can of worms. Because of that, says Charles Yesalis, an emeritus professor of sports science at Pennsylvania State University in State College, \u201cthere\u2019s no way to know what advantages different combinations of steroids, nutritional supplements and specialized diets could produce. It\u2019s a witches\u2019 cauldron.\u201d \n               Code breaking \n             Gene doping \u2014 enhancing performance by adding or modifying genes \u2014 has been the subject of locker-room gossip for the past ten years. There are plenty of natural mutations for which to wish. The Finnish cross-country skier Eero M\u00e4ntyranta, who won three gold medals in the early 1960s, had a mutation that made his body\u2019s EPO receptors more efficient. In 2004, a toddler made headlines for having a mutation that disabled myostatin, giving him the physique of a petite body builder. And the gene that encodes angotensin-converting enzyme, which has been hailed as the gene for physical performance, has one variation known to boost endurance by increasing oxygen delivery capacity and capillary density, and another that is associated with muscle growth and strength 6 , 7 . Advances in gene therapy could one day make it possible for any athlete to enhance their DNA. For example, in experiments aimed at treating muscular dystrophy in the elderly, a group led by physiologist Lee Sweeney of the University of Pennsylvania in Philadelphia introduced a gene to cause over-expression of IGF1 in mice. The treatment boosted muscle strength of young adult mice by 14%, earning the rodents the nickname \u2018mighty mice\u2019 8 . Other researchers are turning genes on and off with drugs. In 2008, Ronald Evans and his colleagues at the Salk Institute for Biological Studies in La Jolla, California, worked with GW1516, a drug that activates a gene that increases the ratio of \u2018slow-twitch\u2019 to \u2018fast-twitch\u2019 fibres in muscle. As the names suggest, slow-twitch fibres contract more slowly than fast-twitch, but they are more efficient at aerobic activity. Evans and his team found 9  that in mice, GW1516 combined with exercise increased the rodents\u2019 endurance by 70%. However, both Evans and Sweeney are sceptical about how useful athletes will find such therapies. \u201cIn humans, I expect the same general relationship \u2014 the under-exercised will be the ones who will have the most benefit from exercise mimetics,\u201d says Evans. \u201cMy view is that endurance athletes are physically advantaged and will have the least benefits.\u201d Gene therapy has its share of health risks, including potentially severe immune reactions to the viruses used to ferry genetic material into cells. The results may also be hard to control. \u201cIf you\u2019re going to turn a gene for something like EPO on, you better be able to turn it off,\u201d warns Catlin. Gene doping, he says, \u201cis not a good idea, but I wouldn\u2019t be surprised if someone\u2019s out there trying it\u201d. \n               Human 2.0 \n             Drugs are not the only way to potentially enhance performance. Surgery and, ultimately, technological augmentations could also help athletes towards the podium. Baseball pitchers who have undergone surgery to replace a damaged elbow ligament with tissue from a hamstring or forearm tendon claim that they can throw harder after the two-year rehabilitation process. But Scott Rodeo, an orthopaedic surgeon at the Hospital for Special Surgery in New York City, warns that the science doesn\u2019t back up the stories. \u201cTo truly say you\u2019re making this elbow better would be a bit of a stretch,\u201d says Rodeo. Replacing entire joints would be unlikely to work for an elite athlete: too many screws could come loose and the artificial joint wouldn\u2019t quite match the mechanics of a natural one. The materials would also wear out within a few years under the physical demands of elite sport. Still, Rodeo says, that assessment could change if researchers make major advances in engineering skin, tendons and other replacement body parts in the laboratory. Miah sees potential in more imaginative surgical enhancement. \u201cConsider using skin grafts to increase webbing between fingers and toes to improve swimming capacity,\u201d he says. \u201cThese kinds of tweaks to our biology are likely ways that people would try to gain an edge over others.\u201d Another frontier is nanotechnology, adds Miah. Researchers are already experimenting with blood supplements based on oxygen-carrying nanoparticles for use in emergency situations. From there, he says, \u201cthere is a lot of discussion about the possibility of biologically infused nano\u00addevices that could perpetually maintain certain thresholds of performance\u201d. Mechanical prosthetics are already a reality, such as the \u2018cheetah-style\u2019 legs used by amputees including Oscar Pistorius from South Africa, a Paralympic gold medallist who was approved this month to run in the 2012 Olympics. But scientists are split on whether current artificial limbs actually confer an advantage over the flesh and blood variety. Bryce Dyer, a prosthetic engineer at the University of Bournemouth, UK, explains that although Pistorius\u2019s spring-like prosthetics allow him to speed up at the end of a race, they put him at a disadvantage coming out of the crouch at the start of a race or when turning a curve. \u201cWhen he\u2019s running straight ahead, he eventually hits a natural state of harmony like bouncing on a trampoline,\u201d says Dyer, \u201cbut then he sometimes runs right off the track because he can\u2019t turn.\u201d Pistorius\u2019s prosthetics lack the stiffness of a human ankle and can\u2019t generate the same forces as they hit the ground. To get around this, Pistorius pumps his legs faster. \u201cIt\u2019s a biomechanically distinct way of running fast, but there\u2019s no evidence that it\u2019s advantageous,\u201d says Hugh Herr, a biomechanical engineer at the Massachusetts Institute of Technology (MIT) in Cambridge. Technology might get around these problems. \u201cStepping decades into the future, I think one day the field will produce a bionic limb that\u2019s so sophisticated that it truly emulates biological limb function. That technology will be the Olympic sanctioned limb,\u201d says Herr, whose lab at MIT is currently working on a bionic running leg. \u201cWithout any such human-like constrains, the Paralympics limb will become [the basis of] this human\u2013machine sport like racecar driving.\u201d According to Herr, performance-enhancing technologies will advance to a point at which they will not only extend human limits, they will demand an Olympics all of their own. \u201cFor each one there will be a new sport \u2014 power running, and power swimming, and power climbing,\u201d projects Herr. \u201cJust like the invention of the bicycle led to the sport of cycling. What we\u2019ll see is the emergence of all kinds of new sports.\u201d Reprints and Permissions"},
{"file_id": "485566a", "url": "https://www.nature.com/articles/485566a", "year": 2012, "authors": [{"name": "Henry Nicholls"}], "parsed_as_year": "2006_or_before", "body": "Conservationists are taking heroic measures to restore the fertility of a three-footed Sumatran rhino. But some ask whether this is the right way to save an endangered species. First, the vet inserts his arm in a shoulder-length plastic glove. Next, he grips an ultrasound probe and slides both arm and probe deep into the rectum of a 500-kilogram rhinoceros. All eyes of those present, including his, are on the ultrasound image on the laptop monitor nearby. As the vet moves the probe over the animal's intestinal wall, her uterus comes into view on the screen. Even to the untrained eye, it is clear that there is something seriously wrong: marble-sized cysts fill the space where there should be a smooth uterine lining. As if in acknowledgement of the fact, the rhino lets out a doleful moan. This is Puntung, a Sumatran rhinoceros that is missing a foot as well as a working uterus. Yet the future of this species in Malaysian Borneo may rest on the hairy shoulders of this singular beast. If she is ever to reproduce, she will need Thomas Hildebrandt and his veterinary team from the Leibniz Institute for Zoo and Wildlife Research (IZW) in Berlin to rescue her womb \u2014 and then push the boundaries of rhino assisted-reproduction to new extremes. According to the latest best guess, only 200\u2013300 Sumatran rhinos ( Dicerorhinus sumatrensis ) may be left in the wild, split between three territories in southeast Asia: the Indonesian island of Sumatra, Peninsular Malaysia and the state of Sabah in Malaysian Borneo (see 'The remaining rhinos'). This perilous situation is a result of a devastating combination of habitat loss (mainly to create lucrative oil-palm plantations) and poaching (to feed the black market for rhino horn). Conservationists say that the species' small, fragmented population is now the biggest threat to its survival 1 , with animals so sparsely distributed that they are simply unable to meet each other to mate. Because females that haven't mated when they are in oestrus can develop problems with their uterus, the rare encounters that do take place often come to naught. At best, rhino mothers take several years between pregnancies \u2014 meaning that the birth rate in the wild is unlikely to keep up with poaching and natural deaths. \n               Drastic measures \n             This desperate situation has led conservationists in Sabah to a desperate conclusion: that the only way to maintain the rhino population here is to capture as many as possible of the remaining animals \u2014 which may number as few as 30 \u2014 and subject them to assisted reproductive technology. That includes scrubbing out the uterus of Puntung, and possibly techniques such as  in vitro  fertilization (IVF) and cloning, the likes of which have rarely been wielded in the name of conservation. \u201cEither we give up or we try to make every fertile rhino contribute to the future of this species,\u201d says John Payne, executive director of the Borneo Rhino Alliance (BORA) in Kota Kinabalu, Sabah. \u201cThe best way to do that is to bring them into fenced, managed facilities.\u201d Such a drastic attempt to rescue a highly endangered species has precedents. Conservationists have, through heroic efforts, wrestled species such as the Arabian oryx ( Oryx leucoryx ), the black-footed ferret ( Mustela nigripes ) and the California condor ( Gymnogyps californianus ) back from the brink of extinction by bringing all the remaining animals together, using artificial insemination to spread sperm and maximize genetic diversity, and keeping offspring alive through round-the-clock husbandry. In the case of the Sumatran rhino, however, some conservationists worry that without a long-term strategy for reversing the environmental pressures that are killing them off, captive breeding alone can never restore the wild population. \u201cIt's not a plan unless you've mitigated the threats that wiped them out in the first place,\u201d says Alan Rabinowitz, chief executive of the wild-cat conservation group Panthera in New York city. Others are uncomfortable with throwing so much money and effort at a single species \u2014 a single animal, in Puntung's case \u2014 when the chances of success are so slim. \u201cOne of the biggest challenges facing conservation today is our inability to step back and admit that there are animals that would take a little bit less work and a little bit less money but have the potential to survive for their genetic diversity into the future,\u201d says John Fraser, chief executive of the New Knowledge Organization in New York city, a think tank and advocate of a triage response to species conservation. \u201cThey may not be as charismatic, but quite frankly we have to admit that some species are not going to make it and it's really, really sad.\u201d Puntung got her name, which translates roughly as 'Stumpy', in 2007, when a ranger in the Tabin Wildlife Reserve in eastern Sabah came across her distinctive three-footed tracks. It is thought that she must have lost her foot to a poacher's snare as a calf, and that her mother nursed her back to hobbling fitness. \u201cIf she had been even two years of age, the wound that she has would not have healed over,\u201d says Zainal Zahari Zainuddin, BORA's field manager, on-site vet and the person closest to Puntung. In April 2010, the Sabah Wildlife Department and BORA began a joint operation to catch her. It was the first push in an effort to bring as many as possible of Sabah's remaining rhinos into captivity. But it was only after 20 frustrating months that she finally walked into a trap. On Christmas Day 2011, a helicopter airlifted Puntung to her current home in a temporary captive facility within the reserve. Payne estimates that the entire operation, including the cost of hiring the helicopter and constructing her enclosure, set BORA back more than US$250,000. With Puntung apparently in her reproductive prime, and with a lone male called Tam in residence since 2008, there was hope that the pitter-patter of tiny rhino feet might soon follow. It was something of a setback, then, when ultrasound scans carried out by Hildebrandt and his team in February showed that Puntung's uterus was riddled with cysts that would make any full-term pregnancy near impossible. Her ruptured hymen suggests an explanation. \u201cWe think she must have mated in the wild, got pregnant, but with her handicap was unable to sustain the fetus and it died  in utero ,\u201d says Hildebrandt, who specializes in the assisted reproduction of endangered mammals and has been involved with Sabah's rhinos since 2004. The failed pregnancy led to the cysts. \u201cSuch pathology is not uncommon in rhinos,\u201d Hildebrandt says, \u201cbut is rarely this bad. A decade ago, this might have been the moment to give up. But reproductive medicine has advanced at such a pace that there are still options for Puntung, particularly as she seems to be relatively young \u2014 with as many as 10 years of reproductive life ahead of her \u2014 and her ovulatory cycle seems to be normal. At the end of March, Hildebrandt and two of his IZW colleagues flew back to Sabah on a uterine-rescue mission, accompanied by huge suitcases filled with veterinary paraphernalia: green scrubs, anaesthetics, antibiotics, drips, probes, a carbon-fibre catheter patented by Hildebrandt and his colleagues for the insemination of rhinos, and a gun case containing a 2-metre-long video endoscope tailor-made to fit Puntung's reproductive tract. Once in the Tabin reserve, the IZW vets, BORA staff, including Payne and Zahari, and the Sabah Wildlife Department's chief field vet assemble in a hut beneath the glare of fluorescent strip lighting to be briefed on the impending procedure. If all goes to plan, explains Hildebrandt, he will insert the endoscope into Puntung's uterus and attempt to lance some of the cysts, particularly ones that are preventing sperm from entering the oviducts. That might smooth the way for insemination \u2014 either artificially or by Tam \u2014 followed quickly by the collection of fertilized embryos before they implant. By repeating the procedure every month for the rest of her reproductive life, it might be possible to harvest as many as 100 embryos, freezing them in liquid nitrogen to be implanted into surrogate females in years to come. With everyone's questions answered, Hildebrandt and his team wheel their equipment out into the rain. The croak of thousands of invisible amphibians falls suddenly silent as the vets pass by on the way to Puntung's enclosure. \n               Rare breed \n             Past efforts to breed Sumatran rhinos in captivity have been spectacularly unsuccessful. Between 1984 and 1993, at least 35 wild rhinos were taken into captivity across the region without the birth of a single calf. Zoologists knew little about the reproductive rhythms of rhinos, breeding facilities rarely housed a good mix of males and females, and disagreements over whether the Sabah rhino was a subspecies of the Sumatran rhino meant that there was little cooperation between Indonesia and Malaysia and even between Peninsular Malaysia and Malaysian Borneo. The fruitless attempts frustrated some conservationists, including Rabinowitz. In a frank essay 2  published in 1995, he accused the conservation community of \u201chelping a species go extinct\u201d by placing too much emphasis on captive breeding of the Sumatran rhino at the expense of \u201cthe more difficult job of protection and management in the field\u201d. The case for captive breeding may be stronger now. \u201cIn Peninsular Malaysia, the species is either extinct or about to go extinct,\u201d Payne says. And in Sabah \u201cthe numbers are so low, that no method exists to find out how many are now left\u201d. In the 1980s, when he was working in what is now the Tabin Wildlife Reserve, he recalls coming across rhino footprints within a matter of days in the field. \u201cAt best we can now find old rhino footprints perhaps once or twice per year,\u201d he says. Meanwhile, captive breeding has scored some successes. In 2001, Cincinnati Zoo announced 3  the first Sumatran rhino to be born in captivity since 1889. The same star breeding pair, on loan from Indonesia, went on to produce two more calves. \u201cWe had to learn how to feed this species, we had to learn about its reproductive physiology, and thank goodness we started as early as we did because now it looks like [captive breeding] is a serious need for the species,\u201d says Terri Roth, director of the zoo's Center for Conservation and Research of Endangered Wildlife, which works closely with Indonesia's Sumatran Rhino Sanctuary in Way Kambas National Park. There are also signs of greater cooperation between captive facilities. At a March meeting of the Sumatran Rhinoceros Global Management and Propagation Board in Jakarta, all parties put their signature to a \u201cLetter of Intent for Collaboration\u201d. This puts aside past taxonomic differences, and acknowledges that all captive animals should be part of a single, globally managed breeding programme and that captive facilities will share sperm and embryos \u201cbased on availability and need\u201d. Testifying to this new  entente cordiale , the Sabah Wildlife Department has agreed to send semen collected from Tam to Cincinnati Zoo to attempt artificial insemination of a young female when she reaches sexual maturity. But with just ten animals in captivity worldwide \u2014 three at Cincinnati Zoo, four at the Sumatran Rhino Sanctuary and three in the Tabin reserve \u2014 more animals will need to be caught in Sumatra to establish a viable captive population, says Roth. \u201cWe need to pull them in and manage them intensively and make sure as many of them breed as possible,\u201d she says. Rabinowitz acknowledges the greater urgency for captive breeding, but disputes whether the data on population size, sex ratio and breeding success in the wild are good enough to say that wild populations are in terminal decline or that captive breeding \u2014 \u201can absolute last resort\u201d, he says \u2014 is the only option. \u201cWhen you lack information and just say there's no hope, then you're really writing the end of the book.\u201d \n               Operation uterus \n             Before her ultrasound scan, the unsuspecting Puntung is lured into a small pen by a bucketful of diced bananas. Hildebrandt's colleague Frank G\u00f6ritz loads a syringe with a dose of sedative calculated to send her into a standing anaesthesia, then reaches through the bars to plunge the needle through her sparsely haired hide. Within seconds, she has relaxed into a sling, which supports her bulk and makes it easier to insert an endoscope into her uterus than if she were lying down. When Robert Hermes, the third member of the team, slides his gloved arm into Puntung's rectum she barely flinches. She has undergone a period of intensive coaching to tolerate medical procedures. Now, it is impossible to tell that she's undergoing a transrectal ultrasound scan, were it not for the vet squatting at her rear. Almost an hour later, however, the first signs of stress are showing \u2014 though not from Puntung. The ultrasound is over and Hildebrandt is struggling to insert the carbon-fibre catheter into her uterus. On his knees, with his right arm deep in her vagina and his cheek brushing up against her buttocks, his face is a picture of concentration and his scrubs are darkening with sweat. Puntung's cervix, tightly constricted owing to the phase of her menstrual cycle, is proving a serious obstacle to the catheter. Eventually, Hildebrandt triumphs and is able to flush out the uterus with a sterile cell medium, which will be tested for any underlying infection. With the cervix so narrow, there is no hope of moving on to the bigger-bored endoscope, but before Hildebrandt removes the catheter he injects a highly concentrated penicillin solution. This will destroy any pathogenic bacteria, and is so concentrated that it may actually strip away some of the lining and cysts, possibly making it easier to attempt fertilization and embryo collection. Hildebrandt has successfully used this approach to boost the fertility of two tigers and a leopard 4 . If it doesn't work, the favoured next step is to carry out a similar procedure at a future date, but to inject a more caustic chemical such as kerosene to attack the cysts. This carries a risk. The team has to make sure that the treatment \u201cis not so aggressive that it destroys the uterus\u201d, Hildebrandt says. Before the vets call it a wrap, there is still time to take a cast of Puntung's stump, which will be used to fashion a prosthetic foot. This will allow her to move around with greater comfort. If she ever gets a chance to mate with Tam, the foot will also be handy for supporting his weight on her back during the half-hour encounter. Even if embryo collection proves unsuccessful, it might not be the end of the road for Puntung. It should be possible to collect immature eggs, by inserting a fine needle through the wall of her rectum and into her ovaries. The challenge is getting them to mature and fertilize  in vitro . The IZW vets have attempted this with white and black rhinos 5 . They obtained 29 eggs and managed to fertilize one, but the embryo did not progress beyond the four-cell stage. The only attempt to harvest eggs in Sumatran rhinos \u2014 from Cincinnati Zoo's star female just after her death in 2009 \u2014 was unsuccessful 6 . There are other, more futuristic options. In theory, Puntung could be cloned, taking a nucleus from one of her cells and injecting it into an egg stripped of its own DNA. That rhino eggs are in short supply needn't be a problem, says Pasqualino Loi, a reproductive biologist at the University of Teramo in Italy, who, more than a decade ago, used domestic sheep as a source of eggs and surrogates to clone an endangered sheep relative, the mouflon 7 . \u201cPlay around,\u201d he suggests. \u201cInject some rhino mitochondria and a nucleus into a horse egg.\u201d It's just possible, says Loi, that it could result in a viable embryo that could be successfully nurtured to term by a surrogate mare. Pursuing another strategy, scientists at San Diego Zoo in California last year showed that banked tissue from the almost extinct northern white rhino ( Ceratotherium simum cottoni ) could be induced to form a line of pluripotent stem cells, capable of forming many tissues 8 . It's possible that these cells could be used to generate working gametes, using the same techniques that have produced sperm in mice 9 . Hildebrandt advocates natural mating before attempting IVF or other reproductive technologies, but he is already starting to bank rhino tissue. With part of a \u20ac500,000 (US$640,000) grant from the German Federal Ministry of Education and Research awarded in December 2010, he established a cryo-bank facility in Kota Kinabalu. In it are fibroblasts from Tam and Gelogob, a blind and elderly female rhino in captivity at the Tabin Wildlife Reserve. Cells from Puntung will join them shortly. \u201cIf we can't find the solutions, then people after us can,\u201d Hildebrandt says. \u201cWe have the responsibility to make it available to the next generation.\u201d Yet the chance that such technologies will succeed in a species like the Sumatran rhino, whose basic biology is still poorly understood, seems remote. Roth says that tissue banking \u201cis not a priority compared with some of the other issues we're up against\u201d. And the Indonesian government's action plan for rhino conservation, spanning 2007\u201317, contains no mention of tissue banking 10 . Money, too, is in short supply. It is a stinging irony that by far the biggest donor to BORA is the Sime Darby Foundation, the philanthropic arm of the Sime Darby Group, based in Kuala Lumpur, one of the world's biggest producers of palm oil, the crop that led to the destruction of much of the rhino's rainforest home. It has committed a further $2 million to fund BORA's operations up to 2015 and after that the charity is on its own. \u201cThis is a bit of a worry,\u201d admits Payne. Hildebrandt says that his grant from the German government has expired. He knows that he needs some demonstrable success with Puntung to get more. \u201cIf we are not successful in the next few months, then I think the programme is over,\u201d he says. Other conservation biologists argue that it already is. Even if assisted reproductive technologies do prove possible, Fraser asks how long the new animals would survive. \u201cMy concern is that [the Sumatran rhino's] future viability as a species on this planet and the future viability of any offspring is really in question because the habitat just isn't there. So I question the priority setting, although I can certainly understand the emotional state of those invested in saving the animal. Puntung, of course, is oblivious to the emotions and the debate. The operation over, G\u00f6ritz injects her again to reverse the effect of the anaesthesia and within minutes she is out of the sling. Zahari enters the enclosure and unfurls a hose to spray her down. It's a ritual she clearly enjoys, raising her neck to meet the droplets of water as they rain down. Puntung can savour a few weeks of rest and bananas, before science's next assault on her infertility. \n                     Biodiversity: Endangered and in demand 2011-Dec-21 \n                   \n                     Could stem cells rescue an endangered species? 2011-Sep-04 \n                   \n                     Conservation: Invest in a DNA bank for all species 2011-Aug-24 \n                   \n                     Looking beyond the glamour of conservation 2010-Sep-28 \n                   \n                     Leibniz Institute for Zoo and Wildlife Research \n                   \n                     Borneo Rhino Alliance \n                   Reprints and Permissions"},
{"file_id": "486020a", "url": "https://www.nature.com/articles/486020a", "year": 2012, "authors": [{"name": "Jeff Tollefson"}, {"name": "Natasha Gilbert"}], "parsed_as_year": "2006_or_before", "body": "The world has failed to deliver on many of the promises it made 20 years ago at the Earth summit in Brazil. The tropical air was charged with hope and despair as the world\u2019s leaders descended on Rio de Janeiro for the United Nations\u2019 Earth summit in May 1992. Countries were buoyed by a string of successful environmental treaties in the 1970s and 1980s, capped by a landmark deal to save the ozone layer in 1987. Yet the Earth summit in Rio, which drew 178 nations and around 100 heads of state, was also rife with frustration and distrust. Diplomats had spent the previous two years drafting a pair of treaties intended to safeguard Earth\u2019s biodiversity and climate, but the talks had recently faltered as rich and poor countries split over who should pay for protecting the planet. In the end, the leaders decided that they could not go home empty handed. They signed off on both the Convention on Biological Diversity and the Framework Convention on Climate Change, making broad pledges to solve some of the most complex problems facing humanity. Countries also agreed to a laundry list of goals spelled out in a document known as Agenda 21, which eventually spawned the Convention to Combat Desertification. Although the agreements lacked teeth, they created formal international processes that engaged almost the entire world and eventually led to more targeted accords (see \u2018Global awakening\u2019). \n               boxed-text \n             At the end of the summit, Richard Benedick, who had negotiated the ozone accord for the United States, told  The New York Times  that \u201cthe history books will refer back to this day as a landmark in a process that will save the planet from deterioration\u201d. But he and others warned that progress would not come quickly. The pace turned out to be far slower than anticipated, however. Although nations have made some marginal advances, the three conventions have failed to achieve even a fraction of the promises that world leaders trumpeted two decades ago. Dismal grades dominate  Nature \u2019s report cards on the Rio treaties, although the assessment also highlights some progress and offers pointers for the future. As diplomats and leaders prepare to converge on Rio this month for the UN Conference on Sustainable Development, or Rio+20, they will be looking back to consider how to do better. \n               Climate of inaction \n             The climate numbers are downright discouraging. The world pumped 22.7\u00a0billion tonnes of carbon dioxide into the atmosphere in 1990, the baseline year under the UN Framework Convention on Climate Change. By 2010 that amount had increased roughly 45% to 33\u00a0billion tonnes. Carbon dioxide emissions skyrocketed by more than 5% in 2010 alone, marking the fastest growth in more than two decades as the global economy recovered from its slump. And despite constant deliberations under the convention, the overall growth rate of global emissions hasn\u2019t changed much since 1970 (see \u2018Report card: UN Framework Convention on Climate Change\u2019). \u201cPlausibly we are a little better off than if we didn\u2019t have all of this diplomacy,\u201d says David Victor, director of the Laboratory on International Law and Regulation at the University of California, San Diego. \u201cBut the evidence is hard to find.\u201d Ratified by 194 countries plus the European Commission, the treaty sought to stabilize emissions at a level that would \u201cprevent dangerous anthropogenic interference with the climate system\u201d. Although there were no specific targets, wealthy countries agreed to take the lead and help poor countries with monetary and technological aid. In 1997, negotiators followed up with the Kyoto Protocol, which entered into force in 2005 and committed industrialized countries to reduce their collective emissions of all greenhouse gases by 5.2% (compared with 1990) by 2012. Overall, industrialized countries are on track to surpass the Kyoto goal with a reduction of some 7%, but this is largely due to the demise of the Soviet Union and its inefficient factories, as well as to the industrial slump caused by the recent economic crisis, which is starting to reverse. The United States, the developed world\u2019s largest greenhouse-gas producer, never ratified the protocol and increased its greenhouse-gas output by 11% between 1990 and 2010. In the meantime, developing countries more than doubled their emissions, increasing their share of the global total from 29% to 54%. In spite of the failure to rein in emissions, the climate treaty has performed better on many lesser goals. The international process it spawned encouraged investment in climate science and provided a venue for scientists and policy experts to showcase their work. Periodic scientific reports by the Intergovernmental Panel on Climate Change (IPCC) underpinned each major round of treaty talks. The negotiations also helped to raise awareness of climate change across the globe. Governments began working on climate adaptation, sustainable agriculture and reducing tropical deforestation, and Kyoto sparked experimentation with carbon markets and new ways of transferring money and technology to poor countries. But on the core challenge of overhauling the global energy industry and reducing emissions, the questions remain the same 20 years later: who must do what and who pays? The original treaty introduced the notion of \u201ccommon but differentiated responsibilities\u201d, with a heavier burden on wealthier countries, historically responsible for the largest share of greenhouse-gas emissions. That concept was put into practice through the Kyoto Protocol, when industrialized countries agreed to reduce emissions and provide aid to developing countries, which took on no formal obligations. But as the world changed and the proportion of emissions increasingly shifted towards developing countries, the treaty remained static. The result has been a prolonged stand-off, with poor nations demanding that their wealthy neighbours do more and industrialized countries increasingly concerned about skyrocketing emissions among the rapidly emerging economies. In particular, the United States baulked at the idea of moving forward without China, which is now the world\u2019s largest emitter, whereas China cited its lower per-capita emissions in questioning whether the United States is doing enough. Negotiators wrestled with those issues at the 2009 climate summit in Copenhagen, where China, Brazil, South Africa and other major developing countries promised for the first time to reduce emissions. Last December in Durban, South Africa, countries agreed to negotiate a new global climate treaty by 2015 that would include formal commitments from both developed and developing countries. Climate negotiators will gather in Doha, Qatar, in November to begin the process of designing that new treaty, but scepticism remains. \u201cThe only way we are going to achieve significant emissions reductions is through technology,\u201d says Barry Brook, director of climate-change research at the University of Adelaide\u2019s Environment Institute in Australia. The fundamental barrier is the cost of clean-energy alternatives, he says. \u201cA lot of this can\u2019t be driven by an international process.\u201d Some argue that the climate talks might be more fruitful if the focus were on securing agreement within groups of major economic powers such as the G20, which is responsible for more than 80% of global emissions. But even if the cacophony of voices in the UN negotiations makes progress difficult, many believe that the process has helped to inspire countries, local governments and even corporations to tackle the issue of climate change in a more serious way. \u201cWhat we have today is nowhere near what the science says we need,\u201d says Manish Bapna, acting president of the World Resources Institute in Washington DC. \u201cBut is it closer than we would have been in the absence of climate negotiations? I would say the answer is an unequivocal yes.\u201d \n               Biodiversity on the sidelines \n             \u201cLet us have the courage to look in the eyes of our children and admit that we have failed.\u201d That stark message came from Ahmed Djoghlaf in October 2010, when he addressed the 193 parties to the Convention on Biological Diversity (CBD) at a summit in Nagoya, Japan. As executive secretary of the CBD at the time, Djoghlaf lamented that countries were nowhere near to meeting the treaty\u2019s chief goal of \u201csignificantly\u201d cutting species loss by 2010 (see \u2018Report card: Convention on Biological Diversity\u2019). Instead, he said, \u201cwe continue to lose biodiversity at an unprecedented rate\u201d. Some 30% of amphibians, 21% of birds and 25% of mammal species are at risk of extinction, according to the International Union for Conservation of Nature (IUCN) based in Gland, Switzerland. The CBD has failed to slow the problem, say biodiversity scientists, because it did not set concrete and focused targets, and it provided no means to measure progress towards protecting wildlife and ecosystems. At the Nagoya meeting, countries agreed on a set of 20 goals \u2014 the Aichi targets \u2014 which include halving the rate of loss of natural habitats, one of the biggest threats to biodiversity, by 2020. Another target seeks to protect 17% of the world\u2019s land area in nature reserves by 2020. In addition, the CBD parties put money towards developing better indicators for measuring progress. The 20 Aichi targets are a step in the right direction but they still miss the mark, warn scientists and conservationists. \u201cThe Aichi targets are still not very focused and they add no obligations on countries to comply with them. There is an unwillingness among countries to accept obligations,\u201d says Stuart Harrop, a wildlife-management lawyer and director of the Durrell Institute of Conservation and Ecology at the University of Kent in Canterbury, UK. Another long-standing problem with the CBD has been that it lacked a dedicated body, similar to the IPCC, that would provide scientific advice and help it to define quantifiable targets. The CBD gained an equivalent scientific arm only two months ago, when the Intergovernmental Platform on Biodiversity and Ecosystem Services was launched. \u201cIt has not been a science-based convention,\u201d says Anne Larigauderie, a plant ecologist and executive director of DIVERSITAS, an international biodiversity research programme headquartered in Paris. In addition, countries lack the observational infrastructure to track the state of their national biodiversity. The CBD currently relies on data compiled by conservation groups, including the IUCN\u2019s Red List of threatened species. Poor investment in observation systems means that there are still large gaps in the data on local and global biodiversity, says Larigauderie. Lack of funding for biodiversity conservation has also constrained progress, says Cyriaque Sendashonga, a zoologist and director of global policy at the IUCN. In Nagoya, countries agreed to report on their bio-diversity spending at the CBD summit this October in Hyderabad, India. They will also discuss ways to boost spending, including redirecting current subsidies that are harmful to the environment towards conservation actions. This could generate US$50 billion annually for biodiversity, says Sendashonga. In the end, progress on preserving global biodiversity has stalled because \u201cthe political will is just not there\u201d, she says. In large part because public awareness is limited, politicians have not felt compelled to address the issue, she says, and, as a result, \u201cbiodiversity does not feature prominently at Rio\u201d. \u201cWe have been talking about how to implement the CBD for 20 years. At this rate, we will still be talking about it at Rio+80,\u201d says Sendashonga. \n               The deserted convention \n             Of the three treaties that came out of Rio, the UN Convention to Combat Desertification (UNCCD) is the poor relation. This treaty, which aims to prevent and reverse land degradation and to mitigate the effects of drought, has received scant attention by governments and paltry funding, say desert scientists. Progress towards its goals has been even more elusive than for climate and biodiversity (See \u2018Report card: UN Convention to Combat Desertification\u2019). Dryland ecosystems cover more than one-third of the world\u2019s land area and are vulnerable to overexploitation and degradation, which threaten the food security of around a billion people, according to the Food and Agriculture Organization of the United Nations in Rome. And the situation is getting worse: the percentage of land area that is degrading jumped from 15% in 1991 to 24% in 2008, the most recent global figures available. Developing regions are the most susceptible because poor farmers lack access to the more productive agricultural land and often do not have the knowledge or money to use farming techniques that preserve the soil. For their part, rich nations neglected the convention because they do not view desertification as an acute concern. Until recently, they have found it easy to expand agricultural production by opening up new areas at home or buying up land in other countries, says William Dar, director-general of the Inter-national Crops Research Institute for the Semi-Arid Tropics in Andhra Pradesh, India. The convention has also been constrained financially. It is \u201cthe most underinvested of all conventions\u201d, says Dar, who served from 2007 to 2009 as chairman of the committee on science and technology that provides advice to the UNCCD. In 2011, the Global Environment Facility, an international organization that provides funding to help countries implement the Rio conventions, spent just $369 million on UNCCD projects, about 10% of the money it directed towards biodiversity. It took countries until 2009 to agree on a set of 11 impact indicators to measure progress towards combating desertification and land degradation. Beginning in 2012, parties to the convention must submit national reports that include two of the indicators: the proportion of the population in vulnerable areas that is living above the poverty line; and the area of land covered by vegetation. This will begin to provide a baseline from which to measure progress. Yet even such basic requirements will strain poorer nations, which lack the scientific knowledge and technical capacity to track the growth of deserts, says a desert scientist and former employee of the UNCCD, who asked not to be named. Last year, nations agreed to establish a fellowship programme, starting this year, to support postgraduate students and young scientists from developing countries to study and train at specialized institutions on land degradation and desertification. Ultimately, though, the problem of land degradation cannot be solved in isolation because it is intrinsically tied to the other issues that brought leaders to Rio in 1992 \u2014 how to foster economic development without ruining the planet. The task for negotiators this month is to figure out a way to deal more successfully with the related concerns of energy, environment, poverty and resources. \u201cThis is a call to action for Rio,\u201d says Dar. \u201cWe need to tie the conventions together.\u201d See Editorial  page 5 \n                     World governments establish biodiversity panel 2012-Apr-23 \n                   \n                     Durban maps path to climate treaty 2011-Dec-13 \n                   \n                     Science enters desert debate 2011-Sep-13 \n                   \n                     World gets 2020 vision for conservation 2010-Nov-02 \n                   \n                     Biodiversity hope faces extinction 2010-Oct-11 \n                   \n                     Nature special: Rio+20 \n                   \n                     Rio+20 \n                   \n                     United Nations Framework Convention on Climate Change \n                   \n                     Convention on Biological Diversity \n                   \n                     United Nations Convention to Combat Desertification \n                   \n                     Intergovernmental Panel on Climate Change \n                   \n                     Intergovernmental Platform on Biodiversity and Ecosystem Services \n                   \n                     International Union for Conservation of Nature \n                   \n                     International Crops Research Institute for the Semi-Arid Tropics \n                   \n                     DIVERSITAS \n                   Reprints and Permissions"},
{"file_id": "486019a", "url": "https://www.nature.com/articles/486019a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "Twenty years ago, when the world's leaders pledged to protect Earth's climate and biodiversity at the Rio Earth Summit, they knew it would not be easy. But few could have guessed how much worse the situation would get. In 1992, the atmosphere held fewer than 360 parts per million (p.p.m.) of carbon dioxide; the concentration is now nearing 400 p.p.m. and surging upwards. At the same time, species are disappearing at an accelerating rate. On the eve of the second Rio Earth Summit,  Nature  explores the causes and consequence of those changes, as well as the efforts that are being made to avert the worst outcomes. Our assessment shows how little progress nations have made towards honouring the commitments they made in 1992 (see  pages 5  and  20 ). There are some success stories. Brazil has made remarkable advances in curbing deforestation and setting aside protected swathes of land. But with its more recent policies raising concern, the country must do even more to safeguard its environment, argue representatives of Conservation International (see  page 25 ). And although international environmental efforts have stalled, a bottom-up approach that changes how corporations operate could turn a profit for both the planet and for business, says Pavan Sukhdev (see  page 27 ). In sharp contrast to the political stalemate over the past two decades, scientists have developed a more sophisticated understanding of the roots and effects of the current environmental crisis. Articles and reviews elsewhere in this issue explore how shrinking biodiversity is affecting ecosystems and how much the voracious consumption patterns of the developed world are to blame \u2014 see Bradley Cardinale  et al . ( page 59 ), David Hooper  et al . ( page 105 ) and Manfred Lenzen  et al . ( page 109 ). Anthony Barnosky and his colleagues ( page 52 ) argue that the global ecosystem could eventually pass a tipping point and shift into a new state, the likes of which are hard for science to predict. But there are ways to avoid that fate, say Paul Ehrlich and his colleagues ( page 68 ), who suggest techniques to make societies more sustainable and to head off many of the world's chronic environmental problems. Earth and its inhabitants have a second chance in Rio. They may not get many more. \n                     World governments establish biodiversity panel 2012-Apr-23 \n                   \n                     Two successful weeks at Rio 1992-Jun-18 \n                   \n                     Nature special: Return to Rio \n                   \n                     Rio+20 \n                   Reprints and Permissions"},
{"file_id": "486178a", "url": "https://www.nature.com/articles/486178a", "year": 2012, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Adrian Owen has found a way to use brain scans to communicate with people previously written off as unreachable. Now, he is fighting to take his methods to the clinic. Adrian Owen still gets animated when he talks about patient 23. The patient was only 24 years old when his life was devastated by a car accident. Alive but unresponsive, he had been languishing in what neurologists refer to as a vegetative state for five years, when Owen, a neuro-scientist then at the University of Cambridge, UK, and his colleagues at the University of Li\u00e8ge in Belgium, put him into a functional magnetic resonance imaging (fMRI) machine and started asking him questions. Incredibly, he provided answers. A change in blood flow to certain parts of the man's injured brain convinced Owen that patient 23 was conscious and able to communicate. It was the first time that anyone had exchanged information with someone in a vegetative state. Patients in these states have emerged from a coma and seem awake. Some parts of their brains function, and they may be able to grind their teeth, grimace or make random eye movements. They also have sleep\u2013wake cycles. But they show no awareness of their surroundings, and doctors have assumed that the parts of the brain needed for cognition, perception, memory and intention are fundamentally damaged. They are usually written off as lost. Owen's discovery 1 , reported in 2010, caused a media furore. Medical ethicist Joseph Fins and neurologist Nicholas Schiff, both at Weill Cornell Medical College in New York, called it a \u201cpotential game changer for clinical practice\u201d 2 . The University of Western Ontario in London, Canada, soon lured Owen away from Cambridge with Can$20 million (US$19.5 million) in funding to make the techniques more reliable, cheaper, more accurate and more portable \u2014 all of which Owen considers essential if he is to help some of the hundreds of thousands of people worldwide in vegetative states. \u201cIt's hard to open up a channel of communication with a patient and then not be able to follow up immediately with a tool for them and their families to be able to do this routinely,\u201d he says. Communicating with vegetative patients. Many researchers disagree with Owen's contention that these individuals are conscious. But Owen takes a practical approach to applying the technology, hoping that it will identify patients who might respond to rehabilitation, direct the dosing of analgesics and even explore some patients' feelings and desires. \u201cEventually we will be able to provide something that will be beneficial to patients and their families,\u201d he says. Still, he shies away from asking patients the toughest question of all \u2014 whether they wish life support to be ended \u2014 saying that it is too early to think about such applications. \u201cThe consequences of asking are very complicated, and we need to be absolutely sure that we know what to do with the answers before we go down this road,\u201d he warns. \n               Lost and found \n             With short, reddish hair and beard, Owen is a polished speaker who is not afraid of publicity. His home page is a billboard of links to his television and radio appearances. He lectures to scientific and lay audiences with confidence and a touch of defensiveness. Owen traces the roots of his experiments to the late 1990s, when he was asked to write a review of clinical applications for technologies such as fMRI. He says that he had a \u201cweird crisis of confidence\u201d. Neuroimaging had confirmed a lot of what was known from brain mapping studies, he says, but it was not doing anything new. \u201cWe would just tweak a psych test and see what happens,\u201d says Owen. As for real clinical applications: \u201cI realized there weren't any. We all realized that.\u201d Owen wanted to find one. He and his colleagues got their chance in 1997, with a 26-year-old patient named Kate Bainbridge. A viral infection had put her in a coma \u2014 a condition that generally persists for two to four weeks, after which patients die, recover fully or, in rare cases, slip into a vegetative or a minimally conscious state \u2014 a more recently defined category characterized by intermittent hints of conscious activity. Months after her infection cleared, Bainbridge was diagnosed as being in a vegetative state. Owen had been using positron-emission tomography in healthy people to show that a part of the brain called the fusiform face area (FFA) is activated when people see a familiar face. When the team showed Bainbridge familiar faces and scanned her brain, \u201cit lit up like a Christmas tree, especially the FFA\u201d, says Owen. \u201cThat was the beginning of everything.\u201d Bainbridge was found to have significant brain function and responded well to rehabilitation 3 . In 2010, still in a wheelchair but otherwise active, she wrote to thank Owen for the brain scan. \u201cIt scares me to think of what might have happened to me if I had not had mine,\u201d she wrote. \u201cIt was like magic, it found me.\u201d Owen moved from visual to auditory tests \u2014 \u201cup the cognition ladder, from basic sound perception, to speech perception and then to speech comprehension\u201d. For example, he presented people in a vegetative state with phrases containing words that sound the same but have two meanings, such as \u201cThe dates and pears are in the bowl\u201d. The ambiguity forces the brain to work harder and shows up in characteristic fMRI patterns in healthy people \u2014 if, that is, they are comprehending the words. One of Owen's patients, a 30-year-old man who had been incapacitated by a stroke, showed the same pattern 4 . But not everyone was convinced that these signs pointed to comprehension. \u201cEvery time I would go to a neurologist or anaesthesiologist and say, 'he's perceiving speech', they'd ask 'but is he conscious?'.\u201d Owen realized that he needed a different experiment to persuade the sceptics. \n               Anyone for tennis? \n             It was June 2006. Wimbledon was on, and in a headline-stealing study, Owen took fMRI scans of a 23-year-old woman in a vegetative state while he asked her to imagine playing tennis and walking through the rooms of her house. When healthy, conscious adults imagine playing tennis, they consistently show activation in a region of the motor cortex called the supplementary motor area, and when they think about navigating through a house, they generate activity in the parahippocampal gyrus, right in the centre of the brain. The woman, who had been unresponsive for five months after a traffic accident, had strikingly similar brain activation patterns to healthy volunteers who were imagining these activities, proving, in Owen's mind, that she was conscious. The result, published in a one-page article in  Science 5 , evoked wonder and disbelief. \u201cI got two types of e-mail. People either said 'this is great' or 'how could you possibly say this woman is conscious?',\u201d Owen says. Other researchers contended that the response was not a sign of consciousness, but something involuntary, like a knee-jerk reflex. Daniel Greenberg, a psychologist at the University of California, Los Angeles, suggested in a letter to  Science  that \u201cthe brain activity was unconsciously triggered by the last word of the instructions, which always referred to the item to be imagined\u201d 6 . But Owen went on to bolster his case. Working with neurologist and neuroscientist Steven Laureys from the University of Li\u00e8ge, Owen showed that of 54 patients in a vegetative or minimally conscious state, five responded in the same way as the first woman 1 . Four of them were in a vegetative state. After refining their methods, the researchers asked patient 23 to use that capability to answer yes-or-no questions: imagine playing tennis for yes, navigating the house for no. They then asked about things that the technicians scoring the brain scans couldn't possibly know. Is your father's name Thomas? No. Is your father's name Alexander? Yes. Do you have any brothers? Yes. Do you have any sisters? No. The experiment is no easy feat for the patient. Owen's protocol demands patients maintain focus for 30 seconds then rest for 30 seconds, with lots of repetition. In front of a computer screen showing the fMRI data, Owen traces a blue line indicating activity in the supplementary motor area \u2014 a 'yes' \u2014 as it rises during the 'answer' period. It dives during the rest periods. A red line \u2014 indicating activity in the parahippocampal gyrus \u2014 represents the 'no'. The lines are sharp and clear, and Owen, who has a taste for puns, calls the implication \u201ca no-brainer\u201d. \u201cYou don't need to be a functional-imaging expert to appreciate what this person is telling you,\u201d he says. The patient answered five of six questions correctly 1 . There was no discernible signal for the sixth. Russell Poldrack, a neuroimaging expert at the University of Texas at Austin, calls Owen's methods ingenious. \u201cWhen I want to give someone examples in which fMRI has told us something we really didn't know before, I use these,\u201d he says. But Parashkev Nachev, a clinical neuroscientist at Imperial College London, criticizes the work for \u201cassuming that consciousness is a binary phenomenon\u201d. Many patients, such as those having certain types of epileptic seizures, exhibit limited responsiveness without being conscious. Nachev says that more data are needed to indicate where in the continuum of cognitive abilities people in vegetative states fall. Owen agrees that consciousness is not an \u201con-or-off thing\u201d. He sees it as an \u201cemergent property\u201d of many \u201cmodules\u201d of the brain working together. Enough of these modules are at work in his exercise, he says, for responsive patients to qualify as being conscious. A person needs long-term memory to know what tennis is, short-term memory to remember the question or command and intention to give an answer. Ultimately, Owen is not concerned with pinpointing a threshold of consciousness or with providing a comprehensive definition for it. He takes a \u201cknow it if you see it\u201d approach. Responding to commands and questions \u2014 communication \u2014 is an undeniably conscious activity, in his view. \u201cIn the end if they say they have no reason to believe the patient is conscious, I say 'fine, but I have no reason to believe you are either',\u201d he says. \n               To the clinic \n             Currently, there are tens of thousands of people in a vegetative state in the United States alone. Owen reckons that up to 20% of them are capable of communicating; they just don't have a way to do so. \u201cWhat we're seeing here is a population of totally locked-in patients,\u201d Owen says. Owen now wants to put his technique into the hands of clinicians and family members. So far, the technology has done little. The first woman in the tennis study died last year, and patient 23, for logistic and financial reasons, was assessed only once. Even if a person in a vegetative state is 'found', there is no guarantee that he or she will later be able to return a normal life. Owen nevertheless insists that \u201cclarifying\u201d a patient's state of consciousness helps families to deal with the tragedy. \u201cThey want to know what the diagnosis really is so that they can move on and deal with that. Doubt and uncertainty are always bad things.\u201d Two years ago, Owen was awarded a 7-year Can$10-million Canada Excellence Research Chair and another $10 million from the University of Western Ontario. He is pressing forward with the help of three new faculty members and a troop of postdocs and graduate students. An early goal of the programme was to repeat the fMRI findings using an electroencephalogram (EEG) 7 . An EEG lacks fMRI's precision, and it cannot look as deeply into the brain, so the regions active in the tennis study were \u201coff the menu\u201d, says Owen. But other tasks \u2014 imagining wiggling a finger or toe \u2014 produce signals that, through repetition, become clear. An EEG is also cheap, relatively portable and fast (with milliseconds of lag compared with 8 seconds for fMRI), meaning that the research team can ask up to 200 questions in 30 minutes. \u201cFrom a single trial you're not going to say, 'that person is saying yes', but if they get 175 of 190 right when tested, it's pretty clear.\u201d Now, using an EEG, Owen is planning to study 25 people in a vegetative state every year. He will have the help of a new 'EEGeep', a jeep equipped with experimental equipment that will allow the researchers to travel around to test patients who cannot be transported to Western Ontario. One goal is to identify other brain systems, such as smell or taste, that might be intact and usable for communication. Imagining sucking a lemon, for example, can produce a pH-level change in the mouth and a recognizable brain signal 8 . Owen has shown that registering jokes provokes a characteristic response in healthy people 9  and plans to try it on patients in a vegetative state. He hopes that he can use these tests to find some level of responsiveness in patients who cannot produce the tennis and navigation patterns of activity because of their level of brain damage. The studies will also explore whether these patients have the capacity for greater intellectual depth. Owen thinks that some people in a vegetative state will eventually be able to express hopes and desires, perhaps like French magazine editor Jean-Dominique Bauby, who dictated his memoirs by repeatedly winking one eye. \u201cI don't see a reason why they could not have a similar richness of thought, although undoubtedly some will not,\u201d Owen says. His techniques could also radically change treatment. Owen is already asking patients whether they feel pain. The answers will be useful in dosing pain killers, and similar tests could even be used in intensive-care units to guide rehabilitation resources, says Loretta Norton, a graduate student who is undertaking a study for this purpose. But she recognizes that this will be controversial. \n               Decision time \n             Owen's methods raise more difficult dilemmas. One is whether they should influence a family's or clinician's decision to end a life. If a patient answers questions and demonstrates some form of consciousness, he or she moves from the 'possibly allowed to die' category to the 'not generally allowed to die' category, says Owens. Nachev says that claiming consciousness for these patients puts families in an awkward position. Some will be given hope and solace that their relative is still 'in there somewhere'. Others will be burdened by the prospect of keeping them alive on the basis of what might be ambiguous signs of communication. Even more ethically fraught is whether the question should be put to the patients themselves. Fins and Schiff question whether patients would ever be able to show that they can understand the complexities of that question in the way that is normally demanded of, for example, patients giving informed consent. Owen hopes one day to ask patients that most difficult of questions, but says that new ethical and legal frameworks will be needed. And it will be many years, he says, \u201cbefore one could be sure that the patient retained the necessary cognitive and emotional capacity to make such a complex decision\u201d. So far, he has stayed away from the issue. \u201cIt might be a little reassuring if the answer was 'no' but you can't presuppose that.\u201d A 'yes' would be upsetting, confusing and controversial. For now, Owen is hoping to use the technology to find other responders like Kate Bainbridge \u2014 who Owen now describes as a \u201cmotivational force\u201d. \u201cOtherwise,\u201d he says, \u201cwhat's the point?\u201d \n                     Controversial research: Good science bad science 2012-Apr-25 \n                   \n                     Out-of-body experience: Master of illusion 2011-Dec-07 \n                   \n                     Out-of-body experience: Master of illusion 2011-Dec-07 \n                   \n                     Neuroscience: Capturing free will 2011-Oct-19 \n                   \n                     Brain scan allows unconscious patient to communicate 2010-Feb-03 \n                   \n                     Looking for hidden signs of consciousness 2007-Mar-21 \n                   \n                     Nature Neuroscience \n                   \n                     Adrian Owen \n                   Reprints and Permissions"},
{"file_id": "486174a", "url": "https://www.nature.com/articles/486174a", "year": 2012, "authors": [{"name": "Ivan Amato"}], "parsed_as_year": "2006_or_before", "body": "Two physicists say they have forced hydrogen to become an exotic metal thought to exist only in the hearts of giant planets. Now they must face their critics. Mikhail Eremets and Ivan Troyan work only with the very best, gem-quality diamonds. Nothing else can handle the stresses involved \u2014 not when the two physicists make a habit of forcing the diamonds' tips together until the pressure between them reaches levels normally found at the centre of the Earth. Eremets and Troyan, both at the Max Planck Institute for Chemistry in Mainz, Germany, are not alone in this strange pursuit. Their apparatus, known as a diamond anvil cell, is a standard fixture in high-pressure research labs. But they have provoked widespread agitation in their research community by claiming to have crushed hydrogen in their cells until it gave up being a diatomic gas, and instead became a shiny, presumably monatomic, solid that conducted electricity like a metal. The arguments over this alleged discovery \u2014 one of the most sought-after results in high-pressure research \u2014 have been raging ever since Eremets and Troyan published their results last November 1 . \u201cWe could just read their paper and say it was wrong,\u201d declares condensed-matter physicist William Nellis, an associate of Harvard University's physics department in Cambridge, Massachusetts, and one of the team's most vocal challengers 2 . But others, such as Raymond Jeanloz, a planetary scientist and high-pressure-materials researcher at the University of California, Berkeley, are keeping an open mind. Whether Eremets and Troyan are eventually proved right or wrong about metallic hydrogen, Jeanloz says, \u201cwhat I feel is beautiful about their work is that they did a bazillion different experiments at these extreme conditions. They lit a fire under a couple of research groups.\u201d On 26 June, the main figures in this controvery will gather in Biddeford, Maine, during a Gordon Research Conference on high-pressure science. The result could be a meeting of minds \u2014 or a display of fireworks. \u201cThis is a very intense field,\u201d says Jeanloz. High-pressure scientists have been trying \u2014 and failing \u2014 to make metallic hydrogen ever since theorists first predicted its existence in 1935 (ref.  3 ). Anyone claiming success can expect an all-out critique from rival groups \u2014 especially considering what is at stake. Not only would making metallic hydrogen in the laboratory allow researchers to do planetary science at the bench \u2014 gas-giant planets such as Jupiter, or the even larger ones being discovered around distant stars, are thought to have huge amounts of the stuff in their interiors \u2014 but it could point the way towards an entirely new world of high-pressure phenomena. \u201cHydrogen is the simplest atom, the simplest molecule and perhaps the most complicated elemental solid,\u201d says Arthur Ruoff, a high-pressure physicist at Cornell University in Ithaca, New York. In 1968, Cornell physicist Neil Ashcroft predicted that solid metallic hydrogen might be a superconductor 4 . In 2004, calculations 5  by Ashcroft and others suggested that, under certain combinations of pressure and temperature, hydrogen atoms would rearrange themselves into a new kind of quantum liquid with attributes of both superconductors, which conduct electricity without resistance, and superfluids, which flow without resistance. \n               Bright future \n             Such exotic behaviours become particularly interesting if some of these phases of hydrogen turn out to be metastable. This would mean that the phases could retain their high-pressure forms for an indefinite period once external forces are removed, much as diamonds formed by high temperatures and pressures deep inside Earth remain diamonds even after they reach the surface, instead of immediately reverting to carbon's more stable form, graphite. Nellis and others have imagined a host of applications for metastable metallic hydrogen, ranging from super-lightweight structural materials that would allow entire cities floating on the sea to be built, to rocket fuel that packs nearly four times as much propellant power per kilogram as the liquid hydrogen used in the most powerful rockets today 6 . First, however, comes the reality check. Diamond anvil cells can use only vanishingly small sample sizes. (The volume of Eremets and Troyan's hydrogen samples was about 160 cubic micrometres \u2014 somewhat smaller than an average human cell.) High-pressure experiments are fraught with the potential for error. And even the most experienced researchers run the risk of fooling themselves. The question is whether Eremets and Troyan are among them. In their experiments 1 , the Mainz physicists started with pairs of brilliant-cut diamonds. They trimmed each of the diamonds' points into a flat surface, or culet, 20\u201330 micrometres across, then aligned the diamonds with those truncated tips almost touching, on either side of a piece of metal foil pierced with a culet-sized hole that would enclose a minuscule experimental chamber. \n               Through a gem darkly \n             For each experiment, Eremets and Troyan loaded hydrogen gas into the hole, and started tightening a set of screws that forced the diamonds closer together. As the culets bit into the foil at the rim of the hole, the metal deformed around them to form a seal trapping the hydrogen. And as the force exerted by the screws was focused down onto the culets, the pressure in the chamber began to skyrocket. This is where high-pressure experiments often go awry. Although the anvil's diamond jaws are made of one of the hardest materials known, superpressured hydrogen routinely infiltrates them, making them brittle and causing the gems to crack like cheap plastic cups. This also spoils the gemstones' transparency, stopping the physicists from seeing what is happening in the chamber. Eremets and Troyan addressed that problem by applying semi-transparent coatings to protect their diamonds from the infiltration of hydrogen. But even so, they went through about 100 pairs of diamonds as they worked out the bugs of their apparatus and ran trials and controls. When the pressure inside their anvils reached 200 billion pascals (200 GPa), or about 2 million times Earth's atmospheric pressure at sea level, the two Mainz physicists saw spectroscopic signs that the diatomic hydrogen molecules had begun to interact in a way that signalled that they were becoming a solid. At 220 GPa, the sample chamber became dark, another sign that hydrogen had apparently assumed a condensed phase. Eremets and Troyan found that laser pulses fired through the transparent diamond triggered small flows of electrons that they could detect by means of copper and gold electrodes deposited on the culet surfaces \u2014 behaviour characteristic of semiconducting materials, in which electrons need a small energy kick to flick them out of orbit around atoms and into a conductive flow. At 240 GPa, Eremets and Troyan recorded small currents even without the laser shots, an indication that room-temperature thermal vibrations alone could nudge the electrons into a conductive mood. And at about 270 GPa, the researchers saw their samples' electrical resistance suddenly drop by several orders of magnitude, just as their spectroscopy was showing that the hydrogen's molecular vibrations were slowing down and morphing in ways suggestive of a phase transition \u2014 and the samples were becoming shiny like a metal. \u201cIt is hard to sit on data like these,\u201d says Eremets. He and Troyan are convinced that their findings are at least consistent with having made metallic hydrogen. But others are not so sure. Sceptics note that pitfalls are everywhere in experiments such as these. If an experimenter peers through the diamonds and sees the sample begin to darken, for example, that may mean that it is becoming a solid \u2014 or that the hydrogen is reacting with the foil or other impurities to form metal hydrides. If odd electrical signals start coming in from the culet electrodes, they may indicate the formation of a new phase of hydrogen \u2014 or that the diamond jaws are deforming, causing the electrodes to short out or emit spurious signals. Eremets says that he and Troyan are well aware of such pitfalls, and did their best to avoid them. Nonetheless, says Ruoff, \u201cI don't know anybody who thinks their claim is valid\u201d. One fact that troubles Ruoff and other critics is that the resistance rises as the sample's temperature drops. This is contrary to normal metallic behaviour, in which the resistance goes down as the temperature does. But when reviewers of the paper raised that issue, says Eremets, he successfully argued that the upward trend is consistent with that seen in a disordered metal, in which the atomic structure is more like that of a glass than a crystal. Russell Hemley, a high-pressure-materials researcher at the Carnegie Institution of Washington in Washington DC, is sceptical of Eremets and Troyan's claims for another reason: if the hydrogen really becomes metallic, then the shininess that the Mainz team reports at optical wavelengths ought to be accompanied by equally strong reflectivity at infrared wavelengths. Eremets and Troyan were not able to get good infrared data on their samples. But Hemley says that in his own experiments with hydrogen at similar pressures, \u201cwe see it transmitting\u201d in the infrared. Moreover, in a paper published in April 7 , Hemley and his colleagues report signs that hydrogen squeezed up to 360 GPa holds on to its diatomic character and fails to morph into a monatomic metal. Adding to the complexity of the situation, some theorists suggested 8  that, if squeezed enough, even intact hydrogen molecules might develop a new and crowded bonding pattern that could have metallic properties. Eremets and Troyan are standing their ground. \u201cOur measurements are not perfect,\u201d Eremets concedes, but he insists that \u201cmetallic hydrogen remains a viable interpretation\u201d. He points to a paper published in March 9  by Eugene Gregoryanz, a physicist at the University of Edinburgh, UK, and his colleagues. \u201cThey observe a new phase, the same Raman spectra and a darkening of the sample\u201d at around 220 GPa, says Eremets. Clearly, he argues, something is happening at that point \u2014 although Gregoryanz and his colleagues attributed the changes to formation, not of metallic hydrogen, but of a previously unseen, graphene-like phase of molecular hydrogen. In an effort to clarify the situation, Eremets and Troyan travelled to Villigen in Switzerland in late April, to gather infrared spectra using the synchrotron light source at the Paul Scherrer Institute there. The data could reveal vibrations in the lattice structures of high-pressure hydrogen samples that would help theoreticians to identify specific structures of any solid phases that might be present, Eremets says. Such structural information would not, by itself, prove that the hydrogen had become metallic. But Eremets and Troyan also plan to attempt more thorough and extensive electrical measurements, which could prove conclusive. Looking back, Eremets admits that he and Troyan probably should have been more circumspect in their paper \u2014 conveying the message that they might have made metallic hydrogen, rather than claiming more strongly that they had done so, as they did in their abstract and their concluding paragraphs. Meanwhile, the race for metallic hydrogen continues, as other high-pressure research groups pursue their own experiments. Jeanloz points out that many members of this community, himself included, have mingled over the years as collaborators, postdocs, supervisors and mentors, only to go on to become each other's staunchest critics and rivals, unlikely to let the slightest chink in an argument go unchallenged. What emerges from this dynamic, say Jeanloz and others, is a creative tension that could eventually force those who claim to have produced metallic hydrogen to do enough experiments, with enough controls, to compile enough lines of evidence to convince even the pickiest of critics. Until then, the trophy seems to be up for grabs. \n                     Earth science: Probing the core's light elements 2011-Nov-23 \n                   \n                     Chemistry: Hydrogen made metallic 2011-Nov-23 \n                   \n                     High-pressure physics: Testing one's metal 2011-Nov-23 \n                   \n                     New materials from high-pressure experiments 2002-Sep-02 \n                   \n                     Great balls of metal 2000-Jun-20 \n                   \n                     Metallic hydrogen and beyond 1989-Aug-03 \n                   \n                     Scientific American: Making metallic hydrogen \n                   Reprints and Permissions"},
{"file_id": "486312a", "url": "https://www.nature.com/articles/486312a", "year": 2012, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "As researchers find more uses for data, informed consent has become a source of confusion. Something has to change. Late in May, the direct-to-consumer gene-testing company 23andMe proudly announced the impending award of its first patent. The firm's research on Parkinson's disease, which used data from several thousand customers, had led to a patent on gene sequences that contribute to risk for the disease and might be used to predict its course. Anne Wojcicki, co-founder of the company, which is based in Mountain View, California, wrote in a blog post that the patent would help to move the work \u201cfrom the realm of academic publishing to the world of impacting lives by preventing, treating or curing disease\u201d. Some customers were less than enthusiastic. Holly Dunsworth, for example, posted a comment two days later, asking: \u201cWhen we agreed to the terms of service and then when some of us consented to participate in research, were we consenting to that research being used to patent genes? What's the language that covers that use of our data? I can't find it.\u201d The language is there, in both places. To be fair, the terms of service is a bear of a document \u2014 the kind one might quickly click past while installing software. But the consent form is compact and carefully worded, and approved by an independent review board to lay out clearly the risks and benefits of participating in research. \u201cIf 23andMe develops intellectual property and/or commercializes products or services, directly or indirectly, based on the results of this study, you will not receive any compensation,\u201d the document reads. The example points to a broad problem in research on humans \u2014 that informed consent is often not very well informed (see 'Reading between the lines'). Protections for participants have been cobbled together in the wake of past controversies and have always been difficult to uphold. But they are proving even more problematic in the 'big data' era, in which biomedical scientists are gathering more information about more individuals than ever before. Many studies now include the collection of genetic data, and researchers can interrogate those data in a growing number of ways. Several US states, including California, are considering laws that would curtail the way in which researchers, law-enforcement officials and private companies can use a person's DNA. The research coordinators who develop consent forms cannot predict how such data might be used in the future, nor can they guarantee that the data will remain protected. Many people argue that participants should have more control over how their data are used, and efforts are afoot to give them that control. Researchers, meanwhile, often bristle at the added layers of bureaucracy wrought by the protections, which sometimes provide no real benefits to the participants. The result is a mess of opinions and procedures that sow confusion and risk deterring people from participating in research. \u201cA lot of times researchers will say, 'Why can't we just go back to the way it was?', which was basically that we take these samples and people do it for altruistic reasons and everything's lovely,\u201d says Sharon Terry, president of the patient-advocacy group Genetic Alliance in Washington DC. \u201cThat worked in a prior age. I don't think it works today.\u201d The concept of informed consent was first set out in the Nuremberg Code, a set of research-ethics principles adopted in the wake of revelations of torture by Nazi doctors during the Second World War. But in recent years, a series of mishaps over consent have undermined support for research. In 2004, for example, scandal erupted in the United Kingdom after parents found out that from the late 1980s to the mid-1990s doctors and researchers had removed and stored organs and tissues from patients \u2014 including infants and children \u2014 without parental consent. New laws were passed that required explicit consent for such collections. Then, in 2010, the Havasupai tribe of Arizona won a US$700,000 settlement against Arizona State University in Phoenix. Individuals believed that they had provided blood for a study on the tribe's high rate of diabetes, but the samples had also been used in mental-illness research and population-genetics studies that called into question the tribe's beliefs about its origins. In the settlement, the university's board of regents said that it wanted to \u201cremedy the wrong that was done\u201d. The cases illustrate the divide between researchers and the public over what people need to know before agreeing to participate in research. Many of the recent concerns over consent are driven by the rapid growth of genome analysis. Decades ago, researchers weren't able to glean much information from stored tissue; now, they can identify the donor, as well as his or her susceptibilities to many diseases. Researchers try to protect the genetic data through technological and legal mechanisms, but both approaches have weaknesses. It is not enough to strip out any information that would identify the donor, such as names and full health records, before the data are stored. In 2008, geneticists showed that they could easily identify individuals within pooled, anonymized data sets if they had a small amount of identified genetic information for reference (N. Homer  et al .  PLoS Genet   4 , e1000167; 2008 ). And it may become possible to identify a person in a public database from other information collected during a study, such as data on ethnic background, location and medical factors unique to the study participants, or to predict a person's appearance from his or her DNA. Even legal mechanisms have vulnerabilities. In 2004, Jane Costello, a social psychologist at Duke University in Durham, North Carolina, was forced to go to court to defend the confidentiality of patient records from the Great Smoky Mountains Study. The study, which is just going into its third decade, examines emotional and behavioural problems in a cohort of people who enrolled as adolescents. A participant in the study was testifying against her grandfather, John Trosper 'JT' Bradley, who had been accused of sexual abuse. JT's lawyers subpoenaed the granddaughter's records from the study in hope that the information would undermine her credibility as a witness. It meant a major crisis of confidence for Costello. \u201cI was telling 1,400-plus people every time we saw them that 'your data are absolutely safe', and now I was in a position where I was told, 'No, that's not true',\u201d she says. After Costello's day in court, in August 2004, the records remained sealed, but mostly because the judge did not believe that they would exonerate JT. The result provided no clarity about patient protections. \n               Better models for consent \n             One solution is to keep genetic information separate from demographic data. The BioVU databank at Vanderbilt University Medical Center in Nashville, Tennessee, for instance, contains DNA samples from patients treated at the hospital \u2014 143,939 people as of 11 June. The DNA is linked to health records in a second database, called a 'synthetic derivative', in which the data are anonymized and scrambled in ways that, its creators say, make it difficult for anyone to work back from the database to verify a patient's identity. Sample-collection dates are altered, for example, and some records are discarded at random, so that it is not possible to know that someone is in the database just because he or she was treated at the hospital. Even researchers who work with the data cannot determine whose data they are using. The databank expects to include as many as 200,000 individuals by 2014, making it one of the largest collections of linked genetic and health records in the world. But when it comes to consent, BioVU takes a different approach from many other programmes. Patients don't choose to participate; rather they are given the chance to opt out. Patients are asked to sign a 'consent to treat' form every year. It includes a box that they can tick to keep their DNA out of the database. That model helps BioVU to collect many more samples, and much more cheaply, than other projects can. The opt-out model \u2014 which is used in only a few other places \u2014 troubles Misha Angrist, a genome policy analyst at Duke University, who says that it risks taking advantage of people when they are ill. \u201cEven a routine visit to the clinic can be a vulnerable moment, and they're saying, 'Would you mind doing this for future generations, to help people just like you?'.\u201d And legal challenges have shown the weaknesses of opt-out policies. Health officials are now destroying millions of blood samples taken from newborn babies in Texas and Minnesota because the families were not adequately informed that the samples, collected to screen for specific inherited disorders, would also be used in research. Vanderbilt officials and researchers counter that they have run extensive public campaigns to ensure that people in Nashville are aware of BioVU and are comfortable with the way it works. They regularly consult a community advisory board about the project. And Vanderbilt's approach actually goes above and beyond what is required by federal law; because the synthetic derivative includes de-identified data, it doesn't legally require informed consent at all. Last July, the US Department of Health and Human Services signalled that it might be rethinking the rules that exempt de-identified data from the consent requirement, as part of a broad overhaul of research ethics regulations. Irrespective of the outcome, obliterating patient identities has drawbacks. Researchers can't perform some types of research on the scrambled data. Because dates are changed, studies on the timing of influenza infections, for example, are impossible. And patients can't be told if the research has revealed that they carry individual genetic risks linked to disease. \n               Full disclosure \n             Returning study results to research participants has been another thorny issue for consent. Doctors might learn about genetic predispositions to disease that are separate from the ailments that led a patient to participate in the research in the first place, but it is not clear what they should do with this information. UK researchers, for example, are forbidden from sharing genetic results with participants. But US research societies, such as the American College of Medical Genetics and Genomics in Bethesda, Maryland, are moving towards adopting standards that would encourage the practice for some types of findings, such as those that are medically relevant. Some countries, such as Germany, Austria, Switzerland and Spain, are already feeding back such information. And some clinical sequencing programmes are considering offering patients 'tiered' consent, in which people can decide whether to be told about their data and how much they want to learn. This is what Han Brunner, a geneticist at the Radboud University Nijmegen Medical Centre in the Netherlands, had hoped to do. Last year, he began a project to sequence the exomes \u2014 the protein-coding regions of the genome \u2014 of 500 children and adults, looking for the genetic causes of intellectual disabilities, blindness, deafness and other disorders. Brunner proposed allowing participants to choose from three options: they could learn everything that researchers had divined about disease susceptibility; just information relevant to the disease for which their genomes were examined; or no information at all. Ethics reviewers shot down his proposal. \u201cThey said that in practice, it would be impossible for people to draw those lines, because people giving consent cannot foresee all the possible outcomes of the study,\u201d Brunner says. Instead, everyone participating in the studies must agree to learn all medically relevant information arising from the analysis of their genomes. As a consequence, Brunner recently had to tell the family of a child with a developmental disability that the child also has a genetic predisposition to colon cancer. Not all researchers endorse the idea of informing children about diseases that might affect them as adults. In this case, doctors recommended early screening, and Brunner says, \u201cthe family handled it very well; they said, 'This is not what we anticipated, but it's useful information'\u201d. Many of the studies done now ask patients to give consent for research linked to particular investigators or diseases. But that means that researchers cannot pool data from separate studies to tackle different research questions. Many researchers say that the obvious solution is a broad consent document that gives researchers free rein with the data. But many non-scientists think participants should be able to control how their data are used, says lawyer Tim Caulfield of the University of Alberta in Calgary, Canada, who has surveyed patients about this idea. \u201cThere's an emerging consensus within the research community about the need to adopt things like broad consent, but that hasn't translated out to the legal community or to the public,\u201d he says. Another solution might be called 'radical honesty'. A US project called Consent to Research, which aims to provide a large pool of user-contributed genomic and health data, has devised what it calls a 'Portable Legal Consent', which allows anyone to upload information about him or herself, such as direct-to-consumer genetic results and lab tests ordered through medical providers, to an interface that strips the data of identifiers. It makes the data widely available to researchers under broad guidelines, but also requires data donors to go through a much more rigorous consent process than most studies do. The Portable Legal Consent specifically informs participants that researchers might be able to determine their identities, but that they are forbidden from doing so under the project's terms of use. Such approaches could help scientists by giving them access to a trove of data with no restrictions on use. But the participant protections system that is in place might not be ready for such frank dialogues, says Angrist, who serves on one of Duke's institutional review boards. While reviewing a research proposal for a large biobank, for example, Angrist suggested that the researchers send the participants an annual e-mail explaining how their samples were being used, and thanking them for donating their time and tissue. The review board voted this suggestion down after its chair argued that e-mailing the patients would create a problem in light of the Health Insurance Portability and Accountability Act (HIPAA) \u2014 the US law that guarantees the privacy of health records. \u201cThe irony is that the HIPAA is supposed to protect people, and what I was hearing was, 'We can't talk to people because we're too busy protecting them',\u201d Angrist says. \u201cInstitutions use informed consent to mitigate their own liability and to tell research participants about all the things they cannot have, and all the ways they can't be involved. It borders on farcical.\u201d But as patient data become more precious to researchers, and as advocacy organizations become more involved in driving research agendas and in funding the work, such paternalistic attitudes will probably not survive, says Terry. She adds that technologies that allow research participants to control and track how researchers use their data will soon catch on. These approaches could benefit patients, who gain transparency and control over their data, and researchers, who gain access to richer data sets. \u201cI think we're going to have to get to a place where consenting people becomes customizable easily through technology, and we're not there yet,\u201d Terry says. See Editorial  page 293 \n                     Open-data project aims to ease the way for genomic research 2012-Apr-25 \n                   \n                     DNA donor rights affirmed 2012-Mar-21 \n                   \n                     Sequencing set to alter clinical landscape 2012-Feb-15 \n                   \n                     Secrets of the human genome disclosed 2011-Oct-04 \n                   \n                     Human-subjects research: Trial and error 2007-Aug-01 \n                   \n                     Blogpost: Personal-genetics company patent raises hackles - May 31, 2012 \n                   \n                     Blogpost: Geneticists debate what to tell patients about clinical genome sequences - March 20, 2012 \n                   \n                     Personalized medicine: Bring clinical standards to genomic research \n                   \n                     Genetic Alliance \n                   \n                     NIH information on certificates of confidentiality \n                   \n                     US Department of Health and Human Services notice of proposed rulemaking on human subjects research protections \n                   \n                     Consent to Research \n                   Reprints and Permissions"},
{"file_id": "485570a", "url": "https://www.nature.com/articles/485570a", "year": 2012, "authors": [{"name": "Virginia Hughes"}], "parsed_as_year": "2006_or_before", "body": "Once thought to be passive sentinels, microglia now seem to be crucial for pruning back neurons during development. The work required the mind of an engineer and the hands of a surgeon. Axel Nimmerjahn had both. It was 2002 when Nimmerjahn, then a graduate student at the Max Planck Institute for Medical Research in Heidelberg, Germany, began trying to spy on the everyday activity of the mysterious brain cells known as microglia. Others had caught glimpses of the cells in their spider-like resting state, but only in slices of dead tissue. No one had been able to see them in a live brain. That's because microglia \u2014 which, unlike other cells in the brain, are part of the immune system \u2014 are extremely sensitive. Cut a nerve, or release infectious bacteria into brain tissue, and microglia spring into action, retracting their many appendages and morphing into big, round blobs that gobble up pathogens and clear away cellular wreckage. To see the cells without disturbing them, Nimmerjahn used a newly published approach for imaging a live mouse brain 1 . After anaesthetizing the animal and peeling back its scalp, he removed the top two-thirds of the skull's thickness and shaved the bone down to just 20 micrometres \u2014 thin enough for light to penetrate, but thick enough to avoid setting off the microglia. The work progressed slowly \u2014 Nimmerjahn had to douse the surgical site with cooling fluid after realizing that even the heat from scraping could aggravate the cells. But within a few months at the bench, he was able to record some time-lapse movies 2 . He was floored by what he saw: 'resting' microglia are anything but. Their delicate branches snake through densely packed brain tissue, constantly extending and shrinking and re-growing. \u201cThey're very dynamic, much more than any other cell in the adult brain,\u201d says Nimmerjahn, now a biophysicist at the Salk Institute in La Jolla, California. He calculated that the cells' concerted movements could survey the entire brain every couple of hours. But it was unclear why the microglia were moving so much, Nimmerjahn says. \u201cWhy does the brain invest so much energy?\u201d \n               Coded signals \n             Nimmerjahn is not the only researcher intrigued by this question. A flurry of studies during the past two years \u2014 the latest published last week in  Neuron 3 \u2014 have investigated microglia's influence in adult and developing brains. The results are overturning the idea that microglia are passive immune sentinels. Several groups have proposed that these shape-shifting cells not only eat up invaders and damaged tissue, but also trim away weak connections, or synapses, between neurons. This pruning process occurs on a large scale in the developing brain, and it is known to be important in learning and memory. Neurodevelopmental disorders such as autism and schizophrenia are often associated with faulty pruning. Two provocative studies have suggested that mouse models of obsessive-compulsive disorder 4  and Rett syndrome 5 , an autism spectrum disorder, show marked improvements after their microglia are replaced. But many questions remain. No one knows how microglia 'talk' to neurons or other cells, or whether their functions are limited to certain brain regions, notes Richard Ransohoff, a neurologist at the Cleveland Clinic in Ohio and a co-author of the latest  Neuron  report. But, he adds, that makes the field ripe for discovery. \u201cThe possible ramifications of these observations, for both developmental diseases like autism and degenerative diseases like Alzheimer's, are virtually endless.\u201d For more than a century, neurons have been the stars of neuroscience. But they account for only about 10% of the cells in the human brain. The balance is made up by different types of glia, which surround and support neurons and influence neuronal signalling. Oligodendrocytes, for example, create fatty sheaths that encase long neuronal branches and help to speed up electrical impulses. Astrocytes surround synapses and have been shown to affect neuronal signalling by controlling the mix of chemical messengers at neuronal junctions. Microglia are quite different from their neighbours. Unlike neurons and other glial cells, they begin in the embryonic yolk sac as immune-cell progenitors, just as the macrophages that patrol the bloodstream for foreign invaders do. During prenatal development \u2014 within eight embryonic days in a mouse \u2014 microglia migrate to the brain, where they become its dedicated immune cells. Researchers assume that the brain needs microglia because the blood\u2013brain barrier seals it off not only from toxins, pathogens and some drugs in the bloodstream, but also from the immune cells circulating there. Microglia spring into action in most brain diseases, engulfing pathogens, dead cells and misfolded proteins. They also clear away synapses that have been damaged by injury. It is not a big intellectual leap, then, to suppose that microglia have similar roles in the healthy brain, says Helmut Kettenmann, a neurobiologist at the Max Delbr\u00fcck Center for Molecular Medicine in Berlin, Germany, who has studied glia for the past 30 years. Given the spate of new imaging studies, he says, \u201cI think microglia cells are probably extremely important for synapse remodelling and plasticity in development.\u201d The idea is gaining traction. At the annual meeting of the Society for Neuroscience last November, when some 30,000 neuroscientists convened in Washington DC, the organizers held a session on microglia for the first time. It was packed. The society later circulated a list of the ten most-searched terms on the meeting's website. 'Microglia' was number six, just behind dopamine, optogenetics and schizophrenia. The momentum has been building since April 2005, when Nimmerjahn published his movies 2 . A month later, a team led by Wen-Biao Gan \u2014 a neuroscientist at New York University, who first developed the skull-thinning method \u2014 published similar results 6 . \u201cThis was a major breakthrough and inspired a lot of people,\u201d says Marie-\u00c8ve Tremblay, a postdoctoral researcher at the University of Wisconsin\u2013Madison who studies the role of microglia in sleep and wakefulness. In 2010, Tremblay and her colleagues published a report on the activity of microglia in the visual cortex of young mice. In rodents and in people, this region is known for its plasticity: the animal begins life with a large number of synapses, and then the ones that are not activated by light input from the eyes are gradually pruned away. Tremblay's study showed that microglia seem to interact with small synapses that disappear within a couple of days. Moreover, when she housed the animals temporarily in darkness \u2014 effectively dampening neural activity in the visual cortex \u2014 microglia changed into their active, blobby form and seemed to hug synapses more snugly 7 . Around the same time, other scientists were watching microglia in another highly plastic region of the developing mouse brain \u2014 the hippocampus, which is important for learning and memory. They examined young mice lacking the fractalkine receptor protein, which is expressed only by microglia and which binds fractalkine, a protein present on neurons. The mutant mice have an abundance of weak and immature synapses in the hippocampus, according to a study 8  published last September. By the time the mutant mice are adults, the number of synapses normalizes, but the researchers have unpublished data showing that some other synaptic problems remain. \u201cMy guess is that there's probably a very close signalling going on between neurons and microglia, back and forth, that coordinates which synapses they prune,\u201d says Cornelius Gross, a neuroscientist at the European Molecular Biology Laboratory in Monterotondo, Italy, who led the study. The trouble is that none of these studies indicate what that signal is. \u201cWhat you'd like to find is some sort of an 'eat-me' marker, like in  Alice in Wonderland , displayed on synapses that are to be pruned,\u201d Gross says. The latest report in  Neuron  claims to have identified such a tag 3 . \n               Full complement \n             The study's roots date back to 2007, when Ben Barres, a neurobiologist at Stanford University in California, together with postdoc Beth Stevens and their colleagues, showed that pruning in a deep area of the visual system \u2014 part of the thalamus called the lateral geniculate nucleus, or LGN \u2014 depends on certain proteins in the complement cascade, part of the innate immune system that helps to clear out pathogens and unwanted cells. The researchers reported that complement proteins are expressed by immature neuronal cells and are more likely to show up around immature synapses than elsewhere during key periods of brain development. Mice that lack complement proteins show a mess of unrefined neural connections 9 . According to Barres, all of this suggested that the complement system was responsible for tagging weak synapses for pruning. But how could this tagging lead to synapse removal? \u201cOur obvious hypothesis was that it might work exactly the same way as it works in the immune system,\u201d Barres says. In the bloodstream, complement proteins tag harmful bacteria, signalling for macrophage cells to come along and eat them. Microglia are both the brain's resident macrophages and the only brain cells that express the complement receptor. Nimmerjahn, who happened to be starting a postdoc with Barres at the time, had already shown that microglia were interacting with synapses in the mature brain. But nobody knew anything about what microglia were doing in the young brain. Stevens focused on that question beginning in late 2008, when she launched her own lab at Boston Children's Hospital in Massachusetts. The  Neuron  paper is her team's first publication. Dori Schafer, a postdoc in Stevens's lab, designed an assay for imaging the LGN using a previously developed mutant mouse whose microglia glow bright green under ultraviolet light. Schafer further altered the mice so that the synapses connected to one eye would appear red, and those linked to the other eye, blue. She then used chemicals to increase the firing of neurons in one eye and decrease it in the other eye. Because neuronal activity is known to make synapses stronger, this manipulation is thought to weaken the synapses for one eye and strengthen those for the other. \n               Right time, right place \n             The researchers' colourful pictures, showing fragments of red and blue synapses in the bellies of the microglia, suggested that the cells selectively engulf the weakest synapses (see \u2018Full belly\u2019). \u201cThis was really exciting because it showed for the first time that, OK, the microglia are actually sensing, in some way, activity changes in the neuron,\u201d Schafer says. The researchers then repeated the experiments using mice that lacked the complement receptor. Their theory predicted that getting rid of the receptor would thwart microglia's ability to eat up complement-tagged synapses. Sure enough, these mutant animals had microglia with significantly less-full bellies. Despite such findings, neuroscientists are still debating whether microglia have an active role in synaptic pruning. The pretty pictures put the cells at the right time and place, but no one has caught them in the act. \u201cWe can't see microglia picking off a synapse in real time,\u201d Schafer says. The cells could be initiating the operation, or they may simply swoop in to clear up the carnage after the synapse has been destroyed. It is also unclear whether neuronal activity influences the complement-tagging process, notes Carla Shatz, a neurobiologist at Stanford. Her work has shown that other immune-system players \u2014 the molecules of the major histocompatibility complex \u2014 are necessary for synaptic pruning, influenced by neuronal activity and likely to show up near complement proteins 10 . \u201cI think there's a way to connect all of these observations, and to really test the idea that they're all part of a signalling system for synapse elimination,\u201d Shatz says. But current microscopy tools are a limiting factor. \u201cWe just don't have the resolution to see which cells are making the molecules versus which ones are receiving the signals.\u201d Meanwhile, microglia studies continue to yield unexpected results. A 2010 study of mouse models of trichotillomania \u2014 a psychiatric disorder characterized by compulsive hair-pulling \u2014 showed that disruption of the  Hoxb8  gene, which in the brain is expressed only by certain types of microglia, caused mice to groom the fur right off their bodies 4 . The behaviour stopped after the mice received whole-body irradiation followed by a bone-marrow transplant. The researchers speculate that radiation wipes out defective microglia (and the blood\u2013brain barrier) and allows them to be replaced with new ones from the transplanted bone marrow. Similarly, a study published in March showed that a bone-marrow transplant greatly increased the lifespan of mouse models of Rett syndrome 5 . \n               Singular power \n             These studies have raised the alluring idea that microglial manipulations could be used to treat neurodevelopmental disorders. \u201cThis is the only population in the brain that could be very easily replaced,\u201d says Jonathan Kipnis, a neuroscientist at the University of Virginia in Charlottesville and lead investigator of the Rett study. \u201cIf we learn how to harness microglia for the benefit of the brain, I think clinically that would be a powerful tool.\u201d The transplant papers have many critics. It is not known, for one thing, how many microglia repopulate the brain after the procedure. And wiping out an animal's immune system is bound to cause a host of changes. But Stevens, Gross, Tremblay and others are all forging ahead, beginning to investigate the role of microglia in various mouse models of autism. Researchers are also eager to get their hands on a much-anticipated tool: mutant mice that have genes knocked out of microglia but not other cells. Such 'conditional-knockout' mice can be used to investigate a gene's function specifically in microglia, as opposed to in astrocytes or other cells. Gan says that he and his team have already created conditional-knockout mice for two genes \u2014  MECP2 , which is mutated in human cases of Rett syndrome, and  GRN , which has mutations associated with a heritable form of frontotemporal dementia. The results are not yet published. \u201cRight now, the excitement is good about microglia,\u201d Gan says. \u201cWe still need to do the hard work to figure out what exactly they do.\u201d\n Reprints and Permissions"},
{"file_id": "nature.2012.10458", "url": "https://www.nature.com/articles/nature.2012.10458", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "An interactive map of ancient human migrations. \n                   Special issue: Peopling the planet 2012-May-02 \n                 \n                   Human migrations: Eastern odyssey 2012-May-02 \n                 \n                   Archaeology: Date with history 2012-May-02 \n                 \n                   Evolution: What makes a modern human 2012-May-02 \n                 \n                   Ancient migration: Coming to America 2012-May-02 \n                 \n                   Young Americans 2012-May-02 \n                 Reprints and Permissions"},
{"file_id": "485296a", "url": "https://www.nature.com/articles/485296a", "year": 2012, "authors": [{"name": "Sharon Levy"}], "parsed_as_year": "2006_or_before", "body": "Shape-shifting coyotes have evolved to take advantage of a landscape transformed by people. Scientists are now discovering just how wily the creatures are. Near the dawn of time, the story goes, Coyote saved the creatures of Earth. According to the mythology of Idaho's Nez Perce people, the monster Kamiah had stalked into the region and was gobbling up the animals one by one. The crafty Coyote evaded Kamiah but didn't want to lose his friends, so he let himself be swallowed. From inside the beast, Coyote severed Kamiah's heart and freed his fellow animals. Then he chopped up Kamiah and threw the pieces to the winds, where they gave birth to the peoples of the planet. European colonists took a very different view of the coyote ( Canis latrans ) and other predators native to North America. The settlers hunted wolves to extinction across most of the southerly 48 states. They devastated cougar and bobcat populations and attacked coyotes. But unlike the other predators, coyotes have thrived in the past 150 years. Once restricted to the western plains, they now occupy most of the continent and have invaded farms and cities, where they have expanded their diet to include squirrels, household pets and discarded fast food. Researchers have long known the coyote as a master of adaptation, but studies over the past few years are now revealing how these unimposing relatives of wolves and dogs have managed to succeed where many other creatures have suffered. Coyotes have flourished in part by exploiting the changes that people have made to the environment, and their opportunism goes back thousands of years. In the past two centuries, coyotes have taken over part of the wolf's former ecological niche by preying on deer and even on an endangered group of caribou. Genetic studies reveal that the coyotes of northeastern America \u2014 which are bigger than their cousins elsewhere \u2014 carry wolf genes that their ancestors picked up through interbreeding. This lupine inheritance has given northeastern coyotes the ability to bring down adult deer \u2014 a feat seldom attempted by the smaller coyotes of the west. The lessons learned from coyotes can help researchers to understand how other mid-sized predators respond when larger carnivores are wiped out. In sub-Saharan Africa, for example, intense hunting of lions and leopards has led to a population explosion of olive baboons, which are now preying on smaller primates and antelope, causing a steep decline in their numbers. Yet even among such opportunists, coyotes stand out as the champions of change. \u201cWe need to stop looking at these animals as static entities,\u201d says mammalogist Roland Kays of the North Carolina Museum of Natural Sciences in Raleigh. \u201cThey're evolving\u201d. At a fast rate, too. Two centuries ago, coyotes led a very different life, hunting rabbits, mice and insects in the grasslands of the Great Plains. Weighing only 10 to 12 kilograms on average, they could not compete in the forests with the much larger grey wolves ( Canis lupus ), which are quick to dispatch coyotes that try to scavenge their kills. The big break for coyotes came when settlers pushed west, wiping out the resident wolves. Coyotes could thrive because they breed more quickly than wolves and have a more varied diet. Since then, their menu has grown and so has their range; they have invaded all the mainland United States (with the exception of northern Alaska) and Mexico, as well as large parts of southern Canada (see 'On the move'). The animals that arrived in the northeastern United States and Canada in the 1940s and 50s were significantly larger on average than those on the Great Plains, sometimes topping 16 kilograms. Kays and his colleagues studied the rapid changes in coyote physique by analysing mitochondrial DNA and skull measurements of more than 100 individuals collected in New York state and throughout New England. They found 1  that these northeastern coyotes carried genes from Great Lakes wolves, showing that the two species had interbred as the coyotes passed through that region. \u201cCoyotes mated with wolves in the 1800s, when wolf populations were at low density because of human persecution,\u201d says Kays. In those circumstances, wolves had a hard time finding wolf mates, so they settled for coyotes. Compared with the ancestral coyotes from the plains, the northeastern coyote\u2013wolf hybrids have larger skulls, with more substantial anchoring points for their jaw muscles. Thanks in part to those changes, these beefy coyotes can take down larger prey; they even killed a 19-year-old female hiker in Nova Scotia in 2009. The northeastern coyotes have expanded their range five times faster than coyote populations in the southeastern United States, the members of which encountered no wolves as they journeyed east. \n               New to the city \n             Coyotes have even moved into Washington DC, appearing in Rock Creek Park in 2004, just a few miles from the White House. Christine Bozarth, a conservation geneticist at the Smithsonian Institution in Washington, has tracked their arrival and has shown that some of them are descended from the larger northeastern strain and carry wolf DNA 2 . Bozarth says the coyotes are there to stay. \u201cThey can adapt to any urban landscape; they'll raise their pups in drainage ditches and old pipes,\u201d she says. She hopes that the coyotes will help to control the deer, whose numbers are booming. But Kays says that coyotes have not made a significant dent in the northeast's deer population. \u201cCoyotes fill part of the empty niche, but they don't completely replace wolves,\u201d he says. Oddly enough, it is the smaller coyotes in the southeastern United States that seem to be having a real impact on deer. About the same size as western coyotes, the southeastern ones have begun to exploit a niche left empty by the red wolves ( Canis lupus rufus ) that once roamed the southeast and specialized in hunting the region's deer, which are smaller than those in the northeast. John Kilgo, a wildlife biologist with the US Forest Service in New Ellenton, South Carolina, and his colleagues found in a 2010 study 3  that South Carolina's deer population started to decline when coyotes arrived in the late 1980s. More recently, he and his colleagues have studied deaths among fawns, using forensic techniques right out of a murder investigation 4 . They analysed bite wounds on the carcasses and sequenced DNA in saliva left on the wounds. They also searched for scat and tracks left by the killers and noted how they had stashed uneaten remains. More than one-third of the fawn deaths were clearly caused by coyotes, and circumstantial evidence suggests that the true number might be closer to 80%. \u201cCoyotes are acting as top predators on deer, and controlling their numbers,\u201d says Kilgo. At first, many researchers had a hard time accepting that conclusion because they thought that coyotes were too small to affect deer populations, Kilgo says. He hopes to study how the newly arrived coyotes will affect other members of the southeastern ecosystem, including wild turkeys and predators such as raccoons, foxes and opossums. There is no danger that the southeastern coyotes will drive the abundant deer in that region to extinction. But at the northern extreme of their range, coyotes are threatening a highly endangered band of woodland caribou ( Rangifer tarandus caribou ) in the mature forests of Quebec's Gasp\u00e9sie National Park. Logging and other changes there had taken a toll on the caribou even before coyotes arrived in the region in 1973 and settled into newly cleared parts of the forest. But then coyotes started hunting caribou calves and the population dropped even further. A 2010 study 5  found that coyotes accounted for 60% of the predation on these caribou, which now number only 140. Dominic Boisjoly, a wildlife biologist with Quebec's Ministry of Sustainable Development, Environment and Parks in Quebec City, says that the best way to protect the caribou would be to cease clear-cutting of the forest, thereby denying the predators a home. Coyotes have been taking advantage of the changes wrought by humans for many thousands of years, according to a study of coyote fossils published this year 6 . Evolutionary biologist Julie Meachen at the National Evolutionary Synthesis Center in Durham, North Carolina, and Joshua Samuels at the John Day Fossil Beds National Monument in Kimberly, Oregon, made that discovery by measuring the size of coyote fossils dating back over the past 25,000 years. During the last ice age, coyotes were significantly larger than most of their modern counterparts and resembled the biggest of the present-day coyote\u2013wolf hybrids in the northeast. They probably scavenged meat from kills made by dire wolves and sabre-toothed cats, and preyed on the young of the large herbivores, such as giant ground sloths, wild camels and horses, that thronged North America at that time. But at the close of the ice age, about 13,000 years ago, most of the megafauna vanished \u2014 an extinction attributed to both climate change and the appearance of efficient Stone Age hunters. With them went the largest predators, allowing the smaller grey wolves to fill the vacant niche, which put them in competition with the largest coyotes. That conflict, as well as the loss of large herbivores, caused coyotes to shrink in stature. Within 1,000 years of the Pleistocene extinctions, coyotes had reached the same size as in most present-day populations. Now, they're going through a whole new set of changes as they adapt to the modern landscape of North America. Genetic studies 7  show that some coyotes are even interbreeding with dogs, which could lead to a different sort of hybrid animal. Researchers are struggling to keep up with the animals and their impacts as they lope into more new regions. \u201cInvading a landscape emptied of wolves may trigger a whole new pathway in terms of the coyote's evolution,\u201d says Bill Ripple, an ecologist at Oregon State University in Corvallis. \u201cAnd the coyote's arrival will have unpredictable effects on other species in the ecosystem.\u201d \n                     Mesopredator release and avifaunal extinctions in a fragmented system 1999-Aug-05 \n                   \n                     Conservation biology Top dogs maintain diversity 1999-Aug-05 \n                   \n                     Mitochondrial DNA analysis implying extensive hybridization of the endangered red wolf Canis rufus 1991-Jun-13 \n                   \n                     Coyote project in Cook County, Illinois \n                   \n                     Eastern Coyote/Coywolf Research \n                   \n                     New York Suburban Coyote Study \n                   Reprints and Permissions"},
{"file_id": "485023a", "url": "https://www.nature.com/articles/485023a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "Not long ago, the story was simple. A vanguard of modern humans left their African birthplace 50,000\u201360,000 years ago and quickly conquered Asia. They turned left into Europe some 40,000 years ago, later crossing the Bering Strait and marching southward into the Americas. With their advance, Neanderthals and other earlier peoples dwindled and vanished. But in the past five years, the picture has grown more complex \u2014 and more interesting. Few question the idea that modern humans are all emigrants from Africa. But when their journey began, when it ended and what they did along the way makes for a deepening mystery, explored in this issue of  Nature . Discoveries on the Arabian peninsula, for example, show that modern humans were camped on the doorstep of Asia more than 100,000 years ago, nearly twice as long ago as anyone thought. If they went farther at that early date \u2014 and some archaeologists insist that they must have \u2014 their presence would explain a smattering of ambiguous artefacts and fossils around Asia (see  page 24 ). When did our ancestors make the journey from Africa to Asia, and which of our ancient relatives did we meet? Elsewhere, humans definitely arrived ahead of schedule. Sensitive new radiocarbon-dating techniques show that the first modern humans reached Europe thousands of years earlier than was thought, implying a lengthy coexistence with Neanderthals there (see  page 27 ). And the picture of big-game hunters following an inland route from Asia to the Americas 13,000 years ago has been obliterated by a barrage of reports of older sites. Archaeologists are studying DNA, ancient and modern, for clues to when and how the first Americans arrived (see  page 30 ). The most dramatic change, however, concerns the archaic peoples whose world we inherited. In the past two years, ancient-DNA researchers have deciphered the full genome sequences of Neanderthals and a hitherto unknown group called Denisovans, then compared them with modern human genomes. The startling upshot: genetic traces of our vanished cousins live on in people today (see  page 33 ). Just where and how the ancient trysts took place is yet to be revealed, as researchers continue to unravel the human story. \n                 See Editorial \n                 page 6 \n               \n                     Human evolution: Cultural roots 2012-Feb-15 \n                   \n                     African cave's ancient ochre lab 2011-Oct-13 \n                   \n                     Early human migration written in stone tools 2011-Jan-27 \n                   Reprints and Permissions"},
{"file_id": "485164a", "url": "https://www.nature.com/articles/485164a", "year": 2012, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "Clouds and aerosol particles have bedevilled climate modellers for decades. Now researchers are starting to gain the upper hand. Seen from space, Earth can look dressed up or downright dowdy, depending on the location. In some spots, swathes of cloud cloak the dark ocean, offering a stunning contrast of hues. In others, power plants spew out plumes of grey haze and desert storms cover vast regions in palls of dust. Together, those clouds and the fine particles, which are known as aerosols, do more than just obscure the planet's surface. By reflecting, absorbing and emitting radiation, they have a major role in setting Earth's temperature and have proved maddeningly difficult to simulate in atmospheric models. For decades, they have been the biggest sources of uncertainty in forecasts of future climate. But researchers say they are beginning to turn a corner in simulating clouds and aerosols. In recent months, climate scientists have started rolling out initial results from the newest generation of models, which represent atmospheric chemistry and microphysics in much more sophisticated ways than previous incarnations. These models allow clouds and aerosols to evolve as they interact with each other and respond to factors such as temperature, relative humidity and air currents. And early results suggest that such processes have a much greater impact on regional climate than scientists had realized. Recent studies have shed light on the roles that clouds and aerosols might have in triggering major African droughts, altering Arctic climate and weakening the monsoon in southern Asia. \u201cThis is fundamentally new science,\u201d says Ben Booth, a climate modeller at the UK Met Office Hadley Centre in Exeter, who is investigating how aerosols influence surface temperatures in the North Atlantic Ocean and affect the weather on the surrounding continents. \u201cThe new generation of models is changing the kinds of questions we face as scientists.\u201d And more science is coming soon. Leading climate-modelling groups around the world are racing to work up their latest results for the Intergovernmental Panel on Climate Change (IPCC), which is due to release its fifth report section by section in 2013 and 2014. It is already clear that the issue of aerosols and clouds will provide some of the biggest surprises. \u201cThis is the real wild card,\u201d says Ron Stouffer, a climate researcher at the National Oceanic and Atmospheric Administration's Geophysical Fluid Dynamics Laboratory (GFDL) in Princeton, New Jersey. \n               The drought-makers \n             Each day, the winds that sweep east across North America stir up a witch's brew of atmospheric refuse. Power plants belch out sulphur dioxide gas, which evolves into sulphate particles that reflect sunlight and serve as seeds for clouds. Microscopic specks of carbon rise from vehicles, steel smelters, agricultural fires and other sources. The brighter carbon particles scatter the Sun's rays and dark ones absorb them, processes known as the direct aerosol effect. As the particles ride the air currents eastward, they collide with each other and mix with natural dust and ocean spray to form the load of atmospheric aerosols. Over time, they can build up chemical coatings or merge to form new particles with different properties. The prevailing winds carry this aerosol stew on a long horseshoe-shaped route around the Atlantic basin (see graphic). The particles are first transported eastward across the ocean, then take a right turn down the coast of France, gathering up more pollution from Europe. The aerosol-laden air curves towards the west coast of North Africa before veering westward and riding tropical air currents back towards America. Scientists have proposed that this arc of aerosols could block enough sunlight to cool sea surface temperatures in the Atlantic Ocean and alter the regional climate. So Booth and fellow researchers at the Hadley Centre tested the idea with their newest model, which simulates not only the direct aerosol effect but also many of the indirect effects that aerosols have on cloud properties. These interactions take place on too fine a scale to simulate in a global model, so they are represented by statistical equations derived from even more detailed models. The Hadley Centre team reported last month that, in the model, the aerosols had an exceptionally large effect on North Atlantic sea surface temperatures 1 . And it was an indirect aerosol effect that made the bulk of the difference. The sulphate particles attracted water vapour to create a vast supply of tiny droplets within clouds, brightening them and reducing the amount of sunlight reaching the sea surface. Overall, North Atlantic sea surface temperatures climbed throughout the simulation, from 1860 to 2005. But an increase in aerosols slowed the ocean warming during the mid-twentieth century, when rapid industrialization caused extreme levels of air pollution. After restrictions on sulphur emissions in the United States and Europe started to kick in the 1970s, the skies grew clearer and sea surface temperatures increased. In the end, Booth says, the changing output of industrial aerosols explains two-thirds of the long-term swings observed in sea surface temperatures in the North Atlantic. \u201cIt's only in the current generation of models that we can see that relationship physically,\u201d says Booth. The Hadley Centre's results seem to overturn the prevailing wisdom in climate circles, which holds that the ups and downs in sea surface temperatures result from a natural ocean cycle dubbed the Atlantic multidecadal oscillation (AMO). Earlier research suggested that the cooler Atlantic temperatures associated with the AMO could have contributed to droughts over the Sahel in Africa during the latter half of the twentieth century; the same cooling effect may have led to a reduction in the force of tropical storms and hurricanes steaming towards America 2 . But on the basis of the new picture, human pollution could be causing these climate disruptions instead. The question now is whether the results will hold up. Researchers at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado, say that they see hints of similar effects in their new simulations. But not everybody is convinced that aerosol pollution could have such a profound effect on ocean temperatures \u2014 and consequently on climate. NCAR climate scientist Kevin Trenberth says that the results depend on uncertain estimates of aerosol pollution and cloud distributions around the Atlantic. At the same time, satellite observations do not find the indirect aerosol effect to be as strong as the models seem to suggest, he says. \u201cIt would be surprising to me if the ocean is not playing a substantial role\u201d through natural cycles. \n               Arctic warmers \n             Researchers are also struggling to tease apart the roles of natural cycles and human-caused changes in the melting Arctic. The sea ice there has taken a beating during the past few decades and coverage reached a near-record low of 4.33 million square kilometres last September. Because the speed of the ice loss has outstripped all but the most dire model predictions, researchers have wondered what might be missing from their simulations. Early results from the new models suggest that the addition of the more complex clouds and aerosols to simulations could help to provide an explanation. NCAR's new atmospheric model produced more warming and sea-ice loss than the previous iteration 3 , and the culprit seems to be clouds \u2014 a result that caught researchers by surprise. \u201cI'm a cloud girl, but I didn't go into this thinking that clouds were going to play the lead role,\u201d says Jennifer Kay, an atmospheric scientist at NCAR. To figure out what was happening, the team built new diagnostic tools into the model that effectively tell scientists what they would see if they were observing the planet from a pair of US satellites, CloudSat and Calipso. The model's output is translated into a signal that can be compared directly with radar and laser instruments aboard the satellites, Kay explains. \u201cYou basically fly a little satellite around inside the model,\u201d she says, \u201cand what it shows is that the clouds are remarkably improved in the new version.\u201d They tend to be thinner and more transparent \u2014 more like their physical counterparts in the Arctic skies \u2014 although why remains unclear. The gauzy clouds allow more sunlight through in the summer, which melts more ice and exposes more sea and land surfaces; these effects are enhanced by deposition of dark aerosol particles on the snow. It all adds up to a shift towards darker surfaces that absorb more sunlight and amplify warming. Although the model still tends to underestimate sea-ice loss on average, Kay says, some simulations lined up with satellite observations reasonably well. Researchers at the GFDL are also seeing greater sea-ice declines with their new climate model. Michael Winton, a modeller at the GFDL, says this is likely to be a theme in the IPCC's fifth assessment, but he warns against premature celebration. The addition of enhanced clouds and aerosols to the simulations is driving the extra warming, but the exact details remain unclear 4 . In the end, the climate community must confront a basic question about models. \u201cIf you made a model and it matched the observations perfectly, would you claim success?\u201d Winton asks. Although the new GFDL model has an enhanced representation of the atmosphere and does a better job of matching satellite observations, Winton warns that modellers could get the right answer for the wrong reasons. There is some evidence, for example, that natural variability in ocean circulation has caused some of the sea-ice loss during the past two decades. \u201cThe Arctic has to be understood in the context of the overall climate,\u201d he says. \n               Taming the monsoon \n             In satellite images, southeast Asia is often covered by a giant blemish \u2014 a brown cloud fed by black carbon emissions from millions of primitive cooking stoves and open fires throughout rural India and neighbouring countries. In the atmosphere, those dark particles absorb sunlight and heat the surrounding air while cooling the land below, effectively stabilizing the atmosphere and slowing the regional circulation that draws moisture inland from the northern Indian Ocean. Researchers proposed seven years ago that this mechanism could explain why the south Asian summer monsoon has grown weaker over the past half-century 5 . However, simulations with one of the new models at the GFDL suggest that the situation might be more complicated, with aerosols and clouds disturbing a much larger hemispheric energy exchange 6 . The overall system is driven by the summer Sun, which delivers more heat north of the equator than south. In what amounts to a massive heat engine that redistributes energy between the hemispheres, hot air rises in the north and carries heat at altitude to the south, where the air descends and picks up moisture from the Indian Ocean on its return north. It is this last step that brings the summer monsoons, which provide up to 80% of the precipitation to most of India. But the GFDL results, reported in  Science  last October, showed that aerosols are creating a major disruption 6 . \u201cAerosol emissions are like putting up a sunscreen over the Northern Hemisphere, and that reduces the solar imbalance that drives the system,\u201d says Yi Ming, a GFDL climate modeller and an author of the study. \u201cWe're trying to argue this from a larger spatial scale.\u201d Their model also shifts the blame away from the black-carbon emissions of cooking stoves and agricultural fires, and towards sulphur pollution from coal-fired power plants throughout the region. The sulphate particles that develop from such pollution serve as the seeds for water droplets and brighten clouds, cooling the land below. In addition to capturing the 4\u20135% overall decline in summer rainfall over India since 1950, the model reproduces regional variations in precipitation \u2014 more drying over north-central India versus a slight increase in rainfall over southern India and northwestern India and Pakistan. Ming says the indirect aerosol effect included in the new study shows \u201ca different part of the puzzle\u201d. Surabi Menon, a climate modeller and an affiliate scientist at the Lawrence Berkeley National Laboratory in California, cautions that the simulations rely on relatively incomplete estimates of emissions. Menon has been exploring aerosols and the monsoon with the latest model from the NASA Goddard Institute for Space Studies in New York, and says that modellers can at least check their data against measurements of pollution, which were not available even a few years ago. \u201cWe are getting there,\u201d she says. \u201cSlowly.\u201d \n               The global puzzle \n             As climate researchers test drive the new generation of models, they are particularly keen to measure the models' overall sensitivity: how strongly they warm up in response to increasing concentrations of greenhouse gases. The addition of indirect aerosol effects makes the new model at NCAR more sensitive to greenhouse gases, says NCAR researcher Andrew Gettelman. Simulations show that the additional cooling from aerosol pollution, as well as the direct effect of haze, masked some of the warming from greenhouse gases during the twentieth century; but the model shows enhanced warming in the twenty-first century as curbs on pollution expose the full power of greenhouse gases. In simplified runs that double greenhouse-gas concentrations \u2014 which could happen by the end of this century \u2014 the new atmospheric model projects a 4 \u00b0C rise in global temperatures, whereas the previous model showed a 3.1 \u00b0C increase. The Hadley Centre model is moving in the same direction, but this is not the rule. A model at the Pierre Simon Laplace Institute near Paris produces less warming in response to greenhouse gases than did the previous generation, says Sandrine Bony, a climate modeller there. The improved treatment of clouds may help explain that change, but the researchers have yet to fully analyse the new results. These are just the first wave of a deluge in modelling data. Scientists in the IPCC's physical science working group have until 31 July 2012 to submit papers for the IPCC process, so the literature will explode with results from climate simulations over the coming year. Then the real hard work will begin \u2014 working out what to believe. Scientists must tease apart the subtle causes and effects in their models and, where possible, test their results against other models and observations. \u201cWhat we need now is to really understand what the models are doing, and why they differ,\u201d Bony says. \u201cIt's really by comparing the results from a spectrum of models that we can assess which results are robust.\u201d \n                     Forecasters look back in time 2012-Mar-13 \n                   \n                     Models hone picture of climate impacts 2012-Feb-13 \n                   \n                     Earth science: The climate machine 2010-Feb-24 \n                   \n                     Coupled Model Intercomparison Project \n                   \n                     Intergovernmental Panel on Climate Change \n                   Reprints and Permissions"},
{"file_id": "485298a", "url": "https://www.nature.com/articles/485298a", "year": 2012, "authors": [{"name": "Ed Yong"}], "parsed_as_year": "2006_or_before", "body": "In the wake of high-profile controversies, psychologists are facing up to problems with replication. For many psychologists, the clearest sign that their field was in trouble came, ironically, from a study about premonition. Daryl Bem, a social psychologist at Cornell University in Ithaca, New York, showed student volunteers 48 words and then abruptly asked them to write down as many as they could remember. Next came a practice session: students were given a random subset of the test words and were asked to type them out. Bem found that some students were more likely to remember words in the test if they had later practised them. Effect preceded cause. Bem published his findings in the  Journal of Personality and Social Psychology  ( JPSP ) along with eight other experiments 1  providing evidence for what he refers to as \u201cpsi\u201d, or psychic effects. There is, needless to say, no shortage of scientists sceptical about his claims. Three research teams independently tried to replicate the effect Bem had reported and, when they could not, they faced serious obstacles to publishing their results. The episode served as a wake-up call. \u201cThe realization that some proportion of the findings in the literature simply might not replicate was brought home by the fact that there are more and more of these counterintuitive findings in the literature,\u201d says Eric-Jan Wagenmakers, a mathematical psychologist from the University of Amsterdam. Positive results in psychology can behave like rumours: easy to release but hard to dispel. They dominate most journals, which strive to present new, exciting research. Meanwhile, attempts to replicate those studies, especially when the findings are negative, go unpublished, languishing in personal file drawers or circulating in conversations around the water cooler. \u201cThere are some experiments that everyone knows don't replicate, but this knowledge doesn't get into the literature,\u201d says Wagenmakers. The publication barrier can be chilling, he adds. \u201cI've seen students spending their entire PhD period trying to replicate a phenomenon, failing, and quitting academia because they had nothing to show for their time.\u201d These problems occur throughout the sciences, but psychology has a number of deeply entrenched cultural norms that exacerbate them. It has become common practice, for example, to tweak experimental designs in ways that practically guarantee positive results. And once positive results are published, few researchers replicate the experiment exactly, instead carrying out 'conceptual replications' that test similar hypotheses using different methods. This practice, say critics, builds a house of cards on potentially shaky foundations. These problems have been brought into sharp focus by some high-profile fraud cases, which many believe were able to flourish undetected because of the challenges of replication. Now psychologists are trying to fix their field. Initiatives are afoot to assess the scale of the problem and to give replication attempts a chance to be aired. \u201cIn the past six months, there are many more people talking and caring about this,\u201d says Joseph Simmons, an experimental psychologist at the University of Pennsylvania in Philadelphia. \u201cI'm hoping it's reaching a tipping point.\u201d \n               Pervasive bias \n             Psychology is not alone in facing these problems. In a now-famous paper 2 , John Ioannidis, an epidemiologist currently at Stanford School of Medicine in California argued that \u201cmost published research findings are false\u201d, according to statistical logic. In a survey of 4,600 studies from across the sciences, Daniele Fanelli, a social scientist at the University of Edinburgh, UK, found that the proportion of positive results rose by more than 22% between 1990 and 2007 (ref.  3 ). Psychology and psychiatry, according to other work by Fanelli 4 , are the worst offenders: they are five times more likely to report a positive result than are the space sciences, which are at the other end of the spectrum (see 'Accentuate the positive'). The situation is not improving. In 1959, statistician Theodore Sterling found that 97% of the studies in four major psychology journals had reported statistically significant positive results 5 . When he repeated the analysis in 1995, nothing had changed 6 . One reason for the excess in positive results for psychology is an emphasis on \u201cslightly freak-show-ish\u201d results, says Chris Chambers, an experimental psychologist at Cardiff University, UK. \u201cHigh-impact journals often regard psychology as a sort of parlour-trick area,\u201d he says. Results need to be exciting, eye-catching, even implausible. Simmons says that the blame lies partly in the review process. \u201cWhen we review papers, we're often making authors prove that their findings are novel or interesting,\u201d he says. \u201cWe're not often making them prove that their findings are true.\u201d Simmons should know. He recently published a tongue-in-cheek paper in  Psychological Science  'showing' that listening to the song  When I'm Sixty-four  by the Beatles can actually reduce a listener's age by 1.5 years 7 . Simmons designed the experiments to show how \u201cunacceptably easy\u201d it can be to find statistically significant results to support a hypothesis. Many psychologists make on-the-fly decisions about key aspects of their studies, including how many volunteers to recruit, which variables to measure and how to analyse the results. These choices could be innocently made, but they give researchers the freedom to torture experiments and data until they produce positive results. In a survey of more than 2,000 psychologists, Leslie John, a consumer psychologist from Harvard Business School in Boston, Massachusetts, showed that more than 50% had waited to decide whether to collect more data until they had checked the significance of their results, thereby allowing them to hold out until positive results materialize. More than 40% had selectively reported studies that \u201cworked\u201d 8 . On average, most respondents felt that these practices were defensible. \u201cMany people continue to use these approaches because that is how they were taught,\u201d says Brent Roberts, a psychologist at the University of Illinois at Urbana\u2013Champaign. All this puts the burden of proof on those who try to replicate studies \u2014 but they face a tough slog. Consider the aftermath of Bem's notorious paper. When the three groups who failed to reproduce the word-recall results combined and submitted their results for publication, the  JPSP ,  Science  and  Psychological Science  all said that they do not publish straight replications. The  British Journal of Psychology  sent the paper out for peer review, but rejected it. Bem was one of the peer reviewers on the paper. The beleaguered paper eventually found a home at  PLoS ONE 9 , a journal that publishes all \u201ctechnically sound\u201d papers, regardless of novelty. \u201cI've done everything possible to encourage replications,\u201d says Bem, who stands by his results, and has put details of all his methods and tests online. But he adds that one replication paper is uninformative on its own. \u201cIt's premature,\u201d he says. \u201cIt can take years to figure out what can make a replication fail or succeed. You need a meta-analysis of many experiments.\u201d St\u00e9phane Doyen, a cognitive psychologist at the Free University of Brussels, encountered similar issues when he and his colleagues failed to replicate a classic experiment by John Bargh from Yale University in New Haven, Connecticut, showing that people walk more slowly if they have been unconsciously primed with age-related words 10 . After several rejections, Doyen's paper was also eventually published in  PLoS ONE 11 , and drew an irate blog post from Bargh. Bargh described Doyen's team as \u201cinexpert researchers\u201d and later took issue with the writer of this story for a blog post about the exchange. Bargh says that he responded so strongly partly because he saw growing scepticism of the idea that unconscious thought processes are important, and felt that damage was being done to the field. Of course, one negative replication does not invalidate the original result. There are many mundane reasons why such attempts might not succeed. If the original effect is small, negative results will arise through chance alone. The volunteers in a replication attempt might differ from those in the original. And one team might simply lack the skill to reproduce another's experiments. \u201cThe conduct of subtle experiments has much in common with the direction of a theatre performance,\u201d says Daniel Kahneman, a Nobel-prizewinning psychologist at Princeton University in New Jersey. Trivial details such as the day of the week or the colour of a room could affect the results, and these subtleties never make it into methods sections. Bargh argues, for example, that Doyen's team exposed its volunteers to too many age-related words, which could have drawn their attention to the experiment's hidden purpose. In priming studies, \u201cyou must tweak the situation just so, to make the manipulation strong enough to work, but not salient enough to attract even a little attention\u201d, says Kahneman. \u201cBargh has a knack that not all of us have.\u201d Kahneman says that he attributes a special 'knack' only to those who have found an effect that has been reproduced in hundreds of experiments. Bargh says of his priming experiments that he \u201cnever wanted there to be some secret knowledge about how to make these effects happen. We've always tried to give that knowledge away but maybe we should specify more details about how to do these things\u201d. After Bargh's 1996 paper on unconscious priming, dozens of other labs followed suit with their own versions of priming experiments. Volunteers who were primed by holding a heavy clipboard, for example, took interview candidates more seriously and deemed social problems to be more pressing than did those who held light boards 12 . And people primed with words relating to cleanliness judged dirty deeds more leniently 13 . Such conceptual replications are useful for psychology, which often deals with abstract concepts. \u201cThe usual way of thinking would be that [a conceptual replication] is even stronger than an exact replication. It gives better evidence for the generalizability of the effect,\u201d says Eliot Smith, a psychologist at Indiana University in Bloomington and an editor of  JPSP . But to other psychologists, reliance on conceptual replication is problematic. \u201cYou can't replicate a concept,\u201d says Chambers. \u201cIt's so subjective. It's anybody's guess as to how similar something needs to be to count as a conceptual replication.\u201d The practice also produces a \u201clogical double-standard\u201d, he says. For example, if a heavy clipboard unconsciously influences people's judgements, that could be taken to conceptually replicate the slow-walking effect. But if the weight of the clipboard had no influence, no one would argue that priming had been conceptually falsified. With its ability to verify but not falsify, conceptual replication allows weak results to support one another. \u201cIt is the scientific embodiment of confirmation bias,\u201d says Brian Nosek, a social psychologist from the University of Virginia in Charlottesville. \u201cPsychology would suffer if it wasn't practised but it doesn't replace direct replication. To show that 'A' is true, you don't do 'B'. You do 'A' again.\u201d \n               Missed misconduct \n             These practices can create an environment in which misconduct goes undetected. In November 2011, Diederik Stapel, a social psychologist from Tilburg University in the Netherlands and a rising star in the field, was investigated for, and eventually confessed to, scientific fraud on a massive scale. Stapel had published a stream of sexy, attention-grabbing studies, showing for example that disordered environments, such as a messy train station, promote discrimination 14 . But all the factors making replication difficult helped him to cover his tracks. The scientific committee that investigated his case wrote, \u201cWhereas all these excessively neat findings should have provoked thought, they were embraced \u2026 People accepted, if they even attempted to replicate the results for themselves, that they had failed because they lacked Mr Stapel's skill.\u201d It is now clear that Stapel manipulated and fabricated data in at least 30 publications. Stapel's story mirrors those of psychologists Karen Ruggiero and Marc Hauser from Harvard University in Cambridge, Massachusetts, who published high-profile results on discrimination and morality, respectively. Ruggiero was found guilty of research fraud in 2001 and Hauser was found guilty of misconduct in 2010. Like Stapel, they were exposed by internal whistle-blowers. \u201cIf the field was truly self-correcting, why didn't we correct any single one of them?\u201d asks Nosek. Driven by these controversies, many psychologists are now searching for ways to encourage replications. \u201cI think psychology has taken the lead in addressing this challenge,\u201d says Jonathan Schooler, a cognitive psychologist at the University of California, Santa Barbara. In January, Hal Pashler, a psychologist from the University of California, San Diego, in La Jolla and his colleagues created a website called PsychFileDrawer where psychologists can submit unpublished replication attempts, whether successful or not. The site has been warmly received but has only nine entries so far. There are few incentives to submit: any submission opens up scientists to criticisms from colleagues and does little to help their publication record. Matthew Lieberman, a social psychologist from University of California, Los Angeles, suggests a different approach. \u201cThe top psychology programmes in the United States could require graduate students to replicate one of several nominated studies within their own field,\u201d he says. The students would build their skills and get valuable early publications, he says, and the field would learn whether surprising effects hold up. Wagenmakers argues that replication attempts should also be published under different rules. Like clinical trials in medicine, he says, they should be pre-registered to avoid the post-hoc data-torturing practices that Simmons describes, and published irrespective of outcome. Engaging or even collaborating with the original authors early on could pre-empt any later quibbling over methods. These changes may be a far-off hope. Some scientists still question whether there is a problem, and even Nosek points out that there are no solid estimates of the prevalence of false positives. To remedy that, late last year, he brought together a group of psychologists to try to reproduce every study published in three major psychological journals in 2008. The teams will adhere to the original experiments as closely as possible and try to work with the original authors. The goal is not to single out individual work, but to \u201cget some initial evidence about the odds of replication\u201d across the field, Nosek says. Some researchers are agnostic about the outcome, but Pashler expects to see confirmation of his fears: that the corridor gossip about irreproducible studies and the file drawers stuffed with failed attempts at replication will turn out to be real. \u201cThen, people won't be able to dodge it,\u201d he says. \n                     Drug development: Raise standards for preclinical cancer research 2012-Mar-28 \n                   \n                     Psychology must learn a lesson from fraud case 2011-Nov-30 \n                   \n                     Report finds massive fraud at Dutch universities 2011-Nov-01 \n                   \n                     Science publishing: The trouble with retractions 2011-Oct-05 \n                   \n                     The trouble with replication 2006-Jul-26 \n                   \n                     PsychFileDrawer \n                   \n                     Open Science Framework \n                   Reprints and Permissions"},
{"file_id": "485431a", "url": "https://www.nature.com/articles/485431a", "year": 2012, "authors": [{"name": "Brendan Maher"}], "parsed_as_year": "2006_or_before", "body": "The fight over mutant flu has thrown the spotlight on a little-known government body that oversees dual-use research. Some are asking if it was up to the task. \n               boxed-text \n             The packages that started arriving by FedEx on 12 October last year came with strict instructions: protect the information within and destroy it after review. Inside were two manuscripts showing how the deadly H5N1 avian influenza virus could be made to transmit between mammals. The recipients of these packages \u2014 eight members of the US National Science Advisory Board for Biosecurity (NSABB) \u2014 faced the unenviable task of deciding whether the research was safe to publish. The group deliberated. Soon, the rest of the NSABB's 22 voting members and two dozen non-voting members and advisers were drawn in. For five-and-a-half weeks, they pored over the data in the papers, weighing the benefits of sharing the information against the risk that doing so might lead to the accidental or intentional release of a lethal new virus. They exchanged views in hundreds of e-mails and in more than 24 hours of teleconference calls. On 21 November, the NSABB recommended that journals should redact the papers, publishing their conclusions but sharing methods and data only with approved scientists and health officials. It was the first time that the board had recommended any such restriction since it was convened in 2005, and it sparked a global debate \u2014 aired in journals, meetings, blogs and newspapers \u2014 that is still raging and has left the US government in an awkward spot. \u201cThe United States funded this research and then wanted to censor it,\u201d says David Fidler, who teaches international law at Indiana University Bloomington. \u201cThis looked dysfunctional.\u201d Throughout these turbulent months, the spotlight has shone as much on the NSABB as it has on the mutant flu viruses. The board's members, with backgrounds ranging from biology to medicine to national security and law, have been developing guidelines for biosecurity oversight for nearly seven years. The flu research was a major test of the principles they had been espousing. By all appearances, the board struggled. By mid-February, the NSABB was under pressure to overturn its initial assessment. And in the last days of March, it did \u2014 voting unanimously in favour of full publication for one paper, which appeared early this month 1 . The board also recommended that the second paper be published, but six members dissented, arguing that the work still posed significant concerns. (That paper's publication is expected within weeks.) The whole episode has left many people with questions. Could the board have done better? Why wasn't the research flagged earlier? And is there a way to publish sensitive information while minimizing risks? There is one point of agreement, says David Relman, a microbiologist at Stanford University in California and member of the NSABB: \u201cThis is not the way any of us wants to see these issues discussed, that is, at the eleventh hour and fifty-ninth minute.\u201d \n               Security scare \n             The NSABB's roots can be traced back to October 2001, when letters carrying anthrax spores were sent to several public figures around the country (see  'Threat and response' ). In response, the US government invested billions of dollars to prepare for future acts of bioterror, much of it channelled into pathogen research through the National Institute of Allergy and Infectious Diseases (NIAID) in Bethesda, Maryland. In parallel, Congress asked the National Academies to form a panel to recommend how dual-use research \u2014 work that could carry bioterror risks as well as benefits \u2014 should be identified, regulated and reported. Scientists were anxious to show that they could police their own work and avoid heavy-handed or cumbersome regulation from above. \u201cThe science community ought to come up with a process before the public demands the government do it for them,\u201d warned Parney Albright of the US Department of Homeland Security in 2003 (ref.  2 ). Geneticist Gerald Fink at the Massachusetts Institute of Technology in Cambridge was chosen to chair the panel. The recommendations in the resulting 'Fink report', published in 2004, set out seven 'deadly sins': types of research that should warrant close scrutiny, such as experiments to render a vaccine ineffective or to make a pathogen more virulent. The report also called for the creation of a national advisory board to further explore the issues on a national and international stage. This would become the NSABB, an independent panel that is managed and supported by the National Institutes of Health (NIH). In June 2005, NIH director Elias Zerhouni swore in 23 NSABB members in Bethesda. Paul Keim, a microbiologist at Northern Arizona University in Flagstaff and acting chair of the NSABB, says that the ceremony involved the raising of hands. \u201cWe all kept from giggling,\u201d he says. Right away, the board started to flesh out guidelines for a US policy on dual-use research. Its flagship document, released in 2007 and building on the Fink report, emphasized local self-governance, suggesting, for example, that investigators monitor their own and colleagues' projects, possibly with the help of existing institutional biosafety committees. Although not officially part of the board's remit, the NIH also called on the NSABB to review the occasional paper that raised biosecurity concerns. The first two 3 , 4  to land in the board's lap, in 2005, dealt with efforts to resurrect the Spanish flu virus that was responsible for millions of deaths immediately after the First World War. The board recommended that the papers be published in full. Keim says he now wishes that the group had had more time to deliberate over the Spanish flu work, which raised many of the same issues as the current debate. \u201cI guess I have some regrets about that decision because of the impact it would have had on policy,\u201d he says. Nevertheless, the papers the board received last October were different from those it had handled before. Their roots go back to 1997, when H5N1 started devastating bird populations worldwide and health officials voiced alarm about the catastrophe that could ensue if the disease gained the ability to jump between humans. In 2006, the NIH convened a blue-ribbon panel to identify priority research on avian influenza. Among other projects, it highlighted the need for experiments to see how bird flu might evolve the ability to spread from person to person. Soon after, the NIH commissioned and funded several such projects, including one from Ron Fouchier at the Erasmus Medical Center in Rotterdam, the Netherlands, and one from Yoshihiro Kawaoka at the University of Wisconsin-Madison and the University of Tokyo. Robert Webster, a virologist at St Jude Children's Research Hospital in Memphis, Tennessee, and a member of the blue-ribbon panel, says that it paid close attention to the stringent biosafety requirements of such work, but that dual-use concerns \u201cdidn't really surface\u201d. They should have, says Keim. The experiments committed at least two of the Fink report's deadly sins: they deliberately changed the host range of a pathogen and they increased its transmissibility. \u201cYou think about adapting H5N1 to mammals,\u201d Keim says, and you quickly \u201crealize that there is the potential to do something very dangerous\u201d. Concerns surfaced in September 2011, when Fouchier presented his results at a high-profile meeting in Malta. He described, in ominous terms, how he had mutated wild H5N1 virus to make it more likely to infect human cells. He had then let the virus evolve in ferrets, a good model for human transmission, until it was able to spread through the air by a cough or a sneeze. Kawaoka took a different approach, mutating a single gene from H5N1 and plugging it into a less pathogenic viral genome. What resulted \u2014 two influenza viruses that could spread in mammals, that most humans had never been exposed to and that stemmed from a virus with the potential to kill \u2014 was worrying. Still, the board struggled with its decision. At first, says NSABB member Arturo Casadevall, a microbiologist at the Albert Einstein College of Medicine in New York, \u201cI was very uncomfortable with the idea of redacting information because I think that it's a slippery slope\u201d. But the data and expert analysis assembled by the board convinced him that what Fouchier and Kawaoka had done was too easy to repeat. \u201cWe just didn't think it would be a good idea to put a recipe out there,\u201d he says. Michael Osterholm, a public-health researcher at the University of Minnesota in Minneapolis, emphasized his support for the research, but stressed the precautionary principle. Once the work was published, it could not be taken back. \u201cYou can't unring a bell,\u201d he said on several occasions. In late December, the US Department of Health and Human Services, which oversees the NIH, announced that it would follow the NSABB's advice. The response was severe, says Keim. \u201cThat redaction approach has been universally panned,\u201d he says. \u201cThe investigators hated it, the people who weren't going to get the data hated it. The government hated it because they couldn't figure out how to do it.\u201d Meanwhile, the NSABB's members were scrambling to make clear that the issues needed international discussion. In mid-February, Kawaoka and Fouchier presented their work at a closed meeting at the World Health Organization (WHO) in Geneva, Switzerland. They assured the researchers that the benefits \u2014 for monitoring wild viruses for potentially dangerous mutations and for vaccine development \u2014 outweighed the risks. They also explained that the mutant viruses weren't necessarily lethal to the ferrets, something that hadn't been clear to everyone before. The attendees, mostly academic flu researchers, recommended that both papers be published in full. In light of the new information, the NIH asked the NSABB to reconsider its position. A workshop was scheduled for 29\u201330 March. \n               Second thoughts \n             The meeting started at 7 a.m. in a sixth-floor conference room of building 31 on the NIH campus in Bethesda. Keim had heard the presentations at Geneva, but still couldn't predict how the rest of the board were going to react. \u201cI was not placing bets either way.\u201d The voting members sat round a conference table, with about 60 administrators, government officials and ex officio members looking on. Everyone was given two hours in silence to review revised manuscripts from Kawaoka's and Fouchier's teams. The researchers had edited the papers to clarify the benefits of the research and to explain the safety measures taken during work with the viruses. Later, they gave presentations. Fouchier was reportedly questioned for two hours. By this point it was clear that Kawaoka's paper posed less of a threat than Fouchier's because of the low pathogenicity of his hybrid virus. But Relman and other members of the NSABB say that they were not reassured by Fouchier or by the revisions to his manuscript. \u201cThere were no new data that for me diminished the evidence for mammal-to-mammal transmissibility and no data that convinced me that the virulence was any less in his mutant viruses than it was in the wild-type parental H5N1 strains,\u201d Relman says. The board also heard that the practical and political barriers to redaction looked formidable. NIH director Francis Collins told them that export-control rules and freedom-of-information laws in other countries would make it impossible to implement a system for selectively releasing data quickly. Moreover, such a system could jeopardize the pandemic-influenza preparedness framework, an international agreement to share influenza viral samples and information that had been hammered out in 2011 by the WHO after years of debate. For officials in countries such as Indonesia, where poultry farmers have faced financial ruin because of H5N1, a decision to redact information sounded like a decision to withhold it. It became clear to the board that redaction was effectively off the table, meaning that the NSABB could vote to publish the paper in full, or not at all. After a full day of briefings and another of deliberation, the board voted. The members present at the meeting unanimously recommended publication of the Kawaoka paper and voted 12\u20136 in favour of publishing Fouchier's. Few came out of the meeting happy. Some were still unsure about how dangerous Fouchier's virus really was. \u201cEven the 12 who voted in favour of publication were uneasy about this uncertainty in the virus,\u201d says Keim, who declined to reveal his vote. Relman, who voted against publication, says that the process felt unbalanced and that he didn't have enough time to assess some new data presented there that had not yet been peer reviewed. \u201cI do think questions should be asked about the manner and process by which we were asked to perform this reassessment,\u201d he says. Osterholm asked some of these questions in a sharply worded letter to the NSABB and Amy Patterson, the board's director at the NIH, a week and a half after the meeting. (The letter was leaked to  Science  and  Nature  days later.) In it, Osterholm said that the presentations given at the meeting were one-sided and designed to favour full publication of the articles. He said that Fouchier had revealed at the meeting an additional mutation that makes H5N1 both transmissible through the air and deadly. This work \u201csurely must be considered as a candidate for the next manuscript to be before the NSABB for review\u201d, wrote Osterholm, who worried that all the same problems would come up again. In her response to the letter, Patterson respectfully disagreed with Osterholm's complaints. But by this point, the spat had started to attract the attention of law-makers. Congressman Jim Sensenbrenner (Republican, Wisconsin) wrote letters to the NIH and to the White House asking how decisions about the research were reached. People within the NSABB, and outside it, now say that the board did its best in a highly complex situation. But many point a finger at a flawed mechanism for identifying and dealing with dual-use research. \u201cAlmost at every step the system isn't working very well for these projects that raise serious concerns about biosecurity,\u201d Fidler says. The most pressing question is why the research wasn't flagged up earlier for scrutiny. The answer: the policy simply wasn't in place. In its 2007 report, the NSABB recommended that the federal government develop guidelines and implement a code of conduct to help institutions and researchers to report potential risks at the earliest stage of project development. It also recommended the development of strategies for communicating sensitive research, including restricted publication. These recommendations went largely unheeded because scientists resisted the introduction of cumbersome new practices. \u201cWe got all worried about the possibility of these threats,\u201d says Fidler, but when it came to imposing regulations on research, \u201cwe tended to back off\u201d. Now, the flu controversy has forced the US government's hand. On 29 March, while the NSABB was being briefed, it released a policy that requires federal agencies to identify and monitor research projects they fund that tick boxes on the 'deadly sins' list. Tom Inglesby, who directs the Center for Biosecurity of UPMC in Baltimore, Maryland, welcomes the new policy. \u201cIt would be much more preferable for these decisions to go on at the beginning of this experimental process. It's more fair to the scientists, more fair to their institutions, more fair to the journals and more fair to the NSABB,\u201d he says. Keim, however, points out that the policy does not require review by disinterested parties. \u201cThese are decisions that need to be made in the open with input from different segments of our society,\u201d he says. It may be too much to expect scientists to coolly evaluate the risks of their own research against the benefits they gain personally from publication. And even if regulatory changes do take root in the United States, international agreement will take years to solidify. Keim and several others at the NSABB say that publishing with controlled access to certain data would still have been the preferred option for the H5N1 papers, but the challenges extend well past US borders. Most observers and participants expect that the NSABB will continue to weigh in on policy development, although it may have to resolve questions about conflicts of interest first. In the wake of the flu controversy, some observers have questioned whether it is appropriate to have the NSABB under the control of the NIH \u2014 which funded the flu research \u2014 and populated by NIH-funded scientists. Board members might not have wanted to vote against publication if it risked biting the hand that feeds them. \u201cI'd be lying if I didn't say that that thought crossed my mind,\u201d says Michael Imperiale, a virologist at the University of Michigan in Ann Arbor and a member of the board since its inception. Ultimately, he says, he followed his conscience, which favoured publication of both articles. Anthony Fauci, director of the NIAID and a non-voting member of the NSABB, calls the idea of the NIAID taking revenge against NSABB members for their vote \u201cpreposterous\u201d. The whole controversy has been an ordeal for those involved. But Casadevall takes a positive view. \u201cThe end result has been a tremendous education,\u201d he says. \u201cI don't know how much of a silver lining that is,\u201d Fidler says. There's little consensus as to what a new system for dual-use research oversight should look like, he says, and governments have simply kicked the can down the road in the past. \u201cThat may happen again, but at least it's out in the open,\u201d he says. \n                     Mutant-flu paper published 2012-May-02 \n                   \n                     US biosecurity board revises stance on mutant-flu studies 2012-Mar-30 \n                   \n                     Flu surveillance lacking 2012-Mar-28 \n                   \n                     Death-rate row blurs mutant flu debate 2012-Feb-13 \n                   \n                     About the NSABB \n                   Reprints and Permissions"},
{"file_id": "485030a", "url": "https://www.nature.com/articles/485030a", "year": 2012, "authors": [{"name": "Andrew Curry"}], "parsed_as_year": "2006_or_before", "body": "For decades, scientists thought that the Clovis hunters were the first to cross the Arctic to America. They were wrong \u2014 and now they need a better theory The mastodon was old, its teeth worn to nubs. It was perfect prey for a band of hunters, wielding spears tipped with needle-sharp points made from bone. Sensing an easy target, they closed in for the kill. Almost 14,000 years later, there is no way to tell how many hits it took to bring the beast to the ground near the coast of present-day Washington state. But at least one struck home, plunging through hide, fat and flesh to lodge in the mastodon's rib. The hunter who thrust the spear on that long-ago day didn't just bring down the mastodon; he also helped to kill off the reigning theory of how people got to the Americas. For most of the past 50 years, archaeologists thought they knew how humans arrived in the New World. The story starts around the end of the last ice age, when sea levels were lower and big-game hunters living in eastern Siberia followed their prey across the Bering land bridge and into Alaska. As the ice caps in Canada receded and opened up a path southward, the colonists swept across the vast unpopulated continent. Archaeologists called these presumed pioneers the Clovis culture, after distinctive stone tools that were found at sites near Clovis, New Mexico, in the 1920s and 1930s. As caches of Clovis tools were uncovered across North America over subsequent decades, nearly all archaeologists signed on to the idea that the Clovis people were the first Americans. Any evidence of humans in the New World before the Clovis time was dismissed, sometimes harshly. That was the case with the Washington-state mastodon kill, which was first described around 30 years ago 1  but then largely ignored. Intense criticism also rained down on competing theories of how people arrived, such as the idea that early Americans might have skirted the coastline in boats, avoiding the Bering land bridge entirely. \u201cI was once warned not to write about coastal migration in my dissertation. My adviser said I would ruin my career,\u201d says Jon Erlandson, an archaeologist at the University of Oregon in Eugene. But findings over the past few years \u2014 and a re-examination of old ones, such as the mastodon rib \u2014 have shown conclusively that humans reached the Americas well before the Clovis people. That has sparked a surge of interest in the field, and opened it up to fresh ideas and approaches. Geneticists and archaeologists are collaborating to piece together who came first, when they arrived, whether they travelled by boat or by foot and how they fanned out across the New World. To test their ideas, some researchers are examining new archaeological sites and reopening old ones. Others are sifting through the DNA of modern people and unearthing the remains of those buried millennia ago in search of genetic clues. \u201cThere's a powerful meshing of the archaeology we're pulling out of the ground with genetic evidence,\u201d says Michael Waters, a geographer at Texas A&M University in College Station. Like those original Americans, researchers are exploring new frontiers, moving into fresh intellectual territory after a long period of stasis. \u201cClovis has been king for 50 years, and now we have to reimagine what the peopling of the New World looked like,\u201d Erlandson says. \u201cIf it wasn't Clovis, what was it? \n               Overthrowing king clovis \n             It took a chance finding halfway around the world to set this reappraisal in motion. In the late 1970s, Tom Dillehay, an archaeologist at Vanderbilt University in Nashville, Tennessee, uncovered the remains of a large campsite in southern Chile, close to the tip of South America (see 'Routes to a new world'). Radiocarbon dating of wood and other organic remains suggested that the site was around 14,600 years old, implying that humans made it from Alaska to Chile more than 1,000 years before the oldest known Clovis tools 2 . But because the remote site was so hard for most researchers to examine, it would take nearly 20 years for Dillehay to convince his colleagues. The case for pre-Clovis Americans has now gained more support, including from analyses of ancient DNA. One of the first bits of genetic evidence came from preserved faeces, or coprolites, that had been discovered in a cave in south-central Oregon by Dennis Jenkins, an archaeologist at the University of Oregon. Radiocarbon dating showed that the coprolites are between 14,300 and 14,000 years old, and DNA analysis confirmed that they are from humans 3 . The recovered DNA even shared genetic mutations with modern Native Americans. Since the coprolite evidence emerged, in 2008, ancient DNA has also been used to reconstruct that long-ago mastodon hunt. Radiocarbon studies in the 1970s had suggested that the mastodon pre-dated the Clovis people, but some researchers explained that away by arguing that the animal had died in an accident. However, DNA studies last year 4  showed that a fragment of bone embedded in the mastodon's rib had come from another mastodon \u2014 strong evidence that it was a spear point made by humans and not a shard that had chipped off a nearby bone in a fall. The case against Clovis got another major boost last year, when an excavation in Texas unearthed stone tools that pre-dated Clovis-style artefacts by more than a millennium 5 . \u201cWe found a solid site with good context, good artefacts and solid dating,\u201d says Waters. This slow avalanche of findings has all but buried the Clovis model \u2014 the problem now is what to replace it with. The abundant Clovis artefacts and sites discovered over the past century have set a high bar. Telling the story of the first Americans means coming up with a plausible explanation and definitive evidence to support it \u2014 a combination that researchers are struggling to achieve. One idea they are exploring is that a small group of big-game hunters made it into the Western Hemisphere over land \u2014 but significantly earlier than previously thought. Another, more popular, theory argues that humans used boats to navigate along the coast of Siberia and across to the Americas. There is also a controversial variant of the coastal migration model, put forward by archaeologists Dennis Stanford at the Smithsonian Institution in Washington DC and Bruce Bradley at the University of Exeter, UK. Called the Solutrean hypothesis, it suggests that coastal migration from Asia could have been supplemented by parallel migrations across the Atlantic, bringing stone-tool technologies from present-day Spain and southern Europe to eastern North America. DNA studies argue strongly against this hypothesis, and it gets little support from researchers. But some are hesitant to reject the idea outright, recognizing that the community was once before too conservative. \u201cThat's what happened with the Clovis paradigm,\u201d says Dillehay. To move the field forward, researchers are using as many types of data as possible. Some key clues have emerged from studies of population genetics, in which researchers tallied the number of differences between the genomes of modern Native Americans and those of people living in Asia today. They then used estimates of DNA mutation rates as a molecular clock to time how long the diversity took to develop. That provides an estimate for when people split from ancient Asian populations and migrated to the Americas. Judging from the limited genetic diversity of modern Native Americans, Ripan Malhi, a geneticist at the University of Illinois at Urbana-Champaign, and others have argued that the founding population was small, perhaps just a few thousand hardy settlers. In a study of mitochondrial DNA from modern Native American and Asian populations, Malhi and his colleagues also found hints that the first American colonists paused on their way out of Asia 6 , waiting out the peak of the last ice age on the exposed Bering land bridge for perhaps 5,000 years \u2014 long enough to become genetically distinct from other Asian populations. When the glaciers blocking their path into North America began to melt around 16,500 years ago, the Beringians made their way south over land or sea, passing those genetic differences on to their descendants in America. Other researchers say that there is a major problem with relying on population genetics to answer questions about the peopling of the Americas. At least 80% of the New World's population was wiped out by disease, conflict or starvation after Europeans first arrived some five centuries ago. And the genes of many Native Americans today carry European and African markers, which confounds efforts to piece together the migration story. \u201cIf we look pre-contact, we're going to find a lot more indigenous diversity,\u201d says Malhi. That means going back in time, by studying ancient genomes. \u201cYou're going to see a lot of ancient-DNA studies coming out, and that's going to tell a powerful story about the first Americans,\u201d says Waters. The chances of finding well-preserved bones from the first Americans are slim, but valuable information can be pulled from DNA samples that fall in between then and now, argues Eske Willerslev, who studies ancient DNA at the University of Copenhagen. Willerslev and his colleague Thomas Gilbert proved that point in 2010, when they extracted the first complete ancient-human genome from a 4,000-year-old hank of hair found in Greenland that had languished for decades in a museum storeroom in Copenhagen. The DNA helped to show that there had been multiple waves of migration into Greenland, and that modern Greenlanders arrived more recently 7 . Now, Willerslev's lab is trying to extract similar information about population movements from ancient-human remains from sites all over the Americas. \n               Joining forces \n             When paired with sequences from modern populations, ancient DNA can help to refine the calculations made by population geneticists and test the claims made by archaeologists. In 2008, Brian Kemp, now at Washington State University in Pullman, extracted mitochondrial DNA from a 10,300-year-old tooth found in On Your Knees Cave in Alaska. When he compared the DNA sequences with those from modern Native Americans, he found that the mutation rate was faster than previously thought 8 . The results, he says, effectively rule out the possibility that humans came to North America as early as 40,000 years ago \u2014 a date based on equivocal evidence from archaeological sites in the eastern United States. The finding also argues against the idea that people used boats before the thaw to go around the glaciers and come down the coast. Instead, the DNA evidence supports the consensus that people didn't migrate into the Americas \u2014 whether by boat or over land \u2014 until the end of the last glacial maximum, 16,500 years ago at most. The DNA told researchers a few more things. The ancient man who died in that Alaskan cave had mitochondrial DNA most closely related to Native American groups living today along the west coast of North America. \u201cMost of the people who descended from that type are still living near the coast,\u201d Kemp says. So the first wave of migrants probably came down the coast and then spread east from there, developing tiny variations in their DNA as they went, Kemp says. Dennis O'Rourke, a geneticist at the University of Utah in Salt Lake City, is using similar comparisons to fill in the map of ancient migrations in the New World. In the past ten years, dozens of similar studies have established a clear trend \u2014 comparisons of DNA from modern people with ancient DNA have shown that the geographic distribution of genetic groups in the Americas has been stable for millennia. \u201cThe patterns must have been established more than 4,000 years ago,\u201d he says. That helps to constrain the timing of when people spread across the continent and when they stopped migrating, he says. In Point Barrow, Alaska, O'Rourke recently began studying human remains from a cliff-top cemetery threatened by coastal erosion, where people have been buried for the past 1,000 years. By comparing the samples from ancient Alaskans to populations from Greenland, eastern Canada and elsewhere, O'Rourke hopes to learn more about the colonization of the Arctic, an environment similar to what the first Americans would have encountered towards the end of the last ice age. O'Rourke's collaborators are also collecting DNA samples from Inupiat people in northern Alaska. By matching up the modern and ancient DNA sequences from that region, they hope to refine the genetic clock and improve estimates for when people arrived in the Americas. Similar work is going on at a cemetery on Prince Rupert Island off northern British Columbia, where local Tsimshian people are working with archaeologists to gather ancient and modern DNA evidence. While geneticists open up intellectual frontiers, archaeologists are searching for ways to test the migration theories in the field. Direct evidence for coastal migration will be hard to come by, because a rise in the sea level since the end of the last ice age has flooded the ancient coastlines. But researchers are turning up indirect evidence in many locations. Last year, for example, Erlandson demonstrated that humans lived on California's Channel Islands as far back as 12,200 years ago 9 , which shows that they must have mastered the use of boats before that time. And at the Monte Verde site in Chile, researchers have found evidence that the ancient occupants were fans of seafood 10 . \u201cMonte Verde has ten different species of seaweed at the site,\u201d Dillehay says. \u201cSomebody was intimately familiar with seaweeds and the microhabitats where they could be found.\u201d That lends support to the idea that the earliest Americans were seafarers, he says. Dillehay's recent findings, which came 30 years after the first excavations at Monte Verde, show that previously studied sites can become potential gold mines, says Waters. Because so many sites were either dismissed or forgotten during the 'Clovis-first' era, Waters says that \u201cthe field can really be pushed forward by going back and taking a look at sites that were put up on a shelf\u201d. He is already planning to reopen sites in Tennessee and Florida, where evidence of pre-Clovis mammoth hunting was uncovered in the 1980s and 1990s. Geneticists and archaeologists agree that the death of the Clovis theory has injected the field with excitement and suspense. \u201cThere's a sense that there was something before Clovis,\u201d says Jenkins, whose coprolite study shook the field four years ago. \u201cBut what it was and how it led to the patterns that we see in North and South America \u2014 that's a whole new ball game.\u201d See Editorial  page 6 \n                     Mastodon fossil throws up questions over 'rapid' extinction 2011-Oct-20 \n                   \n                     Stone tools cut swathe through Clovis history 2011-Mar-24 \n                   \n                     Oldest American artefact unearthed 2009-Nov-05 \n                   \n                     Texas A&M Center for the Study of the First Americans \n                   \n                     Paisley Caves Research \n                   Reprints and Permissions"},
{"file_id": "485435a", "url": "https://www.nature.com/articles/485435a", "year": 2012, "authors": [{"name": "Nicola Nosengo"}], "parsed_as_year": "2006_or_before", "body": "The world's largest underground laboratory has been a success story for Italian science. But 30 years after construction began, its future is uncertain. The drive along Italy's highway A24 from the central Adriatic coast towards Rome begins with a winding climb into the snow-covered Apennine Mountains, followed by a plunge into the 10-kilometre-long tunnel under Gran Sasso, the highest peak in the region. About half way through the tunnel, a detour leads off to the right. It reaches a dead end almost immediately at a heavy iron gate. But press the intercom button and utter the words 'particle physicist' into the microphone, and the gate slides open like something from a James Bond movie. Not far beyond the gate is a car park. From there one continues on foot, and begins to get some idea of the scale of the infrastructure hidden beneath the mountain. Opening off a long corridor are three huge halls, each about 20 metres wide, 18 metres high and 100 metres long. This vast area is the home of the Gran Sasso National Laboratory, part of the Italian National Institute of Nuclear Physics (INFN). In fact, the laboratory's 180,000 cubic metres of space is not its most valuable attribute. Lying under 1,400 metres of rock, it offers silence \u2014 not an absence of sound, but of cosmic-ray noise, the rain of particles constantly bombarding Earth's surface from space. This lack of cosmic interference has attracted a generation of physicists to these halls, where they can study some of the rarest and most elusive phenomena in the Universe. Most people probably first heard of Gran Sasso last September, when its OPERA experiment reported \u2014 incorrectly, as it turned out \u2014 that neutrinos seemed to travel faster than light. But the laboratory, construction of which began 30 years ago, has long been known to physicists. Gran Sasso \u201cwas the first true underground laboratory, the only one purposely built for science\u201d, says Stanley Wojcicki, a physicist at Stanford University in Palo Alto, California. It is still by far the largest, serving as a base for 18 experiments and about 950 researchers from 32 countries. \u201cGran Sasso's halls have allowed experiments based on different technologies to work side by side, comparing each other's pros and cons, and building multiple generations of the same experiments,\u201d says Kevin Lesko, a neutrino physicist at the Lawrence Berkeley National Laboratory in Berkeley, California. The result has been some long-standing underground rivalries. But they have helped to make Gran Sasso one of Italy's strongest scientific success stories, responsible for a string of notable results in neutrino and solar physics. \u201cIt is our trading currency with the international physics community\u201d says INFN president Fernando Ferroni. At the age of 30, however, Gran Sasso finds itself in transition. Its scientific priorities are changing, and a long collaboration with CERN, Europe's premier particle-physics laboratory near Geneva in Switzerland, is nearing its end. Budget cuts are making it harder to keep Gran Sasso running. International competition is increasing, thanks to proposals to put in new detectors at other facilities such as SNOLAB near Sudbury in Canada, Japan's Kamioka laboratory and the Soudan laboratory in Minnesota, as well as the proposed Deep Underground Science and Engineering Laboratory at the Homestake gold mine in South Dakota. And although many of its experiments have had important results, Gran Sasso is still waiting for its first big discovery: a groundbreaking finding that would match its size and the ambitions that spawned its creation. \n               boxed-text \n             \n               The mystery of the missing neutrinos \n             When Gran Sasso was first conceived in the late 1970s, one of the key motivations was political. Antonino Zichichi, who proposed and oversaw the project as president of the INFN, admits he wanted to give Italy something that would increase its weight in the international physics community and counterbalance CERN's role in European physics. But there were also two solid scientific drivers. The first was the case of the 'missing' neutrinos. Since the late 1960s, US physicist Raymond Davis had been running an experiment in Homestake to detect neutrinos created in nuclear reactions at the core of the Sun. He found only about one-third of the number predicted by theory. Other physicists had suggested a solution: if neutrinos 'oscillate' as they travel in space, spontaneously transforming from one of their three types to another, they would be so thoroughly mixed by the time they arrived at Earth that only about one-third would still be the type that Davis's detector could pick up. But because neutrinos interact so weakly with other particles, testing that idea would require a detector shielded from cosmic rays by hundreds of metres of rock. The other problem was proton decay. Various efforts to build 'grand unified theories' of particle interactions suggested that the proton was ever so slightly unstable, and would decay into lighter subatomic particles with a half-life many times longer than the age of the Universe. The only hope of seeing such a rare event was to monitor a huge amount of matter for a long time, while shielding it from any background radiation that might swamp the signal. All the project needed was a gigantic cavern in a mountain. Zichichi found it at Gran Sasso, 120 kilometres from Rome, where a highway tunnel under the mountain had been started and then abandoned for economic and political reasons. \u201cThe shape of the mountain was ideal\u201d, he recalls. \u201cGran Sasso is flat, so the thickness of the shield remains constant along its length.\u201d INFN physicists measured cosmic rays in the gallery, and found that their flux was about one million times lower than at the surface. Radioactivity measurements were also encouraging, one thousand times lower than on the ground. Gran Sasso's dolomite rock is very poor in uranium and thorium, the main sources of natural radioactivity. A mountain with the ideal physical properties, already containing a tunnel but devoid of traffic \u2014 \u201cit seemed too good to be true\u201d, says Zichichi. Had they had to build the laboratory from scratch, he says, it would have cost too much. As it was, its estimated price tag came to 77 billion Italian lire, roughly equal to US$160 million today. Zichichi presented the project to the Italian Parliament in 1979. It was approved in February 1982 \u2014 a decision had also been made to complete the abandoned highway \u2014 and construction began in September. In 1987, the halls were ready for the installation of the first experiments. Building a scientific community took longer. \u201cFor a long time, Gran Sasso was mostly a training camp for underground physics,\u201d says Ferroni \u2014 an entirely different endeavour from particle accelerator physics, which was where most of the physicists coming to work in Gran Sasso had learned their craft. Rather than smashing particles against each other and seeing what happens, underground physicists spend their days painstakingly selecting and testing materials for use as shields and detectors, weeding out every conceivable source of background noise, and analysing months and months of data \u2014 only to find that, nine times out of ten, a 'signal' is just background noise that somehow got through. The first-generation of experiments established what could and could not be done with underground detectors. Neutrino physics proved especially fruitful: one of Gran Sasso's most notable early experiments was Gallex, which ran from 1991 to 1997 and provided confirmation that Davis's absent solar neutrinos really were missing 1 . But the effort to measure proton decay was quickly abandoned. \u201cEarly theories were too naive,\u201d says Ferroni. \u201cSeeing a proton decay would require one million tonnes of water, or more than 10,000 tonnes of liquid argon. We lack the technology, the laboratory, the money.\u201d Also shot down was the quest for magnetic monopoles: theoretical particles with just one magnetic pole, which were the subject of Gran Sasso's first major experiment, a primarily Italian\u2013US collaboration called MACRO. Researchers searched for the particles between 1989 and 2000, but never caught a glimpse of them 2 . \n               OPERA takes the stage \n             By the 2000s, Gran Sasso had entered into a phase marked by new scientific priorities, a fully formed scientific community and the construction of the larger, more ambitious experiments that now fill its halls (see  'The A, B and C of Gran Sasso' ). Coming from the car park, one first encounters Hall C and the Borexino experiment, a follow-on from Gallex that studies the full energy range of neutrinos emitted by the Sun. Borexino is a huge dome, 18 metres in diameter, with two concentric spheres nested inside it like Russian dolls. The outer dome is filled with ultrapure water that helps to reduce the radiation reaching the innermost sphere, which detects flashes of light caused by neutrinos hitting a scintillator liquid. Cristiano Galbiati, a physicist at Princeton University in New Jersey and a member of the Borexino team, says that the experiment's unmatched background-noise reduction is what allowed the team to report last October the first ever detection of low-energy 'pep' neutrinos, which are produced by a rare reaction in the Sun whereby protons and electrons interact to make deuterium 3 . Predicted by theory but never previously observed, pep neutrinos formed one of the last missing pieces in models that explain how the Sun keeps burning. \u201cLow-energy neutrinos from the Sun oscillate in a completely different way from high-energy ones,\u201d says Galbiati. \u201cThe only way to solve the solar neutrino problem once and for all is to measure neutrinos across the whole spectrum, and this is the only experiment that has knocked background noise down enough.\u201d Right beside Borexino is the now famous OPERA experiment: a detector the height of a three-storey building made of about 150,000 'bricks' of photographic film separated by lead plates. Since 2008, OPERA has been looking for oscillations in a beam of neutrinos fired from CERN, some 730 kilometres away. The beam comprises only muon neutrinos, and the idea is to look for tau neutrinos at the Gran Sasso end, which would prove that they have switched from one type, or 'flavour', to another during their journey. OPERA reported its first tau neutrino in 2010 (ref.  4 ), and the team expects to confirm one or two more before the end of 2012. But that achievement was not all that proponents had hoped. The experiment was first proposed in the 1990s, but negotiations with CERN, whose management was wary of distracting staff and funds from its conventional work, dragged on for the better part of a decade. By the time OPERA finally began collecting data, neutrino oscillations had long since been confirmed by similar neutrino-beam experiments in Japan and the United States. The one consolation was that those experiments were only able to record muon neutrinos disappearing from their beams \u2014 so far, only OPERA has detected their reappearance as taus. However, those results were eclipsed by the OPERA team's announcement in September that its neutrinos seemed to be travelling faster than light 5 . The resulting media frenzy exacerbated divisions among team members \u2014 some of whom refused to sign the announcement preprint, arguing that the collaboration had no business publicizing what was almost certainly an experimental error. The dissidents' objections were also echoed early and often in neighbouring Hall B, home to OPERA's arch-rival ICARUS, a pair of rectangular tanks each 20 metres long and filled with 300 tonnes of liquid argon, that competes with OPERA on the detection of tau neutrinos. \u201cOPERA's confidence level on tau neutrinos is not very high,\u201d says deputy ICARUS spokesperson Sandro Centro. \u201cWe will report our first results this year and we think we can do better.\u201d In October, the ICARUS team flatly contradicted OPERA with its own neutrino-velocity measurement, finding that the particles do not travel faster than light 6 . In the end, the dissidents were right: the source of the error, a loose data cable, was disclosed in February. But the incident led to the resignations of both OPERA's spokesperson, Antonio Ereditato, and its physics coordinator, Dario Autiero. Former Gran Sasso director Mario Monacelli, who is now an OPERA scientist and one of those who did not sign the velocity paper, says that the frenzy has not interfered with the experiment's day job. \u201cBut it has created tensions that will take some time to go away,\u201d he says. \u201cWe are now working to prevent the collaboration from breaking into opposing factions.\u201d Another locus of tension can be found in Hall A and its surroundings, much of which are occupied by experiments searching for dark matter. The existence of dark matter is abundantly clear to astronomers, who can see its gravitational effect on galaxies and clusters of galaxies through their telescopes. But its nature is a mystery: the stuff is utterly transparent, and passes through stars and planets as if they weren't there. A prevailing theory holds that it is a haze of weakly interacting massive particles (WIMPs) that formed during the Big Bang, and have permeated the Universe ever since. The trick is to catch and study WIMPs in a laboratory detector \u2014 a task that, once again, requires ultra-low background radiation. Gran Sasso's dark matter (DAMA) experiment, which opened in 1996 and has gone through many upgrades since, looks for flashes of light that occur when dark-matter particles collide with the atoms of a sodium iodide crystal. DAMA works on the assumption that Earth's velocity through the dark matter in our Galaxy varies as it orbits the Sun, producing an annual variation in the flux of dark-matter particles passing through the detector. For 13 years, the team has been reporting just such an oscillation in signal, although one that is consistent with dark-matter particles lower in mass than most theorists expect 7 . The source of the tension lies just a few metres away, in XENON100: a US-led experiment that has been using more than 100 kilograms of liquid xenon as a detector for WIMPs since 2009. With its first publication in 2010, covering its first 11 days of data, the XENON team found no sign of WIMPs in DAMA's mass range 8 . The public finger-pointing goes on to this day. DAMA's Rita Bernabei insists that XENON's results depend on a specific model of dark matter. \u201cThere are candidates, scenarios and uncertainties that can account for all the results presented so far,\u201d she says, including those from both DAMA and XENON. But XENON scientist Francesco Arneodo is dubious. \u201cYou can play with models as much as you want, but it's a pity they did not make any effort to stimulate similar experiments elsewhere, which would close the argument,\u201d he says. Ferroni sees only two possible resolutions for the DAMA controversy. \u201cEither they will end up describing some previously unknown source of background noise,\u201d he says, \u201cor they will go straight to Stockholm\u201d to collect a Nobel prize. \n               The road ahead \n             Leaving behind the close atmosphere of the underground halls and following the highway tunnel to its western end, it's a short drive to the base of the mountain. Here, in Gran Sasso's above-ground offices, director Lucia Votano is planning its future. Funding remains a concern, she says. Gran Sasso costs the INFN almost \u20ac10 million (US$12.8 million) a year \u2014 not including the experiments. The agency's budget has shrunk by one-third during the past decade, and a further 5% cut is anticipated in 2013 owing to Italian austerity measures. But even without cuts, she says, many things will soon change under the mountain. By the end of 2012, the neutrino beam will vanish when CERN shuts down its accelerators to upgrade its flagship Large Hadron Collider. OPERA and ICARUS will almost certainly be disbanded. \u201cAt the moment it's really not clear what the future of neutrino physics in Europe will be,\u201d says Centro \u2014 although the ICARUS detector will be moved to CERN and used as a testbed to develop much larger detectors. Gran Sasso, meanwhile, will be left to focus on dark matter, and on a second longstanding mystery just as crucial for understanding phenomena not predicted by the standard model of particle physics: neutrino-less double beta decay. This is a hypothetical form of radioactivity, thought to be extremely rare, that would be possible only if the neutrino is its own antiparticle. In 2001, Hans Klapdor-Kleingrothaus and his colleagues reported detection of the phenomenon using a now-dismantled experiment in Gran Sasso 9 . But no other experiment has been able to replicate the finding so far, and Klapdor-Kleingrothaus's use of statistics has been criticized by some scientists 10 . Although, admits Ferroni, who counts himself a sceptic, \u201cif those results are wrong, they are so in a much less obvious way than the OPERA one\u201d. Votano and Ferroni expect that Gran Sasso's GERDA experiment, which is looking for neutrino-less double beta decay in a detector with exceptionally low background radiation, will decisively confirm or reject the result within a couple of years. In around 2014, it will be joined by CUORE, a tower made from 1 tonne of tellurium dioxide. In the end, both experiments will probably prepare the ground for even larger detectors, which will further increase the probability of spotting the very unlikely event they are after. \u201cIt is too early to say which technology works best,\u201d says Votano. As for dark matter, the XENON team is now building a 1-tonne detector \u2014 expected to begin collecting data by late 2014 \u2014 that will become the world's most sensitive detector for WIMPs. Another experiment in the making, DarkSide, will use 50 kilograms of liquid argon as its detector and will borrow the successful background reduction system of the Borexino experiment. DAMA, meanwhile, will undergo a further upgrade. And the German experiment CRESST is already looking for dark-matter collisions in crystals at temperatures near absolute zero. Given all that, says XENON spokesperson Elena Aprile, a physicist at Columbia University in New York, \u201cthe first detection of a WIMP will come from Gran Sasso\u201d. Or, at least, she says, \u201cthis is where we will understand if we are completely on the wrong track\u201d. However, they have competition. Similar dark-matter and double-beta-decay experiments are under construction or already running at Homestake, Sudbury and Kamioka. And with the completion of the 2,500-metre-deep Jin-Ping laboratory two years ago, China has joined the dark-matter race. Many of these experiments may take advantage of better natural shielding \u2014 something that physicists measure as metres of water equivalent. Gran Sasso's shielding equals 3,300 metres of water, against 4,100 at Homestake and almost 6,000 at Sudbury. On the other hand, says Votano, Gran Sasso has developed techniques \u2014 such as the Russian-doll system pioneered by Borexino \u2014 that allow it to simulate a greater depth. It remains the largest and best equipped underground laboratory in the world. And, Aprile says, pointing to the snowy peaks that surround the external laboratories, the location is hard to beat. \u201cIf I can make good physics in a place like this, why not?\u201d\n \n                     Particle physics: A matter of detail 2012-Apr-18 \n                   \n                     Neutrinos not faster than light 2012-Mar-16 \n                   \n                     Particles break light-speed limit 2011-Sep-22 \n                   \n                     Roman ingots to shield particle detector 2010-Apr-15 \n                   \n                     Lucia Votano 2009-Aug-19 \n                   \n                     Gran Sasso National Laboratory \n                   \n                     The DUSEL/SURF project at Homestake \n                   \n                     SNOLAB \n                   \n                     Kamioka Underground Observatory \n                   Reprints and Permissions"},
{"file_id": "483528a", "url": "https://www.nature.com/articles/483528a", "year": 2012, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Biologists ponder what fundamental discoveries might match the excitement of the Higgs boson. Biologists may have little cause to envy physicists \u2014 they generally enjoy more generous funding, more commercial interest and more popular support. But they could have been forgiven a moment of physics envy last December when, after a week of build-up and speculation, researchers at the Large Hadron Collider (LHC) near Geneva in Switzerland addressed a tense, standing-room-only auditorium. Scientists there had caught the strongest hints yet of the Higgs boson: what some have called the 'God particle' and the final missing piece of the standard model that explains the behaviour of subatomic particles. The discovery, if confirmed, will mark the culmination of a hunt that has taken years and cost billions of dollars, and will shape the field for years to come. The research community was abuzz. \u201cThere were lots of rumours flying around about how significant the signal was,\u201d says Lisa Randall, a theoretical particle physicist at Harvard University in Cambridge, Massachusetts, who got up at 4 a.m. to talk to the press before watching the webcast of the presentation at the LHC. \u201cIt's been quite exciting.\u201d All this led  Nature  to wonder: what fundamental discoveries in biology might inspire the same thrill? We put the question to experts in various fields. Biology is no stranger to large, international collaborations with lofty goals, they pointed out \u2014 the race to sequence the human genome around the turn of the century had scientists riveted. But most biological quests lack the mathematical precision, focus and binary satisfaction of a yes-or-no answer that characterize the pursuit of the Higgs. \u201cMost of what is important is messy, and not given to a moment when you plant a flag and crack the champagne,\u201d says Steven Hyman, a neuroscientist at the Broad Institute in Cambridge, Massachusetts. Nevertheless, our informal survey shows that the field has no shortage of fundamental questions that could fill an anticipatory auditorium. These questions concern where and how life started \u2014 and why it ends. \n               Is there life elsewhere? \n             In 1964, palaeontologist George Gaylord Simpson wrote a stinging dismissal of exobiology, the search for life on other planets. \u201cThis 'science' has yet to demonstrate that its subject matter exists!\u201d he wrote 1 . The searing critique caused many researchers in the nascent field to shy away from exobiology. But it was unfair, says planetary scientist Christopher Chyba of Princeton University in New Jersey. Chyba has for years been comparing the search for life on other planets to the search for the Higgs: another quest whose subject has never been proved to exist. \u201cWhy should we suddenly become giggly when it is biology at stake, rather than physics?\u201d Chyba wrote in a 2005 rebuttal to Simpson's attack 2 . The search for extraterrestrial life can be described as one way to test \u201ca standard model of biology\u201d, says astrobiologist Chris McKay of the NASA Ames Research Center in Moffett Field, California. \u201cIt's the model of DNA and amino acids and proteins and a genetic code,\u201d he says. \u201cIt's the common features of all biology, and the framework through which everything we know about life is based.\u201d If life fundamentally different from this standard model \u2014 perhaps relying on a wildly different biochemistry \u2014 were found on another planet, it would show that there is more than one way to produce a living system, he adds. Others say they don't need evidence of such a 'second genesis' to get a Higgs-like thrill from the prospect of life on other planets. \u201cIf we found our same biology, but on Mars, that would be pretty exciting,\u201d says biochemist Gerald Joyce of the Scripps Research Institute in La Jolla, California. \u201cThen the question would be: where did it come from first?\u201d But whereas the Higgs-hunters in Geneva have a good idea of what to look for, astrobiologists seeking alternative forms of life face a bigger logistical challenge: figuring out what clues are most revealing. The chemical signatures of compounds that are commonly associated with life, such as methane or liquid water, could identify planets to focus on. But atmospheric signatures of life are unlikely to be convincing, says Chyba. Within the Solar System, McKay puts his money on three habitats as most likely to harbour life: Enceladus, an icy moon orbiting Saturn that, according to NASA's Cassini spacecraft, probably has liquid water and is spewing organic material from cracks in its surface 3 ; Mars, but \u201cold Mars, not Mars today\u201d; and Jupiter's moon, Europa, whose icy surface masks tantalizing seas of water. The Mars Science Laboratory, scheduled to land on the red planet in August, will include a simple mass spectrometer and a laser spectrometer, enabling it to detect methane, and could reveal preliminary signs of life. But the mission is not designed to yield definitive evidence. Another way to hunt for life is to look for organic molecules that are too complex to have arisen by simple chemical synthesis, unaided by enzymes. \u201cLet's say you came to Earth and scooped up matter,\u201d says McKay. \u201cYou'd find all of this chlorophyll and DNA: big, huge, complex molecules that were clearly there in high abundance and distinctly different from what you'd expect from a chemical mix.\u201d Finding this would require sophisticated equipment that had been baked and scrubbed free of earthly contaminants and, at present, there are no concrete plans to include such equipment on NASA's proposed trips to Mars or Europa. \u201cMy sense is that people are just trying to avoid it as long as possible,\u201d Chyba says. \u201cMoney is extremely tight, but at some point we'll just have to bite the bullet.\u201d Searching rocks on other planets for fossils is another popular proposition, says Jeffrey Bada, a planetary geochemist at the Scripps Institution of Oceanography in La Jolla. \u201cThat's easy enough,\u201d he says. \u201cBut if you don't find them, does that tell you that life never existed there?\u201d McKay argues that fossil evidence or living proof of life may be required to convince a field. \u201cUltimately, you'll have to have a body,\u201d he says. \u201cIt doesn't have to be alive, but you'll have to have a body.\u201d \n               Is there foreign life on earth? \n             Alien life \u2014 and a Higgs moment \u2014 might also be lurking close to home. Some have postulated the existence of a 'shadow biosphere' on Earth, teeming with life that has gone undiscovered because scientists simply don't know where to look. It could contain life that relies on a fundamentally different biochemistry, using different forms of amino acids or even entirely novel ways of storing, replicating and executing inherited information that do not rely on DNA or proteins. The idea is not as far-fetched as it might sound, says Steven Benner, a chemist at the Foundation for Applied Molecular Evolution in Gainesville, Florida. Researchers have found shadow biospheres before. The invention of the microscope revealed whole new worlds, says Benner; and the discovery of a new realm of microorganisms, the archaea, opened a window on another. \u201cThe question is: is it going to happen again?\u201d The trick is deciding what to look for and how to detect it. The usual way that researchers search for new organisms \u2014 by sequencing DNA or RNA \u2014 will not pick up life that does not depend on them. Some scientists have speculated that desert varnish, a peculiar dark-coloured coating of unknown origin found on many desert rocks, could be a product of a shadow biosphere. Benner suggests looking in nooks and crannies that cannot support conventional life, such as areas with extremely high temperatures, radiation levels or harsh chemical environments. Felisa Wolfe-Simon, now at the Lawrence Berkeley National Laboratory in Berkeley, California, and her colleagues took this approach when they searched for life in the arsenic-rich environment of California's Mono Lake. In late 2010, they reported the discovery of a life form that can use arsenic in place of phosphorus in its DNA and proteins \u2014 a seemingly remarkable departure from conventional life 4 . But at least one attempt to reproduce the result has failed. Another approach is to search on the basis of size. If cells were liberated from their reliance on bulky ribosomes and proteins, they could be much smaller, says Benner, perhaps tucked away in rocks with pores only nanometres across. That is the rationale behind a project that John Atkins, a molecular geneticist at the University of Utah in Salt Lake City, is pursuing with Richard Herrington of the Natural History Museum in London. They plan to sequence the contents of rocks of different ages and origins with pores less than 100 nanometres in diameter. By screening for nucleic-acid sequences that lack the code for protein-making ribosomes, they hope to find a protein-free life form that has its roots in RNA, as known life probably does, but that arose independently. \u201cThe RNA world is thought to have originated, in geological terms, relatively quickly,\u201d Atkins says. \u201cSo why couldn't it have arisen again multiple times?\u201d \n               How did life start\u2026? \n             Even if alternative forms of life elude scientists, a fuller picture of how familiar life originated on Earth would surely create ripples in biology. Joyce says that there will come a point at which researchers learn how to synthesize an evolving, replicating system from scratch. Getting there won't have the \u201cmonolithic, big-science march across the goal line\u201d that has characterized the search for the Higgs, he cautions. But it will answer a key biological question: what does it take to create life from a primordial soup? And that could provide insight into how life on Earth began. \u201cWe'll never know for sure, but at least you can test plausible hypotheses,\u201d says James Collins, a synthetic biologist at Boston University in Massachusetts. Several labs have already made headway. Joyce and his collaborators have pioneered work on the RNA-world concept, in which RNA molecules, capable of encoding information and catalysing chemical reactions, replicated and evolved faster than they degraded. RNA is notoriously unstable, and the idea is that, over time, this system gave way to DNA, a sturdier system for storing information, and proteins, a more versatile mode of catalysing reactions. \u201cThe transition to DNA and protein created the potential to evolve into more complex things,\u201d Bada says. In 2009, a paper from Joyce's lab reported the development of a system of RNA molecules that undergo self-sustaining Darwinian evolution 5 . But enzymes and a human hand were needed to create the RNA sequences to start off the reaction, Joyce says, and so far his lab has not found conditions that would allow the system to form spontaneously. \u201cWe're still a bit challenged,\u201d he says. \u201cBut the system is running more and more efficiently all the time.\u201d Jack Szostak and his colleagues at Harvard Medical School in Boston have taken a different approach, enclosing RNA molecules in fatty-acid vesicles as an early step towards the creation of a primitive cell. The vesicles grow and divide spontaneously, but the genetic material does not replicate without the aid of an enzyme 6 . Some believe that RNA may have had a precursor. Ramanarayanan Krishnamurthy at the Scripps Research Institute, is testing novel polymers of organic chemicals that could have formed in the primordial goo, in search of those that could replicate and evolve. \u201cRNA was not the first living entity,\u201d says Bada. \u201cIt's too complex. Something preceded RNA, and that's where the interest is right now.\u201d \n               \u2026 and can we delay its end? \n             In a 1993 review 7 , Linda Partridge and Nicholas Barton, both then researchers on ageing at the University of Edinburgh, UK, delivered \u201ca baleful message\u201d to the field of gerontology. The complexity of the biological networks that influence ageing, they wrote, means \u201cit is most unlikely that engineering of a few genes or intervention in a handful of physiological pathways will prevent the process from occurring.\u201d Things have changed. \u201cI could tolerate that debate 20 years ago,\u201d says Richard Miller, who studies ageing at the University of Michigan in Ann Arbor. \u201cBut now it's just wrong.\u201d Some eight months after the publication of Partridge and Barton's review, Cynthia Kenyon and her colleagues at the University of California, San Francisco, reported that mutations in a single gene allowed the nematode  Caenorhabditis elegans  to live more than twice as long as usual 8 . Three years later, a group led by Andrzej Bartke, who studies ageing at Southern Illinois University in Springfield, reported that mice bearing a single mutation that causes hormonal deficiencies live up to 68% longer than mice without the mutation 9 . Both papers, and a slew of work since, have suggested that it might be possible to significantly slow human ageing and its associated diseases. Such an intervention could have a tremendous impact on society, adding years of health and economic productivity, but creating new strains on a society having to support many more older people. And scientifically, the ability to slow ageing would address Higgs-like fundamental questions about human life: why do we age; what pathways control it; and what are the consequences if they are switched off? There are signs that such interventions may exist. In 2010, Miller and his colleagues showed that feeding mice a drug called rapamycin lengthened their average lifespan by 10% for males and 18% for females 10 . And slashing calorie intake by 25\u201340% can extend lifespan in mice and other mammals. But there is no proof that these approaches would work in humans and, even if they did, neither is likely to catch on: rapamycin can suppress the immune system, and few people can tolerate brutal dietary restriction. One major challenge for the field is to prove that a putative life-extending agent actually works \u2014 something that in humans would take 60 years or more. Jay Olshansky, who studies ageing at the University of Illinois in Chicago, says the field should set a concrete goal: a seven-year delay in the onset and progression of age-related disease. \u201cIf you look at the risk of most of the things that go wrong with us as we grow older, age-related risk doubles roughly every seven years,\u201d he says. \u201cIf you eliminate one doubling, you reduce the risk of everything by half. It would be monumental.\u201d Miller has a different goal. \u201cWe will have the answer when we have something that we can put in dog food that extends the average dog's lifespan by 15 to 20%,\u201d he says. Dogs offer an ideal intermediate between mice and humans, says Miller: they are considered a long-lived species and live side-by-side with humans. But Partridge and Barton's observations about the complexity of ageing still hold true. Most researchers acknowledge that they are only beginning to understand the molecular networks that regulate ageing and its associated diseases. \u201cI don't believe there's one cause of ageing,\u201d says Brian Kennedy, president of the Buck Institute for Research on Aging in Novato, California. \u201cBut there are pathways that are designed to modulate many things at one time. I think a lot of the genes and drugs we're studying are tapping into those.\u201d At this point, a life-extending therapy seems a much more distant prospect than does confirmation of the Higgs boson. Last month, researchers announced a bump in data from the Tevatron, the US particle collider at Fermilab in Batavia, Illinois, that is consistent with results from the LHC. It has added to physicists' excitement that they are on the threshold of discovery. Ageing, however, \u201cis almost the complete inverse of the situation of the Higgs particle\u201d, reflects Thomas Kirkwood, a leader in the field at Newcastle University, UK. \u201cEverything that we're learning tells us it's highly unlikely that we'll find a single unitary cause.\u201d \n                     Boost for Higgs from Tevatron data 2012-Mar-07 \n                   \n                     Debate bubbles over the origin of life 2012-Feb-13 \n                   \n                     Detectors home in on Higgs boson 2011-Dec-13 \n                   \n                     Enceladus named sweetest spot for alien life 2011-May-31 \n                   \n                     Solar System showdown 2010-Jul-06 \n                   \n                     Large Hadron Collider \n                   \n                     Mars Space Laboratory \n                   \n                     NASA Astrobiology \n                   Reprints and Permissions"},
{"file_id": "484021a", "url": "https://www.nature.com/articles/484021a", "year": 2012, "authors": [{"name": "Jennifer Frazer"}], "parsed_as_year": "2006_or_before", "body": "The mysterious Kawasaki disease might cross the Pacific on air currents high in the atmosphere. The desperately ill baby had been airlifted in from Wyoming, recalls Jane Burns, thinking back to 1981 and her third year as a paediatric resident at the University of Colorado School of Medicine in Denver. Twenty-one days later, the little girl's skin rashes were mostly gone, but the accompanying fever was still raging, and Burns had no idea why. \u201cI think this is Kawasaki disease,\u201d said Richard Anderson, an infectious-disease fellow at the school, who had also examined the tiny patient. Burns was stunned. Kawasaki disease was uncommon even in Japan, where it had been first identified in the early 1960s, and was almost unheard of in the United States. It was also utterly mysterious \u2014 some kind of inflammation in the blood vessels that primarily targeted children under the age of five and produced a variety of dramatic symptoms (see 'Mysterious malady'). Burns had heard of the disease only because she had encountered two Kawasaki disease patients in the previous year. And now Anderson was telling her she'd just got a third. Less than 12 hours later, the baby was dead. \u201cI was so completely amazed by this disease that had now come and got me for a third time that I did the post mortem with the pathologist,\u201d says Burns. \u201cAnd I'll never forget opening up her chest and looking at her heart and seeing the aneurysms sitting there.\u201d These balloon-like bulges are common enough in the blood vessels of adults, especially those with risk factors such as diabetes or high blood pressure. But in a once-healthy infant? For Burns, now a paediatrics researcher at the University of California, San Diego (UCSD), and director of the Kawasaki Research Center at the UCSD Children's Hospital, the baby's death was a turning point. She has been studying Kawasaki disease ever since, whenever she can find funding. And she is not alone. \u201cKawasaki disease is something that has been fascinating people in infectious disease since it was described,\u201d says Ian Lipkin, an epidemiologist and director of the Center for Infection and Immunity at Columbia University in New York. \u201cIt smells like an infectious disease; we've just never been able to catch the culprit. Epidemiologists now have a new place to look: on winds blowing from central Asia. A team of medical and climate scientists, including Burns, argue in last November's issue of  Scientific Reports 1  that the agent of Kawasaki disease is not only reaching Japan from the Asian mainland by this route, but it seems to be crossing the Pacific Ocean to infect children in Hawaii and the North American mainland. If windborne spread turns out to be true, the Kawasaki disease agent will be the first viable human disease pathogen proved to cross thousands of kilometres of ocean by natural means (as opposed to carriage on planes or ships). And it may not be the last: researchers are beginning to ask whether the wind might also be a factor in the spread of influenza. \n               First signs \n             Japanese paediatrician Tomisaku Kawasaki saw his first case of the disease in 1960. He had no idea what it was. But it was so striking that he made diagrams and kept detailed records of the symptoms. \u201cHe had this joke that he filed it in a folder called GOK, which was God Only Knows,\u201d says Burns. Jennifer Frazer talks about the hunt for the cause of Kawasaki disease Kawasaki published the first formal description of the malady in 1967 in Japanese 2 . Since then, there have been three major outbreaks in Japan: peaking in April 1979, May 1982 and March 1986. And the number of cases has been rising steadily each year (see 'Seasonal cycle'), despite Japan's falling birthrate. Today, the average annual incidence of about 12,000 cases in Japan rivals that of the earlier outbreaks at their peaks. Even in San Diego, Burns sees 80 to 100 new cases a year. It is hard to say how widespread the disease actually is, because outside Japan the diagnosis is probably missed as often as not; children get mysterious rashes all the time. But the consequences can be serious. The kind of aneurysms that Burns saw in the 1981 autopsy occur in a quarter of untreated cases, and kill about 1 patient in 100. In addition, the body's attempts at repair can cause a build-up of scar tissue or narrowing of the arteries. \u201cDamage can be completely silent for decades until it's not,\u201d Burns says. \u201cAnd the presentation can be with a massive heart attack in these young adults, who just have no idea why this is happening to them.\u201d Genetics seems to play a big part, she says. Asian children are more susceptible than those in other ethnic groups. The immune system is deeply involved as well. The disease is characterized by widespread inflammation, which eventually focuses on the smooth muscle cells found in the walls of medium-sized arteries, in the heart and elsewhere, and can lead to aneurysms. The only effective treatment is intravenous injection of human immunoglobulin G, the major antibody fraction in blood, which \u2014 for reasons that are still not completely understood \u2014 lowers the probability of aneurysms from 25% to 1\u20135%. Yet the cause of the disease remains GOK: for decades, researchers have looked for the Kawasaki disease agent among viruses, bacteria and every other category of pathogen, to no avail. Lipkin has been collaborating with Burns on this search for 20 years, applying each new molecular diagnostic tool as it came along and coming up empty-handed each time. Burns herself spent much of the 1980s investigating an initially promising link between Kawasaki disease and carpet cleaning, only for it to lead nowhere. In the mid-2000s she started looking at a possible connection between Kawasaki disease and climate, along with Daniel Cayan, a meteorologist at the Scripps Institution of Oceanography at UCSD. Their first success came when they analysed the incidence of Kawasaki disease in Japan by prefecture, using Burns's contacts in the country to access detailed records of nearly 85,000 patients between 1987 and 2000. A trend was clear: cases were sharply seasonal, peaking in the winter and early spring, and again in early summer, which suggested that an environmental factor was involved 3 . Funding ran out and that lead went cold. But then in 2007, Cayan heard a lecture by Xavier Rod\u00f3, director of the Catalan Institute of Climate Sciences in Barcelona, Spain, who was on sabbatical at UCSD. Rod\u00f3 had experience in figuring out how climate affects infectious diseases such as cholera, and had designed mathematical and statistical tools to pick out variables that might have low signal-to-noise ratios, or that might be intense but brief. After the lecture, Rod\u00f3 recalls, Cayan told him about Burns and her access to the extraordinary database of Japanese Kawasaki disease patients. \u201cHe said many people have had a go at this disease but no one really found anything that significant,\u201d says Rod\u00f3 \u2014 a challenge too good to refuse. Adding Japanese records of more than 247,000 patients to his programs, Rod\u00f3 let the software plough through a plethora of climate variables, including temperature, precipitation and humidity. One trend popped out: when the winds blew from central Asia across Japan, the number of Kawasaki disease cases skyrocketed. All three major outbreaks in Japan had followed this pattern, and it was also evident in the normal disease seasons. When the winds shifted to blow from the Pacific, cases dropped 1 . And when winds from central Asia made their way to Hawaii or California, cases spiked there too. \u201cI must say I was really shocked and surprised,\u201d says Rod\u00f3. The climate\u2013disease correlation had fallen out with remarkable ease. And, the implication \u2014 that a human disease agent might still remain active after riding the winds all the way across the Pacific \u2014 was unprecedented. Certainly the group's analysis would fly in the face of conventional wisdom if the disease agent proves to be a living organism, says Burns. Microbiologists have generally assumed that ultraviolet radiation and the near-cryogenic temperatures at high altitude will annihilate any infectious microbes before they can make it across an ocean. But maybe not, she says. \u201cMy background is molecular virology. When I preserve my viruses in the lab, what do I do? I desiccate them and freeze them at \u221280\u00b0C. Well, hello! Those are the conditions up in the troposphere.\u201d Besides, says Burns, wind is often full of dust. \u201cIf you take a dust particle and look at it under the electron microscope, it's like a whole universe,\u201d she says. \u201cIt's got nooks and crannies and valleys and peaks\u201d, any of which could shelter a microbe or two from solar ultraviolet. It's certainly the case that wind can carry pathogens short distances, says Arturo Casadevall, a microbiologist at the Albert Einstein College of Medicine in New York. He points to coccidioidomycosis, or valley fever, a human fungal disease that often appears in the US Southwest after dust storms or when earthquakes shake spores from the soil into the air. And over longer distances, there is evidence that the fungus  Aspergillus sydowii  rides west on dust storms from Africa to cause disease in sea fans in the Caribbean 4 . Dale Griffin, an environmental and public-health microbiologist at the US Geological Survey in Tallahassee, Florida, has studied African dust storms close up. On cruises to the waters over the Mid-Atlantic Ridge, Griffin has taken air samples just above the boat and cultured hundreds of microorganisms, including two fungal plant pathogens, the bacterium  Pseudomonas aeruginosa , which can cause fatal infections in burn victims, and  Brevibacterium casei , which can cause blood infections. He estimates that about 10\u201320% of the dust-storm culture samples are pathogens. Griffin, who has also collaborated on a project that cultured microorganisms from samples collected at an altitude of 18 kilometres in the stratosphere 5 , believes that Rod\u00f3 and his colleagues have made a strong case that Kawasaki disease is riding the wind. \u201cIt's not surprising to me that an agent that has yet to be identified could be moving in the atmosphere \u2014 with dust or without dust,\u201d he says. \u201cWe also know there are many, many species that are very tolerant and can make long journeys in the atmosphere.\u201d \n               Finding the culprit \n             Casadevall agrees that the case for wind-borne Kawasaki disease is strong, but goes on to emphasize that correlation is not causation, a point also raised by researchers sceptical of the theory. \u201cIn the past, people have made claims about this sort of thing, but it's all circumstantial,\u201d says Donald Aylor, a plant pathologist at the Connecticut Agricultural Experiment Station in New Haven, who has studied the wind dispersal of plant pathogens and pollen for 35 years. Even if the wind is blowing in a certain direction when a particular disease shows up, he says, it can be difficult to prove that a wind-blown pathogen is to blame. And when the pathogen is a total unknown, as in Kawasaki disease, the difficulties are even greater, he says. \u201cYou would have to ask yourself what else was happening during the time that the Kawasaki outbreak was happening. I mean, there could be a million things, right?\u201d The best way to counter this objection, Burns and her collaborators know, is to find the airborne pathogen. With Lipkin, they set up an experiment to filter the air over Japan at various altitudes during a period when the agent was suspected to be present, and then to sequence the DNA of everything on the filter \u2014 an approach known as 'metagenomics'. In early March 2011, a Spanish engineer wearing a protective suit to prevent contamination went up in an aircraft that carried an air-filter built by Rod\u00f3's lab in Barcelona. The craft followed a route mapped out by Rod\u00f3 using real-time wind data. When it returned, the samples were packed in dry ice and shipped to Lipkin's lab at Columbia. The timing was particularly fortunate as the route had criss-crossed Japan's Fukushima region. Just a week later, after nuclear reactors there were damaged in the earthquake and tsunami on 11 March, the winds would be full of radioactivity. At Columbia, where the metagenomic analysis is being carried out by biologist Brent Williams, progress has been slow because of the minuscule amounts of DNA present in air samples taken at high altitude. But the work is beginning to pay off, says Lipkin. Williams has found candidates for the Kawasaki agent \u2014 although Lipkin declined to discuss them before publication \u2014 and will soon be progressing to immunoassays. In these, antibodies generated to proteins predicted to be expressed by the suspected disease agent will be mixed with serum samples from children who have had Kawasaki disease and from controls who have not. If the antibodies interact significantly more strongly with the Kawasaki disease samples than with the controls, the team can be more confident that its suspected Kawasaki agent is the real thing. The next step will be to look for DNA sequences in the blood samples of affected children that match the DNA detected in the air samples. \u201cThat would also be strong circumstantial evidence that would give us confidence that we're on the right track,\u201d Lipkin says. With the identification of a causative agent, many more questions about Kawasaki disease could be addressed. Where is the agent's natural reservoir and is there an animal host? Why did this agent only emerge to cause disease in the 1950s and 60s? And why is its incidence rising? And, of course, what other diseases are blowing in the wind? Taiwanese scientists, noting that outbreaks of avian influenza often occur downwind of dust storms, found influenza virus in air samples, and found that concentrations of the virus spiked when dust storms blew in from central Asia 6 . So, says Burns, \u201cwhy don't we acknowledge the possibility that agents important for human health could be travelling on these wind currents?\u201d \n                     'Rain-making' bacteria found around the world 2008-Feb-28 \n                   \n                     Earth sows its seeds in space 2004-Feb-23 \n                   \n                     The Long Strange Journey of Earth's Traveling Microbes \n                   \n                     The Center for Infection and Immunity at Columbia University \n                   \n                     The High Life: Transport of Microbes in the Atmosphere \n                   \n                     The Kawasaki Disease Research Center at UCSD \n                   \n                     The Kawasaki Disease Foundation \n                   Reprints and Permissions"},
{"file_id": "484155a", "url": "https://www.nature.com/articles/484155a", "year": 2012, "authors": [{"name": "Helen Pearson"}], "parsed_as_year": "2006_or_before", "body": "Researchers in Britain have tracked thousands of children since their birth in the 1990s. Now the study is 21, and turning to the next generation. In a secure storage barn on the outskirts of Bristol, nearly 9,000 placentas float in plastic buckets of formaldehyde. Twenty-five kilometres away, in the basement of a university building, baby teeth from more than 4,000 children fill cardboard boxes in a walk-in freezer. Next door are some 15,000 nail clippings and 20,000 locks of hair. A few steps farther, a parade of freezers house row upon row of bar-coded blood cells, plasma, urine, saliva and chunks of umbilical cord that together make up a tissue library with more than one million entries. This library is the harvest from an unusual study of humanity. In 1990, researchers started to collect tissues and detailed information from more than 14,500 pregnant women in this western British city and its surrounding region of Avon. The women filled in more than 100 pages of questionnaires about their health, relationships, work and home. After birth, researchers tracked the children's development through surveys, clinical examinations and biological samples. They know what the kids ate, when they first talked, how often they fell sick and when a parent read to them \u2014 or deserted them. They know when the children started to hit puberty, drink alcohol, have sex and leave home. In that wealth of data \u2014 collected at a cost of some \u00a342 million (US$67 million) so far \u2014 they are tracing how genetic and environmental factors in the children's early years affect their later ones. Now, the Bristol cohort study is coming of age, literally and scientifically. This spring, the first members of the group turn 21. And on 18 April, leaders of the study and their collaborators from around the world will meet in Bristol to discuss what they have learned from the Avon Longitudinal Study of Parents and Children (ALSPAC), also known as the Children of the 90s. The rich collection of tissues and behavioural data \u2014 a comprehensive phenotype for each of thousands of participants \u2014 makes the study unique and invaluable, say its leaders. \u201cIt's the deepest phenotyping and biobank resource of any large birth cohort \u2014 unequivocally,\u201d says George Davey Smith, the study's scientific director. The results have generated more than 700 scientific papers and range from policy-changing health advice for pregnant women and young children to the discovery of genetic factors involved in fetal growth, obesity, allergies and bone density 1 , 2 , 3 , 4 . The study has also inspired and guided other birth cohorts, including the world's largest, which is tracking more than 100,000 children in Norway. Directors and participants of the Bristol cohort talk about turning 21. Yet many of the data and samples remain untouched, and the cohort leaders acknowledge that the most important findings are likely to emerge years from now, some of them courtesy of new techniques that the founders of the study could barely have imagined. Davey Smith and his colleagues are just starting to analyse the children's genomes \u2014 2,000 of which have been fully sequenced \u2014 and epigenomes, the catalogue of chemical footprints left on a child's DNA by experiences in the womb or in the world. The researchers say that such studies will help them to move from a slew of loose epidemiological associations \u2014 between a mother's fish-eating and her child's intelligence, for example \u2014 to the genetic and epigenetic players responsible for those links. As the children themselves become parents, the team is expanding the scope of the study to a new generation. Still, at the heart of all this remains an unanswered question: how much value is there in collecting a huge amount of information about human life when the scientific pay-off is unknown? Marcus Pembrey, who was director of genetics at ALSPAC until 2005, recalls that when he initially told colleagues that he wanted to measure \u201ceverything\u201d about the children, \u201cthey laughed and said you can't study everything. And I said you have to study everything. You don't know what will be important in the future. \n               Conception and birth \n             Today, the effort to gather everything is headquartered in a concrete slab of a building in central Bristol. On the ground floor, a brightly painted annex houses a clinic where the children of the 90s come for their regular medical examinations. A few middle-aged men \u2014 the dads of the cohort members \u2014 are here, going from room to room for blood-taking, cognitive testing and bone scans. The study scientists are bringing in as many dads as they can to collect clinical data such as DNA, height, weight and blood pressure, in an effort to ramp up studies on the fathers' health, as they already have for the mothers. Also in the clinic is 19-year-old cohort member Amy Murdoch-Davis, with her five-month-old baby Esm\u00e9. Last month, ALSPAC received provisional ethics approval to start recruiting all the children of its cohort members, an effort it hopes to launch in earnest later this year. Esm\u00e9 will be one of the first signed up. \u201cI've been a guinea pig all my life,\u201d Murdoch-Davis says, \u201cand she can be a guinea pig too.\u201d This time around, the researchers want to collect even more samples, including breast milk and the babies' first stools. The study itself was a struggling infant when Murdoch-Davis was born. Its leader, Jean Golding, a mathematician turned epidemiologist, had studied stillbirths and neonatal deaths and was eager to learn how events in pregnancy and infancy affect a child's health and development. She was convinced that studying a large cohort, starting in pregnancy and gathering as much information as possible, was the best way to find answers. Funders, however, saw it differently. \u201cEverybody thought 'if you have a cohort study you're tied down to carrying on funding it \u2014 and it's a bottomless pit',\u201d she says. Golding eventually scraped together some money by writing grant applications that focused on specific diseases. She drummed up interest from mothers by talking on television and radio, and sending an army of midwives to antenatal classes and doctor's surgeries. The 14,541 pregnancies eventually included in the study encompassed more than 70% of those eligible in the region between April 1991 and December 1992. The buckets of fresh placentas started stacking up. And so did other data, such as blood squeezed from the babies' heels during the early clinic visits and reams of questionnaires filled out by the mothers (see 'Building a bank of life'). Little was left unasked. Does baby drink breast milk or formula? Has he or she had antibiotics or skin ointment? Do you have a telephone; a tumble dryer; cockroaches? Within a year or two of starting, however, the cash was draining away. Golding employed her 40\u201350 staff one month at a time, never sure whether she would have enough to pay them again. And there was no time or money to analyse the data that were flooding in. \u201cWe were well in the red,\u201d Golding says. \u201cI was just exhausted.\u201d \n               Childhood and adolescence \n             A few years later, just as parents were collecting baby teeth from beneath thousands of pillows and mailing them to the research team, the first data analyses started coming through. Researchers now point to a handful of results for which the cohort is famous, and that had an impact on public-health policy. One showed that eating oily fish during pregnancy was associated with better eye and cognitive development in children 5 , 6 . Another helped to cement advice that babies should be put to sleep on their backs to reduce the risk of cot death, by showing that this sleeping position did not cause any developmental delays 7 . A third showed the first association between peanut allergy \u2014 an emerging epidemic in Western countries \u2014 and peanut oil in baby lotions 8 . Manufacturers soon started identifying the ingredient on labels. As the children entered their second decade, the study found itself on firm financial ground for the first time. The Wellcome Trust and the Medical Research Council awarded it core funding that has totalled some \u00a321 million for 2001\u201314, and investigator-led grants have brought in much more. With the study maturing comfortably, Golding retired in 2005. (\u201cThey stopped paying me,\u201d as she puts it, still firmly ensconced in her office at the University of Bristol.) Lynn Molloy, a social scientist, took over the managerial reins, and Davey Smith, an epidemiologist passionate about genetics, grasped the scientific ones. The study entered a productive scientific adolescence even as the cohort members suffered their own teen agonies. Questionnaire data revealed that 19% of 16\u201317-year-olds cut or otherwise hurt themselves. By age 18, some 5\u201310% had experienced some form of psychosis \u2014 \u201cmore common than people had previously suspected\u201d, says Stanley Zammit, a psychiatrist working with cohort data at Britain's Cardiff University \u2014 even though few are likely to go on to develop schizophrenia or a related condition. At the same time, genetics was finally entering the picture. In the early years of the project, examining the children's genotypes was just a fond hope. Scientists had announced a draft human genome in 2001, but that was a multibillion-dollar megaproject. Quite what to do with several thousand raw human genomes, no one knew. \u201cThe interesting thing was that although all these high powered alpha-male geneticists were talking the big talk about genetics \u2014 when you actually gave them DNA for a thousand individuals it was too much. They didn't have the technology,\u201d Golding says. In 2007, however, data from ALSPAC and several other large human biobanks were used to scour the human genome for single-letter variants associated with obesity. The work turned up a gene called  FTO , and found that adults with two 'risk' copies of this gene are about 3 kilograms heavier, on average, than those with no risk copies 2 . The discovery became a poster child for the identification of risk alleles through genome-wide association studies, a technique that was sweeping through the genetics community at the time. The Bristol cohort \u2014 with its extensive bank of DNA and medical data \u2014 was perfectly placed to catch the wave. Its data have been used to identify genetic sequences associated with fetal growth 1 , bone density and childhood growth 4 , tooth development 9 , facial features 10  and more. Researchers are now hunting for genetic links to intelligence, educational attainment and gender orientation. Davey Smith sees other opportunities to explore associations in the cohort's DNA. He finds it frustrating that epidemiological studies often reveal a correlation between two factors \u2014 poverty and obesity, say \u2014 without proving that one causes another. The trouble is, many social and biological factors tend to correlate anyway: people who smoke also tend to drink more alcohol, eat unhealthy food, be poorer, weigh more and have high cholesterol and other signature biomarkers of ill health. One way to filter true causes from the correlations is to compare one cohort with another, something Davey Smith did recently to find 'causal associations' with breastfeeding. In the Bristol cohort, breastfeeding is correlated with less obesity, lower blood pressure, higher intelligence and more good things besides. But in the United Kingdom, breastfeeding mothers are also more likely to be middle- or upper-class. So is it breastfeeding that helps children, or some other aspect of a comfortable life? When Davey Smith and his colleagues looked at a birth cohort based in Pelotas, Brazil, where breastfeeding is not linked to socioeconomic status, the links with obesity and blood pressure fell apart, but the link with IQ held up 11 . Researchers are also finding true causes through Mendelian randomization, a genetic technique that is exciting epidemiologists. Stephanie von Hinke Kessler Scholder, an economist at the University of York, UK, is using this method to unpick the associations between children's obesity and poorer performance in school. Obesity is also correlated with lower socioeconomic status, so Scholder sought to test whether obesity directly hinders performance (because of bullying, for example), whether kids who are obese do less well because they come from disadvantaged families, or whether some other factor could explain the correlation. Scholder took the banked DNA of the ALSPAC children and divided them up into groups on the basis of the make-up of two weight-related genes,  FTO  and  MC4R . (Children with all 'heavy' copies of these genes weigh a few kilograms more on average than those with all 'light' copies.) Gregor Mendel's laws of inheritance ensure that the heavy and light forms of the genes are shuffled and randomly delivered to children across a population, irrespective of their social class or any other confounding factor. And when Scholder removed confounders from the equation in this way, she found that children with the heavy versions of  FTO  and  MC4R  did just as well on school tests at age 14 as those who didn't have them. Dispelling the false idea that fat children do worse at school is \u201ca positive thing\u201d, she says 12 . The most technologically advanced answer to the causation problem sits upstairs in the Bristol headquarters of the study. There, a \u00a3300,000 machine is poised to start rapid analyses of methylation \u2014 an epigenetic mark that controls gene activity. By looking at 450,000 sites in the cohort members' genomes, the researchers will build up a bank of methylation data on blood samples taken from the children at birth, at ages 7 and around 17, and on the mothers during pregnancy and 17 years later. \u201cIt's a unique resource,\u201d says Davey Smith. In a study published last month 13 , Caroline Relton at Newcastle University, UK, who is leading the epigenetic work for ALSPAC, looked at methylation on an array of genes in the umbilical-cord blood of cohort children. She found that methylation signatures on nine genes at birth showed some association with body height and tissue composition at age nine. The finding hints that events during pregnancy might shape gene expression early in life \u2014 eventually resulting in altered growth and weight gain. It also \u201cprovides a flavour of the sort of thing we can address more powerfully when we get this huge data set under way\u201d, Relton says. Next, the team plans to search for methylation patterns linked to factors such as neural development, behavioural problems, cardiovascular health and fatty liver disease. The researchers will also look for potential causes of these methylation patterns \u2014 associations with a mother's smoking, alcohol intake, weight gain during pregnancy, folate levels and exposure to air pollution. \n               Next generation \n             The methylation robot is just one piece of the high-tech equipment involved in the study. In one lab in Bristol, blood cells taken from the dads that day are being spun down and divided up into aliquots, ready for storage. In another, researchers are transforming cell samples into immortal cell lines. They have already banked around 7,000 such lines, which provide an endless supply of DNA and might be used for future studies of cell behaviour. Sue Ring, the head of the laboratories, says that her team take turns to carry an emergency mobile phone that will warn them of a freezer failure. After all that the participants have given to the study, she says, she feels a \u201cduty of care for the samples\u201d. Soon, the labs will start to process a whole new set of tissues \u2014 from the children of the cohort members. The eggs that will develop into these children were formed when their mothers themselves were babies, growing in their own mother's uterus. This means that events in the grandmothers' lives, such as an infection, stress or exposure to toxic chemicals \u2014 all recorded in the cohort database \u2014 could produce signals in the streams of data that the researchers plan to collect about the grandchildren. \u201cI was going to retire and wind down until we stumbled on these trans-generational events,\u201d says Pembrey, who wants to explore the third-generation consequences of traumatic events in the lives of grandparents. With so much yet to do, has the study justified the years of effort put in so far? Cohort studies sometimes draw criticism because \u201cthey are very big and very long-term and they seem to be a lifelong source of income for investigators\u201d, says Teri Manolio, who has worked on cohorts in the past and is now director of the Office of Population Genomics at the National Human Genome Research Institute at Bethesda, Maryland. But ALSPAC receives kudos from many researchers, including Nigel Paneth, an epidemiologist at Michigan State University in East Lansing, who runs a data-collection site for the US National Children's Study, which started recruiting in 2009. Unlike ALSPAC, the National Children's Study has ballooned into a mammoth programme with costs estimated at as much as $6 billion, and has struggled for more than a decade to convince sceptical scientists and funders that it will pay off scientifically. Paneth says that big cohort studies can make major contributions to health if they are well planned and executed. \u201cCan I guarantee results? Of course I can't. But I can guarantee you no results if we don't do it.\u201d In Bristol, the team is only starting to learn the value of some of the data collected decades ago. The placentas, which had to be moved twice, were regarded mostly as a \u201cbloody nuisance\u201d until three years ago, when David Barker at the University of Southampton, UK, and Oregon Health and Science University in Portland, asked to use them. Barker is famous for drawing connections between early fetal development and adult health; in the past few years he has reported that the size and shape of a placenta \u2014 the life support of the fetus \u2014 is associated with risk of adult coronary heart disease, high blood pressure and even lifespan 14 . He sent a photographer to Bristol to snap the placentas, and is now using the organs' dimensions to test some of his hypotheses. The correlations are \u201cdefinitely there and amazingly strong\u201d, Barker says. Other correlations will become clear only when the study and its participants have grown up a little more. They do, after all, have most of their lives ahead of them. Murdoch-Davis is planning the next step in hers: going to university to study English and psychology. Meanwhile, Molloy is mapping out what data to collect when the cohort members next visit the clinic, aged 24\u201325, when they will be close to the peak of their health. And Davey Smith has faith in future generations of scientists to find new ways to study the cohort. \u201cMy hope is that when I drop dead it's got an energetic scientific director who's implementing all these future technologies that I couldn't imagine,\u201d he says. Perhaps, Davey Smith says, someone will be analysing data from the digital video recorders that he's thinking about handing to each expectant family, to document every significant event in their child's life. After all, storing terabytes of data doesn't cost anything \u2014 and you never know what they might one day reveal. \u201cDigital recording allows you to store up huge banks of data for future use,\u201d he says. \u201cIt's a bit like Jean collecting the placentas. No one knew what they were going to do with them.\u201d \n                     The generation game 2011-Mar-02 \n                   \n                     Epidemiology: Study of a lifetime 2011-Mar-01 \n                   \n                     Epidemiology: Every bite you take 2011-Feb-16 \n                   \n                     Developmental biology: The whole nine months 2010-Nov-03 \n                   \n                     Neuroscience: In their nurture 2010-Sep-08 \n                   \n                     Avon Longitudinal Study of Parents and Children (ALSPAC) \n                   \n                     ALSPAC: The First 21 Years conference \n                   \n                     Centre for Longitudinal Studies \n                   \n                     Children of the 90s blog \n                   \n                     Children of the 90s Facebook \n                   Reprints and Permissions"},
{"file_id": "484304a", "url": "https://www.nature.com/articles/484304a", "year": 2012, "authors": [{"name": "Lizzie Buchen"}], "parsed_as_year": "2006_or_before", "body": "Neuroscience shows that the adolescent brain is still developing. The question is whether that should influence the sentencing of juveniles. Teenagers can do terrible things. In 1999, Kuntrell Jackson, then 14, was walking with his cousin and a friend in Blytheville, Arkansas, when they decided to rob a local video store. On the way there, his friend, Derrick Shields, revealed that he was carrying a sawn-off shotgun in his coat sleeve. During the robbery, Shields shot a shop worker in the face, killing her. Four years later, 14-year-old Evan Miller and an older friend were getting drunk and stoned with a middle-aged neighbour in a trailer park in Moulton, Alabama. A fight broke out, and Miller and the friend beat the neighbour with a baseball bat. Then they set fire to his home and ran, leaving him to die. Both Miller and Jackson were found guilty of homicide and sentenced to life without parole, meaning that both will spend the rest of their lives in prison. They are not alone. The United States currently has more than 2,500 individuals serving such sentences for crimes they committed as juveniles \u2014 that is, before their eighteenth birthdays. It is the only country that officially punishes juveniles in this way. Both Miller and Jackson appealed, arguing that their immaturity at the time of the crime rendered them less culpable for their actions than adults, and that they deserved a less severe punishment. The Supreme Court heard arguments in Miller v. Alabama and Jackson v. Hobbs in March, and is expected to deliver its ruling by this summer. The cases are notable not only because they could abolish life-without-parole sentences for juveniles, but also because neuroscience research may play a part in the decision. Several organizations submitted briefs to the court detailing the growing body of research showing that the brain's development continues into at least the early twenties. This, they argue, may explain why young people are more impulsive than adults, more readily swayed by their peers and less likely to consider the consequences of their actions. \n               Under the influence \n             Advocates for juveniles have been embracing this work as part of a long-term strategy to ensure that young criminals are given less punishment than adults and more opportunities for rehabilitation. And many neuroscientists studying the adolescent brain are gratified that their work is contributing to these efforts. \u201cIt's so satisfying to think that maybe in some minuscule way my work was relevant to society,\u201d says Bea Luna, who studies adolescent brain development at the University of Pittsburgh in Pennsylvania. But the brain research may not have as great an influence in court as some scientists and advocates like to think. Some say that the neuroscience offers no fresh insight into adolescent behaviour, and may serve merely as a rhetorical flourish in judges' opinions or as a tool that lawyers and advocates exploit to make their case. \u201cThe neuroscience is being used for an advocacy position,\u201d says Emily Murphy of Stanford University in California, who was a fellow with the MacArthur Foundation's Law and Neuroscience Project. \u201cThat's all it's always been, in a legal context.\u201d Murphy and others worry that the neuroscience currently being used in court may be abused, and might overshadow other research that could make a deeper impact on juvenile crime and punishment. Historically, courts in the United States have treated juveniles with leniency. But in the late 1980s and early 1990s, a rise in violent youth crime, including several high-profile school shootings, provoked a backlash of tough justice. Across the country, young offenders were increasingly transferred from the juvenile courts, which emphasize rehabilitation, to adult criminal courts, which focus on retribution and punishment, including the death penalty. Advocates for juveniles have fought to reverse this trend, and have done so, in part, by pointing at major changes now known to take place in the adolescent brain. During maturation, the brain undergoes large-scale structural changes. Fatty tissue called myelin wraps around neurons, speeding up signal transmission in brain cells, particularly between brain regions. At the same time, superfluous connections are pruned away in a process that may decrease noise in the system and allow remaining neurons to function more efficiently. These processes were once assumed to be completed during childhood, but techniques developed over the past two decades have shattered that idea. Structural magnetic resonance imaging (MRI) shows that pruning goes on into early adulthood. Diffusion tension imaging, another form of MRI, shows much the same for myelination. And functional MRI (fMRI), which reveals activity in the brain in near real time, has shown how this ongoing development affects activity levels in different parts of the brain. Some of the most marked changes during these later developmental periods occur in brain systems associated with impulse control 1 , 2 , resisting immediate rewards 3  and emotional processing 4 , 5  \u2014 all behaviours relevant to criminal activity. Systems involved in processing reward also seem to mature more quickly than those involved in decision-making and impulse control. One fMRI study 6  showed that when adolescents were presented with rewards for performing a simple task, the nucleus accumbens \u2014 part of the brain's reward system \u2014 lit up in a pattern similar to that seen in adults in the study, but much more strongly. Meanwhile, the sparse activity seen in the prefrontal cortex \u2014 a region thought to be involved in decision-making and impulse control \u2014 looked more akin to that of children. The authors of the study say that this may help to explain the heightened risk-taking behaviour common in adolescents. A teenager, as advocates and some scientists like to say, is like a car with a great accelerator but terrible brakes. As Larry Steinberg, a psychologist who studies teen behaviour at Temple University in Philadelphia, Pennsylvania, has said, \u201cWith powerful impulses under poor control, the likely result is a crash\u201d. \n               Crime and punishment \n             The Supreme Court got its first taste of this research in 2005, when it considered Roper v. Simmons. In 1994, Christopher Simmons was sentenced to death in Missouri after he and an accomplice wrapped a woman's head in duct tape, bound her limbs with electrical wire, and threw her off a railway bridge. He was 17 at the time of the crime. When the case reached the Supreme Court, the American Medical Association (AMA) and American Psychological Association (APA) filed briefs in Simmons's support explaining the current state of research on the immaturity of adolescent brains. The court found it unconstitutional to impose the death penalty for crimes committed by juveniles; Simmons is now serving life without parole. Although the neuroscience evidence was never directly cited, Justice Anthony Kennedy wrote in the majority opinion that \u201cas any parent knows and as the scientific and sociological studies \u2026 tend to confirm, '[a] lack of maturity and an underdeveloped sense of responsibility are found in youth more often than in adults'\u201d. Many scientists and advocates for juveniles considered the result a triumph for neuroscience in the court, likening it to Brown v. Board of Education of Topeka, the landmark 1954 ruling that ended racial segregation in public schools. Brown v. Board was believed to be heavily influenced by a sociological study of children judging dolls of different colours. This purportedly showed that segregation had a negative impact on black students' self-esteem. Just as that case is thought to mark the modern era of the court's use of scientific research, Roper v. Simmons was believed to herald the era of neuroscience in the court. Emboldened by the Roper decision, advocates and attorneys have increasingly called on neuroscience research when arguing that juveniles should be spared the harshest punishments. In 2010, the court ruled in Graham v. Florida that sentencing a juvenile to life without parole for a crime other than homicide was \u201ccruel and unusual\u201d. The neuroscience research, emphasized in briefs from the AMA, the APA and Graham's lawyers, seemed to strike even more of a chord with the justices, who wrote in the majority opinion that \u201cdevelopments in psychology and brain science continue to show fundamental differences between juvenile and adult minds\u201d. \n               Brain overclaim \n             But some researchers are uncomfortable with the way this research is being used in the criminal justice system. There is certainly a correlation between brain development and behavioural maturity, but saying that observed differences in the adolescent brain cause certain adolescent behaviours is a symptom of what lawyer and psychologist Stephen J. Morse at the University of Pennsylvania in Philadelphia calls \u201cbrain overclaim syndrome\u201d. Neuroscientists, says Morse, are \u201calways using language that suggests causation, when they don't know causation\u201d. Moreover, the behaviours studied in the lab bear little resemblance to criminal behaviour. Scientists cannot perform brain imaging on someone in the process of committing a crime. Instead, they study volunteers who are challenged to resist impulses or follow rules. In some experiments looking to assess impulse control, for example, volunteers are told not to look at a flashing light. Not looking at the light, says Luna, who has used the task for more than ten years, \u201cis extremely difficult to do. We know exactly what brain circuitry gets engaged to stop that reflexive response. Is it the same as murdering someone? No.\u201d But Luna argues that such experiments are relevant. Although adolescents can stop themselves from looking at the light, doing so is associated with much more activation of their prefrontal cortex than is seen in adults, suggesting that it is more difficult for them to control their impulses 7 . But that wasn't really in question. Decades' worth of behavioural research had already established that teenagers take greater risks, are more driven by emotions and peer influence, and generally behave less responsibly than adults. Still, advocates say, neuroscience bolsters the arguments. \u201cWhen you come up with a biological mechanism, it gives it a lot more credibility,\u201d says Luna. To many audiences, neuroscience evidence tends to be more convincing than behavioural science, particularly when aided by pictures of brain areas lighting up. \u201cLawyers and judges have grown up thinking that social science is soft,\u201d says constitutional law scholar David Faigman at the University of California Hastings College of the Law in San Francisco. \u201cNeuroscience gives the courts a hook.\u201d But, Morse says, treating neuroscience data as somehow harder than behavioural data is logically flawed. The neuroscience is only relevant to the law when it connects with behaviour. \u201cIf the psychology is soft, the neuroscience is soft,\u201d Morse says. Hard or soft, the data are open to interpretation. And scientists have little control over when or how their research is used as a persuasive tool. Steinberg's research was cited in the court's opinion in Roper v. Simmons and in briefs in support of juveniles for Graham v. Florida and the two current cases \u2014 but it has also been used by advocates seeking to restrict the rights of adolescents, in particular the right to have an abortion without parental permission. Ultimately, the neuroscience data can only take legal arguments so far. Juveniles may be less responsible than adults, but they may still be responsible enough to deserve the same punishment for similar crimes, says Morse. \u201cThat's not a scientific question. It's a moral question, and, ultimately, a legal question.\u201d Because of this incompatibility, Faigman says that science rarely, if ever, drives a court decision. Judges may use science for rhetorical leverage when writing the opinion, but \u201cit's not always clear whether the research made an impact\u201d. \n               Hot heads or cold blooded \n             Take Roper v. Simmons. Briefs to the court supporting Simmons presented scientific evidence that the immature brains of adolescents like him render them more likely to act in the heat of the moment, giving little thought to the future. But Simmons didn't fit that description: according to Supreme Court documents, he told his friends that he \u201cwanted to murder someone\u201d days before the murder, \u201cby breaking and entering, tying up a victim, and throwing the victim off a bridge\u201d. Although the court alluded to scientific research in its opinion, that research may not have influenced the decision. \u201cThe justices may have [already] come to the conclusion that the death penalty was fundamentally flawed, at least in its application to juveniles,\u201d says Faigman. \u201cThey needed to support that with good reasons.\u201d If science's part in Roper v. Simmons was merely as a makeweight, then comparing it to Brown v. Board might not be far off the mark. In that case, Faigman says, the court had probably already decided to end segregation in public schools on moral and social grounds. Although \u201cthe perception was that science lay at the core of the decision\u201d, says Faigman, the doll study had been \u201cseverely criticized\u201d before the ruling. It was only mentioned in a footnote. When the court decides on Miller v. Alabama and Jackson v. Hobbs, advocates for juveniles hope to see life without parole taken off the table for all juveniles. But the court may draw the line at 14, the age of the petitioners. Whatever line the justices do draw, if they draw one at all, it will probably be based on legal and moral ideas rather than scientific evidence. So does neuroscience deserve a place at the table? Perhaps, says Terry Maroney of Vanderbilt University Law School in Nashville, Tennessee, but it shouldn't outshine other evidence. Solid research by social scientists shows, for example, the high potential of teen criminals to reform, the inability of life sentences to deter juvenile crime, and racial inequalities in life-without-parole sentencing 8 . Focusing on biology draws attention away from socioeconomic, educational and cultural drivers of criminal behaviour. After all, most teenagers do not commit murder, despite their fledgling frontal cortices. Evan Miller grew up with physical and emotional abuse so severe that he attempted suicide several times, starting at the age of five. He was using drugs and alcohol regularly before he was a teenager; the man he killed was his mother's drug dealer. Kuntrell Jackson was raised in the lap of violence. Bryan Stevenson, his attorney, told the Supreme Court justices that \u201chis grandmother shot his uncle. His mother shot a neighbour. His brother shot someone. They were all put to jail.\u201d Neuroscience supports what centuries of casual observation have strongly suggested: teenagers tend to be more impulsive and irresponsible than adults. That probably can't be changed, but the environments that they grow up in can be addressed with social policy. \u201cThat's harder,\u201d says Maroney. \u201cIt requires more work and sacrifice. It's easier to look and say, 'Ooh, look what's going on inside their heads! It's all their problem'.\u201d \n                     Clear up this fuzzy thinking on brain scans 2012-Feb-29 \n                   \n                     Science in court: Head case 2010-Mar-17 \n                   \n                     Brain changes linked to adolescent moods 2008-Feb-25 \n                   \n                     Abnormal neuroscience: Scanning psychopaths 2007-Dec-12 \n                   \n                     Nature News Special: Science in court \n                   \n                     Blogpost: Italian court reduces murder sentence based on neuroimaging \n                   \n                     Macarthur Foundation Research Network on Law and Neuroscience \n                   Reprints and Permissions"},
{"file_id": "484024a", "url": "https://www.nature.com/articles/484024a", "year": 2012, "authors": [{"name": "Kerri Smith"}], "parsed_as_year": "2006_or_before", "body": "Functional magnetic resonance imaging is growing from showy adolescence into a workhorse of brain imaging. The blobs appeared 20 years ago. Two teams, one led by Seiji Ogawa at Bell Laboratories in Murray Hill, New Jersey, the other by Kenneth Kwong at Massachusetts General Hospital in Charlestown, slid a handful of volunteers into giant magnets. With their heads held still, the volunteers watched flashing lights or tensed their hands, while the research teams built the data flowing from the machines into grainy images showing parts of the brain illuminated as multicoloured blobs. The results showed that a technique called functional magnetic resonance imaging (fMRI) could use blood as a proxy for measuring the activity of neurons \u2014 without the injection of a signal-boosting compound 1 , 2 . It was the first demonstration of fMRI as it is commonly used today, and came just months after the technique debuted \u2014 using a contrast agent \u2014 in humans 3 . Sensitive to the distinctive magnetic properties of blood that is rich in oxygen, the method shows oxygenated blood flowing to active brain regions. Unlike scanning techniques such as electroencephalography (EEG), which detects electrical activity at the skull's surface, fMRI produces measurements from deep inside the brain. It is also non-invasive, which makes it safer and more comfortable than positron emission tomography (PET), in which radioactive compounds are injected and traced as they flow around the body. fMRI has been applied to almost every aspect of brain science since. It has shown that the brain is highly compartmentalized, with specific regions responsible for tasks such as perceiving faces 4  and weighing up moral responsibility 5 ; that the resting brain is in fact humming with activity 6 ; and that it may be possible to communicate with patients in a vegetative state by monitoring their brain activity 7 . In 2010, neuroscientists used fMRI in more than 1,500 published articles (see 'The rise of fMRI'). But researchers readily admit that the technique has flaws. It doesn't measure neuronal activity directly and it is blind to details such as how many neurons are firing, or whether firing in one region amplifies or dampens activity in neighbouring areas. The signal \u2014 a boost in blood flow in response to a stimulus \u2014 can be difficult to extract from the 'noise' of routine changes in blood flow, and the statistical techniques involved are easy to misunderstand and misuse. \u201cI'm surprised that fMRI has kept going for 20 years,\u201d says Karl Friston, scientific director of University College London's neuroimaging centre. Friston says he thought all the interesting questions would have been \u201ccherry-picked within the first two or three years\u201d. But fMRI has kept going, in part because no other technique has bettered its ability to see what the human brain is doing. It has turned psychology \u201cinto a biological science\u201d, says Richard Frackowiak, who works with Friston. Now, scientists are intent on finding ways around some of the limitations and pushing the technique into the next 20 years.  Nature  takes a look at four futures for fMRI. \n               Direct measures \n             Perhaps the biggest conundrum in fMRI is what, exactly, the technique is measuring. Researchers know that it measures the oxygen carried in blood by haemoglobin, and they assume that a stronger signal reflects a greater demand for oxygenated blood when neurons become electrically active in response to a task. But several papers have called this assumption into question, suggesting that blood oxygen levels could rise in preparation for neuronal activity as well as during it 8 ; or, worse, that they could be undulating for reasons other than neuronal activity 9 . Most researchers in the fMRI community are comfortable enough with the proxy to carry on doing experiments, even if not all the details have been ironed out. \u201cWe have a pretty good handle that it's measuring something that neurons are doing that's relevant to mental function,\u201d says Russell Poldrack, director of the Imaging Research Center at the University of Texas at Austin. But some teams want to do better, by getting a more direct measure of neuronal activity. \u201cThe thing that we're most interested in is not where blood flow is but where the brain is electrically active,\u201d says John George, an MRI physicist at the Los Alamos National Laboratory in New Mexico. The only ways in which electrical activity can be measured directly, however, are by placing electrodes into the brain, or by picking up electrical signals from outside the skull, a method that lacks the depth and spatial resolution of fMRI. Kerri Smith takes a look at what the future holds for fMRI One solution might be to use a type of MRI that can measure the magnetic field of each neuron as it conducts electrical signals. But these perturbations are an order of magnitude smaller than those produced by changes in blood oxygen level. George's team is therefore developing a technique that uses ultrasensitive magnetometers called SQUIDs (superconducting quantum interference devices) to pick up such perturbations 10 . \u201cWe detect currents close to the levels we anticipate neurons would produce,\u201d he says. But the obstacles are huge. \u201cIt's very much like the early days of fMRI,\u201d says George. The next steps are to make the detection methods faster \u2014 neural signals are much quicker than those from blood \u2014 and to win over sceptics with a clear demonstration of the measurements in a tissue sample or an animal. \u201cThere are hints that signals are there, but most people don't believe it,\u201d says George. \u201cOnce they believe you can do it, they'll show you how to do it better.\u201d \n               More than a pretty picture \n             The multicoloured splodges that correspond to active brain areas have helped fMRI to earn the disparaging nickname 'blobology', reflecting some neuroscientists' frustration with the limited information that a blob conveys. It can show that a language task, for example, correlates with activity in the left hemisphere's frontal lobe, but not whether the activity is actually the result of language processing \u2014 or simply of paying attention to a screen. \u201cYou can't just infer causality from looking at where a task is happening,\u201d says Peter Bandettini, who heads the functional imaging methods section at the US National Institute of Mental Health's Laboratory of Brain and Cognition in Bethesda, Maryland. That is why the use of fMRI to show that a region is correlated with a task, \u201cis starting to slow down\u201d, he says. \u201cNo one's getting tenure based on that any more.\u201d Neuroscientists are now seeking ways to build a more detailed model of the brain's organization, networks and function, so that they can interpret the patterns of activation with more confidence. A good model of brain networks might provide more detail about what happens when a person looks at a familiar face, for example, including which regions are involved in visual processing, memories and emotion; the order in which the regions respond; and how important each area is to the overall task. \u201cThe major shift is towards networks,\u201d says Stephen Smith, associate director of the Oxford University Centre for Functional MRI of the Brain, UK, whose team is working on such models. \u201cWhat we're trying to get is the true underlying connectivity,\u201d he says, \u201crather than make a superficial comment about everything being connected to everything because they're all correlated.\u201d A sophisticated picture of brain networks is also the goal of the Human Connectome Project 11 , a 5-year, US$40-million effort funded by the US National Institutes of Health (NIH) in Bethesda, Maryland, that got under way in 2010. The project aims to map the human brain's wiring using a variety of techniques, including fMRI. Such a 'reference' connectome could help in interpreting individuals' fMRI scans and could reveal how variations in connectomes affect behaviour or contribute to disease. Other researchers are using sophisticated statistical techniques to pick out detailed patterns from fMRI scans. One, called multivariate analysis, charts the behaviour of many units \u2014 or voxels \u2014 of brain activity in parallel, rather than averaging them together into a blob. Blobs can identify large, active brain areas, but might miss clumps of inactive neurons within it or small islands of active neurons in quiet areas. \u201cThe more you look, the more you get meaningful information,\u201d says Bandettini. \u201cWhat previously was noise is now suddenly signal.\u201d These techniques are even allowing researchers to work out what stimuli are present just by looking at brain activity patterns. Last year, Jack Gallant from the University of California, Berkeley, recorded the fMRI activity of three members of his lab as they watched hours of film clips. The team then developed a computational model that used fMRI scans to reconstruct a movie approximating what the people had been watching \u2014 a person wearing blue, for example, or a red bird 12 . \n               Dampening the noise \n             fMRI tends to generate small signals and a lot of noise. \u201cYou need quite a lot of neurons firing in synchrony with each other to see a change in blood oxygenation,\u201d says Smith. The noise means that many changes \u2014 a small group of neurons firing together, or subtle or quick variations in oxygenated blood flow \u2014 might not be picked up. The low signal-to-noise ratio forces fMRI researchers to use statistical approaches to pick out what is significant in their scans \u2014 and that means that there are numerous ways to interpret a data set. \u201cIf you try them all, you're going to find something,\u201d says Poldrack. Some groups are managing to boost the signal by using stronger magnets. In an MRI machine, a high magnetic field aligns the spins of the protons in hydrogen atoms; then radio waves knock the spins out of alignment. As the spins gradually realign, they send out a signal \u2014 or resonate \u2014 and those in areas of oxygenated blood resonate at a different frequency from those in deoxygenated blood. But only a tiny proportion of the protons react to the field and radio waves. Stronger magnets line up a greater proportion of the proton spins, which then generate a stronger signal as they realign. The scanners used in neuroscience today typically have magnet strengths of 3 tesla, which is many thousand times stronger than Earth's magnetic field, and have a resolution of 3 cubic millimetres. But stronger magnets are creeping into practice. In 2010, for example, scientists at the University of Nottingham, UK, used a 7-tesla magnet to build a map of the human somatosensory cortex 13  \u2014 which is responsible for processing touch and some aspects of movement \u2014 at a resolution of 1 cubic millimetre. The NeuroSpin facility near Paris is building an 11.7-tesla whole-body system, the strongest yet for human studies. Magnets much stronger than this cannot be used on humans, because they increase artefacts in the images and can trigger dizziness and other side effects. Another way to increase the signal is to inject molecules that are easier to detect than oxygenated blood, in a method more akin to PET. Gary Green, director of the York Neuroimaging Centre at the University of York, UK, is working with parahydrogen, a 'hyperpolarized' molecule in which the proton spins are more aligned than in many other molecules, and which generates a strong signal during MRI. In 2009, Green and his colleagues showed that they could transfer spins from parahydrogen to an organic molecule without changing the latter's chemical structure 14  \u2014 the first step towards preparing hyperpolarized drugs or other molecules that bind to receptors, and then track how these substances are taken up, or how they interact. Finding better statistical ways to remove noise will also be a big help. Poldrack runs a 'best practice' wiki ( www.fmrimethods.org ) that covers how fMRI data should be analysed, and has published guidelines for how the work should be reported, recommending, for example, that researchers include all the experimental detail necessary to reproduce an analysis, such as \u201cwhat your subjects were asked to do and what they actually did\u201d 15 . \u201cWe need to enforce more rigour,\u201d he says. \n               Which way to the clinic? \n             Getting fMRI to the clinic is, for some, the most pressing challenge the field will face in the next few years. \u201cIt hasn't really been used clinically yet, on individual subjects,\u201d says Bandettini. Clinicians want to be able to ask, for example, whether a drug is working to relieve schizophrenia, or whether a person with depression is in danger of committing suicide. The difficulty lies in making sense of an individual's scan. Most fMRI data are averages of results from many people doing the same task. This method has a higher chance of seeing a true difference between two groups or two tasks than those from an individual. Researchers are now developing statistical methods to pull meaningful information out of a single scan. In one study 16  published in 2010, a team trained a computer to pick out patterns in brain-scan data collected when participants were resting. They did this for nearly 240 people aged 7\u201330 years to build up maps of brain connectivity at different ages. They then showed that they could take a single brain scan from a different person and, by comparing it with their reference set, work out the owner's brain maturity. Such techniques might eventually be used to diagnose a developmental delay or psychiatric disorder, and there are hints that they can identify teenagers genetically at risk for depression 17 . Having a good reference set will form the backbone of clinical fMRI, says Arthur Toga, a neurologist at the University of California, Los Angeles. Toga is a principal investigator on an effort to build such a reference, called the Alzheimer's Disease Neuroimaging Initiative, a longitudinal study of around 800 people looking at the onset and progression of Alzheimer's disease through genetic analyses, brain structure and function and blood biomarkers. Toga hopes that the information will form a database against which future individual scans can be compared. With new ways both to examine the data and to boost the technology, many neuroscientists see a future filled with multicoloured blobs \u2014 albeit sharper and better-understood ones. \u201cPeople will be very busy easily for the next 20 years,\u201d says Bandettini. \u201cI would say that fMRI in many aspects hasn't really even begun.\u201d \n                     Neuroscience: Making connections 2012-Mar-21 \n                   \n                     Reproducibility of brainscan studies questioned 2010-Mar-17 \n                   \n                     Brain imaging skewed 2009-Apr-27 \n                   \n                     Functional Neuroscience: How to get ahead in imaging 2009-Apr-15 \n                   \n                     Brain imaging measures more than we think 2009-Jan-21 \n                   \n                     Brain imaging studies under fire 2009-Jan-13 \n                   \n                     What we can do and what we cannot do with fMRI 2008-Jun-12 \n                   \n                     NIH Section on Functional Imaging Methods \n                   \n                     FMRIB Centre, University of Oxford \n                   \n                     Wellcome Trust Centre for Neuroimaging, UCL \n                   Reprints and Permissions"},
{"file_id": "485162a", "url": "https://www.nature.com/articles/485162a", "year": 2012, "authors": [{"name": "Alison Abbott"}], "parsed_as_year": "2006_or_before", "body": "Old collections of irradiated tissues could answer modern-day questions about the dangers of radiation. Now, researchers are making a concerted effort to save the stores. The town of Ozersk, deep in Russia's remote southern Urals, hides the relics of a massive secret experiment. From the early 1950s to the end of the cold war, nearly 250,000 animals were systematically irradiated. Some were blasted with \u03b1-, \u03b2- or \u03b3-radiation. Others were fed radioactive particles. Some of the doses were high enough to kill the animals outright; others were so low that they seemed harmless. After the animals \u2014 mice, rats, dogs, pigs and a few monkeys \u2014 died, scientists dissected out their tissues to see what damage the radioactivity had wrought. They fixed thin slices of lung, heart, liver, brain and other organs in paraffin blocks, to be sliced and examined under the microscope. Some organs, they pickled in jars of formalin. Fearful of a nuclear attack by the United States, the Soviet Union wanted to understand how radiation damages tissues and causes diseases such as cancer. Concerns about home-grown accidents, such as the 1957 disaster at the Mayak nuclear plant close to Ozersk, were another motivation. Throughout their experiments, the scientists carefully preserved the tissues and meticulously recorded their findings. Similar archives of irradiated tissue were built up in the United States, Europe and Japan, where nearly half a billion animals were sacrificed to the cause. But when the cold war came to an end, the collections fell into disrepair. Now, these archives have become important to a new generation of radiobiologists, who want to explore the effects of the extremely low doses of radiation \u2014 below 100 millisieverts \u2014 that people receive during medical procedures such as computed-tomography diagnostic scans, and by living close to the damaged Fukushima nuclear reactors in Japan. The old collections provide a resource that could not be recreated today. Most of the experiments were done under precise conditions, at a wide range of radiation doses and usually for the lifetime of the animals. \u201cWe will never be able to repeat the scale of those animal experiments, for both funding and ethical reasons,\u201d says Gayle Woloschak, a radiation biologist at Northwestern University in Chicago, Illinois. \u201cBut maybe we can reuse the legacy tissue.\u201d Over the past few years, researchers around the world have organized an effort to identify and save tissue archives from all the major animal irradiation experiments, and they have won support from a diverse range of funding agencies, including the European Commission, the US National Cancer Institute and the US Department of Energy. But the challenges are still great. Researchers have to show that the age of the samples, and the preservation techniques used on them, have not affected the DNA, RNA and proteins the samples contain. They have to piece together such molecular data to reveal whether cell circuitry is disrupted at low radiation doses. Their early tests are indicating that some of the samples will be usable, making them regret how much of such painstakingly collected material around the world has already been lost. \n               Radiation reservoirs \n             When the ageing survivors of the Hiroshima and Nagasaki nuclear bombs and the contaminated Mayak workers started to develop cardiovascular disease at above-normal rates 1 , 2 , it became clear that radiation does more than just cause cancer. What is not known is whether or how very low doses of radiation might increase the risk of these and other diseases. Biologists have generally assumed that the damage will be proportional to the dose, but  in vitro  studies have shown that cells can repair modest DNA damage caused by radiation \u2014 and that low-dose radiation might even protect the cell against future exposure. \u201cMaybe there is a threshold dose below which radiation is not harmful,\u201d says Wolfgang Weiss, head of radiation protection and health at Germany's Federal Office for Radiation Protection in Munich. Epidemiological studies on people exposed to radiation through their jobs, nuclear accidents or medical procedures haven't shed much light on the matter. Some of the studies contained too few people to detect what could be a tiny increased incidence in disease; in others, it is unclear what dose the individuals received. So although radiation protection agencies typically restrict occupational exposure (for the nuclear industry, for example) to an average of 20 mSv per year, scientists don't have hard data on which to base high-stake conclusions about what level of radiation, if any, is really safe. The old animal tissues could hold some of the answers. In February 2007, the quest to find such tissues took Soile Tapio on a mission from one of Germany's former nuclear research centres, the Helmholtz Centre Munich, to a dark, frigid Ozersk. Tapio was taking part in a programme called the Promotion of the European Radiobiology Archives (ERA-PRO), part of an effort dating back to 1996 to digitize the data from radiation experiments done in Europe. In 2006, the director of the animal irradiation programme at the Southern Urals Biophysics Institute (SUBI) in Ozersk alerted Tapio to the enormous scope of the studies there. \u201cAt the time we didn't know much more about SUBI than its name,\u201d Tapio says. She certainly hadn't known quite what to expect when she set off there with her small ERA-PRO delegation. \n               Off-limits \n             It had already taken a few months to get approval from Russia to visit the closed town of Ozersk. After a long flight, a three-hour drive and a lengthy security clearance, a small group of ageing scientists led the delegation to an abandoned house with a gaping roof and broken windows. Glass slides and laboratory notebooks lay strewn on the floors of some offices. But other, heated rooms held wooden cases stacked with slides and wax blocks in plastic bags. In its heyday, the programme had more than 100 staff; but when it was abruptly shut down in the wake of the cold war, just four or five people were left to look after the material it had produced. The visitors were impressed to find that these scientists could link all the samples, from 23,000 animals, to detailed protocols of individual experiments. \u201cThe scientists were so happy that at last someone was taking notice of the collection,\u201d says Tapio. \u201cThey told me many times that they wanted to bring it into order before they died.\u201d Meanwhile, another tissue rescue operation was taking place in the United States. In the mid-1990s, Woloschak had worked on samples from 7,000 beagles and 50,000 mice that had been irradiated in experiments at the Argonne Research Laboratory in Illinois between 1969 and 1992. But after she moved to Northwestern, she was dismayed to hear that the samples were being thrown out and secured permission from the Department of Energy to store them at Northwestern. \u201cWhen the community found out I had all the Argonne tissues they began to ask if I could save their tissues, too,\u201d Woloschak says. Northwestern University is now the official home for material from all US animal irradiation studies, and Woloschak estimates that she has so far received 20,000 samples. But she has also discovered that many samples have already been destroyed, including those from vast mouse studies done at Oak Ridge National Laboratory in Tennessee and some large-scale dog studies conducted at the University of California, Davis. Woloschak says that she \u201cfelt frustrated and angry that the government had invested so many millions of dollars \u2014 and immense human effort \u2014 into studies that were just going to be trashed because of concerns about space\u201d. Tissue collections have also been destroyed elsewhere, including from experiments done at Hiroshima University in Japan, the Italian National Agency for New Technologies, Energy and Sustainable Economic Development's research centre in Casaccia and the UK Medical Research Council's complex in Harwell. Scientists know that laying their hands on the old tissues will be just the first challenge: they then have to work out whether the biomolecules in the materials can still be detected and measured. They want to identify and analyse the molecular pathways hit by low-dose radiation to see how cells in different tissues adjust \u2014 or fail to adjust \u2014 to the stress, and how that might set them on the path to disease. They also want to find patterns of biological molecules that might help to determine how much radiation a person received or whether he or she is particularly susceptible to radiation-induced illness. Woloschak's 1990s work on the old Argonne lab mouse samples provides some hope. She found, for example, that by using a technique called the polymerase chain reaction to amplify genes, she could detect mutations or rearrangements in cancer-specific genes in irradiated tissue that had turned cancerous 3 . Tapio, meanwhile, has adapted standard proteomics techniques so that they can be applied to some of the old tissues, and several groups are studying whether micro-RNAs \u2014 which help to control gene expression and are relatively stable \u2014 are present in the samples. Scientists are now poised to apply such work systematically to the legacy tissues. Tapio, for example, is about to start work on paraffin-embedded heart tissue from irradiated mice from the old Russian and US studies. She wants to identify any signs of damage that might explain the elevated incidence of cardiovascular disease in nuclear-bomb survivors. \u201cThe scientists who did those studies were only looking for cancer, but we can now look at other diseases we know are relevant,\u201d she says. No one is expecting the answers to be quick or simple. The studies could identify many molecular responses that have little to do with disease. \u201cThe cell's stress response to any dose of radiation \u2014 below that which just fries it \u2014 is a complex web of activities, probably affecting many different molecular pathways,\u201d says Tapio. And radiobiologists expect that the threshold 'safe' dose will vary between tissues and between individuals. But at the very least, the tissues in Ozersk have been brought to order, as their guardians hoped. They will soon move into a state-of-the-art storage building being built in the SUBI campus, along with human tissues from radiation-exposed Mayak workers. The animal tissues, researchers hope, will find a new experimental life \u2014 this time on an international stage.\n \n                     Japan's nuclear crisis: Fukushima's legacy of fear 2012-Mar-07 \n                   \n                     Future of Chernobyl health studies in doubt 2011-Sep-30 \n                   \n                     Chernobyl's legacy 2011-Mar-28 \n                   \n                     Sustaining access to Tissues and data from Radiobiological Experiments \n                   \n                     Federal Office for Radiation Protection \n                   \n                     Integrating Low Dose Research \n                   \n                     Multidisciplinary European Low Dose Initiative \n                   Reprints and Permissions"},
{"file_id": "485027a", "url": "https://www.nature.com/articles/485027a", "year": 2012, "authors": [{"name": "Ewen Callaway"}], "parsed_as_year": "2006_or_before", "body": "By revamping radiocarbon dating, Tom Higham is painting a new picture of humans' arrival in Europe. Beside a slab of trilobites, in a quiet corner of Britain's Oxford University Museum of Natural History, lies a collection of ochre-tinted human bones known as the Red Lady of Paviland. In 1823, palaeontologist William Buckland painstakingly removed the fossils from a cave in Wales, and discovered ivory rods, shell beads and other ornaments in the vicinity. He concluded that they belonged to a Roman-era witch or prostitute. \u201cHe did a good job of excavating, but he interpreted it totally wrong,\u201d says Tom Higham, a 46-year-old archaeological scientist at the University of Oxford's Radiocarbon Accelerator Unit. Buckland's immediate successors did a little better. They determined that the Red Lady was in fact a man, and that the ornaments resembled those found at much older sites in continental Europe. Then, in the twentieth century, carbon dating found the bones to be about 22,000 years old 1  and, later, 30,000 years old 2  \u2014 even though much of Britain was encased in ice and seemingly uninhabitable for part of that time. When Higham eventually got the bones, his team came up with a more likely scenario: they were closer to 33,000 years old and one of the earliest examples of ceremonial burial in Western Europe. \u201cIt is another sobering example of cocked-up dates,\u201d says Higham, whose laboratory is leading a revolution in radiocarbon dating. By developing techniques that strip ancient samples of impurities, he and his team have established more accurate ages for the remains from dozens of archaeological sites. In the process, Higham is rewriting European history for around 30,000\u201350,000 years ago \u2014 a time referred to as the Middle-to-Upper Palaeolithic transition \u2014 when the first modern-looking humans arrived from Africa and the last Neanderthals vanished. Higham thinks that better carbon dating will help to resolve debates about whether the two ever met, swapped ideas or even had sex. It might even explain why humans survived and Neanderthals did not. \u201cI admire him,\u201d says Paul Mellars, an archaeologist from the University of Cambridge, UK, and an expert on this period in Europe, for \u201cthe sheer doggedness and sense of vision\u201d he has for improving radiocarbon dating of the Palaeolithic. That vision sometimes clashes with other scientists' views, but Higham makes no apologies for his interpretations as long as the dates are solid. \u201cI want to know the truth\u201d is something he says a lot. \n               A woolly field \n             If you Google 'archaeologist' and 'Higham', the first hit is likely to be Charles Higham, a 72-year-old professor who has charted the origins of agriculture and government in southeast Asia. Tom was born in Cambridge, where his father was based until 1966. Charles then moved the family and nine-month-old Tom to New Zealand's rugged south island to start an archaeology department at the University of Otago in Dunedin. As a teenager, Tom spent summers at Ban Na Di, a study site in northeastern Thailand, where his duties included helping with human excavations and brewing tea for the crew. Tom didn't originally plan to follow his father's path. As a child he was obsessed with the history of the American West. At university, he planned to study geography and glaciology, but switched to archaeology after excelling in an introductory course taught by his father that he had signed up for on a whim. But his enthusiasm soon waned. \u201cI got less and less interested in archaeology because it was so subjective and woolly.\u201d The reasons for that woolliness were partly technical and partly historical, dating back to before the Highams' time. Archaeology before carbon dating relied on two principles: older things are buried beneath younger things, and people with cultural ties make similar-looking objects, such as stone tools. But dates were hard to come by. In the early nineteenth century, the Danish historian Rasmus Nyerup wrote that most of early human history was \u201cwrapped in a thick fog\u201d 3 . \u201cWe know that it is older than Christendom,\u201d he wrote, \u201cbut whether by a couple of years or a couple of centuries or even by more than a millennium, we can do no more than guess.\u201d The fog began to lift in the middle of the twentieth century, when US chemist Willard Libby and his colleagues 4  showed that all formerly living things bear a clock powered by radioactive carbon-14. Organisms incorporate tiny amounts of this isotope as they grow, and they maintain a constant ratio between it and other, non-radioactive, carbon isotopes throughout their lives. After death, the carbon-14 decays with a half-life of about 5,730 years, and the dwindling ratio serves as a time stamp. Libby's team proved the accuracy of this 'clock' on objects of known age, such as Egyptian mummy tombs, and bread from a house in Pompeii, Italy, that was burned during the eruption of Vesuvius. Libby earned the 1960 Nobel Prize in Chemistry for his work. The clock gets less accurate as the samples age, however; cruelly, it begins to fail at one of the most interesting times of human history in Europe. Within 30,000 years, 98% of the already vanishingly small quantities of carbon-14 in bone is gone. And carbon-14 molecules from surrounding soil start to seep into the fossils. Collagen, the part of bone that contains the most carbon suitable for dating, sops up contaminants like a sponge, creating a false record. If just 2% of the carbon atoms are contemporary, then a 44,000-year-old bone will return a carbon date of 33,000 years old, Higham calculates. Most of the thousands of carbon dates from archaeological sites from the Middle-to-Upper Palaeolithic era are wrong, say scientists, perhaps even as many as 90%. As a result, archaeologists can agree on the history of this era only in the broadest of brushstrokes. Tom found himself drawn to the quantitative side of archaeology to help fill in those details. His father had counselled that if he wanted a future in the field, Tom ought to join the push to make it a more rigorous science, emphasizing testable theory, experiment and statistics. So, at his father's urging, Tom applied for and completed a PhD at the University of Waikato's Radiocarbon Dating Laboratory in Hamilton, then did a postdoc there. And when a faculty position became available at a better-funded lab at the University of Oxford in 2000, he moved back to his birth country. Any idea that archaeology hasn't gone in the direction that Charles predicted is dispelled by a visit to his son's workplace. Its centrepiece is a giant \u00a32.5-million (US$4-million) particle accelerator, which is used to tot up the number of radioactive carbon molecules in a sample. Similar machines have been used for carbon dating since the 1970s and have allowed scientists to date smaller samples with more precision than before. But they have also produced their share of erroneous dates. \u201cPeople used to take bones, grind them up and date them, and you got all kinds of dates because no one bothered to check if there was collagen or not,\u201d says Ofer Bar-Yosef, an archaeologist at Harvard University in Cambridge, Massachusetts. And rather than damage valuable human bones or animal bones marked with cuts from stone tools, scientists tended to date fragments of unidentified animal bones found alongside human remains, assuming, not always correctly, that they coincided with human occupation. \u201cIt just breaks your heart to see what people have dated before. They've basically dated pieces of shit,\u201d Higham says. His team didn't change the machine \u2014 the secret to more accurate dating lies in the rigorous way the samples are processed beforehand. The team typically starts with bones that are linked unequivocally with human occupation, such as cut-marked bones. To remove contaminants such as decayed organic matter from soils or even the glues used to assemble fossils, the researchers treat the bone with chemicals that tear collagen's triple helices into single chains to release the trapped contaminants. A molecular sieve then filters out contaminating carbon molecules, leaving behind pure collagen. The colour of the final product is a good indicator of its quality, Higham says, holding up a glass bottle containing a white, fluffy, grape-seed-size fleck that resembles cotton wool. The Red Lady and remains from other sites in Britain were the first that his lab examined. He has since expanded his search across continental Europe, and in 2007 his team won a \u00a3350,000 grant from Britain's Natural Environment Research Council in Swindon to re-date three dozen archaeological sites (see \u2018Invading Europe\u2019). The number eventually ballooned to 65. \n               Older and older \n             Like the Red Lady, bones from many sites are turning out to be millennia older than previously thought. Before Higham's work, the oldest human bones in Europe were from the Pestera cu Oase cave in southwestern Romania, dated to around 40,000 years old. Higham and his colleagues have now begun to find older examples. In November 2011, they announced that they had dated what would become the oldest human fossil in Britain 5 . A fragment of jaw bone had been discovered in 1927 in Kent's Cavern, a coastal cave in Devon, and had been dated in the late 1980s to about 35,000 years old 6 . Higham's team assert that the jaw is more than 41,000 years old 5 , on the basis of dates of animal bones excavated above and below the jaw. (The team was unable to date the jaw itself.) Work by Katerina Douka, an archaeological scientist at Oxford (and Higham's partner), published on the same day 7  dated molars from Cavallo Cave in Italy's heel at between 43,000 and 45,000 years old, making them the earliest modern human fossils in Europe, although not everyone agrees that they are human. \u201cWe're starting to build up a picture that modern humans were getting into Europe much earlier than we thought,\u201d says Chris Stringer, a palaeoanthropologist at London's Natural History Museum and co-author of the Kent's Cavern paper 5 . These early incursions may have put humans in direct contact with Neanderthals who had lived there for millennia. \u201cGetting people up to Kent's Cavern near Plymouth, that's a hell of a thing at 40,000 years ago,\u201d says Richard Klein, an archaeologist at Stanford University in California. He doubts that they coexisted for long: \u201cIt's hard to imagine they were playing games with Neanderthals when they went up there. They must have replaced them very quickly.\u201d Higham says that his dates tell a more nuanced story. He likens Palaeolithic Europe to a giant chess board, with established Neanderthals facing a series of intrusions by modern humans. In places, the two may have lived alongside each other for thousands of years, opening up the possibility of cultural and even sexual exchanges. Comparisons of modern human genomes with Neanderthals' suggest that some interbreeding occurred (see  page 33 ). But because Asians and Europeans have identical levels of Neanderthal DNA, geneticists presume that they are seeing the result of trysts that occurred before modern humans moved to Europe. Higham's work could help to pin down when and where humans and Neanderthals were most likely to have interbred. He thinks that Neanderthals probably went extinct gradually. His work re-dating Neanderthal sites in Croatia 8  and the Caucasus 9  suggests that Neanderthals disappeared from these regions by about 40,000 years ago. Other researchers say that the last Neanderthals may have eked out a living in the Iberian peninsula until as recently as 24,000 years ago 10 , although Higham and his former graduate student, Rachel Wood, have unpublished work that questions that timing. Still, the part of Higham's work that has generated the most debate (or at least the most journal pages), involves the cognitive abilities of Neanderthals. Neanderthals may no longer be written off as knuckle-dragging brutes, but archaeologists disagree over whether Neanderthals were capable of the sort of symbolic representations that underlie language, art and religion. Shell beads and other ornaments suggest that modern humans made symbolic objects as early as 100,000 years ago in Africa, and probably carried those traditions with them into Europe. Evidence that Neanderthals were capable of symbolic thinking comes partly from what is known as the Ch\u00e2telperronian industry in central and southeastern France, which included ornamental objects such as perforated animal teeth, shell beads and ivory pendants. Neanderthal bones found alongside such artefacts at the Grotte du Renne in central France made the site \u201cthe flagship for the idea that Neanderthals had symbolic behaviour\u201d, says Stringer. Higham, however, questions how good that evidence is 11 . His team dated animal bones, antlers and teeth from various layers of the cave. The dates for those in the Ch\u00e2telperronian layers were all over the place, from 49,000 to 21,000 years old. Higham thinks that bones and artefacts from different periods have become jumbled, through a combination of geological tumult, excavation errors and shoddy record-keeping. He therefore doesn't think the Ch\u00e2telperronian objects should be used to support symbolic thinking for Neanderthals. Jo\u00e3o Zilh\u00e3o, a palaeoanthropologist at the University of Barcelona in Spain, has emerged as Higham's staunchest critic. Last year, Zilh\u00e3o and his colleagues pointed out that the artefacts in the Ch\u00e2telperronian layer seemed to be in the right place and questioned whether Higham's team had managed to fully decontaminate the bone samples 12 . \u201cHow come the bones move and the stone tools do not? It's impossible,\u201d he asks. Higham struck back 13 , and Zilh\u00e3o is now drafting another response. \u201cThis could go on forever and I've got no more time to spend on it,\u201d says Higham. Both say that their dispute is purely academic. They continue to work together on other material, and are open to collaboration on the Grotte du Renne controversy. \u201cHe's pretty easy to work with,\u201d Zilh\u00e3o says of Higham. \u201cHe speaks his mind, but so do I.\u2013 Stringer says that the understanding of palaeolithic history is in flux. The dates that Higham and others are now generating may settle some long-standing debates, but they are also generating new questions. \u201cMaybe you've got a muddying of the waters before they clarify and settle out,\u201d Stringer says. \n               A cinematic vision \n             This summer, Higham will trek to the Denisova cave in southern Siberia's Altai Mountains, to try to make sense of its convoluted history. When Soviet scientists found the cave in the 1970s, they discovered Neanderthal tools and human remains there. But in 2010, DNA sequencing of a finger bone extracted from the cave pointed to the existence of a hitherto unknown population of archaic humans, called Denisovans 14 , who lived in the cave sometime between 30,000 and 48,000 years ago 15 . Higham thinks that his team can narrow down that range and perhaps determine whether Denisovans lived in the region with humans and Neanderthals. Higham's grand vision is to develop a fuller, almost cinematic version of early human migrations. \u201cWe want to create this huge map that will allow us to try to look at the movement of people, the movement of objects, the development of new ideas. The big archaeological questions, really.\u201d His team has already begun to play around with software capable of building such a map of Europe, some of which incorporates data from a stack of manuscripts on his desk that he hopes will be published over the next year and a half. But if this film is to be more historical documentary than a period drama, it requires the sort of chronologies that Higham and his team are generating. \u201cYou have to know the dates,\u201d he says.\u201d \n                 See Editorial \n                 page 6 \n               \n                     Step by step around the globe 2012-May-02 \n                   \n                     Human migrations: Eastern odyssey 2012-May-02 \n                   \n                     Evolution: What makes a modern human 2012-May-02 \n                   \n                     Ancient migration: Coming to America 2012-May-02 \n                   \n                     Young Americans 2012-May-02 \n                   \n                     Ancient DNA reveals secrets of human history 2011-Aug-09 \n                   \n                     Europeans never had Neanderthal neighbours 2011-May-09 \n                   \n                     Fossil finger points to new human species 2010-Mar-24 \n                   \n                     Footprint claims get stamped on 2005-Nov-30 \n                   \n                     Ancient Human Occupation of Britain Project \n                   Reprints and Permissions"},
{"file_id": "485024a", "url": "https://www.nature.com/articles/485024a", "year": 2012, "authors": [{"name": "Tim Appenzeller"}], "parsed_as_year": "2006_or_before", "body": "Humans had spread across Asia by 50,000 years ago. Everything else about our original exodus from Africa is up for debate. One day some 74,000 years ago, in a swampy valley in the south of India, dawn never came. In the half-light, greyish dust sifted down, blanketing the ground and turning trees to ghosts. Far to the east, a volcano called Toba on the Indonesian island of Sumatra had unleashed one of the greatest eruptions ever known, flinging thousands of cubic kilometres of rock into the atmosphere and spreading a pall of ash across southern Asia. Clive Oppenheimer, a volcanologist at the University of Cambridge, UK, has studied the ash deposits in India's Jurreru Valley to reconstruct the events that followed. Within days, the trees shed their whitened foliage; rains later swept ash into layers several metres thick on the valley floor. Eventually, the lakes and swamps vanished, perhaps because the climate had become drier and cooler. Toba had transformed a lush habitat into a wasteland 1 . The catastrophe had witnesses. Archaeologists digging beneath the ash layer have found stone artefacts indicating that humans were living in the valley before the eruption. But were they modern humans \u2014 people like us \u2014 or some other, now extinct, branch of the human lineage? Today, the thick ash deposits of the Jurreru Valley mark a division not only in the geological record but also between archaeologists debating one of the field's biggest questions: when and how did modern humans leave their African cradle and colonize Asia, Earth's largest landmass? It was the first great expansion of the human species, carrying people some 12,000 kilometres to Australia by about 50,000 years ago. But just how early the pioneers set out is controversial \u2014 as are the routes they followed, the tools they carried and, most fundamental of all, what triggered the migration. Were they enticed into the wider world by a favourable climate, or propelled by a revolution in technology and culture? In archaeologists' shorthand, the debate boils down to a simple question: pre-Toba or post-Toba? At one pole of the debate, Paul Mellars at the University of Cambridge argues passionately that modern humans left Africa long after the Toba eruption, 60,000 years ago at the earliest. Equipped with new technologies, including bows and arrows, they beach-hopped along the coastline of the Arabian peninsula, India and southeast Asia, reaching Australia in short order. Genetic analyses of contemporary Asians that point to a late, rapid colonization have bolstered his confidence. \u201cI'm more convinced than ever that I'm right,\u201d he says, before adding, \u201cI guess they all say that.\u201d His opposite number, Michael Petraglia at the University of Oxford, UK, certainly does. He is convinced that people spread into Asia at least 74,000 years ago, and perhaps as early as 125,000 years ago, well before Toba, during a wet, warm interlude between ice ages, carrying tools no more sophisticated than those made by earlier humans. Rather than following the coast, he thinks they wandered along river valleys and lake shores, advancing and retreating as the environment allowed, more like wildlife than a wave of colonists (see 'Asian migration'). He takes heart from discoveries that testify to the presence of modern humans in the Arabian Peninsula, on the very doorstep of Asia, more than 100,000 years ago. \u201cI'm feeling more and more confident through time,\u201d he says. It is a full-throated academic duel. Petraglia calls Mellars' view \u201cbaseless archaeologically\u201d; Mellars vows to \u201cdemolish the pre-Toba model\u201d. Their passion is fuelled both by the prize of understanding the first great human migration \u2014 and by the lack of decisive evidence. That leaves many other archaeologists in the same position as Chris Stringer of London's Natural History Museum, who says he is \u201csitting on the fence\u201d until researchers unearth more data. The wait may not be long. Archaeologists are busily hunting for artefacts and even fossils of the first modern Asians, which could finally put the debate to rest. \n               Coastal express \n             Most of Asia is \u201ca blank map, if you will, in its prehistory\u201d, says Petraglia. Scattered fossils record the archaic peoples \u2014  Homo erectus , Neanderthals and the recently identified Denisovans \u2014 who had the continent to themselves before modern humans moved in. But few artefacts and no convincing fossils record this arrival. Researchers have mostly relied on the DNA of people today to reconstruct the ancient story. Geneticists collected mitochondrial DNA (mtDNA) \u2014 which is inherited only from the mother \u2014 across much of Asia, focusing on isolated native groups thought to be descendants of early human settlers in their areas. They identified distinctive mtDNA variants, or haplotypes, and compared them to create a family tree of the African exodus. To date its roots and branches, they used estimates of mutation rates as a molecular clock. The tree's root is marked by a haplotype called L3 that originated before humans left Africa; its genetic signature is found in many Africans and every non-African today. The latest readings of the molecular clock date L3 to 60,000\u201370,000 years ago 2 , suggesting that humanity left Africa a few thousand years after Toba. The three next-oldest haplotypes \u2014 immediate descendants of L3 outside Africa \u2014 are 60,000\u201365,000 years old. All three gave rise to multiple 'starbursts' of genetic variation, scattered all the way from Arabia to Bali. \u201cFor that to happen,\u201d says geneticist Stephen Oppenheimer of the University of Oxford, \u201cpeople would have had to move very fast, before new mutations occurred.\u201d The most plausible route for a rapid migration is along the coast of the Indian Ocean, which could have been followed for thousands of kilometres without the need to master new environments. By the mid-2000s, most researchers accepted the 'coastal express', as this post-Toba migration scenario is sometimes known. Later analyses of mtDNA and of the male Y chromosome suggested that the exit from Africa was even more recent, perhaps less than 60,000 years ago. And in an influential 2006 review in  Science 3 , Mellars argued that the sparse archaeological record of Asia and Australia not only supported the genetic evidence of a rapid post-Toba migration, but showed how cultural advances could have helped to drive it. There is no trace of any ancient beachcombers or their camps, which Mellars says is no surprise because sea-level rise since the most recent ice age has flooded the former coastline. \u201cYour earliest sites in any area are going to be under the sea, and 20 kilometres or more out to sea,\u201d he says. But Mellars sees important clues further inland. The earliest artefacts from the Jurreru Valley and other sites in India and Sri Lanka are simple stone points, scrapers and cores \u2014 the lumps of rock left after points were flaked off. All could have been made by archaic humans. Later, well after Toba, they give way to much more sophisticated handiwork: small, finely worked 'microlithic' blades that might have served as arrowheads, shaped bone points, beads and pieces of ostrich eggshell adorned, in one case, with cross-hatching. The change in the record \u201cappears almost overnight\u201d, Mellars says, and mirrors the transformation seen in Europe some 45,000 years ago, when modern humans arrived, bringing sophisticated tools and ornaments that outshone the cruder handiwork of the continent's resident Neanderthals. If Europe's great cultural flowering commenced with a wave of modern human immigrants, he asks, why should Asia's be any different? Mellars suggests that the migrants carried technology from a culture known as Howiesons Poort, which flourished in southern and eastern Africa from 65,000 to 50,000 years ago. This sophisticated technology, he thinks, was key to launching modern humans out of their native continent. \u201cInnovation would have enormously facilitated expansion eastward,\u201d he says. Critics say the theory faces a serious obstacle, however. Although the genetics suggest that the coastal express dispersed people across Asia at least 55,000 years ago, the earliest microlithic tools found so far in South Asia are no more than 40,000 years old. Mellars is unfazed by the lag, noting that sea-level rise would have flooded the coastal pioneers' earliest sites. The Asian locations with microblades should be younger, he says \u2014 because they lie well inland. \u201cThat's a totally different environment. You've got a lot of adapting to do, and you won't do it overnight.\u201d While Mellars was picturing a late and rapid expansion of culturally advanced people, Petraglia was digging beneath the grey ash beds in the Jurreru Valley and speculating about a very different scenario. He and his colleagues had excavated simple scrapers and cores from below the ash, dated to between about 77,000 and 74,000 years ago 4 . Neanderthals or other archaic humans could have made them \u2014 but, says Petraglia, \u201cno one has ever argued for Neanderthals in India, ever\u201d. Instead, he and his colleagues argued, the artefacts were reminiscent of ones from southern Africa, where the only toolmakers were unquestionably modern humans. To Petraglia, the implication was clear: modern humans found their way to India before Toba blew its top. As for the microblade technologies that Mellars attributes to a wave of later migrants, Petraglia argues that a long-established population of modern humans developed the new tools on their own. He dismisses some geneticists' conclusion that clues in modern human DNA rule out a migration from Africa to Asia any earlier than 60,000 years ago. \u201cMy issue with these guys is, what are they sampling? They're sampling modern humans that live today \u2014 a small subset of what out-of-Africa was.\u201d The genetic signal of earlier arrivals has simply been lost, he says, as populations shifted and vanished. Petraglia's claim intrigued at least one geneticist. Stephen Oppenheimer studies mtDNA and contributed to the coastal-express model 5 . In his view, the migration had to have been rapid and coastal \u2014 but not necessarily as recent as other geneticists have insisted. A clue to an earlier date, he says, comes from mtDNA studies in India. One set of variants was less diverse than expected, suggesting to him that the first modern humans in India suffered some kind of catastrophe that reduced their numbers to almost nothing. The cause, he speculated, might have been the Toba ash cloud, which would imply that modern humans were already established in India at the time of the eruption. He was also intrigued by other hints of a pre-Toba population of modern humans in Asia \u2014 such as a foot bone from the Philippines and a skull from China \u2014 although all were of uncertain age or origin. Oppenheimer notes that DNA is an inexact clock. He concedes that the most likely dates for the L3 haplotype \u2014 and the exit from Africa \u2014 fall after Toba. But \u201cthe logic is in the error bars\u201d, he says. \u201cThe upper limit for the most recent confidence estimate is 79,000 years ago, which means the L3 date straddles Toba.\u201d If DNA can't resolve the dispute, he says, the clinching evidence will have to come from archaeology. \n               Green desert \n             Petraglia and his supporters say that evidence has grown much stronger in the past two years, thanks to the discoveries that put modern humans in Arabia more than 100,000 years ago. What he calls the \u201csmoking gun\u201d comes from Oman, where a group led by Jeffrey Rose of the University of Birmingham, UK, found 106,000-year-old stone relics that are as diagnostic of modern humans as a lost mobile phone would be today. Consisting of distinctive triangular cores and long spear points made from them, this kind of technology was first excavated in Nubia, a region in northern Sudan, at sites inhabited by modern humans. Yet here they were, more than 2,000 kilometres away, on the other side of the Red Sea 6 . \u201cThere's no question,\u201d says Rose. \u201cIt's the same people.\u201d They reached Oman not with the aid of superior technology, Rose says, but because climate and ecosystems favoured the move. At the time, the Arabian peninsula was a moist savannah teeming with game. \u201cThe territory next door suddenly turned green and people from northeastern Africa moved in,\u201d says Rose. \u201cThese people would have been moving into what they already knew.\u201d But did these early explorers press on, from Arabia into Iran and India? No, says Mellars. Theirs was a failed expansion, like one documented in Israel, where modern humans were present more than 100,000 years ago but then vanished. When the climate cooled and dried about 75,000 years ago, turning Arabia back into a desert, the Nubian pioneers either died out or retreated to Africa. \u201cThere's not a smell, not a whiff [of Nubian technologies] that has ever been detected in India,\u201d says Mellars. \u201cIf Mike Petraglia could come to me with one of those Nubian cores and say, 'Look, we found this in India,' I would get down on my knees and say, 'Sorry, Mike, I got it wrong'.\u201d Even if the Nubian toolmakers did not wander farther into Asia, other ancient Arabian populations might have, Petraglia and others say. At a site in the United Arab Emirates called Jebel Faya, Simon Armitage of Royal Holloway, University of London, and his colleagues have found even older artefacts, dating to as early as 125,000 years ago and resembling objects made by modern humans in eastern Africa 7 . Jebel Faya sits on a promontory jutting toward Iran, and its inhabitants could easily have pushed eastward a few thousand years later. By 110,000 years ago, ice sheets were beginning to build up far to the north and sea level was dropping, markedly narrowing the Straits of Hormuz and easing the crossing to Iran. \u201cIt's extremely plausible that a population at Faya could have moved on,\u201d Armitage says. But plausibility is perhaps the strongest argument that Armitage and others favouring the pre-Toba model can make. If a band of pioneers did wander from Arabia into a welcoming green Asia during the last interglacial, their tracks are faint indeed. The pre-Toba artefacts from the Jurreru Valley look nothing like the Arabian ones, says Anthony Marks of Southern Methodist University in Dallas, Texas, who studied the Jebel Faya material. And the archaeologist who analysed the oldest relics from the Jurreru Valley and provided key support for the claim that they are the handiwork of modern humans is no longer so sure. Chris Clarkson of the University of Queensland in Brisbane, Australia, a frequent collaborator of Petraglia's, now thinks they might be the work of an unidentified population of archaic people. Clarkson and others say it is simply too soon to know for sure whether our ancestors were in India to watch the volcanic ash rain down 74,000 years ago. Pre- or post-Toba: either scenario rests on sparse and ambiguous artefacts. \u201cPeople say mute stones speak,\u201d says Marks. \u201cThey don't. They just lie there. We're the ones who impose our views on them.\u201d What is needed is what archaeologists always need: more and better evidence. \u201cWe're at the tip of the iceberg, really,\u201d says Petraglia. \u201cWe've done the best we can with a few sites.\u201d On the Arabian Peninsula, along the coast of the Indian Ocean, and in the heart of India, archaeologists continue to search. Perhaps they will find tools clearly made by modern humans before Toba, or a coastal encampment left by later colonists, littered with microlithic blades. Or, most definitive of all, a skull entombed beneath the Toba ash, silently announcing the presence of modern humans \u2014 or ceding the ground to our archaic cousins. \n                     Human evolution: Cultural roots 2012-Feb-15 \n                   \n                     African cave's ancient ochre lab 2011-Oct-13 \n                   \n                     Early human migration written in stone tools 2011-Jan-27 \n                   \n                     Oxford Toba Super-eruption project \n                   \n                     Into South Asia \n                   Reprints and Permissions"},
{"file_id": "484308a", "url": "https://www.nature.com/articles/484308a", "year": 2012, "authors": [{"name": "Eugenie Samuel Reich"}], "parsed_as_year": "2006_or_before", "body": "American neutrino physicists are getting the measure of their quarry in ultra-high precision. \u201cIt's like Christmas shopping at the specialist boutiques,\u201d says Phil Adamson, as he describes his recent US$250,000 buying spree. Adamson, a physicist at the Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois, leads a team that has spent the past few months acquiring and installing three ultra-high-precision atomic clocks; six Global Positioning System receivers; more than a kilometre of optic fibre; two auxiliary detectors and at least one pair of timing-interval counters (\u201ckind of fancy stopclocks\u201d, he says) \u2014 all to time subatomic neutrinos with nanosecond precision as they pass through the detectors of Fermilab's Main Injector Neutrino Oscillation Search (MINOS). The researchers are trying to answer one simple question: do neutrinos travel at or below the speed of light, as required by the theory of relativity, one of the most fundamental tenets of modern physics? Or do they travel just a tiny fraction faster, as suggested with enormous fanfare last September 1  by an experiment in Italy? To outsiders, this debate has already been settled. Researchers on the Italian experiment, based at Gran Sasso National Laboratory near L'Aquila, announced in March that they had found the error in their measurement \u2014 and two of the team's leaders resigned (see  go.nature.com/xjzhqa ). At the same time, physicists working at a different detector at Gran Sasso have published measurements 2  showing that neutrinos do indeed obey the light-speed limit. Yet neutrino speed is still a prime focus for the MINOS physicists, who are carrying out their own high-precision measurement \u2014 not least because they did not do this when they saw hints of a faster-than-light neutrino in their own data some years ago. \u201cThis is so much on our front burner,\u201d says Robert Plunkett at Fermilab, a spokesman for MINOS. Around 30 members of the 150-strong collaboration are now working on the search. Precision is what the MINOS team is all about. In 2008, Fermilab's Tevatron was supplanted as the world's highest-energy particle accelerator by the Large Hadron Collider (LHC) at CERN, Europe's particle-physics laboratory outside Geneva, Switzerland. Since then, US particle physicists have moved from studying collisions at the highest energies to working with beams at the highest intensities, adapting the country's existing accelerator facilities to measure the rates of extremely rare interactions. The hope is that, even at lower energies, forcing theory and experiment into close comparison can turn up anomalies that point to new physics. Neutrino physics is the centrepiece of that programme. The particles respond only to the aptly named weak force, and mostly stream through solid matter as if there were no barrier. But this aloofness also makes neutrinos potentially a very clean probe of exotic forces: when a neutrino does hit another particle, physicists don't have to disentangle the effects of the much larger strong and electromagnetic forces. Experiments using accelerators, in which physicists can control the energy and direction of the neutrino beam, take maximum advantage of that fact. And MINOS is the most sophisticated experiment of this kind in the United States. True, it takes a special kind of researcher to pursue such work \u2014 pushing measurements towards the last possible decimal point, over decades if need be. But most of the MINOS physicists share the attitude voiced by team member Nathaniel Tagg, a physicist at Otterbein College in Westerville, Ohio. \u201cI'm one for long shots.\u201d \n               Cowboy physics \n             Neutrinos' central role in US physics research is a case of historical turnabout, says Tagg. For years the field was considered 'cowboy physics' \u2014 a fringe area best left to diehard experimentalists who were willing to drag their detectors down remote mineshafts and into underground bunkers, where the devices could escape the confounding effects of atmospheric cosmic rays. The archetypal cowboy was Raymond Davis, a radiochemist at Brookhaven National Laboratory in New York, who wanted to make the first direct observations of nuclear fusion reactions in the core of the Sun. He began in 1967 by setting up a 380-cubic-metre tank of perchloroethylene, a dry-cleaning fluid, nearly 1,500 metres down in the Homestake gold mine in Lead, South Dakota. Davis's idea was that neutrinos created in the Sun's nuclear reactions would very occasionally strike a chlorine atom in the tank and turn it into a radioactive isotope of argon, which he could extract and detect by chemical means. But only about one-third of the expected number of neutrinos seemed to be showing up. Either the theorists were wrong about the rate of fusion reactions in the core of the Sun \u2014 which didn't seem likely, given the success of their calculations in other areas of astrophysics \u2014 or two-thirds of the neutrinos were getting lost. It took decades for physicists to reach a consensus that this 'solar neutrino problem' was real, not some obscure experimental error, and only in the 1990s did they converge on a probable solution. This started from the hypothesis that neutrinos come in three types, or 'flavours', each of which is the electrically neutral partner of a negatively charged particle with mass \u2014 an electron, a muon or a tau. The Sun's fusion reactions produce only electron neutrinos. But as soon as they are produced, according to the theory, these neutrinos begin to 'oscillate', changing from one flavour to another as they travel. By the time they get to Earth, the three flavours have mixed themselves into equal proportions \u2014 meaning that just one-third will be electron neutrinos, the only kind that Davis's tank could detect. This oscillation theory elegantly accounted for the missing solar neutrinos, but posed a new conundrum. The standard model of particle physics held that all three flavours of neutrino have a mass of exactly zero, like that of the photon. But oscillation was possible only if neutrinos have at least a very small mass \u2014 which meant that the particles were hinting at some kind of physics beyond the standard model. This prospect quickly took neutrinos out of the cowboy-physics category (Davis himself would share the Nobel Prize in Physics in 2002). MINOS was one result (see 'Particle switch'). Planning began in the 1990s as physicists looked for a way to verify the oscillation model. In particular, they wanted to create an artificial neutrino beam that would remove one of the biggest uncertainties in solar neutrino experiments, which was the number of neutrinos arriving at the detector. The plan called for Fermilab's accelerator complex to fire protons at a graphite target, producing a spray of short-lived charged particles that would decay into muon neutrinos. The resulting neutrino beam would pass through a 1,000-tonne, train-carriage-sized 'near' detector in the Fermilab grounds, where enough neutrinos would be captured to gauge the total number in the beam. The remaining particles would continue underground on a 735-kilometre, straight-line path to the Soudan Mine in northern Minnesota, where a five-times-larger 'far' detector would measure how many muon neutrinos arrived. If some had oscillated into other forms, the discrepancy would be obvious \u2014 and neutrino oscillation would be verified. \n               Collision course \n             In 1998, however, while MINOS was still on the drawing board, the US project was beaten to this goal by the Super-Kamiokande experiment near Hida in Japan. Through a clever experimental design, the Japanese physicists had been able to verify the existence of oscillation using neutrinos generated by cosmic rays striking the atmosphere 3 . That disappointment took a toll, admits Adamson, one of many particle physicists drawn to the field by a desire to sort out the oscillation phenomenon. But it also proved an opportunity. Rather than being the ones to discover new physics, the MINOS team decided that they would be the ones to carefully characterize the phenomena that the Super-Kamiokande had found. \u201cBy the time we started to operate [in 2005] we were trying to make precision measurements,\u201d says Adamson. One obvious question was why neutrinos have mass at all. The standard model can explain the mass of charged particles, such as the electron, as a subtle interaction with the hypothetical Higgs boson. But that mechanism was not supposed to affect neutrinos. The three neutrino varieties have masses so tiny, less than one-millionth that of the electron, that some kind of exotic mass-generating mechanism may be at work, and high-accuracy measurements of the oscillation phenomenon could shed light on what that is. Such questions soon began to move the long-term planning for accelerator neutrino facilities to the forefront of US high-energy physics. In 2006, the Particle Physics Project Prioritization Panel of the Department of Energy (DOE) laid out a roadmap for the field that included continued support for MINOS and endorsement of a new experiment known as the NuMI Off-Axis Neutrino Appearance (NO\u03bdA). (NuMI, which stands for 'neutrinos at the main injector', is the name of the neutrino beam serving the experiment.) \n               Accelerated development \n             The plans for NO\u03bdA called for a boost in the energy of Fermilab's neutrino beam and a new detector farther north in Minnesota. One of its key goals would be to measure how oscillation occurs among neutrinos' three antimatter counterparts, the antineutrinos, and find out whether the process obeys 'charge-parity' symmetry. This symmetry, which basically means that interactions should remain unchanged if particles and antiparticles swap places and everything is viewed in a mirror, is known to be violated in only a few, very rare reactions. Nevertheless, charge-parity violation is thought to be the ultimate explanation for the emergence of much more matter than antimatter from the early Universe, and why stars, planets and living things can exist today. If the symmetry can be violated for neutrinos and antineutrinos, then these ghostly particles could provide unique insights into the processes that have made the Universe the way it is. At MINOS, meanwhile, the team was busy boosting the intensity of Fermilab's neutrino beam, setting a world record for precisely determining the difference between the masses of the three types of neutrino 4 , and measuring a variety of parameters crucial for the design of NO\u03bdA. Then, in June 2010, scientists at MINOS reported early signs of a discrepancy in the rates at which neutrinos and antineutrinos oscillated 5 . This particular discrepancy would have violated another fundamental symmetry of quantum field theory known as CPT, for charge, parity and time. In its way, this would have been just as astonishing as faster-than-light neutrinos. MINOS scientists began to hope for a paradigm-shattering discovery. But these hopes were dashed when further data, reported in February this year 6 , suggested that the result was a statistical fluctuation. \u201cIt was disappointing,\u201d says Justin Evans, a physicist at University College London who is a member of the MINOS team. \u201cWe made the world's most precise measurement of antineutrinos' parameters \u2014 but everyone wants to be the group that discovers something new.\u201d The faster-than-light neutrino announcement last September from the Oscillation Project with Emulsion-tracking Apparatus (OPERA) experiment in Gran Sasso shook the MINOS team out of its data-collecting routine. The Italian lab reported that neutrinos seemed to be making the 730-kilometre trip from CERN to Gran Sasso some 60 nanoseconds faster than a light beam would. The announcement galled some MINOS collaborators, who back in 2001 had proposed an ultraprecise measurement of neutrino speed only to have the idea nixed by the DOE. The team decided not to resurrect the idea in 2007, when its low-precision measurements hinted that neutrinos might be travelling faster than light 7 . It didn't seem worth fighting that battle again to follow up a result with minimal statistical significance. So, stung by the hullabaloo from Italy \u2014 and aware that MINOS, given the similarity of its set-up to OPERA, was uniquely placed to provide the all-important independent replication of the remarkable finding \u2014 the MINOS team was determined to get the measurement right. But MINOS was scheduled for a temporary shutdown in March 2012, during which the energy of its neutrino beam would be boosted to serve NO\u03bdA. MINOS would also receive some upgrades so that it could look for exotic phenomena such as sterile neutrinos \u2014 hypothetical particles that would not participate in any interaction governed by the standard model \u2014 and neutrino oscillation into extra dimensions. Yet everyone understood how momentous it would be if neutrinos really did violate Einstein's speed limit, says Adamson. Once the team realized that it had the people and the set-up to check the result in a reasonable time, he says, it felt it had a duty to weigh in. Fermilab approved a two-month delay in the neutrino beam shutdown, and the MINOS team resurrected and improved its decade-old proposal to do the measurement at high precision. By the time of the shutdown, now scheduled for 1 May, the experiment should have yielded data sufficient to pinpoint the time-of-flight measurement to within 11 nanoseconds, similar to OPERA's uncertainty. And by sometime in 2013, after the neutrino beam is upgraded to higher energy, the increase in event rate should allow MINOS to reach an error of between 2 and 7 nanoseconds. Physicists at MINOS are determined to make the measurements, even if their chance of a faster-than-light finding is now exceedingly remote given OPERA's admitted error. \u201cThere's a chance it will turn out to be really interesting,\u201d says Tagg, But if, as looks likely, the measurement simply confirms something that everybody already knows, MINOS will at least have produced a high-precision measurement of a fundamental parameter, something that physicists on the experiment insist is a noble contribution, even if it's not a discovery. \u201cIt's a pleasure and privilege to be in a position to settle this,\u201d says Plunkett. \n                     Neutrinos transmit message through solid rock 2012-Mar-15 \n                   \n                     Timing glitches dog neutrino claim 2012-Feb-27 \n                   \n                     Particles break light-speed limit 2011-Sep-22 \n                   \n                     MINOS \n                   \n                     NOvA \n                   \n                     Particle-physics roadmap, 2008 (PDF) \n                   Reprints and Permissions"},
{"file_id": "484432a", "url": "https://www.nature.com/articles/484432a", "year": 2012, "authors": [{"name": "Geoff Brumfiel"}], "parsed_as_year": "2006_or_before", "body": "Work on mutant flu caused a furore, but is far from the only subject in which risks might outweigh benefits. It sounds like a great idea: experimentally mutate a rare but deadly virus so that scientists can do a better job of recognizing dangerous emerging strains. But it also sounds like a terrible idea \u2014 the studies could create a virus that is easier to transmit and produce findings that are useful to bioterrorists. Last year's news that two research teams had done exactly that with the H5N1 bird flu virus was enough to spread fear around the globe and prompt a temporary moratorium on the work. A US biosecurity panel has since lifted its restrictions on publication of the teams' findings in  Nature  and  Science , arguing that the work has clear potential benefits, that the modified virus seems to be less lethal than the original and that the data are already circulating in the community. But the episode has highlighted how thin the line can be between research that's a blessing and research that's a threat. Such fraught lines of enquiry exist in many scientific fields. Some could undermine global security, whereas others could create painful ethical dilemmas for families. The four examples  Nature  profiles here are hardly a definitive list, but they do give a sense of how frequently such conundrums arise \u2014 and show that scientists must constantly ask themselves whether the benefits outweigh the risks. \n               Nuclear fuel or nuclear weapons? \n             A technology that could quickly and efficiently separate radioisotopes for nuclear power plants and nuclear medicine is one that many physicists might find irresistible. But isotope separation is also key to making nuclear weapons, so such a technology could make it easier both to perform and to conceal illicit work on such weapons. Naturally occurring uranium ore is mostly uranium-238, which cannot sustain the kind of runaway chain reaction required to produce an explosion. Just 0.7% is fissile uranium-235. Enriching that quantity to 3\u20135% makes fuel for reactors. To make a bomb, it must be enriched to more than 90%. Because the chemistry of the various isotopes is almost identical, sorting one from another has always been one of the major barriers to the proliferation of nuclear weapons. Today's state-of-the-art technology involves cascades of thousands of centrifuges, and so requires space, a massive amount of electricity, precision-machined parts and time. Lasers can be more efficient. Tiny differences in the mass of uranium nuclei alter the energy levels of their electron shells. Finely tuned lasers can excite just the levels associated with the desired isotope and, together with other technology, can sort the uranium-235 from the rest. The work can be done quickly and secretly. In 2004, it emerged that scientists in South Korea had used lasers to enrich small quantities of uranium-235 to near weapons purity in a matter of weeks. The work went undetected for years before it was eventually disclosed to international inspectors. Now, with the advent of cheap and tuneable lasers, laser separation is within relatively easy reach of physicists the world over. A good example is Mark Raizen at the University of Texas at Austin, who is developing lasers to separate medically important isotopes such as calcium-48, used in the diagnosis of bone disorders; and nickel-64, a promising agent for cancer therapy. The world is facing a shortage of medical isotopes 1 , Raizen says. \u201cPeople's lives will depend on finding new sources.\u201d Raizen's technique is straightforward 2 : finely tuned lasers push electrons in the desired isotope into higher energy states, temporarily changing the atoms' magnetic moment. From that point, all that is needed to sort the isotopes is a large, static magnet. Raizen says he is aware that working with lasers and isotopes poses a proliferation risk. But he argues that it is unlikely that his technique will work well for heavy elements such as uranium. Others stress that laser-enrichment technology should be undertaken with caution. \u201cI think the risks are high,\u201d says Francis Slakey, co-director of the programme on science in the public interest at Georgetown University in Washington DC. Slakey, who has openly opposed the commercialization of laser isotope separation for creating nuclear fuel 3 , would like to see a more open debate in the community \u2014 especially given that many physicists in the field of atomic and molecular optics could follow lines of enquiry similar to Raizen's. \u201cI think there's value in taking a pause and reflecting,\u201d Slakey says. Raizen is pushing ahead, driven by the excitement of using physics for the good of society. As for the risks, \u201cyou can't stop scientific ideas\u201d, he says. If he didn't do it, somebody else would. He expects his first results, on light atoms such as lithium, in a matter of months. \n               Brain scanning or Big Brother? \n             A machine able to accurately read a person's thoughts could be an extraordinary boon \u2014 allowing security officials to catch terrorists before they act, for example, or providing a new voice to some brain-damaged patients who cannot move or communicate. But such a device could also be the stuff of science-fiction nightmares, raising the spectre of Big Brother and ever-vigilant thought police. That may be why the scientists doing such 'mind-reading' research prefer to call it 'brain scanning' or 'brain decoding'. \u201cThe whole concept of 'mind' comes with a lot of baggage,\u201d says Adrian Owen, a neuroscientist at the University of Western Ontario in London, Canada. Nevertheless, these researchers have made extraordinary progress in understanding the human mind. The key has been functional magnetic resonance imaging (fMRI), which allows researchers to monitor blood flow throughout the brain. Blood flow is believed to be a reasonable proxy for neural activity, so fMRI gives a picture of the brain in action. Owen, for example, has worked with patients who have been left in an apparently vegetative state by traumatic injuries. By asking specific questions to stimulate activity in different parts of their brains, he has been able to establish that around 16% of such patients can respond 4 , suggesting that they have at least some level of awareness. Jack Gallant, a neuroscientist at the University of California, Berkeley, has developed algorithms that track patterns of activation in the visual cortex as people watch videos. Reversing those computer codes can create shadowy movies of whatever people are looking at. Gallant thinks that this work could lead to even more advanced methods of communication with locked-in patients, who are paralysed but aware, or brain\u2013machine interfaces that allow people to operate devices with their thoughts. Going further still, John-Dylan Haynes, a neuroscientist at the Charit\u00e9 Medical University of Berlin, is looking for intent. Haynes scans the brain to see whether he can pick out patterns of activity that correspond to a person's decision to act. It works in simple cases 5 : he can see whether an individual decides to press a button up to seconds before the button is pressed, for example. Whether this work could be extended to real-world applications such as lie detection or counter-terrorism is another matter. For one thing, says Gallant, each person's brain is different; it's far from clear that scientists will ever come up with a general-purpose 'mind-reading' algorithm applicable to everyone. For another, says Haynes, fMRI machines could not easily be deployed in airports. Even if they were, a simple shake of the head would throw them off. \u201cYou can't build a detector that says 'this person is going to blow up a plane now',\u201d Haynes says. Nevertheless, even the prospect of such a device raises hackles. \u201cThe thought that someone could use a machine to gain access to your most secret inner thoughts is not pleasant,\u201d says Gallant. Yet entrepreneurs are already dabbling in this arena. Two US companies have fielded fMRI lie-detection services, and the world of advertising has embraced the concept of 'neuromarketing' \u2014 the use of fMRI and other techniques to measure people's subconscious emotional responses to stimuli. So far, concerns raised by such efforts seem hyped. Most courts have listened to scientists' doubts about fMRI lie-detection, and are not admitting them as evidence, says Steven Laken, chief executive of Cephos, an fMRI lie-detection firm in Tyngsboro, Massachusetts. Neuromarketing \u201cis even more dubious\u201d, says Haynes. But Gallant thinks that the applications of the technology will come. \u201cIt'll go way further than you think,\u201d he says. \n               Climate saviour or climate disaster? \n             To hear proponents talk, humanity's best hope to escape the ravages of global warming may be geoengineering: manipulating Earth's environment on a planetary scale. This might involve solar-radiation management \u2014 spraying tiny particles high into the stratosphere, for example, where they could cool things down by reflecting some of the incoming sunlight. Or it might involve the removal of carbon dioxide, perhaps by seeding the ocean with iron to create algal blooms that would take up carbon dioxide from the air and then carry it to the ocean floor when they die. To critics, geoengineering would be reckless in the extreme \u2014 and might further inflame the volatile politics of climate change. Witness the controversy that has swirled around the UK-government-funded Stratospheric Particle Injection for Climate Engineering (SPICE) project, which involves researchers from the universities of Bristol, Cambridge, Edinburgh and Oxford, as well as the UK Met Office and Marshall Aerospace in Cambridge. SPICE is a proof-of-principle project designed to test solar-radiation management. The idea is to pump water up a 1-kilometre-long hose and spray it into the air. The altitude is too low to alter the climate, and there is plenty of water vapour already up there, says David Keith, a geoengineering specialist at Harvard University in Cambridge, Massachusetts. \u201cIt doesn't pose a risk other than the hose falling on someone's head,\u201d he says. Nevertheless, environmentalists sounded the alarm on SPICE as soon as they caught wind of it last year. Quite aside from geoengineering's potential for unintended consequences \u2014 such as accidentally shifting rainfall patterns and triggering droughts \u2014 there is a moral hazard to such work, argues Pat Mooney, executive director of the ETC Group, an environmental organization based in Ottawa, Canada. With climate negotiations stalled around the world, the very presence of such an experiment may make politicians think that there's a way to wriggle out of emissions caps. \u201cIt will be an easy way for governments to sidestep their obligations,\u201d Mooney says. ETC and other groups petitioned the British government to halt SPICE last autumn, saying it would hurt the country's credibility in this year's climate talks in Rio de Janeiro, Brazil. \u201cIt did get a little bit bumpy at the time,\u201d says Phil Macnaghten, a geographer at Durham University, UK, who is overseeing an ethical and societal assessment of SPICE. In September 2011, Macnaghten and others recommended that the experiment pause while researchers engage with the public and interest groups \u2014 at present, it is still on hold. Mooney wants to see internationally agreed rules that would include prohibitions on geoengineering experiments with transnational consequences until major questions are answered. For example, will geoengineering even work? And what unintended consequences might it have? But as global temperatures continue to rise, Macnaghten believes that, provided researchers answer public concerns, the science should be allowed to continue. \u201cWhen you don't know what you don't know, then it's very hard to know how to progress,\u201d he says. \n               Baby blessing or Brave New World? \n             Within a pregnant mother's blood is her unborn child's full genetic sequence. Soon, say geneticists, the question will no longer be how to get at it, but how to use it to understand the baby's future behaviour and health \u2014 and how to cope with the thorny ethical issues that will inevitably ensue. The key to this new form of prenatal diagnosis lies in the fragments of DNA that float freely through every person's bloodstream. In pregnant women, around 15% of that DNA comes from the fetus, according to Dennis Lo, a pathologist at the Chinese University of Hong Kong, who is working to develop fetal genetic screening with Sequenom, a biotechnology company based in San Diego, California. The trick is figuring out which DNA belongs to the fetus and which belongs to the mother. Finding the father's genetic contribution is easiest. Researchers extract DNA from the expectant mother's blood and look for variations in common with the father's genetic code to separate his half of the fetal DNA. The mother's half is tougher to identify because it is identical to the rest of the DNA in her blood. To find it, researchers count the number of times particular versions of genes are sequenced. Those held by the child and mother will appear fractionally more frequently than those held by the mother alone. Screens for specific diseases based on this method are already nearing the market, says Lo. Scientists can check for Down's syndrome, a disorder that arises when an embryo receives three copies of chromosome 21, instead of the usual two. The test is more than 95% sensitive, making it comparable to more invasive tests such as amniocentesis 6 . Because it carries no risk, Lo believes that it will soon become nearly universal. It may sound positive that many more parents will be forewarned of Down's syndrome and other genetic diseases such as cystic fibrosis, but it raises some thorny societal questions, says Henry Greely, a bioethicist at Stanford University in California. With universal screening, many more pregnancies might be terminated \u2014 and women who choose to carry a child with, say, Down's syndrome to term could face social and legal stigmas, he warns. \u201cThere are countries that are very concerned about mental retardation and might be willing to enforce genetic selection to avoid it,\u201d he says. Private insurers or public-health services might resist paying for the care of disabled children if their birth could have been avoided. These dystopian developments aside, some patient advocates fear that a sudden drop in the number of children with these diseases could mean less social support and fewer research dollars for their conditions. Going beyond targeted diseases, full sequencing of the fetal genome is technically possible and will soon be affordable, says Stephen Quake, a researcher at Stanford University who works with Verinata Health, a fetal-screening company in Redwood City, California. And that, says Greely, will raise even more contentious issues. \u201cPeople who come from a family with Alzheimer's might choose to terminate a pregnancy at high risk of Alzheimer's even though that Alzheimer's might occur 65 years into the future,\u201d he says \u2014 or might never occur at all, given that it is currently impossible to predict whether this condition or the vast majority of other diseases will occur on the basis of genetic information alone. At present, there are no guidelines on how to counsel prospective parents about the avalanche of genetic information they may be about to receive. Lo says that he would be wary of telling parents before birth about a disease that could be cured within a child's lifetime. \u201cWho knows where medical science will be in 60 years?\u201d But that is no reason to stop the research, says Quake, who has a cousin with Down's syndrome. He says he has thought long and hard about the issues raised by early testing, but in the end feels that the benefits greatly outweigh the risks. \u201cThe earlier parents find out, the better prepared they are,\u201d he says.\n \n                 See Editorial \n                 page 415 \n               \n                     Brain imaging: fMRI 2.0 2012-Apr-04 \n                   \n                     US biosecurity board revises stance on mutant-flu studies 2012-Mar-30 \n                   \n                     Environmental science: Good governance for geoengineering 2011-Nov-16 \n                   \n                     Fetal gene screening comes to market 2011-Oct-25 \n                   \n                     Get ready for the flood of fetal gene screening 2011-Jan-19 \n                   \n                     Stop laser uranium enrichment 2010-Mar-03 \n                   \n                     Computer model knows what you're thinking 2008-May-29 \n                   \n                     SPICE experiment \n                   \n                     Raizen lab \n                   \n                     Cephos \n                   \n                     Gallant lab \n                   \n                     Sequenom \n                   \n                     Verinata Health \n                   Reprints and Permissions"},
{"file_id": "484436a", "url": "https://www.nature.com/articles/484436a", "year": 2012, "authors": [{"name": "John Whitfield"}], "parsed_as_year": "2006_or_before", "body": "A handful of plant collectors has shaped the field of botany. Now they are disappearing, and there are no clear successors. John Wood has had malaria twice, and Dengue fever once. He has shaved leeches off his legs with a machete in southeast Asia \u2014 \u201cyou're supposed to use a lit cigarette, but I don't smoke\u201d \u2014 had his car stolen in Bolivia and lain face down in the Yemeni desert while local tribes exchanged gunfire over his head. He encountered such inconveniences in the process of collecting more than 30,000 plant specimens over 40 years of travelling the globe, mostly as a hobbyist. More than 100 of his finds have become type specimens, from which new species are described. Those numbers elevate him to the ranks of a star collector \u2014 the top 2% of botanical gatherers, who have accumulated more than half of the type specimens in some of the world's most important collections 1 . These elite field workers have probably numbered fewer than 500 people throughout history. But they have contributed much of what scientists know about plant diversity, ecology and evolution, and have been crucial in the race to document the world's plants before they are lost to deforestation, development, invasive species and climate change. Many botanists, however, believe that the era of the superstar collector is drawing to a close, at least in the 200-year-old form of a man (or occasionally woman) setting out from Europe or North America to see what the tropics hold. As botany has moved away from taxonomy and towards molecular studies, few of the jobs available allow researchers to spend long periods in the field gaining an encyclopaedic knowledge of plants. Tropical countries have also imposed restrictions on foreign researchers and are developing their own botanical expertise among home-grown scientists. \u201cIt's possible that the days of the non-native plant collector are virtually at an end, and people like myself are the last examples,\u201d says Wood. As the star collectors disappear, botanists are debating how to fill the gap. Some researchers, including Wood, are training botanists in tropical countries, the presumed home of most undiscovered plants. But others think that it might be more efficient to recruit a large group of less-skilled collectors, aided by technology and crowdsourcing techniques. \u201cThe real question is, can we exchange a few elite collectors for an army of enthusiastic less-experienced collectors?\u201d asks Cam Webb, a Harvard University plant scientist based in Indonesian Borneo. That is a tall order, given the seminal part that top collectors continue to play. \u201cThe most interesting results are produced mostly by people who know what the plants look like, and what to expect in a certain area, and that's why they can pick out what's unexpected,\u201d says Henk Beentje, a specialist in tropical palms at Kew Gardens in London. \u201cThey're worth more than their weight in gold.\u201d \n               Budding interest \n             Like many elite collectors, Wood started early. As a child, he accumulated stamps, rocks, butterflies and as many flowers as he could. As a teenager, he contributed to a project to record all the plant species living in his home county of Essex, UK. When he moved to Saudi Arabia in 1970 to teach English, botany provided him with an excuse to travel to wild and remote places. A contact in the British embassy put him in touch with a researcher at the Natural History Museum in London who was interested in receiving Arabian plants, and Wood sent his first specimens back in the diplomatic pouch. In 1974, Wood moved to North Yemen, where he spent six years working in educational development, volunteering to inspect remote schools so that he could visit the places with the most interesting plants. Gradually, he began to try to identify and understand plants himself, driven by the thrill of finding something new, or something that had last been collected two centuries ago. He also became interested in broader questions of plant ecology \u2014 his first paper, published in 1979, discussed whether Yemen had once been forested 2 . He went on to collect in Colombia, Bhutan and Bolivia. Since 2001, he has been a professional botanist, spending half the year in plant taxonomist Robert Scotland's lab at the University of Oxford, UK, and the other half in Bolivia, doing fieldwork and training local scientists. Together with Scotland and others, Wood is finishing a monograph on  Strobilanthes , a tropical genus of several hundred species. It was Scotland who led the study that revealed the influence of the elite collectors. Along with Wood and an international team of botanists and ecologists, he scoured databases to find out who had collected each of 103,000 type specimens in four of the world's largest herbaria \u2014 at the Natural History Museum in London, the Royal Botanic Garden Edinburgh, UK, the Missouri Botanical Garden in St Louis and the Royal Botanic Gardens in Melbourne, Australia. The analysis showed that a small group of what the team calls big hitters has been hugely and disproportionately effective at finding species over the past two centuries. It also showed that most big hitters are wide-ranging, in both where and what they collect \u2014 Wood, for example, has combined regular intercontinental relocations with an omnivorous collecting habit that takes in half a dozen plant families, including large groups such as the grasses and daisies. This breadth seems to underpin the ability to find lots of new species. Broad experience helps a collector to know what to sample, and what to ignore. If a plant looks new, collectors try to get as many parts \u2014 flowers, leaves, root and fruit \u2014 as possible. (When sampling a tree, this often involves climbing it.) In the tropics, they have to race to get specimens into a press or preserved in alcohol before the plants start to decay. Drying and mounting plants so that they display their diagnostic features, and yield high-quality DNA samples, requires skill and practice. That craftmanship must be allied to innate gifts in pattern recognition, says Quentin Luke, a botanist affiliated with the East African Herbarium in Nairobi. \u201cPeople with a natural ability to distinguish plants from each other are few and far between,\u201d he says. Identifying plants that aren't in flower \u2014 which will be most of them in a tropical forest with no set flowering season \u2014 is particularly challenging. It requires knowledge of subtle features of leaf morphology or bark, or even the smell of wood or the taste of leaves. A prodigious visual memory also helps. Alwyn Gentry of the Missouri Botanical Garden, one of the leading botanists of the twentieth century, claimed to remember every plant he had ever collected, amounting at his death to more than 80,000 specimens 3 . \n               Field tested \n             For elite plant collectors, experience and ability reinforce one another: field botanists find the largest number of new species per year at the end of their careers. But they can't get that far without a cast-iron constitution and a certain sangfroid. Tom Croat of the Missouri Botanical Garden \u2014 who, with more than 100,000 specimens from 37 countries, is probably the most prolific living plant collector \u2014 once had a Costa Rican road collapse beneath him, causing his camper van, containing a custom-built plant drier, his wife and two young children, to roll down a mountain and into a river. And Beentje once had to talk down a lynch mob on Madagascar. \u201cThey thought I was abducting virgins and stealing their blood. We got out by the skin of our teeth.\u201d Some botanists die at work. Gentry was killed in 1993, aged 48, when a plane taking him on a collecting trip in the mountain forests of Ecuador crashed. And in 2010, Leonard Co, one of the Philippines' top plant researchers, was shot dead while working in the forest, either in crossfire between government forces and communist insurgents, or because the army mistook him for a guerrilla. There is no shortage of adventurous and skilful young botanists willing to embrace such a life, say senior collectors. And there is plenty of work left to do: estimates suggest that there are 70,000 plant species left to discover 4 , mostly in equatorial Latin America and Indonesia, to add to the 350,000 or so already known. For the past few decades, about 2,000 new species have been described each year, with no sign of a slowdown. There are, however, few places employing plant collectors. The first wave of globe-trotting botanists, in the late eighteenth and early nineteenth centuries, carried out surveys on behalf of the European empires; later, horticultural companies paid top collectors to bring back new products. Now, nearly all the serious collectors work for major botanic gardens and museums. Yet even there, general botanists are no longer in such demand. The modern botanist tends to focus on one plant group and uses DNA sequences to decode evolutionary history and relationships. \u201cWe'll see fewer collections per individual because people are becoming so specialized. Just collecting a lot of specimens isn't something people have much respect for,\u201d says Robbin Moran, who studies ferns at the New York Botanical Garden. The shifts in botany have had costs, he says. \u201cThe really big collectors have been tremendous generalists, and that's something that's being lost.\u201d Croat especially laments the waning opportunities to practise floristic taxonomy \u2014 describing all the plants in a location. He earned his spurs putting a name to every plant species on Barro Colorado Island 5 , a research station in the Panama Canal run by the Smithsonian Institution in Washington DC. \u201cFloristic studies give knowledge of all groups of plants,\u201d he says. \u201cWithout that, the average student has no idea what to work on. Most of the graduate students today wouldn't be able to find the forest, let alone find anything in it.\u201d Plant collectors are also facing a growing number of bureaucratic hurdles. Tropical countries, seeking to protect potentially lucrative sources of drugs and crops, have tightened their regulation of plant collecting. India is among those that ban the export of plant specimens altogether; other countries demand that botanists specify what groups they will collect, hindering broad floristic work. \u201cEach time I go back to Bolivia there's more paperwork and more restrictions,\u201d says Wood. That makes it harder for botanists to gain international experience, he says. \u201cThere's a disincentive to start in another country, because it means starting your permits and contacts from scratch.\u201d The top collectors of the future are likely to be born in, or migrate to, tropical countries, he says. This shift is already happening, with local collectors and herbaria compensating for the decline of the big-hitting Westerner, says Gerrit Davidse, of the Missouri Botanical Garden, a co-author of the collector analysis. \u201cIn the past, you could mostly ignore local collections in places such as Mexico and Brazil,\u201d he says. \u201cNow you ignore them at your peril.\u201d  It's possible that the days of the non-native plant collector are virtually at an end.  The tight regulations do not spare native collectors. \u201cWe have many problems applying for permits,\u201d says Alfredo Fuentes, a botanist at the National Herbarium of Bolivia in La Paz. \u201cIt is very difficult to explain why we collect, and that the collections are not for commercial purposes. We spend a lot of time on this.\u201d In Kenya, says Luke, it is \u201ca huge song and dance\u201d for local botanists to send specimens abroad to be identified, which is usually necessary for the most interesting finds. And developing-world botany still requires the support of rich nations. \u201cIn Bolivia, the government support for botany is almost non-existent,\u201d says Fuentes. \u201cThis major shortcoming is largely filled by foreign institutions and researchers who strongly support the training of new botanists.\u201d The changing botanical landscape, and the many threats to plant diversity, have led Webb to advocate a different approach to discovery 6 . Western collectors have always employed local naturalists and students, to gather and process specimens. Now, technology could allow this approach to be scaled up, says Webb. In a few years, he predicts, volunteers will be armed with a tablet computer bearing the world's botanical information in one hand and a pocket DNA sequencer that identifies species in the other. His team is working on software that will allow anyone to help identify specimens online, by pairing up images of known and unknown plants. \u201cPerhaps it doesn't matter which is better, the elite few or the excited rabble,\u201d says Webb. \u201cBut I am optimistic that the latter could actually be made to be highly selective and effective via good training, augmented with the best of tech.\u201d Others are sceptical that this approach will bear fruit. DNA-based identification has so far yielded little for plants, says Scotland. \u201cWe're still trying to work out what the markers are, even though it's been talked about for a decade.\u201d And although volunteers can collect huge amounts of material \u2014 botanists call it hay baling \u2014 they often bring back the weedy and introduced, rather than the rare and interesting. Supporting a new generation of experts might be more productive, Scotland says. \u201cFewer people over a longer period of time might give more rewards than lots of unfocused people collecting lots of the same thing.\u201d Wherever the collectors of the future hail from, they will have to be content with a long wait for recognition. Herbaria are filled with unidentified specimens, and the gap between a species being collected and being described averages about 36 years 4 . This means that any analysis of collectors' achievements will underestimate the contribution of contemporary botanists. It also suggests that at least half of the 70,000 unidentified plant species are already in a cupboard somewhere. The bottleneck means that star collectors of the past remain a force in present-day botany. Today's researchers spend their days with plants collected by botanists going back to the eighteenth-century days of Joseph Banks, and speak of their forebears with the same familiarity as they do of their contemporaries. As Wood puts it: \u201cCollectors have a sense of their place in history.\u201d\n \n                     Botanists shred paperwork in taxonomy reforms 2011-Jul-20 \n                   \n                     Species spellchecker fixes plant glitches 2011-Jun-13 \n                   \n                     Threats to the world's plants assessed 2010-Sep-28 \n                   \n                     DNA barcodes for plants a step closer 2009-Jul-27 \n                   \n                     Entomologists stifled by Indian bureaucracy 2008-Mar-05 \n                   \n                     Nature \u2019s supplement on biodiversity \n                   \n                     JSTOR database of plant collectors \n                   \n                     John Wood \n                   \n                     Robert Scotland's lab \n                   \n                     Tom Croat \n                   \n                     The Plant List \n                   Reprints and Permissions"},
{"file_id": "483264a", "url": "https://www.nature.com/articles/483264a", "year": 2012, "authors": [{"name": "Brendan Borrell"}], "parsed_as_year": "2006_or_before", "body": "The enduring quest for a coffee bean without the buzz. Paulo Mazzafera punched a pea-sized disc out of a waxy green coffee leaf, then placed the disc in a small vial with a mixture of chloroform and methanol to dissolve it. Later, he loaded the extract, along with 95 other samples, into a high-performance liquid chromatography machine, which separates out each chemical component. When the plant physiologist returned to his lab at the University of Campinas in Brazil the next morning, he sat down at his laptop to examine the results. Scrolling from one chromatogram to the next, he scrutinized the peak representing caffeine. In one plant, it was missing. Mazzafera ran the sample twice more and then, just before noon, called his collaborator Bernadete Silvarolla, based at the agricultural station nearby, to share the news. \u201cAre you sure?\u201d she asked. He was. In fact, he was thrilled. After screening thousands of plants over the course of two decades, his project to find a naturally caffeine-free coffee finally seemed to be bearing fruit. That was in late 2003. Coffee contains some 2,000 chemical compounds that give the drink its enticing aroma and flavour, including caffeine, a stimulant and natural pesticide. Removing the caffeine while leaving all the others intact poses a significant challenge. Brewers have generally turned to chemistry: Ludwig Roselius of Bremen, Germany, patented the first commercial decaffeination process in 1905. But his coffee, marketed as Kaffee HAG, used benzene in the extraction process, and the chemical was later replaced by less toxic solvents. Today, companies may instead douse raw green coffee beans in high-pressure liquid carbon dioxide or soak them in hot water for several hours to remove the caffeine before roasting. Aficionados say that all these methods destroy the taste, but the decaf market is still worth US$2 billion a year. Researchers have long sought a better bean, harvested directly from the plant caffeine-free. This would preserve coffee's complex flavour and give growers a high-end slice of the decaf market. But developing such a bean through conventional breeding or even genetic modification has proved more difficult than anyone anticipated (see 'The ups and downs of decaffeination'). Coffee plants take years to begin producing beans, and can be fickle when they do. Moreover, to make them profitable to farm, the plants need to be productive, ripen synchronously and be of a size and shape that can be harvested easily by hand or by machines. The loss of any of these traits can render a plant worthless. The caffeine-free quest has produced a string of high-profile papers, but not a drop of marketable coffee. \n               boxed-text \n             Basic research often proves hard to translate into industrial agriculture, says Rod Sharp, a retired plant cell biologist who tried to produce caffeine-free coffee in the 1980s while at DNA Plant Technology in Cinnaminson, New Jersey. \u201cThose in the research lab are always a bit naive. We jump up and down when there is a breakthrough, but turning that into a commercial operation is another challenge altogether.\u201d However, Sharp remains confident that the plant will one day yield its secrets. \u201cIt will happen,\u201d he says. \u201cIt's just a long incubation period.\u201d This is certainly true for Mazzafera's plant: more than eight years after its discovery, his colleagues are still trying to turn it into a crop. Coffee is worth a total of $15 billion to $20 billion per year to exporting countries, which include Brazil, Colombia and Vietnam. A relatively recent innovation, compared with tea or wine, it dates to about the fifteenth century when \u2014 according to at least one account \u2014 a Yemeni mystic described a revitalizing beverage prepared in Ethiopia by roasting and boiling berries. Two coffee species dominate the market today:  Coffea arabica , the better-tasting bean, which grows in cooler climates, and  Coffea canephora , commonly known as 'robusta', which is used mainly in instant coffee and lower-quality blends. Caffeine, which is present at 1.2% in commercial  C. arabica  and 2\u20133% in  C. canephora , has helped to make both species part of a worldwide addiction. But the stimulant beloved by many is avoided by others who are unusually sensitive to its effects, abstain for religious reasons or simply don't want to be kept awake. Gabriel Bertrand of the Pasteur Institute in Paris discovered a caffeine-free species of coffee on Grande Comore island near Madagascar in 1901. In fact, many of the hundred or so species of  Coffea  are either caffeine-free or contain low levels of the stimulant. Several naturally occurring intermediate-caffeine coffees (with 0.6\u20131% caffeine) have already reached the market, including one produced by the Italian coffee-maker Illy. Unfortunately, most plants with the lowest caffeine levels produce few beans, or contain high concentrations of bitter compounds. Nevertheless, the existence of such natural variation suggests that a diligent breeder could create a commercially viable caffeine-free strain. \n               Coffee and dreams \n             Mazzafera began his attempts to do just that in 1983 at the Agronomical Institute of Campinas (IAC), a century-old agricultural station in the rolling hills northwest of S\u00e3o Paulo, Brazil. He set out to study the genetics and physiology of caffeine biosynthesis under Alcides Carvalho, a pioneering plant breeder who established the IAC's collection of coffee plants, which now number 70,000 and represent more than 1,000 wild strains, breeding lines, hybrids, mutants and cultivated varieties from around the world. Writer Brendan Borrell talks about the difficulties of cultivating a naturally caffeine-free coffee At first, Mazzafera used an old-school spectrophotometer to measure caffeine content one sample at a time. In 1987, he got a job at the University of Campinas and installed a high-performance liquid chromatography machine in his lab, allowing him to process samples more efficiently. By this point, scientists had sketched out the basic four-step pathway by which  C. arabica  synthesizes caffeine. Mazzafera studied caffeine production and breakdown in great detail in seven species, hoping to find one with defects in a pathway that rendered the plant low in caffeine. At the same time, he and Carvalho, who died in 1993, were cross-breeding commercial coffee cultivars with wild non-arabica species low in caffeine. But it proved impossible to eliminate caffeine while maintaining the desirable attributes of  C. arabica . \u201cWe were just wasting time,\u201d says Mazzafera. In 2000, Mazzafera teamed up with Silvarolla, a coffee breeder at the IAC. They shifted their focus to a group of  C. arabica  plants originally collected during a 1964 United Nations expedition to Eritrea and Ethiopia. Seed samples \u2014 620 in total \u2014 were divided up and grown in several countries, including Costa Rica. Later, 308 of these lineages were collected in Costa Rica and sent to Brazil. Mazzafera believed it would be much easier to produce marketable coffee by starting with the Ethiopian  C. arabica  plants than by hybridizing with other species. It was from this collection that Mazzafera discovered the promising strain in 2003, as well as two more like it. After confirming that, like the leaves, the beans were caffeine-free, he worked out that the plants were defective in the final step of the chemical pathway that turns theobromine \u2014 a mild stimulant and diuretic \u2014 into caffeine 1 . The Brazilian government offered the research group a $1.2-million grant along with an order to keep the location of the precious plants under wraps. Mazzafera felt certain that commercial growers would be planting the new variety in five years. That is, so long as others didn't get there first. \n               Bean modification \n             The advent of genetic engineering led many scientists to try to make decaf by splicing the right genes into the right beans. But coffee has proved resistant to this kind of tinkering. In 1992, geneticist John Stiles of the University of Hawaii in Honolulu wanted to use 'antisense' technology, whereby a gene inserted into the plant reduces production of a target protein. This was the technology used to produce the Flavr Savr tomato, the first genetically modified organism to be approved for human consumption. Stiles's goal was to target a protein in the caffeine-producing pathway. Problems cropped up almost immediately. Creating any genetically modified plant involves culturing a blob of plant cells on nutrient-rich agar, inserting the desired genetic material into those cells, and then convincing the tissue to sprout into a plant. For  C. arabica , that process is mysteriously inefficient. Over the next seven years, Stiles and two postdocs, Kabi Neupane and Stefan Moisyadi, struggled to overcome the biological roadblocks. They produced plants that seemed to have low levels of caffeine, and Stiles made some enthusiastic claims. In August 1999, for example, he told  The Wall Street Journal  that he would be beginning field trials that month in Hawaii before expanding to Mexico, with commercial prospects after three years. The plants, however, did not cooperate. As they grew, their caffeine levels rose. Moisyadi and Neupane moved on to academic careers and, in 2000, Stiles left the university, setting up a private lab in Waialua. In 2008, after disagreements with the local community and the state legislature over the right to field test his transgenic coffee, the company folded, and Stiles now says that he was never 100% certain that he had created caffeine-free coffee. Many coffee researchers also doubt that he had. \u201cWe were always doing this on a shoestring,\u201d Stiles says. \u201cWe were never Monsanto.\u201d Neither was Shinjiro Ogita, a postdoc in Hiroshi Sano's lab at the Nara Institute of Science and Technology in Japan. In 2001, he began a research programme targeting an enzyme in the caffeine pathway that had recently been identified in tea. His group used an efficient gene-silencing technology called RNA interference, and worked with robusta coffee in the hope that cell culture would be easier. It wasn't. Few cells took up the engineered DNA. Ogita was able to recover just enough to produce 35 transgenic seedlings. He tested some leaves and found they had as much as 70% less caffeine than his control plants. \u201cIt was kind of unbelievable,\u201d he says. He remembers popping a bottle of Dom Perignon champagne the day his paper was accepted by  Nature 2 . He has since tailored the methods to  C. arabica , but the plants have still not produced beans. Now at Toyama Prefectural University, Ogita tends about 40 transgenic plants. Each year, he says, the female part of the flowers, called the pistil, matures and deteriorates a week before the pollen is ready. Even if Ogita can overcome these breeding issues, it is hard to imagine that transgenic caffeine-free coffee will land on supermarket shelves any time soon. One basic hurdle, says biochemist Alan Crozier at the University of Glasgow, UK, is that side routes in the caffeine pathway result in some production of caffeine, so transgenic coffee may never be caffeine-free. Gaining public acceptance is likely to be another challenge. Monsanto and other agricultural giants have generally commercialized technologies with the grower in mind \u2014 for example, pest resistance or herbicide tolerance \u2014 rather than focus on consumer-oriented traits such as low caffeine or high antioxidants. So finding financial backing may be tricky. \n               Breed appeal \n             A general aversion to genetically modified food has made the naturally caffeine-free Ethiopian strains that much more appealing. But breeding the trait into a commercially viable cultivar has taken longer than Mazzafera or Silvarolla anticipated. During the flowering season, Silvarolla spends all day in the field, clipping the pollen-producing stamens off the flowers and bagging the pistils so that she can hand-pollinate them later. She produces 800 new plants every year. The beans that are produced taste good, according to tasting panels put together by the IAC, but the plants tend to be bushy and don't flower uniformly. The team is now working on breeding plants that have the low-caffeine trait but not the low-productivity one. \u201cAt first, we thought it would be a piece of cake,\u201d says Miriam Maluf, a geneticist at the IAC working on the project. But the researchers may be facing the biggest challenge of all in removing caffeine from living plants: it is there for a reason. Caffeine is a natural insecticide, which explains why wild coffee plants that lack caffeine tend to contain other bitter compounds \u2014 to deter pests. And the researchers have to contend with these issues largely without Mazzafera's help. Soon after the 2004 discovery and subsequent publicity, the IAC took greater control of the programme, and Mazzafera, based at the university, has only a limited role. \u201cIt's disappointing,\u201d he says. Nevertheless, despite so many years without success, the quest for caffeine-free coffee shows little sign of fading. Plant geneticist Benoit Bertrand of the French Centre for Agricultural Research and Development in Montpellier has been searching the centre's collection for caffeine-free plants. And Chifumi Nagai of the Hawaiian Agriculture Research Center in Waipahu has been working in Madagascar with the Japanese coffee manufacturer UCC Ueshima to develop a three-species hybrid that tastes good, has a moderate yield and contains just 0.37% caffeine 3 . Its success is uncertain; Madagascar faces significant logistical challenges even growing and harvesting normal  C. arabica . Even Mazzafera, now 51, hasn't given up. On a cloudy November day, he walks out past two mesh shade houses behind the biology department in Campinas and reveals several hundred hip-high coffee plants. Some have rows of green coffee berries clustered on their branches. Many, he says, are nearly caffeine-free. Miffed at his inability to continue his work with the Ethiopian varieties, he came up with a new plan in 2006. He took the seeds of a productive  C. arabica  variety, soaked them in chemicals that cause mutations, and then screened the caffeine levels of 28,000 seedlings. \u201cIt was a shot in the dark,\u201d he says. He ended up with 7 plants that have only 2% of normal caffeine levels 4 . He has already trademarked their name: Decaffito. Challenges remain \u2014 the strain is susceptible to cross pollination, which can reinstate caffeine production in the beans \u2014 but he is determined to breed a commercially viable strain. He has even been talking to one company about investing in his research. But knowing the hurdles ahead, he is willing to settle for less. \u201cIf I had a farm,\u201d he says, \u201cI would grow this coffee for myself.\u201d \n                     Bacterial gene helps coffee beetle get its fix 2012-Feb-27 \n                   \n                     GM crops: Battlefield 2009-Sep-02 \n                   \n                     Cat droppings yield chic coffee 2004-Jul-27 \n                   \n                     Grow a decaffeinated cuppa 2004-Jun-24 \n                   \n                     GM decaf coffee grown on trees 2003-Jun-19 \n                   \n                     Agronomical Institute of Campinas \n                   \n                     University of Campinas \n                   Reprints and Permissions"},
{"file_id": "483260a", "url": "https://www.nature.com/articles/483260a", "year": 2012, "authors": [{"name": "David Wolman"}], "parsed_as_year": "2006_or_before", "body": "Since the 1960s, researchers have been scrutinizing a handful of patients who underwent a radical kind of brain surgery. The cohort has been a boon to neuroscience \u2014 but soon it will be gone. In the first months after her surgery, shopping for groceries was infuriating. Standing in the supermarket aisle, Vicki would look at an item on the shelf and know that she wanted to place it in her trolley \u2014 but she couldn't. \u201cI'd reach with my right for the thing I wanted, but the left would come in and they'd kind of fight,\u201d she says. \u201cAlmost like repelling magnets.\u201d Picking out food for the week was a two-, sometimes three-hour ordeal. Getting dressed posed a similar challenge: Vicki couldn't reconcile what she wanted to put on with what her hands were doing. Sometimes she ended up wearing three outfits at once. \u201cI'd have to dump all the clothes on the bed, catch my breath and start again.\u201d In one crucial way, however, Vicki was better than her pre-surgery self. She was no longer racked by epileptic seizures that were so severe they had made her life close to unbearable. She once collapsed onto the bar of an old-fashioned oven, burning and scarring her back. \u201cI really just couldn't function,\u201d she says. When, in 1978, her neurologist told her about a radical but dangerous surgery that might help, she barely hesitated. If the worst were to happen, she knew that her parents would take care of her young daughter. \u201cBut of course I worried,\u201d she says. \u201cWhen you get your brain split, it doesn't grow back together.\u201d In June 1979, in a procedure that lasted nearly 10 hours, doctors created a firebreak to contain Vicki's seizures by slicing through her corpus callosum, the bundle of neuronal fibres connecting the two sides of her brain. This drastic procedure, called a corpus callosotomy, disconnects the two sides of the neocortex, the home of language, conscious thought and movement control. Vicki's supermarket predicament was the consequence of a brain that behaved in some ways as if it were two separate minds. After about a year, Vicki's difficulties abated. \u201cI could get things together,\u201d she says. For the most part she was herself: slicing vegetables, tying her shoe laces, playing cards, even waterskiing. But what Vicki could never have known was that her surgery would turn her into an accidental superstar of neuroscience. She is one of fewer than a dozen 'split-brain' patients, whose brains and behaviours have been subject to countless hours of experiments, hundreds of scientific papers, and references in just about every psychology textbook of the past generation. And now their numbers are dwindling. Through studies of this group, neuroscientists now know that the healthy brain can look like two markedly different machines, cabled together and exchanging a torrent of data. But when the primary cable is severed, information \u2014 a word, an object, a picture \u2014 presented to one hemisphere goes unnoticed in the other. Michael Gazzaniga, a cognitive neuroscientist at the University of California, Santa Barbara, and the godfather of modern split-brain science, says that even after working with these patients for five decades, he still finds it thrilling to observe the disconnection effects first-hand. \u201cYou see a split-brain patient just doing a standard thing \u2014 you show him an image and he can't say what it is. But he can pull that same object out of a grab-bag,\u201d Gazzaniga says. \u201cYour heart just races!\u201d Michael Gazzaniga reflects on five decades of split-brain research Work with the patients has teased out differences between the two hemispheres, revealing, for instance, that the left side usually leads the way for speech and language computation, and the right specializes in visual-spatial processing and facial recognition. \u201cThe split work really showed that the two hemispheres are both very competent at most things, but provide us with two different snapshots of the world,\u201d says Richard Ivry, director of the Institute of Cognitive and Brain Sciences at the University of California, Berkeley. The idea of dichotomous consciousness captivated the public, and was greatly exaggerated in the notion of the 'creative right brain'. But further testing with split-brain patients gave a more-nuanced picture. The brain isn't like a computer, with specific sections of hardware charged with specific tasks. It's more like a network of computers connected by very big, busy broadband cables. The connectivity between active brain regions is turning out to be just as important, if not more so, than the operation of the distinct parts. \u201cWith split-brain patients, you can see the impact of disconnecting a huge portion of that network, but without damage to any particular modules,\u201d says Michael Miller, a psychologist at the University of California, Santa Barbara. David Roberts, head of neurosurgery at Dartmouth-Hitchcock Medical Center in Lebanon, New Hampshire, sees an important lesson in split-brain research. He operated on some of the cohort members, and has worked closely with Gazzaniga. \u201cIn medical school, and science in general, there is so much emphasis on large numbers, labs, diagnostics and statistical significance,\u201d Roberts says \u2014 all crucial when, say, evaluating a new drug. But the split-brain cohort brought home to him how much can be gleaned from a single case. \u201cI came to learn that one individual, studied well, and thoughtfully, might enable you to draw conclusions that apply to the entire human species,\u201d he says. Today, the split-brain patients are getting on in years; a few have died, one has had a stroke and age in general has made them all less fit for what can be taxing research sessions of sitting, staring and concentrating. The surgery, already quite rare, has been replaced by drug treatments and less drastic surgical procedures. Meanwhile, imaging technologies have become the preferred way to look at brain function, as scientists can simply watch which areas of the brain are active during a task. But to Miller, Ivry, Gazzaniga and others, split-brain patients remain an invaluable resource. Imaging tools can confirm, for example, that the left hemisphere is more active than the right when processing language. But this is dramatically embodied in a split-brain patient, who may not be able to read aloud a word such as 'pan' when it's presented to the right hemisphere, but can point to the appropriate drawing. \u201cThat gives you a sense of the right hemisphere's ability to read, even if it can't access the motor system to produce speech,\u201d Ivry says. \u201cImaging is very good for telling you where something happens,\u201d he adds, \u201cwhereas patient work can tell you how something happens.\u201d \n               A cable, cut \n             Severing the corpus callosum was first used as a treatment for severe epilepsy in the 1940s, on a group of 26 people in Rochester, New York. The aim was to limit the electrical storm of the seizure to one side of the brain. At first, it didn't seem to work. But in 1962, one patient showed significant improvement. Although the procedure never became a favoured treatment strategy \u2014 it's invasive, risky, and drugs can ease symptoms in many people \u2014 in the decades since it nevertheless became a technique of last resort for treating intractable epilepsy. To Roger Sperry, then a neurobiologist and neuropsychologist at the California Institute of Technology, and Gazzaniga, a graduate student in Sperry's lab, split-brain patients presented a unique opportunity to explore the lateralized nature of the human brain. At the time, opinion on the matter was itself divided. Researchers who studied the first split-brain patients in the 1940s had concluded that the separation didn't noticeably affect thought or behaviour. (Gazzaniga and others suspect that these early sections were incomplete, which might also explain why they didn't help the seizures.) Conversely, studies conducted by Sperry and colleagues in the 1950s revealed greatly altered brain function in animals that had undergone callosal sections. Sperry and Gazzaniga became obsessed with this inconsistency, and saw in the split-brain patients a way to find answers. The duo's first patient was a man known as W. J., a former Second World War paratrooper who had started having seizures after a German soldier clocked him in the head with the butt of a rifle. In 1962, after W.J.'s operation, Gazzaniga ran an experiment in which he asked W.J. to press a button whenever he saw an image. Researchers would then flash images of letters, light bursts and other stimuli to his left or right field of view. Because the left field of view is processed by the right hemisphere and vice versa, flashing images quickly to one side or the other delivers the information solely to the intended hemisphere (see 'Of two minds'). For stimuli delivered to the left hemisphere, W.J. showed no hang-ups; he simply pressed the button and told the scientists what he saw. With the right hemisphere, W.J. said he saw nothing, yet his left hand kept pressing the button every time an image appeared. \u201cThe left and right didn't know what the other was doing,\u201d says Gazzaniga. It was a paradigm-blasting discovery showing that the brain is more divided than anyone had predicted 1 . Suddenly, the race was on to delve into the world of lateralized function. But finding more patients to study proved difficult. Gazzaniga estimates that at least 100 patients, and possibly many more, received a corpus callosotomy. But individuals considered for the operation tend to have other significant developmental or cognitive problems; only a few have super-clean cuts and are neurologically healthy enough to be useful to researchers. For a while, Sperry, Gazzaniga and their colleagues didn't know if there was ever going to be anyone else like W.J.. But after contacting neurosurgeons, partnering with epilepsy centres and assessing many potential patients, they were able to identify a few suitable people in California, then a cluster from the eastern part of the United States, including Vicki. Through the 1970s and the early 1980s, split-brain research expanded, and neuroscientists became particularly interested in the capabilities of the right hemisphere \u2014 the one conventionally believed to be incapable of processing language and producing speech. Gazzaniga can tick through the names of his \u201cendlessly patient patients\u201d with the ease of a proud grandparent doing a roll call of grandchildren \u2014 W.J., A.A., R.Y., L.B., N.G.. For medical confidentiality, they are known in the literature by initials only. (Vicki agreed to be identified in this article, provided that her last name and hometown were not published.) On stage last May, delivering a keynote address at the Society of Neurological Surgeons' annual meeting in Portland, Oregon, Gazzaniga showed a few grainy film clips from a 1976 experiment with patient P.S., who was only 13 or 14 at the time. The scientists wanted to see his response if only his right hemisphere saw written words. In Gazzaniga's video, the boy is asked: who is your favourite girlfriend, with the word girlfriend flashed only to the right hemisphere. As predicted, the boy can't respond verbally. He shrugs and shakes his head, indicating that he doesn't see any word, as had been the case with W.J.. But then he giggles. It's one of those tell-tale teen giggles \u2014 a soundtrack to a blush. His right hemisphere has seen the message, but the verbal left-hemisphere remains unaware. Then, using his left hand, the boy slowly selects three Scrabble tiles from the assortment in front of him. He lines them up to spell L-I-Z: the name, we can safely assume, of the cute girl in his class. \u201cThat told us that he was capable of language comprehension in the right hemisphere,\u201d Gazzaniga later told me. \u201cHe was one of the first confirmation cases that you could get bilateral language \u2014 he could answer queries using language from either side.\u201d The implications of these early observations were \u201chuge\u201d, says Miller. They showed that \u201cthe right hemisphere is experiencing its own aspect of the world that it can no longer express, except through gestures and control of the left hand\u201d. A few years later, the researchers found that Vicki also had a right-hemisphere capacity for speech 2 . Full callosotomy, it turned out, resulted in some universal disconnections, but also affected individuals very differently. In 1981, Sperry was awarded a share of the Nobel Prize in Physiology or Medicine for the split-brain discoveries. (\u201cHe deserved it,\u201d Gazzaniga says.) Sperry died in 1994, but by that point, Gazzaniga was leading the charge. By the turn of the century, he and other split-brain investigators had turned their attention to another mystery: despite the dramatic effects of callosotomy, W.J. and later patients never reported feeling anything less than whole. As Gazzaniga wrote many times: the hemispheres didn't miss each other. Gazzaniga developed what he calls the interpreter theory to explain why people \u2014 including split-brain patients \u2014 have a unified sense of self and mental life 3 . It grew out of tasks in which he asked a split-brain person to explain in words, which uses the left hemisphere, an action that had been directed to and carried out only by the right one. \u201cThe left hemisphere made up a post hoc answer that fit the situation.\u201d In one of Gazzaniga's favourite examples, he flashed the word 'smile' to a patient's right hemisphere and the word 'face' to the left hemisphere, and asked the patient to draw what he'd seen. \u201cHis right hand drew a smiling face,\u201d Gazzaniga recalled. \u201c'Why did you do that?' I asked. He said, 'What do you want, a sad face? Who wants a sad face around?'.\u201d The left-brain interpreter, Gazzaniga says, is what everyone uses to seek explanations for events, triage the barrage of incoming information and construct narratives that help to make sense of the world. The split-brain studies constitute \u201can incredible body of work\u201d, said Robert Breeze, a neurosurgeon at the University of Colorado Hospital in Aurora, after listening to Gazzaniga's lecture last year. But Breeze, like many other neuroscientists, sees split-brain research as outdated. \u201cNow we have technologies that enable us to see these things\u201d \u2014 tools such as functional magnetic resonance imaging (fMRI) that show the whereabouts of brain function in great detail. Miller, however, disagrees. \u201cThese kinds of patients can tell us things that fMRI can never tell us,\u201d he says. \n               Subject of interest \n             Seated at a small, oval dining-room table, Vicki faces a laptop propped up on a stand, and a console with a few large red and green buttons. David Turk, a psychologist at the University of Aberdeen, UK, has flown in for the week to run a series of experiments. Vicki's grey-white hair is pulled back in a ponytail. She wears simple white sneakers and, despite the autumn chill, shorts. She doesn't want to get too warm: when that happens she can get drowsy and lose focus, which can wreck a whole day of research. During a break, Vicki fetches an old photo album. In one picture, taken soon after her surgery, she is sitting up in the hospital bed. Her hair is starting to grow back as black stubble and she and her daughter have wide smiles. Another page of the album has a slightly faded printout of a 1981 paper from  The Journal of Neuroscience  glued into it: the first published report involving data gleaned from Vicki, in which researchers describe how she, like P.S., had some capacity for language in her right hemisphere 4 . When pressed to share the most difficult aspect of her life in science, the perpetually upbeat Vicki says that it would have to be an apparatus called the dual Purkinje eye tracker. This medieval-looking device requires the wearer to bite down on a bar to help keep the head still so that researchers can present an image to just the left or right field of view. It is quite possible that Vicki has spent more of her waking hours biting down on one of those bars than anyone else on the planet. Soon, it is time to get back to work. Turk uses some two-sided tape to affix a pair of three-dimensional glasses onto the front of Vicki's thin, gold-rimmed bifocals. The experiment he is running aims to separate the role of the corpus callosum in visual processing from that of deeper, 'subcortical' connections unaffected by the callosotomy. Focusing on the centre of the screen, Vicki is told to watch as the picture slowly switches between a house and different faces \u2014 and to press the button every time she sees the image change. Adjusting her seat, she looks down the bridge of her nose at the screen and tells Turk that she's ready to begin. \n               Deep connections \n             Other researchers are studying the role of subcortical communication in the coordinated movements of the hands. Split-brain patients have little difficulty with 'bimanual' tasks, and Vicki and at least one other patient are able to drive a car. In 2000, a team led by Liz Franz at the University of Otago in New Zealand asked split-brain patients to carry out both familiar and new bimanual tasks. A patient who was an experienced fisherman, they found, could pantomime tying a fishing line, but not the unfamiliar task of threading a needle. Franz concluded that well-practised bimanual skills are coordinated at the subcortical level, so split-brain people are able to smoothly choreograph both hands 5 . Miller and Gazzaniga have also started to study the right hemisphere's role in moral reasoning. It is the kind of higher-level function for which the left hemisphere was assumed to be king. But in the past few years, imaging studies have shown that the right hemisphere is heavily involved in the processing of others' emotions, intentions and beliefs \u2014 what many scientists have come to understand as the 'theory of mind' 6 . To Miller, the field of enquiry perfectly illustrates the value of split-brain studies because answers can't be found by way of imaging tools alone. In work that began in 2009, the researchers presented two split-brain patients with a series of stories, each of which involved either accidental or intentional harm. The aim was to find out whether the patients felt that someone who intends to poison his boss but fails because he mistakes sugar for rat poison, is on equal moral ground with someone who accidentally kills his boss by mistaking rat poison for sugar 7 . (Most people conclude that the former is more morally reprehensible.) The researchers read the stories aloud, which meant that the input was directed to the left hemisphere, and asked for verbal responses, so that the left hemisphere, guided by the interpreter mechanism, would also create and deliver the response. So could the split-brain patients make a conventional moral judgement using just that side of the brain? No. The patients reasoned that both scenarios were morally equal. The results suggest that both sides of the cortex are necessary for this type of reasoning task. But this finding presents an additional puzzle, because relatives and friends of split-brain patients do not notice unusual reasoning or theory-of-mind deficits. Miller's team speculates that, in everyday life, other reasoning mechanisms may compensate for disconnection effects that are exposed in the lab. It's an idea that he plans to test in the future. As the opportunities for split-brain research dwindle, Gazzaniga is busy trying to digitize the archive of recordings of tests with cohort members, some of which date back more than 50 years. \u201cEach scene is so easy to remember for me, and so moving,\u201d he says. \u201cWe were observing so many astonishing things, and others should have the same opportunity through these videos.\u201d Perhaps, he says, other researchers will even uncover something new. Other split-brain patients may become available \u2014 there is a small cluster in Italy, for instance. But with competition from imaging research and many of the biggest discoveries about the split brain behind him, Gazzaniga admits that the glory days of this field of science are probably gone. \u201cIt is winding down in terms of patients commonly tested.\u201d Still, he adds: \u201cI have a hard time saying it's all over.\u201d And maybe it's not \u2014 as long as there are scientists pushing to tackle new questions about lateralized brain function, connectivity and communication, and as long as Vicki and her fellow cohort members are still around and still willing participants in science. Her involvement over the years, Vicki says, was never really about her. \u201cIt was always about getting information from me that might help others.\u201d\n \n                     Computer modelling: Brain in a box 2012-Feb-22 \n                   \n                     Neuroscience: The connected self 2012-Feb-01 \n                   \n                     Neuroscience vs philosophy: Taking aim at free will 2011-Oct-01 \n                   \n                     Dissecting the right brain 2005-Jul-13 \n                   \n                     Michael Gazzaniga \n                   Reprints and Permissions"},
{"file_id": "483137a", "url": "https://www.nature.com/articles/483137a", "year": 2012, "authors": [], "parsed_as_year": "2006_or_before", "body": "Eighteen hours after a massive earthquake ripped apart the sea floor off the coast of Tohoku, Japan, on 11 March last year, tsunami waves smashed the coast of Antarctica hard enough to knock loose giant icebergs. Over the next few weeks, as an estimated 19,000 people were reported dead or missing in Japan, radioactive isotopes from the crippled Fukushima Daiichi nuclear power plant circled the globe. The earthquake, tsunami and extended nuclear crisis that devastated Japan affected the entire planet and continue to have global repercussions. This week,  Nature  dissects what has been learned about the event over the past year and how those lessons can help societies to prepare for future disasters. Efforts to rebuild the Tohoku coastline have provoked debate about how to best protect Japan from future tsunamis through zoning and physical defences ( page 141 ). Meanwhile, Japan and the United States are upgrading their systems of sensors that forecast these destructive waves ( page 144 ). Seismologist Hiroo Kanamori says that tsunami forecasters should improve their ability to analyse both the magnitude and mechanism of an ongoing earthquake ( page 147 ). And geologist Thorne Lay examines how a spate of giant earthquakes in the past decade has revealed gaps in seismological knowledge ( page 149 ). Researchers are accumulating a vast amount of data on the causes and impacts of the Fukushima disaster \u2014 but some worry that their efforts are being undermined by a public loss of trust in the government and its scientists ( page 138 ). And energy-policy expert Peter Bradford argues that countries should develop sensible policies towards nuclear power, rather than shunning it in a rash reaction to the Fukushima meltdowns ( page 151 ). Scientists have had a key role in helping Japan to recover and gird itself for the next disaster. But even this nation \u2014 one of the most at risk for earthquakes and tsunamis, and so one of the best prepared \u2014 has far to go. Other countries would do well to heed the lessons. \n                     Scientists report back from Fukushima exclusion zone 2012-Feb-24 \n                   \n                     Japan earthquake and Nuclear Crisis \n                   \n                     Japanese government report on Fukushima \n                   \n                     International Tsunami Information Center \n                   \n                     Japanese Meteorological Agency's Tohoku earthquake page \n                   \n                     Tohoku University Disaster Control Research Center \n                   Reprints and Permissions"},
{"file_id": "483390a", "url": "https://www.nature.com/articles/483390a", "year": 2012, "authors": [{"name": "Helen Pearson"}], "parsed_as_year": "2006_or_before", "body": "To dissect evolution, Joe Thornton resurrects proteins that have been extinct for many millions of years. His findings rebut creationists and challenge polluters. Halfway through breakfast, Joe Thornton gets a call from his freezer. A local power cut has triggered an alarm on the \u221280 \u00b0C appliance in his lab at the University of Oregon in Eugene, and it has sent out an automatic call. Thornton breaks off our conversation and calls his senior research scientist, Jamie Bridgham, to make sure that the back-up generator has kicked in. If the freezer starts warming up, a lot could be lost \u2014 not least a valuable collection of proteins that had been extinct for hundreds of millions of years until Thornton and his team brought them back from the dead. One deep-frozen vial holds the more-than-600-million-year-old ancestor of the receptors for oestrogen, cortisol and other hormones, which Thornton brought to life 1  nine years ago. Other tubes house proteins more than 400 million years old, which Thornton resurrected a few years later to show how an ancient receptor had changed its preferences \u2014 and how the march of evolution cannot be reversed 2 , 3 , 4 . In another corner of the freezer rest the ancient protein components of a sophisticated cellular machine that acquired a more complex form through random mutations rather than selection for superior function, as the group showed in  Nature  this January 5 . The sheer awe of working with long-dead proteins doesn't fade, says Thornton. \u201cIt's amazing. The ability to do this type of time travel is fantastic.\u201d Thornton is a leader in a movement to do for proteins what the scientists in  Jurassic Park  did for dinosaurs: bring ancient forms back to life, so that they can be studied in the flesh. \u201cInstead of passively observing things as most evolutionary biologists do, you actively go in and test the hypotheses experimentally,\u201d says Antony Dean, a molecular biologist at the University of Minnesota in St Paul who heads another major group in the field. \u201cHis is one of the leading labs, no doubt.\u201d And Thornton is tackling some important questions, says Kenneth Miller, a molecular biologist at Brown University in Providence, Rhode Island. \u201cHe's helping to put some flesh on the bones of speculation about how complexity arises.\u201d What isn't so widely known is that evolutionary biology is Thornton's second career: in his first, he was an activist for Greenpeace, campaigning vigorously against the release of toxic chemicals. He wrote a controversial book on organochlorines: industrial chemicals that include dioxins, polychlorinated biphenyls (PCBs) and pesticides such as DDT. That activist legacy bleeds into his work today, for example in his focus on the oestrogen receptor, which is corrupted by many pollutants. The grubby, sea-green tiles under Thornton's lab benches were carefully sourced to be free of polyvinyl chloride (PVC), one of the organochlorines that worries him most. His activist past also helps to explain why he has been fearless \u2014 almost enthusiastic \u2014 about highlighting the challenge that his work presents to a creationist argument called intelligent design: the claim that complex molecular systems can only have been created by a divine force. Thornton shows how evolution did the job, leaving no need for a designer. \n               Environment to evolution \n             Thornton says that his activist days \u2014 during which he saw that many risk-assessment models were shot through with assumptions and biases \u2014 left him \u201cintensely committed to methodological reductionism and experimentalism\u201d, which he now uses to break evolution down into detailed steps that he can test. \u201cIf you're doing science, I think it ought to be as strong and decisive as possible,\u201d he says. \u201cIf you're doing politics, go ahead, but don't try to disguise it as science.\u201d Thornton's unconventional career path started with an obsession with  Moby Dick , which led him to study English at Yale University in New Haven, Connecticut. But the course, with its focus on the philosophy of criticism rather than literary texts, left him with a hunger for reality, and nothing seemed more real than politics and activism. He dropped out of college, signed up with Greenpeace and spent several months doorstepping to canvass people for money and support. Helen Pearson talks about Joe Thornton and his protein resurrection lab In the early 1990s, Greenpeace was campaigning against sources of toxic pollution, and Thornton was drawn in. He became the 'science guy', translating the scientific literature into reports and other material that communities and Greenpeace could use to make their case. \u201cYou could rely on Joe when you didn't have enough knowledge of an issue,\u201d says Charlie Cray, a research specialist at Greenpeace in Washington DC, who worked with Thornton. His reports \u201cput a challenge out there that industry couldn't answer\u201d. One campaign that Thornton helped to organize, against plans to build more than 100 hazardous-waste incinerators across the United States, climaxed in May 1993 when Greenpeace parked a truck dressed up as an incinerator outside the White House and some 60 people chained themselves to it. The next day, the Environmental Protection Agency announced a moratorium on new hazardous waste incinerators. But Thornton was growing older, and yearning to \u201cdevelop my own body of work\u201d. His time with Greenpeace had taught him the power of science to influence society, and his ambitions turned to research. First, he had to deal with the small matter of graduating from Yale. Then living in New York, he did that by accruing course credits at Columbia University \u2014 attending his first molecular-biology classes aged 30 \u2014 only to find himself rejected from almost every graduate programme he applied to, in part because of his unusual CV. Of the seven friends and colleagues of Thornton's who spoke to  Nature , six called him intense. The seventh described him as \u201cbeyond intense\u201d. But only a little of that intensity is apparent at his Wednesday morning lab meeting in Eugene. The freezer crisis has blown over: the power came back after half an hour and the thermometer rose to only \u221276 \u00b0C. Now graduate student Dave Anderson gets a friendly grilling during a practice talk outlining his thesis proposal: to trace the evolution of the DNA-binding domain of an ancient hormone receptor. The meeting stretches on for 2.5 hours \u2014 not uncommon in this lab, everyone says. \n               A binding fascination \n             Since his Greenpeace days, Thornton has been fascinated by the steroid hormone receptors: in vertebrates, six proteins that sit in the cell nucleus and control the activity of genes. By binding specific 'ligands' \u2014 hormones ranging from oestrogens and androgens to cortisol \u2014 the receptors trigger \u201cthese remarkable cascades of biological activity during development and physiology\u201d, Thornton says. \u201cTheir affinity for their hormones is just stunning. A drop of hormone in a railroad tank car of serum is enough\u201d \u2014 and yet, as Thornton learned at Greenpeace, they can be waylaid by toxic substances. \u201cI wanted to know where that system came from,\u201d he says. When he was finally accepted for a PhD at Columbia, he set about comparing receptor genes from living organisms to piece together a detailed history of how the receptor family had evolved 6 . Joe Thornton describes how a molecular machine evolved greater complexity Just as Thornton completed his first year of graduate study, however, MIT Press called to ask if he would write a book on organochlorine pollution. He worked in the lab during the day and wrote at night, in a tiny room in his Brooklyn apartment, encircled by towers of papers that eventually formed the nearly 1,200 references and 611 pages of  Pandora's Poison , which came out in 2000. \u201cI was shocked when I saw the book,\u201d says Rob DeSalle, who studies molecular evolution at the American Museum of Natural History in New York, and co-supervised Thornton's PhD. \u201cHe could've been writing  War and Peace  and I wouldn't have known it.\u201d The book caused a stir. Drawing on arguments that he had formulated at Greenpeace, Thornton made the case that regulatory policy should focus on managing classes of toxic chemicals rather than tens of thousands of substances, one by one \u2014 and that the priority should be organochlorines. These substances, generated by the use of chlorine gas in the chemical and paper-making industries, have properties of stability and solubility that make them desirable to industry but problematic to the environment because they are long-lived and accumulate in animal tissues.  Nature 's review called  Pandora's Poison  a \u201clandmark\u201d and another review compared it to Rachel Carson's famous 1962 treatise on pollutants,  Silent Spring . The Chlorine Chemistry Council in Washington DC, however, decried Thornton's \u201chyperbole and faulty risk analysis\u201d. But Thornton was already gearing up to make a different kind of splash, with his first paper in  Science 1 . He and his team trampled the assumption that only vertebrates have steroid hormone receptors by cloning one from the sea slug  Aplysia californica . The finding implied that the origin of the receptor gene was far more ancient than anyone had realized. \u201cI would've hated to be a fellow grad student. He was writing a book and publishing in  Science  and having two children at the same time,\u201d says Darcy Kelley, a biologist at Columbia and Thornton's other PhD co-supervisor. The approach that Thornton took in the 2003 study is one that he has loosely followed ever since. Starting with the genes for steroid hormone receptors from a slew of living organisms, he clambered backwards through the evolutionary tree to deduce the most likely sequence of the common ancestor of all such receptors, which existed some 600 million to 800 million years ago, in the common ancestor of \u201cyou and a snail\u201d, as he puts it. Instead of stopping there, as most evolutionary biologists would have done, he then built the gene and inserted it into cells that could manufacture the ancient protein. Resurrecting the protein, says Thornton, allowed his team \u201cto experimentally test hypotheses about evolution that would otherwise be just speculation\u201d. They went on to show 1  that the ancestral receptor was sensitive to oestrogens but not to related hormones \u2014 supporting the idea that the family of receptors evolved through a series of gene duplications and that the copies gradually evolved affinities for other ligands (see 'Receptors, resurrected'). By the time his paper came out in  Science , Thornton had taken a faculty position in Eugene, an old hippy town that pays as much homage to bicycles as it does to cars. He built a house (no PVC, sustainable bamboo floors) and set to work building up his protein-resurrection lab. Thornton wanted to delve deeper into the puzzle of how complex systems with tightly interacting molecular parts evolve. It was a long-standing conundrum. As Charles Darwin wrote in  On the Origin of Species : \u201cIf it could be demonstrated that any complex organ existed which could not possibly have been formed by numerous, successive, slight modifications, my theory would absolutely break down.\u201d And what was an evolutionary puzzle to biologists was a target for evolution's critics. Michael Behe, a biochemist at Lehigh University in Bethlehem, Pennsylvania, and a senior fellow at the Discovery Institute in Seattle, Washington, proposed in the 1990s that such systems \u2014 the blood-clotting cascade, for example, or the molecular motor called the flagellum \u2014 are so \u201cirreducibly complex\u201d that they could not have evolved step by step, and can only be the product of intelligent design. Thornton says that he didn't set out to refute intelligent design, but the prospect of a fight hardly put him off. \u201cBeen there, enjoyed that,\u201d he says. He chose to explore a pair of steroid hormone receptors: the mineralocorticoid receptor (MR), which binds the hormone aldosterone and regulates salt and water balance; and the closely related glucocorticoid receptor (GR), which binds cortisol and controls stress response. A gene duplication more than 450 million years ago produced the two receptors \u2014 but aldosterone didn't arise until many millions of years later. The timing seemed to make the MR a textbook example of irreducible complexity: how could selection drive the evolution of a lock (the MR) to fit a key (aldosterone) that didn't yet exist? \n               Evolution at work \n             Led by Bridgham, Thornton's team found the answer by resurrecting the ancestor of both receptors. To their surprise, it was sensitive to aldosterone, suggesting that it had been activated by an ancient ligand with a similar structure 2 . Once aldosterone had evolved, the team proposed, evolution was able to take advantage of the existing receptor to control a new biological function \u2014 a process that Thornton termed molecular exploitation. They also showed how its sister receptor, the GR, was evolving functions of its own. \u201cSuch studies solidly refute all parts of the intelligent design argument,\u201d wrote Christoph Adami, an evolutionary biologist at the Keck Graduate Institute of Applied Life Sciences in Claremont, California, in an article entitled 'Reducible complexity' 7 . But Behe dismissed the result. The receptor and ligand are not irreducibly complex, he says, and evolution did not give them any truly new function. \u201cI think his results are quite consistent with my own view that Darwinian processes are poor ones to explain the complexity found in life,\u201d Behe told  Nature . Thornton turned up more clues to the workings of evolution when his team explored the history of the GR, which became sensitive only to cortisol over the course of about 20 million years. Working with structural biologists at the University of North Carolina, Chapel Hill, the group determined the crystal structure of the common ancestor of the GR and MR. They showed 3  that two crucial mutations together altered the binding pocket of the ancestral receptor so that it preferred to bind cortisol \u2014 and identified another five mutations that finished the job. In a final chapter to the story, Thornton tried to run that evolutionary sequence backwards. But when the researchers reversed the seven mutations in the ancient cortisol-specific form, they could not transform it back into a protein that worked like the common ancestor of the GR and MR. They instead engineered a dud, unable to respond to any hormone 4 . That was because a handful of other mutations had also cropped up on the way to making a cortisol-specific receptor. They played little part in the receptor's new function, but acted as an evolutionary ratchet, preventing it from regaining its old one. Thornton showed that it was necessary to undo those mutations too, to reverse the change. To him, the work was a powerful demonstration that the path of evolution can be contingent on random events. \u201cChance plays a very large role in determining what evolutionary outcomes are possible,\u201d he says. The study captivated the scientific press \u2014 and beyond. \u201cEvolution opens gateways into the future. But it appears to close them \u2014 firmly \u2014 behind it as well,\u201d read an editorial in the  New York Times . In the Nature article that was published this year 5 , Thornton took a break from hormone receptors, and instead collaborated with Tom Stevens, a geneticist at Eugene, to dissect the evolution of V-ATPase, a molecular machine that pumps protons across membranes to acidify compartments inside cells. The group wanted to know how an essential part of the machine \u2014 a ring of proteins that spans cell membranes \u2014 evolved from an ancestral form with two components to one with three. With their protein-resurrection toolbox, the researchers showed that, around 800 million years ago, the ancestral gene coding for one protein component was duplicated, and the daughter genes then picked up two vital mutations. The changes meant that the proteins could no longer sit anywhere in the ring, but instead had to occupy a specific spot. Suddenly, the ring could function only with all three parts. What surprised Thornton was that the three-component ring seemed to work no better than its two-component counterpart. Random mutations that actually corrupted proteins had led to 'irreducible complexity'. \n               Computing complexity \n             The study flipped another finger to intelligent-design proponents \u2014 but \u201cI'm sort of bored with them\u201d, Thornton says. He is more excited by the next scientific story that is about to come out of the lab. His group wanted to explore how the ancestor of the entire steroid hormone receptor family, which was sensitive only to oestrogens, evolved into forms sensitive to other hormones. And this time, he found no clues in the crystal structures of resurrected proteins from before and after the change. The answer can be found on a computer screen at the end of Thornton's lab. Mike Harms, a postdoc who joined the lab three years ago, used his expertise in biophysics and some immense computational power to simulate the movements of every atom in the ancestral receptors, showing how just two mutations drove the transformation. When Harms hits play, an oestrogen molecule snuggles its way into the binding pocket of a receptor roughly 550 million years old. But when he runs a simulation of the same receptor with those two mutations, the oestrogen never finds a comfortable spot. This evolutionary story also sheds light on why the oestrogen receptor is now vulnerable to the threats against which Thornton campaigned in his former life. The team worked out that each steroid receptor evolved to be only as specific as it had to be to bind its target ligand and exclude all others that existed at the time. The oestrogen receptor achieves this by binding substances that contain a chemical structure called an aromatized A ring. Because oestrogens are the only steroid hormones to have such a ring, that criterion was enough to ensure that the receptor bound only oestrogens for many millions of years. Until, that is, the chemical industry started pumping out hundreds of substances containing such aromatized rings, which the oestrogen receptor unwittingly bound. \u201cThe endocrine disrupters are taking advantage, unfortunately, of the promiscuity that is the result of the evolutionary history of receptors,\u201d Thornton says. Thornton does see progress on the issues on which he once campaigned. Production of toxic chemicals in the United States has fallen since his days with Greenpeace, and in 2007 the European Union enacted REACH (Registration, Evaluation, Authorisation and Restriction of Chemicals), which emphasizes elimination of the most dangerous substances. That law puts the onus on the chemical industry to show that a chemical is safe rather than on regulators to prove it is dangerous \u2014 the approach for which Thornton argued in  Pandora's Poison . Does he miss having something to campaign against? Yes and no. \u201cI'm less able to convince myself that the world has to be exactly as I envision it. So it's harder for me to occupy that activist persona.\u201d Besides, he says, \u201cMy kids take all that energy now.\u201d Or almost. His creations need tending too. Back in his office, we listen to the tinny voicemail message left by the freezer on his phone earlier that day. \u201cThe past is calling,\u201d Thornton says. \n                     Data gaps threaten chemical safety law 2011-Jul-12 \n                   \n                     Evolution: Revenge of the hopeful monster 2010-Feb-17 \n                   \n                     Biological theory: Postmodern evolution? 2008-Sep-17 \n                   \n                     The scientist delusion 2008-Mar-05 \n                   \n                     Creationists launch 'science' journal 2008-Jan-23 \n                   \n                     Evolution wins Pennsylvania trial 2005-Dec-21 \n                   \n                     Darwin at 200 news special \n                   \n                     Blogpost: Resurrecting extinct proteins shows how a machine evolves \n                   \n                     Joe Thornton \n                   Reprints and Permissions"},
{"file_id": "481426a", "url": "https://www.nature.com/articles/481426a", "year": 2012, "authors": [{"name": "Jo Marchant"}], "parsed_as_year": "2006_or_before", "body": "Armed with high-tech methods, researchers are scouring the Aegean Sea for the world's oldest shipwrecks. Brendan Foley peels his wetsuit to the waist and perches on the side of an inflatable boat as it skims across the sea just north of the island of Crete. At his feet are the dripping remains of a vase that moments earlier had been resting on the sea floor, its home for more than a millennium. \u201cIt's our best day so far,\u201d he says of his dive that morning. \u201cWe've discovered two ancient shipwrecks.\u201d Foley, a marine archaeologist at the Woods Hole Oceanographic Institution in Massachusetts, and his colleagues at Greece's Ephorate of Underwater Antiquities in Athens have spent the day diving near the cliffs of the tiny island of Dia in the eastern Mediterranean. They have identified two clusters of pottery dating from the first century  BC  and fifth century  AD . Together with other remains that the team has discovered on the island's submerged slopes, the pots reveal that for centuries Greek, Roman and Byzantine traders used Dia as a refuge during storms, when they couldn't safely reach Crete. It is a nice archaeological discovery, but Foley was hoping for something much older. His four-week survey of the waters around Crete last October is part of a long-term effort to catalogue large numbers of ancient shipwrecks in the Aegean Sea. And the grand prize would be a wreck from one of the most influential and enigmatic cultures of the ancient world \u2014 the Minoans, who ruled these seas more than 3,000 years ago. Some researchers believe that quest to be close to impossible. But Foley and a few competitors are using high-tech approaches such as autonomous robots and new search strategies that they say have a good chance of locating the most ancient of shipwrecks. If they succeed, they could transform archaeologists' understanding of a crucial period in human history, when ancient mariners first ventured long distances across the sea. Archaeologists have precious little information about the seagoing habits of the Minoan civilization, which erected the palace of Knossos on Crete \u2014 linked to the Greek myth of the Minotaur. Minoans far exceeded their neighbours in weaponry, literacy and art, and formed \u201cpart of the roots of what went on to become European civilization\u201d, says Don Evely, an archaeologist at the British School at Athens, and curator of Knossos. Archaeologists are keen to understand what made the Minoans so successful and how they interacted with nearby cultures such as the Egyptians. Although researchers have studied scores of Roman ships, finding a much older Minoan wreck \u201cwould add 100% new knowledge\u201d, says Shelley Wachsmann, an expert in ancient seafaring at Texas A&M University in College Station. \n               Underwater treasure \n             A Bronze Age wreck called Ulu Burun shows how the remains of a single ship can transform archaeologists' understanding of an era. Discovered in 1982, it lies about 9 kilometres southeast of Ka\u015f in southern Turkey, and dates from around 1300  BC , a century or two after the Minoans disappeared. Christos Agourides, secretary-general of the Hellenic Institute of Marine Archaeology in Athens, describes it as \u201cthe dream of every marine archaeologist\u201d. It took ten years to excavate, and researchers are still studying the nearly 17 tonnes of treasures recovered. The vast cargo includes ebony, ivory, ostrich eggs, resin, spices, weapons, jewellery and textiles as well as ingots of copper, tin and glass. But what really stunned archaeologists was that the artefacts on this one vessel came from at least 11 different cultures 1  \u2014 from a gold scarab bearing the name of the Egyptian queen Nefertiti to copper from Cyprus and tin from central Asia. The wreck provided tangible evidence of an astonishing array of contacts and trade between the different cultures of the Mediterranean and Near East in the late Bronze Age. The Ulu Burun ship sailed at around the time that Tutankhamun ruled Egypt, and \u201cit is far more important than Tutankhamun's tomb as a contribution to our understanding of the period\u201d, according to Wachsmann. \u201cThis goes to the nitty gritty of the world. It's Wall Street in a ship.\u201d The earlier Minoans set the stage for such a widespread trading network through their domination of the eastern Mediterranean. Their seafaring abilities were still celebrated 1,000 years later by Greek historian Thucydides, who credited the Minoans with building the world's first navy and ridding the seas of pirates. Although other contemporary Mediterranean cultures were starting to travel across the sea, the Minoans ventured farther than others, reaching distant ports in Syria, Cyprus, the Cyclades and Egypt (see map). Wachsmann describes them as the \u201cChristopher Columbuses of the Bronze Age\u201d. Researchers have already found one potential Minoan wreck site by the island of Pseira, off the northeast coast of Crete. In 2003, archaeologist Elpida Hatzidaki of the Ephorate of Underwater Antiquities discovered a large collection of underwater pottery dating to around 1800  BC . But at this site and a few even older ones, no portion of the ship itself survives, and it is hard to determine whether the pottery came from a wreck, was simply thrown overboard, or washed into the sea from the nearby coast. Even those who believe the Pseira site does represent a Minoan wreck admit that the pottery itself \u2014 everyday ware of local origin \u2014 doesn't reveal much new information. What archaeologists crave is an equivalent of Ulu Burun, a long-distance trading ship packed with valuable cargo that would reveal how different cultures interacted. \u201cShips were the way that people communicated and moved about the ancient world,\u201d says Foley. \u201cSo if we can find these ancient wrecks, we get a much clearer view of the very dim past.\u201d That dream lured Foley and his team to Crete last year, and they brought a new tool that they hope will significantly raise the chances of finding an ancient shipwreck. In the past, archaeologists have explored the sea floor using divers and, more recently, remotely operated vehicles (ROVs) that are controlled by pilots on ship. Foley's team tested an autonomous diving robot that could search the ocean bottom for hours under its own command. The REMUS 100 vehicle (for Remote Environmental Monitoring Underwater System) is equipped with Global Positioning System technology, side-scan sonar and a video camera. The Woods Hole researchers worked on the project with Greek archaeologists led by Theotokis Theodoulou of the Ephorate of Underwater Antiquities. \n               Robot rovers \n             The torpedo-shaped robot, nicknamed Gudgeon after a Second World War submarine, spent the first month of the field campaign surveying the entire sea floor north of Crete's main harbour, Heraklion, for any lumps and bumps that might signal an ancient wreck. Foley had high hopes for the area because it had been a port for millennia and had never been surveyed by archaeologists. But the search came up empty handed. Close to shore, there was no hope of finding ancient wrecks because the sea floor was covered in a thick pile of sediments that had washed off the island. Farther out, the researchers found furrows left by trawl fishermen, who had scraped the sea floor clean, even in areas where trawling is supposedly forbidden. So Foley's team moved its search to Dia, which lies just north of Heraklion. In 1976, the ocean explorer Jacques Cousteau found some ancient remains there, and Foley suspected that Dia might be a fertile site for shipwrecks because its steep cliffs could be lethal to vessels caught in a storm. The team took a two-pronged approach to exploring around Dia. The Gudgeon crew prowled Dia's bays, where the ocean bottom is smooth and artefacts are more likely to show up in sonar images. Near shore, where the bottom is too rocky for Gudgeon, Foley and his team of divers made a circuit of the bays at about 40 metres depth. Almost immediately, the divers located five ancient wrecks, ranging from around the second century  BC  to the ninth century  AD . The discoveries confirmed Cousteau's impression that now-deserted Dia was used for centuries as an anchorage. And Foley was convinced that the Minoans must have been here too, with the evidence perhaps on the deeper floor of Dia's bays. But Gudgeon's sonar images from those sites kept coming back disappointingly clear. On the penultimate day of the field season, Greg Packard and Mark Dennett of Woods Hole stood on the stern of their small research vessel, and swung Gudgeon overboard. The miniature explorer descended to the bottom and spent the morning cruising back and forth along preprogrammed gridlines. Later that evening, when Packard examined the sonar data, he spied a potential target \u2014 a patch of bright speckles amid the smooth dark image. The team debated whether it could be a heap of pottery on the sand. The next day, Foley took his crew of divers out to the suspect site. Some 15 minutes later, they came back with disheartening news: the sonar signal was a collection of plastic water bottles that must have been dumped overboard from a modern boat. And footage from Gudgeon's video camera explained the absence of archaeological remains \u2014 furrows in the sand showed that trawlers had cleaned out even these tiny bays. If a Minoan ship ever sank here, it has long since been destroyed. \u201cIt's such a waste,\u201d says Foley, clearly disappointed. \u201cI bet they're not even trawling for fish. I bet they're trawling for antiquities.\u201d \n               Diving deeper \n             Wachsmann says that he isn't surprised by what Foley saw. From 2007 to 2009, he led the Danaos project, using sonar-equipped ROVs to survey hundreds of square kilometres of sea floor on a suspected ancient trading route between Crete and Egypt. In three seasons, he didn't find a single ancient wreck from any period, and only a scattering of artefacts. Wachsmann found that sedimentation was a problem even far from shore \u2014 up to a metre per millennium in some areas. This means that although some Greek and Roman remains might still be visible, a Minoan ship would be buried under 3 or 4 metres of sand. And even at 500\u2013600 metres depth, he saw clear evidence of trawling. \u201cIt was almost like somebody had swept the sea in front of me,\u201d he says. On the basis of his experiences, Wachsmann now believes that the chance of finding a Minoan equivalent of Ulu Burun \u201capproaches zero\u201d. The effect of bottom trawling is \u201cdevastating\u201d for archaeologists, agrees Robert Ballard, an oceanographer based at the University of Rhode Island in Narragansett, who has pioneered deep-sea exploration and discovered the wreck of the  Titanic  in 1985. \u201cMost of the Aegean has been destroyed,\u201d he says. Ballard has spent years searching for ancient wrecks and says that he has learned the importance of finding areas beyond the reach of fishermen \u2014 below about 600 metres, say, or close to undersea cables, which trawlers avoid. He has also opened up his search area. Historians once assumed that the number of wrecks in the deep sea was negligible because ancient ships must have hugged the coastlines, but in the 1990s Ballard found eight ancient wrecks far from shore between the islands of Sicily and Sardinia 2  (Foley was Ballard's graduate student at the time). \u201cThe ancient mariner was not afraid of going out to sea,\u201d says Ballard. Since 2008, Ballard has been exploring the eastern Mediterranean, the Aegean and the Black Sea with a suite of ROVs. Although he is finding large numbers of ancient wrecks, he hasn't yet uncovered anything from the Bronze Age. But, like Foley, he believes Minoan ships are waiting to be discovered. The key to finding the oldest wrecks, he says, is locating \u201crelic surfaces\u201d that have escaped being buried by sediment, which flows downhill and covers the deep sea floor 3 . \u201cWhat you want is a shipwreck that came down on a mountain,\u201d he says, because sediment can't accumulate on a steep slope. Last year, Ballard investigated the Eratosthenes seamount, a 700-metre-deep tabletop south of Cyprus, and says it does indeed seem to represent a relic surface. He is now applying for permits to return to Eratosthenes to search for shipwrecks next year. Another area he would like to investigate is the submerged Anaximander mountains south of Turkey. It would be difficult to distinguish a wreck site from such rocky terrain using sonar, so he plans to use video cameras to conduct a painstaking visual search over smaller areas. \u201cIt's very hard hunting,\u201d he says. Foley is also now looking to the deep sea, but has a different strategy. Instead of targeting particular sweet spots, he wants to cover as large an area as possible. He has raised more than US$1 million towards the $1.8 million that he needs to return to the Mediterranean next year, this time with two of Gudgeon's more powerful cousins, REMUS 6000s owned by the Waitt Institute in La Jolla, California. To maximize the chances of finding ancient wrecks, the team will hunt on open, flat areas in the lowest reaches of the sea, up to 6,000 metres deep. Foley estimates that the two REMUS vehicles can cover up to 5,000 square kilometres in one month, equivalent to 1% of the entire Aegean Sea. The recent field trial around Dia encouraged Foley because it should be easier for the sonar surveys to pick out vases than it was to find plastic water bottles, which are poor sonar reflectors, he says. Both Ballard and Foley are ultimately hoping to use their surveys to catalogue large numbers of wrecks of all ages across great swathes of the Mediterranean and the Black Sea. Through a combination of sonar and high-resolution digital photography, they can compile detailed three-dimensional maps of a wreck site and answer questions about the date, origin and cargo of a ship without bringing up a single artefact. Foley estimates that hundreds of thousands of ships must have sunk in ancient times \u2014 including thousands in the Bronze Age alone \u2014 and that a significant proportion of those are still sitting at the bottom of the deep sea. If he's right, then perhaps researchers will eventually have not just one Minoan ship, but hundreds. With enough wrecks, says Foley, \u201cit ought to allow us to draw new conclusions about this absolutely formative period in human experience.\u201d That could shift marine archaeologists into an era in which they can use statistical data gathered from hundreds or thousands of wrecks to build up a bigger picture of trade routes, migration and warfare throughout history. \u201cWe'd rather find 500 ships than excavate one,\u201d says Ballard. Such a dream seems a long way off as Foley's team packs up its gear at the end of its campaign. Packard and Dennett carefully lower Gudgeon into a crate for its long trip back to Woods Hole, while Foley eyes one of the artefacts he retrieved from Dia's waters \u2014 a bulbous Byzantine amphora covered in deposits left by worms. It's not the find Foley hoped for, but he is undaunted \u2014 this is just the beginning of what he knows could be a long search. \u201cI'd like to be doing this every year for the next 20 or 30 years,\u201d he says. \u201cUntil I'm too old to go to sea.\u201d \n                     Ancient Greek ships carried more than just wine 2011-Oct-14 \n                   \n                     Did Vikings navigate by polarized light? 2011-Jan-28 \n                   \n                     What makes a 300-year-old pocket watch tick? 2010-Oct-11 \n                   \n                     Trading Bronze Age technology 2008-Dec-10 \n                   \n                     In search of lost time 2006-Nov-29 \n                   \n                     REMUS 100 \n                   \n                     REMUS 6000 \n                   \n                     Danaos project \n                   \n                     Nautilus Live \n                   \n                     Waitt Institute \n                   Reprints and Permissions"},
{"file_id": "483394a", "url": "https://www.nature.com/articles/483394a", "year": 2012, "authors": [{"name": "Jon Bardin"}], "parsed_as_year": "2006_or_before", "body": "Is a project to map the brain\u2019s full communications network worth the money? A building that once housed a Second World War torpedo factory seems an unlikely location for a project aiming to map the human brain. But the Martinos Center for Biomedical Imaging \u2014 an outpost of the Massachusetts General Hospital in an industrialized stretch of Boston's riverfront \u2014 is home to an impressive collection of magnetic resonance imaging machines. In January, I slid into the newest of these, head first. The operator ran a few test sequences to see whether I experienced any side effects from the unusually rapid changes in this machine's magnetic field. And, when I didn't \u2014 no involuntary muscle twitches or illusory flashes of light in my peripheral vision \u2014 we began. The machine hummed, then started to vibrate. For 90 minutes, I held still as it scanned my brain. That scan would be one of the first carried out by the Human Connectome Project (HCP), a five-year, US$40-million initiative funded by the National Institutes of Health (NIH) in Bethesda, Maryland, to map the brain's long-distance communications network. The network, dubbed the 'connectome', is a web of nerve-fibre bundles that criss-cross the brain in their thousands and form the bulk of the brain's white matter. It relays signals between specialized regions devoted to functions such as sight, hearing, motion and memory, and ties them together into a system that perceives, decides and acts as a unified whole. The connectome is bewilderingly complex and poorly understood. The HCP proposes to resolve this by using new-generation magnetic resonance imaging (MRI) machines, like that used to scan my brain, to trace the connectomes of more than 1,000 individuals. The hope is that this survey will establish a baseline for what is normal, shed light on what the variations might mean for qualities such as intelligence or sociability, and possibly reveal what happens if the network goes awry. \u201cWe increasingly believe that brain disorders \u2014 from schizophrenia to depression to post-traumatic stress disorder \u2014 are disorders of connectivity,\u201d says Thomas Insel, director of the National Institute of Mental Health (NIMH) in Bethesda and a strong supporter of the HCP. \u201cSo it is of vital importance that we have ways of detecting and quantifying these connections.\u201d Yet many wonder whether the NIH is making a mistake. Researchers have yet to prove that MRI techniques can produce a reliable picture of normal connectivity, never mind the types of abnormal connection likely to be found in brain disorders, and some researchers argue that the techniques have not been adequately validated. \u201cI would do the basic neuroscience before I started running lots of people through MRI scanners,\u201d says David Kleinfeld, a physics and neurobiology researcher at the University of California, San Diego. \n               The grand challenge \n             Proponents counter that the HCP is a calculated risk. \u201cNo one thinks this is going to produce a wiring diagram like you might have for the electricity in your house,\u201d says Insel. But so little is known about the connectome, he says, that even crude maps would represent a major scientific advance. The decision to take that risk was made by the NIH's Blueprint for Neuroscience Research, set up in 2004 as a collaboration among the 15 NIH institutes, centres and offices with an interest in nervous-system research. In 2009, after five years of funding smaller projects, the group asked officials from across the NIH to submit ideas for 'grand challenges' in neuroscience: large-scale programmes that, Insel says, \u201cwould be both extremely high-impact, and virtually impossible with traditional grant mechanisms\u201d. The Blueprint group received a dozen submissions, including one from Michael Huerta, then a programme officer at the NIMH and a member of a Blueprint subcommittee. Huerta, now at the NIH's National Library of Medicine, began his research career studying the organization of mammalian brains using old-school anatomical and neural-tracing techniques, which typically require the injection of a tracer compound that migrates along nerve fibres and reveals their routes. So he was all too familiar with the barriers to such studies in humans. For ethical reasons, tracers can only be used post-mortem \u2014 when they don't migrate far enough to trace a fibre's full length. \u201cThe studies just never panned out,\u201d says Huerta. Nature\u2019s Kerri Smith discusses the Human Connectome Project at its launch In 2007, Huerta became fascinated by two new non-invasive imaging methods that might finally allow researchers to study the finer details of connectivity in the brains of living humans. The first was diffusion-spectrum imaging (DSI), developed in 2005 by Van Wedeen, a radiologist at the Martinos Center, and his colleagues 1 . DSI is a refinement of the two-decades-old diffusion tensor imaging technique, which exploits MRI's ability to detect the direction in which water molecules are moving at each point in the brain. Because most of those molecules move along the lengths of nerve fibres, like water through a pipe, the data can be used to reconstruct each fibre's location and trajectory. What DSI adds is a more sophisticated form of signal analysis that allows researchers to continue tracing fibre bundles even when one seems to pass behind another, a situation that posed serious problems for the older technique. The second method that caught Huerta's attention was resting-state functional MRI (rs-fMRI), in which people think about nothing in particular while their brain activity is measured. This is quite different from conventional functional-imaging studies, in which participants are asked to carry out a specific cognitive task and researchers look for the brain regions that are activated in the process. In rs-fMRI, there is no task, and researchers look for correlations among the activity levels in different areas. The presumption is that any two regions with a consistently high correlation are linked \u2014 perhaps by an actual bundle of nerve fibres, but certainly by working together in some way. The application of both DSI and rs-fMRI had already led to a number of high-profile publications. But Huerta realized that few groups were applying both methods in the same subjects, and most studies used small samples, limiting their generalizability. So he proposed that the Blueprint group fund a Human Connectome Project that would apply both methods to hundreds of people. This would allow the first large-scale comparison to be made between structural connectivity, as determined by DSI, and functional connectivity, as determined by rs-fMRI. \u201cNo single neuroimaging approach would give you the type of gold-standard connectivity data you need,\u201d says Huerta, recalling his argument for the dual data sets. The Blueprint group was intrigued, but was not blind to the problems inherent in these techniques. One obvious issue is DSI's spatial resolution: each fibre bundle in the image contains thousands of neurons, meaning that it would miss a great deal of structure on smaller scales. Partha Mitra, a neuroscientist at Cold Spring Harbor Laboratory in New York, illustrated the problem to me by displaying a series of high-resolution digital pictures of mouse brain slices, each of which had some of its neurons coloured with a dark brown dye. On one such slice, he showed neurons that originated in the left cortex, then branched out and sent fibres to areas on both the left and the right side of the brain. \u201cThe brain is not made up of point-to-point connections,\u201d he said. \u201cIt's made up of trees.\u201d This level of connectome structure is invisible to even the most advanced diffusion-imaging methods, says Mitra, who heads the Mouse Brain Architecture Project, a parallel version of the HCP, funded by the NIH and the W. M. Keck Foundation of Los Angeles, that seeks to generate a whole-brain wiring diagram for the mouse using staining techniques. And the problem is made even worse when the data are converted into a 'connectivity matrix', which seeks to quantify how much every point in the brain is connected to every other point \u2014 but can't tell the difference between, say, two separate fibres and one fibre with two branches. The Blueprint group was also aware of concerns about resting-state scans. As with the more familiar form of fMRI, what is actually measured isn't neural activity itself, but blood flow. The general presumption is that the two quantities are closely related \u2014 that blood flow increases in a region of the brain whenever the neurons there are active and need to be supplied with more oxygen. But recently, Kleinfeld points out, several studies have called that assumption into question, showing that some increases in blood flow in the brain occur without an increase in neuronal activity 2 . \u201cThere is no simple one-to-one relationship,\u201d he says. \n               A remaining concern \n             That makes rs-fMRI studies particularly hard to interpret, Kleinfeld adds, if only because the brain's resting-state activity may fluctuate on the same timescales that its blood vessels do. A recent review 3  of rs-fMRI admits that this vascular fluctuation \u201cremains a concern\u201d. Other studies show that even something as simple as a subject's pattern of breathing 4  or slight movements of the head 5  can significantly confound rs-fMRI measurements. Even leaving the technical challenges aside, there was no assurance that collecting the connectomes of hundreds of individuals would lead to interesting generalizations. \u201cYou could certainly imagine situations in which everyone's wiring diagrams are quite different,\u201d says Gregory Farber, the programme officer at the NIMH who manages the connectome project. Nonetheless, the Blueprint group was swayed by the argument that imperfect data are better than no data. \u201cThe committee asked, 'Will we have better methods in five years?',\u201d recalls Huerta. \u201cI'm sure we would. But if we followed that rule, no science would ever get done.\u201d The group also liked the fact that the findings would be broadly applicable to clinical, as well as scientific, questions. \u201cWe thought we could do something like what we did with the Human Genome Project,\u201d Insel says, \u201cbecause once you have that map of the brain you can compare it to similar maps across development, or to maps of subjects with different disorders of brain circuitry.\u201d \n               A blueprint for the brain \n             In July 2009, the Blueprint group announced its choice of the HCP as one of three grand challenges \u2014 the other two focused on pain and on drugs for nervous-system disorders \u2014 and simultaneously put out a request for proposals. On 15 September 2010, the NIH announced that it would be funding two HCP proposals. The larger of the two is a 5-year, $30-million effort led by David Van Essen, a neurobiologist at Washington University in St Louis, Missouri, and Kamil Ugurbil, an fMRI pioneer at the University of Minnesota in Minneapolis. (Another collaborator is Olaf Sporns, a neuroscientist at Indiana University in Bloomington, a co-author on the 2005 review article that coined the term 'connectome' 6 .) During phase one, now nearing completion in Minneapolis, this team has developed a scanner that will be able to double the resolution of standard MRI. Once complete, that scanner will be moved to Washington University, where it will immediately begin high-throughput scanning. The plan is to use both DSI and rs-fMRI (see 'Scanning the connectome') to study 1,200 people: 300 identical twins, 300 non-identical twins and 600 non-twin siblings. This will allow researchers to explore how much of the brain's connectivity is mapped out by genes. Volunteers will also complete behavioural tests and other fMRI, magnetoencephalogram and electroencephalogram protocols, so that brain structure can be further correlated with function. All these data will be made public, allowing unaffiliated researchers to answer their own questions, and Van Essen's group plans to release a set of new data-analysis tools. Connectomics, Van Essen says, \u201chas been a cottage industry. But we expect this project to allow for a much richer, more unified approach\u201d. The smaller HCP project \u2014 a 3-year, $8.5-million effort led by Bruce Rosen, a radiologist at the Massachusetts General Hospital, and Arthur Toga, a neurologist at the University of California, Los Angeles \u2014 involved building a new fMRI scanner optimized for the collection of fibre-tracking data. The idea was to massively increase the gradient strength of the machine \u2014 a measure of how rapidly the MRI's magnetic field varies from point to point in the brain. A more intense gradient is like \u201ca bigger mirror in a telescope\u201d, says Wedeen, who is director of connectomics at the Martinos Center. It simultaneously makes the instrument more sensitive to faint signals, and gives it a higher resolution. The machine has now been built \u2014 it is the one that collected images of my brain in January \u2014 but will require much more tweaking and testing before it is optimized for routine use. But the researchers have already achieved a tenfold increase in sensitivity to the water-diffusion signal, allowing their scanner to trace connections much more precisely than the best off-the-shelf machines. In a press release announcing the launch of the HCP in July 2009, Insel said that the project would \u201cmap the wiring diagram of the entire, living human brain\u201d and that this map could be linked to \u201cthe full spectrum of brain function in health and disease\u201d. Such lofty ambitions may or may not succeed in five years. But the project still has its place, says Sebastian Seung, a computational neuroscientist at the Massachusetts Institute of Technology in Cambridge, who studies brain connectivity at the cellular level. \u201cI think it is a mistake to think we have to look at every cell in every region of the brain to make scientific progress,\u201d says Seung, who is not involved in the HCP. But he also emphasizes that the HCP's connectivity map will be, at best, a beginning. \u201cThat is just going to tell us where to look,\u201d he says. \u201cThen we need to study actual cells to learn more\u201d, to figure out how the brain's networks actually transmit information. A week after my visit to the Martinos Center, I received my DSI data. Using free software from the centre, it is easy to explore the architecture of my brain. I can clearly see my hippocampus, and the vast array of fibres projecting from the midbrain sensory hubs up to my cerebral cortex. I am overwhelmed by the visible detail and obvious organization. At present, it is just a pretty picture \u2014 a novelty to show friends. But, I wonder: once scientists know what 'average' looks like, and once they understand the variations, what, if anything, will this rainbow-coloured highway map of my brain say about me? \n                     Diagnosis by default 2012-Mar-06 \n                   \n                     Neuroscience: The connected self 2012-Feb-01 \n                   \n                     Neuroscience: Towards functional connectomics 2011-Mar-09 \n                   \n                     A critical look at connectomics 2010-Nov-23 \n                   \n                     Cash boost for mapping the human brain 2009-Jul-22 \n                   \n                     Human Connectome Project \n                   Reprints and Permissions"},
{"file_id": "483525a", "url": "https://www.nature.com/articles/483525a", "year": 2012, "authors": [{"name": "Natasha Gilbert"}], "parsed_as_year": "2006_or_before", "body": "The key to tackling hunger in Africa is enriching its soil. The big debate is about how to do it. Eneless Beyadi appears through a forest of maize clutching an armful of vegetables and flashing a broad smile. Beyadi cultivates about half a hectare of plots in the village of Nankhunda, high on the Zomba plateau in southern Malawi. She gets up at 4 a.m. every day to tend her gardens, as she lovingly calls them, before heading off to teach at a school. In the afternoon, she returns to the gardens, which help to feed her family of six. As testimony to her efforts, the maize (corn) on Beyadi's land stands tall even in the lashing rain, whereas the stunted, yellowed stalks on a neighbour's plot bow low. The strength of Beyadi's crop is down to more than her green fingers, though. It is also due to what she feeds the soil. Beyadi borrowed money from a European friend to purchase two 50-kilogram bags of chemical fertilizer for this growing season. Because a bag can cost up to 4,000 Malawian kwachas (US$24), it is beyond the reach of many Malawians, including Beyadi's neighbour, Catharine Changuya, an unmarried mother of four. Fertilizers make such a profound difference here because the rusty red soil, as in many parts of Africa, is deficient in organic matter and in key nutrients such as nitrogen and phosphorus. By farming intensively without replenishing soil nutrients, farmers across sub-Saharan Africa have lost an average of 22 kilograms of nitrogen, 2.5 kilograms of phosphorus, and 15 kilograms of potassium per hectare annually over the past 30 years \u2014 the yearly equivalent of US$4 billions' worth of fertilizer. As a result, yields are meagre. Agricultural experts worry that Africa's soil problems are heading towards a crisis. \u201cThe future picture is dire,\u201d says Dennis Garrity, chief executive of the World Agroforestry Centre (ICRAF), headquartered in Nairobi. \u201cProducing more food for a growing population in the coming decades, while at the same time combating poverty and hunger, is a huge challenge facing African agriculture.\u201d African governments, international donors and scientists all agree that farmers must revitalize their soils. But there is passionate debate about how to do it. Many African governments and agricultural scientists argue that large doses of inorganic fertilizers are the most practical solution. But others, such the Food and Agriculture Organization of the United Nations (FAO) in Rome, are pushing for greener, cheaper solutions, such as no-till farming that conserves soil and 'fertilizer plants' that boost the soil's nitrogen content organically. Researchers report that these latter techniques are beginning to raise yields and improve soil fertility. But farmers are slow to adopt such practices, which require significantly more labour. Natasha Gilbert talks about her trip to Malawi Leading scientific and political figures will take the debate to the UN's Earth Summit in Rio de Janeiro, Brazil, in June. But whatever they recommend, the biggest test is what happens when Beyadi and other African farmers try to put into practice the grand plans of scientists, international donors and governments. \u201cMany people are promoting approaches without understanding the conditions in Africa and the communities and what works for them. They mean well, but they need to appreciate the realities of the smallholder farmer,\u201d says Bashir Jama, director of the soil-health programme for the Alliance for a Green Revolution in Africa (AGRA), based in Nairobi. Sub-Sarahan Africa is one of the poorest regions on Earth, in both living standards and soil fertility. The depleted soil has caused average yields of grain crops to stagnate at around 1 tonne per hectare since the 1960s. By contrast, yields now reach 2.5 t ha \u22121  in south Asia and 4.5 t ha \u22121  in east Asia, where chemical fertilizers have been widely adopted since the green revolution (see 'Uneven landscape'). Fertilizer use across Africa has remained at around 9 kg ha \u22121  of cultivated land over the past 40 years, whereas Asia uses 96 kg ha \u22121  of inorganic fertilizer. Cost is one of the biggest problems. Because of transport expenses, farmers in inland Africa pay more than twice as much for fertilizer as farmers in Europe. And supply is often unreliable because of poor distribution systems. The World Bank and other major international donors helped to fund fertilizer use in sub-Saharan Africa in the 1970s and 80s, but they came to see such subsidies as a drag on private-sector development and cut them off, pushing African nations to cease offering them as well. However, when Malawi faced a major food crisis in 2005, President Bingu wa Mutharika, who was facing re-election, reintroduced subsidies for fertilizers and improved seeds. Over the next few years, that policy reaped strong agricultural gains, which came to be known as the Malawi miracle. As fertilizer use in the country almost doubled between 2005 and 2009, maize yields surged from around 1 t ha \u22121  in 2005 to just under 3 t ha \u22121  in 2009\u201310, according to government figures. The agricultural subsidy programme cost the Malawian government $461.4 million over five years, and comprised 13.5% of the national budget in 2009, the most recent year for which figures are available. Obtaining accurate data on yields is difficult, says Andrew Dorward, an agro-economist at the School of Oriental and African Studies in London, who has analysed the Malawi subsidy scheme, but he is convinced that the subsidy is having a positive effect. And he is not alone. \u201cBefore the subsidy the country was a patchwork of yellow maize. Today it's all green,\u201d says Stephen Carr, a retired consultant on African agriculture based in Zomba, who has worked there since the end of the 1980s. The rise in crop yields helped to convince the World Bank to soften its stance in 2007, when it announced that subsidies \u201cmay be justifiable on a temporary basis to stimulate increased fertilizer use in the short term\u201d. Other African nations have watched Malawi's experiment with interest, and some \u2014 including Rwanda, Zambia and Mali \u2014 have ramped up their own schemes. Rwanda began subsidizing fertilizer transport costs in 2006. Fertilizer imports to the country nearly tripled between 2005 and 2007, and wheat and maize yields have increased by 16% and 73%, respectively, over the past five years. The Rwandan system differs from Malawi's by encouraging the development of a fertilizer distribution industry, which is more attractive to donors and is supported by the World Bank. An international collaboration of researchers is hoping to improve the use of fertilizers by developing digital soil maps covering 42 African countries south of the Sahara. Started in 2009 with an $18-million grant from AGRA and the Bill & Melinda Gates Foundation to the Tropical Soil Biology and Fertility Institute in Nairobi, the maps will provide up-to-date information on soil properties, derived from satellite measurements and sampling at 60 sites across Africa. Keith Shepherd, a soil scientist at ICRAF who has worked on the maps, says that the analysis will inform agronomists and agricultural extension services about soil health and what nutrients are lacking. \u201cUntil now there was no unbiased sampling at this scale so there was no reliable data on acute problems,\u201d he says. AGRA is also helping to bring some of Africa's better-quality phosphate deposits into production, which will provide sub-Saharan countries with a cheaper source of locally produced phosphate fertilizer. Even so, fertilizer use in Africa is at the mercy of precarious politics. Although Rwanda's fertilizer programme is growing, Malawi's has started to fall apart as the country's economy has collapsed and its international relations have deteriorated. Many of Malawi's biggest donors, including the UK government's Department for International Development, suspended budgetary support to the nation last year because of concerns about governance and the Malawian government's refusal to devalue its currency as recommended by the International Monetary Fund. Although the United Kingdom reinstated some funding to help transport fertilizer, many Malawians couldn't purchase it this year. Changuya walked for an hour and a half to the depot in town, only to find that all the subsidized fertilizer was gone and she would not have been able to afford it anyway. \n               Greener solutions \n             With fertilizer-subsidy schemes in trouble, many researchers and donors are supporting more-sustainable methods of boosting yields. They argue that long-term fertilizer use is not only too expensive but also degrades the environment, in particular by releasing the greenhouse gas nitrous oxide. \u201cThe conventional approach has been to focus on improved seeds and chemical fertilizers, but I think there is plenty of evidence to show that there are alternatives that demand significant attention,\u201d says Garrity. One green solution gaining attention is to plant high-protein nitrogen-fixing legumes such as pigeon pea, peanuts and soya beans. With help from bacteria in their roots, legumes capture nitrogen from the atmosphere and convert it into compounds that can be used by plants. They can add up to 300 kg N ha \u22121  to the soil in a season. Farmers can plant legumes next to grain crops or they can be alternated by season. Studies in experimental plots in Malawi showed that the legumes increased maize yields by 116%. Although that strategy looks great on paper, poor farmers cannot generally give up much of their limited land to grow legumes, which require extra labour. So, many of the leguminous plants are underperforming in the field. On the average smallholding in Africa, they often fix less than 8 kg N ha \u22121  per year. Ken Giller, an agronomist at Wageningen University in the Netherlands, is hoping to tackle these problems through a four-year research programme called N2 Africa, which he helped to start with $22 million from the Bill & Melinda Gates Foundation and the Howard G. Buffet Foundation. The project aims to breed edible legumes with increased yields and better nitrogen-fixing ability, and to help spread legume crops across Malawi and seven other African nations. The FAO is promoting other green ways of raising yields, in particular an approach called conservation agriculture, which involves covering fields with mulch and not tilling the soil. The FAO says that this improves soil fertility while reducing erosion and labour. In June 2011, the FAO launched a programme called Save and Grow, currently funded at around $7 million per year, which over the next 15 years aims to promote research, training and resources for this type of agriculture. But critics argue that conservation agriculture can actually decrease yields and that few farmers in sub-Saharan Africa are willing to use these techniques. The promotion of conservation agriculture \u201cis wholly misplaced\u201d, says Giller. In experimental fields outside Lilongwe in Malawi, researchers are studying another type of green approach as part of an ICRAF project run by Gudeta Sileshi, an agricultural scientist at the Chitedze Agricultural Research Station. At the far end of one field, mature  Faidherbia albida  trees stand some 4 metres high, their leafless branches feathery against the sky. Smaller, younger trees dot the fields. They are all 'fertilizer trees', which fix nitrogen and improve the nitrogen content of the soil. Past agricultural-improvement schemes have tried unsuccessfully to sell the idea of these trees to African farmers, but there is renewed interest from researchers and governments, because tree planting is seen as one way of sequestering carbon and combating global warming. Sileshi is testing several types of trees, but he is betting that the top performer will be  F. albida , which is indigenous to Africa. Besides fixing nitrogen, it has deep roots that draw nutrients from far below the surface and store them in the tree's spiky leaves. When the leaves fall, nitrogen is returned to the top layer of the soil for use by crops planted beneath the tree's canopy.  Faidherbia albida  sheds its leaves early in the rainy season when crops are beginning to grow, so it doesn't compete with them for light, nutrients or water; its summer canopy of leaves reduces transpiration from crops underneath it and evaporation from the soil. In a trial in Zambia, maize yields under  F. albida  reached 4 t ha \u22121  compared with 1.3 t ha \u22121  outside the canopy. In the Chimbalanga 2 village near the shores of Lake Malawi, a healthy crop of maize grows beneath the naked branches of  F. albida . \u201cIf everyone planted trees, we would reduce the problem and return the soil to how it used to be,\u201d says Beather Kandaya, a farmer in the village. Kandaya was trained in fertilizer-tree husbandry by Malawi's agricultural extension service and she passes the knowledge on to her neighbours. But the practice is not catching on quickly. In Malawi, just over 1% of farmers grow the trees. This could soon change. Malawi, Niger, Kenya and Rwanda are among the African countries promoting the use of trees within farming. And international donors are starting to support tree programmes. Beyadi's experience, though, shows how much work there is still to do. She and her neighbours care for a small experimental nursery filled with some 200 spindly seedlings of leguminous plants and trees. Of the 240  F. albida  seeds that the group planted last year, only one seedling has survived. It is a common problem because the roots of  F. albida  are very fragile and easily damaged. And it will be 6\u201310 years before an  F. albida  sapling is ready to fertilize crops. At the Chitedze research station, ICRAF and the agricultural non-governmental organization Total Land Care, based in Lilongwe, are trying to find ways of cultivating  F. albida  more efficiently. Proponents of fertilizer trees say that they deserve a chance and that they have received far less funding and promotion than other sustainable farming techniques and inorganic fertilizers. \u201cThe simplest, cheapest techniques are the ones that are ignored as they are not of interest to the private sector,\u201d says Garrity. \u201cIt's time we no longer ignored them.\u201d But many agricultural experts and farmers conclude that green approaches are not enough \u2014 that Africa can't solve its soil problems without chemical fertilizers. \u201cI continue to believe leguminous trees and plants have got to play a part in maintaining soil fertility and food security, but they can't replace inorganic fertilizer,\u201d Carr says. \u201cThe fertilizer subsidy is a matter of life or death.\u201d Giller argues that to win over farmers, new techniques for increasing crop yield must bring extra benefits, which is why he is focusing his research on edible legumes. The acid test is whether farmers continue to use the new approaches after aid support ends. Beyadi acknowledges that many of her fellow farmers will drop the new green techniques when aid goes. And although she says that she will continue to care for the fertilizer trees, she doesn't regard them as her best hope for the future. Like her neighbours, she sees inorganic fertilizers as the key to growing more food. Surveying her lush green gardens, Beyadi wonders whether she will be able to buy enough fertilizer next year to ensure an equally bountiful harvest. See Editorial  page 510 \n                     Climate-smart agriculture is needed 2011-Mar-02 \n                   \n                     Environment: The disappearing nutrient 2009-Oct-07 \n                   \n                     Digital soil map for Africa launched 2009-Jan-13 \n                   \n                     Agronomy: Five crop researchers who could change the world 2008-Dec-03 \n                   \n                     Gates funds agricultural development 2008-Jan-25 \n                   \n                     African leaders say yes to more fertilizer for farmers 2006-Jun-14 \n                   \n                     Nature Africa Special \n                   \n                     World Agroforestry Centre \n                   \n                     World Bank \n                   \n                     FAO \n                   \n                     N2Africa \n                   \n                     Alliance for a Green Revolution in Africa \n                   \n                     Africa Soil Information Service \n                   Reprints and Permissions"},
{"file_id": "482148a", "url": "https://www.nature.com/articles/482148a", "year": 2012, "authors": [{"name": "Matthew Walter"}], "parsed_as_year": "2006_or_before", "body": "In the 1940s, US doctors deliberately infected thousands of Guatemalans with venereal diseases. The wound is still raw. The injections came without warning or explanation. As a low-ranking soldier in the Guatemalan army in 1948, Federico Ramos was preparing for weekend leave one Friday when he was ordered to report to a clinic run by US doctors. Ramos walked to the medical station, where he was given an injection in his right arm and told to return for another after his leave. As compensation, Ramos's commanding officer gave him a few coins to spend on prostitutes. The same thing happened several times during the early months of Ramos's two years of military service. He believes that the doctors were deliberately infecting him with venereal disease. Now 87 years old, Ramos says that he has suffered for most of his life from the effects of those injections. After leaving the army, he returned to his family's remote village, on a steep mountain slope northeast of Guatemala City. Even today, Las Escaleras has no electricity or easy access to medical attention. It wasn't until he was 40, nearly two decades after the injections, that Ramos saw a doctor and was diagnosed with syphilis and gonorrhoea. He couldn't pay for medication. \u201cFor a lack of resources, I was here, trying to cure myself,\u201d says Ramos. \u201cThanks to God, I would feel some relief one year, but it would come back.\u201d Over the decades, he has endured bouts of pain and bleeding while urinating, and he passed the infection onto his wife and his children, he told  Nature  last month in an interview at his home. Ramos's son, Benjamin, says that he has endured lifelong symptoms, such as irritation in his genitals, and that his sister was born with cankers on her head, which led to hair loss. Ramos and his children blame the United States for their decades of suffering from venereal disease. \u201cThis was an American experiment to see if it caused harm to human beings,\u201d says Benjamin. Ramos is one of a handful of survivors from US experiments on ways to control sexually transmitted diseases (STDs) that ran in semi-secrecy in Guatemala from July 1946 to December 1948. US government researchers and their Guatemalan colleagues experimented without consent on more than 5,000 Guatemalan soldiers, prisoners, people with psychiatric disorders, orphans and prostitutes. The investigators exposed 1,308 adults to syphilis, gonorrhoea or chancroid, in some cases using prostitutes to infect prisoners and soldiers. After the experiments were uncovered in 2010, Ramos and others sued the US government, and US President Barack Obama issued a formal apology. Obama also asked a panel of bioethics advisers to investigate, and to determine whether current standards adequately protect participants in clinical research supported by the US government. When details of the Guatemalan experiments came to light, US health officials condemned them as 'repugnant' and 'abhorrent'. Last September, the Presidential Commission for the Study of Bioethical Issues went further, concluding in its report 1 , that \u201cthe Guatemala experiments involved unconscionable violations of ethics, even as judged against the researchers' own understanding of the practices and requirements of medical ethics of the day\u201d (see 'Evolving ethics'). Yet that report and documents written by the researchers involved in the Guatemalan work paint a more complex picture. John Cutler, the young investigator who led the Guatemalan experiments, had the full backing of US health officials, including the surgeon general. \u201cCutler thought that what he was doing was really important, and he wasn't some lone gunman,\u201d says Susan Reverby, a historian at Wellesley College in Massachusetts, whose discovery of Cutler's unpublished reports on the experiments led to the public disclosure of the research 2 . Cutler and his superiors knew that some parts of society would not approve. But they viewed the studies as ethically defensible because they believed that the results would have widespread benefits and help Guatemala to improve its public-health system. Those rationalizations serve as a warning about the potential for medical abuses today, as Western clinical trials increasingly move to developing countries to take advantage of lower costs and large populations of people with untreated disease. Bioethicists worry that laxer regulations and looser ethical standards in some countries allow researchers to conduct trials that would not be allowed at home. \u201cThe strongest lesson should be that the same rules, same principles, same ethics should apply no matter where you are,\u201d says Christine Grady, acting chief of the Department of Bioethics at the National Institutes of Health (NIH) Clinical Center in Bethesda, Maryland, and a member of the bioethics commission. \n               The war against syphilis \n             In the early decades of the twentieth century, US health officials were consumed by the battle against STDs, much as subsequent generations of researchers have fought cancer and HIV. In 1943, Joseph Moore, then chairman of the US National Research Council's Subcommittee on Venereal Diseases, estimated that the military would face 350,000 new infections of gonorrhoea annually, \u201cthe equivalent of putting out of action for a full year the entire strength of two full armored divisions or of ten aircraft carriers\u201d. The government launched vigorous campaigns of research, treatment and advertising to combat the problem. \u201cShe may look clean \u2014 but pick-ups, 'good time' girls, prostitutes spread syphilis and gonorrhea\u201d, read one poster issued by the US Public Health Service, which promotes health initiatives and medical research. Many of the country's leading health officials were veterans of that fight. The surgeon general who would approve the proposal for the Guatemalan experiments, Thomas Parran, had previously run the Public Health Service's Venereal Disease Research Lab (VDRL) in New York, and had written two books on the topic. And the associate director of that lab went on to serve as the chief of the research grants office at the NIH, which would fund the Guatemalan work in early 1946. \u201cYou had a very active venereal-disease division,\u201d says John Parascandola, a former historian of the Public Health Service and author of  Sex, Sin and Science: A History of Syphilis in America  (Praeger, 2008). Even after researchers demonstrated in 1943 that penicillin was an effective treatment for syphilis and gonorrhoea, they had many questions about preventing and treating those diseases and others. \u201cYou still had all these people who cut their teeth with venereal diseases and were interested in that topic. Certainly, the venereal-disease division in the 1940s didn't think the problem was licked.\u201d The military, in particular, wanted to develop prophylactic techniques better than the 'pro kit' that had been in use for decades. After sex, servicemen were supposed to inject a solution containing silver into their penises to prevent gonorrhoea, and rub a calomel ointment over their genitals to prevent syphilis. The methods were painful, messy and not very effective. To test treatments and prophylaxis, the Public Health Service had argued in late 1942 that it was crucial to give the disease to people under controlled conditions. Officials debated the legality and ethics of this, and even solicited the input of the US attorney general. They decided to do the work at a federal prison in Terre Haute, Indiana, using volunteer inmates. Cutler was one of the doctors charged with carrying out the work. When the prison study began in September 1943, Cutler was 28, and had finished medical school only two years before. The researchers tried to infect prisoners by depositing bacteria \u2014 sometimes gathered from prostitutes arrested by the Terre Haute police \u2014 directly on the end of the penis. The experiment established several practices that Cutler would go on to use in Guatemala, including working with local law-enforcement agencies and prostitutes. But the researchers could not develop a means to effectively infect people \u2014 a necessary step towards testing prophylactic techniques. Within ten months, the experiments were abandoned. \n               Captive population \n             After Terre Haute, researchers began to plan a more ambitious study. They wanted to try causing infections through what they called normal exposure, in which people would have sex with infected prostitutes. In 1945, a Guatemalan health official who was working for a year at the VDRL offered to host studies in his country. As director of the Guatemalan Venereal Disease Control Department, Juan Funes was uniquely positioned to help. Prostitution was legal in his country at the time, and sex workers were required to visit a clinic twice a week for examinations and treatment. Funes oversaw one of the main clinics, so he could recommend infected prostitutes for experiments. Cutler and other scientists at the VDRL were quickly sold on the idea: they proposed a programme, which was approved with a budget of US$110,450. According to a Guatemalan report 3 , the US plan was a clear violation of contemporary Guatemalan law, which made it illegal to knowingly spread venereal diseases. But the country was experiencing political upheaval in the mid-1940s and the bureaucracy did not object to the US plan. Government officials as high up as Luis Galich, head of the Guatemalan ministry of public health, were involved in the US study, and even President Juan Jos\u00e9 Ar\u00e9valo, who had been elected in 1945, was at least aware of a syphilis experiment being done by US scientists. The study presented a chance to tap into US funding to upgrade Guatemala's inadequate public-health infrastructure, and to import scientific expertise. Cutler arrived in the country in August 1946 and began setting up experiments. He planned to assess diagnostic blood tests, and to determine the effectiveness of penicillin and an agent called orvus-mapharsen in preventing STDs. At first, Cutler tried using infected prostitutes to spread gonorrhoea to soldiers: he and his team used various bacterial strains to inoculate sex workers, who then had intercourse with many men. Records show that one prostitute had sex with 8 soldiers in a period of 71 minutes. The team also carried out similar experiments using sex workers at a prison. But it was hard to induce infections by the 'natural' method. So researchers turned to inoculation, swabbing the urethra with an infected solution, or using a toothpick to insert the swab deep into the urethra. At the National Psychiatric Hospital of Guatemala, scientists scratched male patients' penises before artificial exposure to improve infection rates, and injected syphilis into the spinal fluid of seven female patients. According to the US bioethics commission's report, Cutler's team exposed 558 soldiers, 486 patients at the psychiatric hospital, 219 prisoners, 6 prostitutes and 39 other people to gonorrhoea, syphilis or chancroid. But the commission was unable to determine how many people actually developed infections or how many of the participants were treated. Researchers also measured the accuracy of diagnostic tests in experiments that involved orphans and people with leprosy, as well as people from the psychiatric hospital, prison and the army. The commission says there is no evidence that Cutler sought or obtained consent from participants, although in some cases he did get permission from commanding officers, prison officials and doctors who oversaw the patients at the psychiatric hospital. In a letter to his supervisor, John Mahoney, director of the VDRL, Cutler openly admits to deceiving patients at the psychiatric hospital, whom he was injecting with syphilis and later treating. \u201cThis double talk keeps me hopping,\u201d Cutler wrote. Cutler and his colleagues treated some people brutally. In one case, detailed by the bioethics commission, the US doctors infected a woman named Berta, a patient at the psychiatric hospital, with syphilis, but did not treat her for three months. Her health worsened, and within another three months Cutler reported that she seemed close to death. He re-infected Berta with syphilis, and inserted pus from someone with gonorrhoea into her eyes, urethra and rectum. Over several days, pus developed in Berta's eyes, she started bleeding from her urethra and then she died. Yet Cutler did do some good in Guatemala. He took steps to improve public health, initiating a venereal-disease treatment programme at the military hospital and developing a prophylactic plan for the army. He treated orphans for malaria, lobbied his supervisors to supply the army with penicillin \u2014 he was turned down \u2014 and trained local doctors and technicians. And he provided treatment for 142 people who may have had venereal disease but had not been exposed to it as part of the research. At the prison, he reported that \u201cwe have found a very ready acceptance of our group, both on the part of the prison officials and the part of the inmates, which we think stems from the fact that we now have given them a program of care for venereal disease, which they have lacked in the past. Thus we feel that our treatment program is worthwhile and fully justified.\u201d In the end, Cutler could claim no real success in his experiments, in part because he was never able to infect people reliably without resorting to extreme methods. He secured an extension to continue the experiments from June to December 1948, and he left Guatemala at the end of that year. Other researchers published some of the blood-test results, but Cutler did not publish his work on prophylactic methods. The experiments were not only unconscionable violations of ethics, the bioethics commission charges, they were also poorly conceived and executed. \n               A distinguished career \n             Despite the failures, the work burnished Cutler's credentials. A few months after he arrived home, the World Health Organization sent Cutler to India to lead a team demonstrating how to diagnose and treat venereal diseases. In the 1960s, he became a lead researcher in the infamous Tuskegee experiment in Alabama, in which hundreds of black men with syphilis were studied for decades without receiving treatment. He flourished in the Public Health Service and later became a professor of international health at the University of Pittsburgh in Pennsylvania. He died in 2003, well before details of the Guatemala experiments were exposed. Michael Utidjian was an epidemiologist at Pittsburgh in the late 1960s and co-authored two papers with Cutler. He describes his former colleague as devoted to venereal-disease studies and enthusiastic about international research. \u201cHe did some pioneer work out in India using penicillin to treat the commoner STDs.\u201d But Utidjian says that Cutler was a flawed researcher. \u201cI wouldn't rank him as a top-flight scientist or designer of studies.\u201d The two scientists collaborated on a study to test the effectiveness of a topical prophylaxis in prostitutes at a brothel in Nevada. However, the poor implementation of the experiment led to \u201cpretty worthless\u201d results, says Utidjian. The participants in Cutler's Guatemalan study fared far worse than the doctor himself. Shuffling among the tin-roofed homes in Las Escaleras, Ramos is bone thin and speaks in a mumble, made worse by his lack of teeth. He says that he put off treatment until about ten years ago, when it became too painful to urinate. His son rushed him to a hospital, where doctors inserted a catheter and later performed an operation. Gonzalo Ramirez Tista lives in the same village as Ramos and says that his father, Celso Ramirez Reyes, also participated in the experiments during his three years in the army. He was required by the scientists to have sex with infected prostitutes. \u201cThey gave him an order, and it came from a superior,\u201d says Tista. They also gave him injections, and within days he noticed pus coming out of his penis. \u201cHe still had these symptoms when he left [the military], and he infected my mother.\u201d After his service, gonorrhoea left Reyes with sores, poor eyesight and lethargy. Like Ramos's family, Tista is a party to the lawsuit seeking compensation from the US government. Neither man could provide documents to support their claims. But Pablo Werner, a doctor with Guatemala's Human Rights Ombudsman's office, has reviewed the cases and found that Ramos's and Reyes's stories are supported by the timing of their military service and details in the medical histories that they gave. Reyes is also named in a database of research participants that was compiled by Guatemala's National Police Historical Archive from Cutler's papers. \n               Never again \n             The US Department of Justice requested last month that the compensation case be dismissed, arguing that the courts are not the \u201cproper forum\u201d for it. But last September, a panel of the presidential bioethics commission recommended 4  that the government set up a general compensation system for test participants harmed by federally funded research. This January, the US Department of Health and Human Services committed nearly $1.8 million to improving the treatment of STDs in Guatemala and strengthening ethics training there regarding research on humans. The plaintiffs are not satisfied and intend to press their case, says Piper Hendricks, an international human-rights lawyer with Conrad & Scherer in Fort Lauderdale, Florida, who is representing them. As the case moves forward, researchers are wrestling with how to judge the actions of Cutler's team, and how to prevent such abuses from happening again. The bioethics commission argues that Cutler and his superiors knew that they were violating the medical ethics of their day, because they had sought the consent of participants in Terre Haute. And in Guatemala, the researchers took steps to suppress knowledge of their work. One colleague told Cutler that the US surgeon general \u201cis very much interested in the project and a merry twinkle came into his eye when he said, 'You know, we couldn't do such an experiment in this country'.\u201d But the ethical landscape was evolving rapidly at the time. The standards of the 1940s were \u201ca lot murkier\u201d than those of today, says Susan Lederer, a bioethicist at the University of Wisconsin\u2013Madison. \u201cThe idea that it was so clear in 1946 to me doesn't ring true.\u201d In late 1946, after Cutler had started his work in Guatemala, 23 Nazi doctors and officials went on trial in Nuremberg, Germany, for the inhuman experiments that they had carried out in concentration camps during the Second World War. From that trial emerged the Nuremberg Code, a set of principles that mandated that experimenters obtain voluntary consent from participants, that participants be capable of giving such consent and that experiments avoid unnecessary physical and mental harm. Although such tight standards were not entirely foreign to researchers before the Nuremberg trials, few followed them. In 1935, for example, the Supreme Court of Michigan stated that researchers could get consent from caregivers of participants, which Cutler did in a sense when he consulted commanding officers and other officials. Many of Cutler's participants were poor, uneducated people from indigenous populations, whom the scientists viewed as incapable of understanding the experiments. At the time, some of the United States's top researchers worked without obtaining consent from individuals. Jonas Salk, who later earned fame for developing the polio vaccine, and Thomas Francis Jr, a leading influenza researcher, intentionally infected patients at a psychiatric hospital in Ypsilanti, Michigan, with influenza in 1943 (ref.  5 ). There is evidence that the patients did not all consent to the experiments. Cutler and his superiors apparently thought it was acceptable in Guatemala to cross ethical lines that they would not have breached at home \u2014 an issue that raises concern today, with Western companies increasingly running clinical trials in foreign countries, particularly in developing nations. In 2010, the US Department of Health and Human Services investigated all requests by companies to market their drugs in the United States, and found that in 2008, nearly 80% of approved applications used data from clinical trials in other countries. Developing nations often have lower medical standards than developed countries, and can't enforce rules as effectively. In India, for example, human-rights activists and members of parliament say that foreign drug companies often test experimental drugs on poor, illiterate people without obtaining their consent or properly explaining the risks. And in 2009, the pharmaceutical giant Pfizer agreed to pay up to $75 million to settle lawsuits over the deaths of Nigerian children who had participated in tests of an experimental antibiotic. Nigerian officials and activists had claimed that the company had acted improperly by, for example, not obtaining proper authorization or consent. But Pfizer denies the allegations and did not admit any wrongdoing in the settlement. Ethicists also warn about practices viewed as acceptable today, such as testing medications on patients who are extremely ill, and who see new treatments as their only hope, no matter how dangerous they are. Lederer notes that some trials of cancer drugs involve particularly toxic compounds. In the future, she says, \u201cpeople might say, 'how can people who are so sick make informed decisions?'\u201d For Grady, the lessons from Guatemala are fundamental tenets of bioethics: not every method is acceptable, transparency is key and scientists should remember that they are working with human beings. But in clinical research, she says, the ethical lines aren't always well defined. \u201cWhen you get to the details of what that means in a particular case, people disagree.\u201d And that may be the most troubling lesson of the Guatemalan experiments. In any era, many if not most researchers might agree that a certain practice or rule is justified and necessary. But for later generations, the barbarism of the past seems only too obvious. \n                 See Editorial \n                 p.132 \n               \n                     US bioethics panel urges stronger protections for human subjects 2011-Dec-15 \n                   \n                     A shocking discovery 2010-Oct-04 \n                   \n                     Blogpost: US seeks to dismiss lawsuit over unethical VD research in Guatemala \n                   \n                     Blogpost: Guatemala experiments 'heinous', commission tells Obama \n                   \n                     Bioethics Commission report (PDF) \n                   \n                     Guatemalan government report (PDF in Spanish) \n                   \n                     Records of the Guatemalan experiments \n                   Reprints and Permissions"},
{"file_id": "481430a", "url": "https://www.nature.com/articles/481430a", "year": 2012, "authors": [{"name": "Jim Giles"}], "parsed_as_year": "2006_or_before", "body": "Lab-management software and electronic notebooks are here \u2014 and this time, it's more than just talk. The basement room in the James H. Clark Center contains all the trappings of a modern imaging laboratory. An X-ray scanner hums away in a corner. A miniature magnetic resonance imaging (MRI) machine, designed to scan the brains of mice, sits nearby. It's the kind of set-up that researchers at well-funded institutions such as Stanford University in California, the centre's home, have come to expect. One piece of equipment, however, is conspicuous by its absence: the humble paper notebook. Michelle James uses her iPad to jot down notes, check protocols and monitor the progress of her experiments on techniques for the early detection of Alzheimer's disease. Since she first brought the device into the lab around four months ago, it has essentially replaced her former hardback notebook. \u201cPaper has nothing to offer me,\u201d declares James. It's a refrain heard in more and more labs. Some groups have ditched notebooks in favour of software from Google, such as free-to-use tools for sharing documents, spreadsheets and calendars. Others are finding that software designed specifically for lab workers has evolved to the point where it can reliably do a range of tasks, from tracking reagent supplies to sharing protocols. The era of the paperless lab, decades in the making, seems finally to have arrived. Now that it's here, adopters say that a paperless laboratory seems to offer real advantages. Bench researchers say that digital notebooks help them track their experiments in more detail. Lab heads report being able to follow and focus projects more efficiently when documentation is tailored to their needs, accessible online and shared among colleagues. In some cases, digital notebooks could even help researchers to find connections or extract results from systematically stored data. \u201cThe efficiency thing is nice,\u201d says Jonathan Hirsch, founder of Syapse, a company based in Palo Alto, California, that develops the software James uses to manage and share her results. \u201cBut understanding your data better is what gets people really excited.\u201d \n               Going paperless, again \n             If these claims sound familiar, that may be because the paper notebook's obituary has been written many times before. The paperless laboratory was \u201cnascent\u201d ten years ago, according to one American Chemical Society journal. Electronic notebooks are \u201cready for prime time\u201d, said Douglas Perry, a bioinformatics expert, in a  Nature  News Feature from 2005 (see   Nature 436, 20\u201321; 2005 ). Yet most early notebook-software programs had limited impact, often because they weren't easy enough to use. Some worked only with specific file types, for example, or had cumbersome data-entry mechanisms. Such drawbacks have not stopped digital notebooks from taking off within the pharmaceutical industry, where companies have the funds to customize the systems and can mandate that employees use them. But for academics, these shortcomings were deal-breakers. \u201cEverything we tried was really crappy,\u201d says Sriram Kosuri, a bioengineer at Harvard Medical School (HMS) in Boston, Massachusetts, who experimented with many of the older packages. Things have changed, thanks in part to the arrival of free or cheap sharing tools that are easy to use and configure. These tools, from storage systems such as Dropbox to the products offered by Google and others, rely on fast and reliable Internet connections and cloud-based storage. They provide a quick and cheap way to set up a basic lab infrastructure for sharing methods, data and other records. At William Shih's synthetic-biology lab at HMS, researchers store records on a password-protected network of interlinked pages that any group member can edit. His team built it using MediaWiki, the free-to-use software that powers Wikipedia. A page for an ongoing experiment, for example, can easily be updated to note changes in a protocol or to include a graph of the latest results. Team members log on to the site through laptops or their iPads, which they wrap in ziplock bags before venturing to the bench. \u201cEven with a finger in a glove we can still get touch-screen sensitivity,\u201d says Shih. When researchers want to sketch out an idea \u2014 an essential process in a lab working on self-assembling nanostructures \u2014 they use Adobe Ideas, software that, for US$10 or less, makes it possible to construct detailed images on touch-screen devices. But these general-purpose tools don't always satisfy researchers' needs. Some note-taking software, for example, does not handle tables well. And although MediaWiki is very flexible, some users say that it has a clunky interface for putting in text. This means that the race to create a good digital notebook \u2014 one that is both flexible and tailored to researchers' requirements \u2014 is still on. \n               Getting plugged in \n             Jonathan Gross is one of the front runners in that competition. Gross began creating lab software when he was a plant-biology researcher at the Hebrew University of Jerusalem. The tools he built gained a following among his colleagues and, in 2007, he quit the lab to found BioData, a company based in Rosh Ha'ayin, Israel, that develops lab-management software. (BioData was purchased in 2010 by Digital Science, a sister company to Nature Publishing Group.) Alex Kentsis, a paediatric oncologist and haematologist at HMS, is an early adopter of Gross's software. \u201cPrior to BioData we had a makeshift operation,\u201d he says. His group used to swap files over shared drives, and Kentsis kept track of the lab's progress using an Excel spreadsheet in which each column represented a project and each row an activity. It worked, but only kind of. External collaborators could not access the shared drives, and the spreadsheet required constant maintenance and was hard to interpret. BioData's software, which was relaunched last December as Labguru, tackles those problems. It's an online home for any information associated with scientific research, from protocols and results to images and related papers. The material is grouped by project, which Gross says makes it easy to track progress and to assemble the components of a paper. A tagging system makes it possible to group experiments that share a common component, such as a specific gene or cell line. External collaborators can use a password to access a specific project, which can be done from anywhere because the data are stored in the cloud. Gross plans to add new functions: he says he is in discussions about integrating his system with  Nature Protocols , a journal dedicated to recipes for lab procedures, and Addgene, a repository of information on genetic-research tools called plasmids. The hope is that Labguru users can seamlessly pull information from the external databases. \u201cIt's about making researchers' lives as easy as possible,\u201d says Gross. Labguru is aimed at life-science labs, but there are alternatives for other fields. Andrew Phillips, a chemist at Yale University in New Haven, Connecticut, uses iLabber, a product from Stockholm-based Contur Software. The selling point for Phillips was iLabber's ability to handle a chemist's daily tasks, such as drawing molecular structures and calculating expected yields. \u201cIt's chemically savvy,\u201d says Phillips, who says he pays $150 per user per year. Labguru charges academic labs a similar fee. At Syapse, Hirsch also has ambitious plans. The company's software, Syapse Discovery, is undergoing testing in around 45 US labs. It combines the project-based structure of iLabber and Labguru with a layer of semantic technology that 'knows' the data that researchers upload. For example, the Syapse software can automatically recognize that data are from a particular lab machine, such as a microarray or MRI, and apply 'time' and other appropriate headings to it. For other data, Syapse Discovery has a system that allows researchers to quickly select labels from a drop-down list. With the tagging in place, researchers can use the software to run complex tasks that would generally require coding skills. Users might ask it to scan multiple experiments and to build a table that combines all results on a specific gene. Or, in a clinical setting, they might ask it how an experimental drug is affecting patients with a particular constellation of symptoms. \u201cWe want to give people the ability to access this information without them having to learn programming,\u201d says Hirsch. \n               End of an era? \n             All of this hints at a future in which iPads and other devices do more than just replace notebooks. Kentsis points to a study of his into a therapy for acute myeloid leukaemia. Only when he looked at the milestones he had highlighted in BioData did he realize that a key piece of evidence \u2014 additional results on the extent to which drug resistance developed \u2014 was missing. The task could have been done using pen and paper, but BioData made it quicker. \u201cIt's been easier to see project arcs and to direct research towards more important questions,\u201d says Kentsis. Digital notebooks may also help researchers to probe correlations that are too time-consuming to pursue using paper-based records. Archana Shenoy, a stem-cell biologist at the University of California, San Francisco, has been using Syapse Discovery for six months. She thinks that it can help to shed light on one of the frustrations of her field: cell lines that die without apparent cause. With a paper notebook it is almost impossible to correlate the myriad factors that might affect cell survival. But with Syapse Discovery, Shenoy can quickly record data ranging from the carbon dioxide levels in a cell incubator to the date when a new batch of reagents arrives. When the search capability is up and running, she will be able to look for correlations between these factors and the fate of her cells. \u201cIt's something everybody wonders about,\u201d she says. \u201cWhat is causing these little changes?\u201d Yet it's unclear how much impact the new programs will have. Expense is one issue: not every lab can afford to equip its members with laptops or iPads. Practicality is another: some labs don't allow laptops near the bench because of the risk of spills. But ultimately, these tools, like the earlier iterations of digital notebooks, will live or die on the basis of their usability. The greatest challenge for Syapse, BioData and their rivals is not to create a tool that can do everything, but one that, like the intuitive software produced by Apple, is fundamentally easy to use. The initial feedback from James and others suggests that the latest generation of lab software might be able to do both. If so, it might finally be time to turn the page on the notebook. See Editorial,  page 410 . \n                     Techniques: Records in the field 2011-Jun-15 \n                   \n                     Science in the digital age 2010-Oct-13 \n                   \n                     Share your lab notes 2007-May-02 \n                   \n                     Electronic notebooks: A new leaf 2005-Jul-06 \n                   \n                     iLabber \n                   \n                     Syapse \n                   \n                     Labguru \n                   Reprints and Permissions"},
{"file_id": "482020a", "url": "https://www.nature.com/articles/482020a", "year": 2012, "authors": [{"name": "Mark Schrope"}], "parsed_as_year": "2006_or_before", "body": "Jellyfish will bloom as ocean health declines, warn biologists. Are they already taking over? Last summer, intrepid surfers flocked to Florida's east coast to ride the pounding swells spawned by a string of offshore hurricanes. But they were not prepared for a different kind of hazard washing towards shore \u2014 an invasion of stinging moon jellyfish, some of which reached the size of bicycle wheels. The swarms of gelatinous monsters grew so thick that they forced a Florida nuclear power plant to shut down temporarily out of concern that the jellies would clog its water-intake pipes. Earlier in the year, similar invasions had forced shut downs at power plants in Israel, Scotland and Japan. The gargantuan Nomura's jellyfish ( Nemopilema nomurai ) found in Japanese waters can weigh up to 200 kilograms and has plagued the region repeatedly in recent years, hampering fishing crews and even causing one boat to capsize. Jellyfish have destroyed stocks at fish farms in Tunisia and Ireland. And in the Mediterranean Sea and elsewhere, officials have built nets to keep out jelly swarms. The jellyfish blooms seem to bear out warnings from some scientists and conservationists, who argue that humans are knocking marine ecosystems off balance, causing a massive increase in the global population of jellyfish \u2014 a catch-all term that covers some 2,000 species of true cnidarian jellyfish, ctenophores (or comb jellies) and other floating creatures called tunicates. But many marine biologists are now questioning the idea that jellyfish have started to overrun the oceans. This week, a group of researchers published preliminary results from what will be the most comprehensive review of jellyfish population data 1 . They say that there is not yet enough evidence to support any conclusions about a global upswing in jellyfish populations. \u201cWe are not at a point to make these claims,\u201d says Robert Condon, a marine scientist at the Dauphin Island Sea Lab in Alabama, who leads the group. \u201cIf you look at how that paradigm formed, it's not based on data or rigorous analyses.\u201d The main problem, say the scientists, is that jellyfish are notoriously difficult to study, so they have historically received scant attention from marine biologists. There are remarkably few data about their life cycles, populations and responses to natural oceanographic cycles. But the creatures could serve as key indicators for the health of the oceans, so scientists are now building a database of jellyfish research and exploring new ways to keep track of them. Monty Graham, chairman of the department of marine science at the University of Southern Mississippi in Diamondhead, is part of the review team now questioning the idea of a rise in jellyfish numbers, but more than a decade ago he was sounding the alarm. In 1996, he took a position at the Dauphin Island Sea Lab, where he found that the US National Oceanic and Atmospheric Administration had years of mostly unprocessed population data on moon jellyfish ( Aurelia aurita ) and Atlantic sea nettles ( Chrysaora quinquecirrha ) in the Gulf of Mexico. These data were a rare treasure; only a handful of similar long-term records exist. Graham discovered that from 1985 to 1997, the jellies had grown substantially more widespread and abundant in several parts of the Gulf, and he suggested that human changes to the ecosystem might be the cause 2 . Similar findings supported the notion. In the Bering Sea, one of the handful of locations with a monitoring record longer than a few years, jelly numbers had also risen through the 1990s. That matched predictions made by ocean scientists, who had warned that as humans degrade the oceans they are shifting ecosystems, reducing numbers of larger fish and promoting populations of organisms from lower down the food chain 3 , 4 . Among the beneficiaries would be algae, toxic plankton and jellyfish \u2014 in other words, there would be a sea of slime. \n               Boom and bust \n             The link between ocean degradation and jellyfish makes biological sense. Nutrient pollution can increase food supplies for jellyfish; overfishing can reduce their competition; and warmer temperatures are thought to trigger reproduction in some jellyfish species. But as the slime paradigm gained traction in the literature, something odd was happening in the Gulf of Mexico. One of Graham's graduate students, Kelly Robinson, found that jellyfish numbers in the northern Gulf had declined for several years after 1997, and then rebounded. Her work has not yet been published. Researchers studying jellyfish in the Gulf of Mexico and the Bering Sea now think that long-term natural climate cycles have an important role in controlling populations there. \u201cJust seeing a lot of jellyfish does not say anything,\u201d says Graham now. \u201cPeople say, 'Oh my God, the world is going to hell,' but jellies form blooms. That's what they're supposed to do.\u201d The challenge for researchers lies in separating normal fluctuations from those for which humans might deserve some of the blame. Graham and others decided to take a scientific step back. In 2009, the National Center for Ecological Analysis and Synthesis at the University of California, Santa Barbara, funded Graham, Condon and Carlos Duarte, a marine ecologist at the Mediterranean Institute for Advanced Studies on Majorca, Spain, to establish the working group that has just published its findings. Made up of dozens of researchers, it compiled all the scientific data available on jellies worldwide. After a preliminary examination, the group said 1  that it could not support the conclusion that jellyfish numbers are increasing globally, because only a few places have been monitored carefully and even there the data are limited. Researchers have tended to ignore or avoid jellyfish, in part because they are such a nightmare to deal with. Typical nets shred them, and collecting them intact can require heroic efforts. Shin-ichi Uye, a marine ecologist at Hiroshima University in Japan, says that because some jellyfish are heavier than sumo wrestlers, marine biologists must carefully balance their small research boats to avoid capsizing when retrieving a single specimen. To make matters worse, many jellyfish groups have complex life cycles. Several species, including moon jellyfish, reproduce sexually to form larvae that settle on the sea floor and develop into anemone-like growths called polyps. If conditions are favourable, a single polyp can bud to form 20 floating jellies. But in hard times, polyps can produce more polyps or retreat into a tough cyst. Then, when the environment improves, the waiting polyps can fuel a massive bloom of jellyfish that might seem like an invasion from nowhere. With very few exceptions, the polyp colonies that cause large jellyfish blooms are \u201creally hard to find\u201d, says Claudia Mills, a jellyfish specialist at the University of Washington's Friday Harbor Laboratories, who was part of the jellyfish review group and was one of the first to examine the possibility of a global rise. Bloom triggers seem to be tied to seasonal temperature changes, she says. And that raises the possibility that warming of the oceans could indeed cause populations to mushroom 5 . Most of the researchers who have questioned the idea of a jellyfish explosion say they cannot rule out the possibility that blooms are becoming more prevalent or that humans are at least partly responsible 6 . In Japan, for example, long-term records suggest that blooms happened only every 40 years or so before 2000, but have come nearly every year since 7 . Moreover, the blooms seem to originate in Chinese waters, where overfishing has severely depleted the Japanese jellyfishes' main competitors. In most other cases, however, the trends are not so clear cut. So in 2010, the biologists on the task force began a Jellyfish Database Initiative (JEDI), compiling every scientific jellyfish record they could find, and they expect to continue expanding this resource. Some researchers are also teaming up with the public. The Monterey Bay Aquarium Research Institute in California has launched a website called Jellywatch.org, through which scientists and citizens can report jellyfish sightings to help fill out the JEDI database. The intergovernmental Mediterranean Science Commission in Monaco has started a similar programme for that sea. \n               Hidden data \n             Despite the lack of long-term studies, some scientists think that there is enough evidence to answer some important questions. In a paper due out later this month, Lucas Brotz, a graduate student in fisheries biology at the University of British Columbia in Vancouver, Canada, and his adviser, Daniel Pauly, analysed media reports and other non-scientific data about bloom patterns since 1950, such as interviews with locals and scientists. The researchers used fuzzy logic, a ranking system that incorporates the reliability and abundance of information, to identify trends in less-than-ideal data sets. They found that jellyfish populations were increasing in 31 of the 45 ocean regions that they studied. \u201cOur study says you can actually pierce through the confusing fog of press reports and anecdotes and scientific data to establish whether increases are occurring,\u201d says Pauly. Graham and other researchers praise the approach, but they contend that such information just isn't adequate. The jellyfish review team will begin to analyse the full JEDI database later this month, encouraged by the growth of programmes in places such as Peru and Japan, where scientists work with fishermen to monitor jellyfish populations. But even so, the researchers caution that they will need to establish many more monitoring programmes to complete a global picture. With such programmes in place, researchers could use the comprehensive jellyfish data sets to track how the oceans are changing. These creatures make ideal environmental sentinels because humans mostly leave them alone, says Graham. \u201cJellyfish are the great bystanders of the oceans and the oceans' health.\u201d \n                     Zoology: Jellyfish eyes on the sky 2011-May-04 \n                   \n                     'Fishing down food chain' fails global test 2010-Nov-17 \n                   \n                     Jellyfish help mix the world's oceans 2009-Jul-29 \n                   \n                     PICES Conference: How much fish in the future? \n                   \n                     Attack of the killer jellyfish! \n                   \n                     Daniel Pauly: A marine biologist dives into the history of the Gulf of California \n                   \n                     US National Center for Ecological Analysis and Synthesis jellyfish project \n                   \n                     Jellywatch \n                   \n                     Daniel Pauly's Sea Around Us Project \n                   \n                     Claudia Mills \n                   Reprints and Permissions"},
{"file_id": "482023a", "url": "https://www.nature.com/articles/482023a", "year": 2012, "authors": [{"name": "Maryn McKenna"}], "parsed_as_year": "2006_or_before", "body": "For decades, Robert Daum has studied the havoc wreaked by methicillin-resistant  Staphylococcus aureus . Now he thinks he can stop it for good. Over the years, Robert Daum has learned to respect his adversary. In 1995, he and his co-workers at the University of Chicago children's hospital in Illinois were investigating infections that had affected two dozen children in their emergency department. Three children had fast-moving pneumonia. A fourth had an abscess the size of his fist buried in the muscle of one buttock. In a fifth, the bacterium had infiltrated the bones of one foot. The infections were resistant to many common antibiotics, including methicillin. To Daum's surprise, the culprit was MRSA \u2014 methicillin-resistant  Staphylococcus aureus  \u2014 a bacterium that was thought to spread only among hospital inpatients. But none of these kids had been to the hospital for months before becoming ill. Few researchers were willing to accept the implications. Daum wrangled for 18 months with editors at the  Journal of the American Medical Association  over a paper reporting the cases and showing that this strain was dangerous, acquired in the community and differed genetically from hospital strains. His article 1  was eventually published in 1998 and is now widely considered to be the early warning of an epidemic that currently results in millions of visits to doctors and hospitals a year 2 . Daum, a paediatric infectious-disease physician and founder of the University of Chicago's MRSA Research Center, is still raising the alarm about the epidemic. He sees the fight as more urgent than ever, and now thinks he knows how to win it. A few days before Christmas, he and Brad Spellberg, a physician who conducts vaccine research at the University of California, Los Angeles, published an article 3  calling for a vaccine that would vanquish  S. aureus . \u201cWe can't treat this,\u201d Daum says. \u201cWe have to prevent it.\u201d This time, Daum's views have more support. Over the past 10 years, as MRSA has become resistant even to last-resort antibiotics, several pharmaceutical companies have launched research programmes for vaccines, some with Daum's input. But Daum contends that they underestimate the enemy by relying on the standard immunological approach of triggering the production of protective antibodies. Instead, he advocates a strategy that stimulates T cells, part of a different branch of the immune system. It is an ambitious proposal and not all infectious-disease specialists are convinced that it will work. \u201cIt is a provocative idea,\u201d says Gerald Pier, a microbiologist at Harvard Medical School in Boston, Massachusetts, who also works on  S. aureus  vaccines. \u201cBut it is still too early to know how applicable this component of immunity would be to vaccine development.\u201d \n               Evidence for an epidemic \n             It took a while for the field to agree with Daum that a new epidemic had begun. Attitudes began to shift around 18 months after his seminal paper, when investigators for the Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia, reported that four children in Minnesota and North Dakota had died from infections similar to those in Daum's hospital. After that, the CDC and hospitals found clusters of community-associated infections in jails and prisons, then in sports teams, then in unusually high numbers of patients in emergency departments. Physicians, too, were reporting unexpected cases of grave illness \u2014 necrotizing pneumonia and flesh-eating disease \u2014 all caused by the community-associated strain. From there, the epidemic grew. By one estimate, community-acquired MRSA accounts for half of the more than 14 million skin and soft-tissue infections that send people to doctors and emergency departments in the United States every year 2 . MRSA also causes around 100,000 serious blood infections and more than 15,000 deaths a year. Meanwhile, pharmaceutical manufacturers are backing away from making new antibiotics, arguing that resistance is undermining compounds too quickly for them to recoup their costs. A study by staff at the CDC's Division of Healthcare Quality Promotion estimates that an  S. aureus  vaccine given to vulnerable groups could reduce the number of serious MRSA infections by 24,000\u201334,000 cases per year 4 . Researchers familiar with vaccine development say that manufacturers have recognized the potential market. \u201cYou can see it within the industry now. They are all interested,\u201d says Jean Lee, an  S. aureus  vaccine researcher at Harvard Medical School. \u201cTen years ago, that wasn't the case.\u201d But getting from interest to a viable formula is proving a formidable challenge. \n               Shot in a different arm \n             Since Edward Jenner first scratched cowpox virus into a boy's arm 216 years ago, vaccination has mostly proceeded along variations of one strategy: introducing into the body an antigen, such as a weakened disease organism or a fragment of an organism. The immune system responds by producing an antibody, a protein that recognizes the antigen and triggers an immune attack on the organism. For years, the presence of antibodies has been taken as a sign that a person will be immune to later infection. The first attempt at making a  S. aureus  vaccine was modelled on successful vaccines for  Streptococcus pneumoniae  and  Haemophilus influenzae . Like them, it used antigens consisting of carbohydrate molecules from the sticky capsule surrounding the bacterium, attached to a protein produced by another bacterium. But the formula, called StaphVax and developed by Nabi Biopharmaceuticals in the late 1990s, was unsuccessful. When the company tested it in 1998\u201399 in a phase III trial 5 , the recipients made antibodies, but then developed  S. aureus  infections in their blood at the same rate as those who received placebo. The programme was suspended in 2005 and sold to GlaxoSmithKline in 2009. Merck, meanwhile, created a formula that used a cell-surface protein involved in the bacterium's ability to take up iron. It cancelled late-phase clinical trials in June last year because of negative results. In retrospect, Daum says, no one should have expected an  S. aureus  vaccine to be that easy. \u201cThis organism has multiple strategies for accomplishing all its tasks, from invading the blood stream to elaborating toxins to causing local skin abscesses,\u201d he says. \u201cTargeting a vaccine against just one of them merely eggs the bug on.\u201d Unlike most pathogens,  S. aureus  is a commensal organism; it lives on the skin and in the nostrils of up to one-third of humans, mostly without causing disease. This benign but continual occupation means that much of the population already has antibodies to the bacterium. And unlike many infections, having it once is no guarantee of protection; roughly one in four people who have one  S. aureus  infection will go on to develop another. So vaccine developers don't really know what characterizes an immune individual. \u201cWe're working without any information as to what constitutes high-level immunity to  S. aureus  infection,\u201d says Pier. Still, some companies are attempting to build immunity using an all-out antibody attack: Pfizer, Novartis and GlaxoSmithKline are testing formulas packed with four or five antigens, hoping to elicit an array of antibodies that will overwhelm the bacterium's defences. Several other companies are trying passive immunization \u2014 delivering antibodies harvested from people \u2014 but none has yet achieved results better than placebo. The team that may have edged closest to success is actually on Daum's own campus. Microbiologist Olaf Schneewind, who is not affiliated with Daum's group, has developed a formula that incorporates a mutated version of a cell-wall component of  S. aureus  called protein A. Under normal circumstances, protein A binds to antibodies, protecting the bacterium from attack by the immune system; the mutant version, however, is unable to bind. So far, the formula has been tested only in mice 6 . Daum is familiar with the failed-vaccine landscape, not just from his consulting work with pharmaceutical companies, but also from serving on the US Food and Drug Administration's Vaccine and Related Biological Products Advisory Committee. At the same time, his research into how  S. aureus  is able to cause disease in so many tissues and its bristling array of defences against the immune system convinced him that a new approach was needed. When Daum discusses  S. aureus , he is blunt about the challenges and impatient to move ahead. \u201cI don't think multiple antigens are enough,\u201d he says, sitting in the old hospital building where he spotted the first community-acquired MRSA cases, now transformed into overcrowded offices stacked with piles of journals. \u201cI think we need multiple immunological mechanisms. And I think the central one should be something that has been considered heresy up to now.\u201d \n               Lucky break \n             The heretical approach was inspired, in part, by a patient. As part of an ongoing project to root out the causes of recurring infections, in 2009 two of Daum's team members went to the home of a toddler who had recently been in the emergency department. But the girl wasn't there; she was in the hospital's intensive-care unit with a new infection. When Daum tracked her down, he noticed something odd in her records. She had had unusually frequent abscesses and repeated bouts of pneumonia. Acting on a hunch, Daum teamed up with Steven Holland, chief of the clinical infectious diseases laboratory at the National Institute of Allergy and Infectious Diseases in Bethesda, Maryland, to carry out a detailed genetic analysis. Daum's hunch was right: the girl had a mutation that Holland had recently linked to a rare immunodeficiency called Job's syndrome 7 . People with the syndrome have persistent, smouldering  S. aureus  infections, owing to an inability to make a type of lymphocyte, or immune cell, called a T H 17 cell. These cells, which make a proinflammatory protein called interleukin-17, have become a hot topic in vaccine research. They are produced by a different branch of the immune system from the one that makes antibodies, yet they still seem to be involved in the body's memory of exposures to pathogens. Daum believes that T H 17 cells are the key to an  S. aureus  vaccine. \u201cIt looks like T cells are very important in staphylococcal immunity,\u201d he says. Spellberg demonstrated in 2009 that a vaccine that stimulated production of interleukin 17 could protect mice against infections of  S. aureus  and  Candida albicans 8 . (That vaccine is now being developed by NovaDigm Therapeutics as NDV3.) Daum and Spellberg have now joined forces and formed a cross-disciplinary team to see whether boosting the activity of T H 17 cells can prevent S.  aureus  infections in humans. The team includes an intensive-care specialist who has developed animal models to study these infections; an epidemiologist; two immunologists; and a biomedical engineer. They have begun by selecting current and former patients with MRSA from the University of Chicago's hospitals and comparing their immunological activity with that of people who have never had MRSA. In a second phase, they will test how lymphocytes harvested from the patients react to a number of infectious organisms, including MRSA. The project will face significant challenges, Spellberg points out. \u201cOne of the reasons the vaccine world has always been so focused on antibodies is because it's so easy to measure antibodies,\u201d he says. \u201cThere is no high-throughput T-cell assay. It takes a lot of work.\u201d \n               Far from final \n             If the team can succeed in boosting T-cell activity, it will still be only part of a solution. The group has to consider whether to include a traditional antibody-stimulating antigen in a vaccine, and whether to add a third component, such as protein A. The researchers must also work out whether one vaccine formula can stop  S. aureus  from invading many types of tissue. \u201cWe want a vaccine that prevents invasive disease, we want a vaccine that prevents pneumonia and we want a vaccine that prevents skin infections,\u201d Daum says. \u201cCan one vaccine solve three separate clinical problems?\u201d The researchers will have to manoeuvre around  S. aureus 's dual role as pathogen and commensal bacterium. If they wipe out the body's benign staph occupiers, a more harmful organism might take their place. Daum and his collaborators will also have to face down scepticism from other staph researchers, who view the T H 17 idea as intriguing but impractical. Schneewind points out that the US Food and Drug Administration's rules require a vaccine to demonstrate antibody production to win licensure. \u201cI am not aware of any vaccine licence where the correlate of protective immunity is IL-17 response,\u201d he says. But given the surge of interest in T H 17 cells, he adds, \u201cpeople will try it, and we'll see how far they get\u201d. Perhaps the most difficult question to answer is: who should get an  S. aureus  vaccine? Because community-acquired MRSA is so widespread, the maximum benefits might come only if the vaccine is administered to everyone. But with a great deal of suspicion of vaccines in the United States and elsewhere, an addition to the routine immunization schedule is likely to be met with resistance. Mention these concerns to Daum, and the trademark impatience break through. \u201cThis is a universal epidemic, and there should be a universal vaccine,\u201d he says. \u201cI think we should put this into the paediatric vaccine schedule in the first year of life. And if it happened to work on all MRSA syndromes, like the skin infections that flood our emergency room, then we would have something wonderful on our hands.\u201d \n                     Superbug family tree sketched out 2010-Jan-21 \n                   \n                     MRSA \"hiding in hospital sinks and vases\" 2006-Mar-01 \n                   \n                     Nature \u2019s vaccine special \n                   \n                     Robert Daum \n                   \n                     CDC's Active Bacterial Core surveillance \n                   Reprints and Permissions"},
{"file_id": "482294a", "url": "https://www.nature.com/articles/482294a", "year": 2012, "authors": [{"name": "Bijal P. Trivedi"}], "parsed_as_year": "2006_or_before", "body": "Susan Lindquist has challenged conventional thinking on how misfolded proteins drive disease and may power evolution. But she still finds that criticism stings. On a frigid winter's morning in 1992, Susan Lindquist, then a biologist at the University of Chicago in Illinois, trudged through the snow to the campus's intellectual-property office to share an unconventional idea for a cancer drug. A protein that she had been working on, Hsp90, guides misfolded proteins into their proper conformation. But it also applies its talents to misfolded mutant proteins in tumour cells, activating them and helping cancer to advance. Lindquist suspected that blocking Hsp90 would thwart the disease. The intellectual-property project manager she met with disagreed, calling Lindquist's idea \u201cridiculous\u201d because it stemmed from experiments in yeast. His \u201csneering tone\u201d, she says, left an indelible mark. \u201cIt was actually one of the most insulting conversations I've had in my professional life.\u201d It led her to abandon her cancer research on Hsp90 for a decade. Today, more than a dozen drug companies are developing inhibitors of the protein as cancer treatments. Lindquist seems able to shrug off such injustices, now. Her work over the past 20 years has consistently challenged standard thinking on evolution, inheritance and the humble yeast. She has helped to show how misfolded infectious proteins called prions can override the rules of inheritance in yeast, and how this can be used to model human disease. She has also proposed a mechanism by which organisms can unleash hidden variation and evolve by leaps and bounds. She was the first female director of the prestigious Whitehead Institute for Biomedical Research in Cambridge, Massachusetts, and has received more than a dozen awards and honours in the past five years. In a paper being published this week in  Nature , she and her colleagues show that in wild yeast, prions provide tangible advantages, such as survival in harsh conditions and drug resistance 1 . What is most striking about Lindquist, however, is that despite having the self-confidence to take on controversial projects, she remains remarkably sensitive to criticism. The sting of rejection from the Chicago intellectual-property office may have dulled, but she recognizes and is dismayed by what she sees as a growing incivility among colleagues, a meanness that she thinks threatens the progress of science. \u201cI feel like the profession is getting less and less genteel and more and more cut-throat,\u201d she says. \n               Heating up research \n             Lindquist began her career at Harvard University in Cambridge, Massachusetts, in 1971, in the laboratory of Matthew Meselson, a biochemist famous for helping to show how genetic information is copied and inherited. \u201cHe was a brilliant scientist,\u201d Lindquist says, but when she started he was spending much of his time lobbying for a federal ban on biological weapons in the United States. \u201cSo he was never here.\u201d Susan Lindquist explains how prion proteins show their useful side in her latest work She found the lack of a mentor very stressful in those early days. \u201cIt was terrifying and I almost left a couple of times,\u201d she says. Working more or less on her own, Lindquist decided to probe a mysterious phenomenon that researchers were exploring, called the heat-shock response. When fruitfly larvae are exposed to high temperatures, certain regions of their chromosomes 'puff up' as genes at these sites frenetically produce RNA. In work that would culminate in her PhD and eventually shape her career, Lindquist showed that applying heat to cultured fruitfly cells triggers an emergency response in which the cells manufacture heat-shock proteins, such as Hsp90, to protect themselves 2 . When Lindquist published her data, she says, \u201can awful lot of people thought it was nonsense\u201d. Colleagues dismissed the findings as an artefact \u2014 the result of heat denaturing proteins. Although the work was published in a prestigious journal, Lindquist took the criticisms hard. Her lab mate, collaborator and close friend at the time Steven Henikoff \u2014 now at the Fred Hutchinson Cancer Research Center in Seattle, Washington \u2014 wondered, \u201cHow can such a nice person survive\u201d in this field? With her newly minted PhD, Lindquist started a postdoctoral fellowship in 1976 at the University of Chicago. Two years later, the university offered her a tenure-track position. Lindquist became interested in studying heat-shock proteins in yeast, partly because it would allow her to manipulate genes more easily than in flies. A faculty member warned her against changing organisms until she had tenure, but Lindquist ignored the advice, assuming that she had little chance of getting tenure anyway. \u201cIt was really very, very difficult being a woman in science then,\u201d she says. So she pursued what she found most mysterious and fascinating. That courage often seems to be lacking in younger scientists these days, Lindquist laments. She recalls struggling to convince students or postdocs to take on risky projects, only to learn later that when they did, their lab mates mocked them. \u201cThat shocks me,\u201d says Lindquist. She has often been afraid of being wrong \u2014 a fear that led to lots of repeated experiments \u2014 but \u201cI didn't have a fear of a new idea\u201d. Most of the new ideas Lindquist has developed met with resistance. In late 1993, when she proposed that a heat-shock protein called Hsp104 could untangle and dismantle clumps of protein,  Nature  initially rejected her paper. The ideas struck many as absurd, Lindquist says. \u201cWhen I gave a talk about it, reactions ranged from scepticism to outright disbelief.\u201d The work was eventually published the following year 3 . Still, she was literally staring at her rejected manuscript when she received a call from Yury Chernoff, then a postdoc in Susan Liebman's lab at the University of Illinois at Chicago, who had found that Hsp104 influenced a bizarre colour trait in some yeast strains. Geneticist Brian Cox, then at the University of Liverpool, UK, first described this trait 4 , called [ PSI + ], in yeast in 1965. Cox noted that when white yeast strains mate with red ones their progeny produce only white offspring, rather than the mixture of red and white predicted by conventional genetic theory. According to one hypothesis, the trait was actually passed on not by genes but by a misfolded protein that worked like the self-replicating, disease-causing prions known to trigger fatal neurological disorders such as Creutzfeldt\u2013Jakob disease. Prions join together to form long, 'amyloid' fibres. Working with Chernoff, Lindquist showed how Hsp104 controls the [ PSI+ ] trait by chopping up fibres of a protein called Sup35 (ref.  5 ). Short segments of these Sup35 fibres are passed to daughter cells and act as a template for more to form. Watching the yeast prions pass from mother cell to daughter cell was \u201cpretty magical\u201d, Lindquist says. Moreover, the results suggested that simple yeast cells could be used to study the proteins that cause neurodegenerative disorders in humans \u2014 another idea that colleagues found hard to swallow. For the next 15 years, Lindquist expanded her study of yeast prions. Chernoff, now editor-in-chief of the journal  Prion  and based at the Georgia Institute of Technology in Atlanta, says that Lindquist pioneered many of the biochemical and molecular techniques now used for studying yeast prions. But her controversial hypotheses, he says, have really driven the field forward and provoked discussion and new experiments. Lindquist suggested that yeast prions are widespread and may be beneficial in some cases because they are able to switch between soluble, active states and fibrous, inactive states 6 . Many have suggested that the prions she has been observing are artefacts of laboratory culture techniques that force proteins to behave in unnatural ways. But in her most recent paper 1 , Lindquist has shown that about one-third of the 700 or so wild yeast strains she examined harboured prions. In almost half of those strains, the prion seems to confer a beneficial trait. For example, a strain isolated from white wine is resistant to acidic environments and to the anti-fungal drug fluconazole; and a strain harvested from Lambrusco grapes is resistant to a DNA-damaging agent. When the prions in these strains are eradicated or 'cured', these useful traits disappear. Lindquist has also continued her studies of Hsp90. When, in the 1990s, she disabled, or knocked out, both copies of the gene that makes Hsp90 in fruitflies, the creatures died; but when she knocked out just one copy, something mysterious happened. Flies were born with a hodgepodge of physical deformities, such as shrunken or square eyes, shrivelled wings and crooked legs 7 . Lindquist realized that Hsp90 was chaperoning proteins that contain detrimental mutations into a working form, thereby hiding their effects. Removing half the Hsp90 meant there wasn't enough of it to go around, proteins could no longer fold correctly, and the effects of all the hidden mutations became apparent. Lindquist hypothesized that the same thing happens during a natural crisis such as starvation or a change in temperature or pH. The environmental shock makes more proteins misfold and these suck up the available Hsp90, leaving a surplus of incorrectly folded proteins that could spawn the evolution of new traits. Most of this misfolding will be bad, says Lindquist. But if any of it yields a cell that is well adapted to the new conditions, some organisms could survive and thrive. Lindquist calls Hsp90 a \u201ccapacitor\u201d for evolutionary change. Just as an electrical capacitor stores electrical energy, Hsp90 lets hidden variation build up in the genome. When an environmental stressor trips the switch, dramatic variations can be unleashed. She found the same kinds of effects in the plant  Arabidopsis thaliana  \u2014 upturned and extra roots, exotic leaf whorls and darker hues appeared when the heat-shock protein system was put under stress 8 . Lindquist suggests that studying this phenomenon would be a powerful approach for discovering hidden variation in plants \u2014 unlocking the basis of traits such as drought resistance or salt tolerance. Lindquist says she was unaware that these ideas would upset people. Many in the evolutionary-biology community adhere to the idea that evolution proceeds in slow, tiny steps, not the big bursts she was proposing. Nick Barton, an evolutionary geneticist at the University of Edinburgh, UK, says that the suggestion that the chaperone system releases \u201cuseful\u201d variation when needed is controversial. \u201cI really don't think there is much evidence for an adaptive role,\u201d he says. Others are more open to the hypothesis. This mechanism should be incorporated into evolutionary theory, says Massimo Pigliucci, an evolutionary biologist and philosopher at the City University of New York Graduate Center. Pigliucci says that Lindquist \u201cput empirical meat on ideas that have been around for a while\u201d. Still, he asks, \u201cHow important are these in the evolution of lineages?\u201d It may take another 20 years to work that out, he says. In August 2001, Lindquist moved from the University of Chicago to take the helm of the Whitehead Institute. It was an honour, but also a draining position that she held for only three years. She oversaw the separation of Whitehead from its genome centre, a sequencing powerhouse that had contributed much of the data for the Human Genome Project. It was a financially messy ordeal that left her desperate to focus on science, and particularly on disease-related research. Even though she hasn't been the one to develop them, Hsp90 inhibitors have already begun to show some promise. More than 20 clinical trials are exploring their effect in cancer. \u201cIt's a hot topic,\u201d says Len Neckers, a cancer biologist at the National Cancer Institute in Rockville, Maryland, who identified the first Hsp90 inhibitor 20 years ago. The inhibitors might also target drug-resistant fungi that cause deadly infections in people with suppressed immune systems 9 . Lindquist's expertise in protein folding fuelled an interest in neurodegenerative diseases. Amyloid fibres are also present in Alzheimer's, Parkinson's and Huntington's diseases, and Lindquist has championed yeast as a model for studying their effects in these conditions. In a study published last year 10 , she showed that a pile-up of the amyloid-\u03b2 protein, a hallmark of Alzheimer's, is toxic to yeast, slowing its growth. She then used the model to screen 5,000 yeast genes for ones that might affect this toxicity. The approach was successful: it turned up 40 genes, 12 of which had human homologues, and one of which is a known risk factor for Alzheimer's. Two others interact with known risk factors. Her hope is to pin down in yeast the initial steps that lead to amyloid formation in Alzheimer's, then to identify drugs that prevent it. The approach continues to raise eyebrows, however. \u201cMany wondered how she could possibly model things such as Alzheimer's and Parkinson's in yeast \u2014 which are a single cell, have a short life span and, of course, don't have a brain,\u201d says Nancy Bonini, a neurogeneticist at the University of Pennsylvania in Philadelphia. Her grant applications have received \u201cvery mixed reviews\u201d, says Lindquist \u2014 a charitable description, she adds. Many hardworking scientists with great ideas get their proposals turned down, she says, but she worries that the tough funding climate is dragging down the tone of grant and paper reviews. \u201cThey get exhausted, tired, and they get cranky. And then they get a paper to review.\u201d She pauses, leans forward and says emphatically, \u201cI think we have to stop and say, 'No, let's not do this. Let's not be mean to somebody else because someone was mean to you'.\u201d Meselson, she says, instilled in her the importance of ethical and compassionate scientific conduct. It is something she has worked hard to emulate and pass on to her own trainees. In late-2010, she wrote a short commentary 11  entitled 'Three quite different things that matter to me'. Think and train broadly, she wrote; be kind, be generous, don't try to destroy someone; and, have faith. Her work and the testaments of colleagues speak to her success with the first two, and her own words attest to the last: \u201cWhen I think about my kids' future I feel very concerned,\u201d she says, tearing up as she lists the world's environmental, social, economic and political woes. \u201cAnd then I go to a lecture. I'll hear someone get up and talk about their work, and they've done something amazing. The profession that I live and breathe gives me hope.\u201d \n                     The beneficial side of prions 2009-Apr-02 \n                   \n                     Prions speed evolution 2004-Aug-16 \n                   \n                     Prion proteins may store memories 2003-Dec-30 \n                   \n                     Hidden evolution 1998-Dec-03 \n                   \n                     Lindquist Lab \n                   Reprints and Permissions"},
{"file_id": "482290a", "url": "https://www.nature.com/articles/482290a", "year": 2012, "authors": [{"name": "Jeff Tollefson"}], "parsed_as_year": "2006_or_before", "body": "A South African archaeologist digs into his own past to seek connections between climate change and human development. Metal scrapes on hard sand as archaeologist Chris Henshilwood shaves away the top layer of sediment in Blombos Cave. After just a few moments, the tip of his trowel unearths the humerus of a pint-sized tortoise that walked the Southern Cape of South Africa many millennia ago. Next come shells from local mussels and snails amid blackened soil and bits of charred wood, all remnants of an ancient feast. It was one of many enjoyed by a distinct group of early humans who visited Blombos Cave over the course of thousands of years. The Still Bay culture was one of the most advanced Middle Stone Age groups in Africa when it emerged some 78,000 years ago in a startlingly early flourishing of the human mind. Henshilwood's excavations at Blombos Cave have revealed distinctive tools, including carefully worked stone points that probably served as knives and spear tips, and bits of rock inscribed with apparently symbolic designs. But evidence of the technology disappears abruptly in sediment about 71,000 years old, along with all proof of human habitation in southern Africa. It would be 7,000 years before a new culture appeared, with a markedly different toolkit, including crescent-shaped blades probably used as arrowheads. What drove the coming and going of these early cultures? At about the time the Still Bay culture disappeared, the globe \u2014 already in the middle of a glacial period \u2014 began to cool even further, causing sea levels to fall (see 'Crucible of culture'). \u201cHumans are very adaptable,\u201d says Henshilwood, \u201cbut I think climate must have played some role in the demise of the Still Bay.\u201d If there is a link, it may hold broader implications. Genetic data suggest that the entire population of modern humans contracted at around the same time, then rebounded and expanded in Africa and onto other continents. Multiple teams are now racing to determine the part climate might have played in driving human evolution during this period. Blombos Cave, with its detailed archaeological record of the Middle Stone Age, could become a key testing ground. With Francesco d'Errico, an anthropologist at the French National Centre for Scientific Research (CNRS) in Bordeaux, Henshilwood has assembled a team of archaeologists, climate modellers and palaeoclimatologists for a five-year, \u20ac2.5-million (US$3.3-million) project to look at correlations between climate and culture during the eventful span of prehistory that includes Still Bay, and the beginnings of modern human behaviour. \u201cThese are very daunting questions indeed, but I think they are answerable,\u201d says Henshilwood, a native of Cape Town who now works at the University of Bergen in Norway. \u201cIf we can get some good climatic data, we can at least hazard some guesses.\u201d \n               Personal history \n             Outside the cave, a cool November breeze scours the steep slope to the shore, which Henshilwood has known since he was a child. His grandfather bought this land on the Southern Cape as a fishing retreat in 1961 and Henshilwood spent his holidays searching the hills and caves for ancient artefacts. Those experiences served him well in 1985, when, out of sheer boredom in his mid-thirties, he decided to leave the family department-store business and enrol in an archaeology course at the University of Cape Town. In 1991, as a PhD student on a scholarship at the University of Cambridge, UK, he returned to Blombos in search of the same kind of artefacts that he had found as a child. What he discovered was much more significant and far older: a series of bone tools and double-sided stone points that were clearly tied to the enigmatic Still Bay period. \u201cIt was right over there,\u201d he says, motioning to the back of the cave. \u201cNobody believed us, because nobody had found a Still Bay site for 40 years.\u201d The Middle Stone Age was not part of his thesis, so Henshilwood covered the site up and moved on. Only in 1997 did he secure funding for a full excavation from the US National Science Foundation. In 2002, Henshilwood published a study 1  in  Science  documenting pieces of red, iron-rich rock called ochre, which were engraved with cross-hatched patterns. He argued that the 77,000-year-old etchings were examples of symbolic behaviour and represented the earliest known evidence of abstract thought. These and other findings have challenged the once-dominant idea that human culture \u2014 as exemplified by art such as carvings and jewellery \u2014 appeared in an explosive transformation during the Late Stone Age, some 40,000\u201350,000 years ago, in north Africa and Europe. Blombos and other sites suggest a more gradual cultural and technological development, beginning far earlier, during the Middle Stone Age throughout Africa. On a visit to Blombos in November, the cave looks like a war bunker, complete with a generator, lights and sandbags. The team has excavated just enough earth to create a workspace for a crew of five. Hundreds of steel tabs mark strata on vertical walls of sediment. While Henshilwood works on the cave's top layer, from 72,000 years ago, his partner and co-excavator, Karen van Niekerk, sifts through the bottom strata of sediments, which are roughly 100,000 years old. Centimetres away, the same layer yielded Henshilwood's most recent blockbuster find 2 : a toolkit of shells, grindstones and crushing stones used to process and store ochre, possibly for use as pigment or for utilitarian purposes such as tanning hides or cleaning wounds. It was further evidence that  Homo sapiens  had developed planning skills and sophistication far earlier than was once believed. Now a postdoctoral researcher at the University of Bergen, van Niekerk has been working with Henshilwood since the early days at Blombos. It's a good life, she says, \u201cand a lot of work\u201d. On this day she finishes early and heads to Henshilwood's beach house and scientific base to help a master's student, Cornelia Albrektsen, to conduct an experiment using home-made stone and bone tools. They struggle for the better part of an hour trying to replicate the way ancient people might have opened shellfish. Then Henshilwood shows up. \u201cGive me one,\u201d he says, grabbing a shell. Within minutes, Henshilwood pops open several snails and determines which tools work best. He then departs to clean up for dinner, leaving the stunned crew to finish the experiment. \u201cIt was really impressive,\u201d Albrektsen says later. \u201cHe was getting all caveman-like.\u201d During a break in the excavations, Henshilwood stares out to sea and wonders aloud whether the Indian Ocean holds answers. Palaeoclimate records from marine sediment and ice cores suggest 3  that around the time the Still Bay culture disappeared, global temperatures dropped and the polar ice sheets grew. Ocean levels fell, and the Still Bay people may have followed the sea onto the continental shelf, which would have become a productive plain. If this idea is accurate, most of the evidence would have been submerged as the ocean returned over the past 15,000 years. Henshilwood has hiked along more than 240 kilometres of coastline in search of caves that might hold clues to the fate of the Still Bay. He hasn't found any yet, but he is beginning excavations on a site called Klipdrift Shelter, west of Blombos, that could allow him to look at the rise of Still Bay's successor: the Howiesons Poort culture, which appeared 65,000 years ago and persisted for about 5,000 years. \n               Time and tide \n             Taking a break from Blombos, Henshilwood visits the new site with Simon Armitage, a mineral-dating specialist at Royal Holloway University of London. Armitage uses a technique called optically stimulated luminescence to determine the last time a sample of dirt saw sunlight before being buried. The method requires Henshilwood and others to cover Armitage with a thick black tarpaulin and sit on its edge to prevent any light from fouling the measurements. While waiting, Henshilwood talks about the significance of the site, which has already yielded a human tooth and some artefacts with markings that could be engravings. He says the findings may turn out to be more fascinating than the decorated ochre pieces that made Blombos famous. Geochronologist Simon Armitage goes under cover to determine the age of sediments at the Klipdrift shelter in South Africa. Once the site has been dated, the researchers will add it to environmental and cultural records from southern Africa and Europe. To construct a climate record, Henshilwood's team is sampling cave deposits, in search of clues to ancient rainfall and temperatures. They are also testing ocean sediment cores for pollen and traces of charcoal that hint at vegetation, rainfall and the frequency of fires. The palaeoclimate data will allow a team at the CNRS to build a high-resolution model of climate in Europe and southern Africa, beginning with the time spanning the Still Bay and Howiesons Poort cultures. The last step is to overlay the climate and cultural data onto an ecological model to analyse the environmental space occupied by specific cultures throughout time. The team can then look for links. Was one industry, for example, always associated with a particular environment? Do similar cultures occupy similar landscapes or respond to climatic shifts in similar ways? \u201cWe can start to test our hypotheses about the role of ecology and the environment,\u201d says William Banks, who runs the modelling at the CNRS in Bordeaux. Henshilwood and his colleagues have some friendly competition. Curtis Marean, an archaeologist at Arizona State University in Tempe, came to the cape shortly after Henshilwood, inspired by the genetic evidence of a population crash in the Middle Stone Age and thinking that the cape would have been a good place for humans to ride out hard times. He partnered with Henshilwood on a paper 4  examining bone tools from Blombos in 2001 and went on to document the use of pigments 5  and heat-treatment of stone tools 6  164,000 years ago at Pinnacle Point, less than 100 kilometres east of Blombos. He is also looking to the sea for answers. Marean and a team of researchers have already produced an assessment 3  of historical sea levels around Pinnacle Point, and now they have received money from the National Geographic Society in Washington DC and the US National Science Foundation to build a detailed geophysical map of the continental shelf. Marean thinks that the exposed shelf would have been a diverse shrubland ecosystem with edible roots, big game for hunting and marine resources. His goal is to reconstruct the vegetation, and then use models to analyse how people might have exploited those resources. \u201cWe need to develop a thick empirical record and put that into a really tight timescale,\u201d says Marean. \u201cOnce we have that, we can start debating the whys.\u201d Alison Brooks, director of the Center for the Advanced Study of Hominid Paleobiology at the George Washington University in Washington DC, says that Henshilwood and others are producing much-needed data and hypotheses, but she warns against the dangers of oversimplification. Brooks is co-authoring a forthcoming publication that aligns palaeoclimate data with archaeological data throughout Africa, and she says that each region of the continent seems to have has its own story. \u201cThere's a lot of complexity here,\u201d she says. Henshilwood acknowledges that comparing environmental and cultural data may not yield concrete answers. The disappearance of the Still Bay, he says, could have resulted from climatic change, migration, the arrival of new people or simply cultural evolution over the course of thousands of years. Back in the cave, Henshilwood settles down into a familiar routine: digging carefully through the sediments and thinking about the past. He uncovers the remains of a clam that lives along sandy beaches and a mussel that prefers rocky shores, evidence that the Still Bay people had access to a varied coastline much like the one he has been exploring all his life. Just behind Henshilwood is another hole, carefully filled with sandbags. He dug that in 2007 as a test plot and found that the sediments inside Blombos date back at least 130,000 years, with artefacts dispersed throughout. \u201cBut that's for another day,\u201d he says, glancing at the wall of dirt in front of him. \u201cOr another year, another decade.\u201d See Books & Arts  page 304 \n                     Archaeologists land world's oldest fish hook 2011-Nov-24 \n                   \n                     African cave's ancient ochre lab 2011-Oct-13 \n                   \n                     Ancient jewellery found in African cave 2004-Apr-16 \n                   \n                     Art history doubles 2002-Jan-11 \n                   \n                     Chris Henshilwood's project \n                   \n                     Curtis Marean \n                   Reprints and Permissions"},
{"file_id": "482456a", "url": "https://www.nature.com/articles/482456a", "year": 2012, "authors": [{"name": "M. Mitchell Waldrop"}], "parsed_as_year": "2006_or_before", "body": "Henry Markram wants \u20ac1 billion to model the entire human brain. Sceptics don't think he should get it. It wasn't quite the lynching that Henry Markram had expected. But the barrage of sceptical comments from his fellow neuroscientists \u2014 \u201cIt's crap,\u201d said one \u2014 definitely made the day feel like a tribunal. Officially, the Swiss Academy of Sciences meeting in Bern on 20 January was an overview of large-scale computer modelling in neuroscience. Unofficially, it was neuroscientists' first real chance to get answers about Markram's controversial proposal for the Human Brain Project (HBP) \u2014 an effort to build a supercomputer simulation that integrates everything known about the human brain, from the structures of ion channels in neural cell membranes up to mechanisms behind conscious decision-making. Markram, a South-African-born brain electrophysiologist who joined the Swiss Federal Institute of Technology in Lausanne (EPFL) a decade ago, may soon see his ambition fulfilled. The project is one of six finalists vying to win \u20ac1 billion (US$1.3 billion) as one of the European Union's two new decade-long Flagship initiatives. \u201cBrain researchers are generating 60,000 papers per year,\u201d said Markram as he explained the concept in Bern. \u201cThey're all beautiful, fantastic studies \u2014 but all focused on their one little corner: this molecule, this brain region, this function, this map.\u201d The HBP would integrate these discoveries, he said, and create models to explore how neural circuits are organized, and how they give rise to behaviour and cognition \u2014 among the deepest mysteries in neuroscience. Ultimately, said Markram, the HBP would even help researchers to grapple with disorders such as Alzheimer's disease. \u201cIf we don't have an integrated view, we won't understand these diseases,\u201d he declared. As the response at the meeting made clear, however, there is deep unease about Markram's vision. Many neuroscientists think it is ill-conceived, not least because Markram's idiosyncratic approach to brain simulation strikes them as grotesquely cumbersome and over-detailed. They see the HBP as overhyped, thanks to breathless media reports about what it will accomplish. And they're not at all sure that they can trust Markram to run a project that is truly open to other ideas. \u201cWe need variance in neuroscience,\u201d declared Rodney Douglas, co-director of the Institute for Neuroinformatics (INI), a joint initiative of the University of Zurich and the Swiss Federal Institute of Technology in Zurich (ETH Zurich). Given how little is known about the brain, he said, \u201cwe need as many different people expressing as many different ideas as possible\u201d \u2014 a diversity that would be threatened if so much scarce neuroscience research money were to be diverted into a single endeavour. Markram was undeterred. Right now, he argued, neuroscientists have no plan for achieving a comprehensive understanding of the brain. \u201cSo this is the plan,\u201d he said. \u201cBuild unifying models.\u201d \n               Markram's big idea \n             Markram has been on a quest for unity since at least 1980, when he began undergraduate studies at the University of Cape Town in South Africa. He abandoned his first field of study, psychiatry, when he decided that it was mainly about putting people into diagnostic pigeonholes and medicating them accordingly. \u201cThis was never going to tell us how the brain worked,\u201d he recalled in Bern. His search for a new direction led Markram to the laboratory of Douglas, then a young neuroscientist at Cape Town. Markram was enthralled. \u201cI said, 'That's it! For the rest of my life, I'm going to dig into the brain and understand how it works, down to the smallest detail we can possibly find.'\u201d That enthusiasm carried Markram to a PhD at the Weizmann Institute of Science in Rehovot, Israel; to postdoctoral stints at the US National Institutes of Health in Bethesda, Maryland, and at the Max Planck Institute for Medical Research in Heidelberg, Germany; and, in 1995, to a faculty position at Weizmann. He earned a formidable reputation as an experimenter, notably demonstrating spike-timing-dependent plasticity \u2014 in which the strength of neural connections changes according to when impulses arrive and leave ( H. Markram  et al .  Science   275,  213\u2013215; 1997 ). By the mid-1990s, individual discoveries were leaving him dissatisfied. \u201cI realized I could be doing this for the next 25, 30 years of my career, and it was still not going to help me understand how the brain works,\u201d he said. To do better, he reasoned, neuroscientists would have to pool their discoveries systematically. Every experiment at least tacitly involves a model, whether it is the molecular structure of an ion channel or the dynamics of a cortical circuit. With computers, Markram realized, you could encode all of those models explicitly and get them to work together. That would help researchers to find the gaps and contradictions in their knowledge and identify the experiments needed to resolve them. Markram's insight wasn't original: scientists have been devising mathematical models of neural activity since the early twentieth century, and using computers for the task since the 1950s ( see page 462 ). But his ambition was vast. Instead of modelling each neuron as, say, a point-like node in a larger neural network, he proposed to model them in all their multi-branching detail \u2014 down to their myriad ion channels (see 'Building a brain'). And instead of modelling just the neural circuits involved in, say, the sense of smell, he wanted to model everything, \u201cfrom the genetic level, the molecular level, the neurons and synapses, how microcircuits are formed, macrocircuits, mesocircuits, brain areas \u2014 until we get to understand how to link these levels, all the way up to behaviour and cognition\u201d. The computer power required to run such a grand unified theory of the brain would be roughly an exaflop, or 10 18  operations per second \u2014 hopeless in the 1990s. But Markram was undaunted: available computer power doubles roughly every 18 months, which meant that exascale computers could be available by the 2020s (see 'Far to go'). And in the meantime, he argued, neuroscientists ought to be getting ready for them. Markram's ambitions fit perfectly with those of Patrick Aebischer, a neuroscientist who became president of the EPFL in 2000 and wanted to make the university a powerhouse in both computation and biomedical research. Markram was one of his first recruits, in 2002. \u201cHenry gave us an excuse to buy a Blue Gene,\u201d says Aebischer, referring to a then-new IBM supercomputer optimized for large-scale simulations. One was installed at the EPFL in 2005, allowing Markram to launch the Blue Brain Project: his first experiment in integrative neuroscience and, in retrospect, a prototype for the HBP. Part of the project has been a demonstration of what a unifying model might mean, says Markram, who started with a data set on the rat cortex that he and his students had been accumulating since the 1990s. It included results from some 20,000 experiments in many labs, he says \u2014 \u201cdata on about every cell type that we had come across, the morphology, the reconstruction in three dimensions, the electrical properties, the synaptic communication, where the synapses are located, the way the synapses behave, even genetic data about what genes are expressed\u201d. By the end of 2005, his team had integrated all the relevant portions of this data set into a single-neuron model. By 2008, the researchers had linked about 10,000 such models into a simulation of a tube-shaped piece of cortex known as a cortical column. Now, using a more advanced version of Blue Gene, they have simulated 100 interconnected columns. The effort has yielded some discoveries, says Markram, such as the as-yet unpublished statistical distribution of synapses in a column. But its real achievement has been to prove that unifying models can, as promised, serve as repositories for data on cortical structure and function. Indeed, most of the team's efforts have gone into creating \u201cthe huge ecosystem of infrastructure and software\u201d required to make Blue Brain useful to every neuroscientist, says Markram. This includes automatic tools for turning data into simulations, and informatics tools such as  http://channelpedia.net  \u2014 a user-editable website that automatically collates structural data on ion channels from publications in the PubMed database, and currently incorporates some 180,000 abstracts. The ultimate goal was always to integrate data across the entire brain, says Markram. The opportunity to approach that scale finally arose in December 2009, when the European Union announced that it was prepared to pour some \u20ac1 billion into each of two high-risk, but potentially transformational, Flagship projects. Markram, who had been part of the 27-member advisory group that endorsed the initiative, lost no time in organizing his own entry. And in May 2011, the HBP was named as one of six candidates that would receive seed money and prepare a full-scale proposal, due in May 2012. If the HBP is selected, one of the key goals will be to make it highly collaborative and Internet-accessible, open to researchers from around the world, says Markram, adding that the project consortium already comprises some 150 principal investigators and 70 institutions in 22 countries. \u201cIt will be lots of Einsteins coming together to build a brain,\u201d he says, each bringing his or her own ideas and expertise. \n               Bottom to top \n             The description of the HBP as an open user facility sparked interest and enthusiasm at the Bern meeting. But much more vocal were Markram's critics, many of whom focused on the perceived inadequacies of the Blue Brain model \u2014 and of Markram's approach to data integration. At the heart of that approach is Markram's conviction that a good unifying model has to assimilate data from the bottom up. In his view, modellers should start at the most basic level \u2014 he focuses on ion channels because they determine when a neuron fires \u2014 and get everything working at one level before proceeding to the next. This requires a lot of educated guesses, but Markram argues that the admittedly huge gaps in knowledge about the brain can be filled with data as experiments are published \u2014 the Blue Brain model is updated once a week. The alternative approach, approximating and abstracting away the biological detail, leaves no way to be sure that the model's behaviour has anything to do with how the brain works, said Markram. This is where other computational neuroscientists gnash their teeth. Most of them are already using simple models of individual neurons to explore high-level functions such as pattern recognition. Markram's bottom-up approach risks missing the wood for the trees, many of them argued in Bern: the model could be so detailed that it is no easier to understand than the real brain. And that is if Markram can build it at all. Judging by what Blue Brain has accomplished in the past six years, critics said, that seems unlikely. The tiny swathe of simulated rat cortex has no inputs from sensory organs or outputs to other parts of the brain, and produces almost no interesting behaviour, pointed out Kevan Martin, co-director of the INI, in an e-mail. It is \u201ccertainly not the case\u201d that Markram has simulated the column as it works in a whole animal, he said. Markram's response to such criticisms in Bern was that more capabilities are always being added to the Blue Brain simulation. But Martin remained unimpressed. \u201cI cannot imagine how this level of detail, which is still very incomplete even after Henry's considerable labours, is ever going to be obtained from more than a few regions of the rodent brain in the next decade, let alone brains of  Drosophila , zebrafish, songbird, mouse or monkey,\u201d his e-mail continued. \u201cOf course,\u201d Martin added, \u201call this would be but a storm in the professors' teacups\u201d if the HBP hadn't come along and raised the stakes enormously. It is all too easy to imagine other areas of neuroscience research being starved for resources by the HBP \u2014 especially in Switzerland, which as host country will have to provide a substantial, but still-undetermined, fraction of the funding. Douglas asks: should Europe be spending \u20ac1 billion to support the passionate quest of one man? He concedes that visionaries are sometimes necessary to drive progress. \u201cBut what if they're passionately wrong?\u201d Also fuelling anxiety \u2014 and irritation \u2014 is the widespread sense that Markram has been making his case through the news media, not through publishing, conferences and the other conventional channels of science. Reporters see much to like: Markram is tall, striking and explains his ideas with the clarity, quotability and urgency of a South African version of the late Carl Sagan. He has \u201ca hypnotic effect\u201d, says Richard Hahnloser, a computational neuroscientist at the INI. But critics say that this results in too many news accounts that leave the impression that the HBP will, say, eliminate the need for experimental animals. \u201cThe whole neuroscience community will be in trouble ten years from now\u201d when the implied predictions don't come true, says another INI researcher, who worries that the politicians will be right there saying, \u201cBut you promised!\u201d \n               March of progress \n             In Bern, Markram bristled at accusations that he has deliberately cultivated hype. \u201cI have never said that the HBP would replace animal experiments,\u201d he shot back at one questioner. \u201cI said that simulation helps you choose the experiments that will best add value.\u201d Markram was also at pains to insist that the HBP will be open to other modelling approaches. \u201cThis concern is unfounded because they simply have not bothered to find out what is being proposed,\u201d he told  Nature  after the meeting. The final facility \u201cwill allow anyone to build models at a range of levels of biological detail with as much data as possible from anywhere\u201d. Markram seems to be building support. Last year, the board that oversees both the ETH and the EPFL enthusiastically endorsed the Blue Brain Project after a rigorous review by a four-member panel that included two outspoken sceptics of Markram's approach. The board asked the Swiss parliament to commit 75 million Swiss francs (US$81 million) to the project for 2013\u201316 \u2014 more than ten times Blue Brain's current budget. Parliament's decision is expected next month. Markram is optimistic that the European Union will come to much the same conclusion about the HBP. However, if the project isn't endorsed, says Markram, \u201cwe'll just continue with Blue Brain\u201d \u2014 although it may take a lot longer to reach a full brain simulation. Markram clearly feels that history is on his side. \u201cSimulation-based research is an inevitability,\u201d he declared in Bern. \u201cIf I get stopped from doing this, it's going to happen. It has happened already in many areas of science. And it is going to happen in life science.\u201d \n                     Turing at 100: Legacy of a universal mind 2012-Feb-22 \n                   \n                     European researchers chase billion-euro technology prize 2011-Mar-08 \n                   \n                     Publisher seeks patent 2010-May-07 \n                   \n                     Bioinformatics: Industrializing neuroscience 2007-Jan-10 \n                   \n                     The Blue Brain Project 2006-Feb-01 \n                   \n                     Blue Brain boots up to mixed response 2005-Jun-08 \n                   \n                     Nature Special: Turing \n                   \n                     The Blue Brain Project \n                   \n                     The Human Brain Project \n                   \n                     The European Flagship Initiatives \n                   \n                     Henry Markram's 2009 TED talk \n                   \n                     Henry Markram at the 2011 International Supercomputing Conference \n                   Reprints and Permissions"},
{"file_id": "482455a", "url": "https://www.nature.com/articles/482455a", "year": 2012, "authors": [{"name": "Tanguy Chouard"}], "parsed_as_year": "2006_or_before", "body": "From the day he was born \u2014 23 June 1912 \u2014 Alan Mathison Turing seemed destined to solitude, misunderstanding and persecution (see  page 441 ). As his centenary year opens,  Nature  hails him as one of the top scientific minds of all time (see page 440). This special issue sweeps through Turing's innumerable achievements, taking us from his most famous roles \u2014 wartime code-breaker and founder of computer science ( see page 459 ) \u2014 to his lesser known interests of botany, neural nets, unorganized machines, quantum physics and, well, ghosts ( see page 562 ). Everyone sees a different Turing. A molecular biologist might surprise you by saying that Turing's most important paper is his 1936 work on the 'Turing machine' because of its relevance to DNA-based cellular operations ( see page 461 ). A biophysicist could instead point to his 1952 work on the formation of biological patterns \u2014 the first simulation of nonlinear dynamics ever to be published ( see page 464 ). Beneath it all, Turing was driven by the dream of reviving \u2014 possibly in the form of a computer program \u2014 the soul of Christopher Morcom, perhaps his only true friend, who died abruptly when they were both teenagers. I want to \u201cbuild a brain\u201d, he said. So does electrophysiologist Henry Markram ( see page 456 ). But it is still a matter of debate whether machine intelligence should faithfully simulate neuronal circuitry, or just emulate brain function using whatever expedient ( see page 462 ). Even when Turing was kept busy by wartime code-breaking and the practical implementation of his universal computer, he never forgot that he had, in 1936, discovered something even bigger: the 'incomputable' world. Contemporary physics hasn't even started to work out the implications of that discovery ( see page 465 ). It is typical of Turing's brilliance and playfulness that even as he gave so many fields the tools that allowed them to blossom, he planted a concept that pushes science as we know it \u2014 physical reality and Newtonian causality\u2014towards the abyss. \n                     Nature Special: Turing \n                   Reprints and Permissions"},
{"file_id": "483020a", "url": "https://www.nature.com/articles/483020a", "year": 2012, "authors": [{"name": "Trisha Gura"}], "parsed_as_year": "2006_or_before", "body": "A Pennsylvania clinic working with Amish and Mennonite communities could be a model for personalized medicine. In 2003, Leon and Linda Hoover embarked on a trying medical odyssey by horse and buggy. The Hoovers, of Lewisburg, Pennsylvania, are Mennonites, a religious group that mostly eschews cars, televisions and other modern conveniences. Along with the Amish communities that dwell in the region, they are the 'Plain people', whose handmade clothes and horse-drawn carriages are an iconic part of the landscape. But modern medical technology was to become a large part of the Hoovers' lives when they rode to the doctor with their six-week-old son, Raylon. He had been suffering from a deluge of infections \u2014 from croup to thrush to cytomegalovirus. After two months and consultations with various physicians, he received a tentative diagnosis: severe combined immunodeficiency (SCID), which describes a number of genetic disorders that leave children unable to fight infections. Although SCID can be treated by bone-marrow transplantation, refining the diagnosis and finding a matching donor require genetic testing. Physicians shipped blood samples to Duke University in Durham, North Carolina, and sent the Hoovers home to wait. But after three long weeks without results, Raylon's health was worsening, and Leon was getting desperate. He called the Clinic for Special Children in Strasburg, Pennsylvania, a timber-framed, slate-roofed structure housing an arsenal of modern genetic and genomics instrumentation. Hoover spoke for 45 minutes to Kevin Strauss, a paediatrician there. \u201cYou have a SCID baby, and you are at home?\u201d Strauss asked, incredulous. To speed things up, he referred the Hoovers to his colleague Nancy Bunin, now director of stem-cell transplantation at the Children's Hospital of Philadelphia (CHOP) in Pennsylvania. She quickly arranged for genetic testing and a bone-marrow transplant. But it came too late. Raylon died at 6 months and 15 days. Last September, when the Hoovers had another child, the story was very different. A test at birth revealed that their daughter, Kendra, had a dangerously low white-blood-cell count and probably had SCID. In tears, Hoover called Strauss on a Sunday at dawn. The paediatrician sprang into action. A midwife collected Kendra's umbilical-cord blood and had it driven the 170 kilometres to his laboratory. Within 12 hours of Kendra's birth, the lab team had detected a single letter change in her  IL7R  gene \u2014 the same mutation that had affected her brother. Hear more about the Hoover family\u2019s story and the Clinic for Special Children The next morning, Strauss drove to the Hoover family's sewing-machine shop. There, 16 relatives lined up to give blood in the hope that one could become Kendra's bone-marrow donor. Testing at the clinic revealed that her sister, 11-year-old Ester Mae, was a match, and Kendra received the transplant at CHOP within 16 days of her birth. Kendra's total medical bill was US$12,000 \u2014 compared with $500,000 for her brother. And she is doing well today. \u201cThis is what genomic medicine is supposed to do,\u201d Strauss says. \u201cIf you know which people are at risk, you can determine a diagnosis before a child is 24 hours old. You can come up with a treatment based on the genetics.\u201d \n               The million-dollar interpretation \n             The Clinic for Special Children, it seems, has found a way to apply the basic tools of genomics to save lives, money and resources. At the clinic, two paediatricians, a molecular geneticist and their staff have tools such as sequencers, microarrays and a LightScanner, which detects gene mutations. Using these tools, they nimbly stitch together the elements of basic science and clinical practice necessary to move from a blood sample to DNA analysis, all the way to diagnosis and treatment \u2014 sometimes in a matter of days. By doing so, the clinic has achieved what many others in genomic medicine are struggling to do. Although genome sequencing is creeping into clinical care around the world, it has yet to become an integral part of everyday medical practice. \u201cWe've talked about the thousand-dollar genome and the million-dollar interpretation,\u201d says Eric Topol, a genomicist at the Scripps Research Institute in La Jolla, California. \u201cThe challenging bottleneck is the process of trying to nail down which DNA variation is the root cause.\u201d The team at the Clinic for Special Children can negotiate that bottleneck in part because of the unusual community with which it works. The Amish and Mennonites in Lancaster County are descended from a small founder population, have a remarkable knowledge of family history and tend to marry within the groups. This means that they have a high rate of particular genetic disorders, which makes it easier for researchers to trace the causes of such diseases. But the clinic's success also hinges on its combined clinical and laboratory facilities, and the close relationship that Strauss and his colleagues have built with the community. The Amish and Mennonites shun technology to varying degrees \u2014 some even forbid zips on clothing \u2014 but they unanimously support the clinic. If a technology draws people together in \u201cfellowship\u201d, says Mark Martin, a Mennonite and member of the clinic board, then the churches will indulge. The community even holds quilt and handicraft auctions to raise funds for the clinic, which last year netted $500,000 \u2014 about one-third of the clinic's budget. Holmes Morton, who started the clinic in 1989, says that it could serve as a model for personalized medicine in many other small populations with similar genetic histories. \u201cPlain populations are interesting not because they are different,\u201d he says. They are interesting because their genetics are the same as those of people everywhere, he says. Morton, now 61, grew up in Fayetteville, West Virginia. He was a high-school dropout, who spent six years as a boilerman and engineman in the Merchant Marines and the Navy while taking a slew of correspondence courses. He used these to talk his way into Trinity College in Hartford, Connecticut, and from there went to Harvard Medical School in Boston, Massachusetts. The dean of admissions, Morton says, was intrigued by his unusual background. In 1988, while completing a medical fellowship in metabolic diseases at CHOP, Morton encountered his first Amish patient \u2014 a six-year-old boy with a strange form of cerebral palsy. Through a urine test, Morton diagnosed him with glutaric aciduria type 1 (GA-1), which is caused by a defect in a protein-digesting enzyme and can lead to brain damage, severe movement problems and early death unless strict dietary restrictions are observed from infancy 1 . (Morton and Strauss later developed a formula to meet those restrictions.) Morton knew that there were more Amish children with GA-1 and other treatable genetic conditions who were not receiving care, either because centres were too far away or tests were too expensive. So he decided to open a clinic that could meet the needs of the community. This meant bringing in diagnostic equipment to provide cheap, in-house testing, factoring in physician time for home visits and, most importantly, setting up shop in the heart of the community \u2014 within driving distance for a horse and buggy. \n               Breaking ground \n             Morton applied for federal funding to cover office space, a computer and a mass spectrometer, but was denied. So he and his wife Caroline decided to take out a second mortgage on their house. Just before they did so, a reporter from the  The Wall Street Journal  wrote about Morton's quest 2 . Within a week, readers had sent in several hundred thousand dollars and Hewlett-Packard had donated equipment. In the grand barn-raising tradition of the Plain people, Amish and Mennonites came together to build the clinic on a plot of land donated by Jake Stoltzfoos, an Amish farmer whose grandchildren Morton had treated. It is probably the only medical centre today with both a hitching post and an Ion Torrent DNA sequencer. Despite the technology available, Strauss says, one of the clinic's most important tools is \u201cinstitutional memory\u201d. An Old Order Mennonite family came to visit Strauss in 2006, for example. Their six-month-old daughter, Rosalyn, had a cluster of developmental problems. Unable to diagnose her, Strauss, who would eventually take over as medical director of the clinic, wandered downstairs to talk to his lab director Erik Puffenberger, a molecular geneticist. \u201cI've got a girl with a small head and vision problems,\u201d Strauss said. \u201cDoes that ring a bell?\u201d It did. Puffenberger recalled a Mennonite family he had met in the late 1980s when he was working with Victor McKusick, a renowned geneticist and author of  Medical Genetic Studies of the Amish . The family had six children: all blind, with abnormally small heads. Puffenberger and Strauss tracked down the family to the same cinder-block residence they had occupied all their lives. The mother was in her eighties, still caring for her five surviving children, by then in their fifties and sixties. Strauss collected blood samples and Puffenberger analysed them, using gene-expression analysis and sequencing all the known protein-coding regions of the genome, known as the exome. Puffenberger and his colleagues identified a novel mutation in a gene called  TUBGCP6 , which encodes a protein necessary for proper cell division and seems to explain the condition 3 . Although the disease cannot be cured, Rosalyn's vision problem, which involved the retina detaching from the eye, was treated with surgery to prevent otherwise inevitable blindness. Strauss's team has since caught the same disorder, before the onset of symptoms, in two of her siblings through newborn screening. One has already received surgery and the other, still an infant, is scheduled to undergo surgery soon. In addition to those within the Lancaster community, Morton and Strauss examine patients from communities in 27 other states and a handful of other countries. Like any paediatrics practice, the physicians send out some samples for routine testing, but can perform almost any genetic and biochemical test in their own basement laboratory. They now know and can test for the molecular basis of 121 heritable genetic diseases common among the populations they serve. If a patient has none of these \u2014 the case for nearly half the children they see \u2014 the basic research starts. Strauss estimates that, in the Lancaster populations, his team will uncover the roots of between 5 and 15 new genetic diseases a year for at least the next decade. Many of those will be present in only a handful of people. About one-half to three-quarters will be treatable, he estimates, especially if detected early, as in the case of Kendra Hoover. How applicable their approach is for other clinics that are currently adopting genomic tools is an open question, however. Some scientists are sceptical. \u201cIt's a pretty unique situation because they are dealing with a closed population,\u201d says Leslie Biesecker, chief and senior investigator of the genetic-disease research branch at the National Human Genome Research Institute in Bethesda, Maryland. By 'closed', he means that because of its small founder population and intermarriage, Plain people stand to inherit only a relatively small number of rare disorders. Although conceding that disease genes are easier to identify among the Amish and Mennonites, Strauss argues that the criticism misses the mark. \u201cIf isolated populations make it so easy to do this work,\u201d he asserts, \u201cwhy haven't other major academic centres nearby that see these patients made the genetic discoveries that we have?\u201d The answer, he says, is that other institutions keep the clinic separate from the research, which complicates genomic screening and makes it prohibitively expensive. By contrast, the clinic embeds its laboratory within its walls, certifies it and uses a blanket institutional review board approval from nearby Lancaster General Hospital. That allows Strauss or Morton to order, say, a microarray test to screen for a genetic mutation in a newborn in the same manner that other physicians might order a cholesterol test. The lab's integration, as much as the community structure, is key to surmounting the problem of million-dollar interpretation. Puffenberger says that the advantages provided by such populations are shrinking. Many of the team's recent discoveries were \u2014 or could have been \u2014 determined by sequencing the exomes of just one patient and his or her immediate family, rather than reaching out to extended families for multiple affected individuals. As other medical centres begin to apply genome and exome sequencing, Strauss, Morton and Puffenberger hope that more will adopt the same sort of integrative style. Even sceptics such as Biesecker concede that the idea of a general population as a well-mixed melting pot is inaccurate. Instead, the 'general population' is actually a mosaic of subpopulations, immigrating together and often living for decades in the same geographical location. In the United States, for example, there are pockets of high intermarriage in Appalachia. And Iceland has some 318,000 residents, who are largely descended from a small founder population. Genomics approaches similar to that used at the clinic are already at work for consanguineous populations in the Middle East and Ireland, says Stacey Gabriel, director of cancer and medical sequencing at the Broad Institute in Cambridge, Massachusetts. \u201cFounder populations are the history of the world,\u201d Morton says. \u201cWhether they are located in a county in West Virginia or a region in Brazil, each population has a genetic make-up that can be studied and served.\u201d That, he adds, is where the model of the clinic becomes useful. Moving forward, the team at the clinic hopes to streamline its approach to diagnosing new patients and the roughly 1,000 current patients in the area still without a molecular diagnosis. For help in proving that the mutations they identify really do lie at the heart of disease, the team is collaborating with neuroscientist Rob Jinks of the Lancaster-based Franklin & Marshall College. With support from an education grant from the Howard Hughes Medical Institute, Jinks and a group of undergraduate students are working to determine the biological consequences of the mutations the clinic discovers. But the clinic team is quick to note that scaling up genomic sleuthing is not the top priority. \u201cWe solve the problems for one child, one family at a time,\u201d Strauss says. The Hoovers have experienced this first hand. Last October, Kendra Hoover lay in her mother's arms as a needle delivered human immunoglobulin into her scalp. These proteins would help protect Kendra from viral and bacterial infection while the cells transplanted from her sister began to take residence and give her a functioning immune system. Her prognosis is good, and her father, Leon, couldn't be happier. \u201cI don't know if I can put into words, how much they mean to us,\u201d he says. \u201cThey have all these patients. So many to take care of. But every one is treated like their own child.\u201d \n                 See Editorial \n                 p.6 \n               \n                     Personalized medicine: Bring clinical standards to human-genetics research 2012-Feb-15 \n                   \n                     Sequencing set to alter clinical landscape 2012-Feb-15 \n                   \n                     Human genetics: Genomes on prescription 2011-Oct-05 \n                   \n                     Software pinpoints cause of mystery genetic disorder 2011-Jun-23 \n                   \n                     The human genome at ten \n                   \n                     \n                         Nature Genetics \n                       \n                   \n                     Clinic for Special Children \n                   Reprints and Permissions"},
{"file_id": "483024a", "url": "https://www.nature.com/articles/483024a", "year": 2012, "authors": [{"name": "Erika Check Hayden"}], "parsed_as_year": "2006_or_before", "body": "Michael Merzenich has a plan for how to convince sceptics of the worth of his brain-training video games: prove that the software can help people with schizophrenia. The intersection of Mission and Sixth streets in San Francisco's South of Market neighbourhood is considered one of the most crime-riddled in the city. Liquor shops, adult bookshops and single-resident-occupancy hotels inhabit most of the buildings. Homeless people sit on the pavements or shuffle by, many of them showing symptoms of mental illness or drug abuse. Yet behind the walls of an unassuming outpatient psychiatric clinic, researchers are conducting experiments that they believe could fundamentally change the landscape of psychiatric care. Inside the San Francisco Citywide and Community Focus Center, in a room about the size of a large walk-in wardrobe, two people wearing headphones sit staring at computer screens. Despite the hubbub \u2014 the din of a nearby group session, clients milling in the hallway and the internal turmoil caused by their mental disorders \u2014 they are mesmerized by the games on the screens. Both have schizophrenia, and they are taking part in a study that aims to determine whether a controversial method of treatment can succeed where modern medicine has largely failed. The man behind the games is Michael Merzenich, an emeritus professor at the University of California, San Francisco, and a pioneering advocate for neuroplasticity \u2014 the notion that the brain can reshape and remodel its neural pathways even into adulthood. He has gained notoriety for his unabashed promotion of video games designed to tap into that plasticity. These have been marketed to treat everything from reading difficulties in children to driving impairment in elderly people. His zeal has, at times, attracted criticism. There is little solid evidence, say critics, that brain training makes a long-lasting difference in the lives of either ill or healthy people. The language-learning program Fast ForWord, in particular, has rankled some. \u201cIt is a waste of money for schools to pay for these programs that, in my reading of the literature, are ineffective,\u201d says Martha Farah, a cognitive neuroscientist at the University of Pennsylvania in Philadelphia. But this year, Merzenich aims to push the envelope further. He and his colleagues plan to start clinical trials that could lead to a first in the brain-training field: approval from the US Food and Drug Administration (FDA). FDA approval for the software would give people with schizophrenia a new sanctioned treatment option, and grant legitimacy to Merzenich's work. It will also put pressure on the rest of the brain-training industry to prove the value of its products. Making the case will not be easy. But Murali Doraiswamy, a psychiatrist and neurobiologist at Duke University in Durham, North Carolina, says that Merzenich is fighting an important battle. \u201cIf he can present rigorous results on the outcomes that the FDA deems meaningful, it will help everyone else to focus on achieving those goals and weed out the bad players.\u201d Weeding out the 'bad players' is one of Merzenich's main hopes; he has long felt that the field of cognitive training lacks discipline and is happy to share what he thinks of it: \u201cbullshit-ridden\u201d. Even some critics, such as Farah, respect his push for FDA approval. \u201cI think this foray into schizophrenia puts us back in much more familiar territory, where we have systems in place for evaluating whether an intervention is effective.\u201d \n               Ready for action \n             A gruff bear of a man, Merzenich grew up as the son of a farmer in rural Oregon. He owns a small farm in Sonoma County, north of San Francisco, where he makes wine and cures olives, and he arrives for a Monday-morning interview with dirt under his fingernails. Merzenich earned his PhD in 1968 at Johns Hopkins University School of Medicine in Baltimore, Maryland, working with Vernon Mountcastle, who laid the basis for brain-plasticity studies by showing that the cerebral cortex is organized into vertical columns of neurons that respond to particular stimuli. Merzenich went on to demonstrate in monkeys that when neurons that normally process sensory information from one part of the hand lose their inputs, they begin processing input from other parts of the hand 1 . Merzenich also mapped the brain systems involved in human hearing \u2014 work that eventually led him to co-develop the first cochlear implant, a device that allows people with severe hearing impairments to hear by training their brains to interpret electrical signals sent to the auditory nerve. That device, developed in the 1980s, is now sold by Advanced Bionics in Valencia, California. His work on the monkeys and the implant showed Merzenich first-hand how the brain could change given the right stimuli, and he began to see rewiring the brain as a way to treat a broad range of medical and societal ills. In 1996, he began selling Fast ForWord through a company he co-founded in Oakland, California, called Scientific Learning. The program aims to train the brain to discriminate sounds better. And that, Merzenich contends, should lead to improved speech processing and reading. In 2003, he formed Posit Science in San Francisco, California, to focus on cognitive training, essentially workouts to sharpen the brain's function. Posit, like other brain-training firms, has faced scepticism. The brain-training industry \u2014 which was projected to grow from US$265 million in 2008 to between $1 billion and $5 billion by 2015 \u2014 markets games that claim to boost skills such as memory or focus in healthy adults. But for those likely to need it most, such as elderly people, there has been no convincing evidence that the games work any better than the mostly free activities that physicians routinely recommend, such as physical exercise, socializing with friends, taking up a new hobby or playing a musical instrument. \u201cReally well-designed clinical trials to test the efficacy of these devices are few and far between. It's sort of like the Wild West,\u201d says Peter Snyder, a neurologist at Brown University's Alpert Medical School in Providence, Rhode Island. Henry Mahncke, Posit's chief executive, says that the company has shown memory improvements in healthy people aged 60 years and up who use the software 2 , 3 . He also criticizes a 2010 paper 4  in  Nature  that reported a study of people recruited over the Internet to play a brain-training game. The study showed that benefits didn't translate into general cognitive improvement. It was widely reported as undermining the concept of brain training, but Mahncke points out that the training was much less intensive than in Posit's trials and the participants were younger. Still, the criticisms have taken a toll. Posit, for instance, shrank from 86 employees in 2007 to fewer than a dozen last year. The company needs a clear success. Schizophrenia might seem an odd place for Posit to stake its future because the disorder is complex and can involve symptoms as diverse as hallucinations, delusions, lack of motivation and difficulties in expressing emotions, speech and thought. But the drugs currently used to treat it have frequent and severe side effects. They also don't alleviate many of the symptoms that can prevent people with schizophrenia from finding work and forming relationships. That means that schizophrenia has a higher social cost than more common psychiatric illnesses, such as depression. Yet the disease's intractability is part of what attracted Merzenich; if his treatment succeeds, it could have a big impact. Moreover, researchers are shifting their focus away from the more attention-grabbing symptoms of schizophrenia \u2014 the delusions and other signs of loss of contact with reality \u2014 and starting to see the disorder as the result of dysfunctions in basic cognitive processes such as attention, learning, memory, speech and problem-solving. That recognition helped to give rise to a therapeutic approach known as cognitive remediation, which aims to tackle the deficits directly. It also led the US National Institute of Mental Health in Bethesda, Maryland, to commission guidelines for testing interventions in schizophrenia. Called MATRICS (Measurement and Treatment Research to Improve Cognition in Schizophrenia), the guidelines were developed in consultation with the FDA and released in 2005. They spell out which cognitive tests should be used to measure deficits and improvements in seven categories of mental abilities, such as visual learning and problem-solving, and how the tests should be used in clinical trials intended to form the basis of FDA approval. MATRICS was designed to facilitate the development of new drugs, but Merzenich sees it as a road map that could guide trials of brain-training software. Thanks to the MATRICS guidelines, Merzenich says, \u201cschizophrenia is a relatively simple thing to carry to trial. If you have a significant effect in a clinical population, then you will be given the right to sell the drug.\u201d He is optimistic that his treatment will be approved. \u201cI'll tell you right now, we will see benefits in all seven MATRICS categories. We will. Because we already have.\u201d The approach that Merzenich is testing, called Plasticity Assisted Cognitive Remediation (PACR), includes elements from programs that Posit already markets to the general public. One set of exercises focuses on improving the processing of sounds and words through tasks that, for instance, ask the user to discriminate between similar sounds, such as ba and ga, or to decide whether a tone is rising or falling in pitch. Another deploys similar tasks in a visual space \u2014 for instance, asking a user to remember where items are hidden, or to spot an object placed in the periphery of his or her visual field. Other exercises, specifically designed for people with schizophrenia, focus on social function. \n               Train of thought \n             Sophia Vinogradov, a psychiatrist at the University of California, San Francisco, has already run some clinical trials of Merzenich's software. The goal of treating people with schizophrenia, she says, is to improve fundamental neural processes so that the brain is freed to tackle higher-order cognitive demands such as working memory. By analogy, she says, if you were trying to improve on a lousy tennis serve, you might get better results by focusing on components necessary for the motion, such as balance, coordination and upper-body strength, than by simply repeating your ineffective serve over and over again. People with schizophrenia have problems at multiple levels of auditory and verbal processing pathways, Vinogradov says. \u201cIt makes sense to start with early levels of these pathways and work your way up.\u201d Some suspect that Posit will have more success in showing benefits for serious disease than for healthy adults. \u201cIf you're very close to maximum performance, you don't have a lot of room for improvement,\u201d says Doraiswamy. \u201cWhereas for people in, for instance, a pre-Alzheimer's stage, if you can show 15% to 20% improvement, it might mean postponing the development of Alzheimer's by six or eight months.\u201d Vinogradov and others have tested various levels and combinations of these training programs in small groups of people with schizophrenia. She has shown that the most-intensive training tested \u2014 100 hours \u2014 can improve global cognition for as long as six months after the training ends 5 . None of the groups showed a significant improvement in symptom severity or quality of life, but Vinogradov speculates that that was probably partly because there were only about ten patients in each group. A small study published last week showed that intensive training can improve people's performance in a task that assesses the ability to distinguish what is real from what is not. Those who improved most had significantly enhanced social functioning six months later 6 . When combined with other interventions, such as counselling and job-placement programmes, as the current trial at Citywide clinic is, cognitive remediation approaches seem to help patients function better in society \u2014 for instance, by helping them to keep jobs 7 . But teasing out what role, if any, the software has in these gains is difficult, partly because the programs have been tested in so many different combinations and conditions. Alice Medalia, a clinical psychiatrist at Columbia University in New York and a pioneer in cognitive remediation, says that she doesn't think Posit should be seeking FDA approval yet, because it hasn't shown its software to be any better than other cognitive remediation therapies, and because it is not clear how the programs actually treat schizophrenia. A meta-analysis 8  of cognitive-remediation studies, including those testing Posit's software, found no differences in the effectiveness of various programs \u2014 or of other methods of non-pharmaceutical remediation. This calls into question the scientific rationale of the games, Medalia says. \u201cWe have no idea what the active ingredient in these computer-based programs is. Saying that neuroplasticity is the active ingredient is not specific.\u201d Merzenich, however, feels that he has fought long enough to prove the validity of brain training. Now, he says, it is time for regulators to weigh in. Treating schizophrenia with software would mark a change for psychiatry, which tends to focus on dispensing drugs in the first instance. Vinogradov says that the growing realization of drugs' shortcomings and a shift away from the idea that brain deficits are immutable are sparking desire for alternative options. \u201cThe dominant force in psychiatry has been the focus on treating symptoms, not the underlying dysfunction. The patient is this passive object to whom you give pills, as opposed to actively helping to stimulate constructive interaction with his or her environment,\u201d Vinogradov says. And Merzenich doesn't plan to stop with schizophrenia. The Brain Plasticity Institute in San Francisco, another Merzenich-founded company, is studying brain-training software for conditions ranging from Alzheimer's disease to traumatic brain injury. \u201cIf we do this in a disciplined way, with scientific confirmation that is beyond question,\u201d Merzenich says, \u201cwe'll very rapidly evolve into a very important aspect of psychiatric medicine.\u201d \n                     Q&A: The instrumentalist 2012-Feb-01 \n                   \n                     Video-game studies have serious flaws 2011-Sep-16 \n                   \n                     Neuroscience: Brain buzz 2011-Apr-13 \n                   \n                     No gain from brain training 2010-Apr-20 \n                   \n                     Nature Video \u2014 Brain training: does it work? \n                   \n                     Posit Science \n                   Reprints and Permissions"},
{"file_id": "483141a", "url": "https://www.nature.com/articles/483141a", "year": 2012, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "Japan is rebuilding its coastal cities to protect people from the biggest tsunamis. On a cold February day, the northeastern Japanese city of Sendai is a snow-covered wasteland. It might pass for out-of-season farmland were it not for the chunks of grey concrete arrayed in rectangles, reminders that houses once stood here. The signs of devastation are all around, although eerily tidied up. Inside one abandoned house that is missing its first-storey walls, dishes have been neatly stacked on a shelf, perhaps by a compassionate rescue worker. The remnants of cars \u2014 240,000 were washed away or destroyed \u2014 and other metallic wreckage are compressed into neat blocks and stacked. Nearby lie piles of uprooted trees that were supposed to provide protection against a tsunami, but instead became lethal battering rams in the raging water. A solitary street sign lies on the ground by the beach, warning of the risk posed by such events. The sign shows areas that must be evacuated in the event of a tsunami, but the stretch of land at risk on the map is just a small fraction of the region of Sendai that was flooded on 11 March 2011 (see 'Danger zone'). Fumihiko Imamura, a tsunami researcher at Sendai's Tohoku University, quietly studies the map, which he helped to produce. \u201cSome people have criticized us, but at that time we were just envisioning the Miyagi quake,\u201d he says, referring to an earthquake that occurs off the Sendai coast every 100 to 150 years, triggering tsunamis about 4 metres high. Instead, water levels here reached 10 metres; farther north they topped 20 metres. The waves inundated more than 500 square kilometres of land across six prefectures, destroying nearly 130,000 buildings and damaging 245,000 others. Some 15,000 people died, and several thousand more are missing and presumed dead. Now the Japanese government is wrestling with how to rebuild cities such as Sendai to keep people safe should a monster tsunami hit again. Scientists, architects and city planners are debating how much to rely on coastal fortifications such as sea walls and forests. These protections helped in some places but many of them failed, and they gave people a false sense of security that may have contributed to the death toll. Despite this, many municipalities are already moving forward with reconstructing damaged defences. A new institute, opening in Tohoku next month, will try to extract lessons from the disaster to aid the rebuilding efforts and to develop better public-education campaigns, which experts say are one of the most effective tools for protecting people. Tatsuo Hirano, minister of the recently launched Reconstruction Agency, says that Japan is setting its sights high as it starts to rebuild. \u201cThe goal is to have zero deaths in future tsunamis,\u201d he says. \n               Walls versus water \n             Japan has been pounded by tsunamis throughout its history, and so had prepared more for these floods than any other country. Over the centuries, communities have planted coastal forests as barriers against the sea. Many towns hold regular training drills and evacuations. And sea walls and breakwaters surround nearly half of the country's 34,500 kilometres of coastline. Maintaining and extending these bulwarks has cost the central government billions of yen per year. In areas of greatest tsunami risk, including the entire Tohoku region, 74% of sea walls were built to be higher than the expected tsunamis. But those expectations were based on magnitude-8 earthquakes that occur every few decades or centuries, not the 1-in-1,000-year Tohoku event, which was ten times stronger at magnitude 9.0. The tsunami that came crashed over most of those walls. Although the giant waves shocked the public, they weren't a complete surprise to some researchers. A decade ago, geologists discovered a sedimentary layer from a massive tsunami that had flowed several kilometres inland in 869 ( K. Minoura  et al .  J. Nat. Disaster Sci.   23,  83\u201388; 2001 ). Some scientists had worried about a repeat. \u201cWe thought one like this might come, but it was not yet in the official model,\u201d says Imamura. During a meeting with Imamura last month, Tsuneaki Iguchi, the mayor of the city of Iwanuma south of Sendai, thanked the scientist for his efforts to protect the region but said he wished that researchers had done better at getting the message out about the 869 tsunami. \u201cIf only that work could have been done a little more quickly.\u201d Japan is now taking steps to shore up its defences against such mega-tsunamis. In December, the parliament passed a law requiring the construction of \u201ctsunami-safe cities\u201d. Sea walls and other structures are meant to provide complete protection from \u201cthe tsunami that comes every 200\u2013300 years\u201d, says Hirano. In the case of the biggest tsunamis, local governments will use zoning restrictions to prevent people from living in low-lying areas and will improve evacuation protocols to augment the protection provided by sea walls. Nature's David Cyranoski reflects on his recent visit to Tohoku. The debate over how to protect cities has sometimes been fierce. Some have questioned the value of expensive sea walls. According to Hirano, of 300 kilometres of such walls in the Tohoku region, 180 kilometres were swept away or destroyed after the Tohoku quake. That includes sections of a \u00a5120-billion (US$1.5-billion) breakwater in Kamaishi Port, which had been completed just three years earlier. The government announced last year that \u00a555 billion would be allocated to repairing it. Supporters say that the Kamaishi breakwater helped to reduce damage from the tsunami. According to simulations by the Port and Airport Research Institute in Yokosuka, the wall reduced the wave's height at landfall from 13.7 metres to 8.0 metres, cut its maximum height inland by 50% and gave residents an extra 6 minutes to evacuate. But those estimates may not be reliable, says Ioan Nistor, a coastal engineer specializing in tsunamis at the University of Ottawa in Canada, who visited Kamaishi just after last year's quake. He says the analysis incorrectly assumed that the breakwater remained intact during the tsunami. \u201cAlthough the presence of this breakwater has had a certain positive benefit,\u201d he says, \u201cgiven that a number of sections were knocked off by the tsunami impact, I am not sure if one can quantify so precisely its benefits.\u201d \n               Failed forests \n             At the other end of the cost spectrum are coastal forests, says Kentaro Imai of Tohoku University. During the past few centuries, coastal cities all around Japan have planted them, especially those in the tsunami-prone Tohoku region. But of the 230 kilometres of protective coastal forests, two-thirds were heavily damaged by last year's tsunami. For the most part, the trees did more harm than good, says Hermann Fritz, who studies the fluid dynamics of natural disasters at the Georgia Institute of Technology in Savannah. Fritz and some Japan-based colleagues carried out a survey of the city of Rikuzentakata, where the tsunami reached heights of 15 metres and destroyed a 200-metre-wide forest before heading inland and laying waste to large sections of the city. Only one tree \u2014 later named the 'tree of hope' \u2014 stood firm. \u201cThere was no 'tsunami control' by the forest,\u201d says Fritz. \u201cIt became 70,000 rams of floating debris impacting buildings.\u201d He is not surprised. In a post-disaster survey of Tohoku's Kesennuma Bay, his team measured flow velocities of about 10 metres per second for the water that coursed through the city of Kesennuma ( H. M. Fritz  et al .  Geophys. Res. Lett.   39,  L00G23; 2012 ). \u201cThere is no way a forest will survive that,\u201d Fritz says. Yet the Japanese government has decided to invest \u00a559 billion in replanting trees in Tohoku. Proponents argue that the trees also serve other purposes, such as providing a wind break that stops sand from blowing inland. And there is evidence that the forests have slowed tsunami waves resulting from some smaller quakes. Even last year there were some examples of success. In Hachinohe, which was hit by waves higher than 6 metres, the trees stood firm and blocked more than 20 boats from being swept inland and causing further destruction. Researchers hope that clues from last year's disaster can help them to improve the performance of coastal forests. Toyohiko Miyagi, who studies Earth and environment interactions at Tohoku Gakuin University in Sendai, examined the trees and found that those that caused the most damage still had their roots. \u201cThey didn't break \u2014 they came right out of the ground,\u201d says Miyagi. Trees with roots reaching deeper than 3 metres were usually able to withstand the force of the tsunami, however. \u201cOur recommendation is to build up the land under the trees so they hold,\u201d says Miyagi. This raised land would allow roots to grow longer and would create an extra barrier to protect inland areas. The trees that stood saved lives in other ways. Some people who missed the call to evacuate were able to climb to safety and wait for rescue. As Imamura drives around Sendai, he points to trees where people rode out the tsunami. He also shows where panicked people took refuge on bridges, schools and river embankments. Many of the official evacuation zones were swept away because they were too low, so the level at which people can be considered safe clearly needs to be revised. But that is the greatest challenge of the reconstruction, says Hirano. \u201cEven with the general agreement that people should build on higher ground, it's difficult to agree on where to build,\u201d he says. \n               Safety zone \n             According to the new law mandating tsunami-safe cities, local governments in coastal areas nationwide must simulate a massive tsunami's effect on the region and then develop zoning policies around the results. Areas where water is likely to reach depths of more than 4 metres are the most dangerous; no residences or hospitals would be allowed to be built in such red zones because people would have difficulty evacuating, especially at night. Offices or factories could be sited there, because workers could easily evacuate. Yellow zones, where water could reach levels of between 2 and 4 metres, are suitable for residences only if they are built on stilts or made with reinforced concrete (see 'Plan for a tsunami-resistant city'). Imamura helped Sendai officials to plan the city's zoning by carrying out some 200 simulations that varied parameters such as the height of the coastal sea wall and the position of a road that serves as an embankment. In Imamura's most cost-effective scenario, the town's 6-metre-tall segments of sea wall would be replaced by one long wall 7.2 metres high, which would act as the first line of defence. Behind that, the city would restore a coastal tsunami-control forest 200\u2013400 metres wide and 20\u201330 kilometres long. Farther inland, the coastal road would be raised from the current 2 metres to 6 metres above sea level. The region between the coast and the road would be declared a red zone and dotted with artificial hills to serve as evacuation sites for those working there. Other evacuation sites would be located farther inland. Imamura says that this scenario would reduce the inundated area by 60% compared with last year and could, if people were properly trained, avoid deaths. Although the proposal impressed local officials, many citizens were not happy that some 1,214 hectares and about 2,000 homes would be declared unsafe for habitation. Some have threatened to sue. But Fumio Yamada, head of Sendai's reconstruction division, agrees with the government's zoning law and says that he will enforce it. After tsunamis ravaged the town in 1896 and 1933, survivors moved up to the hills but later generations returned. \u201cIf you just warn people, if you don't have it in law, people will come back,\u201d says Yamada. Yet Iguchi, Iwanuma's mayor, says he will not kick people off of their land. \u201cI don't want them to live there. But people have their rights and there have been lawsuits,\u201d the mayor says. Some researchers worry that the simulations used in zoning decisions are being pushed too far. Satoru Masuda, a specialist in risk communication and disaster-prevention city planning at Tohoku University, says that zoning officials have not given sufficient consideration to the uncertainties of the simulations. And the debate looks set to spread, says Imamura, as local governments in all coastal areas conduct the mandatory simulation-based zoning. He sits on a committee expected to report back by next month with a reassessment of the tsunami potential of an earthquake in the Nankai Trough south of Tokyo. When all the maps are adjusted, millions of people will probably fall into red zones and could be told to move, he says. \u201cEven after the disaster, some people in Tohoku are resisting,\u201d says Imamura. \u201cOf course in places where there hasn't been a tsunami there will be debate. It will take time.\u201d Imamura hopes that the new institute set to open at Tohoku University on 1 April will help. The International Research Institute of Disaster Science (IRIDeS) will receive \u00a5800 million per year in funding for ten years, and will have roughly 25 teams. These will analyse the performance of disaster-mitigation technologies; develop better ways to support victims; research early-detection systems for megaquakes and tsunamis; and establish a medical system for coping with disasters and a digital archive of them, says Imamura, who will be vice-director. \n               Ignored warnings \n             A key focus is how to make people more aware of the danger that tsunamis pose. Tohoku University's Toshiaki Muramoto, a cognitive psychologist who will take a position in the new institute, plans to look at the way people process information during disasters. He notes that a survey of 870 survivors found that 60% quickly evacuated when they heard the alarms, but the rest waited. Of those, 75% said they \u201cfinished what they were doing\u201d first. \u201cThere's a tendency among some to hear a warning and think that they are ok,\u201d says Muramoto. He wants to understand why people usually play down risks and to use that information to devise better educational messages about natural hazards. \u201cThat could change things,\u201d he says. The digital archive at IRIDeS, which will consist of images and records of the tsunami, could serve as a global resource for education and policy planning, says Shosuke Sato, another Tohoku University researcher and future member of the institute. He says the database will be \u201clike Facebook for disasters\u201d. The real test of the post-disaster research and planning will come when Japan faces its next massive tsunami. In many ways, it will be a memory test \u2014 of how well humans, in this age of information, can package and transmit a message that makes future generations conscious of their vulnerability. It will take an emotional symbol, says a group of some 50 scientists, including Imamura, who propose preserving one of the boats that lodged in a house, an evacuation centre or the twisted warning sign on the beach. \u201cWe're thinking of making spots like this into memorials,\u201d Imamura says, \u201cso that people don't forget.\u201d See  Editorial page 123 \n                     Scientists report back from Fukushima exclusion zone 2012-Feb-24 \n                   \n                     Fallout forensics hike radiation toll 2011-Oct-25 \n                   \n                     Japan's tsunami warning system retreats 2011-Aug-11 \n                   \n                     Nature Special: Japanese earthquake and tsunami \n                   \n                     The Reconstruction Design Council in Response to the Great East Japan Earthquake \n                   \n                     The Reconstruction Agency \n                   \n                     Fumihiko Imamura \n                   \n                     Tohoku University Disaster Control Research Center \n                   \n                     Hermann Fritz \n                   \n                     City of Sendai \n                   Reprints and Permissions"},
{"file_id": "481254a", "url": "https://www.nature.com/articles/481254a", "year": 2012, "authors": [{"name": "Heidi Ledford"}], "parsed_as_year": "2006_or_before", "body": "Philanthropists will sometimes give large sums of money to support science \u2014 but researchers have to learn how to sell themselves first. Asking someone to give you a million dollars is not easy. In 1995, Bruce Walker was seeking philanthropic support to expand his HIV research programme at Massachusetts General Hospital in Boston. He had identified a possible donor: a venture capitalist and the brother of one of his patients. He had teamed up with a personal coach in fund-raising and rehearsed his pitch over and over. But during lunch with the prospective donor, he still nearly choked. \u201cI couldn't quite get it out to say, 'Would you give us a million dollars?',\u201d Walker recounts. Eventually he spat out his request \u2014 and was astonished when the venture capitalist agreed to the entire sum. \u201cAt that point, I fell off my chair,\u201d Walker says. He then raised another US$100 million from philanthropists Terry and Susan Ragon to launch the Ragon Institute of MGH, MIT and Harvard in Charlestown, Massachusetts, in 2009. He and his colleagues are now planning a formal seminar series on raising philanthropic support. His success at fund-raising, he says, \u201cis not because there's something special about me. It's because I got a little bit of training and I put in a lot of effort.\u201d Walker is not the only one with a determined approach to philanthropy. As public funding for research dwindles, scientists are increasingly seeking private benefactors (see  page 252 ). But they have a lot to learn if they are to win trust and money: how to schmooze contacts, promote their science and deliver results to deadline \u2014 all without over-promising on the work (see \u2018How to woo philanthropists\u2019). Much of this does not come naturally to scientists. \u201cYou have to sell yourself,\u201d says Cheryl McEwen, who, with her husband Rob, donated US$10 million to found the McEwen Centre for Regenerative Medicine in Toronto, in 2003. \u201cBut if you can build a case that we can understand, we'll be there for you.\u201d \n               boxed-text \n             To help build that case, research institutions \u2014 particularly those in the United States \u2014 are becoming savvier about how to approach philanthropists. In April 2010, Steve Rum, the vice-president for development and alumni relations at Johns Hopkins School of Medicine in Baltimore, Maryland, started training faculty at the school in fund-raising techniques. Elsewhere, scientists are enrolling in classes provided by external institutes. Researchers are happy to have the help, and not just because it can bring in new income. It can also allow them to pursue projects that government funding committees would find too risky to support. \u201cWhen you come to the government agencies with their committees and extreme accountability and taxpayer dollars, everything tends to come out a bit plain vanilla,\u201d says Tim Hunt, a Nobel-prizewinning biochemist at Cancer Research UK in London, who credits philanthropic support with helping him to continue his basic cell-biology studies even when applied research was more in vogue. \u201cIt's valuable to have funding that's a little bit out of the mainstream.\u201d \n               Personal approach \n             Philanthropy is supporting a growing slice of science: donations from US foundations to science, technology and medical research have grown from $793 million in 1999 to $1.7 billion in 2010, according to figures from the Foundation Center, an organization based in New York that analyses information about philanthropy. But although many scientists have experience in sending grant applications to foundations, few try to win multimillion-dollar donations from rich and generous individuals. Convincing a philanthropist to fund a programme means cultivating a personal relationship with them. \u201cIt's an old adage, but it's completely true: people give money to people,\u201d says Thomas Pierson, chief executive of the SETI Institute, an astrobiology research centre in Mountain View, California. After SETI was cut loose from NASA in 1993, it relied on Bernard Oliver, a well-connected member of its board and a former head of research and development at the computer firm Hewlett Packard in Palo Alto, California, to take its case to local entrepreneurs. The result: support from a who's who of technology luminaries, including Microsoft co-founder Paul Allen. Most scientists will need to look outside their usual network of colleagues and supporters for prospective donors, says Robert Klein, a real-estate magnate who helped to raise $34.5 million in the 2004 campaign for California's $3-billion stem-cell initiative. Most of that, he says, came from wealthy families with a vested interest \u2014 usually a sick relative \u2014 in seeing stem-cell technologies succeed. To reach these families, Klein recommends first building contacts with patients and those who support them. \u201cHave a patient advocate call ahead, and sit next to you while you make the pitch,\u201d says Klein. \u201cBetter yet, if you can get them to do it, have the advocate make the pitch for you.\u201d Walker urges researchers to be on continual alert for new contacts. \u201cWhen you travel, always try to get upgraded to business class,\u201d he says. \u201cThen talk to the people around you about what you do.\u201d This type of schmoozing takes time and a certain personality. Rum says that Morton Goldberg, an ophthalmologist at Johns Hopkins, is a fund-raising \u201csuperstar\u201d \u2014 helping to build an endowment that now funds more than 30 professorships. The secret to his success, says Rum, is his willingness to forge lasting relationships with philanthropists. Goldberg says he considers many of his donors to be close friends. He has travelled with them, spending weekends on their boats and in their vacation homes. \u201cIt has been an extremely rewarding experience, far beyond any connection with money,\u201d he says. Many physicians are reluctant to solicit their former patients, and with good reason, says bioethicist Sheldon Krimsky of Tufts University in Boston. \u201cIt's not OK for a doctor who is actively treating a patient to do it.\u201d Even after a patient has left the hospital, he or she may return, says Krimsky, and a physician who has received that patient's support may now be expected to provide special treatment. Another pitfall of philanthropy, Krimsky says, is donors who attach strings to their gifts. When the Charles G. Koch Charitable Foundation in Arlington, Virginia, agreed to fund a faculty position in economics at Florida State University in Tallahassee, it demanded the right to determine the criteria used to pick a professor, and to veto candidates it did not like ( S. Krimsky Nature 474, 129; 2011 ). \u201cIt was so egregious,\u201d says Krimsky. The university accepted the terms in 2008, but has argued that input from the foundation during the hiring process has not compromised its academic integrity. Krimsky worries that tough economic times can make researchers and their institutions more willing to accept intrusions into academic freedom in exchange for funding. Scientists agree, but several who have received philanthropic support point out that they appreciated the sound financial and strategic advice the donors offered. For many scientists, the most difficult step is pitching their work as if they were an entrepreneur in need of investment, says Garen Staglin, who, with his wife, Shari, donated some of the family's earnings from their vineyard in Napa Valley, California, to mental-health research after their son was diagnosed with schizophrenia. \u201cYou have to go into sell mode,\u201d he says. \u201cYou have to be able to say 'there are no guarantees here but if this works, this is the kind of stuff we think is possible in our lifetime'.\u201d But that type of sell tends to be easier for applied projects, such as potentially life-saving medical studies, than for basic research. Selling research can also require a willingness to set deadlines. \u201cIn difficult economic times, the philanthropies become very goal oriented,\u201d Klein says. It's a practice that many scientists resist, because science rarely goes according to plan. When it doesn't, fund-raising specialists say that it's best to acknowledge the failure and stress the importance of the lessons learned. \u201cYou will still give them the confidence that there are incremental improvements,\u201d says Klein. \n               Philanthropy school \n             Research institutions often rely on professional fund-raisers to approach philanthropists, but Johns Hopkins isn't alone in training faculty members. Advancement Resources in Cedar Rapids, Iowa, has seen a fivefold increase in demand for its fund-raising training over the past four years, says chief executive Joe Golding. Institutions pay $17,500 for a four-hour workshop of lectures and role-playing exercises. Golding says that basic researchers would do well to target entrepreneurs. \u201cThey are, by definition, risk takers,\u201d he says. \u201cAnd they value leverage.\u201d Stress that a $30,000 investment now could lead to a million-dollar government grant later, he advises, and emphasize the impact a project would have on a topic that is close to the entrepreneur's heart. Golding, Rum and other experts also tell their trainees to listen for clues to how much a donor might be willing to commit. \u201cIf I ask for $100,000 and they say 'yes' right away, then I didn't ask for enough,\u201d says one fund-raiser at a large research university who asked not to be named. \u201cIt's a common mistake.\u201d Rum even conducted a trial to find the best way to teach faculty members about how to approach former patients. He divided faculty members into three groups. One received only weekly fund-raising lessons by e-mail. The second also attended a lecture on the topic. The third received individualized coaching, including how to prepare an 'elevator pitch' \u2014 a brief description of research so compelling that it could capture someone's attention in the time it takes to travel between floors. Three months after coaching, the first two groups had brought in no money. The third had collected five gifts totalling $219,550 ( S. Rum and S. M. Wright  Acad. Med.   87,  55\u201359; 2012 ). Walker says that this type of personal coaching \u2014 not to mention the agony of asking for money \u2014 has been more than worthwhile. \u201cI think we as a scientific community don't do a great job in articulating the transformational power of philanthropy,\u201d he says. \u201cBut that funding has allowed me to do things that I never could have considered if I'd been trying to do it through traditional sources.\u201d Too few researchers take advantage of philanthropy, says Goldberg. \u201cThe most common mistake is not to try.\u201d \n                 See Editorial \n                 page 238 \n                 and Comment \n                 page 260 \n               \n                     Research at Janelia: Life on the farm 2011-Nov-16 \n                   \n                     Charities seek cut of drug royalties 2011-Jul-20 \n                   \n                     Neuroscientists unite for 'Moon shot' 2011-May-26 \n                   \n                     Tech titans plan to save the planet 2009-Apr-24 \n                   \n                     Charitable bodies hit by credit crisis 2008-Oct-08 \n                   \n                     Philanthropy in science special \n                   \n                     Foundation Center \n                   Reprints and Permissions"},
{"file_id": "483144a", "url": "https://www.nature.com/articles/483144a", "year": 2012, "authors": [{"name": "Richard Monastersky"}], "parsed_as_year": "2006_or_before", "body": "What can scientists learn from the Tohoku tragedy to improve tsunami forecasting and save lives? As soon as the shaking died down on 11 March last year, Ken-Ichi Sato stumbled back to his office and pressed the alarm button, triggering sirens throughout the city of Kesennuma in northeastern Japan. As the emergency manager of the coastal community, Sato had to alert the 64,000 people there that a tsunami might be coming. A minute later, that threat became more real when Sato received word from the Japan Meteorological Agency (JMA) that the quake was large \u2014 magnitude 7.9 \u2014 and located off the coast of Miyagi Prefecture, where Kesennuma is located, in the Tohoku region. Residents there should brace for a 6-metre tsunami, warned the agency, and the neighbouring Iwate and Fukushima prefectures should prepare for waves half that height. Sato immediately issued an evacuation warning over the city's loudspeakers. But when the tsunami hit around half an hour later, it dwarfed the original JMA estimates. The water surging into Kesennuma reached 9 metres high, and the waves battering other coastal sites topped 20 metres, pouring over the sea walls and barriers that buttress much of the Tohoku coastline. Some 15,000 people died as a result of the tsunami \u2014 some of whom had reportedly not fled to higher ground because the projected wave heights had made them think they were safe. In Kesennuma alone, 1,031 people died and hundreds are missing. Sato thinks that the toll might have been lower had he learned the true size of the tsunami earlier. \u201cWe could have raised the intensity levels of the alerts,\u201d he says. \u201cWe could have made sure that people got to a high-enough place.\u201d A year later, scientists and emergency managers are still struggling to improve their tsunami detection and warning systems before the ocean strikes again. Japan will soon start to install a \u00a532.4-billion (US$402-million) system of ocean-bottom sensors to provide advanced warnings of tsunamis heading towards the coast. And the United States is considering moving some of its deep-ocean warning buoys off the Pacific Northwest coastline closer to the Cascadia subduction zone, where a mammoth quake is expected, perhaps within the next few decades. The efforts are an extension of advances made since 2004, when a tsunami caused by an earthquake off the coast of Sumatra killed more than 230,000 people. The disaster raised awareness of tsunamis and prompted nations to pump money into research and equipment. As a result, emergency managers can now effectively forecast how tsunamis will cross ocean basins and hit coastlines thousands of kilometres from a quake's source. The next, more difficult, goal is to improve warnings for close-in regions, which may only have minutes to react. \u201cHistorically, maybe 95% of tsunami deaths are from local or regional tsunamis,\u201d says Laura Kong, director of the International Tsunami Information Center in Honolulu, Hawaii. \u201cHow do the United States and the global community address that with the resources we have?\u201d Japan intends to meet that challenge with its new sensor network, which is designed to keep tabs on the eastern coastline (see 'Safety net'). Operated by the National Research Institute for Earth Science and Disaster Prevention (NIED) in Tsukuba, the system will consist of 154 sea-floor observatories, each of which contains a seismometer and a water-pressure gauge that can sense the passage of a tsunami, according to Toshihiko Kanazawa, head of the team developing the network. Fibre-optic cables will connect the units in six long loops that each reach the coast at two widely separated locations. According to the NIED, that design will keep the system online even if tsunamis damage a land station or destroy a cable, as happened last March to some sea-floor sensors stationed off the Tohoku coast. The plan is to finish the new network by the end of March 2015. \n               Tried and true \n             A large cabled network is already in place in the Nankai trough area south of Tokyo, where a large earthquake is expected in the coming decades (see  Nature 476, 391\u2013392; 2011 ). The system is \u201cfield-proven\u201d, says Kanazawa. \u201cIts simplicity is suitable for tsunami warning use.\u201d The NIED sensors will sit between the coastline and the earthquake source \u2014 the offshore trench where the Pacific plate dives beneath the plate carrying northern Japan. When the Pacific plate jerks forward, the edge of the overlying plate springs up and displaces a huge volume of water, triggering a tsunami. The waves race through the deep water of the open ocean at speeds of roughly 700 kilometres per hour. They alter the sea level by only a metre or two at most as they travel far from the source. But when they hit shallow water, the waves slow down to less than one-twentieth of their former speed and rear up, creating giant surges that sweep ashore. When the NIED network is in place, it will detect the pressure change caused by the tsunami as it travels from the deep ocean over the continental shelf, providing between 5 and 20 minutes of warning for people on the shore. As a complement to that system, the JMA plans to install three sea-floor sensors on the opposite side of the subduction zone, to catch tsunamis as they speed through the open ocean. Instead of transmitting data through a cable, these sensors will send acoustic signals to nearby buoys that then relay the information up to geostationary satellites. The buoys can be installed faster than the cabled network and will be put in place this year, says Kanazawa. They will be part of an existing network of buoys known as DART, for Deep-Ocean Assessment and Reporting of Tsunamis. The United States has 40 such buoys stationed around the Pacific and Atlantic, and other nations have purchased 14 buoys, which are positioned at sites in the Pacific and Indian oceans, with almost all of the data shared internationally. The impetus to develop the DART system came in part from an expensive false alarm, recalls Eddie Bernard, who designed the system and retired as head of the US National Oceanic and Atmospheric Administration's Pacific Marine Environmental Laboratory (PMEL) in Seattle, Washington, in 2010. When a magnitude-8.0 quake struck the Aleutian Islands in 1986, Hawaii evacuated its beaches and other low-lying coastal areas at a cost of some $40 million, including lost revenue. But when the tsunami washed ashore, it was only about 15 centimetres high. The civil-defence leader called up Bernard, who was head of a lab doing tsunami research, and said: \u201cWhy can't you do better?\u201d The programme got a boost when a 1992 earthquake off the coast of northern California raised concern that the Cascadian subduction zone might let loose with a giant earthquake and trigger a devastating tsunami. So in 1997, Congress provided funds for a tsunami mitigation programme, and Bernard finished his long-term project to develop deep-ocean tsunami sensors. He and others originally thought of DART buoys as sentinels for the entire ocean, watching for tsunamis from distant earthquakes \u2014 the type that usually threaten Hawaii. The buoys had accordingly been stationed far out to sea, both to catch the largest number of tsunamis and because researchers worried that if the sensors were close to the source of an earthquake, the seismic vibrations would drown out any tsunami signal. But the Tohoku quake changed that thinking. At a meeting in January at the PMEL, Japanese and US scientists discussed ways to filter out the seismic vibrations from the sensor data, which would mean that the sensors could be deployed much closer to faults, says Vasily Titov, a tsunami modeller at the PMEL. \u201cWe can put the sensors in a place 5 minutes away from the sources,\u201d he says. Once the front of the tsunami reaches a DART sensor, Titov says, it takes another 5\u201310 minutes for half of the wave to pass by, thereby revealing the height of the tsunami. The United States is now hoping to move some of its DART buoys nearer to earthquake sources \u2014 along the Cascadia subduction zone and in many other regions, says Titov. Warning centres will then combine the DART data with spatial models of coastlines to predict the severity of the flooding more quickly. \u201cWithin half an hour, you can get a very high-quality forecast showing which areas are going to be inundated,\u201d he says. And that would help emergency managers to decide which areas should be evacuated, and when to urge people to move to higher ground. In the regions closest to an earthquake, however, many people would die if they waited for those results. The first waves from a Cascadia tsunami can hit in 15\u201320 minutes, and the problem is even worse in Japan and the Aleutian Islands, where some regions have only a few minutes of lead time. Emergency managers are therefore developing a tiered approach, in which they issue quick warnings that are updated as measurements come in from the sea-floor sensors. \n               Ups and downs \n             The Tohoku earthquake shows how those data can help \u2014 and hurt. At an international meeting last month in Sendai, Japan, Osamu Kamigaichi from the JMA described some of the problems that his agency ran into during the disaster. When the quake struck at 2:46 p.m. local time, the agency quickly determined its size and location from records of short-period seismic waves, the first data to become available. The JMA then used pre-computed tsunami simulations for the estimated quake to forecast the height of the waves. The warning with those details went out within 3 minutes. This method works well for quakes smaller than magnitude 8, but it can't gauge the size of larger shocks. The JMA didn't consider that a problem, however, because the estimated size of the Tohoku event was 7.9, about the size of the largest earthquake expected there. But the quake turned out to have a magnitude of 9.0, more than ten times stronger. The first hints that something was amiss came at 2:58 p.m., 9 minutes after the first warning, when a cabled pressure sensor picked up an unexpectedly large change in sea level off Iwate prefecture (see 'Warning signs'). But the agency did not have a fully developed method for using data from that sensor to update the tsunami warnings. \n               boxed-text \n             At 3:10 p.m., a Global Positioning System sensor off the Iwate coast also detected a large tsunami. The JMA used that reading to estimate how much the tsunami would grow when it hit the shallow coastal waters. At 3:14 p.m., an upgraded warning went out predicting 10-metre tsunamis in Miyagi and 6 metres in Iwate and Fukushima. But by then, the first waves had already slammed into the coast. The JMA may also have caused confusion when it released the initial wave amplitude from a coastal tide gauge, which was 20 centimetres. The earliest waves in a tsunami are not always the largest, and that early statement could have caused people to delay or even halt their evacuations, says Kamigaichi. The agency plans to adopt a new tsunami warning procedure by the end of the year. It is developing an analysis tool to tell whether the quick method is likely to underestimate the size of the quake. The tool uses recordings of the strongest vibrations from a broad area and the early measurements of long-period vibrations. If that additional information indicates that the estimated size is accurate, then the JMA will issue a warning that includes the size of the expected tsunami. But if the quake estimate seems inaccurate, the agency will issue a warning for the worst-case scenario \u2014 based on historical data in the area \u2014 and will use only qualitative descriptions such as 'huge' or 'large' to describe the anticipated tsunami. The agency will then update the warning about 15 minutes later, once the data have arrived from offshore tsunami sensors. \n               Saving lives \n             Modellers in the United States and Japan are confident that their work will eventually pay off. Kenji Hirata, a senior researcher at the JMA, says that he needs several years to finish developing the algorithms for assimilating data from offshore tsunami sensors into forecasting tools for close-by earthquakes. The work may be particularly useful for regions outside the immediate vicinity of the quake, where people may have an hour or more before the tsunami hits but could still face mammoth waves. In those cases, the high-tech data could help emergency managers to decide whether an evacuation is justified. Even for areas where the first wave will hit quickly, direct measurements could help because they can give an idea of whether subsequent waves will be bigger or smaller. And they can provide advance warning of when a relatively small earthquake has triggered an underwater landslide that might then spawn a large tsunami. That sequence happened after a magnitude-7.1 quake in Papua New Guinea in 1998, and it killed more than 2,000 people, many of whom didn't evacuate because the earthquake was not particularly large. In such cases, offshore tsunami sensors might save people because they can pick up events that seismic readings miss. Researchers caution, however, that no amount of expensive hardware can replace basic education about tsunamis. In many cases, communities simply won't have time to wait for estimates of the tsunami's size. \u201cIf you live in a coastal area, you have to be your own warning centre,\u201d says Costas Synolakis, a tsunami researcher at the University of Southern California in Los Angeles. \u201cIf the earthquake lasts for more than 30 seconds, it means it's a big earthquake and local, and you have to evacuate. If it lasts for over 2 minutes,\u201d he says, \u201cit means run for your life. This is a giant.\u201d Additional reporting by David Cyranoski. See  Editorial page 123 \n                     Japan's tsunami warning system retreats 2011-Aug-11 \n                   \n                     Hidden depths 2011-Jun-22 \n                   \n                     Rebuilding seismology 2011-May-11 \n                   \n                     Nature Special on the Japan earthquake and tsunami \n                   \n                     International Tsunami Information Center \n                   \n                     Japan Meteorological Agency's Tohoku earthquake page \n                   \n                     National Data Buoy Center \n                   \n                     Pacific Tsunami Warning Center \n                   \n                     West Coast and Alaska Tsunami Warning Center \n                   Reprints and Permissions"},
{"file_id": "483138a", "url": "https://www.nature.com/articles/483138a", "year": 2012, "authors": [{"name": "Geoff Brumfiel"}, {"name": "Ichiko Fuyuno"}], "parsed_as_year": "2006_or_before", "body": "Japan's worst-ever nuclear accident displaced more than 100,000 people. Many could now safely return home. Yet mistrust of the government prolongs their exile. Yoichi Tao is busily shovelling dirt in Iitate, a small village about 40 kilometres from the ruined Fukushima Daiichi nuclear plant. It is certainly different from his day job. Tao has a background in high-energy physics, and teaches students about information-security systems at Kogakuin University in Tokyo. But on this sunny February morning, he and a dozen volunteers have joined local farmers in removing the top few centimetres of radioactive soil from rice fields. \u201cWhen the soil is frozen, we can remove it easily, like a board,\u201d Tao says. In a corner of the field, they dump the soil in a hole lined with absorbent sheets. \u201cWhen spring comes, the ice melts but the [radioactive] caesium will be absorbed, so we can protect it from leaking out,\u201d he explains. The volunteers, mostly researchers, informally call themselves  Fukushima Saisei-no Kai  (roughly translated as the Fukushima revitalization association), and come armed with car-mounted sodium iodide scintillators and Geiger counters linked to the Global Positioning System. Only in one of the world's most technically advanced societies could an ad hoc group have the means to cope with radioactive decontamination. But there is a dark side to Tao's efforts: he is there because he and many others have lost faith in their government. \u201cSince 11 March, people haven't trusted scientists who receive funding from the government,\u201d Tao says. \u201cThey trust people who act without government funding and who work together with them.\u201d One year after Japan's nuclear crisis began, researchers contacted by  Nature  say that a strong, evidence-based understanding of the accident, and the risks the reactors continue to pose, is within reach. The findings could inform decisions on public health, environmental clean-up and economic recovery (see 'The fallout'). But outside observers, and even some critics in Japan, are increasingly worried that the loss of public trust, together with politicians' desperation to regain it, could undermine rational decision-making about clean-up and resettlement. At stake are the futures of more than 100,000 residents who have been displaced from the area around the plant, and billions of dollars in economic activity across the region. \n               Meltdown \n             The crisis began on 11 March 2011, when a magnitude-9.0 earthquake on the Pacific floor sent a massive wall of water rolling towards the Japanese coastline (see  page 141 ). The three operating reactors at Fukushima Daiichi automatically shut down in the moments after the quake, but 41 minutes later the tsunami burst through the plant's defences and inundated the reactor buildings. Water flooded emergency generators, leaving the plant without power for cooling systems, while radioactive decay continued to heat the cores. In the control room, workers struggled to run crucial instruments, using torches and car batteries scavenged from nearby vehicles. Over the following days, the last line of emergency systems failed and the three reactors melted down. The process released hydrogen gas, which eventually triggered explosions in the reactor buildings. Volatile radioactive chemicals, notably iodine-131 and caesium-137, began to stream into the air and sea. When unit 4 of the Chernobyl nuclear power plant exploded in 1986, the Soviet government imposed a strict information blackout. The situation could hardly have been more different at Fukushima: within the first 24 hours, the government began reporting radiation readings. In the following days and weeks, the deluge of information became swollen with data from university researchers, the military, international monitors, representatives of the US government and concerned citizens such as Tao. \u201cWe've almost got too much,\u201d says Malcolm Crick, secretary of the United Nations Scientific Committee on the Effects of Atomic Radiation (UNSCEAR) in Vienna. At the UN's request, the committee has spent the past six months trying to unpick which data came from where, and how they were calibrated. The committee will deliver its preliminary findings in May, and Crick says they should be able to say a great deal about how much radioactivity was released, where it went, and how much workers and the general public received. \n               Dose levels \n             It is already evident that rapid evacuation and careful screening protected Fukushima's citizens from harm, says Wolfgang Weiss, a physicist at Germany's Federal Office for Radiation Protection in Munich and chair of UNSCEAR. Early and informal analyses by his colleagues suggest that no members of the public received a dangerous dose of radiation. That finding is supported by a sweeping public-health study begun last summer at Fukushima Medical University. With a \u00a578.2-billion (US$958-million) budget, the survey is designed to monitor the health of some 2 million people from the region for 30 years. According to the latest estimates, released on 20 February, 99.3% of 9,747 people living in towns or villages close to the plant received less than 10 millisieverts (mSv) in accumulated effective dose in the first four months after the accident. The highest recorded dose was 23 mSv, well below the acute 100-mSv exposure levels linked to a slight increase in cancer risk. Yet suspicion is hampering the ambitious health survey, which hopes to nail down the long-term impact of Fukushima on ordinary citizens. Despite efforts to promote the study among evacuees, participation stands at just 21%. \u201cMost of the people I've met here refuse to fill in the questionnaires. They don't see credibility in what the government does, and they say, 'this is just a survey of guinea pigs',\u201d says Shizuko Otake of the non-profit organization Shalom, which supports refugees in neighbouring Minamisoma and Iitate. The roots of mistrust can be traced to the confusing days immediately after the explosions, when authorities made a series of inconsistent statements, issuing radiation readings that often turned out to be incorrect. As radioisotopes spread from the plant, the government was repeatedly forced to raise its recommended safety limits for radiation exposure to citizens and workers \u2014 otherwise, it would have been legally required to evacuate the site immediately. As a result, some Japanese people believe that the government is corrupt; others think it is incompetent. The prevailing feeling is that \u201cwhat the government says always changes\u201d, Otake says. Abel Gonz\u00e1lez, a radiation-protection expert with Argentina's nuclear regulatory authority in Buenos Aires, says that the government was forced to raise the safe limits because it started with an international standard that made no provision for accident scenarios or for emergency workers likely to receive higher doses. Without clear guidelines, the Japanese government simply had to increase the safe limits to enable people to keep working to bring the nuclear plant under control, he says. The downside is that \u201cwhen you relax the regime in the middle of an accident, you lose credibility immediately\u201d. In an effort to win back the trust of its citizens, the government is planning one of the most extensive and costly clean-up operations ever \u2014 an effort some experts view as unrealistic. Last autumn, it announced plans to bring radiation doses from the accident to below 1 mSv per year in as much of the evacuation zone as possible. But the goal is based on an international standard for doses received during the normal operation of a nuclear plant, not following an accident. It is also seen by veterans of nuclear accidents as highly ambitious, especially given the mountainous and heavily wooded terrain around Fukushima. \u201cThe best thing to do, according to Chernobyl, is to really turn the first metre of soil upside down,\u201d says Weiss. \u201cBut if you do that, you would kill the whole ecosystem.\u201d The Japanese authorities acknowledge the problem, and have started trialling a variety of clean-up methods in Fukushima. The most prominent pilot project began last November under the Japan Atomic Energy Agency (JAEA), with an estimated budget of \u00a510.9 billion. The JAEA contracted the project to joint ventures led by three major construction companies \u2014 Taisei, Obayashi and Kajima \u2014 which are testing various technologies to clean up radioactive materials in 11 cities, towns and villages whose citizens mostly remain evacuated. \u201cI am impressed how companies have come up with novel ideas to remove decontaminated caesium based on existing technologies,\u201d says Shinichi Nakayama, deputy director of the JAEA's Fukushima Environmental Safety Center. For example, scouring caesium from roads with a high-pressure water jet was thought to be insufficient because contaminated water would simply spread out across the pavement. But engineers have modified the system to recover the contaminated water, purifying and recycling it, he says. Many communities are taking matters into their own hands. With the help of independent researchers like Tao, they are removing contaminated soil and conducting other clean-up operations. But without a central disposal location, Weiss says, these clean-up operations are just creating a different waste problem. \u201cPeople are not allowed to transport the waste, so they put everything in holes on their property.\u201d The government's ambitious goals for decontamination could harm evacuees by inciting needless fears, says Oleg Nasvit, a radioecologist at the National Institute for Strategic Studies in Kiev, Ukraine, who has studied the impact of the Chernobyl nuclear accident. In 1986, the Soviet authorities demanded \u201cobligatory evacuation\u201d of residents living in regions where the additional radiation exposure from the accident was greater than 5 mSv per year, he says. Evacuees struggled to cope with their dislocation, and many were stigmatized because they had come from a contaminated region. \u201cFrankly, this brought to people more harm than good,\u201d he says. Setting low radiation-dose limits is already damaging the economy around Fukushima. Later this year, the health ministry is planning to lower the safe level for caesium in vegetables, grain and other foods from 500 becquerels per kilogram (Bqkg \u22121 ) to 100 Bqkg \u22121  (see 'The limits'). Tomoko Nakanishi, a researcher specializing in plant radiophysiology at the University of Tokyo, says that food with radioactivity lower than 500 Bqkg \u22121  is not harmful to human health, and that areas not heavily affected by Fukushima's radioisotopes may already exceed the proposed lower limits because of older nuclear fallout. Some mushrooms from Chiba prefecture, more than 200 kilometres south of Fukushima, exceed 100 Bqkg \u22121 , for example, but the relative amounts of radioisotopes are characteristic of residual contamination from nuclear weapons tests in the 1950s and 1960s or the Chernobyl accident, not Fukushima. Fukushima prefecture is among the largest rice producers in Japan, but last year the agriculture ministry considered completely prohibiting cultivation where crops contained more than 100 Bqkg \u22121  of caesium. Nakanishi and her colleagues at the University of Tokyo were concerned that the excessively stringent safety measures could hinder not only the recovery of the region's agriculture, but also the collection of scientific data. \u201cContinuous cultivation is very important to predict what will happen in the future. We don't know if rice paddies that produced high-level caesium will do the same this year,\u201d she says. Backed by strong demand from farmers, the ministry recently decided to allow cultivation in most areas of Fukushima as long as cities, villages and towns can prevent the distribution of rice containing more than 100 Bqkg \u22121  of caesium. But the ministry will allow only experimental cultivation in areas that produced rice containing more than 500 Bqkg \u22121  last year. In April, the environment ministry will begin the nation's full-scale decontamination programme, the core part of a \u00a5990-billion recovery roadmap. The ministry says that it wants science to underpin its programme. \u201cWe would like to make detailed plans based on feedbacks from government-led pilot projects as well as other scientific data,\u201d says Kuniaki Makiya, an official in charge of the decontamination roadmap. Already, the ministry has decided to prioritize areas of mid-level contamination above those with very high or very low levels, a move that Nasvit says makes the plan more credible because the areas that will benefit the most from decontamination will be dealt with first. At the moment, there is no clear plan for allowing displaced residents to go home. Although the government's goal is to ensure that people should not receive a dose in excess of 1 mSv per year if they return, it is not a firm rule. Indeed, locals can already go home to villages outside the 20-kilometre restricted zone around the plant if they choose, but many public facilities, such as schools, have not yet reopened. Nasvit believes that citizens should move back, even to zones where they might receive up to 20 mSv per year. Gonz\u00e1lez agrees, noting that in some parts of the world, natural annual levels of radiation are in the range of 10\u2013100 mSv. But Tatsuhiko Kodama, director of the Radioisotope Center of the University of Tokyo, thinks the safety margin is not so clear cut. \u201cThere are various interpretations about what to do in the area of 1\u201320 mSv per year,\u201d he says. He agrees, though, that ultimately the public must choose the course of action. \u201cThe most important thing is to respect what the residents think. We have to proceed with plans based on their decisions. Fred Mettler, a radiologist serving on the UNSCEAR panel, agrees. Rather than setting a strict number or limit, he says, the discussion should be more open ended. \u201cWe tell the people what's there, we tell people what the consequences are, and they decide whether to accept the risk.\u201d \n               boxed-text \n             \n                 See  \n                 \n                     Editorial \n                   \n               \n                     Earthquake hazards: Putting seismic research to most effective use 2012-Mar-07 \n                   \n                     Energy policy: The nuclear landscape 2012-Mar-07 \n                   \n                     Seismology: Why giant earthquakes keep catching us out 2012-Mar-07 \n                   \n                     Rebuilding Japan: After the deluge 2012-Mar-07 \n                   \n                     Lessons of a triple disaster 2012-Mar-07 \n                   \n                     Tsunami forecasting: The next wave 2012-Mar-07 \n                   \n                     Tokyo Electric Power Company \n                   \n                     United Nations Scientific Committee on the Effects of Atomic Radiation \n                   \n                     Japan Atomic Energy Agency \n                   Reprints and Permissions"},
{"file_id": "481252a", "url": "https://www.nature.com/articles/481252a", "year": 2012, "authors": [{"name": "Jim Giles"}], "parsed_as_year": "2006_or_before", "body": "With conventional sources of money drying up, some scientists are turning to crowd-funding. In October 2010, Cesar Harada found himself in New Orleans with little money and a big idea. Harada, an engineer, had been working on oil-spill mitigation at the Massachusetts Institute of Technology in Cambridge. But he quit the lab in frustration at what he saw as a slow pace of work and a focus on expensive solutions. He travelled south to join the clean-up operation for the Deepwater Horizon oil spill in the Gulf of Mexico. Once there, his mind turned to a futuristic solution: a low-cost clean-up robot that local people could build and deploy themselves. Yet his two criteria for the project \u2014 a quick build and open-source intellectual property \u2014 all but ruled out academic or industrial funding. Harada turned to Kickstarter, a website used by authors, film-makers and artists in search of project funding. He uploaded a pitch, set a goal of raising US$27,500 and listed a series of small rewards for donors. Then he started to network furiously. Money came in from friends and engineering colleagues. A few companies heard about his idea; they pitched in several thousand dollars each. Word reached people he had never met, and they contributed too. When Harada's funding appeal closed in April 2011, he had raised almost $34,000 \u2014 enough to assemble a team of engineers and build a prototype of the clean-up robot. \n               Public interest \n             If Harada's experience sounds like a one-off, think again. Crowd-funding \u2014 raising money for research directly from the public \u2014 looks set to become increasingly common. Established platforms such as Kickstarter are wooing scientists. And similar websites dedicated to connecting scientists with potential funders are being built, or have already launched. The public seems to be responding. Last year, for example, a group of scientists wanting to map water quality along the Mississippi River raised $64,000 in a trial project on an online crowd-funding platform called the Open Source Science Project (OSSP). At a time when universities and research funding agencies are facing budget cuts, the strategy is attracting attention \u2014 as are other ways to raise philanthropic support (see  page 254 ). \u201cIt's timely because of what's happening with traditional funding sources,\u201d says Daniel Gutierrez, co-founder of FundaGeek, a crowd-funding platform for technology projects that launched last month and is based in Yucca Valley, California. For crowd-funding to make a real difference, advocates will have to prove that the process \u2014 which sometimes sidesteps conventional peer review \u2014 channels money to good projects, not just marketable ones. But if they succeed, there may be an unexpected bonus: it might help to forge a direct connection between researchers and lay people, boosting public engagement with science. \u201cThis is one of the most appealing aspects of crowd-funding,\u201d says Jennifer Calkins, an ecologist at Evergreen State College in Olympia, Washington, who has raised money for fieldwork on Kickstarter. \u201cWe can involve society in the creative journey that we make as scientists.\u201d Online crowd-funding has already proved its worth in other fields. Kiva, a website through which individuals loan small amounts to entrepreneurs in the developing world, is one notable success: more than 600,000 lenders have channelled almost $275 million through the site since 2005. US President Barack Obama's 2008 election campaign raised a record-breaking $780 million, much of it from small online donations. And donors have pledged more than $100 million to 13,000 Kickstarter projects. By drastically simplifying the process of connecting donor with cause, the Internet has unleashed a new enthusiasm for giving. Scientists have come a little late to the crowd-funding party, because they have conventionally had other funding streams. Jai Ranganathan, an ecologist at the University of California, Santa Barbara (UCSB), is one of several researchers trying to make up for lost time. Last November, he helped to launch the #SciFund Challenge, an exercise in which close to 50 research groups had six weeks to raise money through proposals on a crowd-funding platform called RocketHub, which mostly serves artists and entrepreneurs. The challenge raised a total of $76,000. Brian Meece, RocketHub's chief executive, based in New York, says that research projects are a \u201cnew and exciting\u201d use for his platform, and that he will retain the science section now that the challenge is over. \n               Cash for questions \n             Other crowd-funding enthusiasts are developing donor sites dedicated exclusively to research projects. Sixteen projects are currently vying for funds on SciFlies, a site launched last November by David Fries, a marine engineer at the University of South Florida in St Petersburg. This year, the OSSP hopes to follow up on its success with the Mississippi study by launching a fund-raising appeal for around ten research proposals, says Priyan Weerappuli, a neuroscientist at the University of Michigan in Ann Arbor and the founder of the project. Each site operates in a slightly different way, but there are common themes. Researchers start by describing and pricing a project, which they submit to the site for approval. If accepted, the pitch is placed online and donors have a few weeks or months to read the proposal and make a donation. Some sites operate on a non-profit basis and channel all proceeds to researchers; others are commercial concerns and take a cut of the money raised. But although cash-starved scientists are lining up to list their projects, some are also expressing concerns. Take the issue of peer review. SciFlies and the OSSP post projects only after passing them through an expert review process, but Kickstarter's only requirement is that projects have \u201ca creative purpose\u201d \u2014 as defined by the site's owners. Projects in the #SciFund Challenge did not undergo formal peer review: Ranganathan and co-founder Jarrett Byrnes, a fellow UCSB ecologist, checked only for obvious fraud. \u201cI don't care if people have badly thought-out projects,\u201d says Ranganathan. That may sound like a recipe for shoddy science, but crowd-funding advocates say that the process has an inbuilt peer-review system, driven by the donors. Most donors will hear of a project through their social networks. They might be former colleagues of the project owner, or members of the public interested in an ecological study site. So project owners put their reputation among their peers and supporters on the line every time they post a proposal. \u201cThere's a strong incentive to be honest,\u201d says Kickstarter co-founder Yancey Strickler. \u201cSocial forces carry a lot of weight.\u201d The system also puts a premium on inventive, well-thought-out proposals. A poorly conceived pitch that attracts no funds will do nothing for a scientist's career; nor will one that never delivers on its promises. \u201cIt may not be formal peer review, but crowd-funding has validation based on common trust,\u201d says Meece. \u201cIt's a pretty heavy filter.\u201d Even Sally Rockey, deputy director for extramural research at the US National Institutes of Health in Bethesda, Maryland, sees benefits in an alternative evaluation system if it helps organizations to achieve their research goals. Peer review \u201cis not the only model\u201d, she says. Some sites are trying to enhance this informal review process. FundaGeek has a discussion forum, the 'Geek Lounge', where potential donors are encouraged to debate the merits of a proposal. Last August, the equivalent forum on Kickstarter helped to halt one questionable project. The proposal, for a product called the Tech-Sync Power System, aimed to develop a smartphone app that controls home lighting. It attracted more than $27,000 in pledges, but Kickstarter users with electronics knowledge started to question the viability of the system. The project owner, who could not be reached for comment, eventually deleted his proposal as the criticism mounted, and none of the donors lost their money. \n               The hard sell \n             Another objection to crowd-funding may be harder to shake. To sell a project, researchers need an attention-grabbing story (see \u2018How to woo the crowd\u2019). That is easy to construct if your subject of study is, say, saving pandas or curing cancer. It is less so for researchers working on polymers. So will crowd-funding prove profitable only for 'sexy' science? \n               boxed-text \n             Fries concedes that crowd-funding inherently favours certain types of project, particularly those in applied research. He is an optimist, saying that if the approach takes off, conventional funding agencies will simply have to compensate by upping their support for basic science. Ranganathan, an enthusiastic communicator who runs his own podcast, bristles at the suggestion that crowd-funding will create a two-tier system. \u201cIt's all about telling a compelling story about the research,\u201d he says. \u201cPanda researchers start ahead, but I 100% believe anyone can do it.\u201d A polymer chemist might, for example, focus on new materials that could come out of his or her work. The pressure to communicate the potential fruits of a research project should not be seen as a burden, adds Ranganathan. Most crowd-funding sites expect project leaders to offer donors something in exchange for their contribution, such as regular updates on the progress of the research. For those who make larger donations there might be visits to a lab or field site. In the case of the Mississippi water-quality study, donors in the region were encouraged to help with collecting water samples from the river. This process should help to forge stronger bonds between researchers and the public. Whether all this works in wider practice remains to be seen, but many welcome the experiment. \u201cScience thrives on diversity,\u201d says Jack Stilgoe, who studies science and society at the University of Exeter, UK. \u201cWe shouldn't be afraid of innovations in how it is funded. We should be more afraid when research money is all getting spent in the same way on the same sorts of things.\u201d\n \n                 See Editorial \n                 page 238 \n                 and Comment \n                 page 260 \n               \n                     Rare-disease studies seek online giving 2011-Jun-27 \n                   \n                     Garage biotech: Life hackers 2010-Oct-06 \n                   \n                     Biomedical philanthropy: State of the donation 2007-May-16 \n                   \n                     SciFlies \n                   \n                     RocketHub \n                   \n                     Kickstarter \n                   \n                     Fundageek \n                   \n                     The Open Source Science Project \n                   Reprints and Permissions"},
{"file_id": "481014a", "url": "https://www.nature.com/articles/481014a", "year": 2012, "authors": [{"name": "Nicola Jones"}], "parsed_as_year": "2006_or_before", "body": "Five experiments as hard as finding the Higgs. As the media spotlight shines on the Large Hadron Collider in Geneva and its high-profile hunt for a certain boson, other scientists are pressing forward with experiments that are just as challenging \u2014 and just as potentially transformative. These often unsung researchers are willing to spend years or even decades getting a finicky instrument to run smoothly; setting up proper controls to minimize spurious results; beating back noise that threatens to swamp their signal; and striving for an ever more painstaking level of precision \u2014 a determination and single-mindedness that borders on heroic. Here,  Nature  describes five such quests. \n               Spotting distant signs of life \n             Back in 1999, when David Charbonneau was a graduate student at Harvard University in Cambridge, Massachusetts, he became the first person to measure the tiny dimming caused by the passage of a planet from another solar system across the face of its parent star. Today, such 'transits' are a routine way for astronomers to discover planets. The tricky part is working out what they and their atmospheres are made of. If the atmosphere turns out to contain oxygen, for instance, that could be an indication of the presence of life. But the only way to detect such elements is to find them in the spectrum of the starlight that passes through the planet's atmosphere \u2014 a signal that is ridiculously small. To begin with, explains Charbonneau, \u201cthe fraction of light that the planet blocks is tiny\u201d. A planet the size of Jupiter passing in front of a star like the Sun would block about 1% of the light; and a smaller, Earth-size planet would block about 0.01%. \u201cThen you look at this tiny onion skin around the planet: that's the atmosphere,\u201d Charbonneau says. Only the starlight that passes through that onion skin will have the spectral information that astronomers are looking for \u2014 and that's less than one photon in a million for a Sun-like star and a planet the size of Earth. Although no telescope today has anywhere near the sensitivity required to extract a signal that small from the glare of the star itself, Jupiter-scale gas-giant planets have much bigger atmospheres than Earth-sized ones and a correspondingly bigger spectral signature, says Charbonneau. Orbital observatories such as the Hubble and Spitzer space telescopes have been able to extract atmospheric spectra for about 40 gas giants, all since 2005. Although the initial observations met with scepticism, says Charbonneau, \u201cfor the gas giants, it's now not quite commonplace, but not controversial. Now it's all about Earth-like planets, but no one has done that yet.\u201d The closest researchers have come is examining the spectra of a super-Earth \u2014 called GJ 1214b \u2014 that has a radius about 2.6 times that of Earth's and is circling a relatively small star not too far from the Sun. The first work on this planet implied that it had an atmosphere full of water vapour or clouds; observations by Charbonneau and his colleagues using Hubble confirmed this a few months ago 1 . Detecting the components of the atmosphere of an Earth-like planet around a Sun-like star \u2014 affording the best chance of detecting biological activity on another planet \u2014 requires a step-up in sensitivity. Charbonneau is crossing his fingers and hoping that NASA's long-planned and much-delayed Hubble successor, the US$8-billion James Webb Space Telescope, now scheduled for launch in 2018, will indeed reach orbit. \u201cThat would be fantastic,\u201d he says. \u201cThat would give us an honest shot at finding life on other planets.\u201d \n               Seeing through the molecular mirror \n             Biology has a curious lopsidedness. Many molecules are 'chiral', meaning that their atoms can be arranged in two forms that are mirror images of each other. When making such molecules in the lab, chemists typically get a mix of both forms, which, by convention, they label as right- or left-handed. But living cells are generally made from the left-handed versions only. No one knows why. One possible explanation lies in the fact that one of the four fundamental forces in nature predicted by the standard model of particle physics \u2014 the 'weak' force that mediates certain interactions between nuclei and electrons \u2014 affects left- and right-handed molecules differently. The other forces, which include gravity, are the same in either version of a mirror universe. In theory, explains Beno\u00eet Darqui\u00e9 at the University of Paris 13 North in Villetaneuse, France, the weak force should cause the energy states in one form of a chiral molecule to be ever so slightly different from those in its mirror image twin \u2014 typically by just one part in 10 15  or 10 20 . So if one form had a vibrational frequency of, say, 30 terahertz, its partner's should differ by just a few milli- or even microhertz. Measuring such tiny differences could shed light on the biological lopsidedness conundrum, says Darqui\u00e9, and his group is attempting to do just that. It could even fill in the values of certain parameters in the weak-force theory part of the standard model. He and his colleagues are the only ones in the world pursuing this goal, as far as Darqui\u00e9 knows. Indeed, it took him a full three years to assemble the consortium of experimental physicists, quantum theoreticians and chemists he needed. They now need to crack two problems. First, they need to build extremely high-resolution spectrometers to measure the energy levels of chiral molecules. Their best instrument to date can discern energy differences as small as 5 parts in 10 14  \u2014 about a million times better than the resolution of an off-the-shelf spectrometer. They are now building one that will be even more precise. To achieve such sensitivity, their machines need to be isolated from any external vibrations and maintained at a temperature that is steady to within 0.1 \u00b0C. And to measure the molecular vibrational frequencies with the required level of precision, Darqui\u00e9's lab uses a molecular clock linked by a fibre-optic cable to the world time standard atomic clock in Paris. The researchers' second challenge is to create test molecules in which the asymmetrical effect is large enough to be measurable. Such a molecule needs to have a large central atom, because atomic theory says that will maximize the energy differences between the chiral forms, and must not break apart when heated to the gaseous state necessary for spectroscopy. The team is betting that the best molecule will be something like methyltrioxorhenium that has had two of its oxygen atoms replaced by sulphur and selenium, although the researchers have struggled to make that particular molecule in purely left- or right-handed forms. Even if the researchers find a molecule that works perfectly, they will still need another year to take enough measurements to bump up the signal-to-noise ratio and get a trustworthy number. What if the experiment doesn't solve the puzzle of biological handedness? Darqui\u00e9 says that it won't bother him much, because the techniques they are developing will open up a lot of ways to test the theories of fundamental physics. \u201cMost of the accurate tests are done at high energy with particles, or at lower energies with atoms,\u201d he says. \u201cMolecules are more complex, so give access to more complex questions.\u201d \n               Looking for extra dimensions \n             It is an aspect of reality so fundamental that most us can't imagine anything different: the world has precisely three spatial dimensions \u2014 left\u2013right, forwards\u2013backwards and up\u2013down. But superstring theory and other attempts to devise a 'theory of everything' have led many physicists to propose that space has many more than that. These extra dimensions would presumably be curled up very tightly, and thus hidden from everyday experience. But they would affect gravity at very small scales, producing a force between two masses that differs ever so slightly from that predicted by Newton's classical law of gravity. An experiment able to detect changes in gravity at that scale might therefore be able to 'see' any other dimensions. Eric Adelberger at the University of Washington's Center for Experimental Nuclear Physics and Astrophysics in Seattle first heard about this idea at a talk back in 1999. \u201cSome people thought it was crazy; some thought it was really cool,\u201d he says. But he and his colleagues decided they had to test it. \u201cWhat more exciting thing can you do than discover that our understanding of the dimensionality of the world has been wrong forever?\u201d he says. The team's tool of choice is a torsion balance \u2014 essentially an update of the equipment used by the English physicist Henry Cavendish to make the first laboratory measurement of gravity in the late 1790s. In the modern version, a metal cylinder hangs from a thread, allowing the cylinder to twist freely. Attached to the bottom of the cylinder is a disk called the detector, which has a ring of holes drilled in it. A second disk, with similarly drilled holes, sits just micrometres beneath this. When this second disk, called the attractor, is rotated, the material between its holes exerts a tiny gravitational force on the material between the holes in the detector. The force twists the thread that supports the cylinder, causing it to rotate by an amount measured in billionths of a degree. To make sure that the detector is responding to gravity and nothing else, the equipment has to be made entirely from non-magnetic materials, and all the surfaces need to be coated in gold to spread out any electrical charges on the device. The device also has to be machined to perfection and protected from all vibrations, including cars driving into the car parks outside. \u201cWe get our best data on weekends from midnight to 4 a.m.,\u201d says Adelberger. \u201cIt's frustrating. The amount of time you spend actually getting good data is very small. It's all detective work.\u201d Tweaks to the design allow the experimenters to cancel out the force expected from Newton's law and isolate the deviations: if the detector spins anyway, they know that something funny is going on. And so far, Adelberger's group can say definitively that there are no extra dimensions larger than 44 micrometres. Two of his graduate students, as well as a handful of other groups around the world, are trying to push that limit down, he says. But how long it will take them to spot something depends on the size of the elusive dimensions. If they're curled up too tightly, he says, \u201cthe answer is never. If there is one at 30 micrometres, it'll be a year\u201d. But Adelberger seems to thrive on the uncertainties and difficulties involved. It's like getting to the top of a mountain, he says. \u201cThe harder it is, all the better it feels when you get there.\u201d \n               Catching a gravity wave \n             Scott Ransom has a boyish energy that seems mismatched with his subject: a project that may take a decade to produce its first result. Ransom, an astronomer at the National Radio Astronomy Observatory in Charlottesville, Virginia, uses a rapid-fire stream of words such as \u201cawesome\u201d and \u201ccool\u201d as he talks about the Galaxy's most precise natural clocks \u2014 pulsars \u2014 and how they might allow him and others to detect one of the most fundamental predictions of Einstein's general theory of relativity: gravitational waves. \u201cIt will open a whole new window on our Universe,\u201d he exclaims. \u201cWe will be able to see with mass instead of light.\u201d According to Einstein, explains Ransom, gravity waves are ripples in the fabric of space-time caused by the movement of mass \u2014 an orbiting pair of neutron stars, for example. It's just like jiggling an electron, which causes ripples in the surrounding electric and magnetic fields to spread out as light and other forms of radiation. \u201cWhen you jiggle something massive,\u201d he says, \u201cyou give off gravitational waves\u201d. Unfortunately, even a very big gravitational wave washing over Earth would squash and expand the planet's diameter by only 10 nanometres or less. Ground-based experiments attempting to detect such tiny disturbances, such as the Laser Interferometer Gravitational wave Observatory run by the California Institute of Technology in Pasadena and the Massachusetts Institute of Technology in Cambridge, are forever trying to distinguish genuine signals from background noise caused by passing trucks, thunderstorms and even the fall of waves on a beach a hundred kilometres away. So Ransom and his fellow enthusiasts are taking what they hope will be a cheaper path: looking at pulsars. Some of these ultra-dense stars rotate thousands of times a second, each time emitting a flash of radiation that astronomers can time to within about 100 nanoseconds. The team hopes to monitor about 20 such pulsars spread all over the sky to look for deviations in their timing caused by very-low-frequency gravity waves contracting or expanding the space-time between them and Earth. They expect that one of the strongest sources of such waves is the years-long dance of massive black holes in distant, colliding galaxies. Ransom is one of about a dozen people devoted to this quest, which is coordinated by the International Pulsar Timing Array consortium. The good news is they haven't needed to invent any instruments: facilities such as the Arecibo radio telescope in Puerto Rico can do the job. The bad news is that the pulsars need to be monitored for around 10 years to catch the gravitational waves from those orbiting black holes. So far, they have accurate timing measurements for about 5 years on just 6 pulsars. Still, says an upbeat Ransom, \u201cthe cool thing is that our chance of discovery goes up dramatically with time. As long as we're patient, we will see gravitational waves.\u201d \n               Redefining the kilogram \n             The mass of one kilogram is meant to be an unvarying constant. Yet it actually changes, thanks to an old-fashioned way of defining it as the mass of a more-than-120-year-old cylinder of platinum and iridium that lives in a vault in the outskirts of Paris. No one knows if 'Le Grand K' is getting heavier as atoms are added to its surface, or lighter as atoms are rubbed away, but its mass is certainly drifting: copies that once had precisely the same weight now have measurably different weights. \u201cWe need to tidy things up,\u201d says Jon Pratt, an engineer at the US National Institute of Standards and Technology (NIST) just outside Washington DC, one of a number of metrologists working on a redefinition. The kilogram is the only fundamental unit of measure still defined by a physical object, he says. The basic idea is to pin the kilogram to a precisely measured fundamental physical constant, in much the same way that the metre is now defined in terms of the speed of light in a vacuum: it's the distance that light travels in precisely 1/299,792,458 seconds. To do this for the kilogram would mean fixing Planck's constant,  h , which reflects the size of energy quanta in quantum mechanics and is famously linked to energy through the frequency of light:  E  =  h\u03bd . Combining that equation with the even more famous  E  =  mc 2  then leads to a definition of mass. Determining a precise value for Planck's constant is fussy work, however, and the two methods currently in favour disagree with each other enough to keep the redefinition of a kilogram on hold. One of these ways makes use of a 'watt balance'. In essence this is a simple set of scales: on one side it has a 1-kilogram mass \u2014 standardized carefully against the one in Paris \u2014 and on the other it has a current-carrying coil of wire immersed in a magnetic field. The field is tweaked until the weight of the mass is balanced by the electromagnetic force on the coil, which can then be linked through a string of equations to Planck's constant. But in practice things are not that simple. Researchers still have to measure other things \u2014 the local gravitational field, for instance, the biggest source of error \u2014 and avoid any kind of vibration. In 2007, a Watt balance now run by Pratt produced one of the most precise measurements of Planck's constant \u2014 6.62606891 \u00d7 10 \u221234  J s, with a relative uncertainty of 36 parts per billion 2 . But another instrument, built at the National Physical Laboratory (NPL) in Teddington, UK, and now located at the National Research Council's Institute for National Measurement Standards in Ottawa, Canada, has yielded a result that differs from NIST's by an amount that is small, but just outside the experimental error 3 . The other favoured approach is to count the number of atoms in a sample of isotopically pure material. That would determine the value of the Avogadro constant \u2014 the number of atoms in exactly 12 grams of carbon-12, say \u2014 which can be linked mathematically to Planck's constant through another string of equations. In 2008, scientists at the Federal Institute of Physical and Technical Affairs in Braunschweig, Germany, began working with two near-perfect 1-kilogram spheres that had been fashioned from 99.995% pure silicon-28. Since then they have been using high-precision laser interferometry to determine the spheres' volumes, and X-ray diffraction to determine their crystal structures so that they can count the atoms with ever-more accuracy. So far they have measured the Avogadro constant as 6.02214082 \u00d7 10 23  with a relative uncertainty of just 30 parts per billion 4 . The translation of that into Planck's constant agrees with the NPL's watt-balance result, but not with the NIST's. As of 2010, the recommended value for Planck's constant is 6.62606957 \u00d7 10 \u221234  J s, with an uncertainty of 44 parts per billion. Some say that's good enough to use to redefine a kilogram. But others want to keep picking away at it until the numbers agree better with each other and have a smaller range of error \u2014 to within 20 parts per billion. That could take quite a while, says Pratt. \u201cThese are hard measurements to make. That's just the way it is.\u201d \n                     Astronomy: Exoplanets on the cheap 2011-Feb-02 \n                   \n                     Getting the drop on gravity 2010-Jun-17 \n                   \n                     Pulsar watchers race for gravity waves 2010-Jan-13 \n                   \n                     Scott Ransom \n                   \n                     Beno\u00eet Darqui\u00e9 \n                   \n                     David Charbonneau \n                   \n                     University of Washington gravity group \n                   \n                     Redefining the kilogram \n                   Reprints and Permissions"},
{"file_id": "481018a", "url": "https://www.nature.com/articles/481018a", "year": 2012, "authors": [{"name": "Ron Cowen"}], "parsed_as_year": "2006_or_before", "body": "Data from NASA's Kepler space telescope have revolutionized the search for planets outside the Solar System \u2014 and are now doing the same for asteroseismology. Most astronomers gaze at the heavens and see stars. William Chaplin hears an orchestra \u2014 a celestial symphony in which the smallest stars are flutes, the medium-sized ones are trombones and the giants are reverberating tubas. The sounds are internal vibrations that reveal themselves as a subtle, rhythmic brightening and dimming of a star, explains Chaplin, an astrophysicist at the University of Birmingham, UK, and a specialist in asteroseismology. These waves provide information that astronomers can't get in any other way: triggered by the turbulent rise and fall of hot gases on the star's surface, the vibrations penetrate deep into the stellar interior and become resonating tones that reveal the star's size, composition and mass (see 'Celestial music'). So by watching for the characteristic fluctuations in brightness, says Chaplin, \u201cwe can literally build up a picture of what the inside of a star looks like\u201d. Better still, he adds, asteroseismologists are now hauling in the data wholesale. After years of being hampered by Earth's turbulent atmosphere, which obscures the view of the Universe and has limited asteroseismology to about 20 of the brightest nearby stars, researchers have been astonished by the trove of information coming from a new generation of space observatories. Thanks to the French-led Convection, Rotation and Planetary Transits (COROT) space telescope, launched in 2006, and NASA's Kepler space telescope, launched in 2009, they can now listen in on hundreds of stars at a time. \u201cWe are in a golden age for the study of stellar structure and evolution,\u201d says Hans Kjeldsen, an astronomer at Aarhus University in Denmark. \u201cNature seems to have been kind to us,\u201d agrees Ronald Gilliland, an astronomer at Pennsylvania State University in University Park. \u201cThe stars seem not to be shy about showing us lots of oscillations that will allow us to reveal their innermost secrets.\u201d The flood of data has shed light on the interior of red-giant stars, and forced astronomers to question their understanding of how stars and galaxies form. \n               Stellar serendipity \n             Asteroseismology isn't the main mission of either COROT or Kepler: they are intended to hunt for planets outside the Solar System (exoplanets) that have roughly the size and orbital radius of Earth. But because they both look for the tiny dip in brightness caused when a planet transits, or passes in front of, its parent star, they both have to record a drop in stellar brightness of no more than 1 part in 1,000. And that, in theory, makes them able to detect the effects of the stellar sound waves. Before launch, no one could say whether the satellites would make good on this. Kepler's exoplanet search has, in fact, been hindered by stellar oscillations that obscure transits, but are caused by magnetic activity 1 , so are unrelated to sound waves. Acoustic oscillations and transits don't interfere with each other: sound waves cause the brightness of Sun-like stars to vary on time scales of 5\u201315 minutes, whereas planetary transits last for hours. So the planners for both COROT and Kepler were happy to include asteroseismologists in their mission teams. \u201cWe are riding on the back of the planet hunters,\u201d says Douglas Gough, an asteroseismologist at the University of Cambridge, UK. As it turned out, the sound-wave data came down in an avalanche \u2014 especially from Kepler, which has a 0.95-metre-aperture telescope \u2014 nine times the sensitivity of COROT's \u2014 plus the ability to look at a larger group of stars for a longer period of time than COROT. \u201cEverything came together marvellously well,\u201d says Gilliland. Last April, Chaplin and his colleagues published their analysis 2  of acoustic oscillations observed by Kepler in 500 Sun-like stars. The frequency and amplitude of the oscillations revealed that the stars have roughly the sizes predicted by established theories of astrophysics, but the distribution of their masses turned out to be significantly lower than expected. Chaplin isn't yet sure what to make of these findings. But if further observations of the same stars continue to show masses lower than estimated, theorists may have to rethink models of star formation and galaxy assembly. \u201cWe didn't have a way of testing these models until we began doing the asteroseismology with Kepler,\u201d says Chaplin. And getting them right is crucial: not only do stellar masses underlie theories of galaxy formation, they are also essential for understanding how thermonuclear reactions in stars have produced heavy elements throughout the history of the galaxy \u2014 heavy elements that eventually formed planets including Earth. \u201cThis is amazing to witness,\u201d says Kjeldsen. With the latest data, he adds \u201cwe can test our assumptions, ideas, theories and models in great detail. And we can correct all our errors too.\u201d \n               Secrets of the giants \n             Some of Kepler's biggest surprises have been in its sounding out of red giants. These are Sun-like stars that have exhausted the hydrogen at their cores, causing a fuel crisis that paradoxically leads them to swell up to more than 100 times their original diameters. In about 5 billion years' time, for example, the Sun will become a red giant big enough to devour the innermost planets of the Solar System. Astronomers would like to be able to distinguish between two phases of red-giant evolution: an early stage, in which the giant is still fuelled by hydrogen in a thin shell around a dense core only a few times bigger than Earth; and a later stage, in which the star has begun burning the helium at its core. Knowing the difference would help them to determine the red giants' ages, how quickly they evolve and the amount of gas and heavy elements that they shed into interstellar space during each phase. That was impossible until Kepler: from the outside, a red giant looks the same regardless of what it is burning. But last March, Timothy Bedding, an astronomer at the University of Sydney in Australia, and his colleagues reported 3  that Kepler oscillation data allowed for a clear distinction. \u201cIt's difficult not to be fascinated by an ability to learn about the properties of the tiny core of these huge stars from oscillations on their surface,\u201d says J\u00f8rgen Christensen-Dalsgaard, an astronomer at Aarhus University and a co-author of the study. Going further, the same researchers reported in December 4  that they had measured the rotation rate of the core region of a red giant for the first time, and discovered that it whips around about ten times faster than the surface. This finding confirms the standard model of red-giant formation \u2014 Sun-like stars flinging their shallower layers outwards while their cores contract. Basic physics demands that angular momentum is conserved, so the outer layers must slow their rotation and the contracting core must speed up, just as observed. \n               Mission not yet accomplished \n             Many astronomers have called for an extension to Kepler's mission, which is currently slated to end in November. It is unclear whether NASA will be able to heed them; funding is tight, and other missions need money, too. But asteroseismologists are helping to make the case. They point out, for example, that acoustic oscillations in the Sun shift their frequency ever so slightly \u2014 a change of about 1 part in 10,000 \u2014 over the course of the Sun's 11-year magnetic cycle. The shift provides a new way to measure the length of the cycle, in which changes in the Sun's magnetic field drive sunspots, flares and other fluctuations in energy that can wreak havoc on Earth's satellites and communication systems. Astronomers would now like to compare the Sun's magnetic-activity cycle with those of a slew of similar stars. If the other stars have cycles extending over many years, says Gilliland, Kepler's baseline mission will not be able to track them. \u201cBut with observations extending to 7\u20138 years, or even more \u2014 the spacecraft seems good to allow 11 \u2014 we will be able to probe many stellar activity cycles. It would be profoundly more powerful,\u201d he adds. An extended mission could also allow astronomers to learn more about a different class of oscillation that originates deep in a red giant's core, and could tell them a great deal about the core's structure and density. These oscillations have a very small amplitude by the time they make their presence known at the surface, but their reverberations are persistent, like those of a heavy bell, lasting for months or years. \u201cWe've just begun to wring the interesting astrophysics out of these results,\u201d says Gilliland, and the ability to take data over many years would be an immense help. Asteroseismology may even help in Kepler's primary mission of finding Earth-sized exoplanets orbiting in the habitable zone around their stars, notes Chaplin. Because the craft can detect an exoplanet only by the amount of light that it blocks as it passes in front of its host star, and can measure it only in relation to the host, the radius of a planet is known only as accurately as the radius of the star. But sound-wave oscillations recorded from the parent star can pin down its size very accurately 5 . Such measurements are possible for only the brightest of the stars in Kepler's field of view, but they could make a huge difference in the researchers' confidence in their data as they begin to report detection of planets approaching Earth's size 6 , 7 . Johannes Kepler, the seventeenth-century astronomer after whom the spacecraft was named, theorized that Earth and all the other known planets made their own sounds \u2014 an arrangement that he called the music of the spheres. It would be only fitting if celestial music, of a kind, had a key role in the Kepler space telescope's most prized discovery. \n                     Super-Earths give theorists a super headache 2011-Dec-13 \n                   \n                     Fast core rotation in red-giant stars as revealed by gravity-dominated mixed modes 2011-Dec-07 \n                   \n                     Gravity modes as a way to distinguish between hydrogen- and helium-burning red giant stars 2011-Mar-30 \n                   \n                     The Kepler mission \n                   \n                     The COROT mission \n                   \n                     Astronomy at Aarhus University \n                   \n                     Asteroseismology: The Study of Stellar Origins \n                   Reprints and Permissions"},
{"file_id": "481134a", "url": "https://www.nature.com/articles/481134a", "year": 2012, "authors": [{"name": "David Cyranoski"}], "parsed_as_year": "2006_or_before", "body": "A university cracks down on misconduct in China. Yang Wei has an easy smile and a carefree, even distracted, air \u2014 but he takes such a solemn approach to life that his wife sometimes tells him to relax. \u201cI take everything seriously,\u201d he says. The former materials scientist certainly took it seriously when, two years after he became president of Zhejiang University (ZJU) in Hangzhou, China, he faced a case of scientific misconduct that became a turning point for his presidency. In early October 2008, the editor of the  International Journal of Cardiology  discovered that figures in a manuscript by He Haibo, a scientist researching traditional Chinese medicine who had been hired by the ZJU only months before, were suspiciously similar to those in an article that He had published elsewhere. Confronted, He quickly owned up, submitting a 12-page confession to Yang on 26 October. But the case, which eventually led to the retraction of eight papers, spiralled into an international media catastrophe for the ZJU, one of China's oldest and largest universities, as well as one of the most successful in publishing science. Articles attacked the laxity of a system that gave leadership roles to the likes of Li Lianda, dean of the department of pharmaceutical sciences and He's supervisor, who was largely absent from the lab and unfamiliar with the work, but was last author on some of He's papers. \u201cThere was plagiarism, fabrication and falsification. It was a showcase of every kind of problem,\u201d says Yang. Facing one of the best-publicized misconduct cases in China's recent history, Yang knew he had to act quickly. He personally wrote to all the editors of the journals involved. They supplied copies of copyright-transfer forms with all the co-authors' signatures, and Yang sent them to the national calligraphy centre. \u201cMost signatures were identical to He's own,\u201d says Yang. \u201cEven I could tell that.\u201d In March 2009, the ZJU fired He, terminated the contract of Wu Limao, a co-author on several of He's papers and the laboratory head in Li's absence, and took away Li's dean-ship and graduate students. Yang didn't stop there: he launched a campaign to make the ZJU more responsive to misconduct. With an energetic companion named Yuehong (Helen) Zhang cracking down on the university's journals (see \u2018Policing the plagiarists\u2019), and assistance from a group of university administrators who share his determination and commitment to a zero-tolerance policy for misconduct, Yang hopes to make the ZJU into a role model that can help to clean up China's reputation for rife scientific misconduct. That reputation, exacerbated in the past five years by a string of high-profile cases (see  Nature 441, 392\u2013393; 2006 ), has made observers and journal editors increasingly sceptical of the ability of Chinese research institutions to ensure trustworthy science. \n               boxed-text \n             Yang, who now tours the country giving lectures on scientific integrity, has established a reputation as the most evangelical of the reformers. His collaborators are impressed. \u201cHe is committed to cleaning things up at Zhejiang,\u201d says Mark Frankel, director of the Scientific Freedom, Responsibility and Law Program at the American Association for the Advancement of Science (AAAS) in Washington DC, who is working with Yang to improve research ethics. Frankel says that efforts such as Yang's are driving change. \u201cWhat is most impressive is how open and willing the people with whom I work in China are to admit that a serious problem exists, and that they are committed to turning things around for the younger generation of scientists,\u201d he says. \n               The scale of the problem \n             There are no comprehensive statistics on the extent of research misconduct in China \u2014 and few ministries, agencies or universities make cases public. Surveys and anecdotal evidence, however, reveal a deep-rooted problem, and suggest that students are learning unethical behaviour alongside their science. In an unpublished 2008 survey of 1,641 students at 10 universities, Cao Nanyan, a research-integrity specialist at Tsinghua University in Beijing, found that more than 20% of students admitted to changing data that didn't match their expectations. Some 60% of PhD students said that they sometimes witnessed misconduct, yet only 5% would report it \u2014 and Cao found evidence that the students' tolerance of misconduct increased the longer they stayed in education. \u201cIt suggests that the more entangled you are in the system, the less able or motivated you are to pursue good practices,\u201d says Daniele Fanelli, a social scientist at the University of Edinburgh, UK, who has studied the frequency of scientific misconduct. Fanelli says that Cao's figures are \u201cclearly worrying, because they would suggest much higher rates of misconduct, and lower rates of reporting, compared to what is usually reported in surveys in Western countries\u201d. Cao and other experts on misconduct point to specific contributing factors. China's research system has developed very rapidly, and universities are scrambling to train the influx of students, scientists and administrators. \u201cAs a large, newly developed system of research, China does not have the control of its research programmes that is found in the West,\u201d says Nicholas Steneck, who studies research integrity at the University of Michigan in Ann Arbor. Some researchers are simply oblivious to the rules, says Zhong Haining, a neuroscientist who trained at Tsinghua University and is now starting a lab at Oregon Health and Science University in Portland. \u201cThe official guideline for scientific misconduct may (or may not) exist, but it's not very well publicized, at least not emphasized so much in training,\u201d he says. Steneck adds that these issues may be rooted in a broader lack of honesty in governance, and that this makes it tough to build a culture of honest research. \u201cIt is difficult to have integrity in research if integrity in other aspects of life is questionable,\u201d he says. The government, universities and research institutions have introduced a cornucopia of integrity policies over the past decade. But enforcement is problematic, says Mu-ming Poo, director of the Institute of Neuroscience in Shanghai. Most Chinese funding organizations do not, for example, have permanent offices to deal with misconduct in a systematic and transparent fashion, as the Office of Research Integrity at the US Department of Health and Human Services attempts to do. \u201cVery few people in the funding agency or in the scientific community are willing to be the 'bad guy' and enforce the regulations,\u201d says Poo. He points to an investigation into what he considered a clear-cut case of misconduct. A researcher was dismissed, but soon found a job elsewhere and continued to get large grants. \u201cThere's essentially no punishment for scientific misconduct,\u201d says Poo. \u201cThe tolerance and appeasement within the community \u2014 that really worries me.\u201d \n               Taking action \n             Yang had encountered misconduct before he became president of the ZJU \u2014 as a reviewer of manuscripts in fracture mechanics, and in roles such as director-general of the academic degrees committee of the State Council of China, a post that he held from 2004 to 2006. But when the He case came to light, Yang says he felt the weight of responsibility for the ZJU and its students, and this compelled him to act. \u201cIt's not that I want to do this. I have to do this,\u201d he says. In January 2009, on the basis of lessons learned in the He case, Yang created a research-integrity committee and an investigation task force at the ZJU. That March, at a conference to discuss the He situation, the Chinese minister of education called for a zero-tolerance policy towards misconduct \u2014 and Yang signed up. He issued a series of codes to guide behaviour on authorship, citations and submission procedures, including one that forbids electronic submissions of papers by a non-corresponding author. This addressed one of the key problems in the He case, in which He and some graduate students had submitted papers from an account under the name of the corresponding author, Wu. Yang replaced most of the ZJU's adjunct deans with full-time executive deans in an attempt to avoid the problems created by Li's absentee leadership. And he introduced new investigative procedures and spelled out disciplinary actions. All this helped Yang to prepare for a second big case, in mid-2010. The editor-in-chief of a journal published by Springer contacted Yang to say that plagiarism and fabrication in an article from a ZJU researcher were so egregious that Springer was considering blocking all submissions from the university to its 2,000 science, technology and medicine journals. (Yang declines to name the researcher or editor.) \u201cIt put pressure on. We had to convince them that we could handle the case,\u201d says Yang. This time, Yang was ready. He dismissed the main scientist involved, and cut the salary and PhD-student allocation of the corresponding author. \u201cSpringer was satisfied,\u201d says Yang. Over the past two years, Yang says, he has dealt just as briskly with another 40 or so misconduct cases at the ZJU. More than 20 researchers have been found guilty of wrongdoing after discussion by the university administration. For the ten cases involving recent graduates, more than half lost their degrees. One sued the ZJU to overturn the ruling of plagiarism. She lost. If work done during your training is fraudulent, \u201cyour degree should be taken away\u201d, says Yang firmly. In cases involving faculty members, three had their employment terminated, four faced disciplinary action including a pay cut, and the rest were issued with public or internal warnings. Some have been temporarily forbidden from taking on PhD students. But laws and punishment go only halfway towards tackling the problem \u2014 prevention is also essential. At the ZJU, Yang has established a system for mentoring young faculty members on research ethics, and since 2009 the university has held more than ten seminars and lectures on research integrity, with attendance at some surpassing 1,000. Yang also continues his talks at universities around the country. \u201cWe have to train them to be honest. It's not enough to be aware of the ethics code. You need to really understand it,\u201d says Gong Ke, president of Nankai University in Tianjin, who, with Yang and the AAAS, is preparing a book of scientific-misconduct cases that can be used to teach research integrity in China and the United States. \n               Slow progress \n             Yang says it is too early to tell whether his efforts are really paying off. Most misconduct cases are several years old by the time they come to light, so the researchers involved haven't been exposed to the education and enforcement efforts. And there is always the fear that teaching people about misconduct might simply make some determined individuals craftier \u2014 as in the case of those who try to outwit plagiarism-detection software with software of their own. \u201cBut at least they are more aware that they are doing something wrong,\u201d says Yang. Yang is not cleaning up Chinese science on his own. Other universities have established ethics courses and strengthened their investigation procedures. And China's aggressive 'online police' have been rooting out frauds \u2014 the XYS blog run by Fang Shimin has become famous for its tenacity. Posts on the website discuss problems with data, as well as discrepancies between researchers' CVs and their actual achievements. Fang is not yet convinced that the ZJU is rigorously investigating all the misconduct cases that it should. \u201cI don't think he takes his own words seriously,\u201d he says of Yang. But Fang notes that he has seen improvements in the 11 years since he started his own \u201cfight\u201d against misconduct. The media are more willing to report misconduct and appeal for reform, he says, \u201cand the government at least admits there are problems\u201d. Real change will take more time and effort. At a 2007 meeting on research integrity with the China Association for Science and Technology, Frankel recalls, one Chinese speaker after another presented data on how bad the situation was and \u201copenly worried about its effects on how science coming out of China would be perceived\u201d. The professional guidelines that are surfacing now, he says, are \u201cmerely a first step. They have adopted investigative practices and procedures similar to the United States but lack experience and manpower needed to be truly effective. This will take time.\u201d Even the best efforts of administrators such as Yang might not be enough to change deep-rooted behaviours, says Sheila Bonde, an archaeologist and historian at Brown University in Providence, Rhode Island, who is collaborating with the ZJU to create a course in ethics. \u201cTraining graduate students about ethics as they enter research laboratories is too little, too late and too specific,\u201d she says. \u201cThere is a critical need for broader discussion of ethical choices across the spectrum of Chinese academic, political and economic issues, and this has to begin much earlier in students' lives.\u201d Still, the passion for cleaning up China's science is tangible. Frankel says that reformers such as Yang have a different kind of drive from those in the United States, where \u201cthe emphasis is on accountability for spending the public's money, its impact on research progress, and public trust. My Chinese colleagues view research misconduct as a stain on their country,\u201d says Frankel. \u201cIt's almost personal there.\u201d The reason, suggests Steneck, is that the stakes for China are so high. \u201cIf other countries lose confidence in the integrity of Chinese science, it is the Chinese who will suffer the most,\u201d he says. \n                     China revokes top science award 2011-Feb-23 \n                   \n                     China revokes top science award 2011-Feb-21 \n                   \n                     Strong medicine for China's journals 2010-Sep-15 \n                   \n                     Publish or perish in China 2010-Jan-12 \n                   \n                     Named and shamed 2006-May-24 \n                   \n                     News in brief 2006-Apr-05 \n                   \n                     Zhejiang University \n                   \n                     Journal of Zhejiang University \u2014 Science \n                   \n                     Chinese Association for Science and Technology \n                   \n                     China National Knowledge Infrastructure \n                   \n                     AAAS\u2013CAST joint programme in scientific ethics \n                   \n                     New Threads \n                   Reprints and Permissions"},
{"file_id": "481130a", "url": "https://www.nature.com/articles/481130a", "year": 2012, "authors": [{"name": "Corie Lok"}], "parsed_as_year": "2006_or_before", "body": "With a history of public blunders, can Advanced Cell Technology make embryonic stem-cell therapies a reality? \u201cOh crap, this really puts us in the spotlight!\u201d thought Robert Lanza when he first heard the news. Advanced Cell Technology (ACT), the biotechnology company in Marlborough, Massachusetts, of which Lanza is chief scientific officer, had for more than a year been operating in the shadow of Geron, a rival company in Menlo Park, California. Geron was bigger and better funded than ACT, and it was the first company to be approved by the US Food and Drug Administration (FDA) to test a therapy in humans based on embryonic stem (ES) cells. ACT was second. But in November, Geron announced that it was halting its trial to focus instead on cancer drugs. And with the announcement, Lanza says, he felt the weight of the ES-cell field fall on his shoulders. Lanza and his company have had plenty of experience in the spotlight, but the attention has not always been flattering. Since the late 1990s, ACT has gained a reputation as a renegade company, accused of overhyping results to raise attention and money. Critics say that the company has damaged the field more than once with its high-profile, controversial announcements, such as one describing the company's attempts to clone a human embryo 1  in 2001. ACT's actions \u2014 and the highly politicized nature of stem-cell research \u2014 scared off investors, leaving the company teetering on the verge of bankruptcy for most of the past decade. But the scrappy biotech refused to die, in part because of Lanza's doggedness. ACT is now performing early-phase clinical trials testing the safety of implanting retinal cells derived from human ES cells into the eye to treat certain types of blindness. Lanza says that this time, he aims to do things right: direct good science focused on treating disease, publish in reputable journals with rigorous peer-review processes and work with high-quality collaborators and clinical centres for its trials. \u201cWe're a different company now,\u201d says Lanza. Not everyone is convinced. Even if positive results emerge from these trials, ACT will still face major challenges in getting an ES-cell-based therapy approved for wider use. And some in the field are sceptical about ACT's reformation. \u201cCan you really trust a company that has a spotty record?\u201d says Arthur Caplan, a bioethicist at the University of Pennsylvania in Philadelphia. It's not just Lanza who has a stake in the answer. With Geron out of the game, ACT's success or failure will be important for a field looking to prove itself worthy of further research funding. \u201cIf the trials are positive, that would fundamentally transform the debate,\u201d says Christopher Thomas Scott, director of the Program on Stem Cells and Society at Stanford University in California. \n               Problem child \n             ACT began in the mid-1990s as an animal-cloning outfit owned by Avian Farms, a Maine-based poultry genetics company. ACT quickly shifted focus when Michael West \u2014 who founded Geron \u2014 became its chief executive in 1998. Human ES cells had just been isolated for the first time, and researchers were excited about their potential use in regenerative medicine. But many were concerned that patients' immune systems would reject cells derived from unrelated embryos. To solve this, West proposed 'therapeutic cloning' \u2014 taking the nucleus out of a patient's cell, transferring it into an egg cell to create a cloned embryo, then using that embryo to derive patient-matched stem-cell lines. In 1999, using money he had made at Geron, West bought ACT. Lanza, a physician who had spent the past 20 years working in academic research and biotech on organ and cell transplantation, was one of West's first recruits. The team moved quickly to try to make therapeutic cloning a reality. If the American public had not yet heard of human cloning or ACT by the fall of 2001, it could hardly have missed the hype that began on 25 November that year. West appeared on  Meet the Press , a nationally televised US political talk show, to discuss a paper, published that day, in which ACT scientists described the first cloning of a human embryo. \u201cWe've taken the first halting steps toward what we think is going to be a new area of medicine,\u201d West said. West appeared on several other news shows in the following days. CNN and  US News and World Report  heralded the work as a breakthrough, and West and his team hailed the \u201cdawn of a new age in medicine\u201d in a report for  Scientific American  (now owned by Nature Publishing Group). In the paper 1 , published in the now-defunct online journal  e-biomed , West, Lanza and their colleagues showed that they could pull a nucleus from a human egg cell, replace it with a whole adult ovarian cell and generate an embryo that divided into six cells. It then stopped growing, far short of the 100-cell blastocyst stage from which stem cells can be derived. The work pressed a political hot button. That summer, President George W. Bush had approved federal funding for human ES-cell research, but only for a small number of cell lines that had already been created. He also voiced staunch opposition to human cloning of any kind, and a bill to ban it had been advancing through the US Congress, much to the chagrin of researchers who saw promise in therapeutic cloning. ACT's announcement stoked fears that scientists were trying to clone humans for reproductive purposes \u2014 and conflated reproductive cloning and human-embryonic-stem-cell research in many people's minds. \u201cIt gave critics plenty of ammunition to insist that if stem-cell research was funded, human reproductive cloning would be funded too,\u201d says Caplan. \u201cIt had a huge deleterious impact for years.\u201d Scientists, meanwhile, dismissed the finding. The ACT team hadn't gained new insight into the human developmental process, says George Daley, a stem-cell researcher at Children's Hospital Boston in Massachusetts. \u201cI was not in a position to defend the cloning that they were doing because it was ineffective in what they were trying to do,\u201d he says. \u201cIt was more for publicity than for science.\u201d Jose Cibelli, who was first author on the paper and left ACT in 2002 for a faculty position at Michigan State University in East Lansing, says that in an ideal world he would have waited until the team could grow the embryos to the blastocyst stage before publishing the work. But he had heard rumours that other groups were pursuing the same goal, and he was worried about getting scooped. (A successful derivation of stem cells from a cloned human embryo was not reported until October 2011, and these stem cells had three sets of chromosomes rather than two 2 .) West says that he pushed ahead with publication in the interest of transparency. \u201cIt was our policy not to hide what we were doing and why,\u201d he says. \u201cWe wanted to be honest, accurate and open.\u201d The announcement ended up hurting the company, however. ACT was trying to raise a needed round of venture-capital financing when the cloning news broke. The negative attention combined with the political uncertainty around stem-cell funding killed the deal, says Greg Bonfiglio, who was with Anthem Venture Partners of Santa Monica, California, at the time, and would have been the lead investor on that round. \n               Scraping by \n             The disappearance of the venture funding sent ACT on a financial downward slide from which it would take nearly ten years to recover, says Bonfiglio, who has dealt with the company on several more occasions. Researchers at Geron, meanwhile, had successfully derived neurons from human embryonic stem cells 3  and were pursuing research that would eventually look to repair the damage caused by spinal-cord injuries, a possible use for embryonic stem cells that was much touted at the time. ACT was largely dismissed as a sideshow. Lanza is now the longest-serving employee of the company. He says that a \u201ctough childhood\u201d in Stoughton, a town south of Boston, Massachusetts, helped him to develop a thick skin. Unlike many Boston-area academics, Lanza has the 'R'-dropping accent of the region, most noticeable when he talks about one of his main preoccupations: Stargardt's disease. \u201cStahgahdt's\u201d \u2014 as he says it \u2014 is one of the two types of degenerative blindness his company is targeting in its clinical trials. The other, the 'dry' form of age-related macular degeneration, is the most common cause of age-related blindness. Both diseases result from the death of retinal cells, a process that Lanza suspects can be slowed or even halted using stem-cell-derived replacements. After the venture funding fell through, West sold ACT's animal-cloning division to generate revenue. By 2004, however, money had again started to run low. But Lanza and West had recently hired Irina Klimanskaya, who, as a researcher at Harvard University in Cambridge, Massachusetts, had helped to derive many of the institution's first human ES-cell lines and who had a knack for working with scant resources. At ACT, she began optimizing a protocol for transforming ES cells (derived from embryos donated through fertility clinics) into retinal pigmented epithelial (RPE) cells. These are lost in both Stargardt's and dry age-related macular degeneration 4 . Stopping vision loss didn't quite have the dramatic appeal of Geron's goal of reversing paralysis. But focusing on the eye may have been a wise decision, say experts. \u201cThe eye is an ideal place to begin this type of experimental work,\u201d says Michael Young, an ophthalmology researcher at the Schepens Eye Research Institute in Boston. Surgeons already have protocols for injecting cells directly into the eye, and they can measure changes in the retina just by peering into it. The eye is relatively sealed off from the immune system compared with other parts of the body, which may reduce the risk of cell rejection. Moreover, transplanted RPEs do not need to form synapses, or connections, with neurons, unlike other retinal cell types. \u201cIf cell-based therapy in the eye is going work, it's got to work with the RPEs,\u201d says Thomas Reh, a neurobiologist at the University of Washington in Seattle. By 2004, Lanza and his team were ready to start testing the RPE cells in animals \u2014 but they were paralysed by a lack of money. The cells sat in a freezer for almost a year. Meanwhile, the company's phone service was turned off, purchases of basic lab supplies grew harder to justify and the skeleton crew of remaining scientists wondered week to week whether they would get paid. Some left, but Klimanskaya opted to stay on. \u201cI believe in the company, in the cells, in the technology and in my own skills,\u201d she says. \u201cWhy should I quit?\u201d Out of desperation, West agreed at the end of 2004 to take the company public to gain access to a new source of funding. But the legal, accounting and marketing costs of going public through an initial public offering (IPO) were far beyond the company's reach. Instead, in early 2005, ACT merged with Two Moons Kachinas, an obscure, Utah-based outfit that sold Native American dolls. Two Moons was essentially a 'shell' company, allowing ACT to take it over and become a publicly traded firm. This 'reverse merger' was much cheaper than an IPO, but the US$8 million it raised had more strings attached. As part of the deal, investors required the company to name a new chief executive. \u201cThe issue with ACT at that time was never about the quality of the science team,\u201d says Bonfiglio, who led the deal. \u201cThe business skills were not resident on that team.\u201d The new chief executive, William Caldwell, had more than 30 years of experience in banking, transportation and telecommunications, but none in biotech. \n               Out of the ashes \n             With the infusion of cash, ACT went on a hiring spree. West, who became the company's president and chief scientific officer, moved to California and recruited several researchers in hope of starting a lab that could tap into funding from the San Francisco-based California Institute for Regenerative Medicine (CIRM), a $3-billion, state-backed fund for stem-cell research. Meanwhile, Lanza built up his team in Massachusetts and forged ahead with the RPE transplantation studies in rats. In 2006, positive results began to materialize 5  and ACT opened its new headquarters, a 1,400-square-metre research facility in Alameda, California, which included a lab capable of growing cells according to the strict standards required for human trials. Just as optimism was running high, the company made another very public stumble. In August 2006, Lanza and his co-authors published a paper 6  in  Nature  showing that a single cell could be plucked from an 8\u201310-cell human embryo and grown into stem cells. Lanza wanted to show that it was possible to derive stem cells without destroying the embryo, to sidestep ethical concerns. In fact, the embryos were destroyed in the experiments, but that had not been made clear in the original version of the paper, the press releases about it or in some of Lanza's press interviews.  Nature  issued two clarifications after its original press release, but many news organizations had already reported that the embryos were unharmed. When the truth became clear, critics pounced. Opponents of ES-cell research saw the debacle as an attempt to mislead the public, and scientists criticized the method as impractical and still ethically problematic. Biopsying embryos puts them at risk, says Daley, so some will be lost. Lanza says that the  Nature  paper was only meant to be a proof of principle and that the company soon perfected the technique so that embryos survived. But the episode reinforced perceptions that the company hyped its results, this time to boost its stock value. If that was the intent, the effect was short-lived. The increase in share price on the day of the announcement \u2014 from $0.42 to $1.83 \u2014 would be reversed in the weeks and months that followed. Unable to raise enough money from conventional sources, Caldwell turned to last-resort financing. ACT borrowed cash from investors and then repaid them in shares on a monthly basis, using the lowest share price of the previous month. As that price dropped, ACT had to issue more and more shares, forcing the price down even further. Caldwell completed several rounds of this 'death-spiral financing' between 2005 and 2010 to keep Lanza's RPE research going, and the company sank further into debt. By 2007, West says, he was not getting along with Caldwell and left ACT to head another company to develop products for ES-cell research. In 2008, ACT closed its Alameda facility \u2014 the CIRM funding never materialized \u2014 but Caldwell stayed in Los Angeles. By the time the markets crashed later that year, ACT's stock price had dwindled to pennies. Caldwell lost all of his executives, and the entire RPE development team left. Still, Lanza was convinced that RPE therapy held the key to the company's survival. He was, moreover, impressed with Caldwell's dedication to the project. \u201cHe got all excited [about the science], and that was important,\u201d Lanza says. \u201cHe was really my partner.\u201d The two worked tirelessly throughout 2009 to rebuild the company. Caldwell eked out funding so that Lanza and his team could do the studies needed for FDA approval of the clinical trials. \u201cWe knew we had one chance,\u201d says Lanza. In November 2010, when a fax arrived saying that the trial had been approved, a cheer went through the office. \u201cWe came out of the ashes,\u201d says Lanza. \u201cIt was a long time coming.\u201d There was little time for celebration, however. The team still needed approval from the clinical centres conducting the trials before they could start treating patients. Lanza usually began each morning by answering a slew of e-mails from Caldwell, who often worked later hours in Los Angeles. So he was concerned when, on the morning of 14 December, his inbox was empty. The call came later that afternoon from Caldwell's wife. The man who had kept ACT afloat for the past six years had died unexpectedly, aged 63. Describing the loss now, Lanza becomes quite emotional and almost can't continue. \u201cIt was like I lost a father,\u201d he says. The company faced yet another bleak period. But Gary Rabin, an investment banker who had been on ACT's board since 2007, stepped in as interim leader. Within two weeks, he had secured $25 million in financing from two firms that Caldwell had been courting. Rabin, who is now ACT's chairman and chief executive, says that the funding is enough to pay for the company's two ongoing trials and should last through 2012. \n               The challenges ahead \n             Now, the company's future hinges on the outcome of the trials. Final results won't be out until 2013, and they will show mainly whether the cell transplants are safe. The patients enrolled in the trial are in the late stages of vision loss, so the chances of dramatic improvement are remote, experts say. Still, Rabin and Lanza are optimistic. If the treatment is safe and even moderately effective, they say they would consider partnering with a pharmaceutical company to help take the programme forward \u2014 although they are still working out their plan. Scott, with Stanford's Program on Stem Cells and Society, says that positive results could fire up patient advocacy groups, which can be powerful in building support. And a good outcome could encourage investment in other stem-cell therapy companies, says Bonfiglio, who is now managing partner at Proteus Venture Partners in Palo Alto, California. But even if the trial results are positive, ACT will face enormous challenges in commercializing the technology. The company will have to show the FDA that its RPE cells can slow vision loss in bigger and more expensive clinical trials. And even if the treatment works, storing and distributing the cells, which often have short shelf-lives, is expensive and logistically difficult, says Chris Mason, head of the Stem Cell and Regenerative Medicine Bioprocess Group at University College London. These challenges were thrown into stark relief when Geron halted its stem-cell trial in November, having decided that the hurdles to commercializing the therapy were too great. Now, it is up to ACT to face them. \u201cThe departure of Geron from the field will ultimately place a greater burden on ACT in terms of educating the FDA and establishing standards for safety and efficacy,\u201d Bonfiglio says. ACT is not entirely alone: other stem-cell-based therapies are moving towards the clinic. For example, a consortium of research groups called the London Project to Cure Blindness aims to test RPE transplants from embryonic stem cells in patients with macular degeneration this year. A group in Japan hopes to test a similar approach in humans using stem cells from reprogrammed adult cells within the next three years. Still, some who have tracked ACT's trajectory say that the company might have what it takes to succeed. \u201cWhat has kept ACT going is persistence, tenacity and vision,\u201d says Ronald Green, ACT's long-time ethics adviser and a professor of religion and ethics at Dartmouth College in Hanover, New Hampshire. Lanza says that at times he considered giving up and working on something less controversial. \u201cIf I wasn't a stubborn Italian,\u201d he says, \u201cI would have thrown up my hands at least 25 times.\u201d \n                     Stem cells: The cell division 2011-Dec-14 \n                   \n                     Stem cells that are pure enough for the clinic 2011-Dec-06 \n                   \n                     Stem-cell pioneer bows out 2011-Nov-22 \n                   \n                     Blood transfusion for stem cell company? 2008-Aug-22 \n                   \n                     'Ethical' stem-cell paper under attack 2006-Sep-06 \n                   \n                     Advanced Cell Technology \n                   \n                     Geron \n                   \n                     ACT's Stargardt clinical trial \n                   Reprints and Permissions"}
]